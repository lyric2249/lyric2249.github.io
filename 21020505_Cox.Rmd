# Cox Regression




## Proportional Hazards Model

Proposed by Cox (1972, JRSS-B), primarily to model the relationship between **hazard function** and **covariates**. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science.


Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc.


※ Data Structure

Observed data: $\Big \{ X_i = T_i \wedge C_i, \; \; \; \Delta_i = I(T_i < C_i), \; \;\;  \mathbf Z_i (\cdot) \Big \} \overset {iid} \sim$

추가로 $N_i = I(X_i \le t , \;  \Delta_i = 1)$, $Z_i(t)$ = covariate vector (possibly time-dependent).





## Cox PH Model

$$
\lambda_i (t) = \lambda (t \vert Z_i ) = \lambda_0 (t) \exp (\beta' Z_i) \tag{Cox Model}
$$

semiparametric model:


- $\exp(\beta ' Z_i)$, parametric assumption on covariate effects
- multiplicative model
- $\beta$ : $p \times 1$ vector, $p < \infty$
- $\lambda_0(t)$, nonparametric; is $\infty$ dimensional
- shape of hazard function is unspecified

Due to nonparametric component, **standard maximum likelihood theory** does **not** apply 

Let $Z_{ij}$ be the $j$-th element of $Z_i$
- $\beta_j$ = difference in log hazards
- $\exp(\beta_j)$ = ratio of hazards; assumed constant for all $t$

- $\lambda_0(t)$: baseline hazard; common to all subjects, $\lambda_0(t) = \lambda_i(t \big | Z_i = \mathbf 0)$


The hazard ratio, $\exp(\beta_j)$, is sometimes referred to as a **relative risk**
- risk = **probability**, not a rate
- hazard is a **rate**, not a probability
- in ratio of hazards, time dimension cancels out

Direction of effect:
$$
\begin{align}

\beta_j > 0: &&\uparrow\lambda_i &&\downarrow S_i(t)
\\
\beta_j < 0: &&\downarrow\lambda_i &&\uparrow S_i(t)


\end{align}
$$

Magnitude of effect is easy to interpret w.r.t. $\lambda_i(t)$


Cumulative hazard function:

$$
\begin{align}

\lambda_i (t) &= \lambda_0(t) \exp(\beta Z_i)
\\
\Lambda_i (t) &= \int_0^t \lambda_0(s) \exp(\beta Z_i) ds
\\
&= \Lambda_0(t) \exp(\beta Z_i)

\end{align}
$$




Survival function:

$$
\begin{align}
S_i (t) &= \exp \Big \{ -\Lambda_i (t) \Big\}
\\
&= \exp \Big \{ -\Lambda_0 (t) \exp(\beta ' Z_i)\Big\}
\\
&= S_0(t)^{\exp \Big \{ \beta'Z_i \Big\}}


\end{align}
$$

By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard:
- ex) randomized trial: treatment ($Z_i=1$) versus placebo ($Z_i=0$); $\hat \beta = 0.405$ ($\exp(\hat \beta)=1.5$)
- $\lambda_i(t)$ for treated patients is 50% more of that of the controls.
- irrespective of $\lambda_0(t)$

Nevertheless, $\Lambda_0(t)$ is required in order to **determine $Z_i$'s effect on $S_i(t)$**, e.g.,


$$
\begin{align}

S(t \Big | Z_i = 0) = 0.95 && vs. && S(t \Big | Z_i = 1) = 0.93


\\
S(t \Big | Z_i = 0) = 0.70 && vs. && S(t \Big | Z_i = 1) = 0.59



\end{align}
$$



### Cox Model: Independent Censoring

Independent censoring assumption is less stringent than in nonparametric estimation.

Assumption is often written as $T_i \perp C_i \Big \vert Z_i$:
$$
\begin{alignat}{2}

&\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i < t+ \delta \Big | T_i \ge t , \; C_i \ge t , &&\; Z_i)
\\
= &\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i < t+ \delta \Big | T_i \ge t ,  &&\; Z_i)

\end{alignat}
$$

※ Note: $C_i$ is allowed to depend on $Z_i$








## Semiparametric PH Model: General


- General expression for multiplicative proportional hazards model:

$$
\lambda_i (t) = \lambda_0 (t) g(\beta ' Z_i )
$$

$g(x)$ is link function, specified. $\forall x: g(x) \ge 0$, $\exists g''(x)$, and in special case, $g(x) = \exp(x)$.

- Other choices for link function (e.g., Self & Prentice, 1983):
$g(x) = 1+x = (1+x)^{-1} = \log(1+x)$



※ Notes:
- not all choices of $g(x)$ lead to clear interpretation of $\beta_j$
- certain choices of $g(x)$ lead to numerical issues; e.g., likelihood is flat; local maxima, etc.
- $g(x) \not = exp(x)$ has received little attention in the literature








## Multiplicative Model

**Cox model** is a **multiplicative model**, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard.


- Additive models also been proposed

$$
$$










## Proportional Hazards Regression and Multiplicative Intensity Model

- Recall Counting process: martingale representation

$$
\begin{align}

N(t) &= I(X\le t , \; \Delta = 1)
\\
Y(t) &= I(X \ge t)
\\
M(t) &= N(t) - \int_0^t Y(u)\lambda_0(u) e^{\beta ' Z } du \tag{1}
\\
\mathcal F_t &= \sigma \Big \{ N(u) , Y(u+) , Z: \; \; 0 \le u \le t \Big \}



\end{align}

$$

1) intensity $l(u) = Y(u)\lambda_0(u) e^{\beta ' Z }$, therefore integrated form is cumulative intensity $A(t)$.



- Multiplicative Intensity Model:

$$
l(t) = Y(t)\lambda_0(t) e^{\beta ' Z(t) }
$$



- Counting process: $N(t)$ = Number of events of a specified type that have occurred by time $t$
  - $N(t)$ may take more than one jump
  - multiple infections, repeated breakdowns, hospital admissions
  - $EN(t) < \infty$



- At-risk process: $Y(t)$, left-continuous process,  $1$ if failure can be observed at time $t$, otherwise $0$.
  - $Y(t)$ can be used to represent situation in which a subject enter and exit risk sets several times
  - $Y(t)$ may be $1$ even after an observed failure


- Covariate process: $Z(t)$ = (bounded) predictable process
  - time-dependent treatment, risk factors
  - model checking and relaxing PH assumption

- Baseline hazard function: $\lambda_0(\cdot)$ = an arbitrary deterministic function
 

- Filtration: $\mathcal F_t = \sigma \Big \{ N(u) , Y(u+) , Z(u): \; \; 0 \le u \le t \Big \}$


- Martingale: $M(t) = N(t) - \int_0^t l(u) du$

- Intensity function: $ E \Big \{ dN(t) \Big \| \mathcal F_{t-} \Big} = l(t) dt$



- Data: $n$ independent observations on $ \Big \{ N(\cdot), \;  Y(\cdot), \; Z(\cdot) \Big \}$







## Likelihood; conditional, marginal and partial likelihoods

- $X =$ vector of observations; $f_X(x, \theta) =$ density of $X$
- $\theta =$ vector parameter; $\theta = (\beta ' , \phi')'$
- $\beta =$ parameter of interest; $\phi =$ nuisance parameter
- **likelihood**: $f_X(x, \theta) = f_{W|V} (w \Big | v, \theta )f_V (v, \theta)$

  - $X = (V', W')'$
  - infinite-dimensional $\phi$
  - $f_{W|V} (w \Big | v, \theta )$ does not involve $\phi$ $\Rightarrow$ use $f_{W|V} (w \Big | v, \beta )$ (conditional likelihood)
  - $f_V (v, \theta)$ does not involve $\phi$ $\Rightarrow$ use $f_V (v, \beta)$ (marginal likelihood)


$$
X = (V_1 , W_1 , \cdots, V_K , W_K)
$$

$$
\begin{align}


f_X(x, \theta) &= f_{V_1 , W_1 , \cdots, V_K , W_K} (v_1 , w_1 , \cdots, v_K , w_K\; ;\; \theta)
\\

&= 
f_{V_1}(v_1 \; ; \; \theta)

f_{W_1 | V_1}(w_1 | v_1\; ; \; \theta)

f_{V_2 | V_1, W_1}(v_2 |  v_1, w_1\; ; \; \theta) \times \cdots

\\

&= \left \{ \prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \theta) \right \}


\left \{ \prod_{i=1}^K f_{V_i | P_i } (v_i \Big | p_i \; ; \theta) \right \}

\end{align}
$$

$$
\begin{align}


P_1 = \phi,& && P_i =(V_1 , W_1 , \cdots, V_{i-1} , W_{i-1})
\\
Q_1 = V1,& && Q_i =(V_1 , W_1 , \cdots , W_{i-1}, V_i)

\end{align}
$$

$\prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \theta) $ is free of $\phi$ $\Rightarrow$ use $ \prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \beta) $ (partial likelihood)




### Partial & Marginal Likelihoods

Focus on Proportional Hazards Model: i.e., $(X_i, \; \delta_i, \; Z_i), \; i = 1, \cdots, n$ ($n$ independent triplets)

$$
\begin{align}

&\lambda(t \Big | Z ) = \lambda_0 (t) e^{\beta ' Z} &&S(t \Big | Z) = \Big \{ S_0(t) \Big \}^{e^{\beta ' Z}} \tag{1}

\end{align}
$$

위에서 $ \lambda_0 (t)$는 **unspecified**.

- **Partial Likelihood**: assume no ties, absolutely continuous failure distribution


Suppose there are L observed failures at $\tau_1 < \cdots < \tau_L$ (set $\tau_0 \equiv 0$ & $\tau_{L+1} \equiv \infty$)

16.png

Let (i) be the label for individual failing at $\tau_i$ (set $(L + 1) \equiv n + 1$). Note $t_{(i)} = \tau_i$

Covariates for $L$ failures: $(Z_{(1)}, \cdots, Z_{(L)})$. (Hereafter, condition on $ \Big \{ Z_i : i = 1, \cdots, n \Big \}$)

Censorship times in $[\tau_i; \tau_{i+1})$: $(\tau_{i1}, \cdots, \tau_{i, m_i})$ with covariates $(Z_{(i,1)}, \cdots, Z_{(i,m_i)})$, i.e., $(i, j)$ is label for item censored at $\tau_{ij}$



17.png



The data can be divided into sets

$$
(V_1 , W_1, \cdots, V_{L+1} ,  W_{L+1})
$$

where, for $i = 1, \cdots, L, L+1$, 

$$
\begin{align}
V_i &= \Big \{ \tau_i , \tau_{i-1, j}  \; \; ; \; \; (i-1, j):j = 1, \cdots, m_{i-1} \Big \}

\\

and \; \; \; \;W_i &= \Big \{ (i) \Big \}


\end{align}
$$



18.png

19.png






GOAL: Build a likelihood on a subset of the full data set
- carrying most of the information about $\beta$
- carrying no information on nuisance parameters $\Big \{ \lambda_0 (t) : t \ge 0 \Big \}$

PROPOSAL: Generate likelihood of $\Big \{ W_1, \cdots, W_L \Big \}$



JUSTIFICATION, WHY?:
- Timing of events $\Big \{ \tau_1 , \cdots, \tau_L \Big \}$ can be explained by $\lambda_0(\cdot)$.
- Censoring **times and labels** can be ignored if we assume **non-informative censorship** (independent censoring).




So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data.


If $Q_i \equiv (V_1, W_1 , \cdots, V_{i-1}, W_{i-1}, V_i)$ and $\mathcal F_{\tau_i} \equiv (Q_i, Z)$, the partial likelihood is $\prod_{i=1}^L P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)$, i.e., given the risk set at $\tau_i$, and given event occurs at $\tau_i$.

Denote $R_i \equiv \Big \{ j : X_j \ge \tau_i \Big \}$ as risk set at $\tau_i$. Then, by the assumption of independent censoring,

$$
\begin{align}
P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)




&=
\frac{


P \Bigg \{ t_{(i)} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - (i)} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} 
}{

\sum\limits_{l \in R_i} 
\left[
P \Bigg \{ t_{l} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - l} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}
\right]
}
\tag{a}





\\
\\
\\


&=
\frac{
d\Lambda \Big( \tau_i \Big | Z_{(i)} \Big)
\prod\limits_{j \in R_i - (i)} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \}
}{
\sum\limits_{l \in R_i} \left [ d\Lambda \Big( \tau_i \Big | Z_{l} \Big)
\prod\limits_{j \in R_i - l} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \} \right ]
}


\; \; \; \div \; \; \; \frac{d\tau_i}{d\tau_i}

\tag{2}
\\
\\
\\

&= \frac{\lambda\Big(\tau_i \Big | Z_{(i)} \Big)}{ \frac{P \Big\{T\in [t, t+dt) \Big | T \ge t , Z \Big\}}{dt}= \sum\limits_{l\in R_i} \left[ \lambda\Big(\tau_i \Big | Z_{l} \Big) \right]}

\; \; \; \overset {(1)}{=}  \; \; \; 


\frac{\exp(\beta ' Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta ' Z_{l})}





\end{align}
$$
- at (a), $P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} = 1 - P \Bigg \{ t_{j} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}$
- at (2), $ d\Lambda \Big( \tau_i \Big | Z_{j} \Big)  = 0$


Thus, the **Partial Likelihood** is 

$$
\prod^L_{i=1}\frac{\exp(\beta ' Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta ' Z_{l})} = L(\beta)\tag{3}
$$

Note: unspecified $\lambda_0(\cdot)$ + noninformative censoring $\Rightarrow$ $\prod\limits_{i=1}^L f_{V_i \big | P_i} (v_i \Big | p_i ; \theta)$ contains little or no information about $\beta$.













- Counting process notation:

$$
\begin{align}
L(\beta) = \prod^n_{i=1}\prod_{t\ge0} \left \{ 

\frac{\exp(\beta ' Z_{i})}{\sum\limits_{j=1}^n Y_j(t) \exp(\beta ' Z_{j})}

\right\}^{dN_i(t)}


, && dN_i(t) = \begin{cases} 1 & N_i(t) - N_i {(t-)} =1\\0 & o.w.\end{cases}

\end{align}
$$

- Maximum partial likelihood estimator (MPLE): $L( \hat \beta) = \max_\beta L(\beta)$ (using Newton-Raphson (NR) algorithm)

  - Specifically, the **log partial likelihood** is then
  
  $$
  l(\beta) = \sum_{i=1}^n \int_0^\infty \left[ Y_i (t) Z_i \beta - \log\left( \sum_{j=1}^n Y_j(t) \exp(\beta ' Z_j ) \right) \right]dN_i(t)
  $$
  
  - **The score vector**, $U(\beta)$, can be obtained by differentiating $l(\beta)$ w.r.t. $\beta$:
  
  $$
  \begin{alignat}{2}
  U(\beta) &= \sum_{i=1}^n \int_0^\infty \Big \{ Z_i - \bar Z(\beta, t) \Big \}&&dN_i (t)
  
  \\
  
  &= \sum_{i=1}^n \int_0^\infty \left \{ Z_i - \frac{\sum_{i=1}^n Y_i (t) Z_i \exp(\beta ' Z_i)}{\sum_{i=1}^n Y_i (t) \exp(\beta ' Z_i)} \right \}&&dN_i (t)
  
  \end{alignat}
  $$

    - where $\bar Z(\beta, t)$ is a weighted mean of $Z$ over those observations still at risk at time $t$.
  
  - The information matrix, $\mathcal I(\beta)$, is the negative second derivative where 
  
  $$
  \begin{align}
  
  \mathcal I(\beta) &= \sum\limits_{i=1}^n \int_0^\infty V(\beta, t) dN_i(s)
  
  \\
  \\
  
  V(\beta, t) &= \frac{\sum\limits_{i=1}^n Y_i(t) \exp(\beta ' Z_i ) \Big \{ Z_i - \hat Z (\beta, t)\Big\}'\Big \{ Z_i - \hat Z (\beta, t)\Big\}}{\sum\limits_{i=1}^n Y_i(t) \exp(\beta ' Z_i )}
  
  \end{align}
  $$
    - and $V(\beta, t)$ is the weighted variance of $Z$ at time $t$.

Then, the MPLE, $\hat \beta$, is found by solving the partial likelihood equation: $U(\hat \beta) = 0$.

Under some regularity conditions, $\hat \beta$ is consistent and asymptotically normally distributed with mean $\beta$ and variance $E \Big \{ \mathcal I(\beta) \Big\}^{-1}$ (will be shown later.)

The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value $\hat \beta^{(0)}$).

$$
\hat\beta^{(n+1)} = \hat\beta^{(n)} + \mathcal I ^{-1} \Big( \hat \beta^{(n)}\Big) \cdot U \Big( \hat \beta^{(n)}\Big)
$$

※ Note:
1. (incredibly) Robust algorithm!
2. $\hat \beta^{(0)} = 0$ usually works.













## Cox Proportional Hazards Model
Cox model:

$$
\begin{align}

\lambda_i(t) = \lambda(t \Big | Z_i ) 
&= \lambda_0 (t) \exp(\beta ' Z_i) 
\\
&= \lambda_0(t) \exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})
\\
&\Updownarrow
\\

\log \lambda(t \Big | Z_i ) &= \log \Big[ \lambda_0(t) \Big] +\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik}
\\
S(t \Big | Z_i ) &= 



\Big[ S_0(t) \Big]^{\exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})}


\end{align}
$$





※ Note:

$$
\begin{align}
\lambda_0 (t) &= \lambda(t \Big | Z_1 = \cdots = Z_k = 0)
\\
\\
\exp(\beta_1 Z_{1} + \cdots + \beta_k Z_{k}) &= RR 



\\
&= \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 = \cdots = Z_k = 0)} \tag{1}
\end{align}
$$
- (1) is relative risk of hazard of death comparing covariates values $Z_1,\cdots, Z_k$ to $Z_1 = \cdots = Z_k = 0$



Interpreting Cox Model Coeffcients: $\beta_k$ is the log RR (hazard ratio) for a unit change in $Z_k$, given all other covariates remain constant, i.e., 

$$
\begin{align}


\frac
{\lambda\Big[t \Big | Z_1 , \cdots, (Z_{k'}+1), \cdots, Z_k \Big]}
{\lambda\Big[t \Big | Z_1 , \cdots, Z_{k'}, \cdots, Z_k \Big]} 


&= \exp \Big (\beta_1 \cdot 0 + \cdots + \beta_{k'} \cdot (Z_{k'} +1 - Z_{k'}) + \cdots + \beta_k \cdot 0 \Big)

\\

&= \exp(\beta_{k'})


\end{align}
$$


The RR comparing 2 sets of values for the covariates $(Z_1 , \cdots, Z_k)$ vs. $(Z_1' , \cdots, Z_k')$:








$$
RR = \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 ', \cdots, Z_k')} =\exp \Big \{ \beta_1(Z_1 - Z_1') + \cdots + \beta_k(Z_k - Z_k') \Big \}
$$

20.png








## Comparison of Nested Models

- Nested Models:

$$
\begin{align}

\lambda(t) &= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p + \beta_{p+1} Z_{p+1} +\cdots + \beta_{k} Z_{k}\Big) \tag{Full Model}

\\

&= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p \Big) \tag{Reduced Model}


\end{align}




$$

To test:

- Nested Models:

$$
\begin{align}

&H_0:  &&RM && \Leftrightarrow && H_0: \beta_{p+1} = \cdots = \beta_k = 0
\\
&H_A:  &&RM && \Leftrightarrow && H_A:  \not = \text{ somewhere}

\end{align}




$$

Use the **partial likelihood ratio statistic**, $X^2_{Cox} = -2 \Big[ \log PL(RM) - \log PL(FM)\Big]$.

Under $H_0$: Reduced model, and when $n$ is large:
$$
\begin{align}
X^2_{Cox} \sim \chi^2_{k-p} && k-p \text{ is the # of parameters set to 0 by }H_0
\end{align}
$$


20.png, 21.png






## Stratification

Two Ways to Stratify. Suppose a confounder $C$ has 3 levels on which we would like to stratify when comparin
g $\lambda(t \Big | E )$ and $\lambda ( t \Big | \bar E )$. How? $X_E = \begin{cases}1&E&\text{(exposed)}\\0&\bar E&\text{(not exposed)}\end{cases}$

22.png







- Which Way to Stratify?
1. Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder $C$ may be inadequately controlled.
2. Proportionality assumption can be checked using time-dependent covariates.
3. True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If $C$ can be measured continuously and the strata were formed by grouping values of it, better control for $C$ might be achieved with continuous (could be time-dependent) covariate adjustment.
4. If $C$ is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of $C$. However, we can estimate $\lambda_{0i}(t)$ for each stratum then we can estimate a RR function.
5. True stratification generally requires more data to obtain the same precision in coefficient estimates.






23.png

24.png








## Test statistics

The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood.



25.png




Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least.

26.png

When $p = 1$ and the single covariate is categorical, the score test is identical to the log-rank test.


27.png


## Handling ties

Real data sets often contain tied event times.

- When do we have ties?
1. Continuous event times are grouped into intervals.
2. Event time scale is discrete.

Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood.

When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the $i$-th event at time $t_i$ is $\frac{\exp(\beta ' Z_i)}{ \sum\limits_{j \in R_i} Y_j(t_i) \exp(\beta ' Z_j)}$



Two commonly used methods are
  1. Breslow approximation
  2. Efron approximation

Example: Assume 5 subjects are at risk of dying at time $t$ and two die at the same time $t$ (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either




28.png

29.png

30.png

















































































































































































