% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Self-Study},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage[normalem]{ulem}
% Avoid problems with \sout in headers with hyperref
\pdfstringdefDisableCommands{\renewcommand{\sout}{}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}

\newtheorem{theorem}{Theoremas8df9a8}[section]
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\title{Self-Study}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{intro}{%
\chapter*{Intro}\label{intro}}
\addcontentsline{toc}{chapter}{Intro}

\hypertarget{part-20-02}{%
\part{20-02}\label{part-20-02}}

\hypertarget{categorical}{%
\chapter{Categorical}\label{categorical}}

\hypertarget{overview}{%
\section{Overview}\label{overview}}

\hypertarget{data-type-and-statistical-analysis}{%
\subsection{Data Type and Statistical Analysis}\label{data-type-and-statistical-analysis}}

\hypertarget{bayesian}{%
\chapter{Bayesian}\label{bayesian}}

\hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

조건부 확률은 sample sapce가 \(S\)에서 \(B\)로 축소되었다는 것을 의미한다.

Bayesian의 Multiplication Rule은 사건이 시간순서대로 발생할 때 유용하게 사용될 수 있다.

set of events become \textbf{partition} of sample space \(S\):
1. mutually exclusive(disjoint)
2. Pr of union \(=1\)

event \(H\)와 event \(A\), \(B\)가 주어져 있다. \(A\)와 \(B\) 가 서로 독립이라면, \(H\)가 주어졌을 때 \(A\)가 추가되는 것이 \(B\)에 대한 정보를 아는데 영향을 미치지 않는다. 수식으로 증명가능.

\(Dirichlet\), \(Wishart\)

\(posterior odds\)

\hypertarget{uxbcc0uxc218uxc758-uxb3c5uxb9bduxc131}{%
\subsection{변수의 독립성}\label{uxbcc0uxc218uxc758-uxb3c5uxb9bduxc131}}

\(X_1 , \cdots, X_n\)이 공통 sample space \(S\)를 갖는 변수이고 \(\theta\) is unknown parameter.

if \(S\), with for any subset(events) \(A_1 , \cdots, A_n\), \$Pr(X\_1 \in A\_1 , \cdots, X\_n \in A\_n \rvert \theta) = Pr(X\_1 \in A\_1 \rvert \theta) * \cdots *  Pr(X\_n \in A\_n \rvert \theta), then \(X_1 , \cdots, X_n\) 는 \(\theta\)가 주어졌을 때 \textbf{조건부 독립}이다.

이는 앞서 말한 event의 독립성에 대응된다. 위의 독립성은 event의 독립성과 마찬가지로 \$Pr(X\_i \in A\_i \rvert \theta, X\_j \in A\_j) = Pr(X\_i \in A\_i \rvert \theta) 가 성립. 이는 \(\theta\)가 주어졌을 때 \(X_j\)의 정보가 \(X_i\)에 대하여 아무런 추가정보를 주지 못함을 의미한다.

만약 세타가 주어진 상태에서 X1\textasciitilde Xn이 조건부 독립이라면 조건부 joint pdf는 각 조건부 margianl pdf의 곱과 같다. 만약 X-i가 모두 같은 분포를 따르면\textasciitilde. 이때 X\_i들은 세타가 주어졌을 때 conditionally iid. 이는 marginal iid와는 구변된다. marginal iid는 X\_i들의 marginal iid가 모두 같고 또한 독립이라는 소리.

\hypertarget{uxad50uxd658uxac00uxb2a5uxc131}{%
\subsection{교환가능성}\label{uxad50uxd658uxac00uxb2a5uxc131}}

독립성은 엄격한 조건. 만족안되는 경우 많음. 이것보다는 약조건이 \textbf{교환가능성}. 독립성 \(\rightarrow\) 교환가능성이지만 교환가능성 \(\not \rightarrow\) 독립성. 교환가능성까지만 만족되면 De Finetti thm은 성립함.

\hypertarget{continual-aeassessment-method}{%
\section{Continual Aeassessment Method}\label{continual-aeassessment-method}}

\hypertarget{horseshoe-prior}{%
\section{Horseshoe Prior}\label{horseshoe-prior}}

\hypertarget{part-21-01}{%
\part{21-01}\label{part-21-01}}

\hypertarget{mathematical-stats}{%
\chapter{Mathematical Stats}\label{mathematical-stats}}

\hypertarget{inference}{%
\section{Inference}\label{inference}}

\(T(X)\)가 \(\theta\)의 추정량.
* bias \$ = E \left[ T(X) \right] - \theta\$
* if bias\(=0\), \(T(X)\)는 \(\theta\)의 UE.

이때, \(\theta\) can be \(g(\theta)\). 즉슨, \(\theta\)는 패러미터 그 자체만이 아니라 패러미터의 함수를 패러미터 삼아 이를 추정하려고 들 수도 있다. 이하의 전개에서는 \(\theta = g(\theta)\) 로 이해하자.

\(\theta\)의 추정량 \(T(X)\)의 MSE는 \$MSE = Var \left[ T(X) \right] +(bias)\^{}2 \$.

\(T_1(X)\), \(T_2(X)\)는 \(\theta\)의 UE. \(T_1(X)\)의 \(T_2(X)\)에 대한 Relative Efficiency \(RE= \dfrac {Var \left[ T_2 (X) \right]} {Var \left[ T_1 (X) \right]}\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

rv \$X\_1 , \cdots, X\_n \sim f(x\_1 , \cdots, x\_n \rvert \theta) \$. 이하의 조건 하에서 추정량 \(T^\ast (X)\)는 \(\theta\)의 MVUE.
1. \(E \left [ T^\ast (X) \right] = \theta\). 즉 \(T^\ast (X)\)는 \(\theta\)의 UE.
2. \$\forall T(X):Var \left [ T^\ast (X) \right]  \le \left [ T (X) \right] \$.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Fisher's Information \$I(\theta) = E \left\{ \left[ \dfrac {\partial} {\partial \theta} log f(X_1 ; \theta)\right]\^{}2 \right\} \$

regularity condition:
1. The partial derivative of \(f(X; \theta)\) with respect to \(\theta\) exists almost everywhere. (It can fail to exist on a null set, as long as this set does not depend on \(\theta\).)
2. The integral of \(f(X; \theta)\) can be differentiated under the integral sign with respect to \(\theta\).
3. The support of \(f(X; \theta)\) does not depend on \(\theta\).

e.g.,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  패러미터 다르면 pdf 다름. 즉, \(\theta \not = \theta': f(x;\theta) \not = f(x;\theta')\)
\item
  set \(A = \{ x: f(x;\theta)>0 \}\)은 패러미터 \(\theta\)에 의존하지 않고, \(\forall x \in A, \theta \in \Omega : \log f(x;\theta)\)는 \(\theta\)에 대해 두 번 미분 가능하고 도함수가 연속이다.
\item
  통계량 \(T(X)\)가 \(\forall \theta \in \Omega: E \left [ T (X) \right] < \infty\) 라면, \$ \dfrac {\partial} \{\partial \theta\} E \left [ T (X) \right]  \$에 있어 미분과 적분의 순서를 바꿀 수 있다.
\end{enumerate}

Information inequality:
under regularity condition, \(\forall g^{-1}(\theta) \in \Omega, Var \left [ T^\ast (X) \right] < \infty, E \left [ T^\ast (X) \right] = \theta, 0<I(\theta)< \infty:\) \(\theta\) is differentiable, and \(Var \left [ T^\ast (X) \right] \ge \dfrac {1}{n} \dfrac {\left[ g'(\theta) \right]^2}{I (\theta)}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

rv \$X\_1 , \cdots, X\_n \sim f(x\_1 , \cdots, x\_n \rvert \theta) \$. \(l\)개 stats(통계량)의 벡터 \(\pmb {S(X)} = \left[ S_1(X), \cdots, S_l(X) \right]\).
이때 rv \$X\_1 , \cdots, X\_n \rvert \pmb {S(X)} \$의 분포가 패러미터 \$ \theta = (\theta\_1 , \cdots, \theta\_k )\$에 의존하지 않으면 stats \(\pmb {S(X)}\)는 joint SS.

rv \$X\_1 , \cdots, X\_n \sim f(x\_1 , \cdots, x\_n \rvert \theta) \$. 1개 stats(통계량) \(S(X)\).
이때 rv \(X_1 , \cdots, X_n \rvert S(X)\) 의 분포가 패러미터 \(\theta = (\theta_1 , \cdots, \theta_k )\)에 의존하지 않으면 stats \(S(X)\)는 SS.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Decomposition thm.:
\end{itemize}

rv \$X\_1 , \cdots, X\_n \sim f(x\_1 , \cdots, x\_n \rvert \theta) \$. \(k\)개 stats(통계량) \(\pmb {S(X)} = \left[ S_1(X), \cdots, S_k(X) \right]\).

stats \(\pmb {S(X)}\)는 joint SS \(\iff\) \$f(x\_1 , \cdots, x\_n ; \theta) = g \left[ s(x); \theta \right] \ast h(x\_1 , \cdots, x\_n) \$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{rao-blackwell-thm.}{%
\subsection{Rao-Blackwell thm.}\label{rao-blackwell-thm.}}

패러미터의 함수 \(\theta\), \(S\)는 SS, \(T(X)\)는 UE. let \(\delta (S) = E \left [ T(X) \rvert S \right]\). 이때 \(\delta (S)\)는 \(\theta\)의 UE. 따라서

\$\$
\begin{align*}

Var \left[ \delta (S) \right ] &= E \left\{ \left[ \delta (S) - \theta \right]^2 \right\} \\
&\le E \left\{ \left[ T(X) - \theta \right]^2 \right\} = Var \left [ T(X) \right]

\end{align*}
\$\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{completeness}{%
\section{Completeness}\label{completeness}}

r\textbf{\emph{s}} \$X\_1 , \cdots, X\_n \$의 stats \$ T (X\_1 , \cdots, X\_n ) \$에 대해, let

\[
\forall \theta \in \Omega: \; \; E \left[ g(T) \right]=0
\]

이때 이를 만족하는 \(\theta\)에 무관한 함수 \(g\)가 \(g(\cdot) \equiv 0\) 뿐이라면, \(T\)는 CS. \(T\)가 \(\theta\)에 대한 SS라면, 이는 CSS.

stats \(Y\)가 분포모임 \(\{g(y;\theta);\theta \in \Theta \}\)의 한 원소를 pdf로 가진다고 하자.

\[
\forall \theta \in \Theta: \; \; E_{\theta} \left[ \varphi(Y) \right] \overset{\theta}{=}{0} \; \; \; \rightarrow \; \; \; \varphi(y) \overset{y}{=} 0
\]

위의 명제가 성립할 때 위 분포족은 completeness를 지닌다.
* 여기서 \(\varphi\)는 \(\theta\)에 무관한 함수이다.
* 피명제는 보다 엄밀히는 \(\forall \theta: P_{\theta} \{ \varphi (Y)=0 \}=1\).
* \(\overset{\theta}{=}\)는 모든 \(\theta \in \Omega\)에 대해 등호가 성립함을 나타낸다.

Remarks:
1. completeness는 본질적으로 확률분포의 패러미터 \(\theta\)가 통계량 \(Y\)를 통해 추정될 수 있음을 보장하는 조건으로 이해될 수 있다.
* 즉, completeness는 서로 다른 패러미터값을 지니는 두 분포는 서로 구분(distinct)됨을 보장해주는 조건이다.
2. 통계량 \(Y\)의 분포족이 completeness를 만족하면, \(Y\)를 완비통계량 CS라고 부른다.
3. 완비성은 CS의 함수로 이루어지는 UE는 unique하다는 사실을 보이는 도구로 이용된다. 레만-쉐페 thm 참조.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{uxb808uxb9cc-uxc250uxd398-thm.}{%
\subsection{레만-쉐페 thm.}\label{uxb808uxb9cc-uxc250uxd398-thm.}}

패러미터 \(\theta\)에 대해 \(T\)가 CSS, \(S(X)\)는 \(\theta\)의 UE. 이때 \$\delta(T)=E \left [ S(X) \rvert T \right ] \$는 \(\theta\)의 UMVUE.

r\textbf{\emph{s}} \(X_1 , \cdots, X_n \overset{iid}{\sim} f(x;\theta)\). \(\theta\)에 대한 CSS \(Y=u(X_1 , \cdots, X_n)\). 이때 임의의 UE \(\hat \theta\)에 대해

\[
\varphi (Y) = E(\hat \theta \rvert Y)
\]

는 \(\theta\)에 대한 UMVUE. 이는 unique.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{rao-blackwell-thm.-1}{%
\subsection{Rao-Blackwell thm.}\label{rao-blackwell-thm.-1}}

r\textbf{\emph{s}} \(X_1 , \cdots, X_n \overset{iid}{\sim} f(x;\theta), \theta \in \Theta\).
1. \(Y= u(X_1 , \cdots, X_n)\)는 \(\theta\)의 CSS.
2. \(Z= v(X_1 , \cdots, X_n)\)의 분포는 \(\theta\)에 의존하지 않는다.

이상의 조건이 만족되면 \(Y \perp Z\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  exponentail family:
\end{itemize}

pdf가 적절한 함수 \(a, b, c_i, t_i (i=1,\cdots, k)\)에 대해 \(f(x;\theta) = a(\theta) b(x) \exp \left[ \sum_{i=1}^k c_i (\theta) t_i (x) \right], -\infty\)

지수족에 속하는 pdf로부터 r\textbf{s} \$X\_1 , \cdots, X\_n \$를 얻었다면, 통계량 \$S\_1 = \sum\emph{\{i=1\}\^{}n t\_1 (X\_i), \cdots, S\_k = \sum}\{i=1\}\^{}n t\_k (X\_i) \$ 는 패러미터 \$\theta\_1 , \cdots, \theta\_k \$에 대한 joint (C) SS이다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(g(\theta)\)에 대한 est \(\tau(\pmb X)\)가 \(\forall \epsilon >0: \lim_{n \rightarrow \infty} P \left( \vert \tau(\pmb X) - g(\theta) \vert \le \epsilon \right) =1\)을 만족하면 est \(\tau(\pmb X)\)는 consistency를 가진다.

이는 표본의 크기가 커짐에 따라 est \(\tau(\pmb X)\)가 \(g(\theta)\)에 \textbf{확률적으로 수렴}한다는 것. 표본의 크기가 매우 클 때, est \(\tau(\pmb X)\)로부터 계산된 추정값 estimates는 높은 확률로 참모수값에 매우 가까이 있다는 뜻.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

est \(\tau(\pmb X)\)를 \(g(\theta)\)의 것일 때, \(\forall \theta \in \Theta: \lim_{n \rightarrow \infty} P E \left\{ \tau(\pmb X)-g(\theta)\right\}^2 = 0\)이 성립하면 est \(\tau(\pmb X)\)는 consistent.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

est \(\tau(\pmb X)\)가 \(\theta\)의 consistent이고, \(g(x)\)가 \(\theta\)에서 연속인 함수라면, \(g\tau(\pmb X)\)

\hypertarget{hypothesis-test}{%
\section{Hypothesis Test}\label{hypothesis-test}}

통계적 가설 \textbar{} Statistical Hypothesis \textbar{} 관심있는 population의 성질에 대한 단정이나 추측 등의 표현 (statement) 이러한 가설은 흔히 모집단의 성질을 나타내는 rv의 분포에 대한 표현으로 나타난다. \textbar{}\\
단순가설 \textbar{} Simple Hypothesis \textbar{} 어떤 가설이 확률분포 (pd) 를 완전히 결정한다 \textbar{}\\
복합가설 \textbar{} Composite Hypothesis \textbar{} 그렇지 않다 \textbar{}

다양한 검정법에서 우선순위를 정하는 것은 옳은 결론을 내리는 빈도가 높은, 즉 \textbf{잘못된 결정을 내릴 확률이 낮은 검정법이 좋은 검정법}이라는 것.

검정통계량(Test Statistics): 주어진 rs에 근거하여 통계적 가설에 대한 증거를 살펴볼 때 사용되는 통계량

기각영역(Rejection Region, Critical Region): \(H_0\)를 기각하게 되는 검정통계량의 값을 가지는 \textbf{sample space의 부분집합} (event)

\textbar{} \(H_0\) True \textbar{} \(H_0\) False \textbar{}\\
reject \(H_0\) \textbar{} \textbar{} Type 2 Error (\(\beta\)) 유죄인데 석방 \textbar{}\\
accept \(H_0\) \textbar{} Type 1 Error (\(\alpha\)) \textbf{무죄인데 사형} \textbar{} \textbar{}

제1종 오류를 범활 확률 \(\alpha\)는 유의확률(Significance Level) 라고 따로 칭함. \(H_1\)은 기존으로부터의 변화이므로 채택에 있어 훨씬 엄격해야 함. 따라서 \(\alpha\)가 \(\beta\)보다 훨씬 더 중시됨.

let Rejection Region \(C\). then

\$\$
\begin{alignat*}{2}

\alpha &= P(\text{Type 1 Error}) \\
&= P(\text{accept }H_1 \vert H_0) \\
&= P(\pmb X_n \in C \vert H_0) 

\begin{aligned}[t]
           & = \int_C f(\pmb x \vert H_0) d \pmb x\\
           &= \sum_C f(\pmb x \vert H_0)
         \end{aligned}


\end{alignat*}
\$\$

This can also be written as Loss Function.

\$\$
\begin{align*}

L(H_i ; H_j ) = 

 \begin{cases}
    0, & \text{if } i = j  \\
    1, & \text{for } i \not = j, \; \; (i,j = 0, 1)
    
  \end{cases}

\end{align*}
\$\$

\$\$
\begin{align*}

E \left [ L(H_1 ; H_0 ) \right] &= P(\text{Type 1 Error}) \\
E \left [ L(H_0 ; H_1 ) \right] &= P(\text{Type 2 Error})

\end{align*}
\$\$

\hypertarget{power-fucntion}{%
\section{Power Fucntion}\label{power-fucntion}}

여기서, \(H_0\)에 대한 기각영역이 \(C\)인 test의 검정력함수 (power function)은 이하와 같다. 즉, 이는 \textbf{\(H_0\)를 기각하는 확률}로 정의된다.

\[
\pi(\theta) = P (\pmb X_n \in C \vert \theta)
\]

이는 패러미터 \(\theta\)의 참값이 무엇이냐에 따라 다른 값을 가지므로 \(\theta\)의 함수이다.

주어진 \(\theta\)에서의 power function의 값 \(\pi(\theta)\)은 이 \(\theta\)에서의 검정력 (power).

power는 \(H_0\)를 기각할 확률.
* if \(\theta \in H_0\), power는 작을수록 좋다.
* \(\theta = \theta_0 \in H_1\), 이 경우 power \(\pi(\theta) = \pi(\theta_0) = \alpha\).
* if \(\theta \in H_1\), power는 클수록 좋다.
* \(\theta \in H_1\), and \(H_1\)이 simple hypothesis, 이 경우 power \(\pi(\theta) = 1- \beta\).

이와 같이 power function은, 마치 MSE가 점추정의 기준이 되었던 것처럼, \(\alpha\) (유의수준)이 고정되었을 때 test 방법의 성능을 결정하는 기준이 된다.

\hypertarget{significance-probability-p-value}{%
\subsection{Significance Probability (p-value)}\label{significance-probability-p-value}}

앞에서 언급했던 것과 같이, 좋은 검정법을 찾기 위해 sample space를 \(C\)와 채택영역 \(C^c\)로 나누고 \(\alpha\)와 \(\beta\)를 계산하여 오류의 확률을 작게 만드는 검정법을 고르게 된다. 사용할 검정법을 결정하고 나면, 자료에서 관측된 값이 \(C\)에 속할 경우 \(H_0\)를 기각하고, 이외에는 \(H_0\)를 기각하지 않는다고 결론을 내리게 된다. 그런데 관찰된 test stat의 값이 \(C\)에 속한다 하더라도 값의 크기 등에 따라 \textbf{통계적 유의성}에 대한 의미가 다를 수 있다. 따라서 기각할 것인지, 하지 않을 것인지 이분법적인 결론만을 제시하기보다, 관측한 자료가 \(H_0\)에 대하여 어느 정도의 반증이 되는지를 수치적으로 나타낼 수 있는 \(\alpha\) (유의확률)을 이용하여 test의 결론에 이르는 경우가 많이 있다.

p값 (p-value), 즉 관측된 유의수준 (observed significance level), 혹은 유의확률 (Significance Probability), 는 \(H_0\)가 참이라는 가정 하에, 우리가 관측한 값과 같거나 더 극단적인 값을 얻을 확률 (ex. \(P(T \ge t \vert H_0 )\)) 로 정의된다. 여기서 더 극단적이라는 것은, 관측한 값보다 \(H_1\)에 더 가까운 것을 의미한다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 아주 작은 값이 나왔다면, 우리가 관측한 값 자체가 이미 매우 극단적이라서 이보다 더 강한 \(H_1\)에 대한 증거를 관측할 확률이 작다는 것이다. 즉, \textbf{관측값이 \(H_0\) 하에서 나오기 어려운 값}이라는 뜻이므로 \(H_0\)를 기각할 근거가 된다고 할 수 있다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 작지 않은 값이 나왔다면, 우리가 관측한 값이 \(H_0\) 하에서 흔히 나올 수 있는 값이라는 것이고, 즉 \(H_0\)를 기각할 근거가 되지 않는다고 할 수 있다.

p값이 \(H_0\)를 기각할만큼 작은지를 결정하는 것은 보통 결과를 해석하는 사람에게 달려있다. 그러나 가설검정을 할 때는 흔히 적당한 유의수준 \(\alpha\)의 값을 생각하고 있기 마련이므로, p값이 \(\alpha\)보다 작으면 관측된 자료가 대립 가설에 대한 충분한 증거가 된다고 판단하여 \(H_0\)를 기각하게 된다. 정리하자면, p값은 \(H_0\) 하에서 test stat의 관찰값 (test stats) 이 \(H_0\)를 기각하는 방향으로 나타나는 확률을 의미한다. 주어진 유의수준 \(\alpha\)보다 p값이 작으면 \(H_0\)를 기각하며, 그렇지 않은 경우에는 \(H_0\)를 받아들이게 된다.

\hypertarget{optimal-testing-method}{%
\section{Optimal Testing Method}\label{optimal-testing-method}}

항상 옳은 결과를 가져다주는 검정법을 사용할 수 있다면 가장 좋겠지만, 샘플에서 주어지는 정보만을 가지고 모집단의 특성에 대한 결론을 내려야 하는 상황에서 언제나 옳은 결과를 가져다주는 test 방법을 찾을 수는 없다. 그렇기에 이 장의 목표는 옳은 결과를 가져다주는 빈도가 높은 test 방법을 찾는 것이 된다. 잘못된 결론을 내릴 확률은 두 가지 오류로 표현되므로, 제 1종 오류와 제 2종 오류의 발생확률을 낮게 하는 test 방법을 찾아야 한다. 불행히도, 샘플의 크게가 정해져 있는 경우 둘 다를 최소로 하는 test 방법을 찾는 거은 불가능하다. 예를 들면, \(\alpha\)를 최소로 하는 가장 간단한 방법은 언제나 \(H_0\)를 채택하는 것이지만 (\(\alpha = 0\)), 이는 \(H_1\)에서의 power를 0으로 최소화시키고, 즉, \(\beta\)를 극대화시킨다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

let \(\pmb X_{25} \overset {\text{iid}} {\sim} N(\mu, 10^2 )\).

\[
H_0 : \mu = 100, \; \; \; \; \; H_1 : \mu > 100
\]

이때. \(\mu=100\)에서의 power는 유의수준 \(\alpha\)와 같고, \(\mu>100\)일 경우에는 \(\pi(\mu) = 1-\beta(\mu)\). 이인즉

\$\$
\begin{align*}

\lim_{\mu \downarrow 100} \beta(\mu) &= 1- \pi(100) \\
&= 1- \alpha

\end{align*}
\$\$

따라서 \(H_0\)와 \(H_1\)의 경계점에서 \(\alpha + \beta = 1\)이 된다. 즉, 샘플의 크기가 일정할 때 \(\alpha\)를 줄이고자 하면 경계점에서 \(\beta\)의 값이 커지며, 이 역 또한 성립한다. 이를 power로 표현하면, \(H_0\) 하에서 power는 큰 것이 바람직하나 power \(\pi (\mu)\)를 늘이고자 하면 \(\alpha\)의 값이 같이 커지게 되므로 제1종 오류의 확률 (\(\alpha\))의 확률을 최소화하면서 power를 최대화하는 일은 sample의 크기가 정해져 있는 경우 불가능하다.

만약 sample의 크기를 늘인다면, \(\alpha\)의 값을 고정시킨 상태에서 주어진 \(H_1\) 하에서의 \(\mu\) 값에서의 power를 크게 할 수 있다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

이 절에서는 power function \(\pi(\cdot)\)을 기준으로 하는 Optimal Testing Method (최량검정법)에 대해 살펴볼 것이다. 우선, \(H_0\)와 \(H_1\)이 모두 simple인 경우를 생각해보자. 위에서 이야기하였듯 \(\alpha\)를 최소화하면서 \(H_0\) 하에서의 power를 최대화하는 것은 불가능하므로, 이에 대한 합리적 대안으로 \(\alpha\) (제1종 오류를 범할 확률)을 주어진 작은 값으로 제한한 상태에서, power를 최대화하는 의미에서의 OTM을 다음과 같이 정의한다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\$\$

H\_0: \theta = \theta\_0, ; ; ; ; ; H\_1: \theta = \theta\_1

\$\$

에 대한 rejection region \(C^\ast\) 가 다음 조건을 만족할 때 이를 유의수준 \(\alpha\) 에서의 MPT의 RR, 또는 MPRR이라고 한다.

\(\pi^\ast\)가 \(C^\ast\)에 해당하는 power function이라 하면,
1. \(\pi^\ast (\theta_0) = \alpha\),
2. \(\forall \text{ RR } C, \; \text{whose 유의수준과 power function } \alpha, \pi: \pi^\ast(\theta_1) \ge \pi(\theta_1)\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-reduction}{%
\section{Data Reduction}\label{data-reduction}}

\hypertarget{sufficiency-principle}{%
\subsection{Sufficiency Principle}\label{sufficiency-principle}}

\(X \vert T(X)\)의 분포가 \(\theta\)에 의존하지 않는다면, \(T(X)\)는 \(\theta\)의 SS.
- \(T(X)\)가 \(\theta\)의 SS라면, \(\theta\)에 대한 모든 추론은 \(T(X)\)를 거쳐서만이 \(X\)에 의존함. 즉 \(T(X)\) 값만 알 수 있다면 모든 \(X\)에 대해 알지 못해도 무관.

비율 \(\dfrac{f_X(x \vert \theta)}{f_T(X) \left( T(x) \vert \theta \right)}\)가 \(\forall x \in \Omega\)에 대해 \(\theta\)의 함수로서 constant 하다면, \(T(X)\)는 \(\theta\)의 SS. 이인즉 \(f(x \vert T(x))\) 는 \(\theta\)에 의존하지 않는다.
- rs itself와 rs의 order statistics는 SS이다.

Factorization thm.: sample point \(x\), parameter points \(\theta\)

\$\$

T(X) \text{ is SS} \iff \forall x, \theta: \text{function }g \left[ T(x) \vert \theta \right], h(x) : f(x \vert \theta) = g \left[ T(x) \vert \theta \right] \ast h(x)

\$\$

SS를 찾기 위해 factorization thm.을 쓰려면, 우리는 샘플의 joint pdf를 두 부분으로 나눠야 한다. 이는 \(\theta\)를 포함하지 않는 (의존하지 않는) \(h(x)\)와 \(\theta\) 를 포함하는 \(g \left[ T(x) \vert \theta \right]\) 이다. \(\theta\)를 포함하는 \(g\) 쪽의 식이 \(T(x)\)로 표시될 수 있으면, 즉 \(x\)에 의존하는 바가 \(T(x)\)를 통해서만 의존한다면, \(T(x)\)는 \(\theta\)의 SS이다.

proof)

\(X_1 , \cdots, x_n \overset {iid} {\sim} f(x \vert \pmb \theta) = h(x)c(\pmb \theta) \exp \left( \sum_{i=1}^k w_i (\pmb \theta)t_i(x) \right)\), s.t. exponential family, where \(\pmb \theta = (\theta_1 , \cdots, \theta_d), d \le k\). then

\[
T(X) = \left( \sum_{j=1}^n t_1 (X_j) , \cdots, \sum_{j=1}^n t_k (X_j) \right)
\]

is SS for \(\theta\).

\hypertarget{borel-paradox}{%
\section{Borel Paradox}\label{borel-paradox}}

Throughout this chapter, for continuous rv \(X, Y\), we have been writing expressions such as \(E(Y \rvert X=x)\) and \(P(Y \le y \rvert X=x)\). Thus far, we have not gotten into trouble. However, we might have.

Formally, the conditioning in a conditional expectation is done with respect to a sub sigma-algebra(1.2.1), and the conditional E \$E(Y \rvert G) \$ is defined as a rv whose integral, over any set in the sub sigma-algebra \(G\), agrees with that of \(X\). This is quite an advanced concept in probatbility theory (see Billingsley 1995, Section 34).

Since the conditional E is only defined in terms of its integral, it may not be unique even if the conditioning is well-defined. However, when we condition on sets of probatbility 0 (such as \$ \{ X=x \}\$), conditioning may not be well defined, so different conditional expectations are more likely to appear. To see how this could affect us, it is easiest to look at conditional distributions, which amounts to calculating \(E \left[ I(Y \le y) \rvert X=x \right]\).

Proschan and Presnell (1998) tell the story of a statistics exam that had the question ``If \(X\) and \(Y\) are independent standard normals, what is the conditional distributions of \(Y\) given that \(Y=X\)?'' Different students interpreted the condition \(Y=X\) in the following ways:
1. \(Z_1 = 0\), where \(Z_1 = Y-X\);
2. \(Z_2 = 1\), where \(Z_2 = Y/X\);
3. \(Z_3 = 1\), where \(Z_3 = I(Y=X)\).

Each condtion is a correct interpretation of the conditon \(Y=X\), and each leads to a different conditional distribution (see Excercise 4.60.).

This is the \textbf{\emph{Borel Paradox}} and arises b/c different (Correct) interpretations of the probatbility 0 conditioning sets result in different conditional E. How can we avoid the paradox? One way is to avoid conditioning on sets probatbility 0. That is, compute only \(E(Y \rvert X \in B )\), where \(B\) is a set with \(P (X \in B)>0\). So to compute something like \(E(Y \rvert X =x )\), take a sequence \(B_n \downarrow x\), and define \(E(Y \rvert X =x )= \lim_{n \rightarrow \infty} E(Y \rvert X \in B_n )\). We now avoid the paradox, as the different answers for \(E(Y \rvert X =x )\) will arose from different sequences, so there should be no surprises (Exercise 4.61).

\hypertarget{neymanpearson-lemma}{%
\section{Neyman--Pearson lemma}\label{neymanpearson-lemma}}

rs \(X_1 , \cdots, X_n \overset {iid}{\sim} f(x_1 , \cdots, x_n ; \theta)\)이고, \$H\_0 : \theta=\theta\_0, ; ; ; H\_1 : \theta=\theta\_1 \$. 이때 이하를 만족하면 rejection region \(R\)은 MP test의 기각역.

\(\exists k \ge 0\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\pmb x \in R\) if \(f(\pmb x \vert \theta_1) > k f(\pmb x \vert \theta_0)\).
\item
  \(\pmb x \in R^c\) if \(f(\pmb x \vert \theta_1) < k f(\pmb x \vert \theta_0)\).
\item
  \(\mathbb{P}_{\theta_0} \left( \pmb X \in R \right) = \alpha\) for the prefiexed significance level \(\alpha\).
\end{enumerate}

Proof:

\begin{align}

P(\pmb X \in A \vert \theta) &= \int_A L(\theta ; \pmb x) d \pmb x \\

&= \int_A f(\pmb x ; \theta) d \pmb x 

\end{align}

이므로, \(A \subset C^\ast\)라면

\begin{alignat}{4}

\int_A f(\pmb x ; \theta) d \pmb x &\le \int_A && k \ast f(\pmb x ; \theta) d \pmb x \\

\\

P(\pmb X \in A \vert \theta_0) &\le && k \ast P(\pmb X \in A \vert \theta_1)

\end{alignat}

마찬가지 방법으로 \(A \subset \left( C^\ast \right)^c\)라면 \(P(\pmb X \in A \vert \theta_0) \ge k \ast P(\pmb X \in A \vert \theta_1)\).

\(C^\ast\)의 유의수준이 \(\alpha\)라 하고, 유의수준이 동일한 임의의 RR \(C\)를 가정하자. 이때 두 RR은 각각

\begin{align}

C^\ast &= (C^\ast \cap C) \cup (C^\ast \cap C^c) \\


C &= (C^\ast \cap C) \cup ({C^\ast}^c \cap C) 

\end{align}

로 표현할 수 있으며, 두 RR에 대한 power function은 각각

\begin{alignat}{4}

\pi^\ast(\theta) &= P(\pmb X \in C^\ast \vert \theta)



&&= P(\pmb X \in C^\ast \cap C \vert \theta) &&+ P(\pmb X \in C^\ast \cap C^c \vert \theta) \\


\pi(\theta) &= P(\pmb X \in C \vert \theta)

&&= P(\pmb X \in C^\ast \cap C \vert \theta) &&+ P(\pmb X \in {C^\ast}^c \cap C \vert \theta) \\


\end{alignat}

이때 \(H_0\)에서 두 power의 차이는

\begin{alignat}{4}

\pi^\ast(\theta_1) -\pi(\theta_1)

&= && P(\pmb X \in C^\ast \cap C^c \vert \theta_1) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_1) \\

&\ge \dfrac{1}{k} && \left\{ P(\pmb X \in C^\ast \cap C^c \vert \theta_0) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_0) \right\} \\

&=


\dfrac{1}{k} && \left\{

 P(\pmb X \in C^\ast \cap C^c \vert \theta_0) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_0) \\

+ P(\pmb X \in C^\ast \cap C \vert \theta_0) - P(\pmb X \in C^\ast \cap C \vert \theta_0) 

\right\} \\

&= \dfrac{1}{k} && \left\{ \pi^\ast (\theta_0) - \pi (\theta_0) \right \} \\

&=0 &&


\end{alignat}

이에 의해 MP test의 정의를 만족한다. 이때 \(C\)의 유의수준이 \(< \alpha\)인 경우, \(\pi^\ast (\theta_1) > \pi (\theta_1)\)이 되므로, \(C^\ast\)의 \(H_1\)에서의 power인 \(\pi^\ast(\theta_1)\)은 유의수준이 \(\le \alpha\)인 모든 RR의 power보다 크거나 같음을 알 수 있다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{overview-1}{%
\subsection{Overview}\label{overview-1}}

\begin{itemize}
\tightlist
\item
  Example
\end{itemize}

\begin{longtable}[]{@{}ccccccc@{}}
\toprule
\(x\) & 1 & 2 & 3 & 4 & 5 & 6 \\
\midrule
\endhead
\(f(x \vert \theta_0)\) & .01 & .02 & .02 & .05 & .10 & .80 \\
\(f(x \vert \theta_1)\) & .03 & .05 & .15 & .10 & 0 & .67 \\
\$ \dfrac{f(x \vert \theta_0)}{f(x \vert \theta_1)}\$ & .33 & .4 & .13 & .5 & \(\infty\) & 1.19 \\
\bottomrule
\end{longtable}

유의수준이란 기본적으로 \(H_0\)이 사실인데 \(H_1\)을 선택할 확률. 선택한 RR에 해당하는 \(H_0\)와 \(H_1\)에서의 density가 각각 있다면, \(H_0\)에서의 density의 합이 된다. 기각을 해버렸는데 \(H_0\)가 발생해버렸다는 소리니까.

power란 RR에서의 \(H_1\)이 발생할 확률.

test 자체가 \(H_1\)에 마음을 두고 시작하는 거임. power는 무조건 \(H_1\)에만 직결. 실패하면 어쩌지? 무지성으로 \(H_1\) 골라버리자. 이랬다가 \(H_0\) 발생해버리면? 난 망하는거잖아. 이 망함의 risk를 고정해두자. 이게 \(\alpha\).

power function은 \(H_0\)와 \(H_1\) 각각에 대해서 존재한다. 이는 각각에서의 pdf이다.

즉, 표본을 통한 \$ \dfrac{f(x \vert \theta_0)}{f(x \vert \theta_1)}\$의 값이 크면 \(H_0\)를 기각할 이유가 없고, 작으면 기각할 근거를 갖는다. 이 값이 얼마나 작아야 기각할 수 있는가는 유의수준에 의해 결정. 이와 같이 rs의 LR을 통해 MP test의 RR을 찾을 수 있다. 이때 RR과 \textbf{검정법}은 실제로 동일한 것이므로 혼돈이 없다는 전제 하에 test라는 단어를 주로 사용한다.

\(LR(\theta_0, \theta_1 ; \pmb x) = \dfrac{L(\theta_0 ; \pmb x)} {L(\theta_1 ; \pmb x)}\) 는 표본의 \(\theta_0\)에 대한 지지 (그리고 \(\theta_1\)에 대한 반증)의 정도를 표현한다고 볼 수 있다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{generalized-lrt}{%
\subsection{Generalized LRT}\label{generalized-lrt}}

rs \(\pmb X_n \overset {iid}{\sim} f(\pmb x ; \theta)\), \(H_0: \theta \in \Omega_0\), \(H_0: \theta \in \Omega_1 (=\Omega - \Omega_0)\).

\$

\Lambda (\pmb x) = \dfrac{\max_{theta \in \Omega_0} L(\theta ; \pmb x) }{\max_{theta \in \Omega} L(\theta ; \pmb x) } = \dfrac{L(\hat \theta_0)}{L(\hat \theta_n )}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

rs \(X_1, \cdots, X_n\)의 pdf가 \(f(x ; \theta), \; \; \; \theta \in \Omega\)라고 하자. 확률구간 \(\left[ L(\pmb X_n ), U(\pmb X_n ) \right]\)가

\[
P \left[ L(\pmb X_n ) \le \theta \le U(\pmb X_n ) \right] = 1- \alpha
\]

를 만족하면 이를 패러미터 \(\alpha\)의 \(100(1-\alpha) \%\) CI라 부른다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

rs \(\pmb X_n\) 의 분포가 pdf \(f(x ; \theta), \; \; \; \theta \in \Omega\)를 따른다 하자. 이때 샘플과 패러미터 \(\theta\)의 함수인 random quantity \(T(\pmb X_n ; \theta)\)의 분포가 패러미터 \(\theta\)에 의존하지 않으면 이는 \textbf{pivotal quantity}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(H_0: \theta \in \Omega_0, H_1: \theta \in \Omega - \Omega_0\) 에 대한 RR \(C^\ast\)가 이하를 만족하면 이는 UMP test. \(\pi^\ast\)가 이 test의 power function이라면

\$\$

\max \{ \pi\^{}\ast (\theta) \vert \theta \in \Omega\_0 \} =\alpha,

\$\$

모든 다른 power function에 대해 위의 기각역에서의 power 가 최대.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

rs \$\pmb X\_n \$ 의 joint pdf가 \(f(\pmb X_n ; \theta)\)일 때, \(LR( \theta_1 ,\theta_2 ; \pmb X_n) = \dfrac{L(\theta_1 ; \pmb X_n)}{L(\theta_1 ; \pmb X_n)}\)가 \(\theta_1 < \theta_2\)에 대해 \(T(\pmb X_n)\)의 non-dec 혹은 non-inc라면 \(L(\theta)\)는 \(T(\pmb X_n)\)에 대해 monotone LR를 갖는다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Karlin-Rubin
\end{itemize}

\(H_0: \theta \le \theta_0, H_1: \theta \ge \theta_0\). \(T\)가 \(\theta\)에 대한 SS임을 가정하고, \(T\)의 pdf의 family는 MLR을 가짐. then \(\forall t_0\), reject \(H_0 \; \; \; \iff \; \; \; T>t_0\) 하는 test는 level \(\alpha\)의 UMP test이다. 이때, \(\alpha = P_{\theta_0} (T>t_0)\).

\(L(\theta ; \pmb X_n)\)이 \(T(\pmb X_n)\)에 대해 non-inc인 MLR. 이때

\(H_0: \theta \le \theta_0, H_1: \theta \ge \theta_0\)에 대한 level \(\alpha\)의 UMP test는 \(C = \left\{ \pmb X_n : T(\pmb X_n) \ge k \right\}\) 이며, 상수 \(k\)는 \(P[T(\pmb X_n) \ge k \vert H_0 ] = \alpha\)에 의해 결정.

\(H_0: \theta \ge \theta_0, H_1: \theta \le \theta_0\)는 \(C = \left\{ \pmb X_n : T(\pmb X_n) \le k \right\}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

MLE의 불변성

MLE의 함수는 MLE

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

서로 독립인 rv X Y의 공통된 성공 확률 p의 MLE. f(X)와 f(Y)를 곱해서 쓴다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(\pmb X_n \sim U(\theta - \tfrac{1}{2}, \theta + \tfrac{1}{2})\). 이때 LF로 MLE 구하는 건 굳이 log 안 거쳐도 가능함. 안 거쳐야 증명이 깔끔한 부분이 있음.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\$\$

\dfrac{\partial f(x;\theta)}{\partial \theta}

= f(x;\theta)

\dfrac{\partial \log f(x;\theta)}{\partial \theta}

\$\$

에 의해

\$\$

E \left\{

\dfrac{\partial}{\partial \theta} \log f(X;\theta)

\right\}\^{}2

\begin{itemize}
\tightlist
\item
\end{itemize}

E \left\{

\dfrac{\partial^2}{\partial \theta^2} \log f(X;\theta)

\right\}

=0

\$\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(X \sim U(0, \theta)\)일 때, \(\theta^2\)의 UE는? \(E(X^2) = \dfrac{\theta^2}{3}\)이므로 \(T(X)=3X^2\)는 \(\theta\)의 UE.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(\pmb X_n \sim U(-\theta, \theta)\)일 때, \(c(X_{(n)}-X_{(1)}\)가 \(\theta\)의 UE가 되기 위한 c의 값은?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(\pmb X_n \sim N(\mu, \sigma^2 )\). 이때 \(cS = c \sqrt{\dfrac{\sum (X_i - \bar X)^2}{n-1}}\)가 \(\sigma\)의 UE가 되도록 하는 c의 값은?

\(Y=(n-1)\dfrac{S^2}{sigma^2}\)이 카이제곱을 따르는 rv임을 이용하여 \(E(\sqrt{Y})\)를 구하라.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(Var \left( \sum a_i \hat \theta_i \right)\)는 \(a_i = \dfrac{\tfrac{1}{\sigma^2_i}}{\sum \tfrac{1}{\sigma^2_i}}\)일 때 최소화.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

통계량 \(S(X)\)의 분포가 패러미터 \(\theta\)에 의존하지 않는다면 이는 \textbf{ancillary statistic}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

최소 SS가 존재한다면, 모든 CSS는 MSS이다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{uxac1cuxb150}{%
\section{개념}\label{uxac1cuxb150}}

충분통계량

분해정리

Minimum 충분통계량

Completeness 6.3.

ancillary 통계량 (분포가 모수에 의존 안함)

바수정리 complete고 minimum 충분통계량이면 모든 ancillary랑 독립

지수족 만족하면 뭐의 묶음은 complete 충분통계량 (추가조건, 6.6

minimum 충분통계량 존재하면 모든 Complete 통계량은 동시에 minimum 충분통계량

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

모먼트, MLE (2차까지 확인)

MLE 불변성

MSE를 통해 통계량 성능 비교 가능함
bias

MSE = precision + accuracy

UMVUE 7.5

크래머-라오 부등식 : 최저 분산 뽑아내는 수단

피셔 정보

2차원 피셔 정보

라오-블랙웰 : uniform better UE 뽑아내는 수단

unique best UE

best UE는 오직 하나뿐

(레만쉐페) CSS에 기반한 UE는 오직 유일함

W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7

consistent (점근성)

충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일

test으 unbaised 8.8

네이만 피어슨

카를린 루빈 8.3

빅 샘플 추정자들과 8.5

스코어 스탯 8.12

왈드 테스트 8.13

1-a confidence iterval = acceptance region of level 알파 test

뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨

pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT.

MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량.

cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2.

감마와 포아송간 변환

유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5.

dog-tired

Bubble Plot
3D Scatter Plot
Star Plot
Chernoff Faces
Parallel Coordinate Plot

1.Q-Q Plot
Shapiro-Wilks Test
Kolmogorov-Smirnov Test
Skewness Test ( )
Kurtosis Test: ( )
Lin and Mudholkar

Scatter Plot
Squared Generalized Distances
Chi-Square Plot (Gamma Plot)

nqplot
contour plot
cqplot

(Python -- assumption check)

\hypertarget{mcmc}{%
\chapter{MCMC}\label{mcmc}}

\hypertarget{importance-sampling}{%
\section{Importance Sampling}\label{importance-sampling}}

\hypertarget{independent-monte-carlo}{%
\subsection{Independent Monte Carlo}\label{independent-monte-carlo}}

타겟분포 \(f\)로부터의 시뮬레이션의 랜덤 draws \$ \pmb X\_1 , \cdots, \pmb X\_n \$.

적분 범위에 걸쳐 (over) support가 펼쳐져 있는 분포로부터 무작위로 포인트를 추출해서 해당 포인트들의 적분값을 종합하여 만들어내는, 적분값에 대한 통계적 측정.

let \(f\)는 \(X\)의 density, \(\mu = E_f \left[ h(X) \right]\). 이때

\$

\hat \mu\emph{\{MC\} = \dfrac {1}{n} \sum}\{i=1\}\^{}n h(X\_i ) \rightarrow \int h(x)f(X) dx =\mu ; ; ; ; ; \text{as } n \rightarrow \infty

\$

let \$ v(x) = \{ h(x)-\mu \}\^{}2\$, \$ E\_f \{ \left[ h(X) \right]\^{}2 \} \textless{} \infty \$. Then, sampling \(Var\) of \$ \hat \mu\_\{MC\} \$ is \$\dfrac {\sigma^2}{n} = E \{ \dfrac {v(x)}{n} \}. This can be written as

\$

\hat {Var} (\hat \mu\emph{\{MC\}) = \dfrac {1} \{n-1\} \sum}\{i=1\}\^{}n \left[ h(X_i) - \hat \mu_{MC} \right]\^{}2

\$

when \sigma\^{}2 exists, by CLT, \(\hat \mu_MC \overset {\cdot} {\sim} N\), for large \(n\).

수치해석은 다차원 문제에는 적용하기 어렵다. 하지만, MC integration은 \(p\)차원의 \(f\)의 support에 걸쳐서 \(f\)에서 랜덤하게 샘플링 한 후 이 영역에 대한 그 어떤 체계적인 탐색도 시도하지 않는다. 샘플링 후에는 그냥 냅둬버림. 따라서 MC는 고차원에서도 덜 피곤함.

\hypertarget{inverse-cdf}{%
\paragraph{Inverse-cdf}\label{inverse-cdf}}

\(\forall F, X=F^{-1}(U) = \text{inf}\{ x:F(x) \ge U \}\)는 \(F\)와 같은 cdf를 가짐. 이때 \(F\)는 continuous distribution function, \(U \sim U(0, 1)\).

이때, linear interpolation을 활용해, \(F^{-1}\) 계산 없이 \(F\)만으로 난수 샘플링 가능.
1. \(f\)의 supoprt를 span하는 grid \(x_1 , \cdots, x_m\) 정의
2. 각 grid point에서 \(u_i = F(x_i)\) 계산하거나 approximate
3. 가장 가까운 grid points \(u_i , u_j\)에 대해, \(u_i \le U \le u_j\)에 해당하는 영역을 이하에 따라 linearly interpotate. \(X = \dfrac{u_j-U}{u_j - u_i}x_i + \dfrac{U-u_i}{u_j - u_i}x_j\). 이때 \(U \sim U(0, 1)\).
- illustration of Rejection Sampling for a target distribution \(f\) using a Rejection Sampling envelope \(e\).

\hypertarget{rejection-sampling}{%
\paragraph{Rejection Sampling}\label{rejection-sampling}}

\(f(x)\)의 상수배 (proportionality constant) 만이라도 계산될 수 있다면, 정확한 타겟분포 \(f(x)\)로부터의 샘플링을 위하여 \textbf{Rejection Sampling} 사용 가능. 이는 더 간단한 후보 (candidate) 분포로부터 샘플링한 후 이렇게 샘플링한 것 중 일부를 확률에 기반하여 랜덤하게 쳐냄으로써 샘플링 확률을 보정하는 것.
* \(g\)는 우리가 분포의 형태를 정확히 알고 있고 \(g(x)\) 계산도 쉬운 덴시티라고 정의.
* \(e\)는 \textbf{envelope}, 이하의 성질을 갖는다. \(\forall x \; \; \; \text{s.t. for a given constant } \alpha \le 1, f(x)>0 \; \; \; : \; \; \; e(x) = \dfrac {g(x)}{\alpha} \ge f(x)\).

방법은 이하와 같다.
1. \(Y \sim g\)에서 샘플링.
2. \(U>\dfrac {f(y)}{e(Y)}\)일 경우 \(Y\)를 기각. 기각된다면 \(Y\)값을 target random sample의 요소로 기록하지 않음. step 1으로.
3. \(U \le \dfrac {f(y)}{e(Y)}\)일 경우 set \(X=Y\)로 한 후 \(X\)를 타겟 랜덤샘플의 요소로 넣음. step 1으로.

여기서 \(\alpha\)는 채택될 후보들의 expected 비율로 해석될 수 있다.

good RS envelope의 요건:
* 간단하게 제작되거나, 모든 값에서 타겟분포를 넘김이 간단하게 확인되어야 한다.
* 샘플링이 쉬어야 한다.
* rejected draws가 적어야 한다.

\begin{quote}
Example: Normal From Double Exponential, Sampling a Bayesian Posterior
\end{quote}

\hypertarget{variants-of-the-rs-squeeze-rs}{%
\paragraph{Variants of the RS: Squeeze RS}\label{variants-of-the-rs-squeeze-rs}}

\(f\) 계산해내는 게 비용이 많이 들고 RS가 매력적인 상황이면 \textbf{Squeeze RS}에 의해 더 빠른 연산속도를 획득할 수 있음. nonnegative squeezing function \(s(x)\)를 정의하고 이를 사용함. 이때 \(s\)가 적합한 squeezing function이기 위해선 \(f\)의 모든 support에서 \(s<f\).
* illustration of squeezed Rs for a target distribution \(f\), using envelope \(e\) and squeezing function \(s\). Keep First and Keep Later correspond to steps 3 and 4 of the algorithm, respectively.

proceeds:
1. \(Y \sim g\)에서 샘플링.
2. if \(U \le \dfrac {s(Y)}{e(Y)}\), keep \(Y\).
3. if not, whether if \(U \le \dfrac {f(Y)}{e(Y)}\), keep \(Y\).
4. both are not, reject \(Y\).

2번에선 \(s\), 3번에선 \(f\)임에 주목. 샘플링 쉬운 \(s\)에서 먼저 비교해서 우선권 시드 주고, 그 후에 \(f\)로 본선 해보는거.

\begin{quote}
Example: Lower Bound for Normal Generation
\end{quote}

\hypertarget{variants-of-the-rs-adaptive-rs}{%
\subparagraph{Variants of the RS: Adaptive RS}\label{variants-of-the-rs-adaptive-rs}}

적절한 envelope \(e\)를 어떻게 만들 것인가? squeezed RS를 위해, support의 connected region에 대해 continuous, differentiable, log-concave인 덴시티를 만드는 자동화된 envelope 생산 전략에 해당함. 패키지로 실행.
* envelopes \(e\) and squeezing function \(s\) for adaptive RS. The target density \(f\) is smooth, nearly bell-shaped curve. The first method discussed in the text, using the derivative of \(l\), produces the envelope \(e\) shown as upper boundary of the lighter shaded region. This correponds to Equation (6.9) and Figure 6.4. Later in the text, a derivative-free method is presented. That envelope is the upper bound of the darker shaed region and corresponds to (6.11) and Figure 6.6. The squeezing function \(s\) for both approaches is given by the dotted curve.

\hypertarget{importance-sampling-1}{%
\paragraph{Importance Sampling}\label{importance-sampling-1}}

\textbf{Importance Sampling} 접근법은 \(E\{h(x)\}\) w.r.t. its density는 이하처럼 alternative form으로 쓰일 수 있다는 것에 기반한다. 이때 \(g\)는 envelope의 importance sampling function.

\$
\begin{align*}



\mu &= \int h(x)f(x)dx &= \int \left( h(x) \dfrac {f(x)}{g(x)} \right)g(x)dx \tag{1} \\

\\
\\

&= \dfrac {\int h(x)f(x) dx}{\int f(x) dx} &= \dfrac {\int \left( h(x) \dfrac {f(x)}{g(x)} \right) g(x) dx}{\int \left( \dfrac {f(x)}{g(x)} \right) g(x) dx} \tag{2}

\end{align*}

\$

\begin{itemize}
\tightlist
\item
  (1)은 \(E \{ h(X) \}\)를 측정하기 위한 MC 접근법이 이하임을 제시한다. \(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} g\)처럼 \(g\)에서 랜덤샘플을 뽑고, 이의 (이를 활용한) estimator는 이하. 이때 \(w^{\ast} (X_i)\)는 \textbf{unstandardized weights}, i.e., \textbf{importance ratios}.
\end{itemize}

\$

\hat \mu\emph{\{IS\}\^{}\{\ast\} = \dfrac {1}{n} \sum}\{i=1\}\^{}n h(X\_i) w\^{}\{\ast\}(X\_i) = \dfrac {1}{n} \sum\_\{i=1\}\^{}n h(X\_i) \ast \dfrac {f(X_i)}{g(X_i)}

\$

(2)는 \(g\)에서 \(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} g\)의 랜덤샘플을 뽑고 이하를 계산. 이때 \(w(X_i)\)는 standardized weight. 이 (2)는 \(f\)의 상수배 (proportionality constant) 까지만 알 수 있더라도 적용할 수 있다는 점에서 매우 중요함. \(f\)의 상수배까지만 알 수 있는 상황은 베이지안 분석의 post에서 빈번하게 발생함. \textbf{\emph{Both estimators converge by the same argument applied to the simple Monte Carlo estimator.}}

\$

\hat \mu\emph{\{IS\} = \sum}\{i=1\}\^{}n h(X\_i) w(X\_i) = \sum\_\{i=1\}\^{}n h(X\_i) \dfrac {w^{\ast}(X_i)}{\sum_{i=1}^n w^{\ast}(X_i)}

\$

Proceeds:
1. Sample \(X_j \sim g(\cdot)\).
2. Calculate \(w(X_j) = \dfrac {f(X_j)}{g(X_j)}\)
3. 지정 샘플 갯수까지 반복

then,

\$
\begin{align*}

E\{\hat h(x)\} &= \dfrac {1}{n} \sum_{j=1}^n w(X_j)h(X_j) \\

\hat \sigma^2 &= \dfrac {1}{n-1}  \sum_{j=1}^n \left\{ h(X_j) - E\left[ \hat h(x) \right] \right\}^2

\end{align*}
\$

과도한 변동성을 회피하기 위해, \(\dfrac {f(x)} {g(x)}\)는 bounded여야 하며 또한 \(g\)는 \(f\)보다 heavier tail을 가져야 한다. 이것이 만족되지 않는다면 standardized importance weight는 제법 커질 수 있음.

함수 \(g\)는, \(h(x)\)가 매우매우 작을 경우에만 \(\dfrac {f(x)} {g(x)}\)가 커지게 만드는 녀석으로 잘 골라야 한다. 가령 \(h\)가 아주 드문 상황에서만 1을 반환하는 indicator function이라면, 우리는 \(g\)로 하여금 샘플링의 편의성을 위해 해당 사건을 좀 더 빈번하게 발생시키도록 하는 녀석을 고를 수도 있을 것이다. 이를 택한다면 우리는 우리의 관심사가 아닌 사건, 가령 \(h(x)=0\)에 대한 적절한 샘플링 power을 어느정도 희생하게 된다. \textbf{\emph{이는 낮은 확률에 해당하는 case의 측정에 특히 잘 들어맞는 방법론이다.}}

\$\hat \mu\_\{IS\}\^{}\ast \$ 자체는 unbiased지만, 이를 importance weight로 standardize 하는 과정에서 \(\hat \mu_{IS}\)에 다소 bias가 생겨버린다.

standardized weight를 쓰는 건 \(w^\ast(X)\)와 \(h(X)w^\ast(X)\)가 서로 강하게 상관관계가 있는 상황에서 더욱 우수한 estimator를 반환한다.

standardized weight는 \(f\)의 비례상수를 요구하지 않는다. (우리가 갖고 있는 덴시티가 \(f\)의 얼마만큼의 상수배인지를 알지 않아도 된다)

IS 방법론의 매력은 시뮬레이션의 reusability이다. 같은 sample points들과 weight들이 다양한 다른 quantity의 MC 적분 estimates를 구하는데 사용될 수 있다. (\textbf{컴퓨팅 파워가 증가한 오늘날에 와서는 유의미한 장점은 아니다.})

\begin{quote}
Example: Small Tail Probabilities
\end{quote}

\hypertarget{antithetic-sampling}{%
\paragraph{Antithetic Sampling}\label{antithetic-sampling}}

let \(\hat \mu_1, \hat \mu_2\). 이 둘은 identically distributed, UE, and \(Corr(\hat \mu_1, \hat \mu_2)<0\).

이 estimator 둘을 평균한 \(\hat \mu_{AS} = \dfrac{\hat \mu_1 + \hat \mu_2}{2}\)는 각 estimator들의 샘플을 2배 한 것보다 우월함. \textbf{\(Corr(\hat \mu_1, \hat \mu_2)<0\)이기 때문에 성립한다는 것을 유의.}

\$

Var(\hat \mu\_\{AS\}) = \dfrac {1}{4} \left( Var(\hat \mu\_1) + Var(\hat \mu\_2) \right) + \dfrac{1}{2} Cov(\hat \mu\_1, \hat \mu\_2) = \dfrac {1}{2} \ast \dfrac {\sigma^2} \{n\} (1+\rho)

\$

\(\hat \mu_1 (X)\)를 MC integral estimate로 잡는다면, 이는

\$

\hat \mu\emph{1 (X) = \dfrac{1}{n} \sum}\{i=1\}\^{}n h\_1 \left\{ F\_1\^{}\{-1\}(U\_\{i1\}), \cdots, F\_m\^{}\{-1\}(U\_\{im\}) \right\}

\$

이때 \(h_1\)은 그의 \textbf{arguments}에 monotone이며, \(F_j\)는 각 \(X_{ij}, \; j=1,\cdots,m\)의 cdf이며 \(U_{ij} \sim U(0,1)\). 이에 의해 \(1-U_{ij} \sim U(0,1)\)이기도 하며, 이에 의해 이하도 성립.

\$

\hat \mu\emph{2 (X) = \dfrac{1}{n} \sum}\{i=1\}\^{}n h\_1 \left\{ F\_1\^{}\{-1\}(1-U\_\{i1\}), \cdots, F\_m\^{}\{-1\}(1-U\_\{im\}) \right\}

\$

이는 \(\mu\)의 2번째 estimator이며, 이는 \(\hat \mu_1 (X)\)와 같은 분포를 가짐.

따라서 \(\hat \mu_{AS} = \dfrac{\hat \mu_1 + \hat \mu_2}{2}\)는 \(\hat \mu_1\)의 샘플을 2배 한 것(2n)보다 더 작은 \(Var\)을 가지며, 따라서 더 우월함.

\hypertarget{control-variates}{%
\paragraph{Control Variates}\label{control-variates}}

우리는 알지 못하는 quantity \(\mu = E \{ h(X) \}\)를 알고자 하며, 이에 연관된 quantity \(\theta = E[c(Y)]\)에 대해서는 알고 있음. 후자는 수치적으로 획득 가능. \((X_1 , Y_1 ) ,\cdots, (X_n , Y_n )\)은 simulation outcom에서 독립적으로 관측된 pairs of rv.

이때 MC estimator는 이하와 같다. \(\hat \mu_{MC}, \hat \theta_{MC}\) 간에 상호연관이 있음을 유의.

\$
\begin{align*}

\hat \mu_{MC} = \dfrac {1}{n} \sum_{i=1}^n h(X_i), & \; \; \; \; \; \; \; \; \; \; \hat \theta_{MC} = \dfrac {1}{n} \sum_{i=1}^n c(Y_i)

\end{align*}
\$

즉 우리는 여기서

\begin{longtable}[]{@{}ccc@{}}
\toprule
& \(\mu = E[h(x)]\) & \(\theta = E[c(Y)]\) \\
\midrule
\endhead
MC (ex. \(\theta_{MC}\)) & able & able \\
itself & & able \\
\bottomrule
\end{longtable}

즉 \(\theta\)와 \(\theta_{MC}\) 간의 차이를 알아내고, 이 차이를 적당히 스케일링해서 \(\mu\)에 적용한다는 것이 기본 메커니즘.

여기서 Control Variate Estimator는 \(\hat \mu_{CV} = \hat \mu_{MC} + \lambda(\hat \theta_{MC} - \theta)\). \(\lambda\)는 사용자에 의해 정해지는 임의의 parameter. 이에 의해

\$

Var(\hat \mu\emph{\{CV\} ) = Var (\hat \mu}\{MC\}) + \lambda\^{}2 Var (\hat \theta\emph{\{MC\}) + 2 \lambda Cov(\hat \mu}\{MC\}, \theta\_\{MC\})

\$

이며 이가 최소가 된 경우의 분산은 아래와 같으며, 이를 최소로 하는 \(\lambda\)는 아래와 같다.

when \(\lambda = - \dfrac {Cov(\hat \mu_{MC}, \hat \theta_{MC})}{Var(\hat \theta_{MC})}\), \(\min_\lambda \left( Var(\hat \mu_{CV} ) \right) = Var(\hat \mu_{MC}) - \dfrac{\left[ Cov(\hat \mu_{MC}, \hat \theta_{MC}) \right]^2} {Var(\hat \theta_{MC})}\).

\hypertarget{rao-blackwellizaiton}{%
\paragraph{Rao-Blackwellizaiton}\label{rao-blackwellizaiton}}

rs \(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} f\)를 활용해 \(\mu = E \{ h(X) \}\)를 estimation.

각각의 \(X_i = (X_{i1}, X_{i2})\)라고 가정하고, 조건부 기댓값 \(E\{ h(X_i) \rvert x_{i2} \}\)가 수치적으로 풀릴 수 있다고 가정하자.

\$ E\{h(X\_i)\} = E\_\{X\_\{i2\}\}\{ E \left[ h(X_i) \rvert x_{i2} \right] \}\$라는 사실을 활용하여 \$ \hat \mu\_\{MC\} \$ 에 대한 다른 estimator를 구축해보자.

Rao-Blackwellized estimator \(\hat \mu_{RB} = \dfrac 1 n \sum_{i=1}^n E \{ h(X_i) \rvert X_{i2} \}\). 이는 ordinary MC estimator \(\hat \mu_{MC}\)와 같은 mean을 갖는다. Note that

\$

Var(\hat \mu\emph{\{MC\}) = \dfrac {1} \{n\^{}2\} Var \left\{ E\left[ E\{ h(X_i) \rvert X_{i2} \}\right] \right\} + \dfrac 1 \{n\^{}2\} E \left\{ Var \left[ E\{ h(X_i) \rvert X_{i2} \}\right] \right\} \ge Var (\hat \mu}\{RB\})

\$

따라서 Mean Squared Error, MSE 관점에서 \(\hat \mu_{RB}\)는 \(\hat \mu_{MC}\) 보다 우수하다.

\hypertarget{sampling-importance-resampling}{%
\paragraph{Sampling Importance Resampling}\label{sampling-importance-resampling}}

SIR 알고리즘은 몇 타겟분포에서 실현값을 모사적으로 시뮬레이트한다. SIR은 Importance Sampling의 개념에 기초하고 있다. IS에서 우리는 IS function \(g\)에서 샘플링하는 식으로 진행했었다. 샘플의 각 point는 샘플링 확률을 보정 (correct)하기 위해 weighted 되었었으며, 이에 의해 weighted 샘플들은 타겟분포 \(f\)와 연결지어질 수 있었다. 타겟분포 \(f\)를 획득하기 위해 샘플링 확률 보정 목적으로 가해지는 weight는 \textbf{standardized importance weight} \(w(x_i)\)로 불렸으며,

\$
w(x\_i) = 이 만으로 난수 샘플링 가능.
\dfrac 
\{\dfrac {f(x_i)}{g(x_i)}\}
\{\sum\_\{i=1\}\^{}m \dfrac {f(x_i)}{g(x_i)}\}

\$

이렇게 획득했던 standardized weight는 이후에 출신 density가 아닌 다른 타겟 \(f\)에서 다른 샘플을 생산할 때 재사용되는 것이 가능하다.

for a collection of values, \(x_i , \cdots, x_m \overset {\text{iid}} {\sim} g\), 이때 \(g\)는 Importance Sampling Function.

proceeds:
1. sample candidates \(Y_1 , \cdots, Y_m \overset {\text{iid}} {\sim}\) 타겟분포 \(g\). \textbf{\(g\)가 타겟분포라고?????? 수업발언}
2. caculate the standardized importance weights, \(w(Y_1) , \cdots, w(Y_m)\).
3. resample \(X_1 , \cdots, X_m\) from \(Y_1 , \cdots, Y_m\) with probabilities, \(w(Y_1) , \cdots, w(Y_m)\).

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}@{}}
\toprule
for \(n\) samples & Rejection Sampling & SIR \\
\midrule
\endhead
& perfect & not perfect \\
distribution of generation draw is & exactly \(f\) & random degree of approxiamtion to \(f\) \\
required number of draws & random & determined \\
\bottomrule
\end{longtable}

It is important to consider the relative sizes of the initial sample and the resample. In principle, we require \(\dfrac n m \rightarrow 0\) for distributional convergence of the sample.

1만개를 생산해놓고 이 안에서 추가적으로 공정을 진행해서 목표했던 랜덤한 샘플을 뽑아내는 것이 SIR. 그러나 전 영역에서 체크하는것과 생산해놓은 1만개에 randomness를 첨가하여 만들어낸 샘플은 퍼포먼스 차이가 당연히 존재. 그러나 전 영역 대비 1만개라는 한정된 영역에서 추가공정을 진행하므로 cost down.

기존에 만들어두었던 weight를 재사용하므로 시뮬레이션을 다시 할 필요가 없음. 시간 down.

Rejection Sampling \textbar{} envelope \(e\)를 만들고 이 안에서 뽑음. 이는 continuous point. \textbar{} perfect, exact \textbar{}\\
SIR \textbar{} n개의 candidate point를 이미 선택해놓고 이 안에서 뽑음. discrete. \textbar{} approximate sampling \textbar{}

candidate \(m\)개, 샘플 \(n\)개. 당연하지만 candidate \(m\)의 숫자가 커질수록 효율성 (approximate 성능) 은 높아짐. The maximum tolerable ratio \(\dfrac n m\) depends on the quality of the envelope, bsed on \(m\) candidate samples and their weights. 이상적으로는 \(m\)이 무한해지면 SIR 조차도 exact sampling일 수 있다.

The SIR algorithm can be sensitive to the choice of \(g\).
* The support of \(g\) must include the entire support of \(f\), for a reweighted sample from \(g\) is to approximate a sample from \(f\).
* \(g\) should have heavier tails than \(f\), or more generally \(g\) should be chosen to ensure that \$ \dfrac {f(x)}{g(x)}\$ never grows to o large.
* If \(g(x)\) is nearly zero anywhere where \(g(x)\) is positive, then a draw from this region will happen only extremely rarely, but when it does it will receive a huge weight.
* weight-degeneracy problem

\begin{quote}
Example: Slash Distribution
Example: Sampling a Bayesian Posterior
\end{quote}

\hypertarget{sequential-monte-carlo}{%
\paragraph{Sequential Monte Carlo}\label{sequential-monte-carlo}}

When the target density \(f\) becomes high dimensional, SIR is increasingly inefficient and can be difficult to implement. Specifying a very good high-dimensional envelope that closely approximates the target with sufficiently heavy tails but little waste can be challenging.

Sequential Monte Carlo methods address the problem by splitting the high-dimensional task into a sequence of simpler steps, each of which updates the previous one.

\(\pmb X_{1:t} = (X_1 , \cdots, X_t )\) represents a discrete time stochastic process with \(X_t\) being the observation at time \(t\).

\(\pmb X_{1:t}\) represents the entire history of the sequence.

Suppose the density of \(\pmb X_{1:t}\) is \(f_t\) and we wish to estimate the expected value of \(h(\)\pmb X\_\{1:t\}\()\) w.r.t. \(f_t\).

A direct application of the SIR approach would be to draw a sample \(\pmb x_{1:t}\) sequences from an envelope gt and then calculate the importance weighted average of this sample of \(h(\pmb X_{1:t})\) values.

This SIR approach overlooks a key aspect of the problem.
* As t increases, \(\pmb X_{1:t}\) and the expected value of \(h(\pmb x_{1:t})\) evlove.
* At time \(t\) it would be better to update previous inferences than to act as if we had no previous information. \textbf{Inefficient !!!}

Need to develop a strategy that will simulate \(X_t\) from previously simulated \(\pmb X_{1:t-1}\) and adjust the previous importance weights in order to estimate the expected value of \(h(\pmb X_{1:t})\) . \textbf{Sequential Importance Sampling}.

\hypertarget{sis-for-markov-process}{%
\paragraph{SIS for Markov Process}\label{sis-for-markov-process}}

Simplify assumption that \(\pmb X_{1:t}\) is a Markov process.

The target density \(f_t (\pmb x_{1:t})\) may be expressed as

\$
\begin{align*}

f_t (\pmb x_{1:t}) &= f_1 (x_1) &\ast f_2 (x_2 \rvert \pmb x_{1:1}) &\ast f_3 (x_3 \rvert \pmb x_{1:2}) &\cdots &\ast f_t (x_t \rvert \pmb x_{1:t-1}) \\


&= f_1 (x_1) &\ast f_2 (x_2 \rvert x_1) &\ast f_3 (x_3 \rvert x_2) &\cdots &\ast f_t (x_t \rvert x_{t-1})

\end{align*}
\$

Suppose that we adopt the same Markov form for the envelope, namely

\$

g\_t (\pmb x\_\{1:t\})= g\_1 (x\_1) \ast g\_2 (x\_2 \rvert x\_1) \ast g\_3 (x\_3 \rvert x\_2) \cdots \ast g\_t (x\_t \rvert x\_\{t-1\})

\$

Sample from \(g_t (\pmb x_{1:t})\) and reweight each \(\pmb x_{1:t}\) value by \(w_t = \dfrac {f_t (\pmb x_{1:t})}{g_t (\pmb x_{1:t})}\).

The weight at time \(t\) is \(w_t = \dfrac {f_1 (x_1) \ast f_2 (x_2 \rvert x_1) \ast \cdots} {g_1 (x_1) \ast g_2 (x_2 \rvert x_1) \ast \cdots}\).

A sample of \(n\) such points and their weights can be used to approximate \(f_t (\pmb x_{1:t} )\) and calculate the expected value of \(h(\pmb x_{1:t} )\).

The sequential Monte Carlo algorithm for generating one sample is
1. Sample \$X\_1 \sim g\_1 \$. Let \(w_1 = u_1 = \dfrac {f_1(x_1)}{g_1(x_1)}\). Set \(t = 2\).
2. Sample \(X_t \rvert x_{t-1} \sim g_t (x_t \rvert x_{t-1})\).
3. Append \(x_t\) to \(\pmb x_{1:t-1}\), obtaining \(\pmb x_{1:t}\).
4. \(u_t = \dfrac{f_t (x_t \rvert x_{t-1})}{g_t (x_t \rvert x_{t-1})}\).
5. let \(w_t = w_{t-1}u_t\). \(w_t\) is the importance weight for \(\pmb x_{1:t}\) .
6. Increment t and return to step 2.

The weighted average \(\sum_{i=1}^n \left( \dfrac {w_t^{(i)}}{\sum_{i=1}^n w_t^{(i)}} \right) \ast h(\pmb X_{1:t}^{(i)})\) serves as the estimate of \(E_{f_T} h(\pmb X_{1:t})\).

\hypertarget{generalized-sequential-importance-sampling}{%
\paragraph{Generalized Sequential Importance Sampling}\label{generalized-sequential-importance-sampling}}

Assume that \(\pmb X_{1:t}\) is not a Markov process.

target density \(f_t (\pmb x_{1:t})\) and envelope \(g_t (\pmb x_{1:t})\) may be expressed as

\$
\begin{align*}

f_t (\pmb x_{1:t}) &= f_1 (x_1) \ast f_2 (x_2 \rvert \pmb x_{1:1}) \ast f_3 (x_3 \rvert \pmb x_{1:2}) &\cdots &\ast f_t (x_t \rvert \pmb x_{1:t-1}) \\

g_t (\pmb x_{1:t}) &= g_1 (x_1) \ast g_2 (x_2 \rvert \pmb x_{1:1}) \ast g_3 (x_3 \rvert \pmb x_{1:2}) &\cdots &\ast g_t (x_t \rvert \pmb x_{1:t-1})
\end{align*}
\$

the importance weight at time \(t\) is

\$

w\_t (\pmb x\_\{1:t\}) = \dfrac {f_1 (x_1) \ast f_2 (x_2 \rvert \pmb x_{1:1}) \ast f_3 (x_3 \rvert \pmb x_{1:2}) \cdots \ast f_t (x_t \rvert \pmb x_{1:t-1})} \{g\_1 (x\_1) \ast g\_2 (x\_2 \rvert \pmb x\_\{1:1\}) \ast g\_3 (x\_3 \rvert \pmb x\_\{1:2\}) \cdots \ast g\_t (x\_t \rvert \pmb x\_\{1:t-1\})\}
\$

and the recursive updating expression for the importance weights is

\(w_t(\pmb x_{1:t}) = w_t(\pmb x_{1:t}) \dfrac {f_t (x_t \rvert \pmb x_{1:t-1})}{g_t (x_t \rvert \pmb x_{1:t-1})}, \; \; \; \; \; \; \; \; \text{for }t>1\)

\hypertarget{markov-chain-monte-carlo}{%
\section{Markov Chain Monte Carlo}\label{markov-chain-monte-carlo}}

\(f\) 가 측정은 되는데 샘플화가 안되면, MC를 통해 유사한 샘플을 만들어낼 수 있었다. 이를 넘어서 MCMC는 \$ f \$ 의 모사함수에서 샘플링하는 게 가능하지만, 이 이상으로 이는 임의의 함수 \(p\)에 대해 \(E[p(X)]\)가 신뢰도 높게 측정되는 경우에만 샘플링 가능한 별개의 방법론으로 보는 게 정확하다.

\begin{longtable}[]{@{}ccc@{}}
\toprule
MC & MCMC & numerical integration approach \\
\midrule
\endhead
& iterative nature & \\
& can be customized to very diverse \& difficult problem & \\
& 무관하며 implementation이 complex하지도 않음 & 문제가 고차원이면 수렴이 느려짐 \\
\bottomrule
\end{longtable}

시퀀스 \(\{\textbf X^{(t)}\}\)는 MC, \(t = 0, 1, 2, ….\). \(\textbf X^{(t)} = (X_1^{t} , \cdots, X_p^{(t)})\) 와 \textbf{state space} 는 양쪽 모두 연속이거나 discrete.

For the types of Markov chains, \(\{ \textbf X^{(t)} \}\)의 분포는 체인의 limiting stationary distribution으로 수렴한다. 체인이 irreducible, aperiodic 할 때.

MCMC의 샘플링 전략은 irreducible, aperiodic MC를 만드는 것. stationary distribution이 목표분포 \(f\) 와 일치하는.

t가 충분히 크다면 이 체인으로부터의 \(\textbf X^{(t)}\)의 실현값은 근사적으로 마지널 분포 \(f\) 를 갖는다.

이런 MCMC의 특성은 베이지안 추론에 크게 도움이 되며 자주 쓰인다.

Markov Chain 자체는 \textbf{어떤 상태에서 다른 상태로 넘어갈 때, 바로 전 단계의 상태에만 영향을 받는} (Markov Property) 확률 과정을 의미한다.

\begin{itemize}
\tightlist
\item
  보통 사람들은 전날 먹은 식사와 유사한 식사를 하지 않으려는 경향이 있다.
\item
  가령, 어제 짜장면을 먹었다면 오늘은 면종류의 음식을 먹으려고 하지 않는다.
\end{itemize}

\hypertarget{mh-algorithm}{%
\subsection{MH Algorithm}\label{mh-algorithm}}

MCMC 중 가장 유명한 적용법은 MH 알고리즘. \(t=0\)에서 시작. 시작 distribution \(g\)에서 추출한, \(f(\textbf x^{(0)} )> 0\) 을 만족하는 \(\textbf x^{(0)}\)를 \(\textbf X^{(0)} = \textbf x^{(0)}\) 로 잡고 개시한다.

이때 제안분포 \(g\) 에서 후보 \(\textbf X^{( \ast )}\) 를 하나 만들고, MH ratio \(R (\textbf {x}^{(t)}, \textbf X^{\ast} )\) 는

\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} ) 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )} | \textbf X^{( \ast )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )} | \textbf x^{( t )}) } 
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf X^{( \ast )} | \textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )} | \textbf X^{( \ast )})}
}
=\dfrac
{\dfrac
{f(\textbf X^{( t+1 )})}
{g(\textbf X^{( t+1 )} | \textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )} | \textbf X^{( t+1 )})}
}
\]

\textbf{warning}

여기서 단순 Metropolis 알고리즘은 단순히 \$ \dfrac {f(x_1)} \{f(x\_0)\}\$ \textgreater{} \$1 \$ 이기만 하면 새로운 샘플을 수용한다. 이인즉 \(g\)로 표준화해주는 것의 가장 주요한 요점은 둘의 시작 높이, 즉 쥐고 나온 수저가 다를 수 있으므로 이를 표준화해준다는 것이다. 아웃풋이 높은 \(x_i\)를 선택하는 것은 MLE 관점에 기반한다.

단 언제나 그렇듯 이렇게 샘플을 다쳐내면 오히려 음질의 결과가 나온다. 따라서 샘플의 풀을 넓히기 위해 탈락할 녀석들도 확률적으로 살려서 합류시킨다. 이게 고정된 기준점으로 샘플을 쳐내는 것이 아닌, \(\dfrac {f(x_1)} {f(x_0)}\) \textgreater{} \(u \sim U {(0,1)}\) 을 기준으로 삼아 샘플을 생존시키는 것이다. 이 조건을 실패하면 생산해두었던 샘플 \(\textbf X^{(t)}\) 는 버려지고 새로운 샘플을 \(t+1\)으로 설정해 재진행한다.

이후

\[
\textbf {X}^{(t+1)} = \left\{\begin{array}{@{}lr@{}}
    \textbf {X}^{\ast}, & \text{with probability } min \left\{ R \left( \textbf {x}^{(t+1)}, \textbf {X}^{\ast} \right), 1 \right\} \\
    \textbf {x}^{(t)}, & o.w.
    \end{array}\right\}
\]

이러한 MH 알고리즘에 의해 생성된 MC가 aperiodic \& irreducible 이라면, 해당 체인은 정적분포로 수렴.

우리는 이러한 MH 체인에 의해 생성된 정적분포의 실현값들을 평균함으로써 rv의 함수의 기댓값을 구할 수 있다.

\(E \left[ h \left( \textbf {X} \right) \right] \approx \dfrac {1} {n} \sum_{i=1}^n {h \left( \textbf {x}^{(i)} \right)},\)

\(E { \left\{ h \left( \textbf {X} \right) - E \left[ h \left( \textbf {X} \right) \right] \right\} }^2\),

\(E \{ I_{h ( \textbf {X} \le q )} \}\)

시퀀스 \(\{ \textbf x^{(\inf)} \}\) 는 state space의 몇몇 포인트들의 multiple copies를 가질 수 있다는 것을 명심. 이는 \(\textbf {X}^{(t+1)}\)가 제안값 \(\textbf {x}^{(\ast )}\)가 아니라 \(\textbf {x}^{(t)}\)를 채택했을 때 발생.

\begin{itemize}
\tightlist
\item
  Burn-in Period: 체인의 초기값에 대한 persistent dependence는 이의 성능을 심각하게 낮출 수 있다. 이는 샘플 평균을 계산할 때 체인의 초기 실현값 일부를 제하는 것으로 보정될 수 있다.
\end{itemize}

consistent 결과들을 관측하기 위해 MCMC를 여러 시작점에서 각각 돌려본다.

잘 골라진 제안분포 \$ g \$가 생산하는 후보값들은 \textbf{stationary 분포}의 서포트를 합리적인 반복 안에서 전부 커버하고, 내놓는 후보값들이 지나치게 여러번 accepted되거나 rejected 되지 않는다.

\begin{itemize}
\tightlist
\item
  proposal 분포 \$ g \$ 가 지나치게 퍼져있으면, 후보값들은 자주 reject되고 체인은 타겟분포 \$ f \$ 의 space를 탐색하기 위해 많은 반복을 요구하게 된다.
\item
  proposal 분포 \$ g \$ 가 지나치게 모여있으면, 체인은 다회의 반복동안 타겟분포 \$ f \$의 한 작은 구역에 모여있게 된다. 따라서 타겟분포의 다른 영역은 적절하게 탐색되지 못한다.
\end{itemize}

~\\
~\\

\hypertarget{independent-chains}{%
\subsubsection{Independent Chains}\label{independent-chains}}

acceptance 여부 결정시에 ratio 자체는 MH ratio를 사용한다. 이 MC ratio에는 과거 실현값(\(x^{(t)}\))이 들어있다. 따라서 이는 MCMC 방법론에 해당한다. 하지만 새로운 value \(g(x')\)을 생산할 때, 이 자체는 \(g(x'\rvert x^{(t)})=g(x' \rvert \cdot )\)을 따르게, 즉 \(g(x'\rvert x^{(t)})=g(x' )\) 마냥 과거의 실현값에 dependent 하지 않게 새로운 값을 생산해내는 방법론. 즉 새로이 제시되는 candidate value가 과거의 실현값들과 independent 하므로 명칭이 저러한 것이다.

즉 \textbf{MH ratio 자체는 과거의 샘플을 이용해서} MCMC 범주에 들어가나 샘플 자체는 과거의 샘플과 independent하게 생산.

MH 알고리즘의 제안분포는 고정된 덴시티 \(g\)에 대해서 \$ g \left( \textbf {x}\^{}\{\ast\} \rvert \textbf {x}\^{}\{(t)\} \right)\$ 따위로 생성. 이는 \textbf{independent chain} 이라고 불리며, 이에 사용되는 각 후보값들은 과거에서 독립적으로 추출되었다. MH ratio는

\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} ) 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )} | \textbf X^{( \ast )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )} | \textbf x^{( t )}) } 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )}) } 
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf X^{( \ast )})}
}
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf X^{( \ast )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )})}
}
= \dfrac {w^{\ast}} {w^{(t)}}
\tag{1}
\]

\begin{itemize}
\tightlist
\item
  importance ratio of \(X'\), importance ratio of \(X^{(t)}\). This can be seen as weight also.
\end{itemize}

이때 가장 우측의 등식은 importance ratio (\(r\))의 등식으로 재표현된 것이며, 이때 \(f\) 는 타겟분포, \(g\) 는 그것의 envelope로 본 것이다.

~\\
~\\

\hypertarget{example-bayesian-inference-mixture-distribution}{%
\paragraph{Example: Bayesian Inference, Mixture Distribution}\label{example-bayesian-inference-mixture-distribution}}

MCMC 알고리즘은 \(p(\theta \rvert y ) = c \cdot p(\theta) L(\theta \rvert y)\) 로 표현될 수 있는 베이지안 추론에서 특히 강력하다. 베이지안 추론에서 \(c\)의 계산이 드럽게 어렵다는 것이 이것 이상의 다른 추론전략을 방해하기 때문이다.

보유하는 stationary 분포가 타겟 post인 MCMC에서 생산된 샘플들은 post 모먼트, tail 확률, 그리고 다른 유용한 quantity 계산에 쓰일 수 있다.

independent 체인에서 prior를 proposal 분포(\(g\))로 쓰자. 즉 \(f\)가 post, \(g\)가 prior다. 이런다면

\[
R ({\theta}^{(t)}, \theta^{\ast} ) 
=\dfrac
{\dfrac
{f(\theta^{( \ast )})}
{g(\theta^{( \ast )})}
}
{\dfrac
{f(\theta^{( t )})}
{g(\theta^{( t )})}
}
=\dfrac
{c \; \cdot \; \pi( \theta^{\ast} ) L( \theta^{\ast} \rvert y )}
{c \; \cdot \; \pi( \theta^{(t)} ) L( \theta^{(t)} \rvert y )}
\cdot
\dfrac { \pi (\theta^{(t)} )}{ \pi (\theta^{\ast})}
=\dfrac
{\dfrac
{\pi (\theta^{\ast} \rvert y)}
{\pi (\theta^{\ast})}
}
{\dfrac
{\pi (\theta^(t) \rvert y)}
{\pi (\theta^{(t)})}
}
= \dfrac
{L \left( \theta^{\ast} \rvert y \right)}
{L \left( \theta^{(t)} \rvert y \right)}
\]

\begin{itemize}
\tightlist
\item
  Mixing Properties:

  \begin{itemize}
  \tightlist
  \item
    Good Mixing: 첫번째 그림의 MC는 시작점에서 빠르게 멀어지며 \(\delta\)에 대한 post에서의 모든 서포트에 해당하는 패러미터 space의 모든 부분을 훑으면서 샘플을 뽑아내는게 쉬워보인다.
  \item
    Bad Mixing: 두번째 그림은 starting value에서 멀어지는 것도 느리고, posterior support의 영역을 탐색하는 게 시원찮아보인다.
  \end{itemize}
\item
  Burn-in 이후의 실현값들을 히스토그램으로 만들어서 살펴보면 \(BETA(1,1)\) proposal 덴시티를 쓴 MCMC만이 \(\delta\)의 참값을 잘 모사하는듯.
\end{itemize}

~\\
~\\
~\\
~\\

\hypertarget{random-walk-chains-most-widely-used}{%
\subsection{Random Walk Chains (Most Widely Used)}\label{random-walk-chains-most-widely-used}}

MH method 에 해당.

let \(\textbf {X}^{\ast} = \textbf {X}^{(t)} + \epsilon , \epsilon \sim h(\epsilon )\). 이때 \(h\)는 임의의 덴시티.

\begin{itemize}
\tightlist
\item
  \(h\) 로 자주 선택되는건 \(U, \textbf{N}, \text {Student's } t\).
\end{itemize}

이러면 proposal 덴시티 \(g\)는 어떻게 되는가? \(x^{'} g \sim N( \cdot \rvert x^{(t)}, \sigma^2 )\). 가장 빈번하게 쓰이는게 \(N\)이므로 \(N\)으로 설명. 여기서 \(x^{(t)}\)는 평균으로 사용되었고, \(\sigma^2\)은 \textbf{Jumping Rule}에 해당한다.

\begin{itemize}
\tightlist
\item
  proposal can be

  \begin{itemize}
  \tightlist
  \item
    too diffused: Jumping rule is too big
  \item
    too focused: Jumping rule is too small
  \end{itemize}
\item
  Random Walk

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    generate \(x^{'} g \sim N( \cdot \rvert x^{(t)}, \sigma^2 )\)
  \item
    \(u \sim U(0,1)\).
  \item
    calculate MH ratio: \(r = \dfrac {f(x')}{f(x^{(t)}} \dfrac {g(x' \rightarrow x^{(t)}} {g(x^{(t)} \rightarrow x'} = \dfrac {f(x')}{f(x^{(t)}}\), cause it's \(N\).
  \item
    if \(u<r\), \(x^{(t+1)} = x'\). o.w., \(x^{(t+1)} = x^(t)\).
  \end{enumerate}
\end{itemize}

~\\
~\\

\hypertarget{example-mixture-distribution}{%
\subsubsection{Example: Mixture Distribution}\label{example-mixture-distribution}}

let proposal \(\delta^{(t+1)} = \delta^{(t)} + U(-a, a)\)\footnote{random increment}. 이인즉 몇몇 proposal들은 \([0, 1]\) 이외에서 생산된다.

\begin{itemize}
\tightlist
\item
  note that \(\forall \delta \notin [0,1]\), post is zero,
\item
  Reparameterize the problem by letting \(U = \log{\dfrac {\delta}{1-\delta}}\)(logit). 왜? Probabilty Space is bounded: \(0 \le P(\cdot) \le 1\).
\end{itemize}

Run a random walk chain on \(U\) by adding \(U(-b,b)\).

Two ways of Reparamaterization:

\begin{itemize}
\tightlist
\item
  Run MCMC in \(\delta\)-space. \(u\) 값을 다시 T해와서 \(\delta\)-space에서 돌림.
\item
  Run MCMC in \(u\)-space. \(u\)-space에서 돌리고 마지막에 모델 샘플들을 전부 \(\delta\)-space로 환원.
\end{itemize}

\hypertarget{delta-spaceuxc5d0uxc11c-uxb3ccuxb9acuxb294-uxbc29uxbc95}{%
\paragraph{\texorpdfstring{\(\delta\)-space에서 돌리는 방법}{\textbackslash delta-space에서 돌리는 방법}}\label{delta-spaceuxc5d0uxc11c-uxb3ccuxb9acuxb294-uxbc29uxbc95}}

개략적으로는 \(T^{-1}: \delta' \leftarrow u' \sim g( \cdot \rvert u^{(t)})\) 와 같은 형을 띤다. 조건부 proposal \(g\)에서 생산된 u를 하나하나마다 \(\delta\)로 역변환해서 그 하나하나의 역변환 값으로 MH 알고리즘을 돌린다. proposal 덴시티 \(g( \cdot \rvert u^{(t)} )\) 는 \(\delta\)-space에서의 proposal 덴시티로 변환되어야 한다. 이경우 MH ratio는

\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} )
=\dfrac
{\dfrac
{f(\delta^{\ast})}
{g \left( logit(\delta^{\ast}) \rvert logit(\delta^{(t)}) \right) \cdot \left| J(\delta^{\ast})\right|}
}
{\dfrac
{f(\delta^{(t)})}
{g \left( logit(\delta^{(t)})|logit(\delta^{\ast}) \right) \cdot \left| J(\delta^{(t)})\right|}
}
\]

\$\lvert J(\delta\^{}\{(t)\}) \rvert \$ 는 \$T: \delta \rightarrow u \$에 대한 \(J\)를 \(\delta^{(t)}\)에서 측정한 값. 주의해야 할 것이 해당 방법론에서는 \(T\)한 value를 사용하였으므로 \(g\)에 대한 \(J\)를 구해야 한다.

\hypertarget{u-spaceuxc5d0uxc11c-uxb3ccuxb9acuxb294-uxbc29uxbc95}{%
\paragraph{\texorpdfstring{\(u\)-space에서 돌리는 방법}{u-space에서 돌리는 방법}}\label{u-spaceuxc5d0uxc11c-uxb3ccuxb9acuxb294-uxbc29uxbc95}}

이 상황에서 쓰이는 proposal은 \(\dfrac {g(u^{(t)} \rightarrow u')} {g(u' \rightarrow u^{(t)})}\). \(\delta\)에 대한 타겟 덴시티는 \(u\)에 대한 덴시티로 변형되어야 한다. 이때 \(\delta = logit^{-1}(U) = \dfrac{\exp(U)}{1+\exp(U)}\) 였으므로, \(U^{\ast} = u^{\ast}\) 로 두었을 때 생산되는 MH ratio는

\$\$
R (\textbf {x}\^{}\{(t)\}, \textbf X\^{}\{\ast\} )

=\dfrac 
\{\dfrac
\{f(logit\^{}\{-1\} \{(u\^{}\{\ast\})\})\}
\{g \left(u\textsuperscript{\{\ast\}\textbar u}\{(t)\}) \right) * \left\textbar{} J(u\^{}\{(t)\})\right\textbar\}
\}
\{\dfrac
\{f(logit\^{}\{-1\} \{(u\^{}\{(t)\})\})\}
\{g \left(u\textsuperscript{\{(t)\}\textbar u}\{(\ast)\}) \right) * \left\textbar{} J(u\^{}\{\ast\})\right\textbar\}
\}
\$\$

우리가 transform value를 사용한데가 \(f\) 덴시티이므로 \(f\) 덴시티에 대한 야코비안을 붙여줘야 하는데 그 덴시티에 대한 야코비안은 \(u\)에 대한 야코비안이므로 쓰인 야코비안은 위와 같다. 이때 \(\lvert J(u^{\ast})\ \rvert = \dfrac {1} {\lvert J(\delta^{\ast}) \rvert}\) 이므로 위와 아래에서 만들어지는 \textbf{MH ratio는 같다.} 따라서 두 관점은 equivalent한 체인을 생산한다.

\begin{itemize}
\tightlist
\item
  Sample paths for \(\delta\) from RW chains in Ex. 7.3, run in \(u\)-space iwth b=1 (top) and b=0.01 (bottom).
\end{itemize}

\hypertarget{example-autocorrelation-plot-acf}{%
\subsubsection{Example: Autocorrelation Plot (ACF)}\label{example-autocorrelation-plot-acf}}

배우지 않은 MCMC 방법론 중 하나.

reminder. thinning을 하더라도 거의 줄지 않아서 MCMC 샘플로서 거의 가치가 없는 케이스가 존재한다.

no

~\\
~\\
~\\
~\\

\hypertarget{basic-gibbs-sampler}{%
\subsection{Basic Gibbs Sampler}\label{basic-gibbs-sampler}}

\begin{itemize}
\tightlist
\item
  need to derive the conditional density for all, 모든 joint density에 대해 coefficient를 1개씩 제한 상황의 \textbf{모든 conditional density를 구한 후} GS 제작이 가능

  \begin{itemize}
  \tightlist
  \item
    if conditional densities are not available, we can use MH algorithm when updating \(x_i\) -\textgreater{} 이런식으로 접근할 경우 이를 MH-within-Gibbs라고 부른다.

    \begin{itemize}
    \tightlist
    \item
      1PL IRT HW
    \end{itemize}
  \end{itemize}
\end{itemize}

let \(\textbf {X} = (X_1 , \cdots, X_p )^{'}\) , \(\textbf {X}_{-i} = (X_1 , \cdots, X_{i-1}, X_{i+1}, \cdots, X_p )^{'}\).

시작값 \$\textbf {x}\^{}\{(0)\} \$를 잡고, \(t=0\)으로 설정한다. 이후 각각을 \(t+1\) 단계의 시퀀스의 구성요소 각각을 \(X_i^{(t+1)} \vert \; \; \cdot \sim f \left( x_1 \rvert x_2^{(t)}, \cdots, x_p^{(t)} \right)\) 에 따라서 생산한다.

Gibbs Sampler의 stationary 분포는 \(f\).

\(X_i^{(t)}\)의 limiting 마지널 분포는 \(i\)번째 coordinate에 따른 타겟분포의 단변량 마지널化와 같다.

MH 알고리즘과 마찬가지로, 우리는 \(X\)의 임의의 함수 \(g(X)\)에 대해 \(E \left[ g(X) \right]\) 를 추정하기 위해 체인에서의 실현값을 사용할 수 있다.

~\\
~\\

\hypertarget{example-fur-seal-pup-capture-recapture-model}{%
\subsubsection{Example: Fur Seal Pup Capture-Recapture Model}\label{example-fur-seal-pup-capture-recapture-model}}

1800년대 후반 (by the late 1800s) 뉴질랜드 물범은 거의 전멸했다가 요즘 들어 폭증함 (abundance). 물범의 고름 숫자를 capture-recapture 사용해서 해보자.

사이즈 불명인 모집단의 크기 파악 위에 반복 연구 실행. 각 연구마다 \textbf{\emph{포획}}었던 개체는 표식 새기고 풀어줌. 후속 연구에서 또 포획되면 \textbf{\emph{재포획}}으로 표기. 높은 재포획 비율은 참 모집단 사이즈값이 포획되었던 개체들의 총량을 크게 넘지 않을 것임을 암시.

\begin{itemize}
\tightlist
\item
  \(N\): 불명인 모집단 사이즈. \(l\)회의 조사 통해 얻어진 각 회의 총 \textbf{\emph{포획}} 숫자는 각각 \(c=(c_1, \cdots, c_l)\)로 저장. 모집단 사이즈는 샘플링 동안에는 변동 없다(죽음, 출생, 이주 없음 inconsequential)고 가정한다.
\item
  \(r\): 연구 동안에 포획되었던 이질 동물들의 총 숫자.
\item
  각 연구 시도에서 상응하는 구분되고 알려지지 않은 \textbf{\emph{포획 확률}}은 \(\alpha = (\alpha_1 , \cdots, \alpha_l )\). 이 모델은 모든 동물들이 각 1회의 포획 발생에서 잡힐 가능성 자체는 각각의 동물에 대해서 동일하나, 이 被포획 확률은 시간이 지남에 따라 변할 수 있다는 것을 말함.
\end{itemize}

이 모델의 likelihood는

\[
L \left( N, \alpha \rvert c, r \right) 
\propto 
\dfrac {N!}{(n-r)!} \prod_{=1}^{l} \alpha_i^{c_i} 
\]
Fur Seal Data for Seven Studies in One Season on the Otago Peninsula가 주어졌으며, prior은 \(\pi(N) \propto 1\), \(\pi (\alpha_i ) = BETA(\theta_1 , \theta_2)\) 이다. 계산하라.

해당 모델의 conditional posterior distribution에서 시뮬레이트하는 것으로 Gibbs Sampler를 제작할 수 있다.

\[
N^{(t+1)}-r \rvert \cdot \sim Negative Binomial \left( r+1, 1- \prod_{i=1}^7 \left( 1- \alpha_i^{(t)} \right) \right)
\]

\[
\alpha_i^{(t+1)} \rvert \cdot \sim BETA \left( c_i + \dfrac{1}{2}, N^{(t+1)} - c_i + \dfrac{1}{2} \right)
\]

for \(i= 1, \cdots, 7\), \(r = \sum_{i=1}^7 {m_i} =84\). 이는 unique fur seals were observed during the sampling period.

\begin{itemize}
\tightlist
\item
  Split boxplots of \(\bar {\alpha}^{(t)}\) against \$N\^{}\{(t)\} \$ for the seal pup example.
\item
  Estimated marginal posterior probabilities for \(N\) for the seal pup example.
\end{itemize}

~\\
~\\

\hypertarget{mh-within-gibbs-sampler}{%
\subsubsection{MH-within-Gibbs Sampler}\label{mh-within-gibbs-sampler}}

\textbf{실제 implementation에 무지막지 유용하다.} 이는 각각의 사이클을 GS의 사이클로 만들어놓고, conditional density는 MH 알고리즘으로 획득하는 것이다. \textbf{Gibbs Sampler는 MH Sampler의 특별한 경우라고 볼 수 있다.} MH 알고리즘의 proposal 분포를 시간에 따라 변화하도록 함으로써, GS와 MH 알고리즘 사이에 연결고리가 생긴다. 각 Gibbs 사이클은 \(p\) 개의 MH 스텝으로 구성되어 있다. 사이클 내에서의 \(i\)번째 Gibbs 스텝은, 체인의 현 상태 \((x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\) 가 주어졌을 때, 효과적으로 후보 벡터 \((x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, {\underline{X_i^{*}}}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\) 를 생산한다. 밑줄 차이점에 주목.

\(i\)번째 단변량 Gibbs 업데이트는 이하와 같이 MH 스텝 drawing으로 볼 수 있다.

\[
{\underline{X_i^{*}}} \rvert  (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})}) \sim g_i \left( \cdot \rvert (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)},  x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})}) \right)
\]

where

\[
g_i \left( \cdot \rvert (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)},  x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\right) 
= \left\{
\begin{array}{@{}lr@{}}
f(x_i^{*} \rvert x_i^{(t)} ), & \text{if } \; \; \; X_i^{*} = x_i^{(t)} \\
0 &  o.w.
\end{array}\right\}
\]

이 경우, MH ratio는 1과 같아진다. 즉슨 모든 후보들은 언제나 accept 된다. 즉슨 GS는 MH 알고리즘에서 acceptance ratio가 항상 1인 경우에 해당한다. 따라서 \textbf{conditional density}을 구할 수만 있으면 GS를 사용하는게 좋다. 샘플을 버릴 필요가 없고, 버려지는 샘플이 없기 때문.

~\\
~\\

\hypertarget{update-ordering}{%
\subsubsection{Update Ordering}\label{update-ordering}}

\textbf{Random Scan Gibbs Sampling}: 기본 GS에서 \$ \textbf X \$ 에 가해지는 업데이트의 순서는 \textbf{\emph{한 사이클에서 다음 사이클로 넘어갈 때마다 바뀔 수 있다. 패러미터들이 높은 수준에서 상호연관되어있을 경우, 각 사이클을 랜덤하게 순서배치하는 것은 효과적일 수 있다.\footnote{The ordering of updates made to the components of X in the basic Gibbs sampler can change from one cycle to the next. Random ordering each cycle can be effective when parameters are highly correlated. In practice without specialized knowledge for a particular model, we recommend trying both deterministic and random scan Gibbs sampling when parameters are highly correlated from one iterations to the next.}}} 특정 모델에 대한 전문화된 지식이 없다면, 한 이터레이션에서 다음으로 넘어갈 때 패러미터끼리 높이 상호연관되어있다면 deterministic 한 방법과 RSGS 양쪽 모두를 시도해보는 것이 권장된다.

\hypertarget{blocking}{%
\subsubsection{Blocking}\label{blocking}}

with \(p=4\), e.g., 각 사이클을 다음 절차를 따르면서 업데이트:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X_1^{(t+1)}\rvert \cdot \sim f \left(x_1 \rvert x_2^{(t)}, x_3^{(t)}, x_4^{(t)} \right)\).
\item
  \(X_2^{(t+1)}, X_3^{(t+1)}\rvert \cdot \sim f \left(x_2, x_3 \rvert x_1^{(t+1)}, x_4^{(t)} \right)\).
\item
  \(X_4^{(t+1)}\rvert \cdot \sim f \left(x_4 \rvert x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)} \right)\).
\end{enumerate}

\textbf{Blocing}은 \(X\)의 구성요소들이 서로 상관관계가 있을 때 \textbf{\emph{\(X_i\) 내부가 상관이라는 건가, 아니면 \(X_t, X_{t+1}\) 이 상관이라는 건가?}} 유용함. 해당 알고리즘을 통해 더욱 상관된 구성요소끼리는 한 블럭 안에서 샘플링됨.

\hypertarget{hybrid-gibbs-sampling}{%
\subsubsection{Hybrid Gibbs Sampling}\label{hybrid-gibbs-sampling}}

하나 이상의 \(X\)에 대한 조건부 분포는 대부분 closed form으로 만들 수 없음. 깁스 샘플러의 주어진 스텝에서, 적절한 조건부 분포에서 샘플링하기 위해 MH 알고리즘이 쓰인다면 \textbf{Hybrid MCMC} 알고리즘이 완성됨.

with \(p=5\), e.g., 하이브리드 MCMC 알고리즘은 다음 절차를 따르면서 업데이트:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Update \(X_1^{(t+1)} \rvert \left( x_2^{(t)}, x_3^{(t)}, x_4^{(t)}, x_5^{(t)} \right)\) with 깁스 스텝.
\item
  Update \left( x\_2\^{}\{(t+1)\}, x\_3\^{}\{(t+1)\} \right) \$ \rvert \left( x\_1\^{}\{(t+1)\}, x\_4\^{}\{(t)\}, x\_5\^{}\{(t)\} \right)\$ with MH 스텝.
\item
  Update \(X_4^{(t+1)} \rvert \left( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_5^{(t)} \right)\) with 랜덤워크.
\item
  Update \(X_5^{(t+1)} \rvert \left( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_4^{(t+1)} \right)\) with 깁스 스텝.
\end{enumerate}

\hypertarget{example-fur-seal-pup-capture-recapture-study}{%
\paragraph{Example: Fur Seal Pup Capture-Recapture Study}\label{example-fur-seal-pup-capture-recapture-study}}

\hypertarget{implementation}{%
\subsection{Implementation}\label{implementation}}

MCMC의 목적은 타겟분포 \(f\)의 특징들을 알아내는 것. 모든 MCMC는 정답인 limiting 정적분포를 가지고 있음. 실전에는 체인을 얼마나 충분히 오래 돌릴지를 결정하는 게 중요함. \(X\)의 dimensionality(차원)이 높다면 수렴이 엄청 느려서 엄청 긴 run을 요할 수도 있음. 이하의 요건들을 생각해서 long run을 결정해야 함.

\begin{itemize}
\tightlist
\item
  Has the chain run long enough?
\item
  Is the first portion of the chain highly influenced by the starting value?
\item
  Should the chain be run from several different starting values?
\item
  Has the chain traversed all portions of the region of support of \(g\)?
\item
  Are the sampled values approximate draws from \(f\)?
\item
  How shall the chain output be used to produce estimates and assess their precision?
\end{itemize}

\hypertarget{ensuring-good-mixing-and-convergence}{%
\subsubsection{Ensuring Good Mixing and Convergence}\label{ensuring-good-mixing-and-convergence}}

MCMC 알고리즘이 대상 문제에 얼마나 쓸만한 정보를 주는지 고민해야 함. 이는 곧

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  체인이 얼마나 빠르게 체인의 starting value를 까먹는가
\item
  얼마나 빠르게 체인이 타겟분포 \(f\)의 모든 서포트를 훑는가
\item
  체인이 그것의 정적분포에 근사적으로나마 닿는가를 고민.
\item
  There is substantial overlap between the goals of diagnosing convergence to the stationary distribution and investigating the mixing properties of the chain.
\end{enumerate}

\hypertarget{simple-graphical-diagnostics}{%
\subsubsection{Simple Graphical Diagnostics}\label{simple-graphical-diagnostics}}

트레이스 플롯 (sample path)은 이터레이션 횟수 \(t\)와 \(X^{(t)}\)의 실현값 간의 플롯이다.

\begin{itemize}
\tightlist
\item
  체인의 mixing이 구리면 이는 장기간의 이터레이션동안 동일값 근처에서 머무르게 됨.
\item
  체인의 mixing이 좋으면 시작값에서 빠르게 떠나서 \(f\)의 서포트에 해당하는 영역을 열심히 훑음.
\end{itemize}

\textbf{autocorrelation 플롯}은 \(X^{(t)}\)의 시퀀스에서 다른 \textbf{이터레이션 래그}에서의 상관관계를 서술한다. 래그 \(i\)에서의 autocorrelation은 \(i\) 이터레이션만큼 떨어진 이터레이트 간의 상관관계이다. 구린 mixing 프로퍼티를 가지는 체인은 이터레이션 간의 래그가 증가하더라도 autocorrelation의 부식(decay)이 느림.

MCMC 체인에서의 첫 \(D\) 개의 값은 보통 \textbf{burn-in period}라고 해서 버려짐. 체인의 시작점에 대한 의존이 강하게 남아있을지도 모르기 때문. 어느정도가 적절한 번인 피리어드인가는 \textbf{Gelman-Rubin diagnostics}에 의해 결정된다. 결정된 번인 피리어드가 제대로 된 값을 못내면 \(D\)가 늘어나던가 \(L\)이 늘어나던가 둘다 늘리던가 해야함.
- Motivated by an Analysis of Variance
- 사슬간 분산 (between-chain variance)이 사슬내 분산 (within-chain variance)보다 유의하게 크면 번인 피리어드나 MCMC 길이가 늘어나야 함
- Difficulties
- multimodal \(f\)에서 적절한 스타팅 밸류를 찾는건 어렵고, 체인이 로컬 region이나 mode에서 갇힐수 있음
- 이의 단일차원성 (uni-dimensionality) 때문에 타겟분포 \(f\)가 멀티디멘션이면 타겟분포의 수렴에 대한 정보에 대한 잘못된 직관을 줘버릴 수 있음

proposal \(g\) 선택할 때 고려해야할 요소는? mixing은 proposal 분포 \(g\)의 특질에 큰 영향을 받으며 특히 이의 스프레드(spread)에 큰 영향을 받음. 타겟분포 \(f\)와 \(g\)간의 닮음에 있어서, 프로포절 \(g\)의 tail behavior의 닮음은 high density의 닮음보다 훨씬 중요함. \(f/g\)가 bounded 라면, MC의 정적분포로의 수렴은 \textbf{대체로(overall)} 빠름. 실전에선 정보를 줄 수 있는 이터레이티브 프로세스를 통해 proposal 분포의 분산이 택해질 수 있음. (In practice, the variance of the proposal distribution can be selected through an informal iterative process.) 20\%\textasciitilde50\% 사이의 acceptance rate가 선호되어야 함.

\begin{itemize}
\tightlist
\item
  \textbf{Reparameterization}
\end{itemize}

모델의 reparameterization은 MCMC 알고리즘의 mixing behavior에 상당한 기능향상을 가져올 수 있음. reparameterization은 dependence를 낮추기 위해 가장 우선되어야 할 전략 중 하나임. 서로 다른 모델들은 서로 다른 reparameterization 전략을 적용해야 함. reparameterization 접근법은 보통 특정 모델에 대한 원오프로서 채택되므로 일반화된 조언을 하기에는 어려운 부분이 있음.

\begin{itemize}
\tightlist
\item
  \textbf{Comparing Chains}
\end{itemize}

MCMC 실현값이 크게 상관관계있다면, MCMC의 각 이터레이션에서 주어지는 정보는 run length에서 주어지는 정보 대비 보잘것 없다(will be less than suggested by the run length). 여기서 reduced information은 \textbf{effective sample size}라고 칭해지는 더 작은 iid 샘플에 담겨있는 정보와 동등하다. 여기서 샘플의 총 숫자와 effective sample size 사이의 차이는 잃게 된 효율을 의미한다. 관심있는 변량을 확인하기 위해 우리가 MC 체인에서의 correlated 샘플들을 사용했을 때 잃게된 효율.

\begin{itemize}
\tightlist
\item
  \textbf{Number of Chains}
\end{itemize}

모델 진단에 있어서 가장 진단을 어렵게 하는 부분은 체인이 타겟분포 \(f\)의 1개 이상의 모드에 걸리냐 안걸리냐 하는 부분. 이 경우 모든 수렴진단은 체인이 수렴하긴 한다는 결론을 내리게 된다. 정작 체인이 타겟분포 \(f\)의 모든 특성을 나타내지 못하는데도. 그래서 여러번 돌려보게 되는 것. 최소한 그 여러번의 run들 중 체인 1개에서라도 타겟분포 \(f\)의 모든 흥미로운 특질들이 드러났으면 하니까. 이러한 특질을을 찾아내는데 실패한 개별 체인들의 경우에는 mixing을 더 좋게 만들기 위해 체인 길이가 늘어나거나 문제가 reparameterize 되어야 함.

\hypertarget{advanced-mcmc-wk08}{%
\section{Advanced MCMC (wk08)}\label{advanced-mcmc-wk08}}

\textbf{1, 3, 5번이 자주 사용됨}
2, 3, 4의 목적은 proposal density 개선

1번은 missing data handling

5번은 variable selection

기본적으로 \(f(x) = c \psi (x) = c \exp \left( -\dfrac{U(x)}{t} \right)\)의 개형을 따름.

\hypertarget{data-augmentation}{%
\subsection{1. Data Augmentation}\label{data-augmentation}}

\begin{itemize}
\tightlist
\item
  Missing Pattern
\end{itemize}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}@{}}
\toprule
& MCAR & MAR & NMAR \\
\midrule
\endhead
in missingness in missing on a variable & No patterns & \textbf{can be predicted} by \textbf{other} variables & \\
Missing values related to variable? & not to any & other variables & the variable itself \\
& complete data considered as a random subsample from the original target sample & & whether data is NMAR is a theoretical and conceptual considerate \\
Assumption power & 3 & 2 & 1 \\
missing을 의식할 필요가 있는 상황인가? & No.missing 자체를 무시 (ignore). & Yes.predict missing by other variable & Yes.impute with seperate model \\
\bottomrule
\end{longtable}

\textbf{bayesian 분석에서 Handling Missing Data에 자주 사용된다.}

Data Augmentation(DA) 알고리즘은, 불완전 데이터에 대한 bayesian 분석으로 설명될 수 있다.

\(X_{obs}\) \textbar{} observed data \textbar{}\\
\(X_{mis}\) \textbar{} missing data \textbar{}\\
\$X\_\{com\}= \left(X\_\{obs\},X\_\{mis\} \right) \$ \textbar{} complete data \textbar{}

assume complete 데이터 모델 \(X_{com} = (X_{obs}, X_{mis}) \sim g \left( X_{obs}, X_{mis} \rvert \theta \right)\), where 패러미터 \$\theta \in \Theta \subseteq \mathbb{R}\^{}d, d \in \mathbb{Z}\^{}+ \$.

여기서 목적은 패러미터 \(\theta\)에 대한 prior 분포 \(\pi (\theta)\)와 함께 bayesian 추론을 만드는 것. 이는 곧 \(g \left( X_{obs}, X_{mis} \rvert \theta \right) \ast \pi(\theta)\) 를 말한다.

Multiple Imputation \textbar{} 데이터 impute, 그 impute한걸로 패러미터 업데이트, 다시 impute, \ldots. 여기선 impute 셋을 여러개를 만들어놓고, 그걸 패러미터를 계산을 해서 패러미터 분포를 갖고 inference. \textbar{}\\
Data Augmentation \textbar{} interatively하게 패러미터 impute, 업데이트, impute, 업데이트, \ldots. \textbar{}

\begin{itemize}
\tightlist
\item
  proceeds: MCMC로 DA
\end{itemize}

let observed-data model \(f(X_{obs} \rvert \theta)\). 이는 아래와 같이 joint pdf에서 마지널을 뽑아냄으로써 (integrate) 단독 pdf를 획득하는 것이 가능함.

MCMC 방법론을 사용해 \(\theta\)에 대한 Bayesian 추론을 진행하면 true or observed-data post를 샘플링하거나, 혹은 더욱 일반적으로는 \(\theta\)와 \(X_{mis}\)의 joint 분포를 샘플링할 것을 요구한다. 이의 각각을 수식으로 나타내면 다음과 같다.

\$
\begin{alignat}{4}

& &&f(X_{obs} \rvert \theta) && &&= \int_{\mathbb{X}_{mis}} g(X_{obs}, X_{mis} \rvert \theta) \; dX_{mis}, \; \; \; && \theta \in \Theta \\ 

\\

\pi (\theta \lvert X_{obs}) &\propto \; &&f (X_{obs} \lvert \theta) && \pi(\theta), && \; \; \; \; \; \; \; && \theta \in \Theta \tag{1}\\

\\

\pi (\theta, X_{mis} \lvert X_{obs}) &\propto \; &&g (X_{obs}, X_{mis} \lvert \theta) && \pi(\theta), && \; \; \; \; \; \; \; && \theta \in \Theta \tag{2}\\

\end{alignat}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  integrate하여 획득한 위의 likelihood \(f(X_{obs} \rvert \theta)\)에 post를 곱하여 direct하게 업데이트 하는 1번 방법
\item
  missing을 하나의 unknown 패러미터로 두고, 이 missing 업데이트 한 다음에 missing까지 포함하여 \(\theta\)를 inference하고, 그 후에 다시 missing을 업데이트 하는 방법. 1번에서는 마지널化한 pdf를 사용했고, 2번에서는 complete의 pdf를 통채로 사용했다. 1번에서는 마지널 시켜서 missing의 영향력을 삭제했다는 것을 발견할 수 있어야 한다.
\end{enumerate}

의 2가지 방법을 취하는 것이 가능하다.

let \(h( X_{mis} \lvert \theta, X_{obs})\)는 \(X_{mis}, X_{obs}\)의 conditional 분포. 이때, 이 분포와

\$

\pi (\theta \lvert X\_\{obs\}, X\_\{mis\}) \propto g (X\_\{mis\}, X\_\{obs\} \rvert \theta) \pi(\theta) \tag{Full Posterior}

\$

상기의 분포 2개가 양쪽 모두 샘플링이 간단하다고 가정하자.

이 두 조건부 분포 2개에 기반한 2단계 GS로 이를 해결하고자 하는 것은 당연한 귀결이다. 이를 \textbf{Data Augmentation 알고리즘 (DA)}라 칭한다. 이는 이하와 같이 설명될 수 있다.

take \(\theta^{(0)} \in \Theta\), and iterate for \(t=1,2, \cdots\).
1. Imputation-step: generate \(X_{mis}^{(t)} \sim f_{mis}(X_{mis} \rvert \theta^{(t-1)}, X_{obs})\). (이는 정식적인 likelihood가 아니라 missing variable과 observed variable 간의 관계를 의미하는 것). 해당 스텝에서 missing을 대체. 다른 조건들 (패러미터, obs) 들이 주어졌을 때의 mis의 조건부분포를 구하여 이를 기반으로 mis를 imputation.
2. Parameter update-step: generate \(\theta^{(t)} \sim \pi (\theta \lvert X_{obs}, X_{mis} )\). 해당 스텝에서 패러미터를 갱신. 위에서 채운 mis와 obs를 합쳐 com 데이터로 삼고 이를 토대로 패러미터 추정한다.

As a two-step GS, DA creates two interleaving Markov Chain:

\$
\begin{align*}

\{ \theta(t) &: t=1,2,\cdots \} \\
\{ X_{mis}^{(t)} &: t=1,2,\cdots \}

\end{align*}
\$

\begin{quote}
Example: Multivariate Normal Distribution
\end{quote}

\hypertarget{hit-and-run-algorithm}{%
\subsection{2. Hit-and-Run Algorithm}\label{hit-and-run-algorithm}}

\emph{for improving the inefficiency of the RW}

이를 위해 proposal 분포에 대한 수정이 요구된다.

이는 RW에 추가적인 요소를 넣어 변형하는 것인데, RW의 거리와 방향을 거리에 대응하는 pdf, 방향에 대응하는 pdf를 각각 만들어 거기서 랜덤하게 생산하는 것이다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  draw below two parameters, and compute an MH acceptance probability \(\alpha(x,y)\), where \(x = x^{(t)} = X^{(t)}\).

  \begin{itemize}
  \tightlist
  \item
    direction \(d \sim g(d) \; \; \;(d \in \mathbb{O})\).
  \item
    distance \(\lambda \sim I(\lambda \rvert d,x )\) over \(\mathcal{X}_{x,d}\).
  \end{itemize}
\item
  \$ X\^{}\{(t+1)\} =

  \begin{cases} x^{(t)}+ \lambda d, & \text{if } \; U \le \alpha(x,y) = \dfrac{f(x')}{f(x^{(t)})}\dfrac{g(x' -> x^{(t)})}{g(x^{(t)}-> x' ))}\\ x^{(t)}, & o.w.\\ \end{cases}

  \$.
\end{enumerate}

이때, \(g(d)\)에 대한 가장 흔한 choice는 \(\mathbb{O}\)에 대한 \(U\). 이외에 \(g(\cdot \rvert x, d)\), \(\alpha(x,y)\)에 대한 가장 흔한 choice도 논해졌던 바가 있다.

이는 특히 sharply constrained 패러미터 space (\(\Theta\)) 와 함께하는 문제에 효과적이다.
- Wrapped Normal Distribution

\hypertarget{metropolis-adjusted-langevin-algorithm}{%
\subsection{3. Metropolis-Adjusted Langevin Algorithm}\label{metropolis-adjusted-langevin-algorithm}}

\textbf{how do we propose a new value? proposal improvement에 자주 사용된다. 또한, Hamiltonian MC와 아주 밀접한 관련이 있다.}

Langevin 방정식에 기반하여 생성된 알고리즘. 해당 알고리즘은 기본적으로 \(f\)를 정적 (stationary) 분포로서 내버려두게 된다.

\textbf{gradient flow에 의해 발생하면 얘도 로컬트랩 가능성 있는거 아님?}

\$

dX\_t = dB\_t + \dfrac {1}{2} \bigtriangledown    \log f(X\_t )

\$

이때 \(B_t\)는 표준 브라운 운동.

이의 실적용은 Langevin diffusion process를 RW-like Transition으로 대체한 discretion step을 포함하는 아래의 식으로 이루어진다.

\$

x\^{}\{(t+1)\} = x\^{}\{(t)\} + \dfrac {\sigma^2}{2} \bigtriangledown \log f(X\^{}\{(t)\} ) + \sigma \epsilon\_t, ; ; ; ; ; ; \epsilon\_t \sim N\_d (0, I\_d)

\$

이때 \(\sigma\)는 step size of discretization.

하지만 discretized 된 프로세스는 transient (일시적, 해당 성질이 이후에도 이어질 것이라 장담 불가) 할 우려가 있으며 \(f\)에 대해 더이상 reversible 하지 않음. 이 negative behavior (악영향)을 보정 (correct)하기 위해서 discretization step을 MH acceptance-rejection rule에 기반하여 완화하는 것이 제기됨. 이인즉슨 실적용되는 수식을 conventional MH 제안 (proposal) 분포로서 취급하자는 것.

\begin{itemize}
\tightlist
\item
  새로운 state: Langevin Dynamics 사용해서 제안
\item
  새로운 state의 accept 여부: MH 알고리즘 사용해서 평가
\end{itemize}

따라서 Langevin 알고리즘의 1회의 이터레이션은:
1. 새로운 state \(x^\ast = x^{(t)} + \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^{(t)}) + \sigma \epsilon_t\). 이때 \(\sigma\)는 user-specified 패러미터. For limited classes of target distributions, the optimal acceptance rate for this algorithm can be shown to be 0.574.
2. MH ra tio \(r = \dfrac {f(x^\ast)}{f(x^{(t)})} \ast \dfrac {\exp \left\{ - \dfrac {1} {2\sigma^2} \left[ x^{(t)} - x^\ast - \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^\ast) \right]^2 \right\}}{\exp \left\{ - \dfrac {1} {2\sigma^2} \left[ x^{\ast} - x^{(t)} - \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^{(t)}) \right]^2 \right\}}\).
3. set \(x^{(t+1)} = x^\ast\) with probability \(\min (1, r)\), 남는 확률로는 \(x^{(t+1)} = x^{(t)}\)

\begin{itemize}
\tightlist
\item
  Advantages

  \begin{itemize}
  \tightlist
  \item
    gradient flow 방법론에 따라 높은 density region으로 향하도록 RW를 충동질함. RW 대비 mixing이나 convergence 관점에서 효과적.
  \item
    고차원 분포에서 유리
  \end{itemize}
\item
  Disadvantages

  \begin{itemize}
  \tightlist
  \item
    gradient 계산에 자원 다쳐먹는 경우 있음
  \item
    multi-mode 관장 불가
  \end{itemize}
\end{itemize}

이때 with probability \(\min (1, r)\)라는 것은 \(u < min(1,r), \; \; \; \; \; u \sim U(0,1)\)과 동치라는 것을 알아두자. 앞으로는 모두 이렇게 서술할 것.

\hypertarget{multiple-try-metropolis-algorithm}{%
\subsection{4. Multiple-Try Metropolis Algorithm}\label{multiple-try-metropolis-algorithm}}

\textbf{H\&R, MALA, MTMA + HMC는 모두 proposal의 성능을 높이기 위함}

MH Transition rule에 기반한 MC에서, 이의 효율성은 제안 (proposal) 분포에 크게 의존한다.

여러번의 이동을 거치면 과거의 실값과는 멀어지기 때문에 independent하기 때문에 어떤 측면에선 효율적이지만 acceptance 측면에선 떨어짐.

let \(\lambda(x,y)\) \textbf{non-negative symmetric function}. \(q(y \rvert x) >0\) 이면 항상 \(\lambda(x,y)>0\)임을 가정. define \(w(x,y)=f(x) \ast q(y \rvert x) \ast \lambda(x,y)\).

At here, when \(q(y \rvert x)\) is symmetric, for example, one can choose \(\lambda(x,y) = \dfrac {1} {q(y \rvert x)}\), and then \(w(x, y) = f(x)\). 이 경우, MTM 알고리즘은 orientational bias MC 알고리즘으로 축소되는데, 이는 molecular simulation에서 사용되는 방법론 중 하나다. See Liu, Liang and Wong (2000) for the details.
위의 수식에서 proposal인 \(q(y \vert x)\)에 symmetric이라는 조건을 붙이자. 그러면 \(q(y \vert x) = {1}{\lambda(x,y)}\)라는 상황을 가정하는 것이 가능하다.

\begin{itemize}
\tightlist
\item
  Current state is at \$\pmb x \$. Proceeds:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    draw \(y_1 , \cdots, y_k \sim T(\pmb x \rightarrow \pmb y)\), \(T\) is proposal.
  \item
    select \(\pmb y = y_j\) with probability \(\propto w(y_j , \pmb x)\).
  \item
    draw \(x_1^\ast, \cdots, x_{k-1}^\ast\) from \(T(y \rightarrow x)\). let \(x_k^\ast = \pmb x\).

    \begin{itemize}
    \tightlist
    \item
      이때 ** 3번에서 원본 데이터로 돌아가는 프로세스가 포함된 이유는 MHMCMC 알고리즘에서는 얼마만큼 original proposal로 잘 돌아갈 수 있는지를 항상 고려해주어야 함. for reversability. **
    \end{itemize}
  \item
    accept proposed \(\pmb y\) with probability \(p = \min \left\{ 1, \dfrac{w(y_1, \pmb x) + \cdots + w(y_k, \pmb x)} {w(x_1^\ast, \pmb y) + \cdots + w(x_k^\ast, \pmb y)} \right \} \tag{1}\).

    \begin{itemize}
    \tightlist
    \item
      (1)의 확률 자체가 결정된 메커니즘은 고급확률론이 필요하므로 이해 불가능함
    \end{itemize}
  \end{enumerate}
\end{itemize}

current state \(\pmb x\)에서, \(\pmb x \rightarrow y_1\rightarrow y_2 \rightarrow \cdots \rightarrow y_k\)로 가도록 한다. 이때 각 y에 대해 weight값이 존재.

\hypertarget{reversible-jump-mcmc-algorithm}{%
\subsection{5. Reversible Jump MCMC Algorithm}\label{reversible-jump-mcmc-algorithm}}

\textbf{number of variable이 작을 때, 베이지안 Variable Selection에 자주 사용됨}

\hypertarget{bayesian-variable-dimension-model}{%
\paragraph{Bayesian Variable Dimension Model}\label{bayesian-variable-dimension-model}}

A Bayesian variable dimension model is defined as a collection of models

\$

\mathcal{M}\_k = \left\{ f(\cdot \lvert \theta\_k ) ; ; ; \theta\_k \in \Theta\_k \right\}, ; ; ; ; ; k=1, \cdots, K

\$

with a collection of priors \(\pi_k (\theta_k)\) on the 패러미터 of these models. 이는 곧 model의 변화에 따라 각각의 model들 또한 다른 prior를 갖는다는 이야기이다. and a prior distribution \(\rho_k, \; \; \; k=1, \cdots, K\) on the indices of these models.

※ Note: 당연히 각각의 model space \(\Theta_k\)들은 may have different dimensions. may라고 했지만 대부분의 경우 다름.

In this setting one can compute the \textbf{posterior probability of models}, i.e.

\$
p \left( \mathcal{M}\_k \rvert \pmb y \right) = \dfrac {\rho_k \ast \int f_k (y \lvert \theta_k) \ast \pi_k (\theta_k) d\theta_k } \{\sum\_j \rho\_j \ast \int f\_j (y \lvert \theta\_j) \ast \pi\_j (\theta\_j) d\theta\_j \}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

RJMCMC 알고리즘이란, 패러미터 space의 dim이 정해지지 않은 상황에서, 이 dim과 상관없이 모델 space 자체를 이동할 수 있게 만들어준 MCMC 알고리즘.

단, 패러미터 space의 dim은 모르지만, 여기서는 모델의 총 갯수인 \(k\)로 fix가 되어 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  모델 간을 이동시키면서 모델 셀렉션
\item
  이와 동시에 패러미터 estimation까지 동시에 한다
\end{enumerate}

는 것이 RJMCMC 알고리즘. 즉 RJMCMC 중에는 2가지 공정이 동시에 돌아간다

A variable dimension model is a ``model where one among things you do not know is the number of things you do now know'', 연구자 모르는 것들 중 하나에, 니가 지금 알고 있는 것들의 갯수가 있는 모델. 즉, 내가 지금 알고 있는 것이 총 몇개인지조차도 모른다는 이야기이다. \textbf{그럼 대체 아는게 뭐야;} e.g., 패러미터 space의 dimension이 고정되어 있지 않음. model selection, checking, improvement, 등등 다양한 상황에서 발생 가능. 모델 \(\mathcal{M}_k\) 사이에서의 움직임을 설계하는데 있어 적절한 framework를 구축하고 싶다.

즉슨 모델에 대한 다양한 예상들이 있고, 이러한 모델의 예상도를 확률적으로 옮겨다니면서 이게 맞나? 이게 맞나? 를 체크한다는 이야기.

이를 위한 Green의 원칙:
- 모델 한 쌍 간의 움직임(채택 모델의 변경)만을 고려.
- ``dimension matching'' moves를 설계.
- MH 알고리즘과 유사하게 움직임을 with probability로 수용. 여기서의 probability 노테이션은 \(q\).

let \(x_t = (k^{(t)}, \theta_k^{(t)} )\)가 현 상태를 나타내고, \(x^{(t+1)}\)에 대한 proposed state \(x' = (k', \theta_k')\).
- if \(k'=k\), proposed move 가 같은 subspace \(\mathcal{X}_k\)에서 다른 위치를 탐색한다는 것이다. 따라서 dimension-matching problem 자체가 발생하지 않는다.
- if \(k' \not= k\), 분포 \(\psi_{k^{(t)} \rightarrow k'} (u)\)로부터의 \(s\)개의 rv \(\pmb u = (u_1 , \cdots, u_s)\) 를 생산한다. 그리고 bijection \((\theta_k ' , u' ) = T(\theta_k^{(t)}, u)\)를 생각하자. 이때 \(s'\) 차원의 rvec\(u' = (u_1 , \cdots, u_{s'})\)이며, \(s\)와 \(s'\)는 dimension-matching condition \(s+d_k = s' + d_{k'}\)를 만족한다.

Proceeds:
1. 모델 \(\mathcal{M}_k\) with probability \(q(k^{(t)}, k')\)에 의해 선택.
2. generate \(u_1 , \cdots, u_s \sim \psi_{k^{(t)} \rightarrow k'} (u)\)
3. \((\theta_{k'}', u') = T(\theta_k^{(t)}, u)\).
4. Compute MH ratio \(r = \dfrac {f(k', \theta'_{k'} \rvert Y) } {f(k^{(t)}, \theta^{(t)}_{k} \rvert Y) } \dfrac {g(k^{(t)} \rvert k')} {g(k' \rvert k^{(t)})} \dfrac {\psi_{k' \rightarrow k^{(t)}} (u')} {\psi_{k^{(t)} \rightarrow k'} (u)} \left\lvert {\dfrac{\partial (\theta'_{k'}, u')}{\partial (\theta^{(t)}_{k}, u)}} \right\rvert\)where \$ \dfrac{\partial (\theta'_{k'}, u')}{\partial (\theta^{(t)}_{k} , u ) }\$ is Jacobian of Transformation.
5. set \(X^{(t+1)} = (k', \theta'_{k})\) with probability \(\min (1,r)\).

그러나 이렇게 무제한 모델을 만들면 너무 어려움. 따라서 보통 제약식을 추가해서 간단한 모델을 사용함. 사용되는 제약식은 각 이터레이션에서 이전 것과 이후 것 간의 dim 차이가 ±1 이라는 것.

\begin{quote}
Example: Reversible Jump MCMC Algorithm
\end{quote}

\hypertarget{auxiliary-variable-mcmc}{%
\section{Auxiliary Variable MCMC}\label{auxiliary-variable-mcmc}}

실전에서 마주치는 대부분의 상황에서 ABC나 HMC 문제를 제외하고는 대부분의 경우 MCMC 문제를 완벽하게 풀어내는 건 불가능. 이때 주어진 variable 말고 보조변수 (Auxiliary Variable)을 추가함으로써 시뮬레이션 품질을 좀 더 높일 수 있지 않을까 하는 것이 논하고자 하는 바.

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

\begin{itemize}
\tightlist
\item
  Difficulties with MH Algorithm. 일반적인 MH 알고리즘으로 풀어낼 수 없는 2가지 상황이 존재:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Local-trap problem: 에너지 계가 울퉁불퉁한 complex system에서 시뮬레이션을 진행했을 때 끝없이 로컬 최적값에서 빠져나오지 못함. 시뮬레이션을 비효율적으로 만듬.

    \begin{itemize}
    \tightlist
    \item
      density가 높다는 것은 해당 파트의 에너지가 낮다는 것이며, density가 낮은 에너지가 많은 파트에서 high density로 가는 것은 쉽고 자주 일어나도 역은 드뭄. 조밀하면 움직일 여력이 없으니까. 이것이 local trap의 원인
    \item
      에너지는 이하로 표시 가능: energy function \(= -log \pi(\theta \vert x)\), 즉 negative log posterior, 혹은 negative log density.
    \end{itemize}
  \item
    Doubly-intractable normalizing constants problem:

    \begin{itemize}
    \tightlist
    \item
      Inability to sample from distributions with intractable integrals

      \begin{itemize}
      \tightlist
      \item
        보통이라면, \(pi(\theta \vert x) \propto \kappa(x) f(x\vert\theta)\pi(\theta)\). \(r= \dfrac{pi(\theta ' \vert x)}{pi(\theta^{(t)} \vert x)} = \dfrac{\kappa(x) f(x\vert\theta ' )\pi(\theta ' )}{\kappa(x) f(x\vert\theta^{(t)})\pi(\theta^{(t)})}\) 과정에서 normarlizing constant \(\kappa\)가 알아서 캔슬되어 MH 돌리는데 문제가 없음.
      \end{itemize}
    \item
      let \(f(x) \propto \kappa(x;\theta) \psi(x)\) 는 알고자 하는 분포. 여기서 \(\kappa(x)\)는 unnormalized density의 함수. 이때 \(\kappa(x)\)는 패러미터의 함수이며 각 이터레이션의 다른 패러미터 추정값마다 변화해버려서 캔슬되지 않음. 그러면 계산하면 되는거 아님? 계산 불가능한 상황 존재 - nearly infinite summation or integration 포함하는 경우. (ex:) 이는 곧 intractable integral. acceptance \(Pr\)이 알 수 없는 비 \(\kappa(x')/\kappa(x)\)를 포함하므로 MH 알고리즘은 사용불가. 이러한 문제는 bayesian 추론에서 spatial statistical models, random effects models, 그리고 exponential random graph models 등 다양한 통계적 모형에서 부딪히게 된다.

      \begin{itemize}
      \tightlist
      \item
        ex: Lattice system of areal model (Lattice의 승만큼 연산 필요)
      \item
        e.g., \textbf{Random Effect Model}. 이때는 각 individual별로 Random Effect를 integration 해줘야 하므로 문제터짐
      \item
        ex: Exponential Random Graph model: 네트워크에 사용되는 모델. 얘도 power임.
      \item
        이러한 상황에서는 대부분의 optimization 알고리즘도 다 먹통됨
      \end{itemize}
    \end{itemize}
  \end{enumerate}
\end{itemize}

\begin{itemize}
\tightlist
\item
  이러한 2개의 문제점을 극복하기 위해 다양한 진보된 MCMC 방법론이 제시되었음.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Auxiliary variable-based methods
  \item
    Population-based methods
  \item
    \sout{Importance weight-based methods}
  \item
    Stochastic approximation-based methods
  \end{enumerate}
\end{itemize}

\hypertarget{auxiliary-variable-mcmc-methods}{%
\paragraph{Auxiliary Variable MCMC Methods}\label{auxiliary-variable-mcmc-methods}}

\(f(x)\)를 가지는 mv 분포에서의 샘플링을 생각해보자. \textbf{Rao-Blackwellization}이 MC 시뮬레이션에의 최우선원칙임은 알려져 있다. 시뮬레이션의 수렴을 좀 더 강화하기 위해 우리는 가능한한 많은 \(x\)의 구성물을 integrate하는 것을 시도해보아야 한다. 하지만 이하의 두가지 경우(이외에도 존재)에 시뮬레이션을 양질로 만들기 위해 우리는 1개 이상의 변수를 추가하는 상황을 고려할 수 있다.
1. 타겟분포 \(f(x)\)가 multimodal. 온도 혹은 아직 관측되지 않은 측정값과 같은 auxiliary variable이 계가 \textbf{로컬 트랩}에서 빠져나올 수 있도록 도움을 줌. multimodal 상황.
2. 타겟분포 \(f(x)\)가 intractable normalizing constant 포함. \(X\)의 auxiliary 실현값이 시뮬레이션에 포함됨으로써 시뮬레이션에서 normalizing constant 를 무력화시킴.

MH 알고리즘 \$ \dfrac{ f(\theta ' \vert x )}{f(\theta^{(t)} \vert x )} \dfrac{ g(\theta ' \rightarrow \theta^{(t)} )}{ g(\theta^{(t)}  \rightarrow  \theta ')} \$은 이하의 2가지 기본적인 부품을 가지고 있다.
1. 타겟분포 (左)
2. proposal 분포 (右)

이에 더해서 auxiliary variable 방법론은 이하의 2가지 방법으로 행해질 수 있다. 타겟과 제안 어느쪽에 변수를 추가하는지에 대한 이야기이다.
1. 타겟분포 augmentation 방법론: Augmenting auxiliary variables to the \textbf{target} distribution
* auxiliary variable \(u\)와 조건부 분포 \(f(u \rvert x )\)를 정의한다. joint 분포 \(f(x,u) = f(u \rvert x) f(x)\)를 만들기 위해. 이후 MH 알고리즘이나 GS를 사용해 \((x,u)\)를 업데이트. \(f(x)\)의 샘플은 \((X, U)\)의 실현값 \((x_1, u_1), \cdots, (x_N, u_N)\)를 이용해 marginalization이나 프로젝션 등을 이용해 획득될 수 있다.
2. Method of Proposal Distribution Augmentation: Augmenting auxiliary variables to the \textbf{proposal} distribution.
* proposal 분포 \(T(x', u \rvert x)\)를 특정하고, 이의 reversible version \(T(x, u \rvert x')\)도 특정한다. 즉슨 \(\int T(x', u \vert x)du = T(x' \vert x)\), \(\int T(x, u \vert x')du = T(x \vert x')\)의 관계가 성립한다. 이제 proposal \(T(x', u \vert x)\) 로부터 후보 (candidate) 샘플 \(x'\)를 생산하고, 이를 with probability \(\min \left\{ 1, r(x, x', u) \right \}\). 이때 \(r(x, x', u) = \dfrac {f(x')} {f(x)} \dfrac {T(x,u \vert x')} {T(x',u \vert x)}\).

실현값 (realizations) \(x_1 , \cdots, x_N\)을 생산할 때까지 이를 반복한다. 이제 \(N\)이 충분히 크다면, 이 실현값들은 근사적으로 \(f(x)\)에 의해 분포되어 있다.

이러한 방법론의 타당성은 이하를 통해 보일 수 있다.

\$

K(x' \vert x) = \int\_\{\mathcal{u}\} s(x, x', u) du + \mathbf{1}(x=x') \left[ 1-\int_{\mathcal{X}}\int_{\mathcal{u}} s(x, x', u) du dx' \right]

\$

이는 \(x\)로부터 \(x'\)로의 \textbf{\emph{integrated transition kernel}}을 의미하며, 이때 \(s(x, x', u) = T(x', u \rvert x) \ast r(x, x', u)\). Then,

\$

f(x) \int\emph{\{\mathcal{u}\} s(x, x', u) du = \int}\{\mathcal{u}\} \min \left[ f(x') T(x, u \vert x'), \; \; f(x)T(x', u \vert x) \right] du

\$

이는 \(x\)와 \(x'\) 에 대해 symmetric. 이는 곧 \(f(x)K(x' \vert x) = f(x')K(x \vert x')\) 임을 의미한다.

original density

\hypertarget{multimodal-target-distribution}{%
\subsection{Multimodal Target Distribution}\label{multimodal-target-distribution}}

\hypertarget{simulated-tempering}{%
\paragraph{Simulated Tempering}\label{simulated-tempering}}

분포 \(f(x) \propto \exp \left(-H(x) \right), x \in X\) 에서 샘플링하는데에 관심이 있다고 하자. simulated annealing에서 그러했던 것처럼, simulated tempering \(f(x, T) \propto \exp \left( -\dfrac {H(x)} {T} \right)\)로 타겟 분포를 확장시켰다. 이는 auxiliary variable인 temperture \(T\)를 포함함으로서 이루어진다. \(T\)는 \textbf{사용자가 미리 지정한 값들의 finite set}이 된다. \(H(x)\)는 사실상 energy function.

Temperatur Transition Matrix \(T = \begin{bmatrix} q_{11} & q_{12} & \cdots & q_{1n} \\ q_{21} & \ddots & & \\ \vdots & & \ddots & \\ q_{n1} & \cdots & & q_{nn} \end{bmatrix}\). 이때 row는 current 온도 \(T_1, \cdots, T_n\), column은 행선지 온도.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Parallel Tempering}은 인접한 온도로만 이동 가능 (가장 높은 온도에서 가장 낮은 온도로 한단계 한단계씩). 온도 자체를 시뮬레이션한게 아니라 온도의 chain이 주어져 있어 각 온도 간의 움직임을 만드는 것에 그친다. 따라서 이는 multiple chain을 이용하는 population MC 방법론 쪽에 소속됨.

Simulated Tempering과는 이 점에서 차이를 보임. 후자는 어느 온도로든 다 이동. 온도 매트릭스 만들어놓고, \(U(0,1)\) 분포에서 온도 하나 생산하고 이 온도로 이동할 것인지의 여부를 MH 알고리즘으로 결정.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\(U(0,1)\)에서 랜덤하게 숫자를 뽑고, \(j\)의 값을 proposal transition matrix \((q_{ij})\)에 따라서 정한다. \(u<q_{11}\)이면 \(T_1 \rightarrow T_1\), \(q_{11}<u<q_{11} + q_{12}\)이면 \(T_1 \rightarrow T_2\), \ldots.
- if \(j=i_t\), let \(i_{t+1}=i_t\), and let \(x_{t+1}\)을 MH kernal \(K_{i_t}(x,y)\)에서 뽑는다. 이때 \(K_{i_t}(x,y)\)는 \(f(x, T_{i_t})\)을 invariant distribution로 허용하는 아이이다. 즉 새로운 \(x\)를 생산하면 된다.
- if \(j \not= i_t\), let \(x_{t+1}=x_t\)하고 proposal을 이하의 \(Pr\)에 따라 채택한다. 이때 \(Z\)는 \(Z_i\)의 측정값이다. 채택된다면 \(i_{t+1} = j\)이고, 그외의 경우에는 \(i_{t+1} = i_t\)로 한다. 새로운 \(x\)를 생산하는 것이 아니라 들고 있던 \(x\)를 쓰되, 이걸 accept 할건지 안할건지를 체크한다.

\$
\min \left[ 

1, \; \; 

\dfrac {\hat Z_j} {\hat Z_{i_t}} \ast \exp \right \{

-H(x) \left( \dfrac{1}{T_j}-\dfrac{1}{T_{i_t}} \right)

\left \}

\ast 

\dfrac {q_{j,i_t}} {q_{i_t , j}} 

\right]\$

이때 \$\dfrac {q_{j,i_t}} \{q\_\{i\_t , j\}\} \$는 proposal distribution이라고 생각할 수 있다. 나머지는 Likelihood part이며, 이때 \(\dfrac {\hat Z_j} {\hat Z_{i_t}}\)가 normalizing constant의 ratio이다. 온도가 변화하였으므로 두 식의 normalizing constant가 같지 않기 때문이다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

** \textasciitilde\textasciitilde Issues on Simulated Tempering: \textasciitilde\textasciitilde{} **

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Temperature Ladder를 어떻게 고를 것인가.} -\textgreater{} 각 chain별로 이동이 원활하게 잡는 것이 핵심.

  \begin{itemize}
  \tightlist
  \item
    가장 높은 온도 \(T_1\)은 대부분의 uphill move가 해당 레벨에서 accept 될 수 있도록 설정되어야 한다.
  \item
    사이의(intermediate) 온도들은 sequential manner로 설정될 수 있다. \(T_1\)에서 시작해서, 점차적으로 다음으로 낮은 온도를 \(Var_i \left\{ H(x) \right\} \ast \delta^2 = O(1)\)을 만족하도록 설정하는 것이다. 이때 \(\delta = \dfrac {1}{T_{i+1}} - \dfrac{1}{T_i}\)이며, \(Var_i(\cdot)\)은 \(H(x)\) (taken with respect to \(f(x, T_i)\)) 의 분산을 의미한다.

    \begin{itemize}
    \tightlist
    \item
      이러한 조건들은 \(f(x,T_i), f(x,T_{i+1})\) 사이에 상당히 겹치는 점이 많아야 한다는 것을 의미하기도 한다. 실전에선 \(Var_i \left( H(x) \right)\)는 샘플러를 레벨 \(T_i\)에서 예비적으로(preliminary) 돌려보았던 결과에서 러프하게나마 예측될 수 있다.\\
    \end{itemize}
  \end{itemize}
\item
  \textbf{\(Z_i\)를 어떻게 estimate 할 것인가.} -\textgreater{} accept 여부가 normalizing constant에도 의존해서 이거 이상하게 고르면 효율 떨어짐. 엄청난 단점이라서 요즘은 이 알고리즘 자체를 잘 안씀

  \begin{itemize}
  \tightlist
  \item
    이는 simulated tempering의 효율에 직결되는 부분이다. \(Z_i\)들이 잘 estimate 되었다면, simulated tempering은 temperature ladder을 따라 \textbf{symmetric RW}처럼 동작한다. (\(x\)-updating step을 제하고 볼 경우) 그렇지 않다면 이는 특정 temperature 레벨에서 멈춰버린다. 시뮬레이션이 실패함은 물론이다(rendering). 실전에서 \(Z_i\)들은 stochastic approximation MC 방법론을 사용해서 estimate 가능하다. 혹은 reverse logistic regression 방법론을 사용해서도 \(Z_i\)를 estimate 할 수 있다.
  \end{itemize}
\end{enumerate}

\hypertarget{slice-sampler}{%
\paragraph{Slice Sampler}\label{slice-sampler}}

density \(f(x), \; \; \; x \in \chi\)에서 샘플링하고자 한다. \$ x \sim f(x)\$에서 샘플링하는 것은, \(f(x)\) 그래프 이하의 영역에서 uniform하게 샘플링하는 것과 동등하다. 해당 영역은 \(A = \{ (x,u): 0 \le u \le f(x) \}\)이며, 이것이 acceptance-rejection 알고리즘의 기초(basis)였다. 이 목적을 달성하기 위해 우리는 타겟분포 \(f\)를 auxiliary variable \(U\)를 사용하여 확장해볼 수 있다. 이 \(U\)는, \(x\)에 대해서 조건부일 때, 구간 \([0, f(x)]\)에서 uniform하게 분포되어 있다.

따라서, \((X, U)\)의 joint density function은 \(f(x,u)=f(x)f(u \rvert x) \propto I_{(x,u)\in \textit A}\). 후자의 인디케이터는 언급되었던 영역 안에 속한다는 의미. 이는 GS에 의해 이하와 같이 샘플링 가능하다.
1. draw \(u_{t+1} \sim U[0, f(x_t)]\).
2. draw \(x_{t+1}\) uniformly from the region \(\{ x: f(x) \ge u_{t+1} \}\).

위의 샘플러는 \textbf{slice sampler}라고 불림. 이는 multimodal 분포들에 대해 단순 MH 알고리즘보다 더 나을 가능성이 있음. slice 때문에 b/w-mode-transition에 자유롭기 때문. 현재도 핫한 샘플러중 하나임. horseshoe prior 에서의 패러미터 estimate에 대표적으로 이녀석이 쓰인다.

\hypertarget{doubly-intractable-normalizing-constants}{%
\subsection{Doubly-intractable Normalizing Constants}\label{doubly-intractable-normalizing-constants}}

Spatial models, e.g., the autologistic model, the Potts model, and the autonormal model (Besag, 1974)는 많은 과학적 문제들을 위한 모델링에 쓰이고 있음. 이러한 모델들에 해당하는 주요한 문제는 normalizing constant가 doubly-intractable하다는데 있음.

for dataset \(X\), 패러미터 \(\theta\), normalizing constant \(\kappa (\theta)\). 이때 \(\kappa (\theta)\)는 \(\theta\)에 의존하나 closed form으로는 만들 수 없음. 이하는 dataset을 생산한 likelihood function.

\$
\begin{align*}
X \sim f(x \vert \theta) = \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \}, &x \in \mathcal{X}, &\theta \in \Theta
\end{align*}
\$

\(\pi(\theta)\)는 \(\theta\)의 prior. 이 경우 post는 \(f(\theta \vert x) \propto \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \} \ast \pi(\theta)\).

\hypertarget{boltzmann-density}{%
\paragraph{Boltzmann Density}\label{boltzmann-density}}

known as \textbf{Ising Model}, 그리고 \textasciitilde 로 확장될 경우 \textbf{autologistic model}.

Consider a 2-D Ising model with the Boltzmann density

\$

f(\pmb x) \propto \exp \left\{ K \sum\_\{i\sim j\} x\_i x\_j \right\}

\$

\begin{itemize}
\tightlist
\item
  spins \(x_i = \pm 1\) (S극이 -1)
\item
  \(K\)는 inverse temperature (measure for interaction : \(x_i\)가 주변에 있는 값과 얼마나 많은 같은 값을 가지는지, 다른 값을 가지는지에 대해 측정해주는 패러미터) 온도가 낮을수록 interaction가 강해지며, 이에 의해 동일값 확률이 높아짐.
\item
  \(i\sim j\)는 lattice 상의 가장 가까운 neighbors.
\end{itemize}

온도가 높다면, 이 모델은 GS를 사용해 쉽게 시뮬레이션 가능하다. 조건부 분포에 따라 각 spin의 값을 iteratively 초기화한다. 아래의 식에서 \(n(i)\)는 spin \(i\)의 neighbors의 집합 (set). 이하의 수식은 autologistic 과 그 과정이 유사하다.

\$
\begin{align*}

P(x_i =1 \vert x_j, \; \; j \in n(i)) &= \dfrac {1}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} \\
P(x_i =-1 \vert x_j, \; \; j \in n(i)) &= \dfrac {\exp \left \{ -2K \sum_{j \in n(i)} \right\}}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} &= 1- P(x_i =1 \vert x_j, \; \; j \in n(i))

\end{align*}
\$

하지만, GS는 temperature가 critical temperature로 근접하거나 이하로 내려갈 경우 GS가 빠르게 느려진다. 온도가 낮으면 interaction이 강해져, 주변값과 비슷한 값을 generate 해야만 하기 때문이다. 이렇게 샘플링이 어려워지는 지점, 온도를 \textbf{critical point}라고 부른다. 이는 대략 \(\theta \approx 0.43\). 이것이 소위 \textbf{critical slowing down} 이라고 불리는 현상이다.

\hypertarget{perfect-sampler}{%
\subparagraph{Perfect Sampler}\label{perfect-sampler}}

과거 샘플들의 굉장히 많은 조합을 커플링해서 샘플을 생산. previous realization 전체에 대해 (이는 그 이전의 샘플, 아니면 그 이전의 샘플, 혹은 original 데이터에 대해서조차도) independent한 샘플을 생산해내는 sampler. 즉 그 어떤 것에서도 independent한 sample을 생산해낸다. 문제는 이 샘플러는 \(\theta>0.43\)인 순간 바로 작동을 안함. \(\theta>0.32, 0.35\) 정도로 엔간 크기만 해도 드럽게 느림.

\hypertarget{swendsen-wang-algorithm}{%
\subparagraph{Swendsen-Wang Algorithm}\label{swendsen-wang-algorithm}}

slice sampling에서 Boltzmann 덴시티는 이하의 형으로 다시 쓰여진다. 이때 \(\beta = 2K\). indicator function으로 변형했을 때 저 둘이 어떻게 equation이 성립하는지 유의.

\$

f(\pmb x)

; \propto 

; \prod\_\{i\sim j\} \exp \left\{ K(1+x\_i x\_j) \right\}

; =

; \prod\_\{i\sim j\} \exp \left\{ \beta \ast 

\mathbf{1}(x\_i = x\_j)

\right\}

\$

이때 우리가 auxiliary variable \(\pmb u = (u_{i \sim j})\), where each component \(u_{i \sim j}\), conditional on \(x_i\) and \(x_j\), is uniformly distributed on \(\left[ 0, \; \exp \{\beta \ast \mathbf{1}(x_i = x_j)\} \right]\), then

\$

f(\pmb x, \pmb u)

; \propto  ;

\prod\emph{\{i \sim j\} \mathbf{1} \left( 0 \le u}\{i \sim j \} \le \exp\left\{ \beta \ast \mathbf{1} (x\_i = x\_j) \right\} \right)

\$

이때 \(u_{i \sim j}\) 자체는 \textbf{bond variable}이라고 명명된다. 이는 spin \(i\)와 spin \(j\) 사이의 가장자리에 물리적으로 앉아 있는 변수로서 생각될 수 있다. (i와 j가 묶여져 있는지, 같은 group 안에 존재하는 것인지 아닌지에 대한 indicator가 되는 variable)
* if \(u_{i \sim j}>1\), then \(\exp \left\{ \beta \ast \mathbf{1}(x_i = x_j) \right \}>1\), 따라서 반드시 \(x_i = x_j\).
* if \(u_{i \sim j}<1\), 이 경우 \(x_i, x_j\)에 제약 (constraint) 이 없다.

\(b_{i \sim j}\)가 제약에 대한 indicator variable이라고 정의하자. 즉, \(x_i, x_j\)가 같도록 제약되었다면, \(b_{i \sim j}=1\)이며 이외엔 0이다. for any 2개의 ``like-spin'' (i.e.~2개의 spin이 같은 값을 가진다) neighbors에 대해서, 이 둘은 with probability \(1-\exp (-\beta)\)를 따라 bonded 될 수 있는 가능성이 있음을 기억하라. \(\pmb u\)의 설정 (configuration)에 따라, ``mutual bond'' (i.e., \(b_{i \sim j}=1\)) 을 통하여 연결될 수 있는지 없는지 여부에 따라 spin들을 군집 (cluster) 할 수 있다. (위에서 i와 j가 같다고 indicator가 판별했을 경우에만 이런 cluster 로 묶는 것이 가능하다) Then 동일 클러스터 내의 모든 spin은 같은 값을 가질 것이다. 또한 군집 내부의 모든 spin을 동시에 뒤집는 (flip) 것은 \(f(\pmb x , \pmb u)\)의 평형 (equilibrium)을 해치지 않을 것이다.

Proceeds:
1. Update the bond values: check all ``like-spin'' neighbors, and set \(b_{i \sim j}=1\) with probability \(1-\exp (-\beta)\).
2. Update the spin values: Cluster spins by connecting neighboring sites with a mutual bond, and then flip each cluster with probability \(0.5\).

For the Ising model, the introduction of the auxiliary variable \(\pmb u\) has the dependence between neighboring spins partially decoupled, and the resulting sampler can thus converge substantially faster than the single site updating algorithm. As demonstrated by Swendsen and Wang (1987), this algorithm can eliminate much of the \textbf{critical slowing down}.

같은 값들이 모여있는 cluster를 판별하여 각각을 grouping. grouping을 랜덤으로 하므로 인접해 있는 동일값임에도 그룹에 포함되지 못하는 경우가 존재함. Swendsen-Wang에서는 이렇게 그룹을 만든 후, 해당 그룹을 통채로 toggling. group을 통채로 토글링하기 때문에 dependency가 있는 것들이 통채로 toggling되어서 dependency가 있는 것들은 나머지 것들과 인제 이렇게 independent한 것도 있지만 dependent한 것을 통채로 묶어서 하는 것이므로 좀더 한꺼번에 뒤집으니까 실제로 우리가 업데이트하는 것은 group 내부 말고 group 외부 간들에는 independent하다고 가정될 수 있는 몇몇개의 group들만이 남음. 이 덩어리들을 한꺼번에 업데이트하므로 따라서 샘플러 generate가 상대적으로 쉬움. 하지만 이 만든 덩어리는 매 이터레이션마다 덩어리를 새로 만들어야 함. 매 이터레이션마다 클러스터를 새로 만들고 flip하여 이를 accept할지 말지를 결정하는 이런 형태의 구조를 가짐.

\hypertarget{muxf8ollers-algorithm}{%
\paragraph{\texorpdfstring{\sout{Møoller's Algorithm}}{Møoller's Algorithm}}\label{muxf8ollers-algorithm}}

auxiliary variable \(y\), 이는 \(x\)와 같은 state space를 공유한다고 정의. 그 경우 이하의 joint pdf \(f\) 를 생각해볼 수 있다. \(f(y \vert \theta , x)\)는 \(y\)의 분포.

\$
f(\theta, y \vert x) = f(x \vert \theta) \ast f(\theta) \ast f(y \vert \theta , x)
\$

\$ f(\theta, y \vert x) \$ 에서 MH 알고리즘을 통해 시뮬레이트하기 위해서는 이하와 같은 제안분포 \(q\) 를 사용해볼 수 있다. 이는 패러미터 벡터 \(\theta \rightarrow \theta'\)의 usual change에 상응하며, 이 후에는 \(q(\cdot \vert \theta ' )\)에서 \(y'\)를 추출하는 exact sampling step이 따른다.

\$

q(\theta' , y' \vert \theta , y) = q(\theta`\vert \theta , y) \ast q(y' \vert \theta')

\$

\(q(y' \vert \theta ' )\)가 \(f(y' \vert \theta)\)로 설정되었다면, MH ratio \(r\)은 이하와 같이 쓰일 수 있다. 이때 unknown normalizing constant \(\kappa(\theta)\)가 상쇄 (cancel) 되었음에 주목하라.

\$
\begin{align*}

r(\theta, y, \theta', y' \vert x)

&= 


\dfrac 
{f(x \vert \theta') f(\theta') f(y' \vert \theta' , x) \ast q(\theta\vert \theta' , y') q(y \vert \theta)} 
{f(x \vert \theta) f(\theta) f(y \vert \theta , x) \ast q(\theta'\vert \theta , y) q(y' \vert \theta')}

 \\

&= 

\dfrac {f(\theta', y' \vert x)}{f(\theta, y \vert x)} \ast 
\dfrac {q(\theta , y \vert \theta' , y'))}{q(\theta' , y' \vert \theta , y)}


 \\
&=

\dfrac
{
\dfrac {f(\theta', y' \vert x)}{q(\theta' , y' \vert \theta , y)} 
}
{
\dfrac{f(\theta, y \vert x) }{q(\theta , y \vert \theta' , y'))}
}



\end{align*}
\$

여기서 계산을 간단하게 하기 위해 제안분포 \(q\)와 auxiliary distribution을 이하와 같이 정리하는 것을 생각해볼 수 있다. 이때 \(\hat \theta\)는 \(\theta\)의 estimate로써, 예를 들어 pseudo-likelihood function을 극대화하는 것으로 얻어진 값이다.

\$
\begin{align*}

q(\theta' \vert \theta , y) &= q(\theta' \vert \theta ) , q(\theta \vert \theta ', y') &= q(\theta \vert \theta ') \\

f(y \vert \theta , x) &= f(y \vert \hat \theta ), f(y' \vert \theta' , x) &= f(y' \vert \hat \theta )

\end{align*}
\$

분포 \(f(x \vert \theta)\)를 auxiliary variable, 가령 normalizing constant ratio \(\dfrac {\kappa(\theta)} {\kappa(\theta')}\) 등으로 살찌워놓은 것은, 시뮬레이션 진행 과정에서 상쇄시키는 것이 가능하다.
1. generate \(\theta \sim q(\theta' \vert \theta_t)\)
2. generate exact sample \(y' \sim f(y \vert \theta')\)
3. accept \((\theta', y')\) with probability \(\min (1, r)\), \(r=\dfrac {f(x \vert \theta') f(\theta') f(y' \vert \hat \theta') \ast q(\theta_t \vert \theta') q(y \vert \theta_t)} {f(x \vert \theta_t) f(\theta_t) f(y \vert \hat \theta) \ast q(\theta'\vert \theta_t) q(y' \vert \theta')}\).
* 채택된다면, set \((\theta_{t+1}, y_{t+1}) = (\theta', y' )\).
* o.w., \((\theta_{t+1}, y_{t+1}) = (\theta_t, y'_t)\).

\hypertarget{exchange-algorithm}{%
\paragraph{Exchange Algorithm}\label{exchange-algorithm}}

Møller's 알고리즘을 \textbf{parallel tempering} 개념을 도입하여 개선.
1. propose candidate point \$\theta' \sim \$ proposal distribution \(q(\theta' \vert \theta, x)\).
2. propose auxiliary variable \(y \sim\) perfect sampler \(f(y \vert \theta ' )\).
3. accept \$\theta' \$ with probability \(\min \{ 1, r(\theta, \theta' \vert x) \}\).
- \(r(\theta, \theta' \vert x) = \dfrac{\pi(\theta') }{\pi(\theta) } \ast \dfrac{f(x \vert \theta ') }{f(x \vert \theta)} \ast \dfrac{f(y \vert \theta) }{f(y \vert \theta')} \ast \dfrac{f(\theta \; \vert \theta', x) }{f(\theta' \vert \theta, x)}\)

The exchange algorithm can be viewed as an auxiliary variable MCMC algorithm with the proposal distribution being augmented, for which the proposal distribution can be written as

\$

\begin{align}

T \left( \theta \rightarrow (\theta' , y) \right) &= q(\theta ' \vert \theta) f(y \vert \theta ') \\
T \left( \theta' \rightarrow (\theta , y) \right) &= q(\theta \vert \theta ' ) f(y \vert \theta)


\end{align}
\$

This simply validates the algorithm, following the arguments for auxiliary variable Markov chains.

The exchange algorithm generally improves the performance of the Møller algorithm, as it avoids an initial estimation step (for \(\theta\)) that required by the Møller.

Although the Møller's and exchange algorithms work well for some discrete models, such as the Ising and autologistic models, they cannot be applied to many other models for which perfect sampling is not available.

Even for the Ising and autologistic models, perfect sampling may be very expensive when the temperature is near or below the critical point.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{adaptive-exchange-algorithm}{%
\paragraph{Adaptive Exchange Algorithm}\label{adaptive-exchange-algorithm}}

Object

An adaptive exchange algorithm (AEX) is an adaptive Monte Carlo version of the exchange algorithm, where the auxiliary variables are generated via an importance sampling procedure from a Markov chain running in parallel.

\begin{itemize}
\tightlist
\item
  Advantage

  \begin{itemize}
  \tightlist
  \item
    Removes the requirement of perfect sampling
  \item
    Overcomes its theoretical difficulty caused by inconvergence of finite MCMC runs
  \end{itemize}
\end{itemize}

AEX consists of two chains running in parallel.

The first chain is \textbf{auxiliary}, which is run in the space \({\mathcal{x}}\) with an aim to draw samples from a family of distributions \(f(X \vert \theta^{(1)}), \; \; \cdots, \; \; f(X \vert \theta^{(m)})\) for a set of pre-specified parameter values \(\theta^{(1)}, \; \cdots, \; \theta^{(m)}\).

The second chain is the \textbf{target} chain, which is run in the space \(\theta\) with an aim to draw samples from the target posterior \(\pi(\theta \vert y)\). For a candidate point \(\theta'\), the auxiliary variable \(x\) is resampled from the past samples of the auxiliary chain via an importance sampling procedure.

Assume that the neighboring distributions \(f(X \vert \theta^{(i)})\)'s have a reasonable overlap and the set \(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\) has covered the major part of the support of \(\pi (\theta \vert y)\).

\begin{itemize}
\tightlist
\item
  ALGORITHM: PART 1 - (Auxiliary Chain) Auxiliary Sample Collection via SAMC
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  (Sampling) Choose to update \(\vartheta\) or \(\pmb z_t \vert \vartheta\) with pre-specified probabilities, e.g., \(0.75\) for updating \(\vartheta\) and \(0.25\) for updating \(z_t\).
\end{enumerate}

1-a. Update \(\vartheta_{t}\) : Draw \(\vartheta '\) from the set \(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\) according to a proposal distribution \(T_1 ( \; \cdot \; \vert \vartheta_{t})\),

set \((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta ' , \pmb z_{t+1} )\) with probability \(\min \left\{ 1, \; \; \dfrac{\omega_t^{J(\vartheta_t)}}{\omega_t^{J(\vartheta ')}} \ast \dfrac {\varphi (\pmb z_{t} \vert \vartheta ')} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_1 (\vartheta_{t} \vert \vartheta ' )}{T_1 (\vartheta ' \vert \vartheta_{t} )} \right\}\),

and set \((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta_{t}, \pmb z_t)\) with remaining probability, where \(J(\vartheta_t)\) denotes the index of \(\vartheta_t\), i.e., \(J(\vartheta_t) = j\) if \(\vartheta_t = \theta_i^{(k)}\) and \(\varphi(\pmb z \vert \vartheta)\) is an unnormalized density of \(f(\pmb z \vert \vartheta)\).

1-b. Update \(\pmb z_t\) : Draw \(\pmb z '\) according to a proposal distribution \(T_2 ( \; \cdot \; \vert \pmb z_t)\),

set \((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z ' , \vartheta_{t})\) with probability \(\min \left\{ 1, \; \; \dfrac {\varphi (\pmb z ' \vert \vartheta_{t})} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_2 (\pmb z_{t} \vert \pmb z ' )}{T_2 (\pmb z ' \vert \pmb z_{t} )} \right\}\),

and set \((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z_t , \vartheta_{t})\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  (Abundance Factor Updating) Set
\end{enumerate}

\$

\log (\omega\emph{\{t+0.5\}\^{}\{(j)\}) =\log (\omega}\{t\}\^{}\{(j)\}) + a\_\{t+1\} (e\_\{t+1, ; j\} - p\_j), ; ; ; ; ; j=1, \cdots, m

\$

where \(e_{t+1, \; j} = \begin{cases} 1 & && \vartheta^{t+1} = \theta^{(j)} \\ 0 & && o.w. \end{cases}\).

If \(\omega_{t+0.5}^{(j)} \in \mathcal{K}_{\varsigma_t}\), set \((\omega_{t+1}, \pmb z_{t+1}) = (\omega_{t+0.5}, \pmb z_{t+1})\) and \(\varsigma_{t+1} = \varsigma_t\).
o.w., set \((\omega_{t+1}, \pmb z_{t+1}) = \mathbb{T}(\omega_{t}, \pmb z_{t})\) and \(\varsigma_{t+1} = \varsigma_t + 1\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  (Auxiliary Sample Collection) Append the sample \(\left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right)\) to the collection \(S_t\). Denote the new collection by \(S_{t+1}\) which is set by \(S_{t+1} = S_t \cup \left\{ \left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right) \right\}\).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  ALGORITHM: PART 2 - (Target Chain) Adaptive Exchange Sampler
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (Proposal) Propose a candidate point \(\theta '\) from a proposal distribution \(q(\theta ' \vert \theta)\)
\item
  (Resampling for Auxiliary Variables) Resample an auxiliary variable \(\pmb x\) from the collection \(S_{t+1}\) via a dynamic importance sampling procedure;
\end{enumerate}

that is, setting \(\pmb x = \pmb z_k\) with probability

\$

P(\pmb x = \pmb z\_k)

\dfrac

\{\sum\emph{\{j=1\}\^{}\{\vert S}\{t+1\} \vert\} \omega\_t\^{}\{\left( J(\vartheta\emph{j) \right)\} \tfrac{\varphi(\pmb z_k \vert \theta ' )} \{\varphi(\pmb z\_k \vert \vartheta\emph{j ' )\} \ast I(\pmb z\_j = \pmb z\_k )\}
\{\sum}\{j=1\}\^{}\{\vert S}\{t+1\} \vert\} \omega\_t\^{}\{\left( J(\vartheta\_j) \right)\} \tfrac{\varphi(\pmb z_k \vert \theta ' )} \{\varphi(\pmb z\_k \vert \vartheta\_j ' )\}\}

\$

\begin{itemize}
\tightlist
\item
  \(\left(\pmb z_{j} , \vartheta_{j}, \omega_{t}^{J(\vartheta_{j}} \right)\) denotes the \(j\)-th element of the set \(S_{t+1}\).
\item
  \(\vert S_{t+1} \vert\)는 \(S_{t+1}\)의 size.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  (Exchange Algorithm) Set \(\theta_{t+1} = \theta '\) with the probability \(\alpha(\theta_t , \pmb x, \theta' )\), and \(\theta_{t+1} = \theta_{t}\) with probability \(1-\alpha(\theta_t , \pmb x, \theta' )\).
\end{enumerate}

\$

\alpha(\theta\_t , \pmb x, \theta' ) =

\dfrac {\pi(\theta ' )} \{\pi(\theta\_t )\}

\dfrac {\varphi(\pmb y \vert \theta ' )} \{\varphi(\pmb y \vert \theta\_t )\}

\dfrac {q(\theta_t \vert \theta ' )} \{q(\theta' \vert \theta\_t )\}

\dfrac {\varphi(\pmb x \vert \theta_t )} \{\varphi(\pmb x \vert \theta ' )\}

\$

\begin{itemize}
\tightlist
\item
  Why this algorithm is adaptive?
\end{itemize}

Since the underlying true proposal distribution for generating auxiliary variables in part II is changing from iteration to iteration, the new algorithm falls into the class of adaptive MCMC algorithms (for which the proposal distribution is changing from iteration to iteration).

\hypertarget{approximate-bayesian-computation}{%
\section{Approximate Bayesian Computation}\label{approximate-bayesian-computation}}

Likelihood를 사용하지 않고 Summary Stat을 사용함. 이와 같은 성질로 인해 Likelihood-free inference라고도 불리며, 이의 근거는 simulator-based model (모델 자체를 data generation process라고 보는 것. 모델을 통해 data를 생산해내는 것이 가능하다는 소리). 모델이 있으면, 이 모델과 대응하는 패러미터가 존재할 것. 이 모델 자체를 하나의 data generating process라고 본다면, 당연히 우리는 Auxiliary Data를 생산하는 것 또한 가능. 이 AD를 생산하는 것이 가능하기 때문에, 이렇게 생산한 AD 데이터가 기존 데이터 (original data) 와 얼마만큼 가까운지, 아니면 얼마만큼 떨어져 있는지를 체크하는 것이 ABC 방법론. 이것이 충분히 가깝다면 우리가 가지고 있는 패러미터를 패러미터의 샘플로 인정하는 것이 가능하다는 것. 이때 직접 AD와 OD를 비교하는 것인 대단히 어려우므로 대체재로 Summary Stat을 사용함. 이것이 ABC 방법론의 핵심. 이는 genetics에서 개발됨.

\hypertarget{simulator-based-models}{%
\subsection{Simulator-Based Models}\label{simulator-based-models}}

\textbf{deterministic model}은 뭐임?

모든 모델이 pdf \(p(y \vert \theta)\)의 family로 특정되는 것은 아님.

\begin{itemize}
\tightlist
\item
  Simulator-based Models: Models which are specified via a mechanism (rule) for generating data.
\end{itemize}

Models specified via a data generating mechanism occur in multiple and diverse scientific fields.

\begin{itemize}
\tightlist
\item
  Different communities use different names for simulator-based models:

  \begin{itemize}
  \tightlist
  \item
    Generative Models: 데이터를 생성해주는 메커니즘을 연구하는 모델
  \item
    Implicit Models
  \item
    Stochastic Simulation Models
  \item
    Probabilistic Programs
  \end{itemize}
\item
  Examples

  \begin{itemize}
  \tightlist
  \item
    Astrophysics: Simulating the formation of galaxies, stars, or planets.
  \item
    Evolutionary Biology: Simulating Evolution
  \item
    Neuroscience: Simulating Neural Circuits
  \item
    Ecology: Simulating Species Migration
  \item
    Health Science: Simulating the spread of an infectious disease
  \end{itemize}
\item
  Advantages of Simulator-Based Models

  \begin{itemize}
  \tightlist
  \item
    Direct implementation of hypotheses of how the observed data were generated. obs가 어떻게 생산되었는지에 대한 가설을 입증할 수 있는 하나의 방법이 됨.
  \item
    Neat interface with physical or biological models of data. 갖고 있는 데이터는 한둘에서 끝나고 이의 variation을 고려하는 것이 중요한데 이 variation을 연구하는건 데이터 한둘로는 어려움. 이때 가지고 있는 데이터를 replicate하고 simulator-based model을 이용해 비슷한 데이터를 만들어내서 variation을 연구해 좀더 정확한 inference를 가능케 하고, 그러면서 uncertainty quantification도 가능하게 함.\\
  \item
    Modeling by replicating the mechanisms of nature which produced the
  \item
    observed/measured data. (``Analysis by synthesis'')
  \item
    Possibility to perform experiments.
  \end{itemize}
\item
  Disadvantages of Simulator-Based Models

  \begin{itemize}
  \tightlist
  \item
    Generally elude analytical treatment. analytic한 solution이 없어 수학적 증명이 어려움. Approximate BC인 이유가 여기 있음
  \item
    Can be easily made more complicated than necessary.
  \item
    Statistical inference is difficult but possible.
  \end{itemize}
\item
  Family of pdfs Induced by the Simulator:
\end{itemize}

For any fixed \(\theta\) (패러미터 \(\theta\) 는 주어져 있다는 소리), the output of the simulator \(y_\theta = g( \cdot \; , \theta)\) is a \textbf{random variable}. 즉 \(\theta \longrightarrow y_\theta\). No closed-form available for \(p(y \vert \theta)\), and Simulator defines the model pdfs \(p(y \vert \theta)\) implicitly.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{0.07}}@{}}
\toprule
\endhead
 \\
\#\#\# Approximate Bayesian Computation (ABC) \\
\#\#\#\#\# Intractability \\
\$
\pi (\theta \vert D ) = \dfrac{\pi (D  \vert \theta) \pi (\theta) }{\pi (D)}
\$ \\
- Usual intractability in Bayesian inference is not knowing \({\pi (D)}\), which is marginal Likelihood of Data.
- \(\pi (D \vert \theta) = \kappa(\theta)\pi (D \vert \theta)\) 인 경우라면, MH 알고리즘을 사용하면 됨. 계산 과정에서 \(\pi (D \vert \theta)\)가 캔슬되니까. 그러나 \(\pi (D \vert \theta) = \kappa(\theta)f (D \vert \theta)\), \(f (D \vert \theta)\) 가 unnormalized density인 경우라면 이는 \textbf{doubly-intractable} 케이스. 캔슬도 안되고 고려해줄수밖에 없음. (with \(\kappa(\theta)\) unknown.)
- ABC가 해법이 된다. 만능은 아님. 적용에 약간 회의적.
- A problem is \textbf{completely-intractable} if \(\pi (D \vert \theta)\) is unknown and cannot be evaluated (unknown is subjective). That is, if the analytic distribution of the simulator, \(f(\theta)\) run at \(\theta\) is unknown. 모델이 지나치게 복잡해서 명시적으로 Likelihood 자체가 주어지지 않는 경우가 존재함. \\
Completely intractable models are where we need to resort to ABC methods. (Likelihood가 intractable한 모델에서 ABC가 많이 사용된다. 전 챕터에서 언급된 Doubly Intractable 모델이 대표적인 예. 단 ABC가 스켈레톤 키는 아님. ABC도 패러미터 튜닝이 요구되고, 이 패러미터 튜닝은 상당히 어려움. 따라서 ABC도 상당히 약점이 많음.) \\
- Genetic Background of ABC
- ABC is a recent computational technique that only requires being able to sample from the likelihood \(f(\cdot \; \theta)\)
- This technique stemmed from population genetics models, about 15 years ago, and population geneticists still contribute significantly to methodological developments of ABC.
- Population Genetics
- Describe the genotypes (AA, AO, etc ⇔ penotypes A) , estimate the alleles frequencies, determine their distribution among individuals, populations and between populations.
- Predict and understand the evolution of gene frequencies in populations as a result of various factors.
- Analyses the effect of various evolutive forces (mutation, drift, migration, selection) on the evolution of gene frequencies in time and space. \\
If the likelihood function is intractable, then ABC (approximate Bayesian computation) is one of the few approaches we can use to do inference. \\
 \\
ABC algorithms are a collection of Monte Carlo methods used for calibrating simulators. ABC 자체는 simulator-based model을 calibration한 모델이기 때문에 우리가 Likelihood function에 대해 명시적으로 알 필요가 없다.
- they do not require explicit knowledge of the likelihood function.
- inference is done using simulation from the model (they are `likelihood-free'). \\
ABC methods are popular in biological disciplines, particularly genetics. They are
- Simple to implement
- Intuitive
- Embrassingly parallelizable (MCMC 모델이 아니기 때문에 생기는 성질. multiple chain으로 돌려도 괜찮다는 이야기이다.) MCMC의 사용 상황은 아래의 그림과 같이 도식화된다.
- Can usually be applied \\
 \\
- Proceeds: \\
Target is \(\pi(\theta)f(x \vert \theta)\). When likelihood \(f(x \vert \theta)\) not in closed form, likelihood-free rejection technique of ABC Algorithm is: \\
\(y \sim f(y \vert \theta)\), under the prior \(\pi(\theta)\) (population genetics에서는 prior information이 대단히 강력하다. 따라서 prior에서 샘플을 생산해도 무관하며, ABC의 이러한 성질은 이의 연장선이다.), keep jointly simulating \\
\$
\pi ' \sim \text{prior } \pi(\theta) \textbackslash{}
\textbackslash{}
\text{auxiliary variable } z \sim f(z \vert \theta ' )
\$ \\
until the \(z\) is equal to the observed value \(y\). \(z = y\)라는 결과를 얻을 때까지 위의 과정을 반복. \(z = y\)가 된다면 \$\theta ' \$를 accept. \\
- Proof \\
\$
\textbackslash begin\{alignat\}\{4\}
f(\theta\emph{i) \&\propto \sum}\{z \in \mathcal{D}\} \pi(\theta\_i) f(z \vert \theta\_i) l\_y(z) \&\& \textbackslash{} \\
\&\propto \pi(\theta\_i) f(y \vert \theta\_i) \&\&= \pi (\theta\_i \vert y) \\
\textbackslash end\{alignat\}
\$ \\
- Tolerance Condition \\
When \(y\) is a continuous rv, \(z = y\) is replaced with a tolerance condition, \(\rho(y,z) \le \epsilon\), where \(\rho\) is a \textbf{distance}. \\
Output distributed from \\
\$ \\
\pi(\theta) \ast P\_\theta \left\{ \rho(y,z) \textgreater{} \epsilon \right\} ; ; \propto ; ; \pi \left( \theta \Big \vert \rho(y,z) \textgreater{} \epsilon \right) \\
\$ \\
하지만 이 방법은
- \(\epsilon\) 결정이 어려움
- distance \(d(z,y)\) 계산이 어려움 \\
The idea behind ABC is that the \textbf{summary statistics} coupled with a small tolerance should provide a good approximation of the posterior: 위의 난점을 해결하기 위해 \textbf{summary statistics} \(\eta(z), \eta(y)\)를 사용하여 \(dist\left\{ \eta(z), \eta(y) \right\}\)를 구하여 이를 기준점으로 사용. \\
\$
\begin{align}
\pi_\epsilon (\theta \vert y) &= \int \pi_\epsilon (\theta , z \vert y)dz  \\ &\approx \pi \left( \theta \vert \eta(y) \right)
\end{align}
\$ \\
where \(\eta(y)\) defines a (\textbf{not necessarily sufficient}) statistic. 하지만 대부분의 경우에는 SS를 이용은 함. \\
- Proceeds: \\
For each iteration,
1. Repeat followings until \(\rho \left( \eta(z), \eta(y) \right) \le \epsilon\).
- Generate \(\theta '\) from the prior distribution \(\pi(\cdot)\).
- Generate \(z\) from the likelihood \(f(\cdot \; \vert \theta ' )\).
2 Set \$\theta\_i = \theta ' \$. \\
However, Simulating from the prior is often poor in efficiency. (population genetics에서는 strong prior를 사용했기 때문에 이러한 문제가 표면화되지 않았었음. 그러나 통계적 상황에서는 Bayesian prior를 사용하는 경우도 많으므로 이러한 문제가 유의해짐. 특히 \textbf{non-informative prior}를 쓸 때 poor performance 가능성 높아짐)
- By modifying the proposal distribution on \(\theta\) to increase the density of \(x\)'s within the vicinity of \(y\). \(\theta\)의 proposal 제안할 때 그 과정을 개선한다는 소리.
- By viewing the problem as a conditional density estimation and by developing techniques to allow for larger \(\epsilon\). \(\epsilon\) 잡기가 너무 어려워서 ABC 자체가 애매해짐. summary statistics 따라 \(\epsilon\)이 항상 바뀌고 이거에 대한 규칙성도 현재로서는 없음. Summary Statistics가 모든 정보를 담고 있지 않아서, summary statistics로 \textbf{model selection}을 하려는 시도는 있었지만 실패했음. summary statistics가 담고 있는 정보가 데이터의 성질을 온전히 드러내고 있는지조차도 불명확함.
- By including \(\epsilon\) in the inferential framework. \\
\(\epsilon\) reflects the tension between computability and accuracy.
- As \(\epsilon \rightarrow \infty\), we get observations from the prior, \(\pi(\theta)\).
- If \(\epsilon=0\), we generate observations from \(\pi(\theta \vert D)\). posterior에서 뽑는 것이라고 생각할 수 있다. \(\epsilon=0\)에 가까우면 (최소한 summary statistics로는) \(y=z\) 조건을 만족하는 것. \\
ABC가 사용 불가한 상황은?
- if the data are too high dimensional, we never observe simulations that are `close' to the field data.
- 데이터가 고차원이라면, 데이터의 차원들간의 interaction이 반드시 존재할 수밖에 없으므로, 기존 데이터와 같은 데이터를 생산해내는 것은 사실상 불가능
-Reduce the dimension using summary statistics.
- 1개의 실현값 \(\theta'\) 에서 summary statistics를 10000개 \(\eta(z^{(1)}), \cdots, \eta(z^{(10000)})\) 를 가령 생산한 상황이라면, 이 summary statistics의 distribution이 multimodal이면 절대로 사용불가. \\
\bottomrule
\end{longtable}

\hypertarget{potential-risks-and-remedies-in-abc}{%
\paragraph{Potential Risks and Remedies in ABC}\label{potential-risks-and-remedies-in-abc}}

Non-zero tolerance \(\epsilon\)
- The inexactness introduces a bias in the computed posterior distribution.
- Practical studies of the sensitivity of the posterior distribution to the tolerance.
- sensitivity analysis, specification difficult
- summary statistics를 쓰지 sufficient statistics를 쓰는게 아니기 때문에 필연적으로 information loss가 있고 CI가 넓어짐

Non-sufficient summary statistics
- The information loss causes inflated credible intervals.
- Automatic selection/semi-automatic identification of sufficient statistics. Model validation check.

Small number of models/Mis-specified models
- The investigated models are not representative/lack predictive power.
- Careful selection of models. Evaluation of the predictive power.

Priors and parameter ranges
- Conclusions may be sensitive to the choice of priors. Model choice may be meaningless.
- Check sensitivity of Bayes factors to the choice of priors. Use alternative methods for model validation.

Curse-of-dimensionality
- Low parameter acceptance rates. Model errors cannot be distinguished from an insufficient exploration of the parameter space. Risk of overfitting.
- Methods for model reduction if applicable. Methods to speed up the parameter exploration. Quality controls to detect overfitting.

Model ranking with summary statistics
- The computation of Bayes factors on summary statistics may not be related to the Bayes factors on the original data, which may therefore render the results meaningless.
- Only use summary statistics that fulfill the necessary and sufficient conditions to produce a consistent Bayesian model choice. Use alternative methods for model validation.

Implementation
- Low protection to common assumptions in the simulation and the inference process.
- Sanity checks of results.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{abcifying-monte-carlo-methods}{%
\subsection{ABCifying Monte Carlo Methods}\label{abcifying-monte-carlo-methods}}

Rejection ABC is the basic ABC algorithm: rejection 알고리즘임
- Inefficient as it repeatedly samples from prior More efficient sampling algorithms allow us to make better use of the available computational resource: spend more time in regions of parameter space likely to lead to accepted values.
- allows us to use smaller values of \(\epsilon\), and hence finding better approximations. Most Monte Carlo algorithms now have ABC versions for when we don't know the likelihood

이를 개선하기 위해 제안되는 모델이 아래의 ABC-MCMC 알고리즘

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{abc-mcmc-algorithm}{%
\subsection{ABC-MCMC Algorithm}\label{abc-mcmc-algorithm}}

이 알고리즘에서는 Embrassingly parallelizable 성질을 잃어버리게 된다.

We are targeting the joint distribution

\$
\pi\emph{\{ABC\} (\theta , x \vert D) \propto \pi}\{\epsilon\} (D \vert x) \pi (x \vert \theta) \pi(\theta)
\$

To explore the \((\theta, x)\) space, proposals of the form

\$
Q \left( (\theta, x), (\theta`, x') \right) = q(\theta, \theta`) \pi (x' \vert \theta ' )
\$

seem to be inevitable.

The MH acceptance probability is then

\$
\begin{align}
r &= \dfrac{\pi_{ABC} (\theta' , x' \vert D) Q \left( (\theta', x'), (\theta, x) \right)}{\pi_{ABC} (\theta , x \vert D) Q \left( (\theta, x), (\theta', x') \right)} \\


&= \dfrac{\pi_{\epsilon} (D \vert x') \pi (x' \vert \theta') \pi(\theta')}{\pi_{\epsilon} (D \vert x) \pi (x \vert \theta) \pi(\theta)} \dfrac{q(\theta', \theta) \pi (x' \vert \theta )}{q(\theta, \theta') \pi (x' \vert \theta ' )}

&= \dfrac{\pi_{\epsilon} (D \vert x')  \pi(\theta')}{\pi_{\epsilon} (D \vert x)  \pi(\theta)} \dfrac{q(\theta', \theta) }{q(\theta, \theta') }

\end{align}
\$

For each iteration,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Repeat followings until \(\rho \left( \eta(z), \eta(y) \right) \le \epsilon\).

  \begin{itemize}
  \tightlist
  \item
    Propose \(\theta '\) from a transition kernel \(g(\theta ' \vert \theta^{(t)})\)
  \item
    Generate \(z\) from the likelihood \(f(\cdot \vert \theta ')\)
  \end{itemize}
\item
  accept or stay \$ =

  \begin{cases} \theta ' & \text{with probability MH ratio } \alpha = \min \left( 1, \; \; \dfrac{\pi(\theta ')}{\pi(\theta^{(t)})} \dfrac{g(\theta^{(t)} \vert \theta ')}{g(\theta ' \vert  \theta^{(t)} )} \right) \\ \theta & o.w. \end{cases}

  \$
\end{enumerate}

즉 \(\theta '\)를 MH 알고리즘에서 생산하며, MH 알고리즘에서 생산하였으므로 \(z\)와 \(\theta '\) 양쪽 모두가 수용할지 여부의 평가 대상. \(z\)가 수용되지 않았다면 \(\theta '\)도 수용되지 않고 \(\theta'\)를 새로 생산한다.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sequential-abc-algorithms}{%
\paragraph{\texorpdfstring{\sout{Sequential ABC Algorithms}}{Sequential ABC Algorithms}}\label{sequential-abc-algorithms}}

The most popular efficient ABC algorithms are those based on sequential methods.

We aim to sample N particles successively from a sequence of distributions

\$
\pi\_1 (\theta) , \cdots, \pi\_T (\theta) = \text{target}
\$

For ABC, we decide upon a sequence of tolerance \(\epsilon_1 >\epsilon_2 > \cdots > \epsilon_T\), and let \(\pi_t\) be the ABC distribution found by the ABC algorithm when we use tolerance \(\epsilon_t\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{synthetic-likelihood}{%
\paragraph{\texorpdfstring{\sout{Synthetic Likelihood}}{Synthetic Likelihood}}\label{synthetic-likelihood}}

The synthetic likelihood approach of Wood (2010) is an ABC algorithm which uses a Gaussian likelihood. However, instead of using

\$
\begin{align}

\pi_\epsilon(D \vert X) &= N(D; X, \epsilon) \\
\pi_{ABC}(D \vert \theta)  &= \int N(D; X, \epsilon)\pi(X \vert \theta) dX

\end{align}
\$

they repeatedly run the simulator at \(\theta\), generating \(X_1, \cdots, X_n\), and then use

\$
\pi(D \vert \theta) = N \left( D ; \mu\emph{\theta , \Sigma}\theta \right)
\$

where \(\mu_\theta\) and \(\Sigma_\theta\) is the sample mean and covariance of the (summary of the) simulator output.

\hypertarget{hamiltonian-monte-carlo}{%
\section{Hamiltonian Monte Carlo}\label{hamiltonian-monte-carlo}}

RW의 단점 (randomness에서 오는 inefficiency를 줄이기 위해) 을 보완하기 위해 나온 개념.

Hamiltonian Monte Carlo borrows an idea from physics to suppress the local random walk behavior in the Metropolis algorithm, thus allowing it to move much more rapidly through the target distribution.

Version of Metropolis where you take many ``steps'' per ``iteration''

Use ``Hamiltonian dynamics'' and a latent ``momentum (\(\phi_j\))'' vector so the steps within an iteration move along a ``trajectory''.

Requires computation of gradient of log target density. 한번의 스텝에서 어느정도 움직이는지를 알기 위해선 이것이 요구되기 때문.

Take \(L\) leapfrog steps (leapfrog를 몇번을 할 것인지), each of distance \(\epsilon\) (1번의 leapfrog에서 얼마만큼을 움직일 것인지), then accept/reject.

In a leapfrog step, both \(\theta\) and \(\phi\) are changed, each in relation to the other.

Effecitive Sample Size \(=ESS/S\): correlated되지 않았을 경우에 샘플 사이즈로 볼 수 있는 크기. MCMC는 과거 체인에 dependent하므로 당연히 correlated되어 있으며, 따라서 10000개를 생산했다고 치면 10000개의 샘플 사이즈에서 independent한 샘플의 사이즈가 얼마만큼인지를 체크하는 것. 따라서 ESS가 크면 클 수록 좋음. 마지막에 computation time \(S\)로 나누어준 이유는 단위시간 당 샘플로 비교해야 하니까. 해당 개념은 알고리즘 comparison에서 대단히 많이 사용됨.

Rstan은 GS가 아니라 HMC를 사용함. 그래서 샘플 크기가 상대적으로 작아도 OK.

How far to jump in each step?
- If \(\epsilon\) is too small, you waste time shuffling along.
- If \(\epsilon\) is too large, the physical approximation breaks and you find yourself rejecting.

How many steps? (No U-turn Sampler)
- If \(L\) is too small, you might not go far enough in each iteration.
- If \(L\) is too large, you'll waste time circling around and around.

Still HMC can be much better than Gibbs or Metropolis in high dimensions.

Energy Barrier. Multimodal에 취약.

\begin{itemize}
\tightlist
\item
  Proceeds:
\end{itemize}

우선 momentum부터 만들어야 함. 운동에너지를 위치에너지로 바꾸는 것이 Hamiltonian의 기본적인 메커니즘. 이때 운동에너지 + 위치에너지는 항상 일정한 상수로 일정하다. 이를 위해 momentum을 생산해야 하는데, 이때 가장 손쉽게 momentum을 생산할 수 있는 방법이 \(M=I\) 로 잡는 것. 단, 어떤 측면에서는 \(I\)가 inefficient하기도 함. 다른 제안으로 Inverse Fisher's Information 사용이 제안된 적도 있음. \textbf{하지만 중간중간에 fixed point iteration으로 패러미터를 정해줘야 한다고?} 경사가 완만할 때 더 많은 거리 이동 가능.

A. The iteration begins by updating \(\phi\) with a random draw from its posterior distribution - which is the same as its prior distribution \(\phi \sim N(0, M)\).

B. A simultaneous update of \((\theta, \phi)\) conducted in an elaborate but effective fashion via a discrete mimicking of physical dynamics. B step의 1회 이터레이션이 leapfrog Step 1회에 해당한다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the gradient of the log-posterior density of \(\theta\) to make a half-step of \(\phi\).
\end{enumerate}

\$
\begin{align}

\phi_{half.new} \; \; \; &\leftarrow \; \; \; \phi + \dfrac {1}{2} \epsilon \ast \dfrac{d \log \pi(\theta \vert y)}{d \theta} \\

&= \; \; \; \dfrac{1}{2} \epsilon \bigtriangledown_{\pmb \theta} \log f(\theta^\ast) \\

&= \; \; \; \phi + \dfrac {1}{2} \epsilon \ast \dfrac{d \log \pi(\theta \vert y)}{d \theta} \Bigg \vert_{\theta^\ast}

\end{align}
\$

\{:start=``2''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Use the `momentum' vector \(\phi\) to update the `position' vector \(\theta\):
\end{enumerate}

\$
\theta ; ; ; \leftarrow ; ; ; \theta + \epsilon \ast M\^{}\{-1\} \phi
\$

\{:start=``3''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the gradient of \(\theta\) to half-update \(\phi\):
\end{enumerate}

\$
\phi\emph{\{new\} ; ; ; \leftarrow ; ; ; \phi}\{half.new\} + \dfrac {1}{2} \epsilon \ast \dfrac{d \log \pi(\theta \vert y)}{d \theta}
\$

C. label \(\theta^{t-1}, \phi^{t-1}\) as the value of the parameter and momentum vectors at the start of the leapfrog process and \(\theta^{\ast}, \phi^{\ast}\) as the value after the \(L\) steps. In the accept-reject step, we compute

\$
r = \dfrac{\pi(\theta^{\ast} \vert y)}{\pi(\theta^{t-1} \vert y)} \dfrac{\pi(\phi^{\ast})}{\pi(\phi^{t-1})}
\$

D. Set \(\theta^t = \begin{cases} \theta^\ast & \text{with probability } \min(1,r) \\ \theta^{t-1} & o.w. \end{cases}\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{hmc-example-trajectory}{%
\paragraph{HMC Example Trajectory}\label{hmc-example-trajectory}}

\begin{itemize}
\tightlist
\item
  Blue ellipse is contour of target distribution
\item
  Initial position at black solid circle.
\item
  Arrows indicate a U-turn in momentum
\end{itemize}

``One practical impediment to the use of Hamiltonian Monte Carlo is the need to select suitable values for the leapfrog stepsize, \(\epsilon\), and the number of leapfrog steps \(L\). Tuning HMC will usually require preliminary runs with trial values for \(\epsilon\) and \(L\). Unfortunately, preliminary runs can be misleading\ldots.''

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{introduction-to-hamiltonian-monte-carlo}{%
\subsection{Introduction to Hamiltonian Monte Carlo}\label{introduction-to-hamiltonian-monte-carlo}}

Hamiltonian Monte Carlo (HMC) was originally developed in the late 1980s as Hybrid Monte Carlo to tackle calculations in Lattice Quantum Chromodynamics, a field focused on understanding the structure of the protons and neutrons.

Neal (1995, 2011) introduced the Hamiltonian Monte Carlo into the mainstream of statistical computing.

HMC is built upon a rich theoretical foundation, which is formulated in terms of differential geometry, that makes it uniquely suited to the high-dimensional problems of applied interest.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{foundations-of-hamiltonian-monte-carlo}{%
\paragraph{Foundations of Hamiltonian Monte Carlo}\label{foundations-of-hamiltonian-monte-carlo}}

Most Markov Transitions are diffusive, concentrating around the initial point such that the corresponding MArkov chains linger in small neighborhoods of the typical set for long periods of time. In order to maximize the utility of our computational resources, we need coherent Markov Transitions that are able to glide across the typical set towards new, unexplored neighborhoods.

In order to make large jumps away from the initial point, and into new, unexplored regions of the typical set, we need to exploit information about the geometry of the typical set.

HMC is the unique procedure for automatically generating this coherent exploration for sufficiently well-behaved target distributions.

Introduce some intuition to motivate how we can generate the desired exploration by carefully exploiting the differential structure of the target probability density.

Discuss the procedure with the complete construction of the Hamiltonian Markov transition.

A vector field is the assignment of a direction at every point in parameter space. When those directions are aligned with the typical set, we can follow them like guide posts, generating coherent exploration of the target distribution.

When the sample space is continuous, a natural way of encoding this direction information is with a vector field aligned with the typical set.

A vector field is the assignment of a direction at every point in parameter space, and if those directions are aligned with the typical set then they act as a guide through this neighborhood of largest target probability.

By construction this, we follow the direction assigned to each at point for a small distance.

Continuing this process traces out a coherent trajectory through the typical set that efficiently moves us far away from the initial point to new, unexplored regions of the typical set as quickly as possible.

The gradient of the target pdf encodes information about the geometry of the typical set, but not enough to guide us \textbf{through} the typical set by itself. Follwing along the gradient instead pulls us away from the typical set and towards the mode of the target density. In order to generate motion through the typical set we need to introduce additional structure that carefully twists the gradient into alignment with the typical set.

Need to construct a vector field aligned with the typical set using only information that we can extract from the target distribution.

The natural information is the differential structure of the target distribution which we can query through the gradient of the target probability density.

The gradient defines a vector field in parameter space sensitive to the structure of the target distribution.

Unfortunately, that sensitivity is not sufficient as the gradient will never be aligned with the typical set. Following the guidance of the gradient pulls us away from the typical set and towards the mode of the target density.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Without enough transverse momentum to balance againts the gravitational attraction of the planet, a satellte will still crash into the planet.
\item
  On the other hand, if the satelite is given too much momentum then the gravitational attraction will be too weak to capture the satelite in a stable orbit, which will instead abandon the planet for the depths of space.
\end{enumerate}

When we introduce exactly the right amount of momentum to the physical system, the equations describing the evolution of the satelite define a vector field aligned with the orbit. The subsequent evolution of the system will then trace out orbital trajectories.

The gradient can direct us towards only parameterization sensitive neighborhoods like that around the mode, and not the parameterization-invariant neighborhoods within the typical set.

To utilize the information in the gradient we need to complement it with additional geometric constraints, carefully removing the dependence on any particular parameterization while twisting the directions to align with the typical set.

If we add the right amount of momentum, then the momentum will exactly balance against the gradient information, and the corresponding dynamics of the system will be conservative.

The key is twisting the gradient vector field into a vector field aligned with the typical set, and hence once capable of generating efficient exploration, is to expand our original probabilistic system with the introduction of auxiliary momentum parameters.

There is only one procedure for introducing auxiliary momentum with such a probabilistic structure: Hamiltonian Monte Carlo.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{phase-space-and-hamiltons-equations}{%
\paragraph{Phase Space and Hamilton's Equations}\label{phase-space-and-hamiltons-equations}}

A defining feature of conservative dynamics is the preservation of volume in position-momentum phase space. For example, althou dynamics might compress volumes in position space, the corresponding volume in momentum space expands to compensate and ensure that the total volume is invariant. Such volume-preserving mapping are also known as \textbf{shear} Transformations.

Conservative dynamics in physical systems requires that volumes are exactly preserved.

As the system evolves, any compression or expansion in position space must be compensated with a respective expansion or compression in momentum space to ensure that the volume of any neighborhood in position-momentum \textbf{phase space} is unchanged.

In order to mimic this behavior in our probabilistic system we need to introduce auxiliary momentum parameter, \(p_n\), to complement each dimension of our target parameter space, \(q_n\), expanding the D-dimensional into a 2D-dimensional phase space.

\$
q\_n \rightarrow \left( q\_n, p\_n \right)
\$

Moreover, these auxiliary momentum have to be dual to the target parameters, transforming in the opposite way under any reparameterization so that phase space volumes are invariant.

Having expanded the target parameter space to phase space, we can lift the target distribution onto a joint probability distribution on phase space called the canonical distribution. Then, the choice of a conditional probability distribution over the auxiliary momentum, \$ \pi(q, p) = \pi(p \vert q) \pi(q) \$, which ensures that if we marginalize out the momentum we immediately recover our target distribution.

By constructing a probability distribution on phase space that marginalizes to the target distribution, we ensure that the typical set on phase space projects to the typical set of the target distribution. In particular, if we can construct trajectories that efficiently explore the joint distribution (black) they will project to trajectories that efficientyl explore the target distribution (green).

The canonical density \(\pi(q, p)\) does not depend on a particular choice of parameterization, and we can write it in terms of an invariant \textbf{Hamiltonian} function, \(H(q, p)\),

\$

\pi(q,p) = \exp \left( - H(q, p) \right)

\$

Because \(H(q, p)\) is \textbf{independent of the details of any parameterization}, it captures the invariant probabilistic structure of the phase space distribution and, the geometry of its typical set.

The value of the Hamiltonian at any point in phase space is called the energy at that point.

Hamiltonian decomposes into two terms, Density over the auxiliary momentum, \(K(p,q)\) is called the \textbf{kinetic energy} (unconstrained and specified by the implementation), while the term corresponding to the density of the target distribution, \(V(q)\) is known as the \textbf{potential energy} (determined by the target distribution).

\$

H(q,p)

\equiv

\begin{itemize}
\tightlist
\item
  \log \pi(q,p) = - \log \pi(p \vert q) - \log \pi(q)
\end{itemize}

\equiv K(p,q) + V(q)

\$

Because the Hamiltonian captures the geometry of the typical set, it should be able to use it to generate a vector field oriented with the typical set of the canonical distribution.

The desired vector field can be generated from a given Hamiltonian with

\$

\dfrac{dq}{dt}

= + \dfrac{\partial H} \{\partial p\}

= \dfrac{\partial K} \{\partial p\},

; ; ; ; ;

\dfrac{dp}{dt}

= - \dfrac{\partial H} \{\partial q\}

= -\dfrac{\partial K} \{\partial q\} -\dfrac{\partial V} \{\partial q\}

\$

By channeling the gradient through the momentum instead of the target parameter directly, Hamilton's equations twist differential information to align with the typical set of canonical distribution.

Following the Hamiltonian vector field for some time, \(t\), generates trajectories \(\phi_t (q, p)\), that rapidly move through phase space while being constrained to the typical set.

Projecting these trajectories back down onto the target parameter space finally yields the efficient exploration of the target typical set for which we are searching.

Every Hamiltonian Markov Transition is comprised of a random lift from the target parameter space onto phase space (light red), a deterministic Hamiltonian trajectory through phase space (dark red), and a projection back down to the target parameter space (light red).

\begin{itemize}
\tightlist
\item
  Need a mechanism for introducing momentum to a given point in thetarget parameter space.
\end{itemize}

To lift an initial point in parameter space into one on phase space, we simply sample from the conditional distribution over the momentum, \(p \sim \pi(p \vert q)\).

Once on phase space we can explore the joint typical set by integrating Hamilton's equations for some time, \((q,p) \rightarrow \phi_t (q,p)\). By construction these trajectories coherently push the Markov transition away from the initial point, and neighborhoods that we have already explored, while staying confined to the joint typical set.

After integrating Hamilton's equations, we can return to the target parameter space by simply projecting away the momentum, \((q,p) \rightarrow q\).

\hypertarget{population-monte-carlo}{%
\section{Population Monte Carlo}\label{population-monte-carlo}}

Population-Based MCMC. population이란? 즉, multiple 체인을 돌린다는 것. 로컬 트랩 문제를 회피하기 위해서. 이는 이하의 조건을 탄다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  각 체인이 가지는 분포는 서로 달라야 하지만, 아예 그 분포들끼리 아예 무관해서는 안된다. (2번을 위해)
\item
  체인들 간에 정보의 교환이 이루어져야 한다. 서로가 가지고 있는 정보를 공유하는 것으로 체인들의 타겟 분포로의 수렴을 가속시키는 것이 이 여러개의 체인의 존재 목적이기 때문이다.
\end{enumerate}

이는 패러렐 컴퓨팅을 가능하게 한다.

\begin{itemize}
\tightlist
\item
  Embarrassingly Parallel MCMC
\end{itemize}

언급하였듯 위의 다중체인은 서로간에 정보의 교환이 이루어져 속도가 다소 느려지는 측면이 분명히 생긴다. 이러한 발목잡힘을 피하기 위해 체인간의 정보교환이 전혀 없는 MCMC.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

타겟분포 \(f(x)\)에서 샘플 생산.

f(x\_1 , \cdots, x\_N)=\prod\_\{i=1\}\^{}N f\_i (x\_i)

이때 f(x)와 f\_i(x\_i) 사이에는 반드시 연관이 존재해야 하며, 적어도 하나의 i값에 대해 f(x) = f\_i(x\_i)를 만족해야 함.

N은 체인의 갯수, 혹은 population의 size.

\hypertarget{adaptive-direction-sampling}{%
\subsection{Adaptive Direction Sampling}\label{adaptive-direction-sampling}}

가장 기본적인 형태. 여러개의 체인을 돌린 후 특정 방향으로 다른 샘플을 이동시키는 방법.

\hypertarget{conjugate-gradient-mc}{%
\subsection{Conjugate Gradient MC}\label{conjugate-gradient-mc}}

\hypertarget{parallel-tempering}{%
\subsection{Parallel Tempering}\label{parallel-tempering}}

temperature 개념 사용. 따라서 T\_1\textgreater T\_2\textgreater{}\cdots\textgreater T\_n=1 이어야 하며, T\_n은 타겟분포에 상응한다. 이때 각 temperature에 대응하는 pdf f\_i(x) \propto \exp \left( -\dfrac{H(x)}{T_i} \right)

simulated tempering은 temperature를 생산해서 해당 temperature를 accept한 후 해당 temperature로 이동.
Parallel Tempering은 n개의 온도에 대응하는 체인 n개를 만들어 각각의 온도에 대응시킨 후 n개의 체인을 병렬적으로 돌림. 이때 높은 온도인 T\_1은 넓은 space를 탐색하고 낮은 온도인 T\_n은 좁은 space를 탐색. 이때 태생의 온도에 따라 탐색시키는 것은 탐색 효율이 떨어지므로 체인이 일정 경과할 때마다 swapping (Exhange) opertation을 하여 출신 이외의 다른 체인과 서로 바꿈. 이 바꿈은 인접한 체인과만 발생. 이를 통해 상황이 맞아떨어지면 T\_1 출신의 탐색자가 T\_n까지 가서 탐색하는 상황도 나올 수 있음. 이러한 swapping opertation을 Auxiliary Variable Generation까지 확장시킨 것이 Exhange Algorithm.

Proceeds:
1. local MH. MH 알고리즘을 통해 X\_i\^{}\{(t)\} \rightarrow X\_i\^{}\{(t+1)\} 로 업데이트.
2. Exhange 스텝. 인접한 체인이 2개라면 각각으로 이동할 확률을 0.5로 잡고, 1개라면 서로밖에 교환 못하니 이는 1로 설정. 이후 해당 교환을 accept할지 여부는 확률 \min \left\{ 1, ; ; ; \exp \left[ \left\{ \dfrac{1}{T_i} - \dfrac{1}{T_j} \right\}  \right] \right\}에 따라 결정. 이외면 교환 안 한 채로 남긴다.

이를 고차원으로 확장시키면 Sequential Parallel Tempering.

\hypertarget{exchange-algorithm-1}{%
\paragraph{Exchange Algorithm}\label{exchange-algorithm-1}}

\hypertarget{evolutionary-mc}{%
\subsection{Evolutionary MC}\label{evolutionary-mc}}

Combinatorial Optimization Problem, 무수히 많은 조합 중에 local optimal 찾는 문제에서 가장 자주 사용되는 방법론인 genetic Algorithm, 의 MC 버전이라고 볼 수 있다. 다른 모델, 크로스오버 (스위치), 뮤테이션.

다만 Evolutionary MC 자체는 Combinatorial Optimization을 푼다기보단 Multimodal 문제를 푸는 용도에 가까움. genetic Algorithm과 Evolutionary MC 둘 모두 local mode를 찾는 알고리즘, \textbf{local Trap} 문제를 해결하는 알고리즘.

또한 Evolutionary MC는 local trap 해결 이외에 Variable Selection에도 아주 유용하며 자주 사용됨. 이 Variable Selection 자체가 일종의 Combinatorial Optimization 문제로 생각될 수 있음. 가용 변수의 조합 중 어떤 조합을 써야 효율이 잘 나올 것인가를 고민하는 거니까.

Evolutionary MC 또한 temperature 개념을 사용하므로 parallel Tempering과 유사. 온도 설정과 온도에 따른 체인 설정 후 탐색은 완전히 똑같지만, parallel tempering의 swapping operator가 바로 인접한 체인과의 교환만 발생했던 반면 evolutionary MC는 crossover operator를 사용하여 인접한 것만이 아닌 모든 체인 중에 교환할 체인을 선정. 이렇게 교환 범위가 넓기 때문에 parallel tempering보다 성능이 훨씬 좋음.

Proceeds:
1. Mutation은 자주 일어나는 일이 아니므로 확률로 판정하여 Mutation과 Crossover 둘 중 하나만 일어나도록 함. Mutation의 확률은 q\_m, Crossover의 확률은 1-q\_m. 이 확률 q\_m은 uniform에서 획득. 잘 모르면 0.5.
1. Local MH. 이는 genetic Algorithm에서의 Mutation에 대응. x\_1 , \cdots, x\_N 중 1개를 균일확률로 선정해서 뽑고 뽑은 그 x\_k 1개에 대응하는 y\_k = x\_k + e\_k 를 만들어 이로 대체할 것을 제안. 이는 \min(1, r\_m)의 확률로 accept되고, 이때 accpetance ratio r\_m = \exp \left\{ - \dfrac{H(y_k) - H(x_k)}{T_k}\right\} \dfrac{T(x \vert y )}{T(y \vert x )}. 이때 뒤쪽의 fraction은 proposal density에 해당.
2. Crossover Operator: (1) 현 population \pmb x에서 x\_i를 고른 후, (2) \pmb x / x\_i 에서 x\_j 를 고른다. 이때 x\_j를 선정할 때 \exp \left( - \dfrac {H(x_k)}{T_S = T_i} \right)의 확률에 따라 선정한다. k는 앞서 선정되었던 i를 제외한 모든 수. (3) e=x\_i - x\_j, y\_i = x\_j + r \ast e. 이때 r은 direction에 해당하며 모든 실수일 수 있고, r의 선정은 density f(r) \propto \vert r \vert \^{}\{d-1\} f(x\_i + re)에 따른다. (4) 여기서 획득한 y\_i로 x\_i를 교체한 후 이렇게 교체한 집합을 새로운 population으로 삼는다.
3. Exchange 스텝. 이를 통해 X 내용물을 구성하는 \(x_i\), 즉 각 온도 H(x\_i) 에 대응하는 chromosome들의 교환이 이루어짐. Exchange Operator: parallel tempering과 마찬가지로 양옆의 것들과 확률 판정해서 교환.

\hypertarget{sequential-parallel-tempering}{%
\subsection{Sequential Parallel Tempering}\label{sequential-parallel-tempering}}

\hypertarget{stochastic-approximation-monte-carlo}{%
\section{Stochastic Approximation Monte Carlo}\label{stochastic-approximation-monte-carlo}}

Neural Network의 Multimodality issue. 패러미터는 p개인데 equation은 q개. q가 p보다 훨씬 작아서 관계성이 식으로밖에 나오지 않음. 따라서 identifiability 이슈가 발생하기 때문. gradient descent 방법으로 최적해 찾아내다 뭐 이렇게 말을 하는데 사실 이걸 최적해로 말할 수 없음.

combinatorial optimization에도 로컬 최적해가 다수 존재하고 글로벌 최적해 파악이 어려우므로 유사하게 multimodal issue 존재.

SAMC는 과거의 샘플 전체를 이용하므로 Monte Carlo긴 하나 MCMC는 아님.

에너지 펑션 \(-\log \psi (x)\), \$ \psi (x)\$는 unnormalized density. 이 에너지 펑션을 U(X)로 둔다면 이는 결국 y축에 대응되는 값. 이 U(X)를 파티션한다. 이렇게 나눈 영역 E\_i들은 각각 고유한 weight를 보유하고 있음. 난수 1개를 샘플링했을 때 이 난수가 영역 E\_i에서 나왔다고 한다면, 이 영역 E\_i에 배정되었던 weight를 줄이고 다른 모든 구간의 weight를 높인다. 이를 통해서 모든 영역에서의 고른 샘플링을 기대할 수 있음. 이 weight의 증감량을 얼마만큼 시킬 것인지가 stochastic Approximation을 통해서 얻어짐.

이를 모두 반영한 식은

c \psi(x) \propto \sum\_\{i=1\}\^{}m \dfrac{\psi(x)}{\tfrac{exp(\theta^{(i)}}{\pi_i}} I(X \in E\_i)

이때 이의 denominator는 E\_i에 대한 weight이며, 이것이 결국 c에 대응하는 부분인데 영역이 partition되었으므로 이를 mixture distribution의 형태로 나타내줌.

여기서 \theta\^{}\{(i)\}=log g\_i이고, g\_i = \int\_\{E\_i\} \psi(x). 따라서 이를 exp의 승으로 만드는 것은 log를 취했던 것을 벗기는 작업임.

\pi\_i : 구간 i에서 얼마만큼의 샘플을 생산할 것인가. 보통은 구간별 생산 갯수를 동일하게 하는 것을 목적으로 함. 이에 의해서 보통 이 알고리즘을 flat-histrogram 알고리즘이라고 부름.

gain factor sequence \{ \gamma\emph{k \}}\{k=0\}\^{}\infty. 이는 Stochastic Approximation에 필요함. gain factor \gamma\_k = \dfrac{t_0}{\max (t_0, t)} . 이때 t\_0는 prospected value. 따라서 첫 이터레이션때는 1로 유지되고, 이후에 빠르게 감소함. 따라서 weight도 이에 영향받아 첫번째 이터레이션때는 일정하게 유지되다가 이후에 떨어진다. t\_0가 크면 수렴이 빠르지만 그렇기 때문에 지나치게 커서는 안됨.

이렇게 생산한 샘플을 그냥 써서는 안되고, 획득한 샘플 \theta\^{}\{(t)\}와 weight \exp(theta\^{}\{(t)\} )= g\_i를 사용하여 Importance Sampling을 한번 해서 그 결과물을 사용해야 함.

????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

3시 18분

\hypertarget{review}{%
\section{Review}\label{review}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wk01}{%
\subsection{Wk01}\label{wk01}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the inverse-CDF method and state how we can generate random numbers from \(W(\alpha, \beta)\).
\end{enumerate}

inverse-CDF method는, 우리가 알다싶이 \(0 \le F(x) \le 1\). 즉 \(F(x) \sim U(0,1)\)나 다름없다. \(u \sim U(0,1)\)을 하나 샘플링. 이는 \(F(x)\)의 range와 일치한다. 따라서 \(F(x)=u \iff x=F^{-1} (u)\).

\begin{itemize}
\tightlist
\item
  Weibull Dist: shape parameter \(k\), scale parameter \(\lambda\)에 대해
\end{itemize}

\$
f(x) =

\begin{cases} \left( \dfrac {k}{\lambda} \right) \left( \dfrac {x}{\lambda} \right)^{k-1} \exp{- \left( \dfrac{x}{\lambda} \right) } & x\ge 0 \\ \\ 0 & o.w. \end{cases}

\$

let quantity \(X\) is ``time-to-failure''.

\$
\begin{align}
F(x) = 1- \exp{- \left( \dfrac{x}{\lambda} \right) } &= u \\
\Longrightarrow x &= \lambda \left[ -\log (1-u) \right]^{\tfrac{1}{k}}

\end{align}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  State the RS algorithm.
\end{enumerate}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.25}}@{}}
\toprule
& target density \(f(x)\) & proposal density \(g(x)\) & envelope density \(e(x) = c \ast g(x)\) \\
\midrule
\endhead
evaluate & easy & easy & \\
generate & difficult & easy & \\
& & & cover all areas of \(f(x)\), in all parameter supports, \(f(x) \le e(x)\) \\
\bottomrule
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  State how we can generate random numbers using RS.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    generate sample \(x\) from \(g(x)\)
  \item
    generate \(u \sim U(0,1)\)
  \item
    위에서 언급하였듯, envelope는 proposal의 상수배이며, envelope는 target보다 항상 크므로 \(\dfrac{f(x)}{e(x)}\)는 항상 0 이상이며 1 이하. 이는 곧 \(U(0,1)\)에서 생산되는 값과 동일한 분포를 지니며, \(e(x)\) 아래의 값들 중 \(f(x)\) 아래에도 해당하는 값들은 곧 \(f(x)\)에서 생산된 난수라고 볼 수 있었다. 따라서 if \(u \le \dfrac{f(x)}{e(x)}\), sample \(x\)를 accept, 이외엔 reject.
  \end{enumerate}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wk03}{%
\subsection{wk03}\label{wk03}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  State one iteration of squeezing RS.
\end{enumerate}

\(f(x)\)가 evaluate 자체는 가능한데 그거조차도 비용이 expensive 한 경우를 가정. \(f(x)\)가 샘플 generate가 어려우니 RS를 쓰는건데 평가 비용조차 높으니 샘플링 과정이 비효율적일 수밖에 없음. 따라서 squeeze function \(s(x)\)를 설정하여 확실하게 \(f(x)\)에 속하는 샘플들은 먼저 우선선발 시켜서 패스시키고, 우선선발이 아닌 샘플들만 \(f(x)\)를 직접 사용해서 조건을 통과하였는지 여부를 체크. 당연하지만 \(s(x)\)는 모든 support에서 \(f(x)\)보다 작아야 하며, evaluate 비용이 cheap해야 함.

proceeds:
1. \(Y \sim g\)에서 샘플링.
2. sample \(u \sim U(0,1)\).
3. if \(U \le \dfrac {s(Y)}{e(Y) = c \ast g(y)}\), keep \(Y\).
4. if not, whether if \(U \le \dfrac {f(Y)}{e(Y)}\), keep \(Y\).
5. both are not, reject \(Y\).

이때 \(s(x)\)를 생산하기 위해 Talyor Series Expansion을 사용하는 경우 잦다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  State the adaptive RS.
\end{enumerate}

Make envelope function \(e(x)\) adaptively to the shape of \(f(x)\).

adaptive RS 자체에는 제약이 있다. 이는 log concave function인 density에만 적용이 가능하다는 것. 즉슨 multimodal인 density에는 적용이 불가하다. 이 제약을 해소하기 위해 Adaptive Rejection Metropolis Sampling이 존재.

\textbf{mode가 필수라는 게 RS 자체가 mode가 필수라는 소리인가?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  State the Importance Sampling
\end{enumerate}

\(\mu = E[h(x)]\). 이때 \(h(x)\)는 \(x\)의 함수이며, \(x\)는 \(f(x)\)를 따르므로 \(h(x)\)의 기댓값 계산 또한 이를 따르지만, 이는 기댓값 계산에서 density를 \(g\)로 바꾸고 이의 각 확률에 발생하는 값들을 \(h \ast \dfrac{f}{g}\)로 바꾸는 것과 다르지 않음. 이는 \(f\)에서 샘플 생산이 힘들때 \(f\)를 거치지 않고도 샘플을 생산하여 기댓값을 계산할 수 있다는 점에서 빛을 발함. 즉 확률은 \(g\)를 참조하고, 이 확률에서 발생하는 값들이 있을 것이고, 이 값들을 다시 한번 함수에 넣어서 역변환하면 \(f\)의 확률에서 발생했었을 각 값들을 획득하는 것이 가능하다는 소리.

이러한 역변환 함수에서 \(f, g\)가 차지하는 부분을 weight라고 부르는 것이고, 이를 weight의 총합으로 표준화하면 standardized weight.

\(g\)의 support가 \(f\)의 그것을 다 덮을 필요는 없음. 하지만 1. \(\dfrac{f}{g}\)는 bounded여야 하고, 가장 중요하게, \(g\)는 \(f\)보다 꼬리가 두꺼워야 함. 이는 극단적인 \(x\)값이 나왔을 때 \(g\)의 확률이 \(f\)보다 지나치게 작으면 해당 부분에서의 weight가 너무너무 커져서 다른 샘플 실값들의 영향력을 다 잡아먹어버리는 \textbf{weight-degeneracy}가 발생해버리기 때문.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  State the polar methods for generating normal random variable.
\end{enumerate}

\$ X, Y \overset {iid} \{\sim\} N(0,1)\$

f(x,y) = \dfrac{1} \{2\pi\} \exp\left( -\dfrac{1}{2} (x\^{}2 + y\^{}2 )\right)

\(\theta \sim U(0, 2\pi)\), \(R^2 \sim \EXP (\tfrac{1}{2})\).

\(X\)와 \(Y\)를 모은 만큼의 샘플이 \(N\)을 따른다.

\hypertarget{wk04-05}{%
\subsection{wk04, 05}\label{wk04-05}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  State the effect of proposaldensity \(g\) in IS.
\end{enumerate}

과도한 variability를 피하기 위해, \(\dfrac{f}{g}\)로 설정하고 \(g\)가 \(f\)보다 두꺼운 꼬리를 지니도록 설정해야 함. \(g\)가 너무 작으면 weight-degeneracy.

\(h\)가 너무 작다면, \(\dfrac{f}{g}\)를 크게 할 수 있는 \(g\)를 선정한다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  State the antithetic sampling, Control Variate, and Rao-Balckwellization.
\end{enumerate}

antithetic: use two id UE, whose \(Corr(\hat \mu_1 , \hat \mu_2)<0\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  State one iteration of sampling Importance Resampling.
\item ~
  \hypertarget{uxc65c-uxc61buxb0a0uxc5d0uxb294-variance-reduction-uxd558uxace0-uxc694uxc998uxc5d4-uxc548uxd568}{%
  \section{왜 옛날에는 variance reduction 하고 요즘엔 안함?}\label{uxc65c-uxc61buxb0a0uxc5d0uxb294-variance-reduction-uxd558uxace0-uxc694uxc998uxc5d4-uxc548uxd568}}
\end{enumerate}

\hypertarget{else}{%
\section{Else}\label{else}}

\hypertarget{hw4.-rasch-model}{%
\subsection{Hw4. Rasch Model}\label{hw4.-rasch-model}}

\$
\begin{align}

L(\theta, \beta) &= \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}} \\



\pi (\theta, \beta \vert y) &= \pi(\theta) \pi(\beta) \ast \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}}


\end{align}
\$

\$

0\textless{}\left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}\^{}\{y\_\{ki\}\} \textless1, ; ; ; ; ; 0\textless{}\left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}\^{}\{1-y\_\{ki\}\}\textless1

\$

\textbf{underflow problem}. log 취하면 해결.

\$

\pi(\theta\_k) \sim N(0, \sigma\^{}2), ; ; ; ; ; \pi(\sigma\^{}2 ) \sim IG(0.001, 0.001)

\$

update \(\theta_k , k=1, \cdots, n\)"

\$
\log (r) = \log \pi (\theta\emph{k ' \vert y, \beta\^{}\{(t)\}. \theta}\{-k\}\^{}\{(t)\} - \log \pi (\theta\^{}\{(t)\} \vert y, \beta\^{}\{(t)\}. \theta\_\{-k\}\^{}\{(t)\}
\$

if \(\log U < min(\log(r), 0))\), accept. else, reject.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{da-example-mvn}{%
\subsection{DA) Example: MVN}\label{da-example-mvn}}

for DA 알고리즘, I-step과 P-step이 존재.

\hypertarget{i-step}{%
\paragraph{1. I-Step}\label{i-step}}

\$
\begin{alignat}{4}



Y_2 \vert Y_1 &\sim N && \Big( \mu_2 + \Sigma_{21} \Sigma_{11}^{-1} (Y_1 - \mu_1) , && \Sigma_{22}  - \Sigma_{21}\Sigma_{11}^{-1} \Sigma_{12} \Big) \\

Y_{i, mis} \vert Y_{i, obs}, \mu, \Sigma &\sim N_{dim(Y_{mis}^{(i)})} && \Big( \mu_{mis}^{(i)} + \Sigma_{mis, obs}^{(i)} \Sigma_{obs, obs}^{-1} (Y_{i, obs} - \mu_{i, mis}^{(i)}) , && \Sigma_{mis,mis}^{(i)}  - \Sigma_{mis,obs}^{(i)}[\Sigma_{obs,obs}^{(i)}]^{-1} \Sigma_{obs,mis}^{(i)} \Big)

\end{alignat}
\$

상기의 conditional pdf로 우리는 \(Y_{i, mis}\)를 impute 가능.

\textbf{for \(i=1, \cdots, n\), \(Y_{i, mis} \vert Y_{i, obs}\) 에서 \(Y_{i, mis}\)를 draw.}

\hypertarget{p-step}{%
\paragraph{2. P-Step}\label{p-step}}

베이지안 분석을 위해선 prior가 필요. 여기서 prior는 이하로 설정하자. \(q\)는 known integer이며, \(q=p\)인 상황에 이는 \(\Sigma\)에 대한 Jefferey's prior.

\$

\pi (\mu, \Sigma) \propto \vert \Sigma \vert\^{}\{-\tfrac{q+1}{2}\}

\$

위와 같이 식들을 구성하였을 때, com 데이터에 대한 posterior distribution \(\pi(\mu, \Sigma \vert Y_1 , \cdots, Y_n)\)는 이하와 같이 characterized 가능. 이는 inverse-Wishart 분포.

\$

\Sigma \vert Y\_1 , \cdots, Y\_n \sim \dfrac{1}{\vert \Sigma \vert^{-\tfrac{q+n}{2}}} \exp \left\{ -\dfrac{1}{2} tr\left( \Sigma\^{}\{-1\} S \right) \right\}

\$

이렇게 획득해온 패러미터들을 사용해 \(\mu\)의 post를 구하면 이하와 같다.

\$

\mu \vert \Sigma, Y\_1 , \cdots, Y\_n \sim N\_p \left( \bar Y \dfrac {1}{n} \Sigma \right)

\$

\textbf{\(\Sigma \vert Y_1 , \cdots, Y_n\)에서 \(\Sigma\) 를 생산}

\textbf{이후 \(\mu \vert \Sigma, Y_1 , \cdots, Y_n\)에서 \(\mu\) 를 생산}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{bayesian-adaptive-clinical-trial-with-delayed-outcomes}{%
\subsection{Bayesian adaptive clinical trial with delayed outcomes}\label{bayesian-adaptive-clinical-trial-with-delayed-outcomes}}

\hypertarget{continual-reassessment-method}{%
\paragraph{Continual Reassessment Method}\label{continual-reassessment-method}}

Clinical Trial: Toxicity -\textgreater{} Efficacy -\textgreater{} Confirmation

희귀병 케이스에서는 도즈 레벨을 1\textasciitilde n까지 정해둔 후, 샘플을 slice 하여 1번 subsample에 도즈1 투입. 유효하면 (1차시에 3명 투입했다고 하고 그중에 1명이 독성 나왔으면 독성 확률은 1/3. 해당 여부로 도즈2로 넘어갈 것인지를 판단) 2투입. 2에서 문제 생기면 1로 복귀하고 2번 subsample에 도즈1 투입해봐서 유효한지 검증. 이렇게 모든 서브샘플에 도즈레벨 오가면서 투입해보고 최적 도즈레벨 결정.

이때 CRM을 시작하기 전 대략적으로 이정도의 도즈레벨이 최적 도즈레벨일 것이라는 예측 (Skeleton)을 정하고 CRM을 시작함.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  delay outcome
\end{itemize}

이전 환자들의 evaluation이 끝나기 전에 (evaluation period가 경과하기 전이나, 결과가 나오기 전에) 환자 풀이 증가하는 상황

이 상황에서는 관측이 더 된 환자보다 덜 된 환자에서 outcome이 발생할 확률이 높음. 9개월 누워있던 놈보다 2개월 누워있던 놈이 12개월 경과 전에 뭔가 변화를 보이기 쉽다는 소리.

이때 아직 결과를 관찰하지 못한 환자들을 mis로 지정. 이 상황은 누워있던 기간이 결과 발생 여부라는 variant와 직결되어 있으므로 NMAR. 그러니까, 여기서 결과값은 outcome이 발생했는지 안했는지, 그리고 variable은 환자나 누워있던 기간.

위에서 언급했듯 누워있던 기간이 짧으면 변이확률 높음. 따라서 각각에 대해 다른 survival function을 적용하여 각각의 다른 확률 뽑아낸 후 이거 기반으로 DA 진행하면 해결.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{nmaruxc758-uxc885uxb958}{%
\subsection{NMAR의 종류}\label{nmaruxc758-uxc885uxb958}}

\(m_i\)는 missing indicator. \(Y_i\)가 mis면 1.

\$
f(M, Y \vert X, \theta, \psi) = \prod\_\{i=1\}\^{}n f(m\_i , y\_i \vert x\_i , \theta, psi)
\$

interested in \textbf{direct} relationship b/w \(X\) and \(Y\), rather than in subpopulation defined by missing-data pattern.

Selection Model \textbar{} characterize \(y\) \textbar{} missing mechanism \textbar{}\\
\(f(m_i, y_i \vert x_i, \theta, \psi) =\) \textbar{} \(f_y(y_i \vert x_i, \theta)\) \textbar{} \(\ast f_{m \vert y}(m_i \vert x_i, y_i, \psi)\) \textbar{}\\
\(f(m_i, y_i \vert x_i, \xi, \psi) =\) \textbar{} \(f(y_i \vert x_i, \xi)\) \textbar{} \(\ast f(m_i \vert x_i, \xi)\) \textbar{}\\
Pattern Mixture model \textbar{} mis 데이터의 다른 패턴들에 의해 정의되는 각각 다른 strata에서의 \(y_i \vert x_i\)의 분포 \textbar{} probability of different patterns in missingness \textbar{}

missing의 다른 패턴에 따라 \(x_i\)가 결정이 되고, 그 \(x_i\)를 기준으로 놓았을 때의 \(y_i\)의 분포가 궁금.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wk10-bayesian-model-selection}{%
\subsection{wk10) Bayesian Model Selection}\label{wk10-bayesian-model-selection}}

해당 문제는 prior을 어떻게 고르느냐에 따라서 해결될 수 있음. 이하는 해당 문제에 대한 다양한 해결책들.

\hypertarget{spike-and-slab-prior}{%
\paragraph{1. Spike-and-Slab prior}\label{spike-and-slab-prior}}

let \(X_{n \times p} , Y_{n \times 1}\), then \(Y = X \beta\), where \(\beta_{p \times 1}\).

p가 많다, 즉 배리어블이 많다는 이야기는 실제 각각의 x의 정보량이 중첩될 가능성이 큼. 그러면 수학적으로는 x'x가 full rank matrix가 아닐 것이며, 이는 곧 몇몇 변수들 간에 서로간의 의존관계가 강하여 의미없는 정보를 포함하는 변수들이 많아질 것. 이러한 의미없는 변수를 삭제하고 실제로 필요한 변수들만 골라내어 y에 대한 inference를 하고 싶음. 이것이 모델 셀렉션 문제이며 이걸 베이지안적으로 풀어내는 것이 곧 Bayesian Model Selection.

무지성 prior로는 \(\pi(\beta) \sim N(0, \sigma^2)\)가 쓰이지만, 이로는 variable selection이 불가. \(\beta\) 중 하나의 component가 0에 가깝게 나왔다고 한들 이것을 0으로 판정할 indicator가 없기 때문. (HPD interval을 구성해서 이것이 0을 포함하면 내치는 식의 방법도 있지만 일단은.)

따라서 다른 prior를 필요로 함. 바로 여기서 사용되는 것이 \textbf{Spike-and-Slab prior}. 이름에서 알 수 있듯이 mixture distribution을 prior로 사용함. \(\beta\)의 component가 spike 부분에 포함되면 이를 0으로 판정함, 즉 not significant로 판정. 이의 역은 slab part.

이는 곧 prior로 variable selection을 한다는 이야기이다. 즉 이 상황에서는 prior가 패널티로 들어간 것이 된다. 정의적으로 엄밀하게 패널티는 아니지만 사실상의 패널티로 작동. 패널티 term (error penalty)으로 골라내는 것은 full context에서 많이 사용? 이때는 라플라스 프라이어를 쓰고, 노멀을 프라이어 주면? 패널티 텀을 베이지안 인퍼런스로 연결지어서 생각할 수 있지만, 이 배리어블 셀렉션은 디멘션 셀렉션과 연관이 있기 때문에 위와는 정확하게는 다른 개념?

variable selection에는 3가지 방법:
1. 패널티 텀
2. mixture prior
3. 컴퓨테이셔널 (reversible jump, dimension selection) (gradient descent는 아님!)

spike 파트 (아래에서는 \((1-\lambda)N(0, \sigma^2)\)) 에는 double exponential을 쓰거나, normal 을 변형해서 사용함. 혹은 극단적으로는 dirac 분포 (point mass) 를 쓸 수도 있음.

이하에서 예시로 제시된 수식은 SS prior이며, 이는 spike와 slab 모두 Normal을 사용하였음.

\$
\pi(\beta) \sim (1-\lambda)N(0, \sigma\^{}2) + \lambda N(0, \omega \sigma\^{}2), ; ; ; ; ; w \gg 1
\$

위에서 \(\sigma^2\)는 spike variance, \(w \sigma^2\)는 slab variance.

여기서 \(\lambda\)가 취할 수 있는 값은 0 아니면 1. 확인할 수 있듯이 1이면 slab part, 즉 significant하고, 0이면 역으로 not significant. 우리는 이에 MCMC 알고리즘을 적용하게 되며, 따라서 MCMC 샘플로 계산을 하면 해당 샘플에서 0인 propotion과 1인 비율이 나오게 될 것. 이때 1인 비율이 0.5 이상이면? 해당 component (변수) 는 significant 하다고 결론짓는 것이 가능하다.

\$
\begin{alignat}{3}

\pi(\beta, \lambda, \sigma^2, \omega \vert y, x) &\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) && f(y \vert x, \beta, \lambda, \sigma^2, \omega) \\
&\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) &&L( x, \beta, \lambda, \sigma^2, \omega \vert y) \\

\\

\pi(\lambda) &\sim BETA(1,1), \; \; \; \pi(\sigma^2) \sim \cdot \tag{1}, \; \; \; \omega \sim 1 + GAM(\alpha, \beta)

\end{alignat}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  이때 \(\sigma^2\)는 우리가 임의로 fixed 해서 given으로 잡거나, 위처럼 prior로 해서 시뮬레이션 중에 생산되도록 할수도 있다. 여기선 \(\dfrac{1}{U(4,100)}\)을 사용.
\end{enumerate}

accept를 하기 위해선 위를 돌리면 됨. 이는 \textbf{Stochastic Search Variable Selection (SSVS)}라고 불림. 이는 GS를 통하여 패러미터를 sequentially update. 이의 결과값은 다음과 같으며, 프로세스는 그 다음과 같다.

\$
(\beta\_1 , \cdots, \beta\_p, \lambda\_1, \cdots, \lambda\_p, \sigma\^{}2, \omega)
\$

\begin{itemize}
\tightlist
\item
  Proceeds:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    update model parameter \(\beta_i^{(t+1)} \sim \pi( \beta_{i} \vert y, x, \beta_{-i}^{(t)}, \lambda_{i}^{(t)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)

    \begin{itemize}
    \tightlist
    \item
      where \(\beta_{-i}^{(t)} = \left( \beta_{1}^{(t+1)}, \cdots, \beta_{i-1}^{(t+1)}, \beta_{i+1}^{(t)}, \cdots, \beta_{p}^{(t)} \right)\)
    \item
      \textbf{Simple GS로도 가능하고, MH-within-Gibbs로도 가능함}
    \end{itemize}
  \item
    update \(\lambda_I^{(t+1)} \sim \pi(\lambda_i \vert y, x, \lambda_{-i}^{(t)}, \beta_{i}^{(t+1)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)

    \begin{itemize}
    \tightlist
    \item
      where \$P( \lambda\emph{\{i\}\^{}\{(t+1)\} = 1 \vert y, x, \lambda}\{-i\}\^{}\{(t)\}, \beta\_\{i\}\^{}\{(t+1)\}, \{\sigma\textsuperscript{2\}}\{(t)\}, \omega\^{}\{(t)\} )= \dfrac{a} \{a+b\} \sim BER(\tfrac{a} \{a+b\} ) \$.

      \begin{itemize}
      \tightlist
      \item
        \(a = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=1, {\sigma^2}^{(t)}, \omega^{(t)} )\).
      \item
        \(b = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=0, {\sigma^2}^{(t)}, \omega^{(t)} )\),
      \end{itemize}
    \end{itemize}
  \item
    update \(\sigma^2\)
  \item
    update \(\omega\)
  \end{enumerate}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{horseshoe-prior-scale-mixture-prior}{%
\paragraph{2. Horseshoe prior (Scale-mixture prior)}\label{horseshoe-prior-scale-mixture-prior}}

\textbf{distribution에서 scale이란 Variance}.

위와 동일 케이스 가정. 그 경우

\$
\begin{alignat}{4}

\pi(\beta \vert y, x) \propto f(y \vert x, \beta) \pi(\beta), \; \; \; \; \; &\pi(\beta) && \sim N(0, \sigma^2) \\
 
\Longrightarrow &\pi(\beta_i \vert \tau, \lambda_i) && \sim N(0, \tau^2 \lambda_i^2) 

\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  where \(pi(\tau^2), \pi(\lambda_i^2) \sim Cauchy^{+}(0,1)\)
\end{itemize}

이때 common variance component \(\tau\)는 각 component마다 공유하는 1개의 variance component, 그리고 각 component마다 indiviually 고유한 individual parameter variance component \(\lambda_i\)를 설정한 것.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{autologistic-model}{%
\subsection{Autologistic model}\label{autologistic-model}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wk10-bayesian-model-averaging}{%
\subsection{wk10) Bayesian Model Averaging}\label{wk10-bayesian-model-averaging}}

해당 상황에서 연구자는 다양한 모델 예측 후보를 생각해볼 수 있음. 보통은 프로세스를 거쳐 이 모델들 중의 하나를 선택하게 됨. 하지만 완벽한 모델이라는 건 (보통) 존재할 수 없음, 어떤 모델 후보를 선택하든 해당 후보가 내포하고 있는 uncertainty가 존재하며 이를 수용하게 됨. 따라서 모델을 선택한다는 것은 동시에 over-confidence inference 문제를 발생시킨다. 따라서 모델 후보군을 하나만 골라야 한다는 고정관념을 벗어나 다양한 모델 후보군들 각각을 동시에 반영하자. 이 동시 반영할 때 각 모델이 내포하고 있는 확률 (uncertainty)에 의해 각 모델의 반영 정도를 가감하게 된다.

BMA는 패러미터 estimate를 획득할 때, 이러한 model uncertainty를 설명하기 위한 일관된 메커니즘을 제공한다.

given 데이터 \(D\), posterior prob of \(\mathcal{M}_k\) \(= P(\mathcal{M}_k \vert D) = \dfrac{L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}{\sum_{k=1}^k L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}\).

이때 marginal likelihood under \(\mathcal{M}_k)\) \(L(D \vert \mathcal{M}_k) = \int L(D \vert \theta \mathcal{M}_k) \pi(\theta \vert \mathcal{M}_k) d \theta\)이며, integral 안의 수식은 posterior of model의 상수배

In brief, BMA는 model uncertainty를 설명할 수 있는 posterior density를 획득하기 위해 integral을 취한다 (model에 대해 마지널化). (각각의 모델에 대한 model uncertainty를 구한다)

이를 통해 최종적으로 posterior sample 같은 경우에는 각 모델 별로 model probability에 posterior sample의 probability를 다 더해준 값이 실제로 우리의 \(\theta\)에 대한 post가 된다.

즉슨 BMA란 다양한 모델 후보군들이 존재할 때, 그 어떤 상황에서도 robust inference를 가능케 하는 tool이 바로 BMA.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{ex-bma-crm}{%
\paragraph{Ex: BMA-CRM}\label{ex-bma-crm}}

CRM 시작 전에 skeleton 정하고 시작하는 건 자명. 근데 이 skeleton이 잘못 선정되었다면 제대로된 도즈 selection이 불가능해지므로 skeleton의 선정이 잘못되어 있다면 이는 치명적임. 상식적으로, 하나의 skeleton으로만 도즈 셀렉션을 진행한다면 문제가 생길 확률은 당연히 높음. 이런 리스크를 희석하기 위해 skeleton을 다수를 정하고 CRM을 시작하면 이런 문제를 다소 회피할 수 있지 않을까? 이때 이 각각의 스켈레톤 하나하나를 모델로 인식한다. 이 각각의 모델에 따라서 CRM을, 즉 도즈레벨을 업데이트할 확률을, 즉 업데이트 할 때 패러미터 evaluation을 하는데, 그때 나오는 패러미터 값과 그 각각의 모델 probability를 비교하여 그 모델 averaging을 해주면 그 어떤 상황이 와도 굉장히 robust 한 값을 획득할 수 있을 것.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Main research question
\item
  Justification for your research question (why is it important to answer the question?)
\item
  Data source
\item
  Data analysis
\item
  Summary of the data analysis results and conclusion
\item
  Appendix (if needed)
  -- R scripts (scripts or codes for any other software)
\end{enumerate}

1
-- Technical details regarding the statistical tools used in the analysis

비교적 오랜 기간 데이터가 잘 정립된 MLB 기록 활용을 위해
수업 시 활용하였던 Lahman package(R) 사용

야구는 공격과 수비로 이루어지며, 따라서 분석을 진행함에 있어

야구는

야구 스탯들 간에 상당한 수준의 선형성이 보장되어 이

타자의 가치 = α∗Batting+β∗Fielding, α,β는 임의의 패러미터

선수의 타격능력은 이른바 클래식 스탯으로 불리는 다양한 구형 통계량으로도 표기하는데 문제가 없지만, 수비능력은 선수별로 할당된 수비범위가 천차만별이며 선수가 수비시도를 하지 않으면 선수의 실책으로 이어지지 않는다는 점 때문에 선수 개별의 수비능력이 객관적으로 평가되기 시작한 것은 구장의 정보를 훨씬 자세하게 담을 수 있게 된 2000년대 중반부 이후부터의 이야기.

최신야구에서 선수 수비능력의 평가는 주로 Ultimate Zone Rating (UZR) 로 이루어지며, 해당 스탯은 ARM (달린거리), DPR (병살), RngR (수비커버리지), ErrR (에러빈도) 등 수비에 관련된 스탯을 총집합하여 망라하는 고밀도 스탯이다. 그러나 해당 스탯의 계산은 2002년 BIS (Baseball Info Solutions)라는 회사에서 제공하는 유료 데이터셋과 15년 도입된 스탯캐스트 데이터에 거의 전적으로 의존하고 있다. 스탯캐스트 데이터는 민간에 어느정도는 공개되어 있어 접근이 불가능하지 않지만 (\url{https://baseballsavant.mlb.com/statcast_leaderboard}), BIS 데이터는 접근이 어렵다.

이와 같은 이유로 선수별 수비 스탯을 구하기를 시도하기보단 팀별 수비력에 대한 척도인 Defensive Efficiency Ratio (DER)를 사용하고자 한다. 최대 12개의 팀인만큼 팀 간의 차이를 포착하기 쉬우며, 12개의 팀으로 표준화되니만큼 아웃라이어들이 평준화되어 전반적인 경향성으로 기능하는 것을 기대해볼 수 있다. DER의 수식은 다음과 같다.

DER의 계산법은 이하와 같다.

DER=1−(Hits+Reached.On.Error−HomeRunsPlate.Appearance−BB(Walks)−Strike.Out−Hit.By.Pitch−HomeRuns)

Teams \%\textgreater\%
mutate(., DER = 1-((H + E - HR)/((AB + SF) - SO - HR))) \%\textgreater\%
\#\#select(., yearID, teamID, Rank, SO, SOA)
select(.,yearID, teamID, franchID, Rank, G,DER) -\textgreater{} Teams\_DER

물론 같은 팀에 속했다는 이유만으로 모든 선수들에게 동급의 수비스탯을 배정하는 건 합리적이라고 말하기 어렵다. 팀의 수비에 기여하는 정도가 높은 선수가 있다면 낮은 선수도 있을 것이 자명하기 때문이다. 따라서 팀별로 획득한 DER을 수비에 대한 클래식 스탯인 각 선수의 Fielding Percentage(FPCT) 나 Range Factor(RF)의 비율로 스케일링해서 부여하자. 두 스탯은 각각 수비능력과 개인의 수비범위 평가를 위해 시도되었던 스탯들이지만, 전자는 개인의 수비범위가 좁으면 더 좋은 값이 나온다는 한계, 후자는 공이 본인 위치로 떨어졌을 때 스탯계산에서 이득을 본다는 한계를 넘지 못해 좋은 스탯으로는 평가받지 못했던 값들이다. 그러나 팀 단위로 한번 수비력을 표준화한 후 팀 내에서 상대적인 기여도를 보는 식으로 보정이 한 번 들어갔으므로 어느정도 기준선으로서는 기능할 것이라고 기대된다.

이를 위해 선수생활 중의 메인 수비포지션 지정하고 해당 포지션에서의 통계량만 사용.

\hypertarget{mva}{%
\chapter{MVA}\label{mva}}

\hypertarget{overview-of-mva-not-ended}{%
\section{Overview of mva (not ended)}\label{overview-of-mva-not-ended}}

Find relationships b/w \(\pmb x_p, \pmb y_q\), e.g.,
* Response variables (variable directed)
* PCA
* Factor Analysis
* mv Regression
* Cannonical Correlation Analysis
* Experiment units (individual directed)
* Discriminant Analysis
* Cluster Analysis
* MANOVA

Multivariate techniques tend to be exploratory.
* i.e.~not hypothesis testing type

Experimental units \textbf{must be independent}. Time series data are not appropriate for this course.

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

Variable \(y_1 , \cdots, y_p\)

One observation \(\pmb y ' = (y_1 , \cdots, y_p )\)

Data Matrix \(Y_{n \times p} = \begin{bmatrix} \pmb y ' = (y_1 , \cdots, y_p ) \\ \vdots \\ \pmb y ' = (y_1 , \cdots, y_p ) \end{bmatrix}\)

Random Samples: Suppose we intend to collect n sets of measurements on p variables, but not been observed yet. If \$\pmb x\_1 `, \cdots, \pmb x\_n' \$ are independent observation from pdf \(f(\pmb x) = f(x_1, \cdots, x_p)\), then \$\pmb x\_1 `, \cdots, \pmb x\_n' \$ are said to be rs from \(f(\pmb x)\).

rvec \(\pmb X = X_{p \times n} = \begin{bmatrix} \pmb x_1 \\ \vdots \\ \pmb x_p \end{bmatrix}\)

mean vector \(\pmb \mu = E (\pmb x) = \begin{bmatrix} \mu1 \\ \vdots \\ \mup \end{bmatrix}\)

Covariance Matrix \(\Sigma\)

Correlation Matrix \(\rho\), \(\rho_{ij} = \tfrac{\sigma_{ij}}{\sigma_{ii}\sigma_{jj}}\)
* Correlation measures linear association.
* Correlation is 0 if \textbf{symmetric} non-linear association exists.

\hypertarget{summary-statistics}{%
\subsection{Summary Statistics}\label{summary-statistics}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample Mean Vector \(\bar X=\) estimate of \(\pmb \mu\)
\item
  Sample Covariance Matrix
\item
  Sample Correlation Matrix
\end{enumerate}

\hypertarget{statistical-inference-on-correlation}{%
\subsection{Statistical Inference on Correlation}\label{statistical-inference-on-correlation}}

\$
H\_0: \rho = 0
\$

test stat \(T=\dfrac {r \sqrt{n-2}}{\sqrt{1-r^2}} \sim t_{n-2}\), where \(r=Corr(x,y)\) and \(x \sim N_2, y \sim N_2\)
Notes:
1. Correlation measures a linear relationships
2. it is still difficult to get a CI for \(\rho\).

\hypertarget{ci-for-rho}{%
\paragraph{\texorpdfstring{CI for \(\rho\)}{CI for \textbackslash rho}}\label{ci-for-rho}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fisher's Method:
\end{enumerate}

\(100(1-\alpha)%
\) CI for \(\rho\) \$=\tanh \left(\inv \tanh(r) \pm \dfrac{z_{\alpha/2}}{\sqrt{n-3}} \right)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Ruben's Method
\end{enumerate}

let \(u=z_{\alpha/2}, r^\ast = \dfrac {r}{\sqrt{1-r^2}\)

\$
\begin{align*}
a &= 2n-3-u^2
b &= r^\ast \ast \sqrt{(2n-3)(2n-5)}
c &= (2n-5-u^2} \ast (r^\ast)^2 - 2u^2

\end{align*}
\$

set \(ay^2 - 2by +c =0\), then root of this equation will be \(y_1, y_2 = \dfrac{b}{a} \pm \dfrac {\sqrt{b^2-ac}}{a}\).

이때 \(100(1-\alpha)%
\) CI for \(\rho\) \(=\left[ \dfrac{y_1}{\sqrt{1+y_1^2}, \dfrac{y_2}{\sqrt{1+y_2^2}, \right]\)
* 이때, input은 \(n, \alpha, r\), output은 \(\rho\)의 CI.

\hypertarget{standardization}{%
\subsection{Standardization}\label{standardization}}

\hypertarget{missing-value-treatment}{%
\subsection{Missing Value Treatment}\label{missing-value-treatment}}

\hypertarget{multivariate-nomral-wk2}{%
\section{Multivariate Nomral (wk2)}\label{multivariate-nomral-wk2}}

\hypertarget{overview-2}{%
\subsection{Overview}\label{overview-2}}

let rvec \(Z=(Z_1 , \cdots, Z_p)', Z_i \overset {iid}{\sim} N(0,1)\).

then \(X=(X_1 , \cdots, X_p)' = A_{k \times p} Z + \pmb \mu_{k \times 1}\) follows MVN.

at here, if \(rank(A)=p(\le k), AA' = \Sigma\), then \(X \sim N_p (0, \Sigma)\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

notation: \(\pmb y \sim N_p (\pmb \mu , \Sigma)\)

rvec \(\pmb y ' = [y_1 , \cdots , y_p ]\) have \textbf{Multivariate Normal Distribution}, if \(\sum_{i=1}^p a_i y_u = \pmb a' y\) has Univariate Normal Distribution, for every possible set of values for the elements in \(\pmb a\).

pdf for \(f(\pmb y) = \dfrac{1}{(2\pi)^p {\vert \Sigma \vert}^{1/2}} \exp \left\{ -\dfrac{1}{2} (\pmb y - \pmb \mu)' \Sigma^{-1} (\pmb y - \pmb \mu) \right\}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Ellipsoid:
- path of \(\pmb y\) values yielding a constant height for the density, i.e., all \(\pmb y\) s.t. \(\{ (\pmb y - \pmb \mu)' \Sigma^{-1} (\pmb y - \pmb \mu)=c^2 \}\).

Standard Normal Distribtion:
- \(\pmb z = \left( {\Sigma^{1/2}}\right)^{-1} (\pmb y -\pmb \mu) \sim N_p (\pmb 0, I_p)\), where \(\left( {\Sigma^{1/2}}\right)^{-1}\) satiesfy \$ \Sigma = \left( \{\Sigma\textsuperscript{\{1/2\}\}\right)}\{-1\} \ast \left( \{\Sigma\textsuperscript{\{1/2\}\}\right)}\{-1\}\$.

Property of \(\Sigma\):
1. symmetric Matrix
2. positive definite Matrix
3. \$Cov(A \pmb y + \pmb b) = A \Sigma A' \$.

※ if \(A\) is symmetric and non-singular, then \(A=CC'\), where \(C\) is lower triangular Matrix. This is called \textbf{Cholesky Decomposition} of \(A\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(E(X)=\mu, Cov(X)=AA' = \Sigma\)
\item
  \(M_X (t) = \exp (t' \mu + \dfrac {1}{2} t' \Sigma t\)
\item
  if \(\Sigma=AA'\) is non-singular Matrix \(\iff rank(A)=p\)
\item
  \(\Sigma = Cov(X)\)는 symmetric, n.n.d.
\end{enumerate}

이상의 \(X\)에 대해 이하는 TFAE.
1. \(X \sim N_p (0, \Sigma)\).
2.
3.
4.
5.

\hypertarget{spectral-decomposition}{%
\subsection{Spectral Decomposition}\label{spectral-decomposition}}

if \(A\) is symmetric, non-singular, then \(A=E \Lambda E'\), where \(\lambda_i\) are ev (\(\lambda_1 \ge \cdots \ge \lambda_n\)), and \(\pmb e_i\) are evec (\(E'E = I_p)\). This is called \textbf{Spectral Decomposition} of \(A\).

\$

\Lambda =

\begin{bmatrix}

\lambda_1 & & \pmb 0 \\  
& \ddots & \\ 
\pmb 0 & & \lambda_n 

\end{bmatrix}

, ; ; ; ; ; E=\left[ \pmb e_1 , \cdots, \pmb e_p \right]

\$

이때 \(\Sigma = E \Lambda E' = E \Lambda \Lambda^{1/2} E' = E \Lambda E' E \Lambda^{1/2} E' = \Sigma^{1/2} \Sigma^{1/2}\).

Center \& Axis of ellipsoids of \(\{ (\pmb y - \mu)' \Sigma^{-1} (\pmb y - \mu)=c^2 \}\):
* center: \(\pmb \mu\)
* axis : \(\pm c \sqrt{\lambda_i \pmb e_i}\)

Square root Matrix:

let symmetric non-negative Matrix \(A_{p \times p}\). the square root matrix of \(A\) is defined as \(A^{1/2} = E \Lambda^{1/2} E'\), where

\$
\Lambda\^{}\{1/2\} =

\begin{bmatrix}

\sqrt{\lambda_1} & & \pmb 0 \\  
& \ddots & \\ 
\pmb 0 & & \sqrt{\lambda_n }

\end{bmatrix}

\$

Negative Square Root Matrix:

Let \(A\) be of \textbf{full rank} and all of its \textbf{\(\lambda_i\) are positive}, in addition to symmetry. \(A^{-1/2} = E \Lambda^{-1/2} E'\), where

\$
\Lambda\^{}\{-1/2\} =

\begin{bmatrix}

\dfrac{1}{\sqrt{\lambda_1}} & & \pmb 0 \\  
& \ddots & \\ 
\pmb 0 & & \dfrac{1}{\sqrt{\lambda_n }}

\end{bmatrix}

\$

Generalized Inverse:

let \(A\) be a non-negative M. if \(\lambda_1> \lambda_2 > \cdots > \lambda_r > 0 = \lambda_{r+1} = \cdots = \lambda_{p}\), i.e., not full rank, then the \textbf{Moore-Penrose generalized inverse of \(A\)} is given by

\$

A\^{}\{-\} =

\dfrac{1}{\lambda_1} \pmb e\_1 \pmb e\_1 ' + \cdots +
\dfrac{1}{\lambda_r} \pmb e\_r \pmb e\_r '

\$

where

\$
\Lambda\^{}\{-\} =

\begin{bmatrix}



\dfrac{1}{\lambda_1} & & & & \pmb 0 \\  
& \ddots & & & \\ 
& & \dfrac{1}{\lambda_n } & & & \\
& & & 0 & &  \\
& & & & \ddots &  \\
\pmb 0 & & & & & 0  \\
\end{bmatrix}

\$

Marginal Distribtion:

\$
\begin{align*}
\pmb y \sim N_p (\pmb \mu , \Sigma)

&\Longrightarrow

y_i \sim N(\mu_i, \sigma^{ii}), \; \; \; i= 1, \cdots, p \\

&\not \Longleftarrow

\end{align*}
\$

\hypertarget{properties-of-mvn}{%
\subsection{Properties of MVN}\label{properties-of-mvn}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  linear combination of the components of \(\pmb y\) are normally distributed.
\item
  any subset of \(\pmb y\) have MVN.
\item
  conditional distribution of the components of \(\pmb y\) are MVN:
\item
\item
\item
\end{enumerate}

\$ \pmb y \sim N\_p(\pmb \mu , \Sigma) \iff \pmb a ' \pmb y \sim N( \pmb a ' \pmb \mu, \pmb a ' \Sigma \pmb a ) \$

\$ \pmb y \sim N\_p(\pmb \mu , \Sigma) , ; ;

A\_\{n times p\} =

\begin{bmatrix}

a_{11} & \cdots & a_{1p} \\
\vdots & \ddots & \vdots \\
a_{n1} & \cdots & a_{np}

\end{bmatrix}

\Longrightarrow

A \pmb y \sim N\_n(A \pmb \mu , A \Sigma A')
\$
즉슨 dimension 변화

if \$ \pmb y \sim N\_p(\pmb \mu , \Sigma)\$, and cvec \(\pmb d\), then \$ \pmb y + \pmb d \sim N\_p(\pmb \mu + \pmb d , \Sigma)\$.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  If we partition y, μ, S
  ! !
  as follows
\end{enumerate}

Let
1
11
2
\textasciitilde{} ( , ) p
y
y N
y
μ
é ù
ê ú
= ê ú S
ê ú
ë û
!"
! !
!
with

\hypertarget{chi2-distribution}{%
\subsection{\texorpdfstring{\(\Chi^2\) distribution}{\textbackslash Chi\^{}2 distribution}}\label{chi2-distribution}}

if \(\pmb z \sim N_p ( \pmb 0 , I_p )\), then \(\pmb z ' \pmb z = \sum_{i=1}^p z_i^2 \sim \Chi_p^2\).

if \$ \pmb y \sim N\_p(\pmb \mu , \Sigma)\$, then \$(\pmb y - \pmb \mu)' \Sigma\^{}\{-1\} (\pmb y - \pmb \mu) \sim \Chi\_p\^{}2 \$

the \(N_p(\pmb \mu , \Sigma)\) distribution assigns probability \(1-\alpha\) to the solid ellipsoid \(\left \{ \pmb y : (\pmb y - \pmb \mu)' \Sigma^{-1} (\pmb y - \pmb \mu) \le \chi_p^2 (\alpha) \right \}\), where \(\chi_p^2 (\alpha)\) denotes upper \((100 \ast \alpha)\) th percentile of the \(\chi_p^2\) distribution.

\hypertarget{linear-combination-of-random-vectors}{%
\subsection{Linear Combination of Random Vectors}\label{linear-combination-of-random-vectors}}

\hypertarget{multivariate-normal-likelihood}{%
\subsection{Multivariate Normal Likelihood}\label{multivariate-normal-likelihood}}

\hypertarget{sampling-distribtion-of-bar-pmb-y-s}{%
\subsection{\texorpdfstring{Sampling Distribtion of \(\bar {\pmb y}, S\)}{Sampling Distribtion of \textbackslash bar \{\textbackslash pmb y\}, S}}\label{sampling-distribtion-of-bar-pmb-y-s}}

let rvec \$ \pmb y\_1, \cdots \pmb y\_n \sim N\_p(\pmb \mu , \Sigma)\$.

\(\bar {\pmb y} \sim N_p (\pmb \mu , \dfrac{1}{n} \Sigma)\)

(n-1) \ast S \sim \$ Wishart distribution, with \(df=n-1\)
* \(S\) is random Matrix, e.g., Wishart is distribution of rM.

\(\bar {\pmb y} \perp S\).

\hypertarget{wishart-distribtion}{%
\paragraph{Wishart Distribtion}\label{wishart-distribtion}}

※ \(\dfrac {\sum (x_i - \barx )^2}{\sigma^2} = \dfrac {S^2} {\dfrac{\sigma^2}{n-1}} \sim \chi_{n-1}^2\), i.e., \(\sum (x_i - \barx )^2 = (n-1)S^2 \sim \sigma^2 \ast \chi_{n-1}^\)

for let rvec \$ \pmb y\_1, \cdots \pmb y\_n \sim N\_p(\pmb \mu , \Sigma)\$,

\$
\begin{align*}

\sum_{i=1}^n(\pmb y - \pmb \mu)(\pmb y - \pmb \mu)' &\sim W_p (n, \Sigma) \\
\\

(n-1)S^2 = \sum_{i=1}^n(\pmb y - \bar {\pmb y} )(\pmb y - \bar {\pmb y} )' &\sim W_p (n-1, \Sigma)
\end{align*}
\$

if \(A \sim W_p (n, \Sigma), B \sim W_p (m, \Sigma)\), and \(A \perp B:\) \(A+B \sim W_p (n+m, \Sigma)\)

if \(A \sim W_p (n, \Sigma)\), then \(CAC' \sim W_p (n, C \Sigma C')\)

\textbf{\emph{if \(A \sim W_p (n-1, \Sigma)\), \(f(A)\), where gamma function.}}

\hypertarget{mv-t-distribtion}{%
\paragraph{MV t-Distribtion}\label{mv-t-distribtion}}

※ univariate t-Distribtion \(t=\tfrac{\tfrac{U}{\sigma}}{\sqrt{\tfrac{V}{nu}}} \sim t_{\nu}\), where \(U \sim N(0, \sigma^2), V \sim \chi_{\nu}^2\), and \(U \perp V\).

let \$ \pmb y = (y\_1, \cdots, y\_n)' \sim N\_p(\pmb \mu , \Sigma)\$, and \(V \sim \chi_{\nu}^2\), and \(\pmb y \perp V\).

assume rvec \(\pmb t = (t_1 , \cdots, t_p)'\),\(t_i = \tfrac {\tfrac{y_i - \mu_I}{\sigma_i}{\sqrt{V/\nu}}, i=1, \cdots, p\)
* Note that each \(t_i \sim t\).

at here, joint distribution of \(\pmb t\) is called MV t-distribution, with \(df=\nu\) and matrix parameter \(\Sigma\).

\textbf{\emph{denote this distribution by }}

\hypertarget{dirichlet-distribution}{%
\paragraph{Dirichlet Distribution}\label{dirichlet-distribution}}

※ is MV generalization of \(BETA\).

let \$ \pmb y \sim D\_p(\nu\emph{1 \cdots , \nu}\{p+1\})\$
* parameters: \(\{\nu_i, i=1, \cdots, p+1\}\)
* pdf: f(\pmb y) = \tfrac{1}{\Beta(\nu_1 \cdots , \nu_{p+1})} \prod\_\{i=1\}\^{}p y\_i\^{}\{v\_i - 1\}\$

?????????????????????????????????????????????????

\hypertarget{clt}{%
\paragraph{CLT}\label{clt}}

let

\$ \pmb y\_1 , \cdots, \pmb y\_n \overset {iid} \{\sim\} \pmb \mu, \Sigma \textless{} \infty\$. then

\$
\begin{align*}

\sqrt {n} (\hat {\pmb y} - \pmb \mu) &\overset {d} {\rightarrow} N_p (\pmb 0 , \Sigma) \\

n (\hat {\pmb y} - \pmb \mu)' S^{-1} (\hat {\pmb y} - \pmb \mu)
&\overset {d} {\rightarrow} \chi_p^2

\end{align*}
\$

\hypertarget{assessing-normality}{%
\subsection{Assessing Normality}\label{assessing-normality}}

\hypertarget{univariate-marginal-distribtion}{%
\paragraph{1. Univariate Marginal Distribtion}\label{univariate-marginal-distribtion}}

\hypertarget{a.-q-q-plot}{%
\subparagraph{a. Q-Q Plot}\label{a.-q-q-plot}}

※ Sample quantile vs.~quantile of N distribution

let order statitics, or sample quantiles \(x_{(1)} \le \cdots \le x_{(n)}\).

the proportion of sample below \(x_{(j)}\) is approximated by \(\tfrac{j-\tfrac{1}{2}}{n}\).

the quantiles \(q_{(j)}\) for std. N are defined as

\$
P(z \le q\_\{j)\}) = \int\emph{\{-\infty\}\^{}\{q}\{(j)\}\} \tfrac{1}{\sqrt{2 \pi}} \exp \left( -\tfrac{1}{2} z\^{}2 \right) dz \overset {\triangle}{=} \tfrac{j-\tfrac{1}{2}}{n}
\$

if the data arise from a N population, then \((\sigma \ast q_{(j)} + \mu \congruent x_{(j)}\).

Similarly, the pairs \((q_{(j)}, x_{(j)})\) will be linearly related.

Proceeds:
1. get \(x_{(1)} \le \cdots \le x_{(n)}\) from original obs.
2. calculate probability values \(\tfrac{j-1/2}{n}, \; \; j= 1, \cdots, n\)
3. calculate standard normal quantities \(q_{(1)}, \cdots, q_{(n)}\)
4. plot the pairs of observations \$(q\_\{(1)\}, x\_\{(1)\}), \cdots, \((q_{(n)}, x_{(n)})\)

Checking the straightness of Q-Q plot:
* using corr coef
* Hypothesis tesiting: \(H_0: \rho=0\), \$T=\tfrac {r\sqrt{n-2}}{\sqrt{1-r^2}} \overset {H_0}{\sim} t\_\{n-2\}

\hypertarget{b.-others}{%
\subparagraph{b. others}\label{b.-others}}

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Shapiro-Wilks Test:
  \end{enumerate}
\end{itemize}

Test of correlation coefficient b/w \(x_{(j)}, r_{(j)}\). \(r_{(j)}\) is function of the expected value of standard normal order statistics, and their \(Cov\).

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Kolmogorov-Smirnov Test
  \end{enumerate}
\end{itemize}

Compare cdf's:

If the data arise from a normal population, the differences are small.

\$
T = \sup\_x \left\vert F(x) - S(x) \right \vert
\$

where cdf \(F(x)\), empirical cdf \(S(x)\).

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Skewness Test
  \end{enumerate}
\end{itemize}

skewness \(\sqrt{b_1} = \tfrac{\sqrt{n} \sum_{i=1}^n (x_i - \bar x)^3} {\left[ \sum_{i=1}^n (x_i - \bar x)^2 \right]^{\tfrac{3}{2}}}\)

When the population is normal, the skewness = 0.

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{3}
  \tightlist
  \item
    Kurtosis Test:
  \end{enumerate}
\end{itemize}

kurtosis \({b_2} = \tfrac{n \sum_{i=1}^n (x_i - \bar x)^4} {\left[ \sum_{i=1}^n (x_i - \bar x)^2 \right]^{3}}\)

When the population is normal, the kurtosis is 3.

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{4}
  \tightlist
  \item
    Lin and Mudholkar (1980):
  \end{enumerate}
\end{itemize}

\$

Z = \tanh\^{}\{-1\}(r) = \tfrac {1}{2} \ln \left( \tfrac {1+r}{1-r} \right)
\$

where \(r\) is the sample \(corr\) of \(n\) pair \((x_i , q_i), \; \; i=1, \cdots, n\) with \(q_i = \tfrac {1}{n} \left( \sum_{i \not = j} x_j^2 - \tfrac{1}{n-1} \left( \sum_{i \not = j} x_j\right)^2 \right)^{\tfrac{1}{3}}\).

if the data arise from a normal population, \(Z \sim N(0, \tfrac 3 n)\).

\hypertarget{bivariate-normality}{%
\paragraph{2. Bivariate Normality}\label{bivariate-normality}}

※ If the data are generated from a multivariate normal, \textbf{each bivariate distribution} would be normal.

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Scatter Plot
  \end{enumerate}
\end{itemize}

the contours of bivariate normal density are ellipses. The pattern of the scatter plot must be near elliptical.

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Squared Generalized Distances
  \end{enumerate}
\end{itemize}

※ \(\pmb y \sim N_p (\pmb \mu, \Sigma) \; \; \; \Longrightarrow \; \; \; (\pmb y - \pmb \mu)' \Sigma^{-1} (\pmb y - \pmb \mu) \sim \chi_p^2\).

it means, for bivariate cases, \textbf{Squared Generalized Distances} \(d_j^2 = (\pmb x_j - \hat {\pmb x})' S^{-1} (\pmb x_j - \hat {\pmb x}) \sim \chi_2^2\).

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Chi2 Plot (Gamma Plot)
  \end{enumerate}
\end{itemize}

\(d_1^2 , \cdots, d_n^2\) should behave like \(\chi_2^2\) rv.
1. order the squared distances \(d_{(1)}^2 \le \cdots \le d_{(n)}^2\)
2. calculate the probabilitt values \(\tfrac{j-1/2}{n}\), \(j=1,\cdots, n\)
3. Calculate quantiles of \(\chi_2^2\) distribution \(q_{(1)}, \cdots, q_{(n)}\).
4. Plot the pairs \((q_{(j)}, d_{(j)}^2 ), \; \; j=1, \cdots, n\) where \(q_{(j)} = \chi_2^2 \left( \tfrac{j-1/2}{n} \right)\)

The plot should resemble a straight line through the origin having slope 1.

\hypertarget{multivariate-normality}{%
\paragraph{2. Multivariate Normality}\label{multivariate-normality}}

Practically, it is usually sufficient to investigate the univariate and bivariate distributions.

Chi-square plot is still useful. When the parent population is multivariate normal, and both \(n\) and \(n-p\) are greater than 25 or 30, the squared generalized distance \(d_{1}^2 \le \cdots \le d_{n}^2\) should behave like \(\chi_p^2\).

\hypertarget{power-transformation}{%
\subsection{Power Transformation}\label{power-transformation}}

\$
x\^{}\lambda =

\begin{cases}

\tfrac{1}{x},                   & \lambda = -1                              \tag{\text{Reciprocal Transformation}}\\
\tfrac{1}{\sqrt{x}},            & \lambda = -\tfrac{1}{2} \\
\ln(x),                             & \lambda = 0 \\
\sqrt{x},                       & \lambda = \tfrac{1}{2} \\
x,                                  & \lambda = 1                   \tag{\text{No Transformation}}

\end{cases}

\$

Examine Q-Q plot to see whether the normal assumption is satisfactory after power transformation.

\hypertarget{power-transformation-1}{%
\paragraph{Power Transformation}\label{power-transformation-1}}

\$
x\^{}(\lambda) =

\begin{cases}

\tfrac{x^\lambda - 1}{\lambda},                     & \lambda \not = 0 \\
\ln(x),                             & \lambda = 0

\end{cases}

\$

at here, find \(\lambda\) that maximizes

\$

l(\lambda) = -\tfrac{n}{2} ln\left[ \tfrac{1}{n} \sum_{j=1}^n \left( x_j^{(\lambda)} - \hat{x_j}^{(\lambda)} \right) ^2 \right] + (\lambda-1) \sum\_\{j=1\}\^{}n \ln x\_j

\$

where \(\hat{x_j}^{(\lambda)} = \tfrac{1}{n} \sum_{j=1}^n x_j^{(\lambda)}\)

x\^{}\{(\lambda)\} is the most feasible values for normal distribution, but not guaranteed to follow normal distribution.
* Transformation (Box-Cox) usually improves the approximation to normality.
* Trial-and-error calculations may be necessary to find \(\lambda\) that maximizes \(l(\lambda)\)
* Usually, change \(\lambda\) values from -1 to 1 with increment 0.1.
* Examine Q-Q plot after the Box-Cox transformation.

\hypertarget{nqplot-contour-plot-cqplot-cqplot-and-box-cox-plot}{%
\paragraph{nqplot, contour plot, cqplot, cqplot and box-cox plot}\label{nqplot-contour-plot-cqplot-cqplot-and-box-cox-plot}}

\hypertarget{inference-about-mean-vector-wk3}{%
\section{Inference about Mean Vector (wk3)}\label{inference-about-mean-vector-wk3}}

\hypertarget{overview-3}{%
\subsection{Overview}\label{overview-3}}

Recall:
univariate case \(x_1 , \cdots, x_n \overset {iid} {\sim} N(\mu, \sigma^2)\)

\(H_0 : \mu = \mu_0\)

\$
\begin{alignat*}{2}

\text{test stat } &t &&=\tfrac{\bar X - \mu_0}{\tfrac{S}{\sqrt{n}}} &\overset{H_0}{\sim} t_{n-1} \\


&t^2 &&=\tfrac{(\bar X - \mu_0)^2}{\tfrac{S^2}{n}} &\overset{H_0}{\sim} F_{1, \; n-1}

\end{alignat*}
\$

reject \(H_0\) if as below, which means upper \((100-\alpha)\)th percentile.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\$
\begin{alignat*}{1}
\tfrac{(\bar X - \mu_0)^2}{\tfrac{S^2}{n}} = n(\bar X - \mu_0)\tfrac{1}{S^2}(\bar X - \mu_0) &> F_{1,n-1}(\alpha)
\end{alignat*}
\$

therefore, with assumption \(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\),

\$

H\_0 : \pmb \mu = \pmb \mu\_0

\$

\$
\begin{alignat*}{3}

\text{Hotelling's }T^2 \; \; T^2 &= n(\bar {\pmb X} - \pmb \mu_0)' S^{-1} (\bar {\pmb X} - \pmb \mu_0) \\

&\overset{H_0}{\sim} \tfrac{(n-1)p}{(n-p)} F_{p,n-p} \\

\iff \; \; \tfrac {(n-p)} {(n-1)p} T^2 &\overset{H_0}{\sim} F_{p,n-p}
\end{alignat*}
\$

reject \(H_0\), if \(T^2 > \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)\).

assumption check: \(\pmb X_1 , \cdots, \pmb X_n \overset{iid}{\sim} N_p (\pmb \mu , \Sigma)\).

\hypertarget{remark}{%
\paragraph{Remark}\label{remark}}

stat \(T^2\)는 측정 단위에 invariant. proof)

let \$\pmb Y\_\{p \times 1\} = C\_\{p \times p\} \pmb X\_\{p \times 1\} + \pmb d\_\{p \times 1\} \$. then

\$
\begin{align*}
\bar {\pmb Y} &= C \bar {\pmb X} + \pmb d \\
\\

S_{\pmb y} &= CSC'\\
\\

\mu_y &= E(\pmb Y) \\
&=C \ast E(\pmb X) + \pmb d \\
&= C \pmb \mu_0 + \pmb d

\end{align*}
\$

therefore,

\$
\begin{align*}

T^2
&= n(\bar {\pmb Y} - \pmb \mu_y)' S_y^{-1} (\bar {\pmb Y} - \pmb \mu_y) \\
&= n \left[ C(\bar {\pmb X} - \pmb \mu_0) \right]' (CSC')^{-1} \left[ C(\bar {\pmb X} - \pmb \mu_0) \right] \\
&= n (\bar {\pmb X} - \pmb \mu_0)' C' (C')^{-1} S^{-1}(C)^{-1}  C(\bar {\pmb X} - \pmb \mu_0) \\
&= n (\bar {\pmb X} - \pmb \mu_0)' S^{-1}(\bar {\pmb X} - \pmb \mu_0) 

\end{align*}
\$

\textbf{\emph{여기서 \(C^{-1}\)이 존재한다는게 뭔수로 보장되는거지?}}

\hypertarget{confidence-region}{%
\subsection{1. Confidence Region}\label{confidence-region}}

\hypertarget{confidence-region-1}{%
\paragraph{Confidence Region}\label{confidence-region-1}}

region \(R(\pmb X)\), is \$100(1-\alpha) \% \$ \textbf{CR} of

\$
\begin{alignat*}{3}


&P \left\{
R(\pmb X) \text{ will cover the true } \pmb \theta 
\right\}

&&= 1-\alpha \\




&P \left\{

n (\hat {\pmb X} - \pmb \mu)' S^{-1}(\hat {\pmb X} - \pmb \mu) \le \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)

\right\}

&&=



\end{alignat*}
\$

the inequality \(n (\bar {\pmb X} - \pmb \mu)' S^{-1}(\bar {\pmb X} - \pmb \mu) \le \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)\) will define a region \(R(\pmb X)\).

The region is an ellipsoid centered at \(\bar {\pmb X}\).

Testing \(H_0 : \mu = \mu_0\) at \(\alpha =.05\) is equivalent to see whether \(\mu_0\) falls within the CR.

\begin{itemize}
\tightlist
\item
  with ev \(\lambda_1 , \cdots, \lambda_p\), evec \(\pmb e_1 , \cdots, \pmb e_p\) of \(S\),

  \begin{itemize}
  \tightlist
  \item
    CR Axis: \(\pm \sqrt{\lambda}\sqrt{\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)} \ast \pmb e_i'\)
  \item
    CR half-length: \$ \sqrt{\lambda}\sqrt{\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)}\$
  \end{itemize}
\end{itemize}

\hypertarget{simultaneous-ci}{%
\subsection{2. Simultaneous CI}\label{simultaneous-ci}}

let \(\pmb X \sim N_p (\pmb \mu, \Sigma)\), then linear combination \(\pmb a' \pmb X \sim N_p (\pmb a' \pmb \mu, \pmb a' \Sigma \pmb a)\)

\$
\begin{align*}

t=\dfrac{\bar X - \mu} {S / \sqrt{n}} &\sim t_{n-1} \tag{recall: univariate}\\

t= \dfrac {\pmb a ' \bar X - \pmb a ' \pmb \mu} {\sqrt{\pmb a ' S \pmb a / n } } = \dfrac {\sqrt{n}(\pmb a ' \bar X - \pmb a ' \pmb \mu)} {\sqrt{\pmb a ' S \pmb a} } &\sim t_{n-1} \tag{MV}

\end{align*}
\$

therefore, \(100(1-\alpha)\%\) CI for \(\pmb a ' \mu\) (at here, \(\pmb a\)is fixed) is \(\pmb a ' \bar {\pmb X} \pm t_{n-1} \dfrac {\alpha} {2} \dfrac{\sqrt{\pmb a ' S \pmb a} } {\sqrt{n}}\). \textbf{This is not a simultaneous CI.} let each \((a_1 , a_2), (b_1, b_2)\) be CI for \(\mu_1 , \mu_2\). then simultaneous CI \((a_1 , a_2), (b_1, b_2)\) has confidence \(95\% \ast 95\% = 90.25\%\). \textbf{need a wider interval}.

let rs \(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\).

then, simultaneously for all \(\pmb a\), the interval \(\pmb a ' \bar {\pmb X} \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p,n-p} (\alpha) \pmb a ' S \pmb a}\) will contain \(\pmb a ' \pmb \mu\) with probability \(1-\alpha\).

\$
\begin{alignat*}{3}
\because 1-\alpha 


&=  

P \left[
n 
(\bar {\pmb X } - \pmb \mu)'
S^{-1}
(\bar {\pmb X } - \pmb \mu)


\le

(n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)

\right] \\





&=  

P \left[




(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)'
(\pmb a' S \pmb a)^{-1}
(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)


\le


\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)


\right] \\





&=  

P \left[

(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)'
(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)

\le

\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a' S \pmb a)

\right] 

\tag{∵ Scalar}
\\





&=  

P \left[

(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)^2

\le

\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a' S \pmb a)

\right] \\





&=  

P \left[


-

\sqrt{\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a' S \pmb a)}


\le

(\pmb a' \bar {\pmb X } - \pmb a' \pmb \mu)

\le

\sqrt{\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a' S \pmb a)}


\right] 







\end{alignat*}
\$

\hypertarget{simultaneous-ci-for-mu_i---mu_k}{%
\paragraph{\texorpdfstring{Simultaneous CI for \(\mu_i - \mu_k\)}{Simultaneous CI for \textbackslash mu\_i - \textbackslash mu\_k}}\label{simultaneous-ci-for-mu_i---mu_k}}

let \(\pmb a ' = [0,\cdots, 0, a_i, 0, \cdots, 0, a_k, 0, \cdots, 0]\). then as below, where \(S =\begin{bmatrix} S_{11} & \cdots &S_{1p} \\ & \ddots & \\ S_{p1} & \cdots & S_{pp} \end{bmatrix}\).

\$
\begin{align*}
\pmb a ' \pmb \mu &= \mu_i - \mu_k \\

\pmb a ' S \pmb a  =S_{ii} -2 S_{ik} + S_kk
\end{align*}
\$

therefore, the simultaneous CI for \(\mu_i - \mu_k\), is \((\bar x_i - \bar x_k ) \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p, n-p}(\alpha)S_{ii} -2 S_{ik} + S_kk}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

at here, if we let \(\pmb a ' = [1, 0, \cdots, 0]\).

then

\$
\begin{align*}
\pmb a ' \pmb \mu &= \mu_1\\

\pmb a ' S \pmb a  =S_{11}
\end{align*}
\$

therefore, the simultaneous CI for \$\mu\_1 \$, is \(\bar x_1 \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p, n-p}(\alpha)S_{11}}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{note-bonferroni-multiple-comparison}{%
\subsection{3. Note: Bonferroni Multiple Comparison}\label{note-bonferroni-multiple-comparison}}

Bonferroni's CI, \(\bar x_1 \pm \left\{ t_{n-1} \left( \dfrac{\alpha}{2p} \right) \right\} \sqrt{\dfrac{S_11}{n}}\), is more precise (narrower) than simultaneous CI.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{large-sample-inferences-about-a-mean-vector}{%
\subsection{4. Large Sample Inferences about a Mean Vector}\label{large-sample-inferences-about-a-mean-vector}}

\emph{Recall} mv CLT:

let \(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\) and for \(n-p\) large. then

\$
\begin{align*}

\sqrt{n} (\bar {\pmb X} - \pmb \mu) &\overset {d}{\Longrightarrow} N_p (\pmb 0, \Sigma) \\


n (\bar {\pmb X} - \pmb \mu)' S^{-1}(\bar {\pmb X} - \pmb \mu) &\overset {d}{\Longrightarrow} \chi^2_p

\end{align*}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

when the sample size is large, the MVN assumption is less critical. therefore,

let \(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\).

\$
H\_0: \pmb \mu = \pmb \mu\_0
\$

when \(n-p\) is large, the \(H_0\) is rejected if \(n (\bar {\pmb X} - \pmb \mu)' S^{-1}(\bar {\pmb X} - \pmb \mu) > \chi^2_p (\alpha)\).

Note: \((n-1) \dfrac{p}{n-p} F_{p,n-p} )\alpha \simeq \chi_p^2(\alpha)\), for large \(n-p\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  CI:
\end{itemize}

\$
P \left[
n 
(\bar {\pmb X } - \pmb \mu)'
S^{-1}
(\bar {\pmb X } - \pmb \mu)


\le

\chi_p^2 (\alpha)
\right] 
 = 1-\alpha
\$

the inequality \$ n (\bar \{\pmb X \} - \pmb \mu)' S\^{}\{-1\} (\bar \{\pmb X \} - \pmb \mu) \le \chi\_p\^{}2 (\alpha) \$ will define a region, which means, \(100(1-\alpha) \%\) region.

\begin{itemize}
\tightlist
\item
  Simultaneous CI:
\end{itemize}

let \(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\) and for \(n-p\) large. then

\(\forall \pmb a\), \(100(1-\alpha) \%\) simultaneous CI for \(\pmb a ' \pmb \mu\) \(= \pmb a ' \bar {\pmb X} \pm \sqrt{ \chi_p^2 (\alpha)} \sqrt{ \dfrac{\pmb a ' S \pmb a} {n}}\).

\begin{itemize}
\tightlist
\item
  Simultaneous CI for \(\mu_i\)
\end{itemize}

\$
\bar x\_i \pm \sqrt{\chi_p^2(\alpha)} \sqrt{\dfrac{s_{ii}}{n}}
\$

\begin{itemize}
\tightlist
\item
  Bonferroni's CI for \(\mu_i\)
\end{itemize}

\$
\bar x\_i \pm z\_\{\tfrac{\alpha}{2p}\}\sqrt{\dfrac{s_{ii}}{n}}
\$
- Bonferroni's CI is more precise. as also.

\hypertarget{profile-analysis-wk4-5}{%
\subsection{1. Profile Analysis (wk4, 5)}\label{profile-analysis-wk4-5}}

if \(\pmb X \sim N_p (\pmb \mu, \Sigma)\), and the variables in \(\pmb X\) are measured in the same unit, we may with to compare the means \(\mu_1 , \cdots, \mu_p\) in \(\pmb \mu\).

ex) repeated measure: a measurement is taken at the same experimental unit \(p\) successive times.

A profile is a plot, connecting \((i, \mu_i), i= 1, \cdots, p\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Question: is the profile flat?

\$
\begin{align*}

&H_0: \mu_1 = \cdots = \mu_p \\

\iff &H_0: C_1 \pmb \mu = \pmb 0 , \left[ C_1\right]_{(p-1) \times p} \\

\iff &H_0: C_2 \pmb \mu = \pmb 0 , \left[ C_2\right]_{(p-1) \times p}

\end{align*}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

if \(\pmb X \sim N_p (\pmb \mu, \Sigma)\), then \(C \pmb X \sim N_{p-1} (C \pmb \mu, C \Sigma C')\), thus when \(H_0 : C \pmb \mu = 0\) is true, then \(C \bar X \sim N_{p-1} (C \pmb \mu, C \Sigma C')\).

test stat \(T^2 = n (C \bar {\pmb X})' (C S C')^{-1} (C \bar {\pmb X}) \overset{H_0}{\sim} (n-1) \dfrac{p-1}{n-p+1} F_{p-1,n-p+1}\)

reject \(H_0\), if \(T^2 > (n-1) \dfrac{p-1}{n-p+1} F_{p-1,n-p+1} (\alpha)\).

**Note: \(C_{(p-1) \times p}\) is not square, so there's no inverse. thus \(C\) in test stat doesn't be canceled.

\$
H\_0 : C \pmb \mu = 0
\$

where \(C_{q \times p} (q \le p)\), and \(rank(C)=q\). then

test stat \(T^2 = n (C \bar {\pmb X})' (C S C')^{-1} (C \bar {\pmb X}) \overset{H_0}{\sim} (n-1) \dfrac{q}{n-q} F_{q,n-q}\)

which means \(p-1\) become \(q\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{test-for-linear-trend}{%
\subsection{2. Test for Linear Trend}\label{test-for-linear-trend}}

suppose \(p\) variables are measured across equally spaced time periods. Also suppose \(H_0 : \mu_1 = \cdots = \mu_p\) is rejected.

Question: Do the means fall onto a straight line?

\$
\begin{align*}

&H_0: \mu_2-\mu_1 = \cdots = \mu_p-\mu_{p-1} \\

\iff &H_0: \mu_3 -2 \mu_2+\mu_1 = 0, \; \; \cdots, \; \; \mu_p - 2 \mu_{p-1} + \mu_{p-2} = 0 \\

\iff C_{(p-2) \times p},  &H_0: C \pmb \mu = \pmb 0

\end{align*}
\$

at here, we acquire test stat \(T^2 \overset {H_0} {\sim} (n-1) \dfrac{p-2}{n-p+2} F_{p-2,n-p+2}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{inferences-about-a-covariance-matrix}{%
\subsection{3. Inferences about a Covariance Matrix}\label{inferences-about-a-covariance-matrix}}

let rs \(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\).

\$
H\_0 : \Sigma = \Sigma\_0
\$

let \(W = (n-1)S = \sum_{i=1}^n (\pmb X_i - \bar {\pmb X})(\pmb X_i - \bar {\pmb X})'\). then

\$

\Lambda\^{}\ast 

= \left( \dfrac{e}{v} \right)\^{}\{\tfrac{pv}{2}\} \lvert \Sigma\_0\^{}\{-1\} W \rvert\^{}\{\tfrac{v}{2}\} \exp \left[ -\tfrac {1}{2} tr(\Sigma_0^{-1} W) \right], ; ; ; ; ; ; ; v=n-1

\$

then calculate \(L=-2 ln \Lambda^\ast \; \; \; \; \; \; \; \overset {H_0}{\sim}\) function of \(\chi^2\)-distribution.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Test for Sphericity (Test for no Correlation)
\end{itemize}

\$
H\_0 : \Sigma = \sigma\^{}2 I
\$

\$ \Lambda = \dfrac {\vert W \vert}{\left[ \tfrac {1}{p}tr(W) \right]^p} \overset {H_0}{\sim} \$ function of \(\chi^2\)-distribution.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Test for Compound Symmetry
\end{itemize}

if \(\Sigma = \begin{bmatrix} \sigma^2 & \rho & \cdots & \rho \\\rho & \sigma^2 & & \vdots \\ \vdots & \rho & \ddots & \rho \\ \rho & \cdots & \rho & \sigma^2 \\ \end{bmatrix}\), then \(\Sigma\) has compound symmetry.

\$
H\_0: \Sigma \text{ has compound symmetry.}
\$

Compute \(\Lambda = \dfrac{\vert S \vert} {(S^2)^p (1-r)^{p-1} (1+ (p-1)r)}\), where
- \$S\^{}2 = \dfrac{1}{p}\sum\emph{\{i=1\}\^{}p S}\{ii\} \$.
- \$r = \dfrac{1}{p} \dfrac{2}{(1-p)S^2} \sum\emph{\{i\textless j\}\^{}p S}\{ij\} \$.

reject \(H_0\) if \(Q> \chi_f^2 (\alpha), \; \; \; \; \; f= \tfrac{p(p+1)-4}{2}\)
- \(Q = -\dfrac{(N-1)-p(p+1)^2(2p-3)}{6(p-1)(p^2+p-4)} \ast \ln\Lambda\).

\hypertarget{comparison-of-several-mv-means-wk5}{%
\section{Comparison of Several MV Means (wk5)}\label{comparison-of-several-mv-means-wk5}}

\hypertarget{paired-comparison}{%
\subsection{Paired Comparison}\label{paired-comparison}}

\emph{Recall:}

for univariate, let \(X_i - Y_i = D_i \sim N(\delta, \sigma_d^2)\), \(i=1, \cdots, n\)

then for \(H_0 : \delta = 0\), test stat \(t = \tfrac{\bar D}{\tfrac{S_d}{\sqrt{n}}} \overset {H_0}{\sim} t_{n-1}\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Assume independent rvec \(\pmb D_1 , \cdots, \pmb D_n \sim N_p (\pmb \delta , \Sigma_{\pmb d})\).

then test stat \(T^2 = n(\bar {\pmb D} - \pmb \delta)' S^{-1}_{\pmb d} (\bar {\pmb D} - \pmb \delta) \sim (n-1)\tfrac{p}{n-p} F_{p, n-p}\).

\begin{itemize}
\tightlist
\item
  Hypothesis Testing:
\end{itemize}

\$
H\_0 : \pmb \delta = \pmb 0
\$

\$

T\^{}2 = n(\bar \{\pmb D\} )' S\^{}\{-1\}\emph{\{\pmb d\} (\bar \{\pmb D\} ) \sim \tfrac{(n-1)p}{n-p} F}\{p, n-p\}

\$

reject \(H_0\) if \(T^2 > \tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \$100(1-\alpha) \% \$ CR for \(\pmb \delta\):
\end{enumerate}

\$

(\bar \{\pmb D\} - \pmb \delta)' S\^{}\{-1\}\emph{\{\pmb d\} (\bar \{\pmb D\} - \pmb \delta) \le \tfrac{1}{n} \tfrac{(n-1)p}{n-p} F}\{p, n-p\} (\alpha)

\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  \$100(1-\alpha) \% \$ simultaneous CI for individual \(\delta_i\):
\item
  Bonferroni's \$100(1-\alpha) \% \$ simultaneous CI for individual \(\delta_i\):
\end{enumerate}

\$
\begin{alignat*}{3}

\bar d_i \pm 
&\sqrt{\tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)} 
&\sqrt{\tfrac{S^2_{d_i}}{n}} \tag{2} \\

\bar d_i \pm 
&t_{n-1} \left( \tfrac {\alpha} {2p} \right)
&\sqrt{\tfrac{S^2_{d_i}}{n}}\tag{3}


\end{alignat*}
\$

\begin{itemize}
\tightlist
\item
\end{itemize}

--

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

====

\hypertarget{different-approach}{%
\paragraph{Different Approach}\label{different-approach}}

let \(\pmb X = \left[ x_{11}, \cdots, x_{1p}, x_{21}, \cdots, x_{2p} \right]_{1 \times 2p}' \sim N_{2p}(\pmb \mu, \Sigma)\).

then \(\pmb D = C \pmb X\), where \$C = \left(

\begin{matrix} 1 &  & \pmb 0 & \vdots & -1 &  & \pmb 0 \\  & \ddots &  & \vdots &  & \ddots &  \\ \pmb 0 &  & 1 & \vdots & \pmb 0 &  & -1 \end{matrix}

\right)\_\{p \times 2p\} \$.

at here,

\$
\begin{align*}

E(\pmb D) 
&= E(C \pmb X) = C \pmb \mu \\ 
&= \pmb \delta\\
\\

Cov(\pmb D)  
&= Cov(C \pmb X) = C \Sigma C' \\ 
&= \Sigma_d\\

\\

\pmb D &= C \pmb X \sim N_p (C \pmb \mu, C \Sigma C')

\end{align*}
\$

therefore, given \(H_0 : C \pmb \mu = \pmb 0\),

test stat \(T^2 = n (C \bar {\pmb X})' (CSC')^{-1} (C \bar {\pmb X}) \overset {H_0}{\sim} \tfrac{(n-1)p}{n-p} F_{p, n-p}\)

\begin{itemize}
\tightlist
\item
  graph, check normality:
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{comparing-mean-vectors-from-two-populations}{%
\subsection{Comparing Mean Vectors from Two Populations}\label{comparing-mean-vectors-from-two-populations}}

\emph{Recall:}
univariate, \$ t = \dfrac{\bar X_1 - \bar X_2} \{sqrt\{S\_p\^{}2 \left( \tfrac{1}{n_1} + \tfrac{1}{n_2}\right)\}\} \overset {H_0}{\sim} t\_\{n\_1 + n\_2 - 2\}\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

for MV, assume below, where \((\pmb X_{11}, \cdots, \pmb X_{1n_1})\) and \((\pmb X_{21}, \cdots, \pmb X_{2n_2})\) are independent.

\$
\pmb X\_\{11\}, \cdots, \pmb X\_\{1n\_1\} \sim N\_p (\pmb \mu\_1 , \Sigma\_1 )

\$
\$

\pmb X\_\{21\}, \cdots, \pmb X\_\{2n\_2\} \sim N\_p (\pmb \mu\_2 , \Sigma\_2 )
\$

at here,

\$
H\_0 : \pmb \mu\_1 - \pmb \mu\_2 = \pmb 0
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{case-1-_1-_2}{%
\paragraph{\texorpdfstring{case 1: \$ \Sigma\_1 = \Sigma\_2 = \Sigma \$}{case 1: \$ \_1 = \_2 = \$}}\label{case-1-_1-_2}}

이하 대부분은 벡터에 관한 이야기이다.

\(\bar X_i\) estimates \(\mu_i\), \(i=1,2\).

\(S_p\) estimates \(\Sigma\), where \$S\_p = \dfrac {(n_1 -1)S_1 + (n_2 - 1) S_2} \{(n\_1-1) + (n\_2-1)\} \$.

the test stats \textbf{Hotelling's } \$ T\^{}2 = \dfrac {n_1 n_2}{n_1 + n_2} \left( \bar \{X\_1 \} - \bar \{X\_2\} \right) ' S\_p\^{}\{-1\} \left( \bar \{X\_1 \} - \bar \{X\_2\} \right) \$

where \$ \dfrac {(n_1 - 1) + (n_2 - 1) - (p - 1)} \{p {[} (n\_1 - 1) + (n\_2 - 1) {]}\} ; T\^{}2 = \dfrac {n_1 + n_2  - p - 1} \{p {[} (n\_1 + n\_2 - 2) {]}\} ; T\^{}2 \overset{H_0}{\sim} F\_\{p, n\_1 + n\_2 -p - 1\}\$. (p.285 for pf)

\begin{itemize}
\tightlist
\item
  \textbf{CR for \(\mu_1 - \mu_2\)} will be
\end{itemize}

\$

Pr \left[ 
\left( 
\left( 
(\bar X_1 - \bar X_2 ) - (\mu_1 - \mu_2) 
\right)^T
\left( 
\left( 
\dfrac {1}{n_1} + \dfrac {1}{n_2}
\right) S_p

\right)^{-1}

\left( 
(\bar X_1 - \bar X_2 ) - (\mu_1 - \mu_2) 
\right)

\le c^2

\right)
\right] = 1-\alpha

\$

where \$ c\^{}2= \dfrac {p [ (n_1 + n_2 - 2) ]} \{n\_1 + n\_2 - p - 1\} ; T\^{}2 \overset{H_0}{\sim} F\_\{p, n\_1 + n\_2 -p - 1\} (\alpha)\$.
* 이때 constant가 역수가 되었음을 눈치.
* The equality will define the boundary of a region.
* The region is an ellipsoid centered at \((\bar X_1 - \bar X_2)\).

\hypertarget{example-testing-h_0-mu_1---mu_2-0-at-alpha0.05-is-equivalent-to-see-whether-falls-within-the-confidence-region}{%
\subparagraph{\texorpdfstring{Example) Testing \(H_0 : \mu_1 - \mu_2 = 0\) at \(\alpha=0.05\) is equivalent to see whether falls within the confidence region}{Example) Testing H\_0 : \textbackslash mu\_1 - \textbackslash mu\_2 = 0 at \textbackslash alpha=0.05 is equivalent to see whether falls within the confidence region}}\label{example-testing-h_0-mu_1---mu_2-0-at-alpha0.05-is-equivalent-to-see-whether-falls-within-the-confidence-region}}

\begin{itemize}
\tightlist
\item
  Axes of the confidence region
  * let \(\lambda_1 , \cdots, \lambda_p\) are ev of \(S_p\).
  * let \(e_1 , \cdots, e_p\) are evc of \(S_p\).

  \begin{itemize}
  \tightlist
  \item
    then \(e_i\)'s are the direction of CI
  \item
    \$\sqrt{\lambda_i} \sqrt{ \left( \dfrac{1}{n_1} + \dfrac{1}{n_2}\right) c^2} \$are the half-length of the CR \href{}{Link}
  \end{itemize}
\end{itemize}

let \$ c\^{}2= \dfrac {p [ (n_1 + n_2 - 2) ]} \{n\_1 + n\_2 - p - 1\} ; T\^{}2 \overset{H_0}{\sim} F\_\{p, n\_1 + n\_2 -p - 1\} (\alpha)\$.

\begin{itemize}
\tightlist
\item
  \(100(1-\alpha)%
  \) \textbf{simultaneous CI} for \(a'(\mu_1 - \mu_2)\), \(\forall a\):\\
  \$
\end{itemize}

a' \left( \bar X\_1 - \bar X\_2 \right) \pm c \sqrt{a' \left( \dfrac{1}{n_1} + \dfrac{1}{n_2}\right) S_p a}

\$

\hypertarget{example-simultaneous-ci-for-mu_1i---mu_2i-i1-cdots-p.}{%
\subparagraph{\texorpdfstring{Example) simultaneous CI for \((\mu_{1i} - \mu_{2i}), i=1, \cdots, p\).}{Example) simultaneous CI for (\textbackslash mu\_\{1i\} - \textbackslash mu\_\{2i\}), i=1, \textbackslash cdots, p.}}\label{example-simultaneous-ci-for-mu_1i---mu_2i-i1-cdots-p.}}

let \(a' = \left[0, \cdots, 0, 1, 0, \cdots, 0 \right]\). 이때 \(a'\)가 하나만 1이고 나머지 0이면, 어떤 특별한 한 axis로 proj하라는 의미. \href{}{link}

let \(\mu_1 - \mu_2 = \left[ \mu_{1i} - \mu_{2i} \right]_{i=1,\cdots,p}\).

\$ a'(\bar X\_1 - \bar X\_2) = \bar X\_\{1i\} - \bar X\_\{2i\}\$, \(a' \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_p a = \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_{p \; ii}\)
* \(S_{p \; ii}\) : p번째 변수의 표본 cov. 이는 단변량에서 나왔던 공통 cov, 즉 샘플 se와 표기법이 동일해지며 유사하다. (ch1) \href{}{link}

the Bonferroni's \$100(1-\alpha)\% \$ simultaneous CI for \((\mu_{1i} - \mu_{2i})\) is \$ (\bar X\_1 - \bar X\_2) \pm t\_\{n\_2 + n\_2 -2, (\dfrac{\alpha}{2p})\} \sqrt{\left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_{p \; ii}}\$.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{case-2-_1-_2}{%
\paragraph{\texorpdfstring{case 2: \$ \Sigma\_1 \not = \Sigma\_2 \$}{case 2: \$ \_1 = \_2 \$}}\label{case-2-_1-_2}}

assume \(n_1 - p , \; n_2 - p\) are large.

for \(H_0 : \mu_1 - \mu_2 = 0\), test stat becomes \(T^2 = (\bar X_1 - \bar X_2 )' \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2 \right]^{-1} (\bar X_1 - \bar X_2 ) \overset{H_0}{\sim} \chi_p^2\).

\begin{verbatim}
$
E(\bar X_1 - \bar X_2 ) = \mu_1 - \mu_2
$

$
Cov(\bar X_1 - \bar X_2 ) = Cov(\bar X_1) + Cov(\bar X_2 ) - 2 Cov(\bar X_1, \bar X_2 ) = \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2 - 0
$


$
\bar X_1 - \bar X_2 \overset{\cdot}{\sim} N_p \left( \mu_1 - \mu_2, \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2  \right)
\tag{∵ CLT}
$

$\\[3ex]
$

$
\text{under } H_0, 
$

$
S_1 \overset{p}{\to} \Sigma_1, S_2 \overset{p}{\to} \Sigma_2 \tag{∵ WLLN}
$

$
(\bar X_1 - \bar X_2 )' \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2\right]^-1 (\bar X_1 - \bar X_2 ) \overset{app}{\sim} \chi_p^2 \tag{∵ Slutsky's thm}
$
\end{verbatim}

\textbf{\emph{why Cov become 0???}}

i.e.~reject \(H_0\) if \(T^2 > \chi_p^2 (\alpha)\).

CI becomes

\$

Pr \left[ 
\left( 
\left( 
(\bar X_1 - \bar X_2 ) - (\mu_1 - \mu_2) 
\right)^T
\left( 
\left( 
\dfrac {1}{n_1} + \dfrac {1}{n_2}
\right) S_2

\right)^{-1}

\left( 
(\bar X_1 - \bar X_2 ) - (\mu_1 - \mu_2) 
\right)

\le \chi_p^2

\right)
\right] = 1-\alpha

\$

차이는\textasciitilde\textasciitilde{}

Remark: if \(n_1 = n_2 = 2\),

\$
\begin{align*}

\dfrac{1}{n_1} S_1 + \dfrac{1}{n_2} S_2 

&=  \dfrac{1}{n} (S_1 + S_2) \\

&= \dfrac{1}{n}

\left[

\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{1i} - \bar {\pmb X_1})(\pmb X_{1i} - \bar {\pmb X_1})' + 
\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{2i} - \bar {\pmb X_2})(\pmb X_{2i} - \bar {\pmb X_2})'

\right] \\

&= \dfrac{1}{n} \dfrac{1}{n-1} S_p \ast 2(n-1) 

= \dfrac{2}{n}  S_p 


\end{align*}
\$

i.e.~case 1 and case 2 are the same procedure when the sample sizes are the same for large sample sizes.

\begin{itemize}
\tightlist
\item
  \(100(1-\alpha)%
  \) \textbf{simultaneous CI} for \(\pmb a'(\pmb \mu_1 - \pmb \mu_2)\), \(\forall \pmb a\):
\end{itemize}

\$

\pmb a' \left( \bar \{\pmb X\_1\} - \bar \{\pmb X\_2\} \right) \pm \sqrt{\chi_p^2(\alpha)} \sqrt{\pmb a' \left( \dfrac{1}{n_1}S_1 + \dfrac{1}{n_2}S_2 \right) \pmb a}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{other-statistics-for-testing-two-mean-vectors}{%
\paragraph{Other Statistics for Testing two Mean Vectors}\label{other-statistics-for-testing-two-mean-vectors}}

\begin{itemize}
\item
  let \(W=(n_1-1)S_1 + (n_2-1)S_2\): within SS, \(B=n_1 (\bar {\pmb X_1} - \bar {\pmb X})(\bar {\pmb X_1} - \bar {\pmb X})' + n_2 (\bar {\pmb X_2} - \bar {\pmb X})(\bar {\pmb X_2} - \bar {\pmb X})'\)
\item
  Wilk's Lambda:

  \begin{itemize}
  \tightlist
  \item
    when two-sample procedure, Hotelling's \(T^2\)
  \end{itemize}
\end{itemize}

\$
\Lambda\^{}\ast = \dfrac{\vert W \vert}{\vert B+W \vert}
\$

\begin{itemize}
\tightlist
\item
  Lawley-Hotelling's Trace:
\end{itemize}

\$
tr(BW\^{}\{-1\})
\$

\begin{itemize}
\tightlist
\item
  Pillai Trace:
\end{itemize}

\$
tr \left[ B(B+W)^{-1} \right]\$

\begin{itemize}
\tightlist
\item
  Roy's Largest Root:

  \begin{itemize}
  \tightlist
  \item
    maximum ev of \(B(B+W)^{-1}\).
  \end{itemize}
\end{itemize}

\hypertarget{testing-equality-of-covariance-matrices}{%
\paragraph{Testing Equality of Covariance Matrices}\label{testing-equality-of-covariance-matrices}}

\$
H\_0 : \Sigma\_1 = \Sigma\_2
\$

let \(S_p = \dfrac{1}{n_1 + n_2 - 2} \left[ (n_1 - 1) S_1 + (n_2 - 1) S_2 \right]\).

\$
\begin{align*}

M &= (n_1 + n_2 - 2) \ln \vert S_p \vert - (n_1 - 1) \ln \vert S_1 \vert - (n_2 - 1) \ln \vert S_2 \vert \tag{test stat} \\

C^{-1} &= 1 - \dfrac{2p^2 + 3p -1}{6(p+1)} \left( \dfrac {n_1 + n_2 - 2}{(n_1-1)(n_2 - 1)} - \dfrac {1}{n_1 + n_2 - 2} \tag{Scale Factor} \\

MC^{-1} &\sim \chi_v^2, \; \; \; \; \; v=\dfrac{p(p+1)}{2}
\end{align*}
\$

reject \(H_0\) if \(MC^{-1} > \chi_v^2(\alpha)\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{profile-analysis-for-g2}{%
\subsection{\texorpdfstring{Profile Analysis (for \(g=2\))}{Profile Analysis (for g=2)}}\label{profile-analysis-for-g2}}

Recall:

\(H_0: \pmb \mu_1 = \pmb \mu_2\), when \(\Sigma_1 = \Sigma_2 = \Sigma\)

\$
\begin{align*}

T^2 &= (\bar {\pmb X_1} - \bar {\pmb X_2})' \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) S_p \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)p} {n_1 + n_2-p-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

let's \(H_0: C \pmb \mu_1 = C \pmb \mu_2\), when \(\Sigma_1 = \Sigma_2 = \Sigma\), where \(C_{q \times p}\), \(q \le p\) and \(rank(C)=q\).

\$
\begin{align*}

T^2 &= (\bar {\pmb X_1} - \bar {\pmb X_2})' C' \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) CS_p C'\right]^{-1} C(\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)q} {n_1 + n_2-q-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}
\$

Profiles are constructed for each group.

Consider two groups. Questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Are the profiles parallel?
\end{enumerate}

\$
\begin{alignat*}{3}

&&H_0 : \mu_{11}-\mu{12} = \mu_{21}-\mu{22}, \mu_{12}-\mu{13} = \mu_{22}-\mu{23}, \mu_{13}-\mu{14} = \mu_{23}-\mu{24}, \cdots, \mu_{1,p-1}-\mu{1,p} = \mu_{2,p-1}-\mu{2,p} \\
&\iff & H_0 : \mu_{11}-\mu{21} = \mu_{12}-\mu{22} = \cdots = \mu_{1p}-\mu{2p}} \\

&\iff C_{(p-1) \times p} &H_0: C \pmb \mu_1 = C \pmb \mu_2

\end{alignat*}
\$

This is equivalent to test the equal mean vector of the transformed data \(C \pmb X_1\) and \(C \pmb X_2\).

Populations 1: \(C \pmb X_{11}, \cdots, C \pmb X_{1n_1} \sim N_{p-1} (C \pmb \mu_1 , C \Sigma C')\)
Populations 2: \(C \pmb X_{21}, \cdots, C \pmb X_{2n_2} \sim N_{p-1} (C \pmb \mu_2 , C \Sigma C')\)

reject \(H_0: C \pmb \mu_1 = C \pmb \mu_2\) (i.e.~paralle profiles), if
\$

T\^{}2 = (\bar \{\pmb X\_1\} - \bar \{\pmb X\_2\})`C' \left[ \left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) CS_p C' \right]\^{}\{-1\} C(\bar \{\pmb X\_1\} - \bar \{\pmb X\_2\}) \textgreater{} d\^{}2 = (n\_1 + n\_2 - 2) \dfrac{p-1}{n_1 + n_2 - p } F\_\{p-1,n\_1+n\_2-p\} (\alpha)

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{coincident-profiles}{%
\paragraph{2. Coincident Profiles}\label{coincident-profiles}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Assuming that the profiles are parallel, are the profiles coincident?
\end{enumerate}

\$
\begin{align*}

&H_0 : \mu_{1i} = \mu_{2i}, i=1, \cdots, p \\
\iff & H_0 : \pmb 1 ' \pmb \mu_1 = \pmb 1 ' \pmb \mu_2

\end{align*}
\$

is the case where \(C\) is replaced by \(\pmb 1 '\).

reject \(H_0\) if

\$
\begin{alignat*}{2}
T^2 &= \pmb 1 ' (\bar {\pmb X_1} - \bar {\pmb X_2}) \left[ \left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 ' S_p \pmb 1 \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) && \\





&= 

\left( 

\dfrac{\pmb 1 ' (\bar {\pmb X_1} - \bar {\pmb X_2})}{\sqrt{\left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 ' S_p \pmb 1}}

\right)^2

&&> F_{1, n_1 + n_2 -2} (\alpha)

(n_1 + n_2 - 2) \dfrac{p-1}{n_1 + n_2 - p } F_{p-1,n_1+n_2-p} (\alpha)



\end{alignat*}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{flat-profiles}{%
\paragraph{3. Flat Profiles}\label{flat-profiles}}

3.Assuming that the profiles are coincident, are the profiles level?

\$
H\_0 : \mu\emph{\{11\} = \mu}\{12\} = \cdots\} = \mu\emph{\{1p\} = \mu}\{21\} = \mu\emph{\{22\} = \cdots\} = \mu}\{2p\}
\$

by 1 and 2, we can collapse two groups into one.

\$
\pmb X\_\{11\}, \cdots, \pmb X\_\{1n\_1\}, \pmb X\_\{21\}, \cdots, \pmb X\_\{2n\_2\} \sim N\_p (\pmb \mu , \Sigma)
\$

this is one population problem

\$
\exist C\_\{(p-1) \times p\}, H\_0: C \pmb \mu = 0
\$

reject \(H_0\), iff

\$
T\^{}2 = (n\_1+n\_2) \bar \{\pmb X\}`C' {[}CSC'{]}\^{}\{-1\} C \bar \{\pmb X\} \textgreater{} d\^{}2 = (n\_1 + n\_2 - 1) \dfrac{p-1}{n_1 + n_2 - p +1} F\_\{p-1,n\_1+n\_2-p+1\} (\alpha)
\$

이는 1번에서의 그것과는 \(F\)분포의 df가 변화했다는 점에 주목.
- \(\bar {\pmb X} = \tfrac{1}{n_1 + n_2} \left( \sum_{j=1}^{n_1} \pmb X_{1j}+ \sum_{j=1}^{n_2} \pmb X_{2j} right)\).
- \(S = n_1 + n_2\) sample covariance matrix, using data.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{comparing-several-multivariate-population-means}{%
\subsection{Comparing Several Multivariate Population Means}\label{comparing-several-multivariate-population-means}}

\emph{Recall:}

In univariate, two-sample t-test is extended to Analysis of Variance(ANOVA).

\$
H\_0:\mu\_1 = \cdots =\mu\_g
\$

\$
F\^{}\ast = \dfrac{SSR/df_1} \{SSE/df\_2\} \overset {H_0}{\sim} F\_\{df\_1 , df\_2\}
\$
- where
- SSR: sum of squared regression,
- SSE: sum of squared error,
- SST: sum of squared total
- \(df_1 = g-1, df_2 = N-g, N=\sum_{i=1}^g n_i\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Assume \(g\) population or treatment groups, and \textbf{each groups are independent}. 각 population은 같은 Cov를 갖고 같은 숫자의 패러미터를 갖되 총 observation 숫자랑 각각의 population mean은 다름.

Population 1\textasciitilde g: \(\pmb X_{i1}, \cdots, \pmb X_{in_i} \sim N_p(\pmb \mu_i , \Sigma)\).

\begin{itemize}
\tightlist
\item
  Model
\end{itemize}

\$
\pmb X\_\{ij\} = \pmb \mu\emph{\{i\} + \pmb \epsilon}\{ij\}, ; ; ; ; ; i=1, \cdots, g, ; ; j = 1, \cdots, n\_i

\$

\$
H\_0: \pmb \mu\_1 = \cdots \pmb \mu\_g
\$

\$
\text{where } \pmb X\_\{ij\} =

\begin{bmatrix} X_{ij1} \\ X_{ij2} \\ \vdots \\X_{ijp} \end{bmatrix}

\emph{\{p \times 1\} , \pmb \mu}\{ij\} =

\begin{bmatrix} \mu_{i1} \\ \mu_{i2} \\ \vdots \\ \mu_{ip} \end{bmatrix}

\emph{\{p \times 1\}, \pmb \epsilon}\{ij\} =

\begin{bmatrix} \epsilon_{ij1} \\ \epsilon_{ij2} \\ \vdots \\ \epsilon_{ijp} \end{bmatrix}

\_\{p \times 1\}
\$

\begin{itemize}
\tightlist
\item
  Assumptions

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    The random samples from different populations are independent.
  \item
    All populations have a common covariance matrix \(\Sigma\).
  \item
    Each population is Multivariate Normal. This assumption can be relaxed by C.L.T., when the sample sizes \(n_1 , \cdots, n_g\) are large.
  \end{enumerate}
\end{itemize}

\hypertarget{one-way-manova}{%
\paragraph{One-Way MANOVA}\label{one-way-manova}}

The quantities SSR, SSE and SST become matrices in MANOVA.

\$
\begin{align*}
B &= \sum_{i=1}^g n_i (\pmb X_i - \pmb X) (\pmb X_i - \pmb X)' \tag{SSR} \\

W &= \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \pmb X_i) (\pmb X_{ij} - \pmb X_i)' \\

&= (n_1 -1)S_1 + \cdots + (n_g -1)S_g \tag{SSE}

\end{align*}
\$

\begin{itemize}
\tightlist
\item
  Note:
\end{itemize}

\$
\begin{alignat*}{3}

(\pmb X_{ij} - \bar {\pmb X}) 

&= 


(\bar {\pmb X_i} - \bar {\pmb X}) 


+ (\pmb X_{ij} - \bar {\pmb X_i})&&

\\

(\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) '


&= 


(\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) ' + 

&&(\bar {\pmb X_i} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X_i})'


+ (\pmb X_{ij} - \bar {\pmb X_i}) (\bar {\pmb X_i} - \bar {\pmb X}) '



+ (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})'


\\

\sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) '

&= \sum_{i=1}^g n_i (\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) ' 

&&+ \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})'

\\

T &= B &&+ W



\end{alignat*}
\$

\begin{itemize}
\tightlist
\item
  B: Between Sum of Squares
\item
  W: Within Sum of Squares
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Any test statistic will be a function of B and W. Popular test statistics use eigenvalues of \(BW^{-1}\).

let \(\lambda_1, \cdots, \lambda_r\) be ev of \(BW^{-1}\), where \(r=\) \#\# of non-zero ev's.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Wilk's Lambda (LRT)
\end{enumerate}

\$
\Lambda = \dfrac{\vert W \vert }{\vert B+W \vert } = \dfrac{1 }{\vert I + BW^{-1} \vert } = \prod\_\{i=1\}\^{}r (1+\lambda\_1)\^{}\{-1\}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Pillai's Trace
\end{enumerate}

\$
\begin{align*}
V &= tr[B(B+W)^{-1}] =  tr[B(B(I+B^{-1}W))^{-1}] = tr[B(I+B^{-1}W)^{-1}B^{-1}] \\

&=tr[B^{-1}B(I+B^{-1}W)^{-1}] = tr[(I+B^{-1}W)^{-1}] = tr[I+(B^{-1}W)^{-1}]\\

&=\sum_{i=1}^r \left( \dfrac{\lambda_i}{1+\lambda_i}\right)

\end{align*}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Lawley-Hotelling's Trace
\end{enumerate}

\$
T = tr\left(BW\^{}\{-1\}\right) = \sum\_\{i=1\}\^{}r \lambda\_i
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Roy's Largest Root
\end{enumerate}

\$
U = \max\_\{i=1,\cdots,r\} \left\{ \lambda\_i \right\}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Sampling Distribution of Wilk's Lambda
\end{itemize}

\$
\begin{alignat*}{2}
p=1, g \ge 2:

&\left(\dfrac{\sum_{i=1}^g n_i - g}{g-1}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&&\overset{H_0}{\sim} F_{g, \sum_{i=1}^g n_i - g}

\\






p=2, g \ge 2:

&\left(\dfrac{\sum_{i=1}^g n_i - g-1}{g-1}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&&\overset{H_0}{\sim} F_{2(g-1), 2(\sum_{i=1}^g n_i - g-1)}

\\







p\ge1, g = 2:

&\left(\dfrac{n_1 + n_2 - p -1}{p}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&&\overset{H_0}{\sim} F_{p, n_1 + n_2 - p -1}

\\







p \ge 1, g \ge 3:

&\left(\dfrac{\sum_{i=1}^3 n_i - p-2}{p}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&&\overset{H_0}{\sim} F_{2p, 2(\sum_{i=1}^g n_i - p-2)} 

\\

\text{large sample sizes}:



&- \left( \sum_{i=1}^g n_i -1 -\dfrac{p+q}{2}\right) \ln \Lambda^\ast

&&\overset{H_0}{\sim} \chi^2_{p(g-1)} \tag{Why?}

\end{alignat*}
\$

\hypertarget{multivariate-multiple-regression-wk6}{%
\section{Multivariate Multiple Regression (wk6)}\label{multivariate-multiple-regression-wk6}}

\hypertarget{overview-4}{%
\subsection{Overview}\label{overview-4}}

Recall:

univariate Linear Regression:

repsponse variable \(Y\), \(r\) predictor variables \(Z_1 , \cdots, Z_r\).

\begin{itemize}
\tightlist
\item
  model:
\end{itemize}

\$
\begin{alignat*}{3}
Y_j &= \beta_0 + \beta_1 Z_{j1} + \cdots + \beta_j Z_{jr} + \epsilon_j , \; \; \; \; \; &E(\epsilon_j) = 0, Var(\epsilon_j) = \sigma^2


\pmb Y_{n \times 1} &= \pmb Z_{n \times (r+1)} \pmb \beta_{(r+1) \times 1} + \pmb \epsilon_{n \times 1}, \; \; \; \; \; &E(\pmb \epsilon) = 0, Var(\pmb \epsilon) = \sigma^2 I

\end{alignat*}
\$

\begin{itemize}
\tightlist
\item
  estimation:
\end{itemize}

\$

\begin{alignat*}{3}
\hat {\pmb \beta} &= (\pmb Z ' \pmb Z )^{-1} \pmb Z ' \pmb Y \\

\hat {\pmb \epsilon} &= (\pmb Y - \pmb Z \hat {\pmb \beta}) = \pmb Y - \pmb Z (\pmb Z ' \pmb Z )^{-1} \pmb Z ' \pmb Y = (I - \pmb Z (\pmb Z ' \pmb Z )^{-1} \pmb Z ') \pmb Y \\ &= (I-H)\pmb Y

\end{alignat*}
\$

\begin{itemize}
\tightlist
\item
  inference:
\end{itemize}

let \(\epsilon \sim N_n (\pmb 0, \sigma^2 I)\). then

\$
\begin{alignat*}{3}

\hat {\pmb \beta} &\sim  N_{r+1} (\pmb \beta , \sigma^2(\pmb Z '\pmb Z )^{-1}) \\

\hat {\pmb \epsilon} ' \hat {\pmb \epsilon} &\sim \sigma^2 \chi^2_{n-r-1} \\

\\  

E(\hat {\pmb \epsilon} ) &= \pmb 0 \\

Cov(\hat {\pmb \epsilon} ) &= \sigma^2 (I - \pmb Z (\pmb Z ' \pmb Z )^{-1} \pmb Z ') \\

E\left( \dfrac{\hat {\pmb \epsilon} ' \hat {\pmb \epsilon}}{n-r-1} \right) &= \sigma^2

\end{alignat*}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{multivariate-multiple-regression}{%
\subsection{Multivariate Multiple Regression}\label{multivariate-multiple-regression}}

\begin{itemize}
\item
  \textbf{Notation}
\item
  Model
\end{itemize}

\$

\pmb Y\_\{n \times m\} = \pmb Z\_\{n \times (r+1)\} \pmb \beta\emph{\{(r+1) \times m\} + \pmb \epsilon}\{n \times m\}, ; ; ; ; ; E(\pmb \epsilon\emph{\{(i)\} ) = \pmb 0, Cov(\pmb \epsilon}\{(i)\}, \pmb \epsilon\emph{\{(j)\}) = \sigma}\{ik\} I, ; ; ; i,k = 1, \cdots, m

\$

\begin{itemize}
\item
  \begin{itemize}
  \tightlist
  \item
    Cov of \(m\) responses:
  \end{itemize}
\end{itemize}

\$
\begin{alignat*}{3}

&\Sigma = \begin{bmatrix} \sigma_{11} & & \sigma_{1m} \\ & \ddots & \\ \sigma_{m1}&& \sigma_{mm} \end{bmatrix}, \; \; \; \; \; 

&&Var(\pmb \epsilon_{(i)}) = \sigma_{ii} I,\; \; \; \; \; 

&&Cov(\pmb \epsilon_{(i)}, \pmb \epsilon_{(j)}) = \begin{bmatrix} \sigma_{ik} & & \pmb 0 \\ & \ddots & \\ \pmb 0 && \sigma_{ik} \end{bmatrix}

\end{alignat*}
\$

\begin{itemize}
\tightlist
\item
  the meaning of

  \begin{itemize}
  \tightlist
  \item
    \(0\): observations from different trials, are uncorrelated
  \item
    \(\sigma_{ik}\): errors for different responses on the same trial are correlated
  \end{itemize}
\item
  \(i\)th response \(\pmb Y_{(i)}\):
\end{itemize}

\$
\pmb Y\_\{(i)\} = \pmb Z \pmb \beta\emph{\{(i)\} + \epsilon}\{(i)\}, ; ; ; ; ; \text{with } Corr(\epsilon\emph{\{(i)\}) = \sigma}\{ii\}I , \hat {\pmb \beta_{(i)}} = (\pmb Z ' \pmb Z )\^{}\{-1\} \pmb Z ' \pmb Y\_\{(i)\}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{least-square}{%
\paragraph{Least Square}\label{least-square}}

\begin{itemize}
\tightlist
\item
  Collecting Univariate Least Squares Estimates (LSE)
\item
  Errors
\end{itemize}

\$

\pmb Y - \pmb Z \hat {\pmb \beta} =

\$

\begin{itemize}
\tightlist
\item
  Error Sum of Squares (SSE)

  \begin{itemize}
  \tightlist
  \item
    diagonal elements: Error SS for univariate least squares \((\pmb Y_{(i)}-\pmb Z \pmb \beta_{(i)})' (\pmb Y_{(i)}-\pmb Z \pmb \beta_{(i)})\) is minimized.
  \item
    the generalized \(Var\) \(\lvert (\pmb Y-\pmb Z \pmb \beta)' (\pmb Y-\pmb Z \pmb \beta) \rvert\) is also minimized.
  \end{itemize}
\item
  Properties
\end{itemize}

\$
\begin{align*}


\hat {Y} &= Z \hat \beta = Z(Z'Z)^{-1} Z' Y \\
&= HY \tag{Predicted Values}\\

\hat {\pmb \epsilon} &=  Y - \hat Y = \left[ I - Z(Z'Z)^{-1} Z' \right] Y \\
&= (I-H)Y \tag{residuals} \\

Z' \hat {\pmb \epsilon} &=  Z' \left[ I - Z(Z'Z)^{-1} Z' \right] Y \\
&=  [Z-Z'] Y =\pmb 0 \tag{3}


\hat Y' \hat {\pmb \epsilon} &=  \hat {\beta} ' Z' \left[ I - Z(Z'Z)^{-1} Z' \right] Y \\
&=  [\hat {\beta} '  Z- \hat {\beta} '  Z'] Y =\pmb 0 \tag{4}

\end{align*}
\$
- - by (3), residuals are orthogonal to \(Z\)
- by (4), residuals are orthogonal to \(\hat Y\)

\begin{itemize}
\tightlist
\item
  Error Sum of Squares
\end{itemize}

\$
\begin{align*}

Y'Y &= (\hat Y \hat {\pmb \epsilon} ) ' (\hat Y \hat {\pmb \epsilon} ) \\
&= \hat Y ' \hat Y  + \hat{\pmb \epsilon}' \hat{\pmb \epsilon} \\

\\  

\hat {\pmb \epsilon}' \hat {\pmb \epsilon}&= Y'Y - \hat Y ' \hat Y \\

&= \hat Y ' \hat Y - \hat \beta ' Z' Z \hat \beta 


\end{align*}
\$

\begin{itemize}
\tightlist
\item
  Results 1
  \$
  \textbackslash begin\{alignat*\}\{2\}
\end{itemize}

E(\hat {\pmb \beta}) \&= \pmb \beta, ; ; ; ; ; Cov(\hat {\pmb \beta_{(i)}}, \hat {\pmb \beta_{(j)}}) \&= \sigma\_\{il\} (\pmb Z'\pmb Z)\^{}\{-1\} \textbackslash{}
\textbackslash{}\\
E(\hat {\pmb \epsilon}) = \pmb 0, ; ; ; ; ;E \left(\dfrac{1}{n-r-1} \hat {\pmb \epsilon}'\hat {\pmb \epsilon} \right) = \Sigma

\textbackslash end\{alignat*\}
\$
- - at here, \(\hat {\pmb \epsilon}\) and \(\hat {\pmb \beta}\) are correlated.

\begin{itemize}
\tightlist
\item
  Results 2

  \begin{itemize}
  \tightlist
  \item
    If \(\pmb \epsilon_j\) has a \(N_m (\pmb 0 , \Sigma)\), then \(\hat {\pmb \beta}= (\pmb Z ' \pmb Z )^{-1}\pmb Z 'Y\) is MLE of \(\pmb \beta\)
  \end{itemize}
\end{itemize}

\$
\begin{align*}

\hat {\pmb \beta_{(i)}} &\sim N_{r+1} ({\pmb \beta_{(i)}}, \sigma_{ii} (\pmb Z ' \pmb Z )^{-1}) \\

\hat \Sigma &= \dfrac{1}{n} \hat {\pmb \epsilon} ' \hat {\pmb \epsilon} \\
&= \dfrac{1}{n} (\pmb Y - \pmb Z \hat {\pmb \beta}) ' (\pmb Y - \pmb Z \hat {\pmb \beta}) \tag{5}

\end{align*}
\$

\begin{itemize}
\item
  \begin{itemize}
  \item
    \begin{enumerate}
    \def\labelenumi{(\arabic{enumi})}
    \setcounter{enumi}{4}
    \tightlist
    \item
      is MLE of \(\Sigma\)
    \end{enumerate}
  \item
    \(n \hat \Sigma \sim W_{p,n-r-1} (\Sigma)\).
  \end{itemize}
\item
  Comment

  \begin{itemize}
  \tightlist
  \item
    Multivariate regression requires no new computational problems.
  \item
    Univariate least squares \(\hat {\pmb \beta_{(i)}}\) are computed individually for each response variable.
  \item
    Diagnostics check must be done as in univariate regression.
  \item
    Residual vectors \([ \pmb \epsilon_{j1}, \cdots, \pmb \epsilon_{jm} ]\) can be examined for multivariate normality.
  \end{itemize}
\end{itemize}

\hypertarget{hypothesis-testing}{%
\subsection{Hypothesis Testing}\label{hypothesis-testing}}

\begin{itemize}
\tightlist
\item
  Note:
\end{itemize}

\$
\begin{align*}

&H_0: \text{ responses do not depend on } Z_{q+1}, Z_{q+2}, \cdots, Z_{r} \\

\iff

&H_0: \begin{bmatrix} \beta_{(q+1)1} & \beta_{(q+2)1} & \cdots & \beta_{(q+1)m} \\ \vdots &&& \vdots \\ \beta_{r1} & \beta_{r1} & \cdots & \beta_{rm} \end{bmatrix} = 0 \\

\iff

&H_0: \pmb{\beta_{(2)}} = \pmb 0, \; \; \; \; \; \ \pmb \beta = \begin{bmatrix} \pmb{\beta_{(1)}}_{(q+1) \times m} \\ cdots \\ \pmb{\beta_{(2)}}_{(r-q) \times m} \end{bmatrix}


\end{align*}
\$

\hypertarget{full-model-vs.-reduced-model}{%
\paragraph{Full Model vs.~Reduced Model}\label{full-model-vs.-reduced-model}}

let \(Z = \begin{bmatrix} Z_1 & \vdots Z_2 \end{bmatrix}\), then \(Z \beta = Z_1 \beta_{(1)} + Z_2 \beta_{(2)}\).

under \(H_0\), \(Y = Z \beta_{(1)} + \epsilon\),

let

\$
\begin{align*}

E &= n \hat \Sigma &\\
&= (\pmb Y - \pmb Z \hat{\pmb \beta})'(\pmb Y - \pmb Z \hat{\pmb \beta})& \tag{Full Model}\\
\\  
H &= n(\hat \Sigma_1 - \hat \Sigma), &\text{ where } E_1 = n(\hat \Sigma_1) = (\pmb Y - \pmb Z \hat{\pmb \beta_{(1)}})'(\pmb Y - \pmb Z \hat{\pmb \beta_{(1)}}) \tag{under H0}

\end{align*}
\$

\begin{itemize}
\tightlist
\item
  \$ E=n \hat \Sigma \$. 여기서 E라는 것은 오차행렬이기 때문에, 즉 univariate 를 4번 반복해서 나온 오차를 모은 것이 바로 이 \(E\)라는 행렬.
\end{itemize}

let \(\lambda_1 \ge \cdots \ge \lambda_s\) be non-zero ev of \(HE^{-1}\), \(s=min(m, r-q)\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Four Test Stat:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Wilk's Lambda:
\end{enumerate}

\$
\dfrac{\vert E \vert}{\vert E+H \vert} = \prod\_\{i=1\}\^{}s \dfrac{1}{1+\lambda_i}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Pillai Trace:
\end{enumerate}

\$
tr \left[ H(H+E)^{-1} \right] = \sum\_\{i=1\}\^{}s \dfrac{\lambda_i}{1+\lambda_i}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Lawley-Hotelling's Trace:
\end{enumerate}

\$
tr(HE\^{}\{-1\}) = \sum\_\{i=1\}\^{}s \{\lambda\_i\}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Roy's Largest Root:

  \begin{itemize}
  \tightlist
  \item
    maximum ev of \(H(H+E)^{-1} = \lambda_1\).
  \end{itemize}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{example}{%
\subsection{Example)}\label{example}}

fit FM \(Y = Z \beta + \epsilon\).

fit \(Y_1 , Y_2 , Y_3 , Y_4 = X_1,X_2,X_3\), then we acquire \(E=n \hat \Sigma\).

\begin{verbatim}
1. $~H_0: \begin{bmatrix} \beta_{31},\beta_{32},\beta_{33},\beta_{34} \end{bmatrix} =0~$,
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(H_0: \begin{bmatrix} \beta_{21},\beta_{22},\beta_{23},\beta_{24}\\\beta_{31},\beta_{32},\beta_{33},\beta_{34} \end{bmatrix} =0\),
\end{enumerate}

under \(H_0\), \(Y=Z \beta_{(1)} + \epsilon\)

\$

Z\_1 =

\begin{bmatrix} 1 & X_{11} \\ \cdots & \cdots \\ 1 & X_{n1} \end{bmatrix}

\_\{n \times 2\}, ; ; ; ; ;

\beta\_\{(1)\} =

\begin{bmatrix} \beta_{01} & \cdots & \beta_{0m} \\ \beta_{11} & \cdots & \beta_{1m}  \end{bmatrix}

\_\{2 \times m\}

\$

now, fit \(Y_1 , Y_2 , Y_3 , Y_4 = X_1\) (X\_2, X\_3 excluded), then we acquire \(E_1 =n \hat \Sigma_1, H = n \hat \Sigma_1 - n \hat \Sigma = E_1 - E\).

let's calculate ev of \(HE^{-1}\), and compute Wilk's Lambda \(\Lambda^\ast = \dfrac{\vert E \vert }{\vert E+H\vert }\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sampling-distribution-of-the-wilks-lambda}{%
\paragraph{Sampling Distribution of the Wilk's Lambda}\label{sampling-distribution-of-the-wilks-lambda}}

let Z be full rank of \(r+1\), and \((r+1) + m \le n\).

let \(\epsilon\) be normally distributed.

under \(H_0\), \$ - \left[ n-r-1 -\tfrac {1}{2} (m-r+q+q) \right] \ln (\Lambda\^{}\ast ) \sim \chi\^{}2\_\{m(r-q)\}\$.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{prediction}{%
\paragraph{Prediction}\label{prediction}}

\$

\hat {\pmb Y}\emph{\{n \times m\} = \pmb Z \hat \beta}\{(r+1) \times m\}

\$

assume fixed values \(\pmb {Z_0}_{(r+1) \times 1}\) of the predictor variables. then \(\hat {\pmb \beta}'_{m \times (r+1)} \pmb Z_0 \sim N_m(\pmb \beta ' \pmb Z_0 , \pmb Z_0 ' (\pmb Z ' \pmb Z)^{-1} \pmb Z_0 \Sigma)\).

\begin{itemize}
\tightlist
\item
  \(100(1-\alpha)\%\) simultaneous CI for \(E(Y_i) = \pmb Z_0 ' \pmb \beta_{(i)}\):
\end{itemize}

\$

\pmb Z\_0 ' \pmb \beta\_\{(i)\} \pm \sqrt{(n-r-1) \dfrac{m}{n-r-m} F_{m,n-r-m} (\alpha)} \sqrt{\pmb Z_0 ' (\pmb Z ' \pmb Z)^{-1} \pmb Z_0 \left(\dfrac{n}{n-r-1} \hat\sigma_{ii} \right)}, ; ; ; ; ; i=1,\cdots, m

\$

\begin{itemize}
\item
  \begin{itemize}
  \tightlist
  \item
    where \(\pmb \beta_{(i)}\) is the \(i\)th column of \(\pmb \beta\).
  \item
    \(\hat \sigma_{ii}\) is the \(i\)th diagonal element of \(\hat \Sigma\).
  \end{itemize}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \(100(1-\alpha)\%\) simultaneous C.I. for the individual responses \(Y_{0i} = \pmb Z_0 ' \pmb \beta_{(i)} + \epsilon_{0i}\):
\end{itemize}

\$

\pmb Z\_0 ' \pmb \beta\_\{(i)\} \pm \sqrt{(n-r-1) \dfrac{m}{n-r-m} F_{m,n-r-m} (\alpha)} \sqrt{\left(1+\pmb Z_0 ' (\pmb Z ' \pmb Z)^{-1} \pmb Z_0 \right) \left(\dfrac{n}{n-r-1} \hat\sigma_{ii} \right)}, ; ; ; ; ; i=1,\cdots, m

\$

\hypertarget{pca}{%
\section{PCA}\label{pca}}

PCA는 상관관계 있는 반응변수 \(y\)의 집합을 상관관계 없는 더 작은 집합으로 바꿈. 이 더 작은 직합들의 이름은 \textbf{principal components}. 이는 더 작은 principal components들이 어쩌면 원본 데이터에 들어있는(available) \textbf{거의} 대부분의 정보를 보유하고 있을지도 모른다는 생각에서 출발함.
1. Outlier
2. Cluster
3. Discriminant: Cov 매트릭스 invert 하려면 필요. 샘플 사이즈 작으면 \((n<p)\) 문제터져서 변수 갯수를 줄임.
4. Regression: predictors 사이에 multicollinearity 존재하는지 체크
5. Multivariate Nomality

semi-positive definite

벡터의 매트릭스 \(\textbf {X}_{1 \times p}\) 의 Cov 매트릭스 \(\Sigma\), 이의 \(ev\) \(\lambda_1 \le \cdots \le \lambda_p \le 0\).

\(\textbf a'_i\)는 \$ p \times 1\$인 열벡터. 이것이 \(i=1~p\)개만큼 존재. \(Y_i = \textbf a'_i \textbf {X}_{i}\), 즉 \(Y\)는 \(a\)와 \(X\)의 선형결합.

\$Cov(Y\_1 , Y\_2) = Cov(\textbf a'\_1 \textbf X , \textbf a'\_2 \textbf X ) = \textbf a\_1 ' \Sigma \textbf a\_2 \left( = 0 \right) \$

벡터와 스칼라 여부 주의. Transpose 여부 주의. 0이 되는 건 \$\textbf a\_1 ' \$과 \$ \textbf a\_2 \$ 가 orthogonal.

Var가 클수록 정보량 많음. 1번은 분산이 가장 큼. 2번은 분산이 2번째로 크되 1번째의 \$\textbf {a}\emph{\{1\} \textbf X \$과 orthogonal 해야함. e.g.~\$ Cov \left( \textbf {a}}\{1\}' \textbf X \textbf {a}\_\{2\}' \textbf X \right)\$.

이를 반복.

1st principal component: \(= \textbf e_1 ' \textbf X\).
* \(Var \left( \textbf e_1 ' \textbf X \right)= \textbf e_1 ' \Sigma \textbf e_1 = \lambda_1\).
* 이때, \(e \textbf v\)의 정의에 의해 \$\Sigma \textbf e\_1 = \lambda\_1 \textbf e\_1 \$ .
* \(Var \left( \textbf e_1 ' \textbf X \right)\) 는 \$\textbf e\_1 ' \textbf e\_1 \$ 를 만족하는 값들 중 \(Var \left( \textbf e_1 ' \textbf X \right)\)를 최대화시키는 값.

2nd principal component: \(= \textbf e_2 ' \textbf X\).
* \(Var \left( \textbf e_2 ' \textbf X \right)= \textbf e_2 ' \Sigma \textbf e_2 = \lambda_2\) 는 모든 \(\textbf a_2 ' \textbf X\) 중 \$Cov \left( \textbf e\_1 ' \textbf X\_1 \textbf a\_2 ' \textbf X \right) = 0 \$ 과 \$\textbf e\_2 ' \textbf e\_2 \$를 만족하는 녀석.

즉 PC 자체는 \(\textbf e_i ' \textbf X\) 로 정해짐. \texttt{note\ ***이건\ proj의\ 일종인\ 모양.***} 근데 이걸로 정해지는 이유가 상기의 조건을 만족해야 한다는 거고, 해당 체크 조건들을 \(\textbf e_i ' \textbf X\) 가 모두 통과할 수 있으므로 이걸 PC로 삼는 것에 문제가 없다는 것.

\$
\begin{align*}

    \sum_{i=1}^p Var(\textbf X_i) &=tr(\Sigma) \\
    &= \sigma_{11} + \sigma_{22} + \cdots + \sigma_{pp} \\
    &= \lambda_1 + \lambda_2 + \cdots + \lambda_p \\
    &= \sum_{i=1}^p Var(\textbf Y_i)


\end{align*}
\$

따라서 kth PC에 의해 유발되는 총 Var의 비율은 \$\dfrac {\lambda_k}{\sum_{i=1}^p \lambda_i } = \dfrac {\lambda_k}{\sum_{i=1}^p Var(X_i) } \$.

이인즉 PCA를 거쳐도 p개의 variable 갯수를 유지한다면 설명력의 총합은 동일함. 하지만 우리는 설명력을 1만큼 잃고 변수를 10만큼 줄이기를 원함. 따라서 어느정도 설명력을 잃더라도 그 이상으로 변수의 갯수를 줄이는 선이면 하꼬변수를 쳐냄. 이는 PCA 분석때 기본적으로 분산의 80\% 설명을 기준으로 함.

Cov 매트릭스 \(\Sigma\), PC \(Y_i = \textbf e_i ' \textbf X\). 이때 \(\rho_{Y_i , X_k } = Corr (Y_i , X_k ) = \dfrac {e_{ik} \sqrt{\lambda_i}} {\sqrt{\sigma_{kk}}}, \; \; \; i,k=1,\cdots,p\).

다룰 때의 편의를 위해 PC 구성 단계에서 \(Y_i =\textbf {e}_i ( \pmb {X} - \pmb {\mu} )\) 로 구성하는 경우도 잦음.

PC Score. n개의 관측 중에서 r번째 관측의 variable의 벡터를 \$\textbf X\emph{r \$이라고 설정하자. 그렇다면 \(Y_{ri} = \textbf e_i ' (\textbf X_r - \pmb \mu_r)\). 이때 \(r=1,\cdots, n\). 이때 PC Score는 \$ \hat Y}\{ri\} = \hat { \textbf {e}_i} ' (\textbf X\_r - \{ \hat {\pmb  \mu}\_r\})\$ 로 추정될 수 있다.

\begin{verbatim}
***elbow***
\end{verbatim}

PCA prerequisite
* variable들이 same unit
* variable들이 have similar Var

해결책
* \$\textbf Z \$로 표준화하고 PCA. \(E(\textbf Z) = 0, Cov(\textbf Z )=\rho\)
* PCA 자체를 corr 매트릭스에 적용

\$
\begin{align*}

    \sum_{i=1}^p Var(\textbf Y_i) &= \sum_{i=1}^p Var(\lambda_i) \\
    &= tr(\pmb \rho) \\
    &= \sum_{i=1}^p Var(\textbf Z_i) \\
    &= p

\end{align*}
\$

따라서 이때의 kth PC에 의해 유발되는 총 Var의 비율은 \$\dfrac {\lambda_k}{\sum_{i=1}^p \lambda_i } = \dfrac {\lambda_k}{p} \$.

\(Corr\)을 썼을 때 PC를 어디까지 쓸지를 솎아낼 때는 scree plot이나 \(ev>1\)인지를 기준으로 한다. 모든 기존 변수들의 분산이 1이므로 최소한의 설명력이 1이라는건데, 1도 안되면 그냥 쓰레기들이므로.

Checking Multivariate Normal: 기존 데이터가 mv normal이라면, 각 PC Score는 normal로 분포되어 있다. 각 PC들을 QQ plot 사용해서 체크하면 답나옴.

\hypertarget{factor}{%
\section{Factor}\label{factor}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.33}}@{}}
\toprule
& PCA & FA \\
\midrule
\endhead
concern with explaining & \(Cov\) and/or \(Corr\) structure among measured variables & Variability in the variables \\
Objectives & & 1. Partition the \(p\) response variables into \(m\) subsets, each consisting of a group of variables tending to be more highly related to others. 2. Create a new set of uncorrelated variables, called \textbf{underlying factors} or \textbf{underlying characteristics}. 3. Use the new variables in future analysis. \\
Warnings & & 1. If the original variables are already uncorrelated, no reason to consider FA.2. Subjective decisions are necessary to determine number of factors, to determine the method to get the underlying factors 3. FA solutions are not unique. \\
\bottomrule
\end{longtable}

\hypertarget{orthogonal-factor-model}{%
\paragraph{Orthogonal Factor Model}\label{orthogonal-factor-model}}

\(\pmb X \sim \pmb \mu , \Sigma\).

\textbf{Common Factors} \$F\_1 , \cdots F\_m \$은 \$\pmb X \$와 linearly dependent.
\textbf{errors, Specific Factors} \$\epsilon\_1 , \cdots, \epsilon\_p \$.

\$ \pmb {X_{p \times 1} - \mu_{p \times 1 } =  L_{p \times m }  F_{m \times 1 } +  \epsilon_{p \times 1 }}\$

\textbf{loading} \(l_{ij}\)은 \(i\)번째 variable의 \(j\)번째 factor에 대한 loading.
\textbf{matrix of Factor Loadings} \(\pmb L\)

즉슨, \(X_i - \mu_i\)는 \(F_j\)의 선형결합과 \(\epsilon_i\)를 더하는 것으로 서술될 수 있다는 게 요지.

다만 관측되지 않은 quantity가 너무 많아서 Factor Model의 직접적인 검증은 사실상 불가능함.
따라서 \(\pmb F\)와 \(\pmb \epsilon\)에 추가적인 조건을 덧붙인 후, \(Cov\) 관계성을 체크하는 것으로 대신한다.

\(E(\pmb F) = \pmb 0, Cov(\pmb F) = E(\pmb F \pmb F' ) = I_{m \times m}\)

\$E(\pmb \epsilon) = \pmb 0, Cov(\pmb \epsilon) = E(\epsilon \epsilon') = \pmb \Psi\_\{p \times p\} =

\begin{bmatrix}\Psi_1 &  & 0 \\ & \ddots &  \\ 0 &  & \Psi_p \end{bmatrix}

\_\{p \times p\} \$

\$ \pmb F \perp \pmb \epsilon\$, so \$Cov(\pmb \epsilon, \pmb F ) = E(\pmb {\epsilon F}') = \pmb 0\_\{p \times m\} \$

이때

\$
\begin{align*}

\Sigma = Cov(\pmb X) &= E \left[ (\pmb X - \pmb \mu) (\pmb X - \pmb \mu) ' \right] \\
&= E \left[ \pmb{LF (LF)' + \epsilon(LF)' + (LF) \epsilon' + \epsilon \epsilon'} \right] \\
&= \pmb {LE(FF')L' + E(\epsilon \epsilon')} \\
&= \pmb{LL' + \Psi}

\end{align*}
\$

ㅁㄴㅇㄹ

\$
\begin{align*}

Cov (\pmb {X, F}) = \pmb {E \left[ (X-\mu)(F-0)' \right]} &= E \left[ \pmb {(X-\mu)F' }\right] \\
&= \pmb { E \left[ (LF + \epsilon)F' \right]} \\
&= \pmb { LE(FF') + E(\epsilon F') }\\
&= \pmb { L}

\end{align*}
\$

따라서 Total Variation은:

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{communality} \(h_j^2 = \sum_{j=1}^m l_{ij}^2\).
* contribution by \(m\) column factors
* \$ \pmb {LL}' =

\begin{bmatrix}h_1^2 &  & \sigma_{1p} \\ & \ddots &  \\ \sigma_{p1} &  & h_p^2 \end{bmatrix}

\_\{p \times p\}\$.

\textbf{specific variance} \(\Psi_i\)

\$

Var(\pmb X\_i) = \sum\emph{\{j=1\}\^{}m l}\{ij\}\^{}2 + \Psi\emph{i \textbackslash{}
Cov(\pmb X\_i, \pmb X\_k) = \sum}\{j=1\}\^{}m l\_\{ij\}l\_\{kj\} \textbackslash{}
Cov(\pmb X\_i, \pmb F\_j) = l\_\{ij\}
\$

Notes:
* When \(m=p\), any \(Cov\) matrix \(S\) can be reproduced exactly as \(\pmb{LL}'\), so \(\pmb \Psi\) is the zero matrix.
* When \(m < p\), the FA is most useful. The FA model provides a ``simple'' explanation of covariance in \(\pmb X\).
* When \(m \lll p\), most \(Cov\) matrices \textbf{cannot} be factored as \(\pmb{LL}'+\pmb \Psi\)(while maintaining basic statistical properties).

\hypertarget{uniqueness}{%
\paragraph{Uniqueness}\label{uniqueness}}

Orthogonal factor model is not unique, b/c rotation.

\hypertarget{method-of-estimation}{%
\subsection{Method of Estimation}\label{method-of-estimation}}

Choosing the appropriate Number of Factors:
1. Similar to PCA. Determine the number of factors using scree plot or eigenvalue \(\ge 1\)
2. Do not include \textbf{trivial factors} (only one variable assigned to one factor).
3. Test the adequacy of the chosen number of factors.(Use ML method and LRT) for standardized variable.
4. Use AIC. Choose m that produces the minimum value for AIC.
5. Use SBC (Schwarz's Bayesian Criterion).

Notes:
* \$\Sigma = \pmb{LL}' + \pmb \Psi
* objective is estimating \(\pmb L\)

\hypertarget{principal-component-method}{%
\paragraph{1. Principal Component Method}\label{principal-component-method}}

\$ \Sigma = \pmb {e \Lambda e'} = \pmb {e \Lambda^{1/2}  \Lambda^{1/2} e'}\$. 여기서 기여도가 낮은 \(\lambda_i\)에 해당하는 ev를 뒤에서부터 쳐내서 적당한 ev만으로 구성. 그 경우 \(=\pmb {L_{p \times m} L_{m \times p}'}\).

여기서 specific factors \(\pmb \Psi\)의 \(Var\)을 \(\Sigma - \pmb {LL'}\)의 diagonal elements 를 사용해서 구할 수 있다. 근사는 \(\Sigma \approx \pmb {LL' + \Psi}\).

\$

\Psi\emph{i = \sigma\emph{i\^{}2 - \sum}\{j=1\}\^{}m l}\{ij\}\^{}2 = \sigma\emph{i\^{}2 - \sum}\{j=1\}\^{}m \lambda\emph{j e}\{ij\}\^{}2

\$

이는 위에서 \(l_{ij} = \sqrt {\lambda_j e_{ij}}\)임을 보여놨기에 가능.

the importance of \(j\)th factor

\$
\begin{align*}
= \dfrac {\lambda_j}{\sum_{i=1}^p \lambda_i} &= \dfrac {\sum_{i=1}^p l_{ij}^2} {\sum_{i=1}^p \sigma^2} \\

&= \dfrac {\sum_{i=1}^p l_{ij}^2} {p} \; \; \; \; \; \; \; \; \; \; \text{if} \; \; \Sigma=\pmb \rho

\end{align*}
\$

at here, \textbf{communality} \(h_i^2 = \sum_{j=1}^m l_{ij}^2\).

\hypertarget{ml-method}{%
\paragraph{3. ML Method}\label{ml-method}}

assumption is needed: \(\pmb X \sim N_p (\pmb mu , \Sigma)\), where \$\Sigma = \pmb{LL'} + \pmb \Psi \$.

이때 \(L(\pmb \mu, \Sigma)\)는 \$\Sigma = \pmb{LL'} + \pmb \Psi \$ 이기에 \(\pmb L\), \(\Psi\)에 의존.

\(\hat \pmb L_{MLE}\), \(\hat \pmb \Psi_{MLE}\)는 수치해석으로 찾아짐.

estimated communalities들은 \$ \hat h\_i\^{}2 = \sum\emph{\{j=1\}\^{}m \hat l}\{ij\}\^{}2\$, \(i=1, \cdots, p\).

The importance of \(j\)th factor는\textasciitilde.

\hypertarget{test-for-the-number-of-factors}{%
\subparagraph{3.5. Test for the number of factors}\label{test-for-the-number-of-factors}}

\(H_0: \; \; \Sigma_{p \times p} = \pmb L_{p \times m} \pmb L'_{m \times} + \pmb \Psi_{p \times p}\)
\(H_1: \Sigma_{p \times p}\)는 any other positive definite matrix.

assume \(\pmb X \sim N_p (\pmb mu , \Sigma)\).

under \(H_0\), \$\Sigma = \pmb{LL'} + \pmb \Psi \$. 이때 \$\hat \Sigma\_\{MLE\} = \hat \pmb{L} \hat \pmb{L'} + \hat \pmb \Psi \$.

under \(H_1\), \(\hat \Sigma_{MLE} = S_n\). 이떄 \$ S\_n\$은 sample \(Cov\) matrix.

LRT for testing \(H_0\):

\$
-2log \Lambda = n log \left( \dfrac {\lvert \hat \Sigma \rvert}{\lvert S_n \rvert}\right) = n log \left( \dfrac {\lvert \hat \pmb{L} \hat \pmb{L'} + \hat \pmb \Psi \rvert}{\lvert S_n \rvert}\right)
\$

\hypertarget{bartletts-approx.}{%
\subparagraph{3.7. Bartlett's Approx.}\label{bartletts-approx.}}

reject \(H_0\) if\textasciitilde.

\hypertarget{minimum-residual-method}{%
\paragraph{3. Minimum Residual Method}\label{minimum-residual-method}}

let \$Cov(\pmb X) = \Sigma = \pmb{LL'} + \pmb \Psi \$, and mv regression \(pmb{Y_{n \times m}=Z_{n \times (r+1)} \beta_{(r+1)\times m)} + \epsilon_{n \times m}\)와 유사한 개형.

estimate factor loadings so that the sum of squares of off-diagonal residuals be minimized.

\(\hat \pmb L_{MLE}\), \(\hat \pmb \Psi_{MLE}\)는 수치해석으로 찾아짐.

estimated communalities들은 \$ \hat h\_i\^{}2 = \sum\emph{\{j=1\}\^{}m \hat l}\{ij\}\^{}2\$, \(i=1, \cdots, p\).

The importance of \(j\)th factor는\textasciitilde.

\hypertarget{factor-rotation}{%
\subsection{Factor Rotation}\label{factor-rotation}}

All factor loadings obtained from the initial loading by an orthogonal transformation have the same ability to reproduce the covariance matrix.
* \$\Sigma = \pmb{LL'} + \pmb \Psi = \pmb{L(TT')L'} + \pmb \Psi = \pmb{L^\ast L^\ast '} + \pmb \Psi \$. at here, must be \(TT' = I\) by characteristics of rotation in linear algebra.

From matrix algebra, we know that an orthogonal transformation corresponds to a rigid rotation of the coordinate axes.

An orthogonal transformation of factor loading is called factor rotation.

The communalities \(\hat h_i^2\) and the specific variances \(\hat \Psi_i\) are not changed, b/c \$\pmb{LL'} = \pmb{L^\ast L^\ast '} \$, and diagonal elements of this is communalities.

Rationale: Since the original loadings \(L\) may not be easily interpretable, it is usual practice to rotate them until a ``simpler structure'' is achieved.

\hypertarget{varimax-criterion}{%
\subsection{Varimax Criterion}\label{varimax-criterion}}

define \(\hat l_{ij}^\ast = \dfrac {l_{ij}^\ast}{\hat h_j}\) to be the rotated coefficients. Then the Varimax procedure selects the orthogonal transformation T that makes \(V=\) as large as possible. 이는 일종의 분산으로서 관점될 수 있다.

In words, \$V \propto \sum\_\{j=1\}\^{}mVar\left( l\_j\^{}2 \right) \$ , which is variance of squares of loading for jth factor.

Maximizing \(V\) corresponding to ``spreading out'' the squares of loadings on each factor as much as possible.

\hypertarget{oblique-rotation}{%
\paragraph{Oblique Rotation}\label{oblique-rotation}}

\begin{itemize}
\tightlist
\item
  It is not possible to rotate the axes so that one axes goes through each cluster of variables while keeping the axes orthogonal to one another.
\item
  Such rotation can be achieved by multiplying L by a matrix Q where Q is not an orthogonal matrix.
\item
  Oblique rotations do not produce new factors that remain uncorrelated, which is a contradiction of the initial FA assumptions \(\rightarrow\) not good!
\end{itemize}

\hypertarget{factor-scores}{%
\subsection{Factor Scores}\label{factor-scores}}

In

\hypertarget{discrimination-and-classification}{%
\section{Discrimination and Classification}\label{discrimination-and-classification}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  여러개의 다른 모집단으로부터 나온 데이터들을 \textbf{설명}. discriminants (구분자) 들의 발견.
\item
  관찰치를 \textbf{분류}하여 이를 클래스로 묶고 싶다. why인지는 크게 중요하지 않고, \textbf{예측}을 하고 싶다.
\end{enumerate}

\hypertarget{bayes-rule}{%
\subsection{Bayes Rule}\label{bayes-rule}}

let r\(v\) for populations \(\pi_1 , \pi_2\), \(\pmb X = (x_1 , \cdots, x_p)'\). 이때, \(f_i(\pmb X)\)는 \(\pi_i\)의 pdf. \(R_i\)는 우리가 해당 object를 \(\pi_i\)로 분류하는 \(\pmb X\) 값들의 set.

\$

R\_1 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \ge 1, ; ; ; ; ; R\_2 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \le 1 \tag{1}

\$

let prior of each \(P_i\) be \(\pi_i\), and \(\sum_{i=1}^n P_i = 1\).

\$

R\_1 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \ge \dfrac {P_2}{P_1}, ; ; ; ; ; R\_2 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \le \dfrac {P_2}{P_1} \tag{2}

\$

let the costs of misclassification can be defined by a cost matrix:

\textbar{} classify \(\pi_1\)\textbar{} \(\pi_2\) \textbar{}\\
True Population \(\pi_1\) \textbar{} 0 \textbar{} \(C(2 \vert 1)\) \textbar{}\\
\(\pi_2\) \textbar{} \(C(1 \vert 2)\) \textbar{} 0 \textbar{}

\$

R\_1 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \ge \dfrac {C(1\vert2)}{C(2\vert1)}, ; ; ; ; ; R\_2 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \le \dfrac {C(1\vert2)}{C(2\vert1)} \tag{3}

\$

and let both.

\$

R\_1 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \ge  \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)}, ; ; ; ; ; R\_2 : \dfrac {f_1 ( \pmb X)} \{f\_2 ( \pmb X)\} \le  \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \tag{4}

\$

\hypertarget{classification-with-two-mv-n-populations}{%
\subsection{\texorpdfstring{Classification with Two mv \(N\) Populations}{Classification with Two mv N Populations}}\label{classification-with-two-mv-n-populations}}

assume \(\pmb X_1 \sim N_p( \pmb \mu_1 , \Sigma_1), \pmb X_2 \sim N_p( \pmb \mu_2 , \Sigma_2)\)

\hypertarget{if-sigma_1-sigma_2-sigma-lda}{%
\paragraph{\texorpdfstring{1. if \(\Sigma_1 = \Sigma_2 = \Sigma\) (LDA)}{1. if \textbackslash Sigma\_1 = \textbackslash Sigma\_2 = \textbackslash Sigma (LDA)}}\label{if-sigma_1-sigma_2-sigma-lda}}

this is called Linear Discriminant Analysis, e.g., LDA.

\$

f\_i ( \pmb X ) = \dfrac {1} \{(2\pi)\^{}\{p/2\} \{\lvert \Sigma \rvert\}\^{}\{1/2\}\} \exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_i)' \Sigma^{-1} (\pmb X - \pmb \mu_i) \right]

\$

suppose the populations parameters, \(\pmb \mu_1, \pmb \mu_2, \Sigma\) are known.

The minimum expected cost rule is

\$

\begin{alignat*}{2}


&R_1 : \dfrac {f_1 ( \pmb X)} {f_2 ( \pmb X)} &
&\ge  \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \\



&\exp \left[ 
-\dfrac {1} {2} (\pmb X - \pmb \mu_1)' \Sigma^{-1} (\pmb X - \pmb \mu_1)' +\dfrac {1} {2} (\pmb X - \pmb \mu_2)' \Sigma^{-1} (\pmb X - \pmb \mu_2)

\right]&

&\ge \\



&-\dfrac {1} {2} (\pmb X - \pmb \mu_1)' \Sigma^{-1} (\pmb X - \pmb \mu_1)' +\dfrac {1} {2} (\pmb X - \pmb \mu_2)' \Sigma^{-1} (\pmb X - \pmb \mu_2) &

&\ge \log \left[ \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \right] \\

\\
\\


\Rightarrow \; \; \; \; \;



&(\pmb \mu_1 - \pmb \mu_2)' \Sigma^{-1} \pmb X - \dfrac {1}{2} (\pmb \mu_1 - \pmb \mu_2)' \Sigma^{-1} (\pmb \mu_1 + \pmb \mu_2) &

&\ge 


\\
\\


\Rightarrow \; \hat R_1 \colon \; \; \; \; \; 



&(\bar {\pmb X}_1 - \bar {\pmb X}_2)' {S_p}^{-1} \pmb X - \dfrac {1}{2} (\bar {\pmb X}_1 - \bar {\pmb X}_2)' {S_p}^{-1} (\bar {\pmb X}_1 + \bar {\pmb X}_2) &

&\ge \tag{1}


\\
\\


\Rightarrow \; \hat R_1 \colon \; \; \; \; \; 


& \hat {\pmb a}' \pmb X - \dfrac {1}{2} ( \hat {\pmb a}' \bar {\pmb X_1} + \hat {\pmb a}' \bar {\pmb X_2}) &

&\ge \tag{2}


\end{alignat*}

\$

Allocate (Classify) \(\pmb X_0\) to \(\pi_1\) if \(R_1\) holds.

Note that \(R_1\) has changed to \$ \hat R\_1\$ at last expression.

\((1):\) However, in practice, \(\pmb \mu_1, \pmb \mu_2, \Sigma\) are unknown. 따라서 해당 룰은 상응하는 패러미터를 샘플 패러미터로 대체해서 이루어짐.

\(\pmb \mu_i\)는 \$\bar \{\pmb X\}\_i \$ 로 대체.

we assumed \(\Sigma_1 = \Sigma_2 = \Sigma\), therefore \(\Sigma\) can be replaced by \(S_p = \dfrac{n_1 - 1 } {n_1 + n_2 -2} S_1 + \dfrac{n_2 - 1 } {n_1 + n_2 -2} S_2\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\((2):\) Note that \((\bar {\pmb X}_1 - \bar {\pmb X}_2)' {S_p}^{-1} \pmb X\) is linear combination of variable \(\pmb X\).

let \((\bar {\pmb X}_1 - \bar {\pmb X}_2)' {S_p}^{-1} = \hat {\pmb a}'\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{lda-intuition}{%
\subparagraph{LDA intuition}\label{lda-intuition}}

\hypertarget{posterior}{%
\subparagraph{Posterior}\label{posterior}}

assuming equal prior, equal misclassification cost:

\$
\begin{alignat*}{1}

P(\pi_1 \vert \pmb X) &= \dfrac{f_1 ( \pmb X) } {f_1 ( \pmb X) + f_2 ( \pmb X) } \\

&= 

\dfrac
{\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_1)' \Sigma^{-1} (\pmb X - \pmb \mu_1)' \right] } 

{\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_1)' \Sigma^{-1} (\pmb X - \pmb \mu_1)'\right] + 
\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_2)' \Sigma^{-1} (\pmb X - \pmb \mu_2)'\right]}


\end{alignat*}
\$

Allocate \(\pmb X_0\) to \(\pi_1\), if \$P(\pi\_1 \vert \pmb X\_0) \ge P(\pi\_2 \vert \pmb X\_0) \$.

This is equivalent to the Bayes Rule \$R\_1 \colon f\_1 (\pmb X) \ge f\_2 (\pmb X) \$.

\hypertarget{sigma_1-not-sigma_2-qda}{%
\paragraph{\texorpdfstring{2. \(\Sigma_1 \not = \Sigma_2\) (QDA)}{2. \textbackslash Sigma\_1 \textbackslash not = \textbackslash Sigma\_2 (QDA)}}\label{sigma_1-not-sigma_2-qda}}

This is called Quadratic Discriminant Analysis (QDA).

suppose the populations parameters, \(\pmb \mu_1, \pmb \mu_2, \Sigma_1, \Sigma_2\) are known.

\$

\begin{alignat*}{2}


R_1 \colon \; &-\dfrac {1} {2} (\pmb X - \pmb \mu_1)' \Sigma_1^{-1} (\pmb X - \pmb \mu_1)' +\dfrac {1} {2} (\pmb X - \pmb \mu_2)' \Sigma_2^{-1} (\pmb X - \pmb \mu_2)'&

&\ge \log \left[ \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \right] 

\\
\\


\Rightarrow \; \; \; \; \;

&(\pmb \mu_1 \Sigma_1 ^{-1} - \pmb \mu_2 \Sigma_2 ^{-1} )'  \pmb X - \dfrac {1}{2} \pmb X ' (\Sigma_1^{-1} - \Sigma_2^{-1} ) \pmb X \; \; \; \; \; -k&

&\ge  \tag{3}


\\
\\

\Rightarrow \; \hat R_1 \colon \; \; \; \; \;

&(\pmb \mu_1 S_1 ^{-1} - \pmb \mu_2 S_2 ^{-1} )'  \pmb X - \dfrac {1}{2} \pmb X ' (S_1^{-1} - S_2^{-1} ) \pmb X \; \; \; \; \; - k&

&\ge 





\end{alignat*}

\$

allocate \(\pmb X_0\) to \(\pi_1\) if \(R_1\) holds.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\((3)\) where

\$

\begin{alignat*}{2} 

k &= \dfrac {1} {2} \log \left( \dfrac {\vert \Sigma_1 \vert}{\vert \Sigma_2 \vert}\right) + \dfrac {1}{2} (\pmb \mu_1 ' \Sigma_1^{-1} \pmb \mu_1 - \pmb \mu_2 ' \Sigma_2^{-1} \pmb \mu_2) \\ 

&= \dfrac {1} {2} \log \left( \dfrac {\vert S_1 \vert}{\vert S_2 \vert}\right) + \dfrac {1}{2} (\hat {\pmb X}_1 ' S_1^{-1} \hat {\pmb X}_1 - \hat {\pmb X}_2 ' S_2^{-1} \hat {\pmb X}_2) 

\end{alignat*}

\$

When \(\Sigma_1 = \Sigma_2\), \(\pmb X ' (\Sigma_1^{-1} - \Sigma_2^{-1} ) \pmb X\) disappears, which means LDA.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This regions \(R_1\) is defined by quadratic functions of \(\pmb X\).

\hypertarget{evaluating-classification-functions}{%
\subsection{Evaluating Classification Functions}\label{evaluating-classification-functions}}

The misclassification probability is \(P(1 \vert 2) + P(2 \vert 1)\). . If \(R_1, R_2\) are selected by Bayes Rule, then this misclassification probability is the minimum.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Sample Misclassification Probability:

\$P\_1 \int\emph{\{\hat R\_2\} \hat f\_1 (\pmb x) d\pmb x + P\_2 \int}\{\hat R\_1\} \hat f\_2 (\pmb x) d\pmb x \$

assume \(f_1(\pmb x), f_2(\pmb x)\) are unkown. 우리가 분포를 가정하지 않으면 이를 측정하는 것은 상당히 어렵다.

\hypertarget{apparent-error-rate-aper}{%
\paragraph{Apparent Error Rate (APER)}\label{apparent-error-rate-aper}}

이는 training 샘플 중에서 sample classification function에 의해 분류될 때 잘못 분류된 관찰값들의 분수.
* Training Sample: classification function 제작을 위해 사용되는 데이터
* Test Sample: classification function 평가를 위해 사용되는 데이터. 이는 training sample과는 독립.

\hypertarget{confusion-matrix}{%
\subparagraph{Confusion Matrix}\label{confusion-matrix}}

\textbar{} Predicted Membership \(\pi_1\) \textbar{} \(\pi_2\) \textbar{} \textbar{}\\
Actual\(\pi_1\) \textbar{} \(n_{11}\) \textbar{} \(n_{12}\) \textbar{} \(n_1\) \textbar{}\\
\(\pi_2\) \textbar{} \(n_{21}\) \textbar{} \(n_{22}\) \textbar{} \(n_2\) \textbar{}

the APER \(= \dfrac {n_{21} + n_{12}} {n_1 + n_2}\): 오분류된 item들의 비율.

\textbf{APER은 true 오분류 확률을 과소평가한다.} 이는 classification function 생산에 활용된 데이터들이 또한 이를 평가하기 위해서도 사용되기 때문. 생산에 쓰였던 놈들인만큼 생산된 classification function은 얘들한테 좀 더 최적화되어있을 수밖에 없고 이에 의해 에러율이 낮아진다.

\hypertarget{test-sample-error-rate}{%
\paragraph{Test Sample Error Rate}\label{test-sample-error-rate}}

training 샘플과 독립인, test 샘플이 따로 존재한다면,우리는 misclassification probability를 test 샘플에서 오분류된 비율로 misclassification probability를 계산하는 것이 가능하다.

test 샘플이 없다면, 총 데이터를 training과 test 샘플로 쪼갠다. training 샘플은 classification function의 구축에 사용되고, test 샘플은 이를 평가하는데 쓰인다. 이 과정은 large sample을 필요로 한다.

\hypertarget{hold-out-error-rate}{%
\paragraph{Hold-out Error Rate}\label{hold-out-error-rate}}

\(= \dfrac {n_{21}^{(H)} + n_{12}^{(H)}} {n_1 + n_2}\)

Also called `leave-one-out' or `cross-validation' error rate.
1. 관측값 1개를 뽑아서 (omit) 제외한 후 나머지 데이터들을 사용해서 cf 생산.
2. 위에서 생산한 function을 써서 \textbf{hold-out} 관측값을 분류.
3. 모든 관측값들이 분류될 때까지 1, 2를 반복.

이에 의해, 역으로 1-LOO는 accuracy rate.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{classification-with-several-populations-wk13}{%
\subsection{Classification with several Populations (wk13)}\label{classification-with-several-populations-wk13}}

let associated with \(\pi_i , i = 1, \cdots, g\):
* density \$f\_i (\pmb x) \$
* Prior distribution \(P_i\)
* misclassification cost \(C(k \vert i)\)
* set of \(\pmb x\) classified as, \(R_k\)

\(R_k\) is the region that
* \(f_k(\pmb x) \propto P_k f_k(\pmb x)\) is largest
* \(\sum_{\not k} f_i(\pmb x) \propto \sum_{\not k} P_i f_i(\pmb x) \propto \sum_{\not k} C(k \vert i) P_i f_i(\pmb x)\) is smallest

\begin{itemize}
\tightlist
\item
  \textbf{under equal misclassification cost}, allocate \(\pmb X_0\) to \(\pi_k\) if:
\end{itemize}

\$
\begin{alignat*}{3}
\forall i \not = &k: P_k f_k (\pmb x) &&>P_i f_i (\pmb x) \\
&\log P_k f_k (\pmb x) &&>\log P_i f_i (\pmb x) \\
\end{alignat*}
\$

\begin{itemize}
\item
  \begin{itemize}
  \tightlist
  \item
    the Bayes rule is identical to the rule that maximizes Posterior Probability \(P(\pi \vert \pmb X) = \dfrac{P_k f_k (\pmb x)}{\sum_{i=1}^g P_i f_i (\pmb x)}\)
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{classification-with-several-normal-populations}{%
\paragraph{Classification with several Normal Populations}\label{classification-with-several-normal-populations}}

assume \(f_i (\pmb x) \sim N_p (\pmb \mu_i , \Sigma_i )\), and \textbf{equal misclassification cost}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sigma_1-cdots-sigma_g-sigma-lda}{%
\subparagraph{\texorpdfstring{1. \(\Sigma_1 = \cdots = \Sigma_g = \Sigma\) (LDA)}{1. \textbackslash Sigma\_1 = \textbackslash cdots = \textbackslash Sigma\_g = \textbackslash Sigma (LDA)}}\label{sigma_1-cdots-sigma_g-sigma-lda}}

MVN을 따르는 것에서 \(f_k\)의 형은 알 수 있다.

according to Bayes rule, we allocate \(\pmb x_0\) to \(\pi_k\) if

\$
\log P\_k f\_k ( \pmb x\_0 ) = \max\_i \log P\_i f\_i ( \pmb x\_0 )
\$

이때 constant \$-\dfrac{p}{2} \log(2 \pi) -\dfrac{1}{2} \log(\vert \Sigma \vert) -\dfrac{1}{2} \pmb x\_0 ' \Sigma\^{}\{-1\} \pmb x\_0 \$는 모든 \(\log P_i f_i (\pmb x_0)\)에 대해 공통 (\(k\)에 의존하지 않으므로). 따라서 해당 constant 부위는 비교 목적으로는 무시될 수 있음.

\$
\begin{align*}

d_i (\pmb x) &= \pmb \mu_i ' \Sigma^{-1} \left( \pmb x \right) - \tfrac{1}{2} \pmb \mu_i ' \Sigma^{-1} \pmb \mu_i + \log P_i \tag{1} \\

\\

S_p &= \tfrac{1}{(n_1 + \cdots +n_g) - g} \left[ (n_1-1)S_1 + \cdots (n_g - 1)S_g  \right] \tag{2} \\

\\

\Longrightarrow \hat d_i (\pmb x) &= \bar { \pmb x_i} S_p^{-1} \ast \pmb x - \tfrac{1}{2} \bar { \pmb x_i} ' S_p^{-1} \bar { \pmb x_i} + \log P_i \tag{3}

\end{align*}

\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  define linear discriminant function (LDF) \(d_i (\pmb x)\), where \(i=1, \cdots, g\).
\item
  \(\Sigma\)'s pooled estimate \(S_p\)
\item
  \(d_i (\pmb x)\)'s estimate \(\hat d_i (\pmb x)\), 실질적으로 사용할 LDF function.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Estimated Bayes Rule:

  \begin{itemize}
  \tightlist
  \item
    allocate \(\pmb x_0\) to \(\pi_k\), if \(\hat d_k(\pmb x_0) = \max \{ \hat d_1(\pmb x_0), \cdots, \hat d_g(\pmb x_0) \}\). 뒤의 조건을 만족하는 것이 Likelihood의 키가 가장 큰 population이므로.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{not-sigma-qda}{%
\subparagraph{\texorpdfstring{2. \(\not = \Sigma\) (QDA)}{2. \textbackslash not = \textbackslash Sigma (QDA)}}\label{not-sigma-qda}}

\$
\log P\_k f\_k ( \pmb x\_0 ) = \max\_i \log P\_i f\_i ( \pmb x\_0 )
\$

constant \(-\dfrac{p}{2} \log(2 \pi)\)는 모든 \(\log P_i f_i (\pmb x_0)\)에 대해 공통, 무시 가능.

\begin{itemize}
\tightlist
\item
  define quadratic discriminant function \(d_i^Q (\pmb x)\), where \(i=1, \cdots, g\):
\end{itemize}

\$
\begin{align*}

d_i^Q (\pmb x) &= -\dfrac{1}{2} \log\vert\Sigma_i \vert -\dfrac{1}{2} (\pmb x - \pmb \mu_i)' \Sigma_i^{-1} (\pmb x - \pmb \mu_i) +\log P_i \\

\\

\hat {d}_i^Q (\pmb x) &= -\dfrac{1}{2} \log\vert S_i \vert -\dfrac{1}{2} (\pmb x - \bar {\pmb x_i})' S_i^{-1} (\pmb x - \bar {\pmb x_i}) +\log P_i \tag{Sample}

\end{align*}
\$

\begin{itemize}
\tightlist
\item
  Estimated Bayes Rule:

  \begin{itemize}
  \tightlist
  \item
    allocate \(\pmb x_0\) to \(\pi_k\), if \(\hat d_k^Q(\pmb x_0) = \max \{ \hat d_1^Q(\pmb x_0), \cdots, \hat d_g^Q(\pmb x_0) \}\)
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{other-discriminant-analysis-methods}{%
\subsection{Other Discriminant Analysis Methods}\label{other-discriminant-analysis-methods}}

\begin{itemize}
\tightlist
\item
  Nearest Neighbor Discriminant Analysis (거리 함수 사용)

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Nonparametric approach -- \textbf{no assumption on distribution}

    \begin{itemize}
    \tightlist
    \item
      Idea
      *For a new observation, first find the observation in the training sample that is closest to the new observation. (i.e.~its Mahalanobis distance is smallest) Then assign the new observation to the group from which the observation's nearest neighbor comes.
    \item
      Variations: K-nearest neighbor

      \begin{itemize}
      \tightlist
      \item
        assign each new observation to the group to which a majority of its k nearest neighbors belongs. e.g.~k=5.
      \end{itemize}
    \end{itemize}
  \end{enumerate}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{knn}{%
\paragraph{KNN}\label{knn}}

\(K_1\) belongs to group 1, \(K_2\) belongs to group 2. 우리는 \(K_1 + K_2 =K =5\) 로 설정함. 즉 가장 가까운 이웃 5개를 뽑되 Group 1과 Group 2에서 뽑은 애들을 합하면 총 5개여야 함.

assign \(\pmb x_0\) to group 1 (\(\pi1\)) if \(K_1 \ge K_2\).
- if \(n_1 \not = n_2\), then assign \(\pmb x_0\) to \(\pi1\) if \(\dfrac{K_1}{n_1} \ge \dfrac{K_2}{n_2}\).
- if \(P_1 \not = P_2\), then assign \(\pmb x_0\) to \(\pi1\) if \(P_1\dfrac{K_1}{n_1} \ge P_2\dfrac{K_2}{n_2}\).

\begin{itemize}
\tightlist
\item
  choice of \textbf{hyper-parameters} \(K\):
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(K = \sqrt{n_1}\).
\item
  select \(K\) s.t. minimizes the error rate
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{kernel-density-estimation-discriminant-analysis-kda}{%
\paragraph{Kernel (Density Estimation) Discriminant Analysis (KDA)}\label{kernel-density-estimation-discriminant-analysis-kda}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bayes Rule 이론에서 출발, Likelihood 함수 사용 (KNN과는 이 부분부터 다름. KNN은 Bayes Rule 안썼음): allocate \(\pmb x_0\) to \(\pi_k\), if \(\dfrac{f_1 (\pmb x)}{f_2 (\pmb x)} \ge \dfrac{P_2 C(1 \vert 2)}{P_1 C(2 \vert 1)}\)
  분포에 대한 가정 없이 개시하므로, 밀도함수 자체를 추정해버리자. density estimation: estimate f\_1 (\pmb x) and f\_2 (\pmb x) for each point \(\pmb x\), where \(N(\pmb x_0)\) is neighborhood around \(\pmb x_0\) of width \(\lambda\)

  이동 히스토그램
  람다는 벽돌 하나의 넓이이며, 람다값이 달라지면 추정된 pdf의 형 또한 조금씩 바뀔 수 있음

  \$
  \hat f(\pmb x\_0) = \dfrac{\sharp \pmb x_i \in N(\pmb x_0)}{N \lambda}
  \$

  this estimate is bumpy. 더 발전된 추정법을 찾아내자. 개선된 추정법:
\item
  Parzen Estimate
\end{enumerate}

\$
\hat f(\pmb x\_0) = \dfrac{1}{N \lambda} \sum\emph{\{i=1\}\^{}N K}\{\lambda\} (x\_0 , \pmb x\_i)
\$

위의 초기형 추정에서 사용된 커널함수는 uniform. 가우시안 커널은 정규분포의 형을 따르므로 이는 당연히 분산을 필요로 함. 여기서 분산 부분에 들어가는건 람다이며, 따라서 람다는 벽돌의 넓이, width를 결정하게 된다. 따라서 람다는 called as smoothing parameters, or bandwidth. 추정의 성능은 거의 전적으로 람다의 selection에 달려있음. 람다 잘 고르면 추정 성능 높고, 람다 잘못 고르면 떡락함. 람다를 너무 좁게 잡으면 삐쭉삐쭉해서 과반영되고, 너무 넓게 잡으면 민둥산이 나와서 값 간의 density가 다 비슷비슷한 나쁜 pdf가 추정됨.

at here, popular choice of \(K_{\lambda}\) is Gaussian kernal:

\$

K\_\{\lambda\} (x\_0 , x) = \Psi \left( \dfrac{\vert x-x_0 \vert}{\lambda} \right) = \dfrac{1}{(2 \lambda \pi)^{p/2}} \exp \left\{ \dfrac{1}{2 \lambda} ( \vert \vert \pmb x\_i - \pmb x\_0 \vert \vert )\^{}2 \right\}

\$

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi})}
  \setcounter{enumi}{2}
  \tightlist
  \item
    estimated Bayes Rule:
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    allocate \(\pmb x_0\) to \(\pi_1\), if \(\dfrac{\hat f_1 (\pmb x_0)}{\hat f_2 (\pmb x_0)} \ge \dfrac{P_2 C(1 \vert 2)}{P_1 C(2 \vert 1)}\)
  \end{itemize}
\end{itemize}

이런 식의 비율 접근법은 클래스가 2개인 경우 한정. 늘어나면 달라?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{modern-classification-methods}{%
\paragraph{Modern Classification Methods:}\label{modern-classification-methods}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Decision Trees

  \begin{itemize}
  \tightlist
  \item
    Classification Trees
  \item
    Regression Trees
  \end{itemize}
\item
  Neutral Networks
\item
  Support Vector Machines
\item
  Ensemble
\end{enumerate}

\hypertarget{clustering-distance-methods-and-ordination}{%
\section{Clustering, Distance Methods, and Ordination}\label{clustering-distance-methods-and-ordination}}

\hypertarget{overview-5}{%
\subsection{Overview}\label{overview-5}}

\begin{itemize}
\tightlist
\item
  Example: Customer Segmentation
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{clustering}{%
\paragraph{Clustering}\label{clustering}}

\begin{itemize}
\tightlist
\item
  군집화의 기준
\end{itemize}

동일한 군집에 속하는 개체 (또는 개인) 은 여러 속성이 비슷하고, 서로 다른 군집에 속한 관찰치는 그렇지 않도록 (여러 속성이 비슷하지 않도록) 군집을 구성

\begin{itemize}
\tightlist
\item
  군집화를 위한 변수: 전체 개체 (개인) 의 속성을 판단하기 위한 기준

  \begin{itemize}
  \tightlist
  \item
    인구통계적 변인 (성별, 나이, 거주지, 직업, 소득, 교육 등)
  \item
    구매패턴 변인 (상품, 주기, 거래액 등)
  \end{itemize}
\end{itemize}

군집분석에서는 관측값들이 서로 얼마나 유사한지, 또는 유사하지 않은지를 측정할 수 있는 측도가 필요하다.
- 군집분석에서는 보통 유사성(similarity)보다는 비유사성(dissimilarity)를 기준으로 하며, 거리(distance)를 사용한다.

\(x\)가 연속형일 때 CA의 위력이 최고로 발휘됨. 유사성의 척도로 거리가 사용되는데, 카테고리컬 변수에는 거리 계산이 불가능하기 때문. 꼭꼭 카테고리컬 변수로 CA를 해야겠다면 지시변수로 대체하여 CA를 시도할 수는 있겠으나, 이는 어느정도 억지로 하는 것이고 오점없는 CA는 아님.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{distance-measures}{%
\paragraph{Distance Measures}\label{distance-measures}}

거리 (Distance) 라는 함수. CA에서 사용되는 모든 거리는 pairwise 거리.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Euclid 거리 (Euclidean) : 가장 메이저함
\end{enumerate}

p차원 공간에서 주어진 두 점 \(\pmb x=(x_1 , \cdots, x_p), \; \; \pmb y=(y_1 , \cdots, y_p)\) 사이의 유클리드 거리는

\$
d(\pmb x, \pmb y) = \sqrt{\sum_{i=1}^p (x_i - y_i)^2}
\$

if \(p=2\),

\{:start=``2''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Minkowski 거리
\end{enumerate}

\$
d(\pmb x, \pmb y) = \left\{ \{\sum\_\{i=1\}\^{}p (x\_i - y\_i)\^{}m\} \right\}\^{}\{\tfrac{1}{m}\}
\$

\(m=2\)일 때 이는 Euclidean과 같아진다. 보통은 m의 값으로 짝수를 많이 씀. 민코프는 결국 Euclidean의 일반화.

\{:start=``3''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Mahalanobis 거리
\end{enumerate}

위에서 A와 B의 거리만을 보는 것이 아니라 위의 점들의 군집의 패턴 또한 고려함. x축과 y축에 해당하는 변수들 사이에 correlation이 있다는 것을 반영함. 중앙의 \(S^{-1}\)으로 corr 구조를 반영하는 것. \textbf{뭔 메커니즘으로?} 위 케이스를 생각하면 A는 전체적인 패턴의 연장선 상에서 멀리 있는데, B는 패턴에서 직교해서 벗어나면서 가까이 있음. 따라서 A보다 B가 멀다고 평가 가능.

\$
d(\pmb x, \pmb y) = \sqrt{(\pmb x - \pmb y) ' S^{-1} (\pmb x - \pmb y) }
\$

\{:start=``4''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Manhattan 거리
\end{enumerate}

\$
d\_\{Manhattan\} (\pmb x, \pmb y) = \{\sum\_\{i=1\}\^{}p \vert x\_i - y\_i \vert\}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  Standardization
\end{itemize}

CA는 자료 사이의 거리를 이용하여 수행되기 때문에, 각 자료의 단위가 결과에 큰 영향을 미친다. 이러한 문제를 해결하기 위하여, 가장 널리 쓰이는 방법이 \textbf{표준화 방법}이다. 표준화 방법이란 각 변수의 관찰값으로부터 그 변수의 평균을 빼고, 그 변수의 표준편차로 나누는 것이다. 표준화된 모든 변수가 평균이 0이고 표준편차가 1이 된다. \textbf{사실상 필수}.

\begin{itemize}
\tightlist
\item
  Graphical Tools

  \begin{itemize}
  \tightlist
  \item
    Scatter Plot
  \item
    Scatter Plot using PCA
  \item
    Andrews Plot
  \item
    Star Plot
  \item
    Chernoff Faces
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{hierarchical-clustering}{%
\subsection{Hierarchical Clustering}\label{hierarchical-clustering}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with \(N\) clusters, each containing a single entity and an \(N \times N\) symmetric matrix of distances, \(D=\{d_{ik}\}\).
\item
  Search the distance Matrix \(D\) for the nearest pair of clusters. Let the distance b/w the most similar (가장 거리가 작은) clusters \(U\) and \(V\) be \(d_{UV}\).
\item
  Mearge clusters \(U\) and \(V\). Label the newly formed cluster \((UV)\). Update the entries in the distance Matrix \(D\) by squences below. The distance b/w \((UV)\) and other cluster \(W\) is denoted by \(d_{(UV)W}\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    deleting rows and columns corresponding to clusters \(U\) and \(V\), then
  \item
    adding a row and a column giving the distance b/w \((UV)\) and the remaining clusters.
  \end{enumerate}
\item
  repeat steps 2 and 3 a total of \(N-1\) times. Then, all observations will be in single clusters. Record the identity of clusters that are merged and the levels at which the mergers take place.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{uxacc4uxce35uxc801-uxad70uxc9d1uxbd84uxc11d-example}{%
\paragraph{계층적 군집분석 Example}\label{uxacc4uxce35uxc801-uxad70uxc9d1uxbd84uxc11d-example}}

distance Matrix \(D\)는 \(n^2\)에 의존하여 변수 숫자가 증가하면 연산 시간도 기하급수적으로 증가.

\{:start=``5''\}
5. 계층적 분석에서만 덴드로그램을 그릴 수 있음. a graphical tool to illustrate the merges or divisions.

python 라이브러리 함수 기준 총 distance의 70\%에서 짤라서 clutser를 판정. color\_threshold.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{hcauxc758-uxc885uxb958}{%
\paragraph{HCA의 종류}\label{hcauxc758-uxc885uxb958}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Single Linkage, 단일 연결 (mimum distance, or nearest neighbor)
\end{enumerate}

\$
d\_\{(UV)W\} = \min \left( d\_\{UW\}, d\_\{VW\} \right)
\$

\{:start=``2''\}
2. Complete Linkage, 완전 연결 (maximum distance, or farthest neighbor)

\$
d\_\{(UV)W\} = \max \left( d\_\{UW\}, d\_\{VW\} \right)
\$

\{:start=``3''\}
3. \textbf{Average Linkage, 평균 연결} (average distance)
- 위의 둘이 변동이 너무 심해서 이를 해결하기 위해 제시됨

\$
d\_\{(UV)W\} = \dfrac{1}{n_{UV}n_W} \left( \sum\emph{\{i=1\}\^{}\{n}\{UV\}\} \sum\emph{\{j=1\}\^{}\{n}\{W\}\} d\_\{ij\} \right)
\$

\{:start=``4''\}
4. \textbf{Centriod Method, 중심점 연결} (For each cluster, compute the centroid)

\$
d\_\{(UV)W\} = \text{ distance b/w the centroids of cluster } U \text{ and } V
\$

\{:start=``5''\}
5. \textbf{\sout{Ward's Method}}

bold들이 무난함

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{hcauxc758-uxc7a5uxb2e8uxc810}{%
\paragraph{HCA의 장단점}\label{hcauxc758-uxc7a5uxb2e8uxc810}}

Advantage:
- cluster의 수를 알 필요가 없음
- 덴드로그램 통해 군집화 프로세스와 결과물을 표현 가능

Disadvantage:
- 계산속도가 느림
- 아웃라이어 (이상치) 가 존재할 경우, 초기 단계에 잘못 분류된 군집은 분석이 끝날때까지 소속 cluster가 변하지 않음
- 아웃라이어에 대한 사전검토 필요, Centroid 방법이 아웃라이어에 덜 민감함

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{k-means-clustering}{%
\subsection{K-means Clustering}\label{k-means-clustering}}

K-평균 군집분석법. 사전에 결정된 군집수 \(k\)에 기초하여 전체 데이터를 상대적으로 유사한 k개의 군집으로 구분한다.

Proceeds:
1. 군집수 k를 결정한다
2. 초기 k개 군집의 중심을 선택한다 (랜덤하게)
3. 각 관찰치를 그 중심과 가장 가까운 거리에 있는 군집에 할당한다.
4. 형성된 군집의 중심 (centroid) 을 계산한다.
5. 3-4의 과정을 기존의 중심과 새로운 중심의 차이가 없을 때까지 반복한다.

\hypertarget{determination-of-k}{%
\paragraph{Determination of K}\label{determination-of-k}}

KCA의 결과는 초기 군집수 k의 결정에 민감하게 반응한다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  여러가지의 k값을 선택하여 CA를 수행한 후 가장 좋다고 생각되는 k값을 이용.

  \begin{itemize}
  \tightlist
  \item
    Elbow point 계산하여 k 선택
  \item
    Silhouette plot으로 k 선택
  \end{itemize}
\item
  자료의 시각화를 통하여 K를 결정 (ex. star plot을 2차원 df로 바꾸어 평균 체크했었음)

  \begin{itemize}
  \tightlist
  \item
    자료의 시각화를 위해서는 차원축소가 필수적이고, 이를 위하여 PCA가 널리 사용된다.
  \end{itemize}
\item
  대용량 데이터에서 sampling한 데이터 (이것이 스몰데이터가 됨) 로 HCA를 우선 수행하여 (여기서 덴드로그램이 얻어짐) k의 값을 선택 (즉 HCA와 KCA를 둘 다 쓰므로 hybrid)
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{uxad70uxc9d1uxc758-uxd3c9uxac00uxbc29uxbc95}{%
\subsection{군집의 평가방법}\label{uxad70uxc9d1uxc758-uxd3c9uxac00uxbc29uxbc95}}

\begin{itemize}
\tightlist
\item
  Silhouette Score (Silhouette Plot)
\end{itemize}

\$
s(i) = \dfrac{b(i)-a(i)}{\max \left\{ a(i),b(i) \right\} } =

\begin{cases} 1-\dfrac{a(i)}{b(i)}, & if \; \; a(i) < b(i) \\ 0, & if \; \; a(i) = b(i) \\ \dfrac{b(i)}{a(i)} - 1, & if \; \; a(i) > b(i) \end{cases}

\$

\begin{itemize}
\tightlist
\item
  \(a(i)\): 개체 \(i\)로부터 \textbf{같은} 군집 내에 있는 \textbf{모든 다른} 개체들 사이의 평균 거리. \textbf{작을수록 좋다.} 작을수록 해당하는 군집 안에서 중앙 부분에 components가 모여 있다는 소리이므로.
\item
  \(b(i)\): 개체 \(i\)로부터 \textbf{다른} 군집 내에 있는 개체들 사이의 평균 거리 \textbf{중 가장 작은 값}. \textbf{클수록 좋다.} 클수록 다른 군집에 헷갈려서 속할 일 없이 확실하게 현재 소속되어 있는 군집에 소속되어 구분된다는 소리이므로.
\end{itemize}

1을 넘어갈 수 없으며, 1에 가까울수록 군집화가 잘 된 관찰값. 몇개의 cluster가 설정되었을 때 가장 해당 stat이 높게 나오는지를 통해 판정하는 것이 이 접근법. 평균 Silhouette Score는 모든 obs마다 \(s(i)\)를 구하여 이를 평균낸 값이므로, 평균 Silhouette Score가 1에 가까울수록 군집분석이 잘됐다고 판단 가능.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{clustering-using-density-estimation-wk14}{%
\subsection{Clustering using Density Estimation (wk14)}\label{clustering-using-density-estimation-wk14}}

Based on \textbf{nonparametric} density estimation
The clusters may be viewed as high-density regions in the space separated by low-density regions between them.
No need to specify the number of clusters. It is determined by the method itself.

밀도기반 추정에 요구되는 (hyper) Parameter: bandwidth. 해당 값이 달라지면 결과도 달라짐.
Iris 데이터 예

\hypertarget{kernel-density-estimation-kde}{%
\paragraph{Kernel Density Estimation (KDE)}\label{kernel-density-estimation-kde}}

\$
f(x\_0) = \dfrac{1}{N \lambda} \sum\_\{i=1\}\^{}N K \left( \dfrac{x_0 - x_i}{\lambda} \right) , ; ; ; ; ; x \in R
\$

N은 샘플사이즈, 람다는 밴드위스, K는 스무딩 커널, x\_i는 obs

closed form처럼 보이지만 그냥 상징적인 공식일 뿐. closed form이 있는게 아니라 데이터 포인트마다 고유한 값이 추정되는 것으로 진행됨.

밀도추정에서 가장 많이 쓰는 방법. 추정하고 싶은 포인트는 \(x_0\). \(x_0\)라는 포인트에 대해 density를 추정하고 싶다. \(x_0\) 인근의 관찰치는 더 많은 가중치를 가짐. \(x_0\) 로 부터 멀어질수록 가중치는 감소함. 각 obs 별로 커널함수 부여하고 최종적으로 그 커널함수 다 더한 다음에 스케일링하면 끝.

K의 가장 흔한 선택은 정규분포함수, 즉 Gaussian Kernel

Bandwidth 의 효과: 커널함수의 좌우 넓이에 해당하는 것으로서, 가우시안 커널에서는 표준편차에 해당함. Bandwith가 크면 x값들 간에 차별화가 덜되어서 추정 위력이 떨어짐

봉우리의 갯수는 군집의 갯수로 생각할 수 있음. 지나치게 밴드위스가 좁으면 뾰족한 부분이 다수 튀어나와 군집의 과다추정 발생

그래프는 1차원 밀도 추정에 해당
회색: 정답. 표준정규분포
붉은색: undersmoothed, 𝜆𝜆 = 0.05 (too small)
녹색: oversmoothed, 𝜆𝜆 =
2 (too large)
검정색: optimally smoothed, 𝜆𝜆 = 0.337

Bandwidth 추정

\begin{itemize}
\tightlist
\item
  2D Kernel Density Estimation: 2차원에서의 KDE는 어떻게 확장될 것인가?
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{multidimensional-scaling-mds}{%
\subsection{Multidimensional Scaling (MDS)}\label{multidimensional-scaling-mds}}

Dimension Reduction Methods
- PCA : x변수들끼리의 분산을 최대화시키는 방향으로 차원축소. 한 변수의 분산이 최대화되어야 함
- Factor: 변수간의 correlation을 최대한 깨트리지 않고 반영하는 방향으로 DR. Corr 구조가 최대한 유지
- MDS
- Canonical Discriminant Analysis

이중 위의 둘은 original data의 Variance 설명에 집중함. (ex. 1명이 401호, 1명이 501호에 있다고 하면, 둘의 직선 거리가 그렇게 크게 떨어져있다고 하기는 어렵지만 위의 두 분석법은 멀리 떨어져 있는 것처럼 그래프에 표현될 수 있음. 거리 개념이 없기 땨문)

\begin{itemize}
\item
  MDS

  \begin{itemize}
  \tightlist
  \item
    Fit (projection) the original data into a low-dimensional coordinate system such that any distortion caused by a reduction in dimensionality is minimized.
  \item
    \textbf{Map the distances} between points in a high dimensional space into a lower dimensional space.
  \end{itemize}
\item
  distortion이란? dissimilarity (distance) among the original data points

  \begin{itemize}
  \tightlist
  \item
    For a given set of observed similarities (or distances) between every pair of N items, find a representative of the items in as few dimensions as possible such that the similarities (or distances) in the lower dimensions match, as close as possible with the original similarities (or distances).
  \end{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Nonmetric MDS
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    Only the rank orders of the N(N-1)/2 original similarities are used to arrange N items in a lower-dimensional coordinate system. 거리 없이 rank만 주어져있음. rank만 안무너지도록
  \end{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Metric MDS (자주씀. Principal Coordinate Analysis)
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    The actual magnitudes of the original similarities are used to obtain a geometric representation.
  \end{itemize}
\end{itemize}

\hypertarget{kruskals-stress}{%
\paragraph{\texorpdfstring{\textbf{Kruskal's Stress}}{Kruskal's Stress}}\label{kruskals-stress}}

so-called \textbf{Badness of fit} criterion. MDS가 잘됐다면 기존 오리지널 차원의 거리나 차원축소된 이후의 거리나 비슷해야 함. 크루스칼 스트레스가 작으면 왜곡도 작은 것. 스트레스가 최소인 DR이 최고의 DR.

\begin{itemize}
\item
  Let \(D_{rs}\) denote the actual distance (or dissimilarity) between item r and item s, then the ordered distances are \$D\_\{r\_1 s\_1 \} \textless D\_\{r\_2 s\_2 \} \textless{} \cdots \textless{} D\_\{r\_M s\_M \}, ; ; ; M=

  \begin{pmatrix} N \\ 2 \end{pmatrix}

  \$.
\item
  Let \(d_{rs}\) denote the distance between item r and item s in the lower dimensional space.
\item
  MDS seeks (iteratively) to find a set of \(d\)'s such that \(d_{r_1 s_1 } <d_{r_2 s_2 } < \cdots < d_{r_M s_M }\) and \(Stress = \left\{ \dfrac{\sum_{i=1}^N \sum_{j=1}^{i-1}(D_{ij} - d_{ij})^2} {\sum_{i=1}^N \sum_{j=1}^{i-1} \left( D_{ij} \right)^2} \right\}^{\tfrac{1}{2}}\) is minimized.
\item
  Interpretation Guideline
\end{itemize}

\begin{longtable}[]{@{}cc@{}}
\toprule
Stress & Goodness of Fit \\
\midrule
\endhead
20\% & Poor \\
10\% & Fair \\
\textbf{5\%} & \textbf{Good} \\
2.5\% & Excellent \\
0\% & Perfect \\
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  Goodness of fit = monotonic relationship between the similarities and the final distances.
\end{itemize}

\textbf{Takane's Stress}

\$

Stress = \left\{ \dfrac{\sum_{i=1}^N \sum_{j=1}^{i-1}(D_{ij}^2 - d_{ij}^2)^2} \{\sum\emph{\{i=1\}\^{}N \sum}\{j=1\}\textsuperscript{\{i-1\}\left(D\_\{ij\}}2\right)\^{}2\} \right\}\^{}\{\tfrac{1}{2}\}

\$

Algorithm:
1. For N items, obtain \(M=\dfrac{N(N-1)}{2}\) 개의 distances \(D_{r_1 s_1 }, D_{r_2 s_2 } , \cdots , D_{r_M s_M }\). Tehn an \(N \times N\) matrix \(D = \{D_{ij} \}\) is constructed.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Using a trial configuration in q dimensions, determine distances \(d_{ij}^{(q)}\). The method to get initial \(d_{ij}^{(q)}\) is given later.
\item
  Using the \(d_{ij}^{(q)}\), move the points around to obtain an improved configurations. A new configuration: new \(d_{ij}^{(q)}\) and smaller stress (e.g.~Newton-Raphson method) The process is repeated until the best (minimum stress) representation is obtained.
\item
  Plot minimum stress (q) versus q and choose the best number of dimensions, \(q^\ast\) from an examination of this plot. x축은 축소된 차원, y축은 stress. 차원이 작아질수록 Stress는 높고, 차원이 p라면 (original 차원과 같다면) Stress는 0. PCA와 달리 여기서는 \textbf{elbow에서 멈춤}.

  \begin{itemize}
  \tightlist
  \item
    similar to scree plot
  \end{itemize}
\end{enumerate}

Note:
1. The larger the dimension, the better the fit.
2. Higher dimension means harder to visualize.

\hypertarget{algorithm-to-find-uxcd08uxae30uxac12-d_ijq}{%
\paragraph{\texorpdfstring{Algorithm to find 초기값 \(d_{ij}^{(q)}\)}{Algorithm to find 초기값 d\_\{ij\}\^{}\{(q)\}}}\label{algorithm-to-find-uxcd08uxae30uxac12-d_ijq}}

q값을 줄이려면 수치해석을 시작하기 전에 넣어줄 초기값에 해당하는 초기좌표들이 필요함. 그 값을 구하는 방법.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Construct the \(N \times N\) matrix \(A = \{ a_{ij} \} = \left\{ -\dfrac{1}{2} D_{ij}^2 \right\}\).
\item
  Construct the \(N \times N\) matrix \(B = \left(I - \dfrac{1}{N} J \right) A \left(I - \dfrac{1}{N} J \right) = \{ b_{ij} \} = \{ \bar a_{ij} - \bar a_{i.} - \bar a_{.j} + \bar a_{..} \}\).
\end{enumerate}

where
\$
\bar a\_\{..\} = \sum{j=1}\^{}N \sum{i=1}\^{}N \dfrac{a_{ij}}{N^2}, ; ; ; ; ; J =

\begin{bmatrix} 1 & \cdots & 1 \\ \vdots & \ddots & \vdots \\ 1 & \cdots & 1 \end{bmatrix}

\$

\{:start=``3''\}

D행렬은 distance들의 SSE 행렬 정도에 해당.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Since \(B\) is a symmetric matrix, use the \textbf{spectral decomposition} to write \(B\) in the \(B = V \Lambda V'\). If B is positive semidefinite of rank \textbf{q} (p차원 아님!! \(q \le p\). 거리행렬이 일정 ev까지는 유의할 수 있는데 그 후로는 0만 튀어나올 수 있으며 DR은 바로 이상황에서 일어남. p는 위에서 보였던 유사 scree plot에서 original data의 차원으로 지정되었던 숫자) , there are q positive eigenvalues.
\end{enumerate}

if

\$

\Lambda\_1 =

\begin{bmatrix} \lambda_1 & \cdots & \pmb 0 \\ & \ddots & \\ \pmb 0 & \cdots & \lambda_q \end{bmatrix}

\_\{q \times q\}, ; ; ; ; ; V\_1 =

\begin{bmatrix} \pmb v_1 ,  \pmb v_2 ,  \cdots, \pmb v_q \end{bmatrix}

\_\{N \times q\}

\$

then we can express

\$

B = \{ V\_1 \}\emph{\{N \times q\} \{ \Lambda\emph{1 \}}\{q \times q\} \{ V\_1 ' \}}\{q \times N\}

= V\_1 \Lambda\_1\^{}\{1/2\} \Lambda\_1\^{}\{1/2\} V\_1 ' = ZZ'

\$

where

\$

Z = V\_1 \Lambda\_1\^{}\{1/2\}

=

\begin{bmatrix} \sqrt{\lambda_1} \pmb v_1 , \sqrt{\lambda_2} \pmb v_2 , \cdots, \sqrt{\lambda_q} \pmb v_q \end{bmatrix}

=

\begin{bmatrix} \pmb z_1 ' \\ \pmb z_2 ' \\ \vdots \\ \pmb z_q ' \end{bmatrix}

\_\{N \times q\}

\$

\{:start=``4''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  The rows \$\pmb z\_1 ' , \pmb z\_2 ' , \cdots , \pmb z\_q \$ of \(Z\) are the points whose interpoint distance \(d_{ij}^{(q)} = (\pmb z_i - \pmb z_j)'(\pmb z_i - \pmb z_j)\) match \$D\_\{ij\} \$s in the original distance matrix \(D\).
\item
  Since \(q\) will typically be too large to be of practical interest and we would prefer a smaller dimension \(k\) for plotting, we can use the first \(k\) eigenvalues and corresponding eigenvectors to obtain \(N\) points whose distances \(d_{ij}^{(k)}\) are approximately equal to the corresponding \(D_{ij}\). 오리지널 데이터의 차원 p가 15개였다면, 이 차원을 SVD했을 때 ev 중 5개가 0이어서 q는 15개로 하였다. 여기서 차원을 더 줄이고 싶다면, 가령 k=5개까지 임의로 내려버리고 싶다면, 뒤쪽의 ev 10개에 해당하는 걸 쳐내는 것
\end{enumerate}

Rank is clearly rank 2. 즉 차원을 2차원까지 줄여도 손실되는 정보가 전혀 없다. 따라서 orginal data Distance Matrix에서 보였던 특성이 그대로 똑같이 드러난다.

\hypertarget{linear}{%
\chapter{Linear}\label{linear}}

\hypertarget{svd}{%
\section{SVD}\label{svd}}

\hypertarget{spectral-decomposition-1}{%
\subsection{Spectral Decomposition}\label{spectral-decomposition-1}}

\$
\begin{align}


A = 

\begin{pmatrix} 

a_{11} & & \cdots  &  & a_{1n} \\
\vdots & \ddots &   &  & \vdots \\
a_{i1} & &  \ddots &  & a_{1n} \\
\vdots & &  & \ddots & \vdots \\
a_{m1} & & \cdots  &  & a_{mn}

\end{pmatrix} 

= (a_{ij})









&\; \; \; \; \; \; \;= 

\begin{pmatrix}

\pmb r_1 \\
\vdots \\
\pmb r_m

\end{pmatrix}



\\\

\\\



&\; \; \; \; \; \; \;= 
\begin{pmatrix}

\pmb c_1 &
\cdots &
\pmb c_m

\end{pmatrix}




\end{align}
\$

for symmetric matrix \(A\):

\$

A\_\{p \times p\} = \Gamma \Lambda \Gamma\^{}\{T\} = \sum\_\{j=1\}\^{}p \pmb \lambda\_j \pmb \gamma\_j \pmb \gamma\_j\^{}T

\$

\$

\begin{alignat}{2}

&\Lambda = diag \{\lambda_1 , \cdots, \lambda_p \} &&\; \; \; \; \;=

\begin{pmatrix}

\lambda_1 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \lambda_p



\end{pmatrix}

_{p \times p}


\\

&\Gamma &&\; \; \; \; \;= 

\begin{pmatrix}

\pmb\gamma_1 ,& \cdots, &\pmb\gamma_p

\end{pmatrix}_{p \times p}


\end{alignat}

\$

where \(\pmb \gamma_j\) is evec of \(A\). Therefore \(\Gamma\) is orthogonal Matrix.

let symmetric Matrix of rank \(r\), \(A_{p \times p}\), \((r \le p)\). Then there exists orthogonal Matrix \(\Gamma_{p \times p}\), which means \(\Gamma^T \Gamma = I_p\) and

\$
A = \Gamma \Lambda \Gamma\^{}T = \Gamma 

\begin{pmatrix}

\Lambda_1 & 0 \\
0 & 0

\end{pmatrix}

\Gamma\^{}T =

\Gamma\_1 \Lambda\_1 \Gamma\^{}T\_1
\$

where letting \(\delta_i=\) i-th ev, \(i=1, \cdots, r\), then

\$

\textbackslash{}\\
\textbackslash{}\\

\Gamma =

\begin{pmatrix} \{\Gamma_1\}_{p \times r} , \; \; \; \{\Gamma_0\}_{p \times (p-r)} \end{pmatrix}

\textbackslash{}\\
\textbackslash{}\\

\Lambda = diag \{\lambda\_1 , \cdots, \lambda\_r \} =

\begin{pmatrix}

\lambda_1 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \lambda_r



\end{pmatrix}

\_\{r \times r\}

\$

then \(\Gamma_1^T \Gamma_1 = I_r, \; \; \; \; \Gamma_1^T \Gamma_0 = 0\) and

\$

A\^{}2 = A'A = AA' =

(\Gamma\_1 \Lambda\_1 \Gamma\^{}T\_1)' \Gamma\_1 \Lambda\_1 \Gamma\^{}T\_1 = \Gamma\_1 \Lambda\_1 \Gamma\^{}T\_1 \ast \Gamma\_1 \Lambda\_1 \Gamma\^{}T\_1

= \Gamma\_1 \Lambda\_1\^{}2 \Gamma\^{}T\_1

\$

let \(\{\pmb \gamma_i\}_{p \times 1}\) be i-th column vector of \(\Gamma\). then

\$
\pmb \gamma\_i' \pmb \gamma\_i =

\begin{cases} 1 & & i=j \\ 0 & & i \not = j \end{cases}

\$

thus

\$
\begin{alignat}{2}

A &= \Gamma_1 \Lambda_1 \Gamma^T_1 

&&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \gamma_i '


\\

A'A &= \Gamma_1 \Lambda_1^2 \Gamma^T_1

&&=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i '

\\

AA'&= 

&&

\\

\gamma_k ' A 

&=  \lambda_k \gamma_k ' \gamma_k \gamma_k '  

&&= \lambda_k \pmb\gamma_k ' 



\\

A \gamma_k 

&=  \lambda_k \gamma_k \gamma_k ' \gamma_k  

&&= \lambda_k \pmb \gamma_k 


\end{alignat}

\$

~\\
~\\

\hypertarget{remark-1}{%
\paragraph{remark}\label{remark-1}}

let orthogonal Matrix \(\Gamma\), therefore \(\Gamma ' \Gamma = I\), and \(\det(\Gamma) = \vert \Gamma \vert = 1\).

let symmetric Matrix \(A_{p \times p}\) with full rank. then by SVD,

\$

\det(A) = \vert A \vert = \vert \Gamma \vert \vert \Lambda\vert  \vert \Gamma\^{}T \vert  = \vert \Lambda \vert  =

\begin{vmatrix}
\lambda & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & \lambda_p

\end{vmatrix}

= \prod\_\{i=1\}\^{}p \lambda\_i

\$

let symmetric Matrix \(A_{p \times p}\) with full rank. then by SVD,

\$

\exists n\in \mathbb{R}: ; ; ;

A\^{}n = (\Gamma \Lambda \Gamma`) \ast (\Gamma \Lambda \Gamma')\cdots (\Gamma \Lambda \Gamma`) = \Gamma \Lambda\^{}n \Gamma'
\$

in particular, a Cov Matrix \(\Sigma\) can be written by

\$
\Sigma = \Gamma \Lambda \Gamma\^{}T = \sum\_\{i=1\}\^{}r \lambda\_i \gamma\_i \gamma\_i'

\textbackslash{}

\Sigma\^{}\{-1\} = \Gamma \Lambda\^{}\{-1\} \Gamma\^{}T = \sum\_\{i=1\}\^{}r \lambda\_i\^{}\{-1\} \gamma\_i \gamma\_i'

\textbackslash{}

\Sigma\^{}\{-\tfrac{1}{2}\} = \Gamma \Lambda\^{}\{-\tfrac{1}{2}\} \Gamma\^{}T = \sum\_\{i=1\}\^{}r \lambda\_i\^{}\{-\tfrac{1}{2}\} \gamma\_i \gamma\_i'

\$

~\\
~\\
~\\
~\\

\hypertarget{singular-value-decomposition-general-version}{%
\subsection{Singular value Decomposition: General-version}\label{singular-value-decomposition-general-version}}

decomposition of any aribtrary Matrix with rank \(r\), \(A_{n \times p} = \Gamma_{n \times r} \Lambda \triangle_{p \times r} ' = \sum_{j=1}^r \lambda_j \pmb \gamma_j \pmb \delta_j '\).

\(\Lambda = diag(\lambda_1 , \cdots, \lambda_r), \; \; \; \; \lambda_j >0\). 이때 \(\lambda_i\)는 \(AA'\)나 \(A'A\)의 non-zero ev.

\(\Gamma, \triangle\)는 \(AA'\)와 \(A'A\)의 corresponding \(r\) evec으로 구성. 따라서 Both \$\Gamma ' \Gamma = \triangle ' \triangle  = I\_r \$, i.e., are column orthogonal.

thus

\$

\begin{alignat}{2}




A &= \Gamma \Lambda \triangle^T 

&&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i '


\\

A'A &= \triangle \Lambda^2 \triangle^T

&&=\sum_{i=1}^r \lambda_i^2 \pmb \delta_i \pmb \delta_i '

\\

AA'&= \Gamma \Lambda^2 \Gamma^T

&&=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i '


\\

\gamma_k ' A 

&=  \gamma_k ' \Gamma \Lambda \triangle^T 

&&= \lambda_k \pmb \delta_k '





\\

A \delta_k 

&=  \Gamma \Lambda \triangle^T  \delta_k  

&&= \lambda_k \pmb \gamma_k 


\end{alignat}

\$

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.50}}
  >{\centering\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.50}}@{}}
\toprule
a & b \\
\midrule
\endhead
\(\begin{alignat}{2} A &= \Gamma \Lambda \triangle^T &&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i ' \\ A'A &= \triangle \Lambda^2 \triangle^T &&=\sum_{i=1}^r \lambda_i^2 \pmb \delta_i \pmb \delta_i ' \\ AA'&= \Gamma \Lambda^2 \Gamma^T &&=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i ' \\ \gamma_k ' A &= \gamma_k ' \Gamma \Lambda \triangle^T &&= \lambda_k \pmb \delta_k ' \\ A \delta_k &= \Gamma \Lambda \triangle^T \delta_k &&= \lambda_k \pmb \gamma_k \end{alignat}\) & \$\begin{alignat}{2} A &= \Gamma_1 \Lambda_1 \Gamma^T_1 &&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \gamma_i ' \\ A'A &= \Gamma_1 \Lambda_1^2 \Gamma^T_1 &&=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i ' \\ AA'&=  && \\ \gamma_k ' A &=  \lambda_k \gamma_k ' \gamma_k \gamma_k '  &&= \lambda_k \pmb\gamma_k ' \\ A \gamma_k &=  \lambda_k \gamma_k \gamma_k ' \gamma_k  &&= \lambda_k \pmb \gamma_k \end{alignat} \$ \\
c & d \\
\bottomrule
\end{longtable}

therefore, generalized inverse matrix, G-inverse Matrix \(A^-\) will be

\$

\begin{alignat}{2}




A &= \Gamma \Lambda \triangle^T 

&&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i '

\\


A^- &= \triangle 

 \Lambda^{-1}  \Gamma'

&&=\sum_{i=1}^r \lambda_i^{-1} \pmb \delta_i \pmb \gamma_i '



\\

AA^- A &= \Gamma \Lambda \triangle^T \ast \triangle \Lambda^{-1}  \Gamma' \ast \Gamma \Lambda \triangle^T 

&&=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i ' \; \; \; \; \;  \; \; \; \; \; = A




\end{alignat}

\$

~\\
~\\
~\\
~\\

\hypertarget{singular-value-decomposition-another-version}{%
\subsection{Singular value Decomposition: Another-version}\label{singular-value-decomposition-another-version}}

rank \(r\) arbitrary Matrix \(A_{n \times p} = \Gamma_{n \times r} \Lambda \triangle^T_{p \times r} =\sum_{i=1}^r \lambda_i^{\tfrac{1}{2}} \pmb \gamma_i \pmb \delta_i '\)

\(\Lambda = diag(\lambda_1^{\tfrac{1}{2}} , \cdots, \lambda_r^{\tfrac{1}{2}}), \; \; \; \; \; \lambda_j^{\tfrac{1}{2}} >0\). 이때 \(\lambda_i\)는 \(AA'\)와 \(A'A\)의 non-zero ev.

\(\Gamma, \triangle\)는 \(AA'\)와 \(A'A\)의 corresponding \(r\) evec으로 구성. 따라서 Both \$\Gamma ' \Gamma = \triangle ' \triangle  = I\_r \$, i.e., are column orthogonal.

~\\
~\\
~\\
~\\

\hypertarget{quadratic-forms}{%
\subsection{Quadratic Forms}\label{quadratic-forms}}

for symmetric Matrix \(A_{p \times p}\), vector \(\pmb x \in \mathbb{R}^p\):

\$
Q(x) = \pmb x' A \pmb x = \sum\emph{\{i=1\}\^{}p \sum}\{j=1\}\^{}p a\_\{ij\} x\_i x\_j \tag{quadratic form}
\$

\$
\begin{align}

\forall x \not = 0: Q(x) &> 0 \tag{positive definite} \\

\\



\forall x \not = 0: Q(x) &\ge 0 \tag{positive semi-definite}



\end{align}
\$

if corresponding quadratic form \(Q(\cdot)\) is positive definite(semi-definite), \(A\) is called positive definite(semi-definite). This is written by \(A>0 \; \; \; (\ge 0)\).

~\\
~\\

\hypertarget{propositions}{%
\paragraph{propositions}\label{propositions}}

if \(A=A'\), and \(Q(x) = \pmb x ' A \pmb x\) is corresponding quadratic form, then \$\exists \pmb y = \Lambda\^{}T \pmb x: ; ; ; Q(x) = \pmb x' A \pmb x = \sum\_\{i=1\}\^{}p \lambda\_1 y\_i\^{}2 \$, \(\lambda_i\) is ev of \(A\).

\$
A\textgreater0 \iff \forall \lambda\_i\textgreater0, ; ; ; i=1, \cdots, p
\$

\$
A\textgreater0 ; ; ; \Longrightarrow ; ; ; \vert A \vert \textgreater0, ; \exists A\^{}\{-1\}
\$

\(A=A', \; B=B', \; B>0\), then maximum of \(\dfrac{\pmb x ' A \pmb x}{\pmb x ' B \pmb x}\) is given by the largest ev of \(B^{-1}A\).

the vector which maximizes(minimizes) \(\dfrac{\pmb x ' A \pmb x}{\pmb x ' B \pmb x}\) is the corresponding evec of \(B^{-1}A\) for largest(smallest) ev of \(B^{-1}A\).

more generally, for ev of \(B^{-1}A\), \(\lambda_1, \cdots, \lambda_p\),

\$

\max \left( \dfrac{\pmb x ' A \pmb x}{\pmb x ' B \pmb x} \right)

= ; ; ; ; ;\lambda\_1 \ge \cdots \ge \lambda\_p ; ; ; ; ; =

\min \left( \dfrac{\pmb x ' A \pmb x}{\pmb x ' B \pmb x} \right)

\$

if \({\pmb x ' B \pmb x}=1\), then

\$

\max \left( \{\pmb x ' A \pmb x\} \right)

= ; ; ; ; ;\lambda\_1 \ge \cdots \ge \lambda\_p ; ; ; ; ; =

\min \left( \{\pmb x ' A \pmb x\} \right)

\$

~\\
~\\
~\\
~\\

\hypertarget{partitioned-matrices}{%
\subsection{Partitioned Matrices}\label{partitioned-matrices}}

\(A_{n \times p}, B_{p \times n}\) and \(n \ge p\). then

\$

\begin{vmatrix} 

-\lambda I_n & -A \\
B & I_p 

\end{vmatrix}

= (-\lambda)\^{}\{n-p\} \ast \left \vert BA - \lambda I\_n \right \vert = \left \vert AB - \lambda I\_n \right \vert

\$

for \(A_{n \times p}, B_{p \times n}\), the non-zero ev of \(AB\) and \(BA\) are the same and have the same multiplicity. if \(\pmb x\) is evec of \(AB\) for an ev \(\lambda \not = 0\), then \(y=B \pmb x\) is an evec of \(BA\).

for \(A_{n \times p}, B_{q \times n}, \pmb a_{p \times 1}, \pmb b_{q \times 1}\), if \(rank \left( A \pmb a \pmb b B \right) \le 1\), then non-zero ev, if it exists, equals \(\pmb b' BA \pmb a\) with evec \(A \pmb a\).

~\\
~\\
~\\
~\\

\hypertarget{geometrical-aspects}{%
\subsection{Geometrical Aspects}\label{geometrical-aspects}}

mutually orthogonal \(\pmb x_1 , \cdots, \pmb x_k \iff \forall {i,j}: \; \pmb x_i ' \pmb x_j\)

In that case, \$X= \left( \pmb x\_1 , \cdots, \pmb x\_k \right) \$ has rank \(k\), and \(X'X\) is a diagonal Matrix with \(x_i ' x_i\) in the i-th diagonal position.

let's consider bivariate data \((x_i , y_i), \; \; \; i= 1, \cdots, n\), and let \(\tilde x_i = x_i - \bar {\pmb x}, \; \tilde y_i = y_i - \bar {\pmb y}\). then correlation b/w \(x\) and \(y\) is

\$
\dfrac
\{\sum\_\{i=1\}\^{}n (x\_i - \bar \{\pmb x\})(y\_i - \bar \{\pmb y\})\}
\{\sqrt{\left[ \sum_{i=1}^n (x_i - \bar {\pmb x})^2 \right] \ast \left[ \sum_{i=1}^n(y_i - \bar {\pmb y})^2 \right]}\}

=

\dfrac

\{\tilde x ' \tilde y\}
\{\Vert \tilde x \Vert \ast \Vert \tilde y\Vert\}

= \cos(\theta)

\$

where \(\theta\) is the angle b/w the deviation vectors \({\tilde x}\) and \({\tilde y}\).

For two dimensions, the rotation can be expressed:

\$

\begin{alignat}{2}

\pmb y &= \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}


&&=


\begin{pmatrix} 

\cos(\theta) & \sin(\theta) \\

-\sin(\theta) & \cos(\theta) 


\end{pmatrix}




\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}



&& = \Gamma 

\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

\\
 
&= \Gamma \pmb x \tag{clockwise rotation}



\\\
\\\



\pmb y &


&&=


\begin{pmatrix} 

\cos(\theta) & -\sin(\theta) \\

\sin(\theta) & \cos(\theta) 


\end{pmatrix}




\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

&&= \Gamma  ' 

\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

\\

& = \Gamma  '  \pmb x \tag{counter-clockwise rotation}




\end{alignat}
\$

~\\
~\\
~\\
~\\

\hypertarget{column-row-and-null-space}{%
\subsection{Column, Row and Null Space}\label{column-row-and-null-space}}

Matrix \(X_{n \times p}\):

\$

\begin{alignat}{2}

\mathcal{C}(X)

&=



\{ \pmb x \in \mathbb{R}^n  \; \vert \; \exists \pmb a \in \mathbb{R}^p \; \; s.t. \; \; X \pmb a = \pmb x\}  

&&\subseteq 
\mathbb{R}^n

\tag{column (range) space}

\\


\mathcal{N}(X)

&=

\{ \pmb y \in \mathbb{R}^p  \; \vert \; X \pmb y = 0 \}  &&\subseteq \mathbb{R}^p

\tag{null space}


\\


\mathcal{R}(X)



&= 

\{ \pmb z \in \mathbb{R}^p  \; \vert \; \exists \pmb b \in \mathbb{R}^n \; \; s.t. \; \; X' \pmb b = \pmb z \}


&&\subseteq 
\mathbb{R}^p

\tag{row space}


\\

&= \mathcal{C}(X')


\tag{column space of X`}


\end{alignat}

\$

Spaces by Singular Value Decomposition: General-version,

Matrix \(X_{n \times p}\) with \(rank(X)=r\):

\$

\textbackslash{}

\begin{alignat}{2}

X &= \Gamma \Lambda \triangle^T 

\\

& =\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i '

\\

\mathcal{C}(X)

&= \{ \gamma_1 , \cdots, \gamma_r \}



\\



\mathcal{N}(X)

&= \{ \delta_{r+1} , \cdots, \delta_{p} \}

\\


\mathcal{R}(X)

&= \{ \delta_{1} , \cdots, \delta_{r} \}


\end{alignat}

\$

\begin{itemize}
\tightlist
\item
  note: Matrix \(X_{n \times p}\) with \(rank(X)=r\)
\end{itemize}

\$

\begin{alignat}{2}

\mathcal{N}(X) &= \mathcal{C}(X')^{\perp} = \mathcal{R}(X)^{\perp} \\

\mathcal{N}(X)^{\perp}

&= \mathcal{C}(X')
= \mathcal{R}(X) \\

\\

\\

\mathcal{C}(X'X) &= \mathcal{C}(X') = \mathcal{R}(X) \\

\\

\\

\dim \left( \mathcal{C}(X) \right) &= 
\dim \left( \mathcal{R}(X) \right) \\
= \; \; \; \; \; 
rank(X) &= 
rank(X') = 
rank(X'X) \\ &= r \le \min(n, p)

\end{alignat}
\$

\(X'X\) has full rank (is nonsingular) \(\iff\) if \(X\) has full column rank (\(X\) has linearly independent columns).

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

\hypertarget{what}{%
\subsection{What}\label{what}}

for linear model \[Y = X \beta + \epsilon\]

\$\$
Y\_\{n \times 1\} =

\begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix}

; ; ; ; ; ; ;

\beta\_\{(p+1) \times 1\} =

\begin{pmatrix} \beta_0 \\ \vdots \\ \beta_p \end{pmatrix}

; ; ; ; ; ; ;

\epsilon\_\{n \times 1\} =

\begin{pmatrix} \epsilon_1 \\ \vdots \\ \epsilon_n \end{pmatrix}

\textbackslash{}
\textbackslash{}\\
\textbackslash{}\\
\textbackslash{}\\

X\_\{n \times (p+1)\} =

\begin{pmatrix} 1 & X_{11} & \cdots & X_{1p} \\ 

1 & X_{21} & \cdots & X_{2p} \\ 

\vdots &  & \ddots & \vdots \\ 

1 & X_{n1} & \cdots & X_{np} \\ 


\end{pmatrix}

\$\$

\begin{itemize}
\tightlist
\item
  linear regression
\end{itemize}

\$\$
\begin{alignat}{2}

y_i &= \beta_0 + \beta_1 x_i &&+ \epsilon_i \tag{Simple}

\\


y_i &= \beta_0 + \sum_{j=1}^p \beta_j x_{ij} &&+ \epsilon_i \tag{Multiple}


\end{alignat}
\$\$

\begin{itemize}
\tightlist
\item
  ANOVA
\end{itemize}

\$\$
\begin{alignat}{2}

y_{ij} &= \mu + \alpha_i &&+ \epsilon_{ij} \tag{One-Way} 

\\

y_{ij} &= \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} &&+ \epsilon_{ij} \tag{Two-Way with interaction}



\end{alignat}
\$\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{random-vectors-and-matrices}{%
\subsection{Random Vectors and Matrices}\label{random-vectors-and-matrices}}

let rv \[Y = \begin{pmatrix} y_1, & \cdots &, y_n \end{pmatrix}'\] with \[E(y_i) = \mu_i , \; \; \; Var(y_i)=\sigma_{ii} \; \; (=\sigma_i^2), \; \; \; Cov(y_i , y_j) = \sigma_{ij}\].

\begin{itemize}
\tightlist
\item
  define the statistics of \[Y\]
\end{itemize}

\$\$
\begin{alignat}{2}


&E(Y) &&= \begin{pmatrix} E(y_1), & \cdots & E(y_n) \end{pmatrix}' = \begin{pmatrix} \mu_1, & \cdots & \mu_n \end{pmatrix}' &&= \pmb \mu \tag{Expected Value of Y elementwise as } 

\\

&Cov(Y) &&= E \left[ (Y-\pmb \mu) (Y-\pmb \mu) ' \right] &&= (\sigma_{ij}) \tag{Covariance Matrix}

\end{alignat}
\$\$

\begin{itemize}
\tightlist
\item
  Note:
\end{itemize}

\$\$
\begin{alignat}{2}


E(AY+\pmb b) &= A \pmb \mu + \pmb b

\\

Cov(AY+\pmb b) &= A \ast Cov(Y) \ast A '

\end{alignat}
\$\$

\begin{itemize}
\tightlist
\item
  Prove or disprove that Cov(Y) is nonnegative definite. how?
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Covariance of \[W_{r \times 1}, \; Y_{s \times 1}\] with \[E(W)=\gamma, \; E(Y) = \mu\]:

\$\$
\begin{alignat}{2}

Cov(W, Y) &= E \left [(W-\gamma)(Y-\mu)' \right ]_{r \times s} &&

\\

Cov(AW+a, NY+b) &= A \ast Cov(W,Y) \ast B ' &&

\\

Cov(AW+NY) &= A \ast Cov(W) \ast A' + N \ast Cov(Y) \ast B' \\
&\; \; \; \; \; \; \; + A \ast Cov(W,Y) \ast B' + B \ast Cov(W) \ast A' \tag{why?}

\end{alignat}
\$\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{multivariate-normal-distributions}{%
\subsection{Multivariate Normal Distributions}\label{multivariate-normal-distributions}}

\$\$

Z = (z\_1 , \cdots, z\_n) ' \sim N\_n (0, ; I\_n), ; ; ; ; ; z\_1 , \cdots, z\_n \overset{iid}{\sim} N(0,1)

\$\$

which means \[E(Z)=\pmb 0, \; Cov(Z)=I_n\].

\[
A_{r \times n}, \; b \in \mathbb{R}^r
\]

Y has an r-dimensional MVN distribution

Definition 1.2.1. Let A be r  n and b 2 Rr . Then Y has an
r-dimensional multivariate normal distribution :
Y = AZ + b  Nr (b;AAT ):
Theorem 1.2.2. Let Y  N(;V) and W  N(;V). Then Y
and W have the same distribution (Proof: p.5)

The density of nonsingular \[Y \sim N(\mu,V)\] is given by

\$\$

f(y) = (2\pi)\^{}\{-\tfrac{n}{2}\} \left[ \det(V)\right]\^{}\{-\tfrac{1}{2}\} \exp \left[ -\dfrac{1}{2} (y-\mu) ' V^{-1} (y-\mu) \right]

\$\$

Theorem 1.2.3. Let Y  N(;V) and Y =

Y1
Y2
!
. Then
Cov(Y1;Y2) = 0 if and only if Y1 Y2
Corollary 1.2.4. Let Y  N(; 2I) and ABT = 0. Then
AY BY

Definition 1.3.1. Quadratic Form of Y: for n  n; A
YTAY =
X
ij
aijyiyj
Theorem

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{distributions-of-quadratic-forms}{%
\subsection{Distributions of Quadratic Forms}\label{distributions-of-quadratic-forms}}

\[E(Y) = \mu, \; Cov(Y) = V\]. then \[E(Y'AY) = tr(AV) + \mu ' A \mu\]. prf)

let's consider \[Z \sim N_n (\mu, I_n)\]. then \[ Z'Z \sim \chi^2 \left(n, \; \dfrac{\mu' \mu}{2} \right) \tag{second one is non-centrality parameter}\]

Let \[Y \sim N(\mu , I)\] and any orthogonal projection Matrix \[M\]. then \[Y'MY \sim \chi^2 \left(r(M), \dfrac{\mu ' M \mu}{2} \right)\]

Let \[Y \sim N(\mu , \sigma^2 I)\] and any orthogonal projection Matrix \[M\]. then \[Y'MY \sim \chi^2 \left(r(M), \dfrac{\mu ' M \mu}{2\sigma^2} \right)\]

Let \[Y \sim N(\mu , M)\]with \[\mu \in \mathcal{C}(M)\] and \[M\] be an orthogonal projection Matrix. then \[Y'Y \sim \chi^2 \left(r(M), \dfrac{\mu ' M \mu}{2\sigma^2} \right)\].

let \[E(Y)=\mu, \; Cov(Y)=V\]. then \[Pr \left[ (Y-\mu) \in \mathcal{C}(V) \right]=1\].

\begin{itemize}
\tightlist
\item
  Exercise 1.6.
  Let \[Y\] be a vector with \[E(Y) = 0\] and \[Cov(Y) = 0\]. Then \[Pr(Y = 0) = 1\].
\end{itemize}

let \[Y \sim N(\mu, \; V)\]. then \[Y' A Y \sim \chi^2 \left( tr(AV), \dfrac{\mu' A \mu}{2}\right)\], provided that
1. \[VAVAV=VAV\].
2. \[\mu ' AVA \mu = \mu ' a \mu\].
3. \[VAVA \mu = VA \mu\] prf)

\begin{itemize}
\tightlist
\item
  Exercise 1.7.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show that if \[V\] is nonsingular, then the three conditions in Theorem 1.3.6 reduce to \[AVA = A\].
\item
  Show that \[Y'V^{-} Y\] has a chi-squared distribution with \[r(V)\] degrees of freedom when \[\mu \in \mathcal{C}(V)\].
\end{enumerate}

let \[Y \sim N(\mu, \; \sigma^2 I)\] and \[BA=0\]. then, for \[A=A'\],
1. \[Y'AY \perp BY\].
2. \[Y'AY \perp Y' BY\] for \[B=B'\].

let \[Y \sim N(\mu, \; V)\] and \[A \ge 0, \; B \ge 0\], and \[VAVBV=0\]. then \[Y'AY \perp Y'BY\].

let \[Y \sim N(\mu, \; V)\]. provided that
1. \[VAVBV=0\].
2. \[VAVB \mu = 0\].
3. \[VBVA \mu = 0\].
4. \[\mu ' ABV \mu = 0\].

and also conditions of above thm,
1. \[VAVAV=VAV\].
2. \[\mu ' AVA \mu = \mu ' a \mu\].
3. \[VAVA \mu = VA \mu\] prf)

hold for both \[Y'AY\] and \[Y'BY\], then \[Y'AY \perp Y'BY\].

\hypertarget{estimation}{%
\section{Estimation}\label{estimation}}

이하와 같은 linear model 고려. 이때 \(x_i '\)는 \(X\)의 i번째 row vector이며, \(E(\epsilon)=0, \; Cov(\epsilon)=\sigma^2 I = \sigma^2 \Sigma\).

\$
Y\_\{n \times 1\} = X\_\{n \times p\} \beta\emph{\{p \times 1\} + \epsilon}\{n \times 1\} =

\begin{pmatrix} x_i '  \beta \end{pmatrix}

\begin{itemize}
\item
  \epsilon

  \$
\end{itemize}

\hypertarget{identifiability-and-estimability}{%
\subsection{Identifiability and Estimability}\label{identifiability-and-estimability}}

\hypertarget{identifiable}{%
\subsubsection{Identifiable}\label{identifiable}}

모델에서의 무한한 갯수의 관측치를 보유한다면, 모델의 underlying 패러미터의 참값을 획득하는 것이 가능한 성질.

A general linear model is a parameterization

\$
\begin{align}
E(Y) &= f(X) \\
&= E(X\beta + \epsilon)\\
&= X\beta + E(\epsilon) \\
&= X\beta  + 0 \\
&= X\beta  

\end{align}
\$

The parameter \(\beta\) is \textbf{identifiable} if for any \(\beta_1\) and \(\beta_2\) \(f(\beta_1) = f(\beta_2)\) implies \(\beta_1 = \beta_2\). If \(\beta\) is identifiable, we say that the parameterization \(f(\beta)\) is identifiable. (패러미터 \(\beta\)가 identifiable하다면, 우리는 해당 패러미터의 parameterization \(f(\beta)\) 또한 identifiable 하다) Moreover, a vector-valued function \(g(\beta)\) is identifiable if \(f (\beta_1) = f(\beta_2)\) implies \(g (\beta_1) = g(\beta_2)\).

For regression models for which \(r(X) = p\), the parameters are identifiable: \(X'X\) is nonsingular, so if \(X\beta_1 = X\beta_2\), then

\$
\beta\_1 = (X'X)\^{}\{-1\} X'X \beta\_1 = (X'X)\^{}\{-1\} X'X \beta\_2 = \beta\_2
\$

A function \(g(\beta)\) is identifiable \(\iff\) \(g(\beta)\) is a function of \(f(\beta)\).

\hypertarget{estimable}{%
\subsubsection{Estimable}\label{estimable}}

The results in the last section suggest that some linear combinations of \(\beta\) in the less than full rank case will not be estimable.

The linear parametric function \(c'β\) is an \textbf{estimable} function if there exists a vector \(a \in \mathbb{R}^n\) such that \(\forall \beta: E(a ' y ) = c ' \beta\).

A vector-valued linear function of \(\beta\), \(\Lambda ' \beta\) is \textbf{estimable} if \(\Lambda ' \beta = P ' X \beta\) for some matrix P; In other words, \(\Lambda ' \beta\) is estimable if \(\Lambda = X ' P \in \mathcal{C}(X')\).

Clearly, if \(\Lambda ' \beta\) is estimable, it is identifiable and therefore it is a reasonable thing to estimate.

\begin{itemize}
\tightlist
\item
  estimable \(\rightarrow\) identifiable
\end{itemize}

For estimable functions \(\Lambda' \beta = P ' X \beta\), although \(P\) need not be unique, its perpendicular projection (columnwise) onto \(\mathcal{C}(X)\) is unique:
let \(P_1 , \; P_2\) be matrices with \(\Lambda ' = P_1 ' X = P_2 ' X\), then

\$

MP\_1 = X(X'X)\^{}\{-\}X'P\_1 = X(X'X)\^{}\{-\}\Lambda = X(X'X)\^{}\{-\}X'P\_2 = MP\_2

\$

\begin{itemize}
\tightlist
\item
  Example 2.1.4 and 2.1.5
\end{itemize}

\(g(\beta)\)'s estimate, \(f(Y)\), is \textbf{unbiased} if \(\forall \beta: \; E[f(Y)] = g(\beta)\).

if \(f (Y) = a_0 + a' Y\) for some scalar \(a_0\) and vector \(a\), \(f(Y)\) is a \textbf{linear estimate} of \(\Lambda ' \beta\).

if \(\Lambda ' \beta\) \(\iff\) \(a_0 = 0\) and \(a ' X = \Lambda'\); say, \(\Lambda = X ' a \in \mathcal{C}(X')\), then a \textbf{linear estimate} \(a_0 + a ' Y\) is \textbf{unbiased}

\(\Lambda ' \beta\) is \textbf{estimable} \(\iff\) there exists \(\rho\) such that \(E(\rho ' Y ) = \Lambda ' \beta\) for any \(\beta\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-least-squares}{%
\subsection{Estimation: Least Squares}\label{estimation-least-squares}}

Estimating \(E(Y)\) is to take a vector in \(\mathcal{C}(X)\) closest to \(Y\);

\$
\begin{alignat}{2}

E(Y) &= X\beta \; &&\in \; \mathcal{C}(X)\\

\\

\hat \beta &= \min_\beta \left\{ (Y-X \beta) ' (Y-X \beta)  \right\} \\
&= \min_\beta \left\{ \Vert Y-X \beta \Vert^2   \right\}

\tag{Least Squares Estimate of beta}


\end{alignat}
\$

for any Least Squares Estimate \(\hat \beta\), LSE of \(\Lambda ' \beta is \Lambda ' \hat \beta\), e.g., \(\hat {\Lambda ' \beta}_{LSE} = \Lambda ' \hat \beta\).

\begin{itemize}
\tightlist
\item
  Theorem 2.2.1
\end{itemize}

where \(M\) is the perpendicular projection operator onto \(\mathcal{C}(X)\), then

\$
\hat \beta\$ is a LSE of \(\beta\) \(\iff\) \$X \hat \beta = M Y
\$

\begin{itemize}
\tightlist
\item
  Corollary 2.2.2
\end{itemize}

\(\hat \beta_{LSE} = X(X'X)^{-}X' Y\)

\begin{itemize}
\tightlist
\item
  Corollary 2.2.3
\end{itemize}

The unique LSE of \(\rho ' X \beta = \rho ' M Y\).

※ Note: the unique LSE of \(\Lambda ' \beta = \Lambda ' \hat \beta = P' M Y\).

\begin{itemize}
\tightlist
\item
  Theorem 2.2.4
\end{itemize}

the LSE of \(\Lambda ' \beta\) is unique only if \(\Lambda ' \beta\) is estimable: \(\Lambda = X'\rho\) if \(\Lambda ' \hat \beta_1 =\Lambda ' \hat \beta_2\), so that \(X \hat \beta_1 = X \hat \beta_2 = MY\).

※ Note: When \(\beta\) is not identifiable, we need side conditions imposed on the parameters to estimate nonidentifiable parameters.

※ Note: With \(r = r (X) < p\) (overparameterized model), we need \(p - r\) individual side conditions to identify and estimate the parameters.

\begin{itemize}
\tightlist
\item
  Proposition 2.2.5
\end{itemize}

If \(\Lambda = X ' \rho\), then \(E(\rho ' MY) = \Lambda ' \beta\).

let's decompose

\$
\begin{alignat}{2}

Y 

&= X \hat \beta &&+ Y - X \hat \beta

\\


&= MY &&+ (I-M)Y

\\



&= \hat Y &&+ e 

\end{alignat}
\$

이때
\$
\begin{align}
\hat Y &\in \mathcal{C}(X) \tag{fitted values of Y} \\
e &\in \mathcal{C}(X)^{\perp} \tag{residuals}
\end{align}
\$

\begin{itemize}
\tightlist
\item
  Theorem 2.2.6
\end{itemize}

Let \(r (X) = r\) and \(Cov(\epsilon) = \sigma^2 I\). At below formula, denominator is \textbf{degrees of freedom for error}.

Then an \textbf{UE} of \(\sigma^2\), MSE, is as below.

\$
\hat \sigma\^{}2 =\dfrac{Y'(I-M)Y}{rank(I-M)} =\dfrac{Y'(I-M)Y}{n-r} \tag{MSE}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-best-linear-unbiased}{%
\subsection{Estimation: Best Linear Unbiased}\label{estimation-best-linear-unbiased}}

\begin{itemize}
\tightlist
\item
  Definition 2.3.1
\end{itemize}

\(a'Y\) is a Best Linear Unbiased Estimate(BLUE) of \(\lambda ' \beta\) if \(a ' Y\) is unbiased.

e.g., \(E(a ' Y) = \lambda ' \beta\) and if for any other linear unbiased estimate \(b ' Y\), \(Var(a ' Y) \le Var(b'Y)\).

\begin{itemize}
\tightlist
\item
  Theorem 2.3.2: Gauss-Markov thm
\end{itemize}

Consider \(Y = X \beta + \epsilon\) with \(E(\epsilon) = 0\), \(Cov(\epsilon) = \sigma^2 I\). Let \(\lambda ' \beta\) be estimable.

Then LSE of \(\lambda ' \beta=\) BLUE of \(\lambda ' \beta\).

\begin{itemize}
\tightlist
\item
  Corollary 2.3.3
\end{itemize}

Let \(\sigma^2 > 0\). Then there exists a unique BLUE for any estimable function \(\lambda ' \beta\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-maximum-likelihood}{%
\subsection{Estimation: Maximum Likelihood}\label{estimation-maximum-likelihood}}

Assume that \(Y \sim N_n(X\beta , \; \sigma^2 I_n)\). Then the Maximum Likelihood Estimates (MLEs) of \(\beta\) and \(\sigma^2\) are obtained by maximizing the log of the likelihood so that

\$
\begin{align}

\left( 

\hat \beta , \; \hat \sigma^2


\right)

&= \text{ MLE of }

\left( 

\beta , \; \sigma^2


\right)


\\

&=

\max_{\left( \beta , \; \sigma^2 \right)} \left\{ 

-\dfrac{n}{2}log(2 \pi) - \dfrac{1}{2} \log \left[ (\sigma^2 )^n\right] - \dfrac{(Y-X\beta)'(Y-X\beta)}{2\sigma^2}




\right\}


\end{align}

\$

\$

\begin{align}

\hat \beta &= \text{ LSE of } \beta \\

\\\

\hat \sigma^2 &= \dfrac{1}{n} \left\{Y'(I-M)Y \right\}


\end{align}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-minimum-variance-unbiased}{%
\subsection{Estimation: Minimum Variance Unbiased}\label{estimation-minimum-variance-unbiased}}

Assume that \(Y = X \beta + \epsilon\) with \(\epsilon \sim N_n(0, \; \sigma^2 I_n)\).

if \(\forall \beta, \sigma^2: \; E \left \{h[T(Y)] \right\} = 0\) implies that \(Pr[h(T(Y)) = 0] = 1\), A vector-valued sufficient statistic \(T(Y)\) is said to be \textbf{complete}

If \(T(Y)\) is a complete sufficient statistic, then \(f(T(Y))\) is a \textbf{Minimum Variance Unbiased Estimate (MVUE)} of \(E \Big [ f (T(Y)) \Big ]\).

\begin{itemize}
\tightlist
\item
  Theorem 2.5.3
\end{itemize}

let \(\theta = (\theta_1 , \cdots, \theta_s)'\) and let \(Y\) be a rvec with pdf as below. then \(T(Y) = \Big( T_1(Y), \cdots, T_s(Y) \Big)'\) is a \textbf{complete sufficient statistics} provided that neither \(\theta\) nor \(T(Y)\) satisfies any linear constraints.

\$
f(Y) = c(\theta) \exp \left[ \sum_{i=1}^s \theta_i T_i (Y) \right] h(Y)
\$

\begin{itemize}
\tightlist
\item
  Theorem 2.5.4
\end{itemize}

MSE is a \$\hat {\sigma^2 }\_\{MVUE\} \$, and \(\hat { \rho ' X \beta }_{MVUE} = \rho ' M Y\) whenever \(\epsilon \sim N(0, \; I)\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sampling-distributions-of-estimates}{%
\subsection{Sampling Distributions of Estimates}\label{sampling-distributions-of-estimates}}

Assume that \(Y = X \beta + \epsilon\) with \(\epsilon \sim N_n(0, \; \sigma^2 I_n)\). Then \(Y \sim N_n(X \beta, \; \sigma^2 I_n)\). then

\$
\begin{alignat}{4}
\Lambda ' \hat \beta &= P' M Y &&\sim N(\Lambda ' \beta , \; &&\sigma^2 P'MP&&\; \; \; ) && \; \; \; \; \; \; \; \; \; \;&& && &&  \\


& &&\sim N(\Lambda ' \beta , \; &&\sigma^2 \Lambda ' (X'X)^{-} \Lambda&&\; \; \; ) &&    && \because && \;M && =X(X'X)^- X' \\



& && && && && && && \; \hat Y && = MY &&\sim N(X\beta, \sigma^2 M)


\\

\hat \beta &= (X'X)^- X'Y &&\sim N(\beta , \; &&\sigma^2 (X'X)^{-1}) && && && && && && (\text{if X is of full rank})



\end{alignat}
\$

Do Exercise 2.1. Show that
\$
\dfrac{Y' (I-M) Y}{\sigma^2} \sim \chi\^{}2 \Bigg( r(I-M), ; \dfrac{\beta'X'(I-M)X\beta}{2\sigma^2} \Bigg)
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{generalized-least-squaresgls}{%
\subsection{Generalized Least Squares(GLS)}\label{generalized-least-squaresgls}}

Assume that for some known positive definite \(\Sigma\),

\$
Y = X \beta + \epsilon, ; ; ; ; ;
\$

\$
\begin{alignat}{3}

Y &= X \beta &&+ \epsilon && \; \; \; \; \; \; \; \; \; \; 

&& E(\epsilon)&&=0, \; \; &&\; Cov(\epsilon) &&= \sigma^2 \Sigma \tag{1}\\








\Sigma^{-\tfrac{1}{2}}Y &= \Sigma^{-\tfrac{1}{2}} X \beta &&+ \Sigma^{-\tfrac{1}{2}} \epsilon 


 && \; \; \; \; \; \; \; \; \; \; && E(\Sigma^{-\tfrac{1}{2}} \epsilon)&&=0, &&\; Cov(\Sigma^{-\tfrac{1}{2}} \epsilon) &&= \sigma^2 I \tag{2, by SVD}
\\

Y_\ast &= X_\ast \beta &&+ \epsilon_\ast



 && \; \; \; \; \; \; \; \; \; \; && E( \epsilon_\ast)&&=0, &&\; Cov( \epsilon_\ast) &&= \sigma^2 I



\end{alignat}
\$

\$
\begin{alignat}{2}

\hat \beta_{GLS} &= \min_\beta (Y_\ast - X_\ast \beta)'(Y_\ast - X_\ast \beta) \\

&= \min_\beta \Vert Y_\ast - X_\ast \beta \Vert^2 \\



&= \min_\beta (Y - X \beta)' \Sigma^{-1} (Y - X \beta) \tag{Generalized LSE (GLSE) of β}


\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  Theorem 2.7.1
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\lambda ' \beta\) estimable in model (1) \(\iff\) if \(\lambda ' \beta\) is estimable in model (2).
\item
  \$\hat \beta \$ is GLSE of \(\beta\) \(\iff\) \(X(X' \Sigma^{-1} X)^{-}X' \Sigma^{-1}Y = X \hat \beta\), which is Normal Equation of GLS.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  For any estimable function, there exists a unique GLSE.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  GLSE estimate of estimable \(\lambda' \beta\), is BLUE of \$\lambda' \beta \$.
\item
  let \(\epsilon \sim N(0, \; \Sigma^2 \Sigma)\). then, GLSE of estimable \(\lambda ' \beta\), is MVUE.
\item
  let \(\epsilon \sim N(0, \; \Sigma^2 \Sigma)\). then, \(\hat \beta_{GLS} = \hat \beta_{MLE}\).
\end{enumerate}

Normal Equation of GLS can be rewritten as

\$
\begin{align}

X(X' \Sigma^{-1} X)^{-}X' \Sigma^{-1}Y &= X \hat \beta \\
AY &=
\end{align}
\$

\(A\) is a projection operator onto \(\mathcal{C}(X)\).

\(Cov(X \hat \beta_{GLS}) = \sigma^2 \ast X(X' \Sigma^{-1} X)^{-}X'\)
Let \(\lambda ' \beta\) be estimable. Then \(Var(\lambda ' \hat \beta_{GLS}) = \sigma^2 \ast \lambda ' (X' \Sigma^{-1} X)^- \lambda\).

\begin{itemize}
\tightlist
\item
  Note: \((I-A)Y\) is residual vector of GLSE.
\end{itemize}

\$
\begin{align}

SSE_{GLS} &= (Y_\ast - \hat Y_\ast)' (Y_\ast - \hat Y_\ast) \\

&\; \; \vdots \\

&= Y'(I-A)' \Sigma^{-1}(I-A)Y \\

\\\

MSE_{GLS} &= \hat \sigma^2 \\
& = \dfrac{1}{n-r(X)} \ast SSE_{GLS}\\

\\\

\dfrac{1}{\hat \sigma^2}

\dfrac{\lambda' \Big(\hat \beta_{GLS} - \beta_{GLS} \Big)}{ \lambda ' (X' \Sigma^{-1} X)^- \lambda} &\sim t\Big( n-r(x) \Big)





\end{align}
\$

denominator는 \(Var(\lambda ' \hat \beta_{GLS}) = \sigma^2 \ast \lambda ' (X' \Sigma^{-1} X)^- \lambda\).

Let \(\Sigma\) be nonsingular and \(\mathcal{C}(\Sigma X) \subset \mathcal{C}(X)\). Then least squares estimates are BLUEs.

\begin{itemize}
\tightlist
\item
  Note: for diagonal \(\Sigma\), GLS is referred to as \textbf{Weighted Least Squares (WLS)}.
\end{itemize}

\begin{itemize}
\tightlist
\item
  Exercise 2.5.
\end{itemize}

Show that \(A\) is the perpendicular projection operator onto \(\mathcal{C}(X)\) when the inner product between two vectors \(\pmb x\) and \(\pmb y\) is defined as \((\pmb x, \pmb y)_\Sigma \equiv \pmb x' \Sigma^{-1} \pmb y\).

\hypertarget{one-way-anova}{%
\section{One-Way ANOVA}\label{one-way-anova}}

\hypertarget{one-way-anova-1}{%
\subsection{One-Way ANOVA}\label{one-way-anova-1}}

General form of One-Way ANOVA model is

\$
y\_\{ij\} = \mu + \alpha\emph{\{i\} + \epsilon}\{ij\}, ; ; ; ; ; i=1, \cdots, a ; ; ; ; ; j=1, \cdots, N\_i
\$

\$
n=\sum\_\{i=1\}\^{}a N\_i \textbackslash{}

\textbackslash{}

E(\epsilon\emph{\{ij\})=0, ; Var(\epsilon}\{ij\})=\sigma\^{}2, ; Cov(\epsilon\emph{\{ij\}, \epsilon}\{ab\})=0
\$

\begin{itemize}
\tightlist
\item
  \textbf{i-th treatment (group) effect} \(a_i\)

  \begin{itemize}
  \tightlist
  \item
    \textbf{Balanced model} is \(\forall i: N_i = b\)
  \item
    \textbf{Unbalanced model} is \(\forall i: N_i\)'s are different
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{more-about-models}{%
\subsection{More About Models}\label{more-about-models}}

\begin{itemize}
\tightlist
\item
  Example 4.1.1:
\end{itemize}

\(a = 3, \; N_1 = 5, \; N_2 = 3, \; N_3 = 3\),

\$
Y = X \beta + \epsilon =

\begin{pmatrix} 
J_5 & J_5 &  0 & 0 \\
J_3 & 0 & J_3 & 0 \\
J_3 & 0 & 0 & J_3


\end{pmatrix}

\begin{pmatrix} 

\mu \\
\alpha_1 \\
\alpha_2 \\
\alpha_3


\end{pmatrix}

\begin{itemize}
\tightlist
\item
\end{itemize}

\begin{pmatrix} 

\epsilon_{11} \\
\epsilon_{12} \\
\vdots \\
\epsilon_{33}

\end{pmatrix}

\$

let \(N_1 = N_2 = N_3 = 5\). then

\$
X =

\begin{pmatrix} 

J_3 \otimes J_5 & I_3 \otimes J_5
\end{pmatrix}

\$

In general, balanced design such as \(i = 1, \cdots, a \; \; \; \; \; j = 1, \cdots, b\):

\$
X =

\begin{pmatrix} 

J_a \otimes J_b & I_a \otimes J_b
\end{pmatrix}

\$

\begin{itemize}
\tightlist
\item
  Notation: \(J_r^c \equiv J_r J_c' = J_r \otimes J^c\) is a \(r \times c\) matrix of \(1\)'s.
\end{itemize}

Let \(Z\) be the model matrix for the alternative one-way analysis of variance model

\$
y\_\{ij\} = \mu\emph{i + \epsilon}\{ij\} ; ; ; ; ; i=1, \cdots, a ; ; ; ; ; k= 1, \cdots, N\_i
\$

then, letting \(X_i X_j = \delta_{ij}\) with 1 for \(i=j\) and 0 for \(i \not = j\),

\$
\begin{align}

X &= \begin{bmatrix}J & Z\end{bmatrix} &&= \begin{bmatrix}J & (X_1 , \cdots, X_a)\end{bmatrix}

\\

\Longrightarrow \; \; \; \; \; \mathcal{C}(X) &=\mathcal{C}(Z)

\\

Z'Z &= diag(N_1 , N_2 , \cdots, N_a)

\\

Z(Z'Z)^{-1}Z' &=Blk \; \; diag \Big[ N_i^{-1} J_{N_i}^{N_i} \Big]

\\

M &=X (X'X)^{-1}X'

\\

M_\alpha &= Z_\ast(Z_\ast ' Z_\ast)^{-1} Z_\ast ' &&=M- M_J = M-\dfrac{1}{n}J_n^n

\\

Z_\ast &=(I-M_j)Z

\\

M &= M_j + M_\alpha



\end{align}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimating-and-testing-contrasts}{%
\subsection{Estimating and Testing Contrasts}\label{estimating-and-testing-contrasts}}

A contrast in the one-way ANOVA

\$

\lambda ' \beta = \sum\_\{i=1\}\^{}a \lambda\emph{i \alpha\emph{i ; ; ; ; ; with ; ; ; \lambda ' J}\{a+1\} = \sum}\{i=1\}\^{}a \lambda\_i = 0

\$

For estimable \(\lambda ' \beta\), find \(\rho\) so that \$\rho`X = \lambda ' \$, \(\rho ' = \begin{pmatrix} \dfrac{J_{N_i} ' \lambda_i}{N_i} \end{pmatrix}\).

\begin{itemize}
\tightlist
\item
  Proposition 4.2.1.
\end{itemize}

\(\lambda ' \alpha = \rho ' X \beta\) is a contrast \(\iff\) \(\rho ' J = 0\).

\begin{itemize}
\tightlist
\item
  Proposition 4.2.2.
\end{itemize}

\(\lambda ' \alpha = \rho ' X \beta\) is a contrast \(\iff\) \(M_\rho \in \mathcal{C}(M_\alpha)\).

since \(\sum_{i=1}^a \lambda_i =0\),

\$
\sum\_\{i=1\}\^{}a \lambda\_i \hat \alpha\emph{i =\sum}\{i=1\}\^{}a \lambda\_i \Big\{\hat \mu + \hat \alpha\emph{i\Big\} = \sum}\{i=1\}\^{}a \lambda\emph{i \bar y}\{i+\}
\$
because \(\mu + \alpha_i\) is estimable, and its unique LSE is \(\bar y_{i+}\).

At significance level \(\alpha\), \(H_0: \lambda ' \alpha=0\) is rejected if

\$
\begin{alignat}{2}


&F 

&&= 

\dfrac
{
\dfrac{ \Big( \sum_{i=1}^a \lambda_i \bar y_{i+} \Big) ^2}
{\dfrac{\sum_{i=1}^a \lambda_i^2}{N_i}}
}
{MSE}

&&> F \Big(1-\alpha, \; \; 1, \; \;  dfE \Big)


\\

\\

\\



\iff

\; \; \; \; \; 

& t  \

&&= 


\dfrac
{\Bigg \vert \sum_{i=1}^a \lambda_i \bar y_{i+} \Bigg \vert}
{\sqrt{MSE \left( \sum_{i=1}^a\dfrac{\lambda_i^2}{N_i}\right)  }}


&&> 


t \left( 1-\dfrac{\alpha}{2}, \; \; dfE \right)

\end{alignat}
\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{cochrans-theorem}{%
\subsection{Cochran's Theorem}\label{cochrans-theorem}}

let \(A_1 , \cdots, A_m\) be \(n \times n\) symmetric Matrices, and \(A = \sum_{j=1}^m A_j\) with \(rank(A_j) = n_j\). consider the following four statements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(A_j\) is an orthogonal projection for all \(j\).
\item
  \(A\) is an orthogonal projection (possibly \(A=I\)).
\item
  \(A_j A_k = 0\) for all \(j \not = k\).
\item
  \(\sum_{j=1}^m n_j = n\).
\end{enumerate}

If any two of these conditions hold, then all four hold.

\begin{itemize}
\tightlist
\item
  Note: Cochran's theorem is a standard result that is the basis of the ANalysis Of VAriance. If we can write the total sum of squares as a sum of sum of squares components, and if the degree of freedom add up, then the \(A_j\) must be projections, they are orthogonal to each other, and they jointly span \(\mathbb{R}^n\).
\end{itemize}

\hypertarget{testing}{%
\section{Testing}\label{testing}}

\hypertarget{more-about-models-two-approaches-for-linear-model}{%
\subsection{More About Models: Two approaches for linear model}\label{more-about-models-two-approaches-for-linear-model}}

\$
\begin{alignat}{2}

Y &= E(Y) &&+ Y - E(Y)  \\

&= \mu &&+ \epsilon \tag{Parameter-free approach }

\\
\\

Y &= E(Y) &&+ Y - E(Y)  \\

&= X \beta &&+ \epsilon \tag{Parameter approach}




\end{alignat}
\$

\$
\begin{alignat}{2}

E(\epsilon) &= 0, \; \; \;  && Cov(\epsilon) &&= \sigma^2 I \tag{Ordinary Least Square, OLS}

\\ 

E(\epsilon) &= 0, && Cov(\epsilon) &&= \sigma^2 \Sigma \tag{Generalized Least Square, GLS}



\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  Consider
\end{itemize}

\$
Y=X \beta + \epsilon, ; ; ; ; ; E(\epsilon)=0, ; Cov(\epsilon) = \sigma\^{}2 I
\$

\begin{longtable}[]{@{}ccc@{}}
\toprule
& \(\mathcal{C}(X)\) & \(\mathcal{C}(X)^\perp\) \\
\midrule
\endhead
itslef & Estimation Space & Error Space \\
orthogonal projection onto & \(M \\ = X(X'X)^-X'\) & \(I - M \\= I - X(X'X)^-X'\) \\
& \(E(Y) = X \beta \in \mathcal{C}(X)\) & \(E(\epsilon) \in \mathcal{C}(X)^\perp\) \\
& \(Cov(Y) = \sigma^2 I\) & \(Cov(\epsilon) = \sigma^2 I\) \\
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  One-Way ANOVA
\end{itemize}

\$

\begin{alignat}{4}



y_{ij} &= \mu_i &&+ \epsilon_{ij} \\
&= E(y_{ij}) &&+ \epsilon_{ij} \\


&= \mu + \alpha_i &&+ \epsilon_{ij} \\

\\\

\bar \mu &= \mu + \bar \alpha_+ \\


\mu_1 - \mu_2 &= \alpha_1 - \alpha_2



\end{alignat}
\$

the parameters in the two models are different, but they are related.

\begin{itemize}
\tightlist
\item
  Simple Linear Regression
\end{itemize}

\$

\begin{alignat}{4}
y_i & = \beta_0 + \beta_1 x_i &&+\epsilon_i

\\


& = E(y_i) &&+\epsilon_i
 
\\

& = \gamma_0 + \gamma_1(x_i - \bar x) &&+\epsilon_i


\end{alignat}
\$

\$

\begin{alignat}{2}

\mathcal{C}(X_1) = \mathcal{C}(X_2) \; \; \Longrightarrow \; \;\; \; \; X_1 &= X_2 T


\\

X_1 \beta_1 &= X_2 T \beta_1 && = X_2 \beta_2

\\

& &&= X_2 (T \beta_1 + \nu), \; \; \; \forall\nu \in \mathcal{C}(X_2')^\perp


\end{alignat}
\$

※ Note: A unique parameterization for \(X_j, \; j=1,2\) occurs \(\iff\) \(X_j ' X_j\) is nonsingular.

\begin{itemize}
\tightlist
\item
  Exercise: Show that a unique parameterization for \(X_j, \; j=1,2\) means \(\mathcal{C}(X_2 ' )^\perp = \{0\}\).
\end{itemize}

\hypertarget{testing-models}{%
\subsection{Testing Models}\label{testing-models}}

Consider

\$
Y=X \beta + \epsilon, ; ; ; ; ; \epsilon \sim N(0, ; I\_n)
\$

let's partition \(X\) into \$X =

\begin{pmatrix} X_0, & X_1 \end{pmatrix}

: ; \mathcal{C}(X\_0) \subset \mathcal{C}(X) \$

\$
\begin{alignat}{2}


Y &= X_0 \beta_0 + X_1 \beta_1 &&+ \epsilon \tag{Full Model, FM}

\\


Y &= X_0 \gamma &&+ \epsilon \tag{Reduced Model, RM}

\end{alignat}
\$

이때 Hypothesis testing procedure can be described as \(H_0:\) Reduced Model, \(H_1:\) Full Model. (Example 3.2.0: pp.~52--54).

Let \(M\) and \(M_0\) be the orthogonal projection onto \(\mathcal{C}(X)\) and \(\mathcal{C}(X_0)\) respectively.

Note that with \(\mathcal{C}(X_0) \subset \mathcal{C}(X)\), \(M - M_0\) is the orthogonal projection onto the orthogonal complement of \(\mathcal{C}(X_0)\) with respect to \(\mathcal{C}(X)\), that is,

\$
\begin{align}

\mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp  &= \mathcal{C}(M - M_0) \\

&= \mathcal{C}(M \cap M_0^\perp ) \\

\\\

\hat\mu &= \hat E(Y) = MY \tag{under FM}



\\

\hat\mu_0 &= \hat E(Y) = M_0 Y \tag{under RM}





\end{align}
\$

If RM is true, then \(MY-M_0 Y = (M - M_0)Y\) should be reasonably small. Note that \(E(M-M_0)Y = 0\).

The decision about whether RM is appropriate hinges on deciding whether the vector \((M - M_0)Y\) is large.

The size of \((M - M_0)Y\)'s \textbf{obvious measure} is \([(M - M_0)Y]'[(M - M_0)Y] = Y'(M-M_0)Y\).

The size of \((M - M_0)Y\)'s \textbf{reasonable measure} is given by \(\dfrac{Y'(M-M_0)Y}{r(M-M_0)}\).

\begin{itemize}
\tightlist
\item
  ※ Note that \$E \left( \dfrac{Y'(M-M_0)Y}{r(M-M_0)} \right) = \sigma\^{}2 + \dfrac{\beta'X'(M-M_0)X \beta}{r(M-M_0)} \$.
\end{itemize}

\begin{itemize}
\tightlist
\item
  Theorem 3.2.1.
\end{itemize}

Consider

\$
Y=X \beta + \epsilon, ; ; ; ; ; \epsilon \sim N(0, ; I\_n) , ; ; ; ; ; \mathcal{C}(X\_0) \subset \mathcal{C}(X) \textbackslash{}

\textbackslash{}
\textbackslash{}

\begin{alignat}{2}


Y &= X_0 \beta_0 + X_1 \beta_1 &&+ \epsilon \tag{Full Model, FM}

\\


Y &= X_0 \gamma &&+ \epsilon \tag{Reduced Model, RM}

\end{alignat}

\$

\$

\begin{alignat}{2}

\dfrac
{\dfrac{Y'(M-M_0)Y}{r(M-M_0)}}
{\dfrac{Y'(I-M)Y}{r(I-M)}}



&=


\dfrac
{\dfrac{Y'(M-M_0)Y}{df_1}}
{\dfrac{Y'(I-M)Y}{df_2}} 




&&\sim 


F \Bigg( df_1 , df_2, \dfrac{\beta' X' (M-M_0)X \beta }{2 \sigma^2} 



&& \Bigg) \tag{Under the FM}

\\

\\\


\\\




\dfrac
{\dfrac{Y'(M-M_0)Y}{r(M-M_0)}}
{\dfrac{Y'(I-M)Y}{r(I-M)}}



&=


\dfrac
{\dfrac{Y'(M-M_0)Y}{df_1}}
{\dfrac{Y'(I-M)Y}{df_2}}


&&\sim 


F \big( df_1 , df_2, 0 

&& \big) 

\tag{Under the RM}

\end{alignat}

\$

\begin{itemize}
\tightlist
\item
  Note: Example 3.2.2.; pp.~58--59
\end{itemize}

\$
\begin{alignat}{2}


M-M_0 &= (I-M_0) &&-(I-M)

\\

Y'(M-M_0)Y &= Y'(I-M_0)Y &&-Y'(I-M)Y

\\

 &= SSE_{RM} &&-SSE_{FM}




\end{alignat}
\$

\hypertarget{a-generalized-test-procedure}{%
\subsection{A Generalized Test Procedure}\label{a-generalized-test-procedure}}

Assume that \(Y = X \beta + \epsilon\) is correct. Want to test the adequacy of a model \(Y = X_0 \gamma + Xb + \epsilon\), where \(\mathcal{C}(X_0) \subset \mathcal{C}(X)\) and some known vector \(Xb=\) offset.

\begin{itemize}
\tightlist
\item
  Example 3.2.3.; Multiple Regression
\end{itemize}

\$
Y = \beta\_0 J + \beta\_1 X\_1 + \beta\_2 X\_2 + \beta\_3 X\_3 + \epsilon
\$

want to test \(H_0: \beta_2 = \beta_3+5, \; beta_1 = 0, \cdots\).

\$
\begin{alignat}{2}


Y &= X \beta && &&+ \epsilon \tag{FM}

\\

Y^\ast &\equiv Y && - X b &&

\\

&=X \beta && - Xb &&+ \epsilon

\\

&=X (\beta && - b) &&+ \epsilon


\\

&=X \beta^\ast && &&+ \epsilon \tag{FM}

\\
\\\
\\\


Y &= X_0 \gamma && + Xb &&+ \epsilon \tag{RM}

\\

Y^\ast &\equiv Y && && && - X b 

\\

&=X \gamma &&  &&+ \epsilon \tag{RM}




\end{alignat}
\$

In addition, when \(Y^\ast = Y_\ast\),

\$

\begin{alignat}{2}

\dfrac
{\dfrac{ Y_\ast ' (M-M_0) Y_\ast }{ r(M-M_0)}}
{\dfrac{ Y_\ast ' (I-M) Y_\ast }{r(I-M)}}

&\sim F \Big( r(M-M_0), r(I-M), \delta^2 \Big)

\\
\\

\delta^2 &=\dfrac{1}{2 \sigma^2} \Big( {\beta^\ast} ' X ' (M-M_0) X \beta^\ast \Big) \tag{non-centrality parameter}


\end{alignat}
\$

\$

\begin{alignat}{2}

0 &= \beta_\ast '  X' &&(M-M_0) X \beta_\ast


\\


&\Updownarrow   

\\


0 &= &&(M-M_0)X \beta_\ast

\\

&\Updownarrow   


\\

X\beta & = M_0 (X &&\beta - X b) + Xb \tag{3}

\end{alignat}

\$

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  will hold if
\end{enumerate}

\$
\begin{align}
\gamma &= (X_0 ' X_0)^- X_0(X \beta - Xb) \\

&= (X_0 ' X_0)^- X_0 X \beta_\ast 

\end{align}

\$

Furthermore,

\$
\begin{alignat}{2}
Y_\ast ' (M-M_0)Y_\ast &= 


Y_\ast ' (I-M_0)Y_\ast &&- &&Y_\ast ' (I-M)Y_\ast  \; \; \; \; \;\text{ , and }




\\

Y ' (I-M)Y &= && && Y_\ast ' (I-M)Y_\ast  




\end{alignat}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{testing-linear-parametric-functions}{%
\subsection{Testing Linear Parametric Functions}\label{testing-linear-parametric-functions}}

\(H_0: Y= X \beta + \epsilon, \; \; \; \; \; \Lambda' \beta=0 \tag{1}\)

\$
\begin{alignat}{2}


\Lambda ' \beta = 0 \; \; \; &\iff \beta &&\in \mathcal{N}(\Lambda ') = \mathcal{C}(X)^\perp

\\

&\iff \beta \perp \mathcal{C}(\Lambda)



\\

&\iff \beta \perp \mathcal{C}(\Gamma) \; \; \; \; \; \; \; \; \; \; &&\text{ if } \exists\Gamma \; \; s.t. \; \mathcal{C}(\Gamma) = \mathcal{C}(\Lambda)

\\

&\iff \beta \perp \mathcal{C}(U) &&\text{ if } \exists U \; \; s.t. \; \mathcal{C}(U) = \mathcal{C}(\Lambda)^\perp

\\

&\iff \beta = U_\gamma && \exists \gamma \tag{2}



\end{alignat}

\$

Thus, letting \(X_0 = XU\), (in general, \(\mathcal{C}(X_0) \subset \mathcal{C}(X)\)), then

\$
\begin{alignat}{2}



Y &= X \beta &&+ \epsilon

\\

&= X U \gamma &&+ \epsilon

\\

&= X_0 \gamma &&+ \epsilon \tag{3}

\end{alignat}

\$

Suppose \(\mathcal{C}(X_0) = \mathcal{C}(X)\). Then there is nothing to test and \(\Lambda' \beta = 0\) involves only arbitrary side conditions that do not affect the model. (EXAMPLE 3.3.1. pp.~62--64)

\$
\Lambda ' \beta ; ; \text{is estimable } ; ; \iff ; ; \exists P:\Lambda = X' P
\$

\$

\begin{align}

\mathcal{C}(MP) &\equiv \mathcal{C}(M-M_0) \\




&= \mathcal{C}(X-X_0) \\



&= \mathcal{C}(X) \; \cap \; \mathcal{C}(X_0)^\perp\\


&= \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp


\end{align}
\$

thus, its distribution for testing \(H_0: \Lambda ' \beta = 0\) is given by

\$

\begin{alignat}{2}

\dfrac
{\dfrac{Y'(M_{MP})Y}{r(M_{MP})}}
{\dfrac{Y'(I-M)Y}{r(I-M)}}

&\sim F \Big( r(M_{MP}), r(I-M), \delta^2 \Big)

 \tag{5}

\\
\\\

\delta^2 &= \beta ' X' M_{MP}X \beta

 \tag{non-centrality parameter}





\end{alignat}

\$

\begin{itemize}
\tightlist
\item
  Proposition 3.3.2
\end{itemize}

\$

\begin{alignat}{2}

\mathcal{C}(M-M_0) 


&= \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp \\

&= \mathcal{C}(XU)_{\mathcal{C}(X)}^\perp


= \mathcal{C}(MP) 

\end{alignat}

\$

\$

\begin{alignat}{2}

H_0: Y=X\beta + \epsilon, \; \; \; \; \; \Lambda ' \beta = 0

\\

\Updownarrow

\\

H_0: Y=X\beta + \epsilon, \; \; \; \; \; P'X \beta = 0

\\

\Updownarrow

\\


H_0: Y=X\beta + \epsilon, \; \; \; \; \; P'MX \beta = 0 (\because MX = X)

\\

\Updownarrow

\\

E(Y) \in \mathcal{C}(X), \; \; \; \; E(Y) \perp \mathcal{C}(MP)

\\

\Updownarrow

\\

E(Y) \in \mathcal{C}(X) \; \cap \;  \mathcal{C}(MP)^\perp, \; \; \; \; 
\mathcal{C}(X_0)=\mathcal{C}(X) \; \cap \; \mathcal{C}(MP)^\perp = \mathcal{C}(MP)^\perp_{\mathcal{C}(X)}

\Longrightarrow

\mathcal{C}(X_0)^\perp_{\mathcal{C}(X)} = \mathcal{C}(MP)





\\

\Updownarrow

\\




X_0 = (I-M_{MP})X








\end{alignat}

\$

\$

\begin{align}

\mathcal{C} \Big[ (I-M_{MP})X \ \Big] 


&= \mathcal{C} (X) \; \cap \; \mathcal{C} (MP)^\perp \\

&= \mathcal{C} (X) \; \cap \; \mathcal{C} (P)^\perp \tag{EXAMPLE 3.3.4.: pp.66–67}


\end{align}
\$

let \(\Lambda ' \beta\) is estimable, i.e., \(\Lambda = X'P\). then \(\mathcal{C}(\Lambda) = \mathcal{C}(X'P) =\mathcal{C}(MP)\), and \(X \hat \beta = MY\), and \(\Lambda ' \hat \beta = P' X \hat \beta = P' M Y\). then

\$

\begin{align}

Y' M_{MP}Y &= Y' M && (P'  M  P)^- && MPY




\\

&= \hat \beta ' \Lambda  && [P' X(X'X)^-X' P]^- && \Lambda ' \hat \beta

\\

&= \hat \beta ' \Lambda  && [\Lambda' (X'X)^- \Lambda]^- && \Lambda ' \hat \beta






\end{align}

\$

\textbf{\emph{이윗부분 전혀모르겠음}}

thus,

\$
\begin{align}
(5) = \dfrac{\dfrac{\hat \beta ' \Lambda [\Lambda ' (X'X)^- \Lambda]^- \Lambda' \hat \beta}{r(\Lambda)}}{MSE} &\sim F \Big( r(MP), r(I-M), \delta^2 \Big)\\


\\\
\\\



\delta^2  &= \dfrac{\hat \beta ' \Lambda [\Lambda ' (X'X)^- \Lambda]^- \Lambda' \hat \beta}{2 \sigma^2} \\

Cov\Big(\Lambda ' \hat \beta \Big)  &= \sigma^2 \Lambda ' (X' X)^{-} \Lambda 



\end{align}
\$

For \(H_0: \lambda ' \beta =0, \; \; \; \lambda \in \mathbb{R}^p\),

\$

\begin{align}


Y'M_{MP}Y &= \hat \beta ' \lambda \big [\lambda ' (X'X)^- \lambda \big]^- \lambda' \hat \beta

\\

&=\dfrac{\big( \lambda' \hat \beta \big)^2}{\lambda'(X'X)^-\lambda}

\end{align}

\$

and, under \(H_0: \lambda ' \beta =0\),

\$
F = (5) = \dfrac{\big( \lambda' \hat \beta \big)^2}{MSE \Big[\lambda'(X'X)^-\lambda\Big]} \sim F \Big ( 1, ; r(I-M) \Big)
\$

\begin{itemize}
\tightlist
\item
  Definition 3.3.5.
\end{itemize}

The condition \(E(Y) \perp \mathcal{C}(MP)\) is called the constraint by \(\Lambda ' \beta = 0\) where \(\Lambda = X' P\). in other words, \(\mathcal{C}(MP)\) is the \textbf{constraint} by \(\Lambda ' \beta = 0\).

\begin{itemize}
\tightlist
\item
  Do Exercise 3.5:
\end{itemize}

Show that a necessary and sufficient condition for \(\rho_1 ' X \beta = 0\) and \(\rho_2 ' X \beta = 0\) to determine the orthogonal constraints on the model is that \(\rho_1 ' X \rho_2 = 0\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{theoretical-complements}{%
\subsection{Theoretical Complements}\label{theoretical-complements}}

Consider testing \(\Lambda ' \beta = 0\) when \(\Lambda ' \beta\) is NOT estimable.

let \(\Lambda_0 ' \beta\) be estimable part of \(\Lambda ' \beta\).

\(\Lambda_0\) is chosen, so that \(\mathcal{C}(\Lambda_0) = \mathcal{C}(\Lambda) \; \cap \; \mathcal{C}(X')\), which means that \(\Lambda ' \beta = 0\) implies that \(\Lambda_0 ' \beta = 0\) but \(\Lambda_0 ' \beta\) is \textbf{estimable}, because \(\mathcal{C}(\Lambda_0) \subset \mathcal{C}(X')\).

\begin{itemize}
\tightlist
\item
  Theorem 3.3.6.
\end{itemize}

let \(\mathcal{C}(\Lambda_0) = \mathcal{C}(\Lambda) \; \cap \; \mathcal{C}(X')\) and \(\mathcal{C}(U_0) = \mathcal{C}(\Lambda_0)^\perp\). Then \(\mathcal{C}(XU) = \mathcal{C}(XU_0)\). Thus \(\Lambda ' \beta = 0\) and \(\Lambda_0 ' \beta = 0\) induce the same RM.

\begin{itemize}
\tightlist
\item
  Proposition 3.3.7.
\end{itemize}

let \(\Lambda_0 ' \beta\) be estimable and \(\Lambda \not = 0\). then \(\Lambda ' \beta = 0 \; \; \Longrightarrow \; \; \mathcal{C}(XU) \not = \mathcal{C}(X)\).

\begin{itemize}
\tightlist
\item
  Corollary 3.3.8.
\end{itemize}

\$

\mathcal{C}(\Lambda\_0) = \mathcal{C}(\Lambda) ; \cap ; \mathcal{C}(X') = \{0 \}

\textbackslash{}

\Updownarrow

\textbackslash{}

\mathcal{C}(XU) ; \cap ; \mathcal{C}(X)

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{a-generalized-test-procedure-1}{%
\subsection{A Generalized Test Procedure}\label{a-generalized-test-procedure-1}}

Consider as below, whose column space is solvable.

\(H_0: \Lambda' \beta = d, \; \; \; \; \; d \in \mathcal{C}(X'), \; \; \; \; \Lambda' b =d\)

\$
\begin{alignat}{2}




\Lambda ' \beta = 

\Lambda ' b =  d



 \; \; \; &\iff \Lambda ' (\beta - b) &&= 0





\\

&\iff (\beta - b) &&\perp \mathcal{C}(\Lambda)

\\

&\iff (\beta - b) &&\in \mathcal{C}(U) \; \; \; \; \; \; &&\text{where } \; \mathcal{C}(U) = \mathcal{C}(\Lambda)^\perp

\\

&\iff (\beta - b) &&= U_\gamma &&\exists \gamma


\\

&\iff X\beta - Xb &&= XU_\gamma

\\

& \; \; \; \Updownarrow

\\

X\beta  &= XU_\gamma + Xb, \\

Y &= X \beta + \epsilon \\
&= X U_\gamma + Xb + \epsilon \\
&= X_0 \gamma + Xb + \epsilon, && && \text{where } \; X_0 = XU








\end{alignat}

\$

if \(\Lambda = X'P\), then \(\mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp = \mathcal{C}(MP)\) and its test statistics is

\$
\begin{align}



F = \dfrac
{\dfrac{(Y-Xb)'M_{MP}(Y-Xb)}{r \Big(M_{MP} \Big)}}
{\dfrac{(Y-Xb)'(I-M)(Y-Xb)}{r \Big(I-M \Big)}}

= 






\dfrac
{\dfrac{(\Lambda ' \hat \beta - d)' \Big[ \Lambda'(X'X)^{-}\Lambda \Big]^- (\Lambda ' \hat \beta - d)}{r(\Lambda)}}
{MSE}


\sim F(?, ?, ?)

\end{align}
\$

\begin{itemize}
\tightlist
\item
  Remark: (EXAMPLE 3.3.9.: pp.71--72, EXAMPLE 3.4.1.: pp.75)
\end{itemize}

If \(\Lambda ' \beta = d\), the same reduced model results if we take \(\Lambda ' \beta = d_0\), where \(d_0 = d + \Lambda ' \nu\) and \(\nu \perp \mathcal{C}(X')\). Note that, in this construction, if \(\Lambda ' \beta = d\) is estimable, \(d_0 = d\) for any \(\nu\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{testing-single-degrees-of-freedom-in-a-given-subspace}{%
\subsection{Testing Single Degrees of Freedom in a Given Subspace}\label{testing-single-degrees-of-freedom-in-a-given-subspace}}

\$
RM: Y=X\_ 0 \gamma + \epsilon  ; ; ; ; ; vs.~; ; ; ; ;

FM: Y=X \beta + \epsilon, ; ; ; ; ; with; ; \mathcal{C}(X\_0) \subset \mathcal{C}(X)

\$

let \(M_\ast = M - M_0\), consider \(H_0 : \Lambda ' \beta = 0\).

if \(\Lambda = X'P\), i.e.~\(\Lambda \in \mathcal{C}(X')\), then \(M_\ast = M_{MP}\).

\begin{itemize}
\tightlist
\item
  Proposition 3.3.2
\end{itemize}

Since \(M M_\ast = M_\ast\),

\$

\begin{align}

&\mathcal{C}(M - M_0) = \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp \equiv \mathcal{C}(XU)_{\mathcal{C}(X)}^\perp = \mathcal{C}(MP)

\\

\Longrightarrow \; \; \; 

&M \rho \in \mathcal{C}(M_\ast)


\\

\Longrightarrow \; \; \; 

&M \rho = M_\ast M \rho =  M_\ast \rho


\\

\Longrightarrow \; \; \; 

&\rho ' \hat \beta = \rho ' M_\ast Y = \rho ' M Y 



\end{align}
\$

thus the test statistic for \(H_0 : \Lambda ' \beta = 0\) is

\$

\dfrac{Y ' M_\ast \rho ( \rho ' M_\ast \rho )^{-1} \rho ' M_\ast Y }{MSE}

=

\dfrac{\dfrac{(\rho ' M_\ast Y)^2}{\rho ' M_\ast \rho} }{MSE}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{breaking-ss-into-independent-components}{%
\subsection{Breaking SS into Independent Components}\label{breaking-ss-into-independent-components}}

Consider \(X = \begin{pmatrix} X_0, & X_1 \end{pmatrix}\). set

\$

\begin{alignat}{2}
&SSR(X_1 \vert X_0) &&\equiv Y ' (M-M_0)Y && \tag{Sum of Squares for regression X1 after X0}\\

&SSR(X) &&\equiv Y ' MY \\

&SSR(X_0) &&\equiv Y ' M_0 Y \\

&SSR(X) &&= SSR(X_0) &&+ SSR (X_1 \vert X_0)

\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  Note: if \(\epsilon \sim N(0, \; \sigma I)\), then \(SSR(X_0) \perp SsR(X_1 \vert X_0)\).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{general-theory}{%
\subsection{General Theory}\label{general-theory}}

Let \(M\) and \(M_\ast\) be the orthogonal projection operator into \(\mathcal{C}(X)\) and \(\mathcal{C}(X_\ast)\) respectively. Then, with \(\mathcal{C}(X_\ast) \subset \mathcal{C}(X)\), \(M_\ast\) defines a test statistic as below.

\$

\dfrac

\{\dfrac{Y' M_\ast Y}{r(M_\ast)}\}
\{\dfrac{Y' (I-M) Y}{r(I-M)}\}

; ; ; \text{for RM}:Y = X\_\ast \gamma + \epsilon

\$

\$
\begin{align}

&I-(M-M_\ast ) &&= (I-M) + M_\ast

\\

&\mathcal{C}(M-M_\ast) &&:\tag{Estimation Space, under H0}

\\

&\mathcal{C}(M_\ast)  &&:\tag{Test Space, under H0}

\\


&\mathcal{C} \Big(I - (M-M_\ast)\Big)  &&:\tag{Error Space, under H0}





\end{align}

\$

Using Gram-Schmidt procedure, let's construct \(M_\ast\) so that

\$

M\_\ast = RR' = \sum\emph{\{i=1\}\^{}r R\_iR\_i ' = \sum}\{i=1\}\^{}r M\_i, ; ; ; ; ; R=(R\_1 , \cdots, R\_r)

\$

and \(M_i M_j=0\) for \(i \not = j\). By \textbf{Theorem 1.3.7},

\$
Y'M\_i Y \perp Y'M\_j Y ; ; ; \iff ; ; ; M\_i M\_j =0
\$

Next, \$ Y'M Y = \sum\_\{i=1\}\^{}r Y'M\_i Y \$, therefore when \(r(M_i)=1\),

\$

\dfrac

\{\dfrac{Y'M_i Y}{r(M_i)}\}
\{\dfrac{Y'(I-M) Y}{r(I-M)}\}

\sim F \Bigg( 1, r(I-M), \dfrac{1}{2 \sigma^2} \beta ' X' M\_i X \beta \Bigg)

\$

\$

\begin{alignat}{2}

& && &&   &&\beta ' X' M_\ast X \beta \; \; &&= \; \; \sum_{i=1}^r \beta ' X' M_i X \beta  &&  =0

\; \; \;

\\

&\iff && && \forall i \; \; : \; \; && \beta ' X' M_i X \beta && &&=0

\\

&\iff && &&\forall i \; \; : \; \; &&R_i ' X \beta && &&= 0

\\

&\iff && && &&H_0 \text{ is true.}




\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  EXAMPLE 3.6.1.: Balanced design; pp.79--80
\item
  EXAMPLE 3.6.2.: Unbalanced design;pp.80--81
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{two-way-anova}{%
\subsection{Two-Way ANOVA}\label{two-way-anova}}

\$
\begin{alignat}{2}
y_{ijk} &= \mu + \alpha_i + \eta_j &&+ \epsilon_{ijk} \tag{FM}

\\





y_{ijk} &= \mu + \alpha_i  &&+ \epsilon_{ijk} \tag{RM}


\end{alignat}
\$

\$
\begin{align}
M &= M_\mu + M_\alpha + M_\eta

\\

Y'(M-M_0)Y &= R(\eta \; \Big \vert \; \alpha, \; \mu) \tag{1}


\end{align}
\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduction in SSE, due to fitting \(\eta_j\)'s after \(\mu\) and \(\alpha_i\)'s.
\end{enumerate}

Next,

\$

\begin{alignat}{2}
y_{ijk} &= \mu + \alpha_i &&+ \epsilon_{ijk} \tag{FM}

\\





y_{ijk} &= \mu &&+ \epsilon_{ijk} \tag{RM}


\\

\\\

\\\


Y'(M_0-M_J)Y &= R(\alpha \; \Big \vert \; \mu) 

\\

Y'(M-M_J)Y &= R(\alpha, \; \eta \; \Big \vert \; \mu)

\\

&= R(\eta \; \Big \vert \; \mu, \; \alpha) &&+ R(\alpha \; \Big \vert \; \mu)  



\end{alignat}

\$

In general,

\$

\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) &\not = R(\eta \; \Big \vert \; \mu)  
 
\\

R(\alpha \; \Big \vert \; \eta, \; \mu) & \not = R(\alpha \; \Big \vert \; \mu)  
 


\end{alignat}

\$

In paricular, for balanced design, if \(\mathcal{C}(X_\alpha) \perp \mathcal{C}(X_\eta)\),

\$

\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) & = R(\eta \; \Big \vert \; \mu)  
 
\\

R(\alpha \; \Big \vert \; \eta, \; \mu) & = R(\alpha \; \Big \vert \; \mu)  
 


\end{alignat}

\$

\begin{itemize}
\tightlist
\item
  Proposition 3.6.3.
\end{itemize}

\$

\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) & = R(\eta \; \Big \vert \; \mu)  
 


\; \; \; \; \; &&\iff \; \; \; \; \;


\mathcal{C}(X_1 - M_j) \perp \mathcal{C}(X_0 - M_j)

\\



\text{that is}\; \; \; \; \; \; \; 


M_1 - M_J& = M-M_0
 


\; \; \; \; \; &&\iff \; \; \; \; \;


(M_1 - M_J)(M_0 - M_J) = 0, 


\; \; \; \; \; \text{where} \; &&R(\eta \; \Big \vert \; \alpha, \; \mu) &&= Y'(M-M_0)Y

\\

& && && R(\eta \; \Big \vert \; \mu) &&= Y'(M_1 -M_0)Y

\end{alignat}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{confidence-regions}{%
\subsection{Confidence Regions}\label{confidence-regions}}

\(100(1-\alpha)\%\) Confidence Region(CR) for \(\Lambda ' \beta\) consists of all the vectors \(d\) satisfying the inequality

\$

\dfrac

\{\dfrac{\Big[\Lambda ' \hat \beta - d\Big]' \Big[\Lambda ' (X'X)^- \Lambda\Big]^- \Big[\Lambda ' \hat \beta - d\Big]}{r(\Lambda)}\}
\{MSE\}

\le \Big( 1- \alpha, ; r(\Lambda), ; r(I-M) \Big)

\$

These vectors form an ellipsoid in \(r(\Lambda)\)-dimensional space.

For regression problems, if we take \(P' = (X'X)^{-1}X'\), then \(\Lambda'\beta = P' X \beta = \beta = d\).

The \(100(1-\alpha)\%\) CR is

\$
\begin{alignat}{2}


&
\dfrac
{\dfrac{\Big[\Lambda ' \hat \beta - d\Big]' \Big[\Lambda ' (X'X)^- \Lambda\Big]^- \Big[\Lambda ' \hat \beta - d\Big]}{r(\Lambda)}}
{MSE}

\; \; \; 
&&
= 

\; \; \; 
&
\dfrac
{\dfrac{\Big(\hat \beta - \beta \Big)' \Big( X'X \Big)\Big(\hat \beta - \beta \Big)}

{p}}
{MSE}

\; \; \; 

&&\le 

\; \; \; 
\Big( 1- \alpha, \; p, \; n-p \Big)


\end{alignat}

\$

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{tests-for-generalized-least-squares-models}{%
\subsection{Tests for Generalized Least Squares Models}\label{tests-for-generalized-least-squares-models}}

\$
\begin{alignat}{4}

&Y &&= &&X \beta &&+ &&\epsilon \; \; \; \; \; &&vs. \; \; \; \; \; &&Y = &&X_0 \beta_0 &&+ &&\epsilon

, \; \; \; \; \; && \epsilon \sim N(0, \; \sigma^2 V)



\tag{1}

\\


& && && && && && \Updownarrow

\\







Q^{-1}&Y &&= Q^{-1} &&X \beta &&+ Q^{-1} &&\epsilon \; \; \; \; \; \; \; \;  \; &&vs. \; \; \; \; \; Q^{-1} &&Y = Q^{-1} &&X_0 \beta_0 &&+ Q^{-1} &&\epsilon



, \; \; \; \; \; Q^{-1} && \epsilon \sim N(0, \; \sigma^2 I)

\tag{2}

\end{alignat}
\$

test (1) and (2) is equal.

\begin{itemize}
\tightlist
\item
  Note: \(\mathcal{C}(Q^{-1}X_0) \subset \mathcal{C}(Q^{-1}X)\).
\end{itemize}

From Section 2.7,

\$
\begin{align}


A &= X(X'V^{-1}X)^- X' \ast V^{-1}

\\
\\

MSE &= \dfrac{Y' (I-A)' V^{-1} (I-A)Y}{n-r(X)}

\\
\\

A_0 &= X_0(X_0'V^{-1}X_0)^- X_0' \ast V^{-1}

\end{align}
\$

\begin{itemize}
\tightlist
\item
  Theorem 3.8.1
\end{itemize}

\$
\begin{align}

\dfrac{\dfrac{Y' (A-A_0) V^{-1} (A-A_0)Y}{r(X) - r(X_0 )}}{MSE} &\sim F \Big( r(X)-r(X_0), \; n-r(X) , \; \delta^2 \Big)

\\
\\

\delta^2 &= \dfrac{\beta ' X' (A-A_0) V^{-1} (A-A_0)X \beta}{2\sigma^2} \tag{1}


\\

\\

\\\


{\beta ' X' (A-A0) V^{-1} (A-A_0)X \beta} \; \; \; \; \; &\iff \; \; \; \; \; E(Y) \in \mathcal{C}(X_0) \tag{2}


\end{align}
\$

\begin{itemize}
\tightlist
\item
  Theorem 3.8.2
\end{itemize}

let \(\Lambda ' \beta\) be estimable. then the test statistic for \(H_0 : \Lambda ' \beta = 0\) is

\$
\begin{align}




\dfrac{\dfrac{\hat \beta ' \Lambda \Big[ \Lambda ' (X'V^{-1}X)^- \Lambda \Big]^- \Lambda ' \hat \beta}{r(\Lambda)}}{MSE} &\sim F \Big( r(\lambda), \; n-r(X) , \; \delta^2 \Big)

\\
\\

\delta^2 &= \dfrac{\beta ' \Lambda \Big[ \Lambda ' (X'V^{-1}X)^- \Lambda \Big]^- \Lambda ' \beta}{2\sigma^2} \tag{1}


\\

\\

\\\


{\beta ' \Lambda \Big[ \Lambda ' (X'V^{-1}X)^- \Lambda \Big]^- \Lambda ' \beta} \; \; \; \; \; &\iff \; \; \; \; \; \Lambda ' \beta  = 0\tag{2}


\end{align}
\$

\begin{itemize}
\tightlist
\item
  Theorem 3.8.3
\end{itemize}

\$
\begin{align}

\dfrac{Y' (A-A_0) V^{-1} (A-A_0)Y}{\sigma^2} &\sim \chi^2\Big(r(x) - r(X_0), \; \delta^2 \Big)

\\
\\

\delta^2 &= \dfrac{\beta ' X' (A-A_0) V^{-1} (A-A_0)X \beta}{2\sigma^2},

\\
\\

\sigma^2 = 0 \; \; \; \; \; &\iff E(Y) \in \mathcal{C}(X_0)




\tag{1}


\\

\\

\\\

\dfrac{\hat \beta ' \Lambda \Big[ \Lambda ' (X'V^{-1}X)^- \Lambda \Big]^- \Lambda ' \hat \beta}{2\sigma^2} 

&\sim \chi^2 \Big( r(\Lambda) , \; \delta^2 \Big)


\\
\\

\delta^2 &= {\hat \beta ' \Lambda \Big[ \Lambda ' (X'V^{-1}X)^- \Lambda \Big]^- \Lambda ' \hat \beta}, 

\\
\\

\sigma^2 = 0 \; \; \; \; \; &\iff \Lambda ' \beta = 0 \tag{2}


\end{align}
\$

\hypertarget{generalized-least-squares}{%
\section{Generalized Least Squares}\label{generalized-least-squares}}

Consider a full rank parameterization

\$
Y = X \beta + \epsilon ; ; ; ; ; ; ; ; ; ; E(\epsilon)=0, ; ; ; Cov(\epsilon) = \sigma\^{}2 \Sigma\textgreater0
\$

by SVD of \(\Sigma\),

\$

\begin{alignat}{2}


\Sigma

&= \Gamma ' \Lambda \Gamma
= \Gamma ' \Lambda^{\tfrac{1}{2}} \Lambda^{\tfrac{1}{2}}\Gamma
= \Gamma ' \Lambda^{\tfrac{1}{2}} \Gamma' \Gamma \Lambda^{\tfrac{1}{2}}\Gamma
= \Lambda^{\tfrac{1}{2}} 

\\

\\

Z &\equiv \Lambda^{-\tfrac{1}{2}} Y = \Lambda^{-\tfrac{1}{2}}(X \beta + \epsilon) = \Lambda^{-\tfrac{1}{2}}X \beta + \Lambda^{-\tfrac{1}{2}} \epsilon = W \beta + \epsilon^\ast

\end{alignat}

\$

\$
\begin{align}

\hat \beta &= (W'W)^{-1} W' Z = (X' \Sigma^{-1}X)^{-1}X'\Sigma^{-1}Y

\\

E(\hat \beta) &= (X' \Sigma^{-1}X)^{-1} X'\Sigma^{-1} X \beta = \beta

\\

Cov(\hat \beta) &= \sigma^2 (X' \Sigma^{-1}X)^{-1}

\\

\hat \sigma^2 &= \dfrac{\Vert Z - \mu_Z \Vert^2}{n-p} = \dfrac{(Y-\hat \mu)' \Sigma^{-1} (Y-\hat \mu)}{n-p}

\end{align}
\$

the projection Matrix is \$ \Sigma\^{}\{-\tfrac{1}{2}\} X (X' \Sigma\textsuperscript{\{-1\}X)}\{-1\}X' \Sigma\^{}\{-\tfrac{1}{2}\}\$, which is symmetric, and hence is an orthogonal projection.

Now all computations have been done in the \(z\) coordinates, so in particular \(x' \beta\) estimates \(\mu_Z = \Sigma^{-\tfrac{1}{2}} \mu\).

Since linear combinations of Gauss-Markov estimates are Gauss-Markov, it follows immediately that \(\hat \mu_Z = \Sigma^{-\tfrac{1}{2}} \hat \mu\).

\hypertarget{a-direct-solution-via-inner-products}{%
\subsection{A direct solution via inner products}\label{a-direct-solution-via-inner-products}}

We can approach the problem of determining the \textbf{Generalized Least Squares} estimators in a different way by viewing \(\Sigma\) as determining an intter product.

We do this by returning to first principles, carefully defining means and covariances in a general inner product space.

let \(x, \; y \in \mathbb{R}^n\) and \((x,y) = x'y\) be the usual innter product.

choose a basis \(\{e_1 , \cdots, e_n \}\), the usual coordinate vectors. then a rvec \(x\) has coordinates \((e_i, x) = x_i\).

\begin{itemize}
\tightlist
\item
  Definition 1.
\end{itemize}

\(E(x)=\mu= \begin{pmatrix} \mu_i \end{pmatrix}\) where \(\mu_i = E(e_i , \; x)\). For any \(a \in \mathbb{R}^n\),

\$
E\Big( (a, x) \Big) =

E\Bigg( \Big(\sum\_\{i=1\}\^{}n a\_i e\_i, ; x \Big) \Bigg) =

E\Bigg( \sum\_\{i=1\}\^{}n a\_i (e\_i, ; x) \Bigg) =

\sum\_\{i=1\}\^{}n a\_i \mu\_i =

(a, ; \mu)
\$

thus, another characterization of \(\mu\) is: \(\mu\) is the unique vector that satisfies \(E\Big( (a, x) \Big) = (a, \; \mu)\) for all \(a \in \mathbb{R}^n\).

Now, turn to Cov. use the same set-up as above. if \(E(x_i^2)<\infty\), then \(Cov(x_i , x_j) = (x_i = \mu_i) (x_j - \mu_j) = \sigma_{ij} = \sigma_{ji}\) exists for all \(i,j\), and defines \(\Sigma = (\sigma_{ij})\).

For any \(a, b \in \mathbb{R}^n\),

\$
Cov\Big( (a, x), (b, x) \Big) =

E\Bigg( \Big(\sum\emph{\{i=1\}\^{}n a\_i x\_i, ; \sum}\{j=1\}\^{}n b\_j x\_j \Big) \Bigg) =

\sum\emph{\{i=1\}\^{}n \sum}\{j=1\}\^{}n a\_i b\_j \ast Cov(x\_i, ; x\_j) =

\sum\emph{\{i=1\}\^{}n \sum}\{j=1\}\^{}n a\_i b\_j \ast \sigma\_\{ij\}

=(a, \Sigma b)

\$

\begin{itemize}
\tightlist
\item
  Definition 2
\end{itemize}

Assume \(E\Bigg( (a,x)^2 \Bigg) < \infty\). The unique non-negative definite linear transformation \(\Sigma: V \rightarrow V\) that satisfies \(Cov\Bigg( (a,x), (b,x) \Bigg) = (a, \Sigma b)\) for all \(a, b \in V\) is called the covariance of \(X\) and is denoted \(Cov(x)\).

\begin{itemize}
\tightlist
\item
  Theorem 1
\end{itemize}

let \(Y \in V\) with innerproduct \((\cdot, \; \cdot)\), \(Cov(Y)=\Sigma\). Define another inner product \((\cdot, \; \cdot )\) on \(V\) by \([x,y] - (x, \; Ay)\) for some positive definite \(A\). Then the covariance of \(X\) in the inner product sapce \(V, \; [\cdot, \; \cdot])\) is \(\Sigma A\).

\begin{itemize}
\tightlist
\item
  Note 1:
  This shows that if \(Cov(X)\) exists in one inner product, it exists in all inner products.
\end{itemize}

If \(Cov(X)=\Sigma\) in \(\begin{pmatrix} V & (\cdot, \; \cdot) \end{pmatrix}\), then if \(\Sigma > 0\) in the inner product \([x,y] = (x, \; \Sigma^{-1}y)\), the covariance is \(\Sigma^{-1} \Sigma = I\).

\begin{itemize}
\tightlist
\item
  Theorem 2
\end{itemize}

Suppose \(Cov(X) = \Sigma\) in \(\begin{pmatrix} V & (\cdot, \; \cdot) \end{pmatrix}\). If \(\Sigma_1\) is symmetric on \(\begin{pmatrix} V & (\cdot, \; \cdot) \end{pmatrix}\), and \(Cov \Big( (a,x) \Big) = (a, \; \Sigma_1 a)\) for all \(a \in V\), then \(\Sigma_1 = \Sigma\). This implies that the covariance is unique.

Consider the inner product sapce given by \(\begin{pmatrix} \mathbb{R}^n & (\cdot, \; \cdot) \end{pmatrix}\), where \([x,y] = (x, \; \Sigma^{-1}y)\), \(E(Y)=\mu \in \mathcal{E}\) and \(Cov(Y) = \sigma^2 \Sigma\).

Let \(P_\Sigma\) be the projection on \(\mathcal{E}\) in this inner product space, and let \(Q_\Sigma = I - P_\Sigma\), so \(y = P_{\Sigma} y + Q_{\Sigma} y\).

\begin{itemize}
\tightlist
\item
  Theorem 3
\end{itemize}

with \([x,y] = (x, \; \Sigma^{-1}y)\), \(P_\Sigma = X(X'\Sigma^{-1} X )^{-1} X' \Sigma^{-1}\) is an orthogonal projection.

\begin{itemize}
\tightlist
\item
  Theorem 4
\end{itemize}

let the OLS estimate \(\hat \beta = (X'X)^{-1}X'Y\) and the GLS estimate \(\tilde \beta = (X'\Sigma^{-1}X)^{-1} X' \Sigma^{-1}Y\). then

\$
\hat \beta = \tilde \beta ; ; ; ; ; \iff ; ; ; ; ; \mathcal{C}(\Sigma\^{}\{-1\}X) = \mathcal{C}(X)
\$

\begin{itemize}
\tightlist
\item
  Corollary 1
\end{itemize}

\(\mathcal{C}(\Sigma^{-1}X) = \mathcal{C}(X)= \mathcal{C}(\Sigma X)\)

So \(\Sigma\) need not be inverted to apply the theory.

To use this equivalence theorem (due to W. Kruskal), we usually characterize the \(\Sigma\)'s for a given \(X\) for which \(\hat \beta = \tilde \beta\).

if \(X\) is completely arbitrary, then only \(\Sigma = \sigma^2 I\) works.

\begin{itemize}
\tightlist
\item
  Intra-class correlation model:
\end{itemize}

let \(J_n \in \mathcal{C}(X)\). then any \(\Sigma\) of the form

\$
\Sigma = \sigma\^{}2 (1-\rho)I + \sigma\^{}2 \rho J\_n J\_n '
\$

with \(-\dfrac{1}{n-1} < \rho < 1\) will work.

to apply the theorem, we write,

\$
\Sigma X = \sigma\^{}2 (1-\rho)X + \sigma\^{}2 \rho J\_n J\_n ' X
\$

so for \(i>1\), the i-th coluimn of \(\Sigma X\) is

\$
\Big( \Sigma X \Big)\_i = \sigma\^{}2 (1-\rho)X\_i + \sigma\^{}2 \rho J\_n a\_i
\$

with \(a_i = J_n ' X\).

Thus, the i-th column of \(\Sigma X\) is a linear combination of the i-th column of \(X\) and the column of \(1\)'s.

For the first column of \(\Sigma X\), we compute \(a_1 = J_n\) and \(\Big ( \Sigma X \Big)_1 = \sigma^2 (1- \rho) J_n + n \sigma^2 \rho J_n = \sigma^2 \Big ( 1 + \rho(n-1) \Big )J_n\), So \(\mathcal{C}(\Sigma X) = \mathcal{C}(X)\) as required, provided that \(1+\rho(n-1) \not = 0\) or \(\rho > -\dfrac{1}{n-1}\).

\hypertarget{flat}{%
\section{Flat}\label{flat}}

\hypertarget{flat-1}{%
\subsection{1.Flat}\label{flat-1}}

Sometimes in statistical applications it is useful to consider a linear subspace that is shifted or translated from the origin. This will happen, for example, in models that include an intercept. It is therefore helpful to have the following definition of a space that is displaced from the origin.

\begin{itemize}
\tightlist
\item
  Definition 1 (Flat)
\end{itemize}

suppose \(M \subset V\) is a linear subspace, and \(y_0 \in V\). Then a \textbf{flat} consists of \(\{x + y_0 \; \Big \vert \; x \in M\}\). We will write \(y_0 +M\) where \(M\) is a subspace to indicate a flat.

By considering \textbf{translations}, \textbf{flats} are equivalent to vector spaces. If \(Y\) is a rv whose domain is the flat \(y_0 +M\), then, if \(y_0\) is fixed, \(Y-y_0\) has domain \(M\).

\begin{itemize}
\tightlist
\item
  example
\end{itemize}

set \(S_4 = \{(1,1,1)' + z, \; z \in S_2\}\) is a flat, because \(0 \not \in S_4\).

\begin{itemize}
\tightlist
\item
  example
\end{itemize}

In \(C e^2\), consider \(M= \left \{ \alpha \begin{pmatrix} 1 \\ 2 \end{pmatrix} \Bigg \vert \; \alpha \in C e \right\}\), and \(y_0 = \begin{pmatrix} 2 \\ 2 \end{pmatrix}\).

Then the flat \(y_0 + M\) is given by the set \(y_0 + M= \left \{ \begin{pmatrix} 2 \\ 2 \end{pmatrix} + \alpha \begin{pmatrix} 1 \\ 2 \end{pmatrix} \Bigg \vert \; \alpha \in C e \right\}\).

which is just a straight line that does not pass through the origin, but rather through the point \((2,2)\). The choice of \(y_0\) is not unique and it can be any point \(y=y_0 + y_\alpha\), where \(y_\alpha = \alpha(1,2)'\). For example, if \(\alpha = -2\), then \(y=(0,-2)'\) and if \(\alpha=+1\), then \(y=(3,4)'\), and so on. For any \(y_0\) not of this form, we simply get a different flat. This is summarized in the next remark.

\begin{itemize}
\tightlist
\item
  Theorem 1
\end{itemize}

The two spans

\$
\begin{align}

F_1 &= \left\{ z \; \Big \vert  \; z=y_0 + x, \; \; \; y_0 \in V, \; \; \;  x \in M \subset V \right\}

\\

F_2 &= \left\{ z \; \Big \vert  \; z=y_1 + x, \; \; \; y_1 \in F_1, \; \; \;  x \in M \subset V \right\}


\end{align}
\$

are the same subspace, so the representation of the flat is not unique.

\begin{itemize}
\tightlist
\item
  Definition 2 (Sum and intersection of subspaces)
\end{itemize}

let \(H,K\) be two linear subspaces. Then

\$
\begin{alignat}{2}


H + K &= \Big\{ x+y \; &&\Big \vert  \; x \in H, \; \; \;  y \in K \Big\} \tag{sum of H and K}

\\

H \cap K &= \Big\{ x \; &&\Big \vert  \; x \in H, \; \; \;  x \in K \Big\} \tag{intersection of H and K}



\end{alignat}
\$

\begin{itemize}
\tightlist
\item
  Theorem 2
\end{itemize}

Both \(H + K\) and \(H \cap K\) are linear subspaces.

\begin{itemize}
\tightlist
\item
  Definition 3 (Disjoint subspaces)
\end{itemize}

Two subspaces are \textbf{disjoint} if \(H \cap K = \big \{ 0 \big \}\), the \textbf{null vector}.

\begin{itemize}
\tightlist
\item
  Theorem 3
\end{itemize}

If \(H \cap K = \big \{ 0 \big \}\), and \(z \in H +K\), then the decomposition \(z = x+y\) with \(x \in H\) and \(y \in K\) is unique.

prf) suppose \(z=x+y\) and \(z=x' + y'\). Then, \(x-x' \in H\) and \(y-y' \in K\). We must have \(x+y = x' + y'\) or \(x-x'=y-y'\), which in turn requires that \(x-x' = y-y' = 0\), since \(0\) is the only vector common to \(H\) and \(K\). Thus, \(x=x'\) and \(y=y'\).

\begin{itemize}
\tightlist
\item
  Theorem 4
\end{itemize}

if \(H \cap K = \big \{ 0 \big \}\), then \(\dim(H+K) = \dim(H) + \dim(K)\). In general, \$\dim(H+K) = \dim(H) + \dim(K) -\dim(H \cap K) \$

Proof: Exercise.

\begin{itemize}
\tightlist
\item
  Definition 4 (Complement of a space)
\end{itemize}

If \(M\) and \(M^c\) are disjoint subspaces of \(V\) and \(V = M +M^c\), then \(M^c\) is called a \textbf{complement} of \(M\).

\begin{itemize}
\tightlist
\item
  Remark 1: The complement is \textbf{not unique}. In \(\mathbb{R}^2\), a subspace \(M\) of dimension 1 consists of a line through the origin. A complement of \(M\) is given by any other line \(M^c \not = \alpha M\) through the origin, because linear combinations of any two such lines span \(Ce^2\).
\end{itemize}

In the linear model \(Y = X \beta + \epsilon\), we have that \$\mu= E(Y ) = X \beta \$, so that \(\mu \in \mathcal{C}(X)\). To estimate \(\mu\) with \(\hat \mu\), we might want to require that \(\hat \mu \in \mathcal{C}(X)\) (note: if \(X\) includes a constant, then \(\mathcal{C}(X)\) is a flat; otherwise, it is a subspace). The estimate would then depend upon \(Y\) in a sensible way by \textbf{moving} \(Y\) to the subspace. The method of moving is via projections. The optimality of moves depends on the way we measure distance - on an inner product defined on the vector space.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{solutions-to-systems-of-linear-equations}{%
\subsection{2. Solutions to systems of linear equations}\label{solutions-to-systems-of-linear-equations}}

Consider the Matrix equation \(X_{n \times p} \beta_{p \times 1} = y_{n \times 1}\). For a given \(X\) and \(Y\) does there exist \(\beta\) to these equations? Is it unique? If not unique, can we characterize all possible solutions?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(n=p\) and \(X\) is nonsingular, the unique solution is \(\beta = X^{-1} y\).
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  If \(y \in \mathcal{C}(X)\), \(y\) can be expressed as a linear combination of the columns of \(X\). If \(X\) is of full column rank, then the columns of \(X\) form a basis for \(\mathcal{C}(X)\), and the solution \(\beta\) is just the coordinates of \(y\) relative to this basis. For any g-inverse \(X^-\), we have \(XX^- y = y\) for all \(y \in \mathcal{C}(X)\), and so a solution is given by \(\beta=X^- y\). If \(\rho (X) = rank \Big( \mathcal{C}(X) \Big) < p\), then the solution is not unique. If \(\beta_0\) as \textbf{any} solution, for example the solution is given by \(\beta=X^- y\), then so is \(\beta_0 + z, \;\;\;\;\; z\in N(X)\), which is null-space of \(X\). The set of solutions is given by \(\beta_0 + N(X)\), which is a \textbf{flat}.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  If \(y \not \in \mathcal{C}(X)\), then there is no exact solution. This is the usual situation in linear models, and leads to the estimation problem discussed in the next chapter.
\end{enumerate}

What we might do is get the \textbf{closest} solution by replacing \(Y\) by another vector \(\hat Y\) that is as close to \(Y\) as possible; if we define close as \(\Vert Y - \hat Y \Vert^2\) making small, we need to solve \(X \beta = P_{\mathcal{C}(X)}Y\) insetead of the original equation. If \(X\) has full column rank, this leads to the familiar solution:

\$
\begin{align}
\beta_0 &= X^+ P y

\\
&= (X'X)^{-1} X' X (X'X)^{-1}X' Y

\\

& = (X'X)^{-1}X'Y

\tag{2}

\end{align}
\$

which is unique. If \(X\) does not have not full column rank, then the set of solutions again forms a flat of the form \(\beta_0 + N(X)\) with \(\beta_0\) given by (2).

\hypertarget{unified-approach-to-balanced-anova-models}{%
\section{Unified Approach to Balanced ANOVA Models}\label{unified-approach-to-balanced-anova-models}}

We can develop a unified approach to obtaining orthogonal projection operatores in arbitrary balanced \(k\)-way ANOVA models by exploting the structure of design matrix. The structure of the design matrix can be easily examined using Kronecker products. Therefore, before we proceed further, we need to establish some more properties of Kronecker products.

Kronecker Product \(:= A \otimes B = (a_{ij}B)\).

Consider the balanced two-way ANOVA model with interaction. This model is given by

\$
Y\_\{ijk\} = \mu + \alpha\_ i + \eta\emph{j + \gamma}\{ij\} + \epsilon\_\{ijk\}
\$

where \(i=1, \cdots, a\), \(j=1, \cdots, b\), \(k=1, \cdots, N\), and \(n=abN\).

We want to write

\$
\mathcal{C}(M) = \mathcal{C}(M\_\mu) + \mathcal{C}(M\_\alpha) + \mathcal{C}(M\_\eta) + \mathcal{C}(M\_\gamma)
\$

and be able to compute the orthogonal projection operators in an easy and unified way.

We can represent each subspace making up \(\mathcal{C}(M)\) in terms of Kronecker produdcts. Once we do this, we can easily obtain the orthogonal projection operator for that space.

※ Notation: let \(s\) be an arbitrary index. Define \(J_s\) as the \(s \times 1\) vector of ones, \$P\_s = \dfrac{1}{s} J\_s J\_s ' \$ and \(Q_s = I_s - P_s\), where \(I_s\) is the \(s \times s\) identity matrix.

Thus, \(P_s\) is the orthogonal projection operator onto \(\mathcal{C}(J_s)\) and \(Q_s\) is the orthogonal projection operator onto \(\mathcal{C}(J_s)^\perp\)

※ Facts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  recall that the OPO onto \(\mathcal{C}(A)\) is always given by by \(A(A'A)^{-}A'\).
\item
  if \(M\) is an OPO, then \(M^{-} = M\).
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\$ Kronecker Product forms for the OPO

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Computing \(M_\mu\).
\end{enumerate}

We can write \(J_n = J_\a \otimes J_b \otimes J_N\), so that \(M_\mu\) is the OPO onto \(\mathcal{C} \Big( J_\a \otimes J_b \otimes J_N \Big)\). Thus by Fact 1 above, we have

\$

\& \&\&M\_\mu \&\& \&\&

\textbackslash{}

\&=
\&\&( J\_\a \otimes J\_b \otimes J\_N )
\&\&\Big( ( J\_a ' \otimes J\_b ' \otimes J\_N ' ) ( J\_a \otimes J\_b \otimes J\_N ) \Big)\^{}\{-\}
\&\&( J\_a ' \otimes J\_b ' \otimes J\_N ' )

\textbackslash{}

\&=
\&\&( J\_a \otimes J\_b \otimes J\_N )
\&\&( J\_a ' J\_a \otimes J\_b ' J\_b \otimes J\_N ' J\_N)\^{}\{-\}
\&\&( J\_a ' \otimes J\_b ' \otimes J\_N ' )

\textbackslash{}

\&=
\&\&( J\_a \otimes J\_b \otimes J\_N )
\&\&( ab N)\^{}\{-\}
\&\&( J\_a ' \otimes J\_b ' \otimes J\_N ' )

\&=
\&\&\dfrac{1}{a} J\_a J\_a ' + \dfrac{1}{b} J\_b J\_b ' + \dfrac{1}{N} J\_N J\_N'

\textbackslash{}

\&=
\&\&P\_a \otimes P\_b \otimes P\_N

\$

Using the properties of Kronecker products, it can be easily shown that \(M = I_a \otimes I_b \otimes P_N\).

the error space is \(\mathcal{C}(I-M)\) and

\$

I-M

\&= I\_\{abN\} - M \textbackslash{}

\&= ( I\_a \otimes I\_b \otimes I\_N ) - ( I\_a \otimes I\_b \otimes P\_N ) \textbackslash{}

\&= ( I\_a \otimes  ) \otimes ( I\_N - P\_N ) \textbackslash{}

\&= I\_a \otimes I\_b \otimes Q\_N

\$

observe that

\$

\begin{align}

M + I - M &= ( I_a \otimes I_b \otimes P_N ) + (I_a \otimes I_b \otimes Q_N) \\

&= ( I_a \otimes I_b) \otimes(P_N + Q_N) \\

&= ( I_a \otimes I_b) \otimes (I_N) \\

&= I_a \otimes I_b \otimes I_N \\

&= I_n

\end{align}

\$

We can summarize the subspace and the OPO for the two-way ANOVA model as follows.

\begin{itemize}
\tightlist
\item
  Excercise
\end{itemize}

Consider the three-way ANOVA model

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  write out the subspaces and all OPO corresponding to each term in the ANOVA model completlely in terms of Kronecker.
\item
  Find the simplest expression for \(M_\mu + M_\alpha + M_\eta\).
\end{enumerate}

\url{https://smartstore.naver.com/hidamari/products/5283571274}

\url{https://smartstore.naver.com/hidamari/products/3029413531}

\hypertarget{part-21-02}{%
\part{21-02}\label{part-21-02}}

\hypertarget{network-stats}{%
\chapter{Network Stats}\label{network-stats}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

\begin{itemize}
\tightlist
\item
  Network = Graph: for mathematical purposes, networks are most commonly represented in a formal manner using graphs of various kinds
\end{itemize}

Vertices (Vertex), Edges, directed, undirected

\hypertarget{types-of-network-analysis}{%
\subsection{Types of Network Analysis}\label{types-of-network-analysis}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Visualization
\item
  Numerical Summaries
\end{enumerate}

\begin{itemize}
\item
  \textbf{Transitivity} (\textbf{Clustering Coefficient}): A-B, A-C 조합의 변호사가 동업할 때, B-C끼리도 동업할 확률은 얼마일까? 이는 social network에서의 \textbf{transitivity} 개념과 대응함. 소위 \textbf{clustering coefficient}로 요약되는, 삼각형을 이루는 (즉, 모든 세개의 vertex pair가 edge로 연결) vertex 3개 묶음들의 비율을 나열하는 것으로 수치적으로 획득 가능.
\item
  \textbf{Assortativity Coefficient}: 2가지 종류의 변호사(corporate와 litigation)이 존재할 때, 동업과 더 일을 자주하는지 다른 분야와 더 일을 자주하는지, 그 비율은 어떻게 되는지 궁금할 수 있음. 이는 social network의 \textbf{assortativity} 개념과 대응하며, in which labels of connected pairs of vertices들이 compared되는, 소위 \textbf{assortativity coefficient}라고 불리는 correlation statistic으로 quantified될 수 있다.
\item
  주된 관심은 네트워크의 vertex (변호사 케이스라면 변호사 실무) 에 있으며 네트워크 구조 레벨의 속성은 좀 더 역할이 흐릿한 편
\end{itemize}

\hypertarget{network-modeling-and-inference}{%
\subsection{Network Modeling and Inference}\label{network-modeling-and-inference}}

관찰 대상 네트워크가 어떻게 생겼는지 묻고 구조를 특성화하는 것을 넘어, 보다 근본적인 수준에서 우리는 네트워크가 어떻게 발생했는지 이해하는 데 관심이 있을 수 있다. 즉, 우리는 네트워크가 복잡한 관심 시스템과 관련된 몇 가지 기본적인 프로세스에서 비롯되었다고 생각하고 이러한 프로세스의 본질적인 측면이 무엇인지 물어볼 수 있다. 네트워크가 어떤 과정을 거쳐 획득되었는지 - 사용된 measurement와 construction process - 또한 숙고될만한 부분이다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Network Modeling:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Mathematical Models: 간단한 확률 규칙에 의거하여 네트워크를 생산. 규칙은 특성한 메커니즘 혹은 원칙을 파악하기 위한 시도의 일환으로 정의됨 (ex: `the rich get richer')
  \item
    Statistical Models: 대부분, 아니면 일부분이나마, 관측된 데이터와 맥락을 같이 하기 위해 정의되는 모델 (자주 probabilistic하기도 함, 1번의 성질도 같이 갖는다는 소리) 이며 이의 fit함은 통계적 추론의 일반적인 원칙들을 사용하여 영향을 받고, 또 평가도 받음
  \end{enumerate}

  이러한 2개의 모델의 종류 사이에는 교집합이 존재하지만, 이 둘을 다루는 paper들 사이에는 그럼에도 불구하고 큰 차이들이 존재함
\item
  Erdos-Renyi Model: 각 vertex 쌍마다 iid 동전던지기를 통해 해당 쌍 사이에 edge를 둘지 안둘지를 랜덤하게 결정. 랜덤 그래프의 유명한 Erdos-Renyi 공식의 변형에 해당. 이는 성질이 정말 좋음. cohesive structure가 edge 1개에서의 확률의 함수로서 나타남. 또한 다른 더 복잡한 모델들과 비교되어 이해를 돕기 위한 교과서로서도.
\item
  Mathematical Network Model: 수학모델은 현실 네트워크 데이터에 비하면 보통 너무 간단하지만, edge 구성의 특정 메커니즘이 어떻게 네트워크의 구조에 영향을 미칠 수 있는가 하는 것과, 관측된 네트워크에서 획득할 수 있는 구조적 성질이 얼마나 ``significance'' 한지를 판정하기 위한 네트워크의 \textbf{null classes}로 작동할 수 있다는 것에서 여전히 공부할 가치가 있음.
\item
  Statistical Network Models: \textbf{Exponential Random Graph Models} 는 Generalized Linear Models (GLM)과 유사하며, 이는 둘다 지수족 형태(exponential family form)에 기반을 두고 있다. edge들이 unmeasured, 혹은 알려지지 않은 변수에 뿌리를 두고 있다는 것이 핵심인 \textbf{Latent network models}은 \textbf{hierarchical modeling}에서의 latent 변수 사용법과 정확하게 평행하다 즉, \textbf{\emph{대비된다???}}. \textbf{Stochastic block models}는 mixture 모델의 형태로 볼 수도 있다. 여기서 중요한건 이렇게 나열해놨지만서도 고차원 데이터가 의존성 높은 데이터를 쓰면 이런 애들은 이렇게 표준화된 모델과 맞아떨어지는 정도가 낮아진다는 것이다.
\end{enumerate}

\hypertarget{network-processes}{%
\subsection{Network Processes}\label{network-processes}}

복잡계의 요소들간의 상호작용을 모사하기 위해, 네트워크 그래프 자체는 보통 네트워크 분석의 주된 목표가 됨. 물론 네트워크 구성 요소 중 시스템 내의 다른 모든 요소들과 상호작용하는 변량 혹은 속성이 있다면 이녀석이 최고관심의 대상이 될 것. 그러나 그럼에도 불구하고 요소들간의 상호작용이 앞에서 언급한 최고관심 대상에게 영향을 줄 것이라고 생각하는 것이 비합리적이지 않으므로 네트워크 그래프 자체는 여전히 모델링과 분석의 대상이기에 합당함. 우리는 확률과정을 네트워크에서의 ``삶''이라고 해석해볼 수 있으며 네트워크 안의 vertices에 의해 첨수(indexed)됨. 이러한 과정에 관한 다양한 질문들은 정적 network process에 관한 것이든 동적 network process에 관한 것이든 이들을 예측하고자 하는 문제로 해석될 수 있음.

\hypertarget{dynamic-processes}{%
\subsubsection{Dynamic Processes}\label{dynamic-processes}}

network-based 관점에서 연구되는 많은 system들은 본질적으로 동적임. 동적이 얘들 특성과 더 잘 부합함.

수학적 모델링이 여전히 이러한 과정을 모델링하는데 있어 1번째로 사용되는 툴이지만, network-based 통계적 모델들이 점차적으로 그 사용이 늘어나고 있음. 왜냐고? contact network에 대한 더욱 대량의 데이터가 사용 가능해지고 있으니까.

네트워크 flow 를 분석하기 위한 통계적 방법론들. 시작점으로부터 도착점까지의 material, 사람, 상품 등의 움직임 등을 생각해보면, flow들은 커뮤니케이션 네트워크 (인터넷 패킷 등), transportation 네트워크에 필수불가결한 동적 프로세스 이며 이외에도 그러함. 이러한 동적 프로세스들은 기본적으로 특이점이 없다면 시간의 흐름에 따라 evolve 될 것이 기대되고 있음.

\hypertarget{descriptive-statistics-of-networks}{%
\section{Descriptive Statistics of Networks}\label{descriptive-statistics-of-networks}}

• In the study of a given complex system, questions of interest can often be re-phrased in a useful manner as questions regarding some aspect of the structure or characteristics of a corresponding network graph.

\begin{itemize}
\tightlist
\item
  Various types of basic social dynamics can be represented by triplets of vertices with a particular pattern of ties among them (i.e., triads).
\item
  Questions involving the movement of information or commodities usually can be posed in terms of paths on the network graph and flows along those paths.
\item
  Certain notions of the `importance' of individual system elements may be captured by measures of how `central' the corresponding vertex is in the network.
\item
  The search for `communities' and analogous types of unspecified `groups' within a system frequently may be addressed as a graph partitioning problem.
\end{itemize}

• The structural analysis of network graphs has traditionally been treated primarily as a descriptive task, as opposed to an inferential task, and the tools commonly used for such purposes derive largely from areas outside of `mainstream' statistics.
-- An overwhelming proportion of these tools are naturally graph-theoretic in nature, and thus have their origins in mathematics and computer science.
-- The field of social network analysis has been another key source, contributing tools usually aimed at least originally at capturing basic aspects of social structure and dynamics.
-- The field of physics has also been an important contributor, with the proposed tools often motivated by analogues in statistical mechanics.

\hypertarget{vertex-and-edge-characteristics}{%
\subsection{Vertex and Edge Characteristics}\label{vertex-and-edge-characteristics}}

• The fundamental elements of network graphs are their vertices and edges
• Characterization of the Vertex and Edges
-- Characterizations based upon vertex degrees
-- Characterizations seeking to capture some more general notion of the `importance' of a vertex

\hypertarget{vertex-degree}{%
\subsubsection{Vertex Degree}\label{vertex-degree}}

• The degree dv of a vertex v, in a network graph G = (V, E), counts the number of edges in E incident upon v.
• Given a network graph G, define fd to be the fraction of vertices v ∈ V with degree dv = d.
• The collection \{fd\}d≥0 is called the degree distribution of G, and is simply a rescaling of the set of degree frequencies, formed from the original degree sequence.
Karate club network\\

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sand)}
\FunctionTok{library}\NormalTok{(igraphdata)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(karate)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{hist}\NormalTok{(}\FunctionTok{degree}\NormalTok{(karate), }\AttributeTok{col=}\StringTok{"lightblue"}\NormalTok{, }\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{),}
\AttributeTok{xlab=}\StringTok{"Vertex Degree"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Frequency"}\NormalTok{, }\AttributeTok{main=}\StringTok{""}\NormalTok{)}
\FunctionTok{hist}\NormalTok{(}\FunctionTok{graph.strength}\NormalTok{(karate), }\AttributeTok{col=}\StringTok{"pink"}\NormalTok{,}
\AttributeTok{xlab=}\StringTok{"Vertex Strength"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Frequency"}\NormalTok{, }\AttributeTok{main=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

• The degree distribution
-- There are three distinct groups of vertices, as measured by degree.
-- The two most highly connected vertices correspond to actors 1 and 34 in the network, representing the instructor and administrator about whom the club eventually split.
-- The next set of vertices consists of actors 2, 3, and also 33.

• Weighted Networks
-- A useful generalization of degree is the notion of vertex strength, which is obtained simply by summing up the weights of edges incident to a given vertex.
-- The distribution of strength sometimes called the weighted degree distribution is defined in analogy to the ordinary degree distribution

Figure 2: The vertex strength distribution for the Karate club network
A Network of Interactions among Protein Pairs in Yeast

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(yeast)}
\FunctionTok{ecount}\NormalTok{(yeast)}
\FunctionTok{vcount}\NormalTok{(yeast)}
\end{Highlighting}
\end{Shaded}

• Histogram: In particular, while there is a substantial fraction of vertices of quite low degree, of an order of magnitude similar to those of the karate network, there are also a non-trivial number of vertices with degrees at successively higher orders of magnitude.
• There is a fairly linear decay in the log-frequency as a function of log-degree.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{d.yeast }\OtherTok{=} \FunctionTok{degree}\NormalTok{(yeast)}
\FunctionTok{hist}\NormalTok{(d.yeast,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"Degree"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Frequency"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Degree Distribution"}\NormalTok{)}
\NormalTok{dd.yeast }\OtherTok{=} \FunctionTok{degree.distribution}\NormalTok{(yeast)}
\NormalTok{d }\OtherTok{=} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{max}\NormalTok{(d.yeast)}\SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{ind }\OtherTok{=}\NormalTok{ (dd.yeast }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(d[ind], dd.yeast[ind], }\AttributeTok{log=}\StringTok{"xy"}\NormalTok{, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{xlab=}\FunctionTok{c}\NormalTok{(}\StringTok{"Log{-}Degree"}\NormalTok{),}
\AttributeTok{ylab=}\FunctionTok{c}\NormalTok{(}\StringTok{"Log{-}Intensity"}\NormalTok{), }\AttributeTok{main=}\StringTok{"Log{-}Log Degree Distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure 3: The degree distribution for protein interactions in Yeast
• It can be interesting to understand the manner in which vertices of different degrees are linked with each other.
• Useful in assessing this characteristic is the notion of the average degree of the neighbors of a given vertex.
• While there is a tendency for vertices of higher degrees to link with similar vertices, vertices of lower degree tend to link with vertices of both lower and higher degrees.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.nn.deg.yeast }\OtherTok{=} \FunctionTok{graph.knn}\NormalTok{(yeast,}\FunctionTok{V}\NormalTok{(yeast))}\SpecialCharTok{$}\NormalTok{knn}
\FunctionTok{plot}\NormalTok{(d.yeast, a.nn.deg.yeast, }\AttributeTok{log=}\StringTok{"xy"}\NormalTok{, }\AttributeTok{col=}\StringTok{"goldenrod"}\NormalTok{,}
\AttributeTok{xlab=}\FunctionTok{c}\NormalTok{(}\StringTok{"Log Vertex Degree"}\NormalTok{), }\AttributeTok{ylab=}\FunctionTok{c}\NormalTok{(}\StringTok{"Log Average Neighbor Degree"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Figure 4: The degree distribution for protein interactions in Yeast

\hypertarget{vertex-centrality}{%
\subsubsection{Vertex Centrality}\label{vertex-centrality}}

• Many questions that might be asked about a vertex in a network graph essentially seek to understand
its `importance' in the network.
-- Which actors in a social network seem to hold the `reins of power'?
-- How authoritative does a particular page in the World Wide Web seem to be considered?
-- The deletion of which genes in a gene regulatory network is likely to be lethal to the corresponding organism?
-- How critical is a given router in an Internet network to the flow of traffic?

• Measures of centrality are designed to quantify such notions of `importance' and thereby facilitate the answering of such questions.
• Most widely used measure of vertex centrality: Vertex Degree.
• Three other classic types of vertex centrality measures: Closeness, Betweenness, and Eigenvector

\begin{itemize}
\tightlist
\item
  \textbf{centrality}
  • Closeness centrality measures attempt to capture the notion that a vertex is `central' if it is `close' to many other vertices.
  -- The standard approach is to let the centrality vary inversely with a measure of the total distance of a vertex from all others,
\end{itemize}

cCL =
1
P
u∈V
dist(u, v)
,
where dist(v, u) is the geodesic distance between the vertices u, v ∈ V .

-- Often, for comparison across graphs and with other centrality measures, this measure is normalized to lie in the interval {[}0, 1{]}, through multiplication by a factor Nv1.

• Betweenness centrality measures are aimed at summarizing the extent to which a vertex is located `between' other pairs of vertices.
-- These centralities are based upon the perspective that `importance' relates to where a vertex is located with respect to the paths in the network graph.
-- If we picture those paths as the routes by which communication of some sort or another takes place, vertices that sit on many paths are likely more critical to the communication process.
-- The most commonly used betweenness centrality is defined as

CB(v) = X
s6=t6=v∈V
σ(s, t \textbar{} v)
σ(s, t)

where σ(s, t \textbar{} v) is the total number of shortest paths between s and t that pass through v, and σ(s, t) is the total number of shortest paths between S and t (regardless of whether or not they pass through v).
-- This centrality measure can be restricted to the unit interval through division by a factor of (Nv − 1)(Nv − 2)/2.

• Other centrality measures are based on notions of `status' or `prestige' or `rank.'
-- Seek to capture the idea that the more central the neighbors of a vertex are, the more central that vertex itself is.
-- These measures are inherently implicit in their definition and typically can be expressed in terms of eigenvector solutions of appropriately defined linear systems of equations.
-- There are many such eigenvector centrality measures. For example,

CEi
(v) = α
X
\{u,v\}∈E
cEi
(u).
The vector CEi = (CEi
(1), · · · , CEi
(Nv))T

is the solution to the eigenvalue problem ACEi, where A is the adjacency matrix for the network graph G.

-- An optimal choice of α−1 is the largest eigenvalue of A, and hence cEi is the corresponding eigenvector.
-- When G is undirected and connected, the largest eigenvalue of A will be simple and its eigenvector will have entries that are all nonzero and share the same sign.
-- Convention is to report the absolute values of these entries, which will automatically lie between 0 and 1 by the orthonormality of eigenvectors.
• An intuitively appealing way of displaying vertex centralities (for networks of small to moderate size) is to use a radial layout, with more central vertices located closer to the center.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("network", repos="http://cran.us.r{-}project.org")}
\CommentTok{\#install.packages("sna", repos="http://cran.us.r{-}project.org")}
\NormalTok{A }\OtherTok{=} \FunctionTok{get.adjacency}\NormalTok{(karate, }\AttributeTok{sparse=}\ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{library}\NormalTok{(network)}
\NormalTok{g }\OtherTok{=} \FunctionTok{as.network.matrix}\NormalTok{(A)}
\FunctionTok{library}\NormalTok{(sna)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{gplot.target}\NormalTok{(g, }\FunctionTok{degree}\NormalTok{(g), }\AttributeTok{main=}\StringTok{"Degree"}\NormalTok{, }\AttributeTok{circ.lab =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{circ.col =} \StringTok{"skyblue"}\NormalTok{,}
\AttributeTok{usearrows =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{vertex.col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\FunctionTok{rep}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\DecValTok{32}\NormalTok{), }\StringTok{"yellow"}\NormalTok{),}
\AttributeTok{edge.col=}\StringTok{"darkgray"}\NormalTok{)}
\FunctionTok{gplot.target}\NormalTok{(g, }\FunctionTok{closeness}\NormalTok{(g), }\AttributeTok{main=}\StringTok{"Closeness"}\NormalTok{, }\AttributeTok{circ.lab =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{circ.col =} \StringTok{"skyblue"}\NormalTok{,}
\AttributeTok{usearrows =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{vertex.col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\FunctionTok{rep}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\DecValTok{32}\NormalTok{), }\StringTok{"yellow"}\NormalTok{),}
\AttributeTok{edge.col=}\StringTok{"darkgray"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("network", repos="http://cran.us.r{-}project.org")}
\CommentTok{\#install.packages("sna", repos="http://cran.us.r{-}project.org")}
\NormalTok{A }\OtherTok{=} \FunctionTok{get.adjacency}\NormalTok{(karate, }\AttributeTok{sparse=}\ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{library}\NormalTok{(network)}
\NormalTok{g }\OtherTok{=} \FunctionTok{as.network.matrix}\NormalTok{(A)}
\FunctionTok{library}\NormalTok{(sna)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{gplot.target}\NormalTok{(g, }\FunctionTok{betweenness}\NormalTok{(g), }\AttributeTok{main=}\StringTok{"Betweenness"}\NormalTok{, }\AttributeTok{circ.lab =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{circ.col =} \StringTok{"skyblue"}\NormalTok{,}
\AttributeTok{usearrows =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{vertex.col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\FunctionTok{rep}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\DecValTok{32}\NormalTok{), }\StringTok{"yellow"}\NormalTok{),}
\AttributeTok{edge.col=}\StringTok{"darkgray"}\NormalTok{)}
\FunctionTok{gplot.target}\NormalTok{(g, }\FunctionTok{evcent}\NormalTok{(g), }\AttributeTok{main=}\StringTok{"Eigenvalue"}\NormalTok{, }\AttributeTok{circ.lab =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{circ.col =} \StringTok{"skyblue"}\NormalTok{,}
\AttributeTok{usearrows =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{vertex.col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\FunctionTok{rep}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\DecValTok{32}\NormalTok{), }\StringTok{"yellow"}\NormalTok{),}
\AttributeTok{edge.col=}\StringTok{"darkgray"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

• Extensions of these centrality measures from undirected to directed graphs are straightforward.

Figure 6: Target plots showing various vertex centralities for the karate club network
-- Characterizes the importance of so-called hub vertices by how many authority vertices they
point to, and so-called authority vertices by how many hubs point to them.
-- Given an adjacency matrix A for a directed graph, hubs are determined according to the
eigenvector centrality of the matrix Mhub = AAT
, and authorities, according to that of
Mauth = AT A.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l }\OtherTok{=} \FunctionTok{layout.kamada.kawai}\NormalTok{(aidsblog)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(aidsblog, }\AttributeTok{layout=}\NormalTok{l, }\AttributeTok{main=}\StringTok{"Hubs"}\NormalTok{, }\AttributeTok{vertex.label=}\StringTok{""}\NormalTok{,}
\AttributeTok{vertex.size=}\DecValTok{10} \SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{hub.score}\NormalTok{(aidsblog)}\SpecialCharTok{$}\NormalTok{vector))}
\FunctionTok{plot}\NormalTok{(aidsblog, }\AttributeTok{layout=}\NormalTok{l, }\AttributeTok{main=}\StringTok{"Authorities"}\NormalTok{, }\AttributeTok{vertex.label=}\StringTok{""}\NormalTok{,}
\AttributeTok{vertex.size=}\DecValTok{10} \SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{authority.score}\NormalTok{(aidsblog)}\SpecialCharTok{$}\NormalTok{vector))}
\end{Highlighting}
\end{Shaded}

Figure 7: AIDS blog network with vertex area proportional to hubs and authority centrality measures

\hypertarget{characterizing-edges}{%
\subsubsection{Characterizing Edges}\label{characterizing-edges}}

• Edge betweenness centrality which extends vertex betweenness centrality in a straightforward manner, by assigning to each edge a value that reflects the number of shortest paths traversing that edge is a natural quantity to use.

• Using edge betweenness with the karate network and examining, for instance, the edges with the three largest betweenness values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eb }\OtherTok{=} \FunctionTok{edge.betweenness}\NormalTok{(karate)}
\FunctionTok{E}\NormalTok{(karate)[}\FunctionTok{order}\NormalTok{(eb, }\AttributeTok{decreasing=}\NormalTok{T)[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

• Many other vertex centrality measures do not extend as easily. One way around this problem is to apply vertex centrality measures to the vertices in the line graph of a network graph G.
• Line graph of G, say G0 = (V
0
, E0
), is obtained essentially by changing vertices of G to edges, and
edges, to vertices.
• The vertices v
0 ∈ V
0
represent the original edges e ∈ E, and the edges e
0 ∈ E0
indicate that the two corresponding original edges in G were incident to a common vertex in G.

\hypertarget{characterizing-network-cohesion}{%
\subsection{Characterizing Network Cohesion}\label{characterizing-network-cohesion}}

• Questions involving network cohesion, the extent to which subsets of vertices are cohesive or `stuck
together' with respect to the relation defining edges in the network graph.
-- Do friends of a given actor in a social network tend to be friends of one another as well?
-- What collections of proteins in a cell appear to work closely together?
-- Does the structure of the pages in the World Wide Web tend to separate with respect to
distinct types of content?
-- What portion of a measured Internet topology would seem to constitute the `backbone'?
• There are many ways that we can define network cohesion, depending on the context of the question
being asked.
-- Definitions differ, for example, in scale, ranging from local (e.g., triads) to global (e.g., giant
components), and also in the extent to which they are specified explicitly (e.g., cliques) versus
implicitly (e.g., `clusters' or `communities')

\hypertarget{subgraphs-and-censuses}{%
\subsubsection{Subgraphs and Censuses}\label{subgraphs-and-censuses}}

\begin{itemize}
\tightlist
\item
  \textbf{Cliques}
\end{itemize}

Cliques are complete subgraphs and hence are subsets of vertices that are fully cohesive, in the
sense that all vertices within the subset are connected by edges.
• A census of cliques of all size can provide some sense of a `snapshot' of how structured a graph is

For the karate network a census of this sort reflects that there are 34 nodes (cliques of size one)
and 78 edges (cliques of size two), followed by 45 triangles (cliques of size three).
• The largest cliques are of size five, of which there are only two

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(}\FunctionTok{cliques}\NormalTok{(karate), length))}
\FunctionTok{cliques}\NormalTok{(karate)[}\FunctionTok{sapply}\NormalTok{(}\FunctionTok{cliques}\NormalTok{(karate), length) }\SpecialCharTok{==} \DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

The cliques of larger sizes necessarily include cliques of smaller sizes.
• A maximal clique is a clique that is not a subset of a larger clique

• Large cliques are relatively rare, as they necessarily require that a graph G itself be fairly dense,
while real-world networks are often sparse

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(}\FunctionTok{maximal.cliques}\NormalTok{(karate), length))}
\FunctionTok{clique.number}\NormalTok{(yeast)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \textbf{\(k\)-core}
\end{itemize}

• Weakened Notions of Cliques. A \(k\)-core of a graph G is a subgraph of G for which all vertex degrees are at least k, and such that
no other subgraph obeying the same condition contains it (i.e., it is maximal in this property).
• The notion of cores is particularly popular in visualization, as it provides a way of decomposing a
network into `layers'.

Figure 8: Visual representation of the k-core decomposition of the karate network

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cores }\OtherTok{=} \FunctionTok{graph.coreness}\NormalTok{(karate)}
\FunctionTok{gplot.target}\NormalTok{(g, cores, }\AttributeTok{circ.lab =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{circ.col=}\StringTok{"skyblue"}\NormalTok{,}
\AttributeTok{usearrows =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{vertex.col=}\NormalTok{cores, }\AttributeTok{edge.col=}\StringTok{"darkgray"}\NormalTok{)}

\FunctionTok{detach}\NormalTok{(}\StringTok{"package:sna"}\NormalTok{)}
\FunctionTok{detach}\NormalTok{(}\StringTok{"package:network"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure 8: Visual representation of the k-core decomposition of the karate network

Vertices of coreness one (black), two (red), three (green), and four (blue) are shown at successively smaller
distances from the center, with the same distance for vertices within each core
Other Classes of Subgraphs in Defining Network Cohesion.
• Dyads are pairs of vertices and, in directed graphs, may take on three possible states: null (no
directed edges), asymmetric (one directed edge), or mutual (two directed edges).
• Triads are triples of vertices and may take on 16 possible states, ranging from the null subgraph
to the subgraph in which all three dyads formed by the vertices in the triad have mutual directed
edges.
The vast majority of the dyads are null and, of those that are non-null, almost all are asymmetric,
indicating a decided one-sidedness to the manner in which blogs in this network reference each other.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aidsblog }\OtherTok{=} \FunctionTok{simplify}\NormalTok{(aidsblog)}
\FunctionTok{dyad.census}\NormalTok{(aidsblog)}
\end{Highlighting}
\end{Shaded}

Consistent with the observations from our earlier analysis of hubs and authorities in this network
• Small connected subgraphs of interest are commonly termed motifs.
• The notion of motifs is particularly popular in the study of biological networks, where arguments
often are made linking such network substructures to biological function.

\hypertarget{density-and-related-notions-of-relative-frequency}{%
\subsubsection{Density and Related Notions of Relative Frequency}\label{density-and-related-notions-of-relative-frequency}}

\begin{itemize}
\tightlist
\item
  \textbf{Density}
\end{itemize}

The density of a graph is the frequency of realized edges relative to potential edges. For example,
in a (undirected) graph G with no self-loops and no multiple edges, the density of a subgraph
H = (VH, EH) is

den(H) = \textbar EH\textbar{}
\textbar VH\textbar(\textbar VH\textbar{} − 1)/2

The value of den(H) will lie between zero and one and provides a measure of how close H is to
being a clique. In the case that G is a directed graph, the denominator is replaced by \textbar VH\textbar(\textbar VH\textbar1).
• Taking H = G yields the density of the overall graph G.
• Conversely, taking H = Hv to be the set of neighbors of a vertex v ∈ V , and the edges between
them, yields a measure of density in the immediate neighborhood of v.
• The subgraphs corresponding to each of the instructor and the administrator, in union with their
immediate respective neighborhoods i.e., the ego-centric networks around vertices 1 and 34 are
noticeably more dense than the overall network.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ego.instr }\OtherTok{=} \FunctionTok{induced.subgraph}\NormalTok{(karate,}\FunctionTok{neighborhood}\NormalTok{(karate, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)[[}\DecValTok{1}\NormalTok{]])}
\NormalTok{ego.admin }\OtherTok{=} \FunctionTok{induced.subgraph}\NormalTok{(karate,}\FunctionTok{neighborhood}\NormalTok{(karate, }\DecValTok{1}\NormalTok{, }\DecValTok{34}\NormalTok{)[[}\DecValTok{1}\NormalTok{]])}
\FunctionTok{graph.density}\NormalTok{(karate)}

\FunctionTok{graph.density}\NormalTok{(ego.instr)}
\FunctionTok{graph.density}\NormalTok{(ego.admin)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \textbf{Clustering Coefficients}
\end{itemize}

The standard use of the term clustering coefficient typically refers to the quantity
clT (G) = 3τ∆(G)
τ3(G)
,
where τ∆(G) is the number of triangles in the graph G, and τ3(G), the number of connected triples
(i.e., a subgraph of three vertices connected by two edges, also sometimes called a 2-star).
• The value clT (G) is alternatively called the transitivity of the graph, and is a standard quantity of
interest in the social network literature, where it is also referred to as the `fraction of transitive
triples'.

clT (G) is a measure of global clustering, summarizing the relative frequency with which connected
triples close to form triangles.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{transitivity}\NormalTok{(karate)}
\FunctionTok{transitivity}\NormalTok{(karate, }\StringTok{"local"}\NormalTok{, }\AttributeTok{vids=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{34}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \textbf{Reciprocity}
  • A concept unique to directed graphs
  • In the case that dyads are used as units, reciprocity is defined to be the number of dyads with reciprocated (i.e., mutual) directed edges divided by the number of dyads with a single, unreciprocated
  edge.
  • Reciprocity is defined as the total number of reciprocated edges divided by the total number of
  edges.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{reciprocity}\NormalTok{(aidsblog, }\AttributeTok{mode=}\StringTok{"default"}\NormalTok{)}
\FunctionTok{reciprocity}\NormalTok{(aidsblog, }\AttributeTok{mode=}\StringTok{"ratio"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{connectivity-cuts-and-flows}{%
\subsubsection{Connectivity, Cuts, and Flows}\label{connectivity-cuts-and-flows}}

기본적으로 궁금한 건 주어진 그래프가 서로 다른 서브그래프로 쪼개질 수 있나 하는 것. 불가능하다면 해당 그래프가 이 쪼개질 수 있는 성질의 역치에 얼마나 가까운지를 체크하는 것이 목적이 된다.

만약 모든 vertex가 다른 모든 vertex에서 접근 가능하다면, 즉 adjacency Matrix가 diag 제외하고 모두 1이면, 그래프 \(G\)는 \textbf{connected}라고 칭해진다. 그리고 그래프의 \textbf{connected component}는 maximally connected 서브그래프이다.

그래프 \(G\)의 connected component 중 하나가 다른 모두를 위력에서 압도한다면, 이는 곧 해당 connected component가 \(G\)의 대부분의 vertex를 포함하고 있다는 이야기. 이러한 component는 \textbf{giant component}라고 불리며 이는 random graph theory 출신 용어.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.connected}\NormalTok{(yeast)}
\NormalTok{comps }\OtherTok{=} \FunctionTok{decompose.graph}\NormalTok{(yeast)}
\FunctionTok{table}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(comps, vcount))}
\end{Highlighting}
\end{Shaded}

결과는 false로 나오지만 이에 대해 census 돌리면 giant component의 존재 확인 가능. 아래 예시의 경우 component 1개가 2375/2617로 90퍼 vertex랑 연결중임. 이는 현실 네트워크에서의 \textbf{small world property}와 연결. vertex 쌍들 collection에서의 minimum path는 보통 되게 작음. 대비되게 clustring은 상대적으로 높음. (ex) protein?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yeast.gc }\OtherTok{=} \FunctionTok{decompose.graph}\NormalTok{(yeast)[[}\DecValTok{1}\NormalTok{]]}
\FunctionTok{average.path.length}\NormalTok{(yeast.gc)}
\FunctionTok{diameter}\NormalTok{(yeast.gc)}
\FunctionTok{transitivity}\NormalTok{(yeast.gc)}
\end{Highlighting}
\end{Shaded}

해당 네트워크에서의 shortest path는 \(N_v\)보다 \(\log N_v\)로 표현되는게 정확할 정도로 짧음. scales more like, thus considered small. 동시에 해당 네트워크에서의 clustering은 상대적으로 large, 이는 transitivity로 확인 가능.

\begin{itemize}
\tightlist
\item
  \textbf{Connectivity}
\end{itemize}

그래프 \(G\) 가
1. \textbf{\(k\)-vertex-connected}
- the number of vertices \(N_v > k\)
- cardinality \(|X|<k\)이며 \(X \subseteq V\)인 vertex의 subset \(X\)을 지우면 connected subgraph가 아니게 됨.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{\(k\)-edge-connected}

  \begin{itemize}
  \tightlist
  \item
    \(N_v ≥ 2\)
  \item
    cardinality \(|Y|<k\)이며 \(Y \subseteq E\)인 edge의 subset \(Y\)을 지우면 connected subgraph가 아니게 됨.
  \end{itemize}
\end{enumerate}

즉 \(G\)의 vertex (edge) connectivity는 \(G\)의 k-vertex(k-edge-) connected가 유지되는 가장 큰 integer. 이때 vertex connectivity \(\le\) edge connectivity \(\le\) minimum degree among vertex in \(G\) (dmin). 따라서 이 서브그래프를 추가적인 component로 분해하기 위해서는 단 1개의 엄선된 vertex나 edge를 제거하는 것으로 충분하다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vertex.connectivity}\NormalTok{(yeast.gc)}
\FunctionTok{edge.connectivity}\NormalTok{(yeast.gc)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \textbf{Cut}
\end{itemize}

vertex (edge)의 subset \(S\)를 제거하는 것으로 해당 그래프가 서브그래프로 조각난다면, \(S\)는 vertex-cut (edge-cut). 여기서 vertex \(S\)의 원소가 1개라면, 즉 vertex 1개만을 제거한 것으로 그래프가 조각났다면, 이는 cut vertex, 혹은 \textbf{articulation point}. 이러한 vertex의 여부를 식별하는 건 해당 네트워크가 외부 공격에 취약하는지를 파악하는데 도움이 됨. 해당 포인트 끊기면 네트워크 정상작동이 안되니까.

• Identification of such vertices can provide a sense of where a network is vulnerable (e.g., in the sense of an attack, where disconnecting produces undesired consequences, such as a power outage in an energy network).
• In the giant component of the yeast network, almost 15\% of the vertices are cut vertices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yeast.cut.vertices }\OtherTok{=} \FunctionTok{articulation.points}\NormalTok{(yeast.gc)}
\FunctionTok{length}\NormalTok{(yeast.cut.vertices)}
\end{Highlighting}
\end{Shaded}

nontrivial 그래프 \(G\)는 k-vertex (k-edge) connected \(\iff\) 서로다른 vertex의 쌍 \(u, v \in V\)가 k vertex-disjoint (edge-disjoint) paths에 의해 connected 가능.

이 결과는 그래프에서 특정 vertex (edge)가 제거된 상황에서도 그래프 내부에서 만들어지는 서로 다른 path 들이 얼마나 많은지를 통해 평가되는 그래프의 robust함과 연결되어 있다. 낮은 vertex (edge) connectivity 를 가지는 그래프는 따라서 path들을 가질 수 있으며, 이에 의해 그 path들을 통과했던 ``information''들은 작은 숫자의 vertex (edge)를 없애는 것만으로 쉽게 방해되고 만다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shortest.paths}\NormalTok{()}
\FunctionTok{graph.maxfow}\NormalTok{()}
\FunctionTok{graph.mincu}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{graph-partitioning}{%
\subsection{Graph Partitioning}\label{graph-partitioning}}

\textbf{Partitioning}은 elements의 집합을 ``발생이 자연스러운'' 부분집합으로 분할하는 과정. 더 이론적으로 말하자면, finite set \(S\)의 partition \(C = \{ C_1, \cdots, C_K \}\)는 \(S\)를 \(K\) 개의 disjoint로 decomposition 한 물건으로, 이인즉 \(\forall C_k \not = \emptyset: \cup_{k=1}^K C_k = S\).

네트워크 그래프 분석에서, partitioning은 겉으로 드러나지 않는 관계성 측면에서 vertex의 묶음이 ``cohesiveness''를 가지고 있는지를 확인하기에 유용한 방법이다. vertex의 ``cohesive''한 subset은 일반적으로 이하와 같은 걸 일컬음:
1. subset 내부에서, ``동시에'', 잘 connected 되어 있어야 한다
2. subset 외부, 즉 남아있는 vertex들과 잘 seperated - 연결성이 없음

Graph partitioning algorithms 은 보통 그래프 \(G(V, E)\)의 vertex set \(V\) 의 partition \(C = \{ C_1, \cdots, C_K \}\)를 찾는 것을 그 목표로 함. 이를 위한 방법으로 \(C_k\) 안의 vertex에서 \(C_k'\)로의 vertex로 잇는 edge의 sets \(E(C_k, C_k ')\)는 \(C_k\) 내에서 vertex 를 잇는 edge들의 set \(E(C_k) = E(C_k , C_k)\)보다 작다는 점을 활용함.

그래프 partitioning의 이 문제는 complex networks 문헌에서의 community detection에서도 동일하게 발생함. 이에 대한 해결책으로 큰 틀에서 2가지 접근법이 존재.

\hypertarget{hierarchical-clustering-1}{%
\subsubsection{Hierarchical Clustering}\label{hierarchical-clustering-1}}

그래프 파티셔닝에 사용되는 대부분의 방법은 본질적으로 Hierarchical Clustering의 변용에 불과함. 여러가지 방법론이 제시되었지만, 그 차이는 결국 이하가 다를 뿐임.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  proposed clusterings의 quality를 어떻게 측정하는가
\item
  연구자가 찾고 있는 해당 quality를 어떻게 최적화하는가. 보통 그리디 알고리즘으로 모든 가능한 partition \(C\)의 space를 탐색하는 식으로 한다. 이 과정에서 계속해서 후보 partition을 갱신하고.
\end{enumerate}

Hierarchical methods 는 다음 둘로 분류됨.
1. agglomerative, 파티션을 합쳐나가는 것을 계속해나가는 것으로 크기를 키워가는 것에 기반 (coarsen)
2. divisive, 파티션을 쪼개나가는 것을 계속해나가는 것으로 연속으로 다듬어나가는 것

각 단계에서 현재의 후보 partition은 지정된 비용 측정값을 최소화한다는 목적으로 계속해서 정제되어 갑니다.
1. agglomerative 방법에서는, 2개의 이전의 partition elements 중 가장 저렴한 merge 방법이 실행된다
2. divisive 방법에서는, 1개의 이전의 partition 중 가장 저렴하게 2개로 split 할 수 있는 방법이 실행된다

비용측정의 기준은 vertex의 ``cohesive'' subset을 뭘 기준으로 판정할지 하는 연구자의 주관이 개입됨. 메이저한 기준은 \textbf{modularity}. \(C = \{ C_1, \cdots, C_K \}\)를 주어진 후보 partition으로 하고, \(f_{ij} = f_{ij}(\mathcal C)\)는 \(C_i\)의 vertex를 to be the fraction of edges in the original network that connect vertices in Ci with vertices in Cj. 이때 \(\mathcal C\)의 \textbf{modularity}는

\[
\mod(\mathcal C) = \sum_{k=1}^K \left[ f_{kk}(\mathcal C) - f_{kk}^\ast \right]
\]

where \(f_{kk}^\ast\)는 random edge assignment의 몇몇 모델을 두고 만들어진 \(f_{kk}\)의 기댓값. \(f_{kk}^\ast\)는 \(f_{k+} \cdot f_{+k}\)이며 각각 \(f\)의 k번째 rowsum과 colsum. 즉 \(f_{ij}\)를 entry로 하는 \(K \times K\) 매트릭스가 만들어짐. This choice corresponds to a model in which a graph is constructed to have the same degree distribution as \(G\), but with edges otherwise placed at random, without respect to the underlying partition elements dictated by \(C\).

In principle the optimization of the modularity requires a search over all possible partitions C, which is prohibitively expensive in networks of moderate size and larger.
• A fast, greedy approach to optimization has been proposed, in the form of an agglomerative hierarchical clustering algorithm, and implemented in igraph as fastgreedy.community.
• The result of this and related community detection methods in igraph is to produce an object of the class communities, which can then serve as input to various other functions.

Applying this method to the karate network,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kc }\OtherTok{=} \FunctionTok{fastgreedy.community}\NormalTok{(karate)}
\FunctionTok{length}\NormalTok{(kc)}
\FunctionTok{sizes}\NormalTok{(kc)}
\FunctionTok{membership}\NormalTok{(kc)}
\end{Highlighting}
\end{Shaded}

The largest community of 18 members is centered around the administrator (i.e., John A, vertex ID 34).
• The second largest community of 11 members is centered around the head instructor (i.e., Mr Hi, vertex ID 1).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(kc, karate)}
\end{Highlighting}
\end{Shaded}

Figure 9: Partitioning of the Karate network obtained from hierarchical clustering

• Whether agglomerative or divisive, when used for network graph partitioning, hierarchical clustering methods actually produce, as the name indicates, an entire hierarchy of nested partitions of the graph, not just a single partition.
• The resulting hierarchy typically is represented in the form of a tree, called a dendrogram.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ape)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dendPlot}\NormalTok{(kc, }\AttributeTok{mode=}\StringTok{"phylo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{spectral-partitioning}{%
\subsubsection{Spectral Partitioning}\label{spectral-partitioning}}

spectral graph theory의 연구결과를 응용하여 그래프 \(G\)의 connectivity를 특정 매트릭스의 eigen-analysis와 연관짓는 것.

adjacency matrix \(A\)에 대한 그래프 \(G\)의 그래프 Laplacian 은 \(L = D − A\)이며, 이때 \(D = diag[(D_{vv} = d_v)]\), \(d_v\)는 \(G\)의 entries of the degree sequences.

spectral graph theory의 결과를 통해 우리는 다음을 파악 가능.

그래프 \(G\)는 \(K\) 개의 connected components로 구성 \(\iff\) \(\lambda_1 (L) = \cdots = \lambda_K(L) = 0\) 이며 \(\lambda_{K+1}(L)>0\), where \(\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_{N_v}\)들은 L의 (not necessarily distinct) ev이며, ordered from small to large.

그래프 안의 component의 숫자는 그래프 Laplacian의 non-zero ev의 숫자과 직접적으로 연관되어 있음. \(L\)의 최소 ev는 0임을 바로 보일 수 있다. evec \(x_1 = (1,\cdots,1)'\)에 대응하므로. 따라서 우리가 그래프 \(G\)가 ``거의'' \(K=2\) 개의 component들로 구성되어 있다고 추론한다면, 즉슨 2개로 쪼개기에 적합하다고 생각한다면, 이는 곧 우리는 해당 대상에 대해 \(\lambda_2(L)\)가 0에 가까울 것이라고 추론할 것이라는 것과 동치이다. 이러한 추론은 \(\lambda_2\)가 그래프 connectivity와 structure의 측정치의 값과 깊은 연관이 있기에 합리적이다. 특히 이러한 관계성은 \(\lambda_2\)가 0에 가까울 수록 서브그래프 A과 서브그래프 B 사이를 통과하는 edge가 적을 것이기에 이렇게 둘로 쪼개는 것이 합리적일 것임을 보여준다. \(\lambda_2\)를 그래프의 connectivity와 연관지은 제언자는 대응하는 evec \(x_2\) 안의 entries들의 부호에 따라 vertex들을 쪼개는 것을 주장했다. 결과는 다음과 같다:

\[
S = \{v \in V: x_2 (v) \ge 0 \}
\\
\bar S = \{v \in V: x_2 (v) < 0 \}
\]

즉, 2개의 vertex의 subset이 생산되며 (이를 보통 \textbf{cut}이라고 부름), 이 벡터 \(x_2\)는 보통 \textbf{Fiedler Vector}라고 불리며 이에 대응하는 ev \(\lambda_2\)는 \textbf{Fiedler Value}라고 부른다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k.lap }\OtherTok{=} \FunctionTok{graph.laplacian}\NormalTok{(karate)}
\NormalTok{eig.anal }\OtherTok{=} \FunctionTok{eigen}\NormalTok{(k.lap)}
\FunctionTok{plot}\NormalTok{(eig.anal}\SpecialCharTok{$}\NormalTok{values, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Eigenvalues of Graph Laplacian"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We plot the eigenvalues of the graph Laplacian.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  0인 ev는 딱 하나. (해당 네트워크는 connected이므로 예상한 결과)
\item
  2번째로 작은 ev인 \(\lambda_2\)는 0에 매우 가까움.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{faction }\OtherTok{=} \FunctionTok{get.vertex.attribute}\NormalTok{(karate, }\StringTok{"Faction"}\NormalTok{)}
\NormalTok{f.colors }\OtherTok{=} \FunctionTok{as.character}\NormalTok{(}\FunctionTok{length}\NormalTok{(faction))}
\NormalTok{f.colors[faction }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{=} \StringTok{"red"}
\NormalTok{f.colors[faction }\SpecialCharTok{==} \DecValTok{2}\NormalTok{] }\OtherTok{=} \StringTok{"cyan"}
\FunctionTok{plot}\NormalTok{(f.vec, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"Actor Number"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Fiedler Vector Entry"}\NormalTok{, }\AttributeTok{col=}\NormalTok{f.colors)}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\StringTok{"lightgray"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Fiedler vector를 생산하고 해당 vector의 요소들을 실제 actor number에 따라 배정한 그래프를 보면 이 spectral 방법이 faction label에 의해 네트워크 partitioning 을 획득할 수 있다는 것을 확인된다.

보통 우리는 네트워크가 서브그래프 2개보다는 더 잘게 쪼개질 수 있으리라고 예상 가능. spectral 방법을 iterative하게 적용하는 것으로 2개 이상으로 쪼갤 수 있음. 하지만 이러한 반복이 특정 목적 함수를 최적화할 수 있도록 목표하는 것이 바람직함. Newman은 spectral bisection method와 논리적 흐름이 유사하나 Laplacian \(L\)이 아니라 이를 대체해서 modularity와 연관된 매트릭스를 사용하는 방법을 제안했다.(leading.eigenvector.community)

\hypertarget{validation-of-graph-partitioning}{%
\subsubsection{Validation of Graph Partitioning}\label{validation-of-graph-partitioning}}

validation 문제는 그래프 partitioning에 항상 중요하지만, 대부분의 경우 nontrivial 문제이다. 네트워크 그래프에 vertex의 cohesive subset 이 존재한다면, 이러한 subset의 기저에는 vertex에게 있어 vertex 간에 특정한 연관적인 특성 (또는 속성)에 일부 공통성이 있을 것으로 일반적으로 예상한다. 그래프 partitioning은 이러한 성질에 대한 지식이 없을때 그러한 subset을 발견하기 위한 도구로 인식될 수도 있다. 우리가 그래프 외부에서 정의된 클래스 멤버쉽에 대한 subset 정의를 알고 있다면, 그래프 내부에서의 partitioning으로 얻은 분절들과 비교하는 것도 흥미로움.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{func.class }\OtherTok{=} \FunctionTok{get.vertex.attribute}\NormalTok{(yeast.gc, }\StringTok{"Class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(func.class)}
\end{Highlighting}
\end{Shaded}

해당 예시는 cell 구축에 있어 protein이 역할하는 바로 분절했음. 단백질들이 서로 다른 단백질들과 얼마나 유사한지는 특정 세포 역할에 해당 단백질이 무슨 일을 하는지와 연관되어 있다고 알려져 있음. 그래프 외부에서 이러한 단백질들을 분류하려는 시도는 분류된 결과가 그래프 내부에서 합리적은 partitioning 과정을 걸쳐 나온 결과물과 어느정도는 연관이 있는게 맞다. 아니면 partitioning이 잘못됐던가 그래프 외부 분절이 잘못됐던가.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yc }\OtherTok{=} \FunctionTok{fastgreedy.community}\NormalTok{(yeast.gc)}
\NormalTok{c.m }\OtherTok{=} \FunctionTok{membership}\NormalTok{(yc)}
\FunctionTok{table}\NormalTok{(c.m, func.class, }\AttributeTok{useNA=}\FunctionTok{c}\NormalTok{(}\StringTok{"no"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{assortativity-and-mixing}{%
\subsection{Assortativity and Mixing}\label{assortativity-and-mixing}}

\begin{itemize}
\tightlist
\item
  \textbf{Assortative mixing}
\end{itemize}

특정 성질에 따라서 vertex 중에 선별적으로 연결.

\begin{itemize}
\tightlist
\item
  Assortativity coefficients
\end{itemize}

assortative mixing의 정도를 량화하는 측도. 이는 correlation coefficients의 변용. vertex 특성은 categorical, ordinal, or continuous 다 가능. categorical 케이스를 가정하고, 그래프 \(G\)의 각 vertex가 \(M\)개의 카테고리 중에 label 될 수 있다고 생각하자. 이 세팅에서의 Assortativity coefficients \(r_a\)는 아래와 같다.

\[
r_a = \frac{\sum_{i}f_{ii} - \sum_i f_{x+}f_{+y}}{1 - \sum_if_{x+}f_{+y}}
\]

where fij is the fraction of edges in G that join a vertex in the i-th category with a vertex in the jth category, and fi+ and f+i denote the ith marginal row and column sums, respectively, of the resulting matrix f.

이때 \(-1 \le r_a \le 1\)

-- It is equal to zero when the mixing in the graph is no different from that obtained through a random assignment of edges that preserves the marginal degree distribution.
-- It is equal to one when there is perfect assortative mixing (i.e., when edges only connect vertices of the same category).
-- However, in the event that the mixing is perfectly disassortative, in the sense that every edge in the graph connects vertices of two different categories, the coefficient need not take the value −1.
• The fact that physical binding of proteins is known to be directly relevant to functional classes suggests that there will frequently be strong assortative mixing in protein-protein interaction networks with respective to these classes as attributes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{assortativity.nominal}\NormalTok{(yeast, (}\FunctionTok{V}\NormalTok{(yeast)}\SpecialCharTok{$}\NormalTok{Class}\SpecialCharTok{==}\StringTok{"P"}\NormalTok{)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\AttributeTok{directed=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

• When the vertex characteristic of interest is continuous, rather than discrete, denote by (xe, ye) the
values of that characteristic for the vertices joined by an edge e ∈ E.
• A natural candidate for quantifying the assortativity in this characteristic is just the Pearson correlation coefficient of the pairs (xe, ye),

\[
r = \frac{\sum_{x,y}xy(f_{xy} - f_{x+}f_{+y})}{\sigma_x \sigma_y}
\]

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{assortativity.degree}\NormalTok{(yeast)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-collection-and-sampling}{%
\section{Data Collection and Sampling}\label{data-collection-and-sampling}}

Difficulties in Network Data Collection. 뭔 분야든 통계의 근간은 데이터 수집. 데이터가 \textbf{IID}라면 이 데이터는 sample이나 실험에서 확보한 데이터. 하지만 이는 네트워크 실험에서는 사실상 불가능. 따라서 우리는 샘플을 deal with 하기가 어려우며, 이전에 해왔던 것 대비 일이 무척 어려워짐. 이러한 복잡성은 empirical networks를 다룰 때는 너무나도 자주 무시되고 있어서 안타까운 실정임.

\begin{itemize}
\tightlist
\item
  \textbf{Sampling Procedures}
\end{itemize}

이상적인 데이터에 해당하는 네트워크 census 를 생각해보자. 이는 모든 node 와 edge 를 기록하고 거기에 오류가 없음. 만약 완벽한 네트워크 census 데이터를 가지고 있는 케이스라면 샘플링 과정 스킵하고 바로 네트워크 formation 모델하는 단계로 넘어갈 수 있음.

하지만 그렇게 운좋을리가. 대다수의 경우에 보유한 네트워크 census 데이터는 불완전함. 보통 이런 실패는 네트워크의 성질과 mesurement process의 디테일 부족에서 옴. Survey 케이스를 생각해보자. survey 질문자, survey 답변자의 성격, survey 질문 구성 등으로 이런건 널뛰기함. 아니면 일부 질문 같은 경우에는 ``가장 좋아하는 연예인 3명'' 이런 식이라고 치자고. 이러면 4명 이하부터는 \textbf{censoring} 발생해서 이것도 완벽 데이터에서 왜곡됨.

\hypertarget{sampling-designs}{%
\subsection{Sampling Designs}\label{sampling-designs}}

우리가 \textbf{true}(참정보, 참값)를 확보하는 것이 불가능하다면, 우리는 IID 통계량에 의해 예시되었던 ``population'' graph \(G = (V, E)\) 확보를 포기하고 ``sample'' graph \(G^\ast = (V^\ast, E^\ast)\)를 얻는 쪽으로 선회한다. 이때 \(V^\ast \subset V\), \(E^\ast \subset E\).

이러한 sampled subgraphs를 얻기 위한 다양한 방법들에 대응되는 서로 다른 sampling designs들이 존재한다. 우선 population으로부터의 units들에 대한 simple random sample (SRS)를 이해하는 것이 샘플링을 이해하기 위한 1단계가 된다. 네트워크에서는 단순 랜덤 샘플마저도 복잡한 이해를 거쳐야 한다.

\hypertarget{induced-and-incident-subgraph}{%
\subsubsection{Induced and Incident Subgraph}\label{induced-and-incident-subgraph}}

node \(V\)의 Simpl Random Sample (SRS)인 \(V^\ast\)로부터 시작하자. 이로부터 발생시킨 (induced) subgraph \((i, j) \in E^\ast\). 이때 \((i, j) \in E^\ast \Leftrightarrow (i,j) \in E\), \(i \in V^\ast\) and \(j \in V^\ast\) 여야만 함. 이 정제되지 않은 natural 한 과정인 \textbf{induced subgraph sampling} 은 정말 간단한 네트워크 stats 에 대해서도 엄청 biased. bias를 계산해낸 후에 bias 를 보정할 수 있는 경우도 있지만 여하튼 bias 가 크다는게 장점은 아니지.

반면에 우리는 edge의 SRS에서 시작해볼 수도 있다. 이 경우 \(E^\ast\)는 \(E\)의 SRS. 이후 이 edge 양끝에 해당하는 발생을 node로서 잡는다. 이인즉슨 \(\exists j \in V:(i,j) \in E^\ast \Rightarrow i \in V^\ast\). 고전적 survey 에 대해 쌓인 경험에 비추어볼 때 \textbf{incident-subgraph sampling} 는 꽤 괴상해보이지만, 그럼에도 이쪽이 natural 한 경우가 꽤 있기는 함.

\hypertarget{example-of-a-bias}{%
\paragraph{Example of a Bias}\label{example-of-a-bias}}

우리가 정말정말 간단하기 그지없는 작업인 node 의 랜덤 샘플링을 진행할 때조차도 샘플링이 왜 bias 를 유발해버리는 걸까? 이는 \textbf{mean degree} 를 생각해보면 쉽게 알 수 있다. 직관적으로 생각해보자. induced subgraph 를 하나 가지고 있다. 이때 우리는 induced subgraph 바깥인데 전체 그래프 안에 있는, 즉 induced subgraph 에 포함되지 못한 edge 는 관측할 수가 없다. 따라서 우리가 각 node 에 대해 기록할 수 있는 degree 는 많아봤자 그것들의 degree 참값에 불과할 것이다. 따라서 샘플된 그래프들의 mean degree 는 mean degree 의 참값보다 작아져버리겠지. bias 발생.

let \(k_i = \sum_{j=1}^n A_{ij}\), 즉 \(k_i\)는 node \(i\)의 degree. 이 경우 모든 네트워크에 걸친 mean degree는 \$\bar k = \frac{1}{n} \sum\emph{\{i=1\}\^{}n k}\{i\} \$. 여기서 \(m\)개의 노드를 SRS 한다면, node \(i\)에게 부여된 확률은 모든 각각의 node에게 부여된 확률과 같으므로, 따라서 \(\pi = \frac{m}{n}\).

여기서 \(Z_i\)를 \(i \in V^\ast\) 여부에 대한 indicator로 정의하자. 그렇다면 node \(i\)가 샘플 안에 있을 경우 \(Z_i = 1\).

또한 관측된 graph \(G^\ast\)는 관측된 adjacency matrix \(A^\ast\)를 보유하며, \(A_{ij}^\ast =1\) iff \(A_{ij}=1\)이며 \(i,j\) 양쪽 모두가 샘플에 있을 경우에만.

그렇다면 plug-in estimate \(\bar k\) from \(G^\ast\)의 기댓값 \(\bar k^\ast\)는 어떻게 되는가?

\$\$
\begin{alignat}{2}

E \left( \bar k^\ast \right)


&= E \left( \frac{1}{m} \sum_{i \in V^\ast} k_i^\ast \right)

&&= E \left( \frac{1}{m} \sum_{i \in V^\ast} \sum_{j \in V^\ast} A_{ij}^\ast \right)

\\


&= E \left( \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}Z_i Z_j \right)

&&= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  E \left(Z_i Z_j \right)

\\

&= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  \pi^2

&&=\frac{1}{n \pi} \pi^2 \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

\\

&= \frac{\pi}{n } \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

&&= \pi \bar k




\end{alignat}
\$\$

\hypertarget{exploratory-sampling-design}{%
\subsubsection{Exploratory Sampling Design}\label{exploratory-sampling-design}}

\textbf{induced} 와 \textbf{incident} 이외의 방법론을 쓰고 싶은 경우도 있지 않을까? \textbf{induced} 와 \textbf{incident} 서브그래프 샘플링 양쪽 모두에서 \textbf{sampling frame} 은 실제로 발생하는 그래프에 비하면 약간 좀 거리가 있고 이질적이다. 우리가 SRS 를 사용하는 대상인 population 은 모든 node를 포함하거나, 모든 edge를 포함해야 하지만, but doesn't use the graph beyond that.

\textbf{egocentric} 디자인에서 우리는 nodes 들을 샘플링한 후에 이렇게 샘플링된 nodes 들의 local 이웃에 대해서만, 혹은 \textbf{ego network} 에 대해서만, 정보를 수집하고 기록한다. 혹은 \textbf{``ego''} 케이스에서 우리는 edge 들이나 initial node 의 이웃들의 edges 들이나 non-edges 들만 기록함; 이는 때때로 \textbf{star design} 이라고 불림. star design 케이스에서 우리는 local 그래프 이웃에 대한 정보를 수집한 후 이들이 중복되는 지점이 있는지를 확인함. 기록 과정을 뭘 쓰느냐에 달려있긴 한데 이 정보는 보통 수집 가능함.

\hypertarget{snowball-sampling}{%
\paragraph{Snowball Sampling}\label{snowball-sampling}}

seed node 로 부터 시작. 이의 직접적인 이웃을 바로 기록. 이후 그 이웃들로 이동한 후 또 직접적인 이웃을 기록. 이 작업을 새로운 node 가 더이상 발견되지 않거나, 정해진 size 에 도달할 때까지 함. 이때 seeds 는 여럿이 있을 수 있음. 이 여럿인 경우에, 가령 seeds 가 2개라면, 진행하다가 서로 다른 seed 로부터 촉발된 2개의 snowball 이 overlap 되는 상황에 마주쳤을 때 어느 snowball을 고를지 결정하는 문제가 생김.

\textbf{snowball 샘플링}은 그래프에 대해, incuded 나 incident 에 의해 얻어지는 것 그 어느것과도 다른 분포를 얻게 되는 결과를 초래함. seed 가 SRS에 의해 정해졌더라도 snowball 에 의해 골라지는 다른 node 들은 랜덤샘플이 아님. initial node 이외의 node 들은 seed 로부터 길을 따라서 도착할 수 있는 node 다 보니, 그들은 적어도 degree 가 1은 보장되어야 하고, 약하게나마 seed 에 연결은 되어 있어야 하마, 일반적으로 평균보다는 높은 degree 를 갖는 경향성을 보임.

\hypertarget{respondent-driven-sampling}{%
\paragraph{Respondent-driven Sampling}\label{respondent-driven-sampling}}

\textbf{Respondent-driven} 샘플링은 소셜네트워크 상황에서 snowball 샘플링의 유의한 변주. 이는 낙인되었거나 혹은 불법적이라 그들의 존재를 관계적으로 잘 발견해내기 어려운 \textbf{sub-populations} 을 찾아내기 위한 방법으로서 태초의 목적은 이것이었음. 이건 연구중인 문제에 해당하는 그룹 안의 멤버를 한둘 골라내서 이들을 이니셜 멤버로 한 뒤 걔들한테 주위 사람들 좀 여기 참가시켜보라고 설득하는 거. 때때로는 이 이니셜 멤버들한테 물리적 토큰(표식)을 준 뒤 이 물리적 표식을 여기 참가하라고 꼬실 대상들한테 뿌리라고 하는 식으로 link 를 트랙하기도 함. 이 물리적 토큰 자체가 인센티브일 수도 있고. 이때 응답자 별로 줄 수 있는 (허락되는) 토큰의 총량이 정해져 있다면 이건 곧 degree 의 censoring 으로 기능함.

\hypertarget{trace-route-sampling}{%
\paragraph{Trace-route Sampling}\label{trace-route-sampling}}

\textbf{Trace-route} 샘플링은 네트워크를 통과하는 각 route 들을 추적하여 네트워크를 검색함. 절차는 아래와 같다:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  source node의 set 을 지정
\item
  target node의 set 을 지정
\item
  각각의 source-target의 조합에 대해서, source 에서 target으로 도착하는 path 하나를 찾고, 그후 이 path에서 거친 모든 edge와 node를 기록함.
\end{enumerate}

물론 이 프로세스는 어떤 path 가 탐색되었는가에 크게 의존하긴 하는데 이건 적용 층위의 문제지 메커니즘 자체가 문제가 있다고 할 건 아님. route 추적이 어떻게 이루어졌는지에 따라 연구자는 ``실패'' (source 에서 target 으로 도착 못했음) 한 route 에 대한 정보를 얻을수도 있고 못얻을수도 있음.

\textbf{Trace-route} 샘플링은 체계적으로 degree 분포를 왜곡하며 모든 종류의 그래프들로 하여금 그들이 heavy-tail 인 것처럼 보이게 할 수 있다. 그들이 실제로 heavy-tail 이었든 아니든.

\hypertarget{coping-strategies}{%
\subsection{Coping Strategies}\label{coping-strategies}}

\hypertarget{head-in-sand}{%
\subsubsection{Head in Sand}\label{head-in-sand}}

이인즉 샘플링으로 인한 왜곡이나 bias 를 싹 무시하고 우리가 현재 보고 있는 그래프가 그래프의 참값이라고 가정하는 것. \textbf{당연히 좋은 생각은 아님.} \textbf{incuded} 서브그래프 샘플링의 경우에 mean degree는 real degree 에서 bias 되어 있는데, 이 bias 는 계산 가능함. 실제로 모든 motif에 대해 motif count 의 샘플값도 또한 (얘도 계산 가능한 방법으로) 편향되어 있다. 얘들을 사후적으로 보정하는 건 꽤 쉬운 편. 하지만 다른 놈들은 복잡하게 꼬여있는데, 꼬여있는 놈들 중 일례로 degree 분포의 경우에는 매우 복잡하게 왜곡되어 있어서 사후적으로 보정하기가 드럽게 어렵다. 이건 induced 상황에서도 마찬가지로 복잡해서 사후적 보정이 난해함.

\hypertarget{learn-sampling-theory}{%
\subsubsection{Learn Sampling Theory}\label{learn-sampling-theory}}

\textbf{Classical sampling theory}은 통계적 추론에 대한 이론으로, probability assumption은 오직 샘플링 프로세스에 대해서만 (성립)만들어진다는 것을 그 골자로 한다. population의 참값은 unknown 하나 fixed 되어 이 참값이 어떻게 생산되었는지에 대해서는 어떤 stochastic 가정도 만들어지지 않는다. (이를 unknown population 에 대해 조건부를 건다고 생각해도 틀리지 않다.) 모든 probability assumption 들이 샘플링 디자인에 대해서만 논하며, 추론의 타당성은 오직 디자인이 정확히 모델링되었는지 여부에만 의존하므로, 이는 때때로 \textbf{design-based} 추론이라고도 불린다.

크기가 n 인 어떤 finite population 에 대한 어떤 quantity \(X_i\) 의 평균을 a sample of units \(S\) 를 사용해구하고자 하는 상황이라고 해보자. 간단하고 고전적인 해는 \textbf{Horvitz-Thompson estimator}:

\[
\hat \mu_{HT} \equiv \frac{1}{n} \sum_{i \in S}\frac{X_i}{\pi_i}
\]

\begin{itemize}
\tightlist
\item
  \(\pi_i\)는 unit \(i\)의 (assumed-known) 포함확률, 즉 unit \(i\)가 샘플에 포함될 확률.
\end{itemize}

포함 확률은 \(\pi = \frac{|S|}{n}\)로 모두 동일하다는 것을 notice. 즉 우리는 다시 sample mean \(X\)로 되돌아감. 이에 대한 직관은 곧 우리가 1개의 unit을 보았고 그 unit의 포함확률이 \(\pi_i\)라면, 우리가 보지 못한 \(\frac{1}{\pi_i}\)개의 다른 것들이 있다는 것이 골자이다. 더 이론적으로 들어가자면 우리는 이것이 \textbf{UE}임을 보일 수 있다.

indicator 변수 \(Z_i = I(i \in S), i \in 1:n\)을 도입하자. 이를 사용하여 \(\hat \mu_{HT}\)의 기댓값을 구하면

\$\$
\begin{alignat}{2}

E \left( \hat \mu_{HT} \right)


&= E \left(\frac{1}{n} \sum_{i \in S} \frac{X_i}{\pi_i} \right)

&&= E \left(\frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} Z_i \right)

\\

&= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} E \left( Z_i \right)

&&= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} P \left( Z_i =1 \right)

\\

&= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} \pi_i

&&= \frac{1}{n} \sum_{i \in 1:n} {X_i}

\\

&= \mu

\end{alignat}
\$\$

또한

\[
Var \left ( \hat \mu_{HT} \right )= \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]

이때 \(\pi_{ij}\)는 joint 포함확률. 즉슨 \(i,j\)가 한번에 샘플에 들어있을 확률. (\(\pi_{ii} = \pi_i\)로 취급)

모든 \(\pi_i \rightarrow 1\)로 가게 된다면, \(Var \rightarrow 0\).

이 Var 참값을 정확히 계산하는 건 불가능. 우리는 population 안의 모든 unknown units의 합을 구하는건 불가능하기 때문. 그러가 empirical 대체값은 주어져 있다. 이는

\[
\hat {Var} \left ( \hat \mu_{HT} \right) = \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]

\textbf{sampling-theory approach}는 population quantity의 평균 (혹은 총량) 으로 나타낼 수 있는 대상에게 적합. 혹은 샘플링 디자인에 대한 지식으로부터 포함 (inclusion) 확률을 파악할 수 있는 상황에 대해서도 쓸만하다. 많은 네트워크 stats는 \textbf{평균}으로 표현될 수 있지만 (때때로 ``unit''을 정의하여 해결하기도 함, node 의 dyad 같은 거), inclusion 확률을 정확히 계산해내는 건 평균 구하는 것보다는 더 빡셈.

\hypertarget{missing-data-tools}{%
\subsubsection{Missing Data Tools}\label{missing-data-tools}}

다른 방법은 네트워크에서 unobserved 된 부분을 missing data로 처리하고 이를 추론해버리는 것. 이건 simple imputation 전략부터 시작해서, EM 알고리즘과 같이 추론에 대한 복잡한 모델-based 전략에 이르기까지 다양한 것들이 속한다. EM 혹은 성공적인 imputation은 design-based 가 아니라 model-based 이며, 네트워크와 샘플링 프로세스 양쪽 모두에 대한 모델을 필요로 한다. 실전에서 ``missing at random'' 상황은 진짜 엄청나게 드물며, ``missing completely at random'' 상황조차도 흔하지 않다. let alone

\hypertarget{model-the-effective-network}{%
\subsubsection{Model the Effective Network}\label{model-the-effective-network}}

마지막 전략은 observed 네트워크를 모델링하는 것. 즉 observation / 샘플링 프로세스와 실제 네트워크 양쪽 모두를 모델링하지만, 그 후 이 둘을 합치는 것으로 observed 그래프에 대한 확률 분포의 family 를 얻는 것이 가능함. 그 observed 네트워크는 underlying generative 모델의 패러미터에 대해 여전히 informative. 이게 알고 싶은 전부라면, 여기까지만 진행한 후에 종료해버릴 수 있음. 전부가 아니라면 이것 이후에 EM이나 imputation 써서 full 그래프를 복원하고자 시도하게 될 것이고.

\hypertarget{big-data-solves-nothing}{%
\subsection{Big Data Solves Nothing}\label{big-data-solves-nothing}}

``\(n =\) all'' 로 설정되고 모든 데이터가 자동적으로 기록된 경우에도 우리가 겪어온 모든 네트워크 샘플링 문제는 여전히 남아있음. 이런 상황에서도 우리가 얻은 데이터는 결국 biased convenience 샘플을 갖고 있는 것이지 가지고 있는 모든 자료가 참값이라고 말할 수가 없기 때문임. 네트워크에서는 특히 아래와 같은 3가지 문제가 두드러짐.

Even when, as the promoters say, ``n = all'', and the data are automatically recorded (voluntarily or involuntarily), almost all the network sampling issues we've gone over remain. After all, as the promoters do not say, you're getting all of a biased convenience sample, not all of the truth. Three issues are particularly prominent for network.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Entity Resolution
\item
  Diffusion
\item
  Performativity
\end{enumerate}

\hypertarget{entity-resolution}{%
\subsubsection{Entity resolution}\label{entity-resolution}}

\textbf{Entity resolution}, 혹은 \textbf{record linkage} 라 불리는 것은 데이터 분석에서 메이저한 문제 중 하나. 이는 간단하게 말하면 동일 대상에 대해 서로 다른 시간대에 기록된 자료가 있다면 이 중 무엇을 쓸 것인가 하는 문제. 혹은 겉보기에 같은 대상에 대해 서술하는 것 같은 (co-referent) 기록들이 실제로는 다른 것들에 대해 이야기하고 있는 상황
. 네트워크에서 이는 보통 같은 underlying entity 로 직결되는 2개의 다른 node 들 중에 뭘 고를까 하는 문제가 됨.

\hypertarget{diffusion}{%
\subsubsection{Diffusion}\label{diffusion}}

\textbf{diffusion}은 우리에게 빅데이터를 제공하는 많은 자동적으로 기록된 네트워크들이 다른 오래된 소셜 네트워크로 퍼져나가는 것. provide A with B 예를 들어 페북의 tie는 pre-페북의 소셜 네트워크과 diffusion 프로세스의 결과물이다. 이 결과물을 이해하는데에는 비교적 약간의 노력만이 이루어졌다. diffusion 프로세스가 모든 node 를 균질하게 취겁하더라도, diffusion을 당한 네트워크는 기반 네트워크와 그 특성이 근본적으로 다를 수 있다.

\hypertarget{performativity}{%
\subsubsection{Performativity}\label{performativity}}

이론이 자기실현적 예전이 되어버리는 상황을 Performativity라고 함. 온라인 소셜 네트워크를 운영하는 회사들은 사용자들의 크고 조밀한 네트워크를 만들어낼 수 있도록 엄청나게 투자중. 이것이 그들이 link 제안 혹은 link 추천 서비스를 제공하는 이유임. 왜 당신이 아실지도 모르는 친구 이런거. 이러한 추천의 이면에 있는 알고리즘들은 소셜 네트워크가 어떻게 만들어지는지에 대한 이론과 그들이 어떤 link 패턴을 가져야하는지에 대한 이론 등이 반영되어 있다. 유저들이 이러한 추천 친구와 link 를 수락하는 순간 이 알고리즘 이면에 반영된 이론의 입맛에 맞는 케이스가 강화되는 거.

\hypertarget{mathematical-models-for-network-graphs}{%
\section{Mathematical Models for Network Graphs}\label{mathematical-models-for-network-graphs}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  By a model for a network graph we mean effectively a collection

  \begin{itemize}
  \tightlist
  \item
    \(G\) 는 가능한 그래프들의 collection (혹은 `ensemble')
  \item
    \(P_\theta\)는 \(G\)의 확률분포 (간단하게 쓰면 \(\cdot_\theta\) 생략하고 \(P\)만 씀)
  \item
    \(\theta\)는 \(\Theta\) 내부에서 가능한 값들 안에서 펼쳐져있는 (ranging over) 패러미터들(패러미터값들)의 벡터
  \end{itemize}
\end{enumerate}

\[
\Big \{ 
P_\theta (G), \; G \in \mathcal G \; \; : \; \; \theta \in \Theta
\Big \}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Variety of Purposes
\end{enumerate}

\begin{itemize}
\tightlist
\item
  The testing for `significance' of a pre-defined characteristic(s) in a given network graph
\item
  The study of proposed mechanisms for generating certain commonly observed properties in real-world
  networks (such as broad degree distributions or small-world effects),
\item
  The assessment of potential predictive factors of relational ties.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  The richness of network graph modeling derives largely from how we choose to specify P(·), with methods in the literature ranging from the simple to the complex.
\item
  It is useful for our purposes to distinguish, broadly speaking, between models defined more from (i) a mathematical perspective, versus (ii) a statistical perspective.
  • Those of the former class tend to be simpler in nature and more amendable to mathematical analysis yet, at the same time, do not always necessarily lend themselves well to formal statistical techniques of model fitting and assessment.
  • On the other hand, those of the latter class typically are designed to be fit to data, but their mathematical analysis can be challenging in some cases.
  • Nonetheless, both classes of network graph models have their uses for analyzing network graph data.
\end{enumerate}

\hypertarget{classical-random-graph-models}{%
\subsection{Classical Random Graph Models}\label{classical-random-graph-models}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{random graph model}이라는 용어는 collection \(\mathcal G\)과 \(\mathcal G\)에 대한 uniform probability \(P(\cdot)\)을 묶어 일컬음. 수학적 관점에서 가장 잘 정의된 네트워크 그래프 모델.
\item
  주어진 order와 size를 따르는 그래프에 대한 모든 후보군에 동일 확률 부여. \(|V|=N_v\), \(|E| = N_e\)를 만족하는 모든 그래프 \(G=(V,E)\)의 collection \(\mathcal G_{N_v, N_e}\)을 정의하고, 각각의 \(G \in \mathcal G_{N_v, N_e}\)에 확률 \(P(G) = {N \choose N_e}^{-1}\)을 부여함. 이때 \(N= {N_v \choose 2}\)는 서로 다른 vertex 2개를 묶은 쌍의 총 숫자.
\item
  \(\mathcal G_{N_v, N_e}\)의 변용이 실전에서는 더 자주 보임. 이 공식에서, \(\mathcal G_{N_v, p}\)는 order \(N_v\)의 모든 그래프 \(G\)로 구성되어 있다. 이는 서로 다른 vertex의 쌍에 \(p \in (0,1)\)의 확률로 edge 1개를 독립적으로 부여하는 것으로 얻어질 수 있다. 이러한 종류의 모델은 \textbf{Bernoulli random graph model}라고 불림. \(p\)가 \(N_v\)의 적절하게 정의된 함수이며, \(N_e \sim p N_v^2\)하면, 이 모델들의 두 클래스는 large \(N_v\)와 거의 동치된다.
\item
  The function erdos.renyi.game in igraph can be used to simulate classical random graphs of either type. The choice of Nv = 100 vertices and a probability of p = 0.02 of an edge between any pair of vertices.
\end{enumerate}

\begin{verbatim}
library(sand)
g.er = erdos.renyi.game(100, 0.02)
par(mfrow=c(1,2))
plot(g.er, layout=layout.circle, vertex.label=NA)
hist(degree(g.er), col="lightblue", xlab="Degree", ylab="Frequency", main="")
is.connected(g.er)
table(sapply(decompose.graph(g.er),vcount))
\end{verbatim}

\(\exists c>1:p = \frac{c}{N_v}\)가 성립한다면, classical random graph \(G\)는 giant component를 보유할 확률이 높다.

위와 \(p\)를 동일하게 정의한다면, \(c>0\)에 대해, degree distribution은 large \(N_v\)에 대해 \(POI(c)\)로 잘 모사된다. 이게 사실이라는 건 직관적으로 보이기도 쉽다. 아무 vertex나 하나 뽑았을 때 이의 degree가 \(B(N_v-1, p)\)를 따르기 때문이다. 이는 곧 mean degree는 \(p(N_v-1)\)에 근접한다는 소리.

classical random graph의 다른 성질은 vertex 쌍 사이에서 shortest path 위에는 상대적으로 적은 숫자의 vertex가 존재한다는 것이며 이로 인해 clustering도 low하다는 것이다. path가 길어야 상대적으로 공간이 넉넉해서 여러개의 vertex가 그 위에 안착할 가능성이 높은데 짧으면 그만큼 공간 좁아서 없는게 정상일테니까.

\begin{verbatim}
average.path.length(g.er)
diameter(g.er)
transitivity(g.er)
\end{verbatim}

\hypertarget{generalized-random-graph-models}{%
\subsection{Generalized Random Graph Models}\label{generalized-random-graph-models}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  이하의 성질을 갖고, fixed order \(N_v\)를 따르는 모든 그래프의 collection \(\mathcal G\)를 정의한다. 각 그래프 \(G \in \mathcal G\)에 동일 확률 부여
\item
  가장 자주 부여되는 성질은 fixed degree sequence의 그것. \(\mathcal G\)를 모든 그래프 \(G\)의 collection으로 정의, 이때 이는 미리 정해진 degree sequence를 따름. 이를 ordered form으로 적으면 \(\{d_{(1)}, \cdots, d_{(N_v)} \}\). 이 조건을 따르면서도 다른 모양의 그래프는 얼마든지 그려지며 따라서 isomorphic이 아님.
\end{enumerate}

\begin{verbatim}
degs = c(2, 2, 2, 2, 3, 3, 3, 3)
g1 = degree.sequence.game(degs, method="vl")
g2 = degree.sequence.game(degs, method="vl")
par(mfrow=c(1,2))
plot(g1, vertex.label=NA)
plot(g2, vertex.label=NA)
#해당 케이스에선 N_v=8 vertex, 이중 절반은 degree=2, 나머지 절반은 3.
\end{verbatim}

\begin{verbatim}
graph.isomorphic(g1, g2)
c(ecount(g1), ecount(g2))
\end{verbatim}

고정된 숫자의 vertex \(N_v\)에서 fixed degree sequence를 따르는 랜덤 그래프들의 collection들은 모두 egde 숫자 \(N_e\)로 동일하다. 이는 mean degree of sqeuence \(\{d_{(1)}, \cdots, d_{(N_v)}\}\)는 \(\tilde d = \frac{2N_e}{N_v}\)이니까.

따라서 이 collection은 랜덤 그래프의 collection \(\mathcal G_{N_v , N_e}\) 안에 strictly 들어있음. 따라서 degree sequence의 가정된 형태의 추가는 원본 collection \(\mathcal G_{N_v , N_e}\)에 조건부 분포를 걸어 우리의 모델을 특정짓은 것과 동일함. 다른말로 이는 degree sequence에 의해 제약되지 않은 부분은 얼마든지 vary 가능하다는 것을 의미.

\begin{verbatim}
data(yeast)
degs = degree(yeast)
fake.yeast = degree.sequence.game(degs, method=c("vl"))
all(degree(yeast) == degree(fake.yeast))
diameter(yeast)
diameter(fake.yeast)
transitivity(yeast)
transitivity(fake.yeast)
\end{verbatim}

하지만 이렇게 고삐를 풀어버리면 원본 네트워크의 직경은 시뮬레이션된 물건의 2배에 달하며 사실상 만들어두었던 clustering들도 다 날아가버렸음. 원칙적으로 class \(\mathcal G\)의 정의를 제한하는 편이 훨씬 쉬우며 그렇기에 degree sequence 이외의 다른 추가적인 특성들은 그냥 고정해버림. 이러한 collection으로부터 랜덤 그래프들 \(\mathcal G\)을 생산해내는데에는 MCMC 방법론이 유명하다. 이때 MC에 의해 액세스되는 상태들 그 자체 각각들이 graph \(\mathcal G\)에 해당함.

\hypertarget{network-graph-models-based-on-mechanisms}{%
\subsection{Network Graph Models Based on Mechanisms}\label{network-graph-models-based-on-mechanisms}}

모던 네트워크 그래프 모델링에서 가장 중요한 혁명 중 하나가 전통적인 랜덤 그래프 모델에서 실제 세계의 성질을 모사하는 쪽으로 옮겨갔다는 거임. 이건 그냥 간단한 몇몇 메커니즘 도입하는 것으로 성공되었음.

\hypertarget{small-world-models}{%
\subsubsection{Small-World Models}\label{small-world-models}}

\begin{itemize}
\tightlist
\item
  \textbf{small-world network}
\end{itemize}

대부분의 node가 다른 node들과 이웃이 아닌 케이스. 그러나 다른 node를 작은 횟수 거치면 모든 노드에 액세스 가능한 케이스. 해당하는 케이스 생산하는 방법으로 lattice 구조로 우선 잔 후에 적은 확률 부여해서 무작위로 각 node로 rewiring.

We begin with a set of Nv vertices, arranged in a periodic faction, and join each vertex to r of its neighbors to each side. For each edge, independently and with probability p, one end of that edge will be moved to be incident to another vertex, where that new vertex is chosen uniformly, but with attention to avoid the construction of loops and multi-edges.

추가적인 조치 없이 lattice만 단독으로 있으면 (\(p=0\) 상황에서 생산됨) 이 경우에는 clustering의 양이 상당하게 나오지만, vertex간의 거리는 non-trivial해짐. 이런 lattice에 상대적으로 적은 숫장 edge 대상으로 rewiring을 거치는 것만으로 vertex 사이의 거리를 극적으로 줄일 수 있다. 이때 clustering level은 높게 유지된다는 것이 포인트. 이 효과는 \(p\)가 극적으로 작더라도 여전히 얻어질 수 있다.

\begin{verbatim}
g.ws = watts.strogatz.game(1, 25, 5, 0.05)
plot(g.ws, layout=layout.circle, vertex.label=NA)
g.lat100 = watts.strogatz.game(1, 100, 5, 0)
transitivity(g.lat100)
plot(g.lat100, layout=layout.reingold.tilford, vertex.label=NA)
diameter(g.lat100)
average.path.length(g.lat100)
g.ws100 = watts.strogatz.game(1, 100, 5, 0.05)
diameter(g.ws100)
average.path.length(g.ws100)
transitivity(g.ws100)
\end{verbatim}

\begin{verbatim}
steps = seq(-4, -0.5, 0.1)
len = length(steps)
cl = numeric(len)
apl = numeric(len)
ntrials = 100
for(i in 1:len){
cltemp = numeric(ntrials)
apltemp = numeric(ntrials)
for(j in 1:ntrials){
g = watts.strogatz.game(1, 1000, 10, 10ˆsteps[i])
cltemp[j] = transitivity(g)
apltemp[j] = average.path.length(g)
}
cl[i] = mean(cltemp)
apl[i] = mean(apltemp)
\end{verbatim}

이 결과는 (normalized 평균적인 path의 길이들과 clustering coefficient들의) 개략적인 기댓값을 p 대비로 plot한 것으로, p가 엄청나게 극단적인 값으로 가지 않은 이상 네트워크가 계속 높은 수준의 clustering을 유지하면서 작은 평균 거리를 보이는 것이 확인된다.

\begin{verbatim}
plot(steps, cl/max(cl), ylim=c(0,1), lwd=3, type="l", col="blue",
xlab=expression(log[10](p)), ylab="Clustering and Average Path Length")
lines(steps, apl/max(apl), lwd=3, col="red")
\end{verbatim}

\hypertarget{preferential-attachment-models}{%
\subsubsection{Preferential Attachment Models}\label{preferential-attachment-models}}

대부분의 네트워크는 시간에 따라 변화함. 주어진 시간 \(t\)에 네트워크가 어떻게 변화하는지는 vertex preferences, fitness, age 등에 따라서든 다양. \textbf{Preferential attachment}는 많은 노드와 연결된 대형 노드가 추가적인 link를 확보할 가능성이 높다는 것. SNS에서의 셀럽 생각하면 됨.

undirected 네트워크의 \textbf{Barabasi-Albert (BA) model} 은 다음과 같음.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  시작 vertex \(N_v^{(0)}\), 시작 edge \(N_e^{(0)}\) 가지는 시작 그래프 \(G^{(0)}\)로 시작.
\item
  각 시간 \(t = 1, 2, \cdots\)에서 \(G^{(t-1)}\) 기반으로 \(G^{(t)}\) 생산. 추가적인 vertex 를 넣되 이 추가되는 vertex들의 degree는 \(m \ge 1\)이고, \(m\)개의 새로운 edge들이 \(m\)개의 서로 다른 vertex에 들러붙음. 이때 새로운 vertex가 기존의 vertex에 들러붙을 확률은 \(\frac{d_v}{\sum_{v' \in V}d_{v'}}\) 을 따름. 즉 기존 그래프에서 높은 degree를 가지고 있던 vertex가 새 vertex와도 들러붙을 확률 높음.
\item
  t번의 이터레이션 후에 결과값 그래프 \(G(t)\)는 \(N_v^{(t)} = N_v^{(0)} + t\) 개의 vertex와 \(N_e^{(t)} = N_e^{(0)} + tm\) 개의 edge 를 가진다.
\end{enumerate}

이런 preferential attachment 경향성 때문에 이터레이션이 쌓일수록 높은 degree를 보유하는 vertex가 많아질 것을 기대할 수 있다.

\begin{verbatim}
g.ba = barabasi.game(100, directed=FALSE)
par(mfrow=c(1,2))
plot(g.ba, layout=layout.circle, vertex.label=NA)
hist(degree(g.ba), col="lightblue", xlab="Degree", ylab="Frequency", main="")
\end{verbatim}

고전적인 랜덤 그래프 대비 vertex 쌍 사이의 edge가 uniform 분포를 따르지 않음을 유의. 이런 경향에 의해 edge를 다수 끌어모으고 있는 ``hub''라 불릴만한 vertex가 있는 것으로 사료됨. 여기서 전체 분포는 꽤 heterogeneous한 감이 있는데, 대부분의 vertex는 degree가 2를 넘지도 못함.

\begin{verbatim}
summary(degree(g.ba))
\end{verbatim}

이러한 \textbf{preferential attachment} 모델에서 특필될만한 특징은 \(t \rightarrow \infty\) 따라서 그래프 \(G^{(t)}\)의 degree distribution이 \(d^{-\alpha}\), \(\alpha = 3\)의 형을 갖는 경향을 보인다는 것이다. 이러한 경향은 고전적인 랜덤 그래프와 큰 차이점임.

반면에 BA 모델에 의해 생성된 네트워크 그래프는 vertex 쌍 사이의 shotest path 위에 위치하는 vertex 숫자가 점점 적어지며 또한 low clustering이라는 고전적인 랜덤 그래프의 특징을 어느정도 공유한다. 뭔소리야 BA가 preferential attachment 모델을 생산하려고 고안된게 아냐? BA가 preferential attachment 모사하려고 고안되긴 했는데 preferential attachment의 특성을 모두 복사하진 못했고 BA의 한계상 asymptotic 상황에서 고전적 랜덤 그래프 성질을 가져버렸다는건가?

\begin{verbatim}
average.path.length(g.ba)
diameter(g.ba)
transitivity(g.ba)
\end{verbatim}

\hypertarget{assessing-significance-of-network-graph-characteristics}{%
\subsection{Assessing Significance of Network Graph Characteristics}\label{assessing-significance-of-network-graph-characteristics}}

위에서 설명한 네트워크 모델들은 관측된 네트워크들로 통계적 모델링하긴 너무너무 간단함. 간단해서 현실모사를 제대로 못해서 쓸모가 없음. 그래도 중요하긴 함. 통계적 가설 검정 측면에서는 말이지. 특히 네트워크 그래프 성질의 significance를 측정(test)하는데 있어 자주 쓰임.

우리가 observations으로부터 얻은 그래프 \(G^{obs}\)를 가지고 있다고 가정하자. 우리는 이때 임의의 structural 특성인 \(\eta(\cdot)\)에 관심있음. 이 경우 \(\eta(G^{obs})\)가 unusual 이든 unexpected 이든 significant 한지를 체크하는 것은 중요함. 지금까지 위에서 언급해온 네트워크 모델들에 대한 이론은 바로 이 경우에 기준으로서 동작한다는 점에서 중요. 이인즉 우리가 가지고 있는 그래프들의 collection \(\mathcal G\) 에 대해 \(\eta(G^{obs})\)를 각 그래프들을 넣어본 값들의 collection \(\{ \eta(G): G \in \mathcal(G)\}\) 과 비교해본다는 것이다. 이때 해당 collection에 들어있는 값들 대비 \(\eta(G^{obs})\)가 극단적이라고 판정되면 \(\eta(G^{obs})\)가 보유한 값이 unusual하다는 것을 판정내릴 수 있는 재료가 됨.

랜덤 그래프 모델을 사용할 경우 척도가 될 수 있는 distribution을 개발하고자 하는 움직임은 지극히 정상적임. 이는 \(\mathcal G\) 안에 있는 각 그래프들 \(G\) 각각에 uniform 확률을 부여해서 만들어보는 게 합리적. 이는 곧

\[
P_{\eta, \mathcal G} (t) = \frac{\text{#}\{ g \in \mathcal G \; : \; \eta(G) \le t \}}{| \mathcal G |}
\]

만약 \(\eta(G^{obs})\)가 이 분포를 따르지 않을 것 같은 확률이 높다면 \(G^{obs}\)는 \(\mathcal G\)로부터의 uniform draw가 아니라는 쪽에 힘이 실림. 이는 랜덤 그래프를 예쁘게 따르는 자주 발생하지 않는 상황 대비 실제 상황으로부터 서브그래프를 뽑아내게 되는 자주 마주치는 상황에 활용가능하다는 점에서 실용적.

\hypertarget{assessing-the-number-of-communities-in-a-network}{%
\subsubsection{Assessing the Number of Communities in a Network}\label{assessing-the-number-of-communities-in-a-network}}

위에서 karate 데이터에 hierarchical clustering 사용했더니 clustering 3개 발견했음. 이 karate 데이터에 비추어볼 그래프로 2개의 \(G\)를 생각하자.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  karate 네트워크와 동일하게 same order \(N_v = 34\), size \(N_e = 78\)
\item
  1번에 더해서 원본과 동일한 degree distribution 따름
\end{enumerate}

MCMC 써서 생산. 뭐 deterministic 관점이었던 물건에 시뮬레이션을 통한 랜덤 관점으로 접근하는 거라는 이야기? 단점이란 소리인가?

\begin{verbatim}
data(karate)
nv = vcount(karate)
ne = ecount(karate)
degs = degree(karate)
ntrials = 1000
\end{verbatim}

• We then generate classical random graphs of this same order and size and, for each one, we use the
same community detection algorithm to determine the number of communities.

\begin{verbatim}
num.comm.rg = numeric(ntrials)
for(i in 1:ntrials){
g.rg = erdos.renyi.game(nv, ne, type="gnm")
c.rg = fastgreedy.community(g.rg)
num.comm.rg[i] = length(c.rg)
}
\end{verbatim}

• Similarly, we do the same using generalized random graphs constrained to have the required degree
sequence.

\begin{verbatim}
num.comm.grg = numeric(ntrials)
for(i in 1:ntrials){
g.grg = degree.sequence.game(degs, method="vl")
c.grg = fastgreedy.community(g.grg)
num.comm.grg[i] = length(c.grg)
}
\end{verbatim}

• The results may be summarized and compared using side by side bar plots.

\begin{verbatim}
rslts = c(num.comm.rg,num.comm.grg)
indx = c(rep(0, ntrials), rep(1, ntrials))
counts = table(indx, rslts)/ntrials
barplot(counts, beside=TRUE, col=c("blue", "red"),
xlab="Number of Communities", ylab="Relative Frequency",
legend=c("Fixed Size", "Fixed Degree Sequence"))
\end{verbatim}

• Clearly the actual number of communities detected in the original karate network (i.e., three) would
be considered unusual from the perspective of random graphs of both fixed size and fixed degree
sequence.
• Accordingly, we may conclude that there is likely an additional mechanism(s) at work in the actual
karate club, one that goes beyond simply the density and the distribution of social interactions in
this network.

\hypertarget{assessing-small-world-properties}{%
\subsubsection{Assessing Small World Properties}\label{assessing-small-world-properties}}

small-world 여부를 확인하는 일반적인 방법론은 대상 네트워크의 clustering coefficient와 average (shortest) path 길이를 보정된 고전적 랜덤 그래프에서 확인할 수 있는 그것들과 비교하는 것이다. 고전적 랜덤 그래프의 그것과 비교했을 때, 만약 대상 네트워크가 small-world라면, clsutering coefficient는 고전적 랜덤 그래프보다 크되, average path 길이는 대충 비슷할 것으로 예상함.

\begin{verbatim}
library(igraphdata)
data(macaque)
summary(macaque)
\end{verbatim}

해당 네트워크에서 clustering을 평가하기 위해 directed 네트워크에 해당하는 clustering coefficient 의 변형 사용. 이 변량은 모든 vertex \(v\)에 대해 vertex 각각의 clsutering coefficient를 평균낸 것이 된다.

\begin{itemize}
\tightlist
\item
  A는 adjacency Matrix
\item
  \(d_v^{tot}\)는 vertex \(v\)의 총 degree (i.e., in-degree plus out-degree)
\end{itemize}

\[
cl(v) = \frac{\left( A+ A' \right)^3_{vv}}{ 2 \left [ d_v^{tot}(d_v^{tot} - 1) - 2 (A^2)_{vv} \right]}
\]

\begin{verbatim}
clust.coef.dir <- function(graph){
A = as.matrix(get.adjacency(graph))
S = A + t(A)
deg = degree(graph, mode=c("total"))
num = diag(S %*% S %*% S)
denom = diag(A %*% A)
denom = 2 * (deg * (deg - 1) - 2 * denom)
cl = mean(num / denom)
return(cl)
}
\end{verbatim}

비교하려면 고전적 랜덤 그래프를 생산하고 이의 각각의 clustering과 평균 path length를 계산하는 과정 필요.

\begin{verbatim}
ntrials = 1000
nv = vcount(macaque)
ne = ecount(macaque)
cl.rg = numeric(ntrials)
apl.rg = numeric(ntrials)
for(i in 1:ntrials){
g.rg = erdos.renyi.game(nv, ne, type="gnm", directed=TRUE)
cl.rg[i] = clust.coef.dir(g.rg)
apl.rg[i] = average.path.length(g.rg)
}
\end{verbatim}

\begin{verbatim}
summary(cl.rg)
summary(apl.rg)
clust.coef.dir(macaque)
average.path.length(macaque)
\end{verbatim}

위 예시에서 랜덤 네트워크에서 계산된 것 대비 clustering 숫자가 엄청 크지만, 동시에 vertex 쌍 사이의 shortest path들의 평균적인 길이 또한 눈에 띄게 길다. 따라서 small-world 여부는 명확하지 않으며, 이 결과는 분석 대상 네트워크가 고전적 랜덤 그래프보다도 훨씬 lattice에 가깝다는 것을 보여준다.

\hypertarget{introduction-to-ergm}{%
\section{Introduction to ERGM}\label{introduction-to-ergm}}

\hypertarget{exponential-random-graph-models}{%
\subsection{Exponential Random Graph Models}\label{exponential-random-graph-models}}

\hypertarget{what-is-a-network}{%
\subsubsection{What Is a Network?}\label{what-is-a-network}}

:= ``relational data'' 를 수학적 그래프로 나타낸 것. node의 set과 edge set의 복합이며, edge는 일부 node를 이음.

Adjacencey Matrix \(X_{ij} = 1\), if node \(i,j\) are connected. \(0\) o.w.

\hypertarget{exponential-random-graph-model-ergms}{%
\subsubsection{Exponential Random Graph Model (ERGMs)}\label{exponential-random-graph-model-ergms}}

\[
P_\theta (X=x) = \frac{1}{\kappa(\theta)} \exp \Big( \theta' g(x) \Big)
\]

\begin{itemize}
\tightlist
\item
  \(X\): A random network written as an adjacency Matrix

  \begin{itemize}
  \tightlist
  \item
    \(X_{ij}\) is an indicator of an edge from node i to node j.
  \end{itemize}
\item
  \(g(x)\): A vector of network statistics of interest.
\item
  \(\theta\): The vector of parameters measuring the \textbf{strengths of the effects} of the corresponding entries in the vector \(g(x)\).

  \begin{itemize}
  \tightlist
  \item
    \(\theta >0\): There exists a tendency to form \(g(x)\) when changing \(X_{ij}\) value from 0 to 1.
  \item
    \(\theta >0\): There exists a tendency \textbf{not} to form \(g(x)\) when changing \(X_{ij}\) value from 0 to 1.
  \end{itemize}
\item
  \(\kappa (θ)\): A normalizing constant
\end{itemize}

네트워크의 전체 구조를 형성하는 로컬적인 selection force를 간략하게 설명함. 네트워크 데이터셋은 리그레션에서의 response 같은 것으로 간주될 수 있으며, 이때 predictor들은 ``파트너십에서 개인들이 삼각형을 형성하는 성향'' 과 같은 것임. \textbf{즉, ERGM은 local transtivity의 정도, 위력을 량화하는데 도움을 줌.} EGRM을 사용해 획득하는 정보는 특정 현상을 이해하거나 특정 네트워크로부터의 랜덤한 실현값을 시뮬레이션하는데에 쓰일 수 있음. 이때 랜덤한 실현값은 당연히 원본의 성질을 유지해야 하고.

\hypertarget{network-statistics}{%
\subsubsection{Network Statistics}\label{network-statistics}}

Basic Markov Network Statistics

\hypertarget{degree-and-shared-partnership-distribution}{%
\paragraph{Degree and Shared Partnership Distribution}\label{degree-and-shared-partnership-distribution}}

\begin{itemize}
\tightlist
\item
  \textbf{Degree}: The number of edges the node has to other nodes.

  \begin{itemize}
  \tightlist
  \item
    \(D_k (x)\): The number of nodes with degree \(k\). 이때 \(\sum D_k(x) = n\).
  \end{itemize}
\item
  Shared Partnership Distribution:

  \begin{itemize}
  \tightlist
  \item
    The number of unordered pairs \((i, j)\) for which \(i\) and \(j\) have exactly share \(k\) common neighbors and

    \begin{itemize}
    \tightlist
    \item
      \(EP_k (x)\): \(X_{ij} = 1\)
    \item
      \(NP_k (x)\): \(X_{ij} = 0\)
    \item
      \(DP_k (x)\): regardless of value \(X_{ij}\)
    \end{itemize}
  \item
    \(\sum EP_k(x) = S_1(x)\) (edge counts) and \(\sum DP_k (x) = {n \choose x}\) (dyad counts).
  \end{itemize}
\end{itemize}

\textbf{geometrically weighted statistics} for degree and shared partnership distribution 는 이하와 같이 정의된다. 여기에 추가된 패러미터 \(\tau\)는 higher order terms 때 부과되는 weight의 decreasing rate를 나타냄.

\$\$
\begin{alignat}{2}

u(x | \tau) 
&= e^\tau \sum_{i=1}^{n-2} \left \{ 1- \left ( 1-\frac{1}{e^\tau} \right)^i \right \} 
&&\cdot D_i(x)

\\

v(x | \tau) 
&= \ditto
&&\cdot EP_i(x)

\\

w(x | \tau) 
&= \ditto
&&\cdot DP_i(x)

\end{alignat}
\$\$

\hypertarget{difficulty-in-parameter-estimation}{%
\subsection{Difficulty in Parameter Estimation}\label{difficulty-in-parameter-estimation}}

\hypertarget{intractable-normalizing-constants}{%
\subsubsection{Intractable Normalizing Constants}\label{intractable-normalizing-constants}}

\(\kappa (\theta) =\sum_{\text{all possible }x} \exp \Big \{ \theta' g(\mathbf x) \Big \}\) 는 ERGMs의 normalizing constant.

undirected 인 경우에조차도 \(2^{n \choose x}\) 개의 네트워크가 존재하므로, \(\kappa(\theta)\) 를 직접 계산하는건 불가능함. 이렇게 직접 계산하는게 불가능하기 때문에 MCMC 가 시뮬레이션과 통계적 추론 양쪽에 있어서 핵심이 된다. 하지만 일반적은 MH 알고리즘에 있어서는 acceptance probability에 알려지지 않은 constant ratio 인 \(\frac{\kappa(\theta)}{\kappa(\theta')}\) 가 끼어있으므로 이를 직접적으로 계산하는 것 또한 실패하게 됨. 이때 \(\theta '\) denotes the proposed value.

\hypertarget{model-degeneracy}{%
\subsubsection{Model Degeneracy}\label{model-degeneracy}}

\(\theta\)를 어떻게 설정하느냐에 따라서 ERGM은 full (모든 연결이 존재하는, \(J\)) 혹은 empty (연결이 없는, \(\mathbf 0\)) 네트워크를 거의 1에 가까운 확률로 생산하기도 한다.

Example: \textbf{Basic Markovian Statistics}. 네트워크에서 하나의 edge가 추가되거나 제거될때, 다른 통계량들이 비교적 크게 변하지 않을 때 basic Markovian 통계량만 엄청나게 요동치는 상황 발생할 수 있음. 따라서 dyadic dependence effects만 빠르게 뻥튀기되어서 모델이 degenerate 될 수 있음.

현재 사용되는 방법인 \textbf{MCMLE} and \textbf{stochastic approximation} 는 시작값이 degeneracy 영역에 있었다면 \(\theta\)의 degenerate 추정값을 생산하기도 한다. 이러한 문제점을 일컫는 용어가 \textbf{Local convergence property}.

\hypertarget{parameter-estimation-of-ergm}{%
\section{Parameter Estimation of ERGM}\label{parameter-estimation-of-ergm}}

Current Methods for ERGM

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Approximation-based Algorithm: Maximize the likelihood function with MCMC samples.

  \begin{itemize}
  \tightlist
  \item
    Maximum Pseudo-likelihood Estimation (MPLE).
  \item
    Markov Chain Monte Carlo Maximum Likelihood Estimation (MCMCMLE).
  \item
    Markov Chain Monte Carlo Stochastic Approximation (MCMCSA).
  \item
    Varying Truncation Stochastic Approximation MCMC Method with Trajectory Averaging (VTSAMCMC).
  \end{itemize}
\item
  Auxiliary Variable Markov Chain Monte Carlo (MCMC) Algorithm: Introduce auxiliary variables to cancel the normalizing constant ratio \(\frac{\kappa(\theta)} {\kappa(\theta')}\) or to approximate the normalizing constant. Used for the Bayesian Inference.

  \begin{itemize}
  \tightlist
  \item
    The Exchange Algorithm.
  \item
    Auxiliary Variable Metropolis-Hasting Algorithm (AVMH).
  \item
    Adaptive Exchange Monte Carlo Algorithm (AEXMC).
  \end{itemize}
\end{enumerate}

\hypertarget{approximation-based-algorithm}{%
\subsection{Approximation-based Algorithm}\label{approximation-based-algorithm}}

\hypertarget{maximum-pseudo-likelihood-estimation}{%
\subsubsection{Maximum Pseudo Likelihood Estimation}\label{maximum-pseudo-likelihood-estimation}}

\(A\) 내부의 성분 간의 의존성을 무시한 채로 조건부 likelihood 함수들의 series를 곱하는 것으로 likelihood 함수를 근사함. ERGMS 의 조건부이며 pseudo Likelihood 는 아래와 같음. 물론 이건 어디까지나 가장 간단한 방법으로서 제시되었을 뿐이고, 이 방법론은 의존성 구조를 완전히 무시했기 때문에 퍼포먼스가 구림.

\$\$
\begin{align}
logit \left \{ P_\theta \Big (X_{ij} = 1 \Big | X_{ij}^c = x_{ij}^c \right \} &= \theta ' g(x_{ij}^c)

\\

\log PL(\theta, x) &= \sum_{ij} \theta ' g(x_{ij}^c) \cdot x_{ij} - \sum_{ij}\log \left \{ 1+ \theta ' g(x_{ij}^c) \right \}

\end{align}
\$\$

\hypertarget{mcmcmle}{%
\subsubsection{MCMCMLE}\label{mcmcmle}}

Approximate \(\kappa(θ)\) using Monte Carlo samples generated from a
distribution

f(x\textbar θ
(0)
), where θ
(0)
is an initial estimate of θ.
Draw x1, · · · , xm denote random samples drawn from f(xobs\textbar θ
(0)
) via
MCMC simulations, the log-ratio of likelihood can be approximated by

\[
I(\theta) - I(\theta^{(0)}) = \left (\theta - \theta^{(0)} \right) ' g(x_{obs}) - \log \left [ \frac{1}{m} \sum_{i=1}^m \exp \left \{ \left (\theta - \theta^{(0)}\right )' g(x_i) \right \} \right ]
\]

) via θ will approximate θˆ (MLE).
The performance of MCMLE depends on the choice of θ
(0)
. If θ
(0)
does
not lie in the attraction region of true MLE, the method may converge to
a suboptimal solution or fail to converge.

\hypertarget{mcmc-stochastic-approximation}{%
\subsubsection{MCMC Stochastic Approximation}\label{mcmc-stochastic-approximation}}

exponential family 에 대한 이론을 통해, 우리는 ERGMs을 maximize 하는 것은 \(E_{\hat \theta} \Big \{ g(X) \Big \} = g(x_{obs})\) 라는 system 을 푸는 것과 동일하다는 것을 알 수 있다. 이 system 의 성립 여부는 이하와 iff (\(\iff\)).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\hat \theta = \hat \theta_{MLE}\)
\item
  Independent network generation
\item
  Parameter estimation update with stochastic approximation
\end{enumerate}

이 방법론은 independent 네트워크 샘플을 생산하는데에는 비효율적이다. 각 샘플 \(x_{k+1}\)을 생산하기 위해 요구되는 이터레이션 스텝의 갯수는 order of \(100 n^2\). 이때 \(n\)은 node 의 갯수.

\hypertarget{auxiliary-variable-mcmc-based-approaches}{%
\subsection{Auxiliary Variable MCMC-based Approaches}\label{auxiliary-variable-mcmc-based-approaches}}

\hypertarget{exchange-algorithm-2}{%
\subsubsection{Exchange Algorithm}\label{exchange-algorithm-2}}

normalizing constant ratio \(\frac{\kappa(\theta)}{\kappa(\theta')}\) 따위의 auxiliary 변수로 분포 \(f(x | \theta)\) 를 augment. 이는 시뮬레이션 중에 canceled.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  후보 point \(\theta ' \sim q(\theta ' | \theta, x)\) 를 생산
\item
  perfect sampler 사용해서 auxiliary 변수 \(y \sim f(y | \theta ')\) 를 생산
\item
  \(\theta'\)를 with probability \(1 \wedge r(\theta, \theta ' \Big | x)\)로 채택. 이때
\end{enumerate}

\$\$
r(\theta, \theta ' \Big \textbar{} x) =

\frac{\pi(theta')}{\pi(theta)}
\cdot
\frac{f(x \Big | \theta ' )}{f(x \Big | \theta )}
\cdot
\frac{f(y \Big \theta)}{f(y \Big \theta')}
\cdot
\frac{q(\theta \Big | \theta ' , x)}{q(\theta ' \Big | \theta , x)}

\$\$

exchange 알고리즘은 \textbf{Ising} 이나 \textbf{autologistic} 과 같은 일부 discrete 모델에는 잘 작동. 하지만 \textbf{perfect sampling} 이 적용되지 않는 많은 다른 모델에는 적용할 수 없다. 우리는 MCMC 샘플을 통해 auxiliary 변수 \(y\)를 생산할 수 있지만, 수렴 문제 부분에서 이론적인 흠결이 있음. 만약 MCMC 샘플의 mixing이 매우 느리다면 딴놈이 아니라 \(\theta_0\) 가 매우 높은 확률로 채택되어버림. 그리고 이 MCMC 샘플의 mixing 이 느린 것 자체가 ERGMs 의 일반적인 특징임. 이래서 문제.

\hypertarget{monte-carlo-mh-algorithm}{%
\subsubsection{Monte Carlo MH Algorithm}\label{monte-carlo-mh-algorithm}}

MH 알고리즘의 MC 버전. 각 이터레이션에서 \textbf{MCMH 알고리즘}은 unknown normalizing constant ratio \(\frac{\kappa(\theta)}{\kappa(\theta')}\) 를 MC estimate와 importance 샘플링 접근법으로 대체한다.

exchange 알고리즘과 다르게, MCMH 알고리즘은 perfect sampler 요구조건을 빗겨간다. 따라서 perfect sampler 를 못 쓰는 다수의 통계문제에 대해서도 얘를 쓸 수 있음. 하지만 얘도 여전히 수렴 문제가 존재함. 얘의 경우에는 importance sampling estimator 가 유한한 숫자의 샘플로는 ratio의 참값 \(\frac{\kappa(\theta)}{\kappa(\theta')}\) 에 수렴하지 못할 수도 있음.

\begin{figure}

{\centering \includegraphics[width=26.08in]{pics/network/06/01} 

}

\caption{Goodness-of-fit Plots, for ERGMs - for the high school student friendship network}\label{fig:ERGMs}
\end{figure}

\hypertarget{varying-trunction-stochastic-approximation-mcmc}{%
\subsection{Varying Trunction Stochastic Approximation MCMC}\label{varying-trunction-stochastic-approximation-mcmc}}

ERGM 의 likelihood 함수는

\[
\begin{align}
&f(y | \theta ) = \frac{1}{\kappa(\theta )} \exp \Big \{ \theta' S(y)\Big \},
&&\theta = (\theta_1 , \cdots, \theta_d)'$, 
&&$S(y) = \Big( S_1 (y), \cdots, S_d(y) \Big)'
\end{align}
\]

이때 \textbf{\(\kappa(θ)\)를 특정할 수 없다} (intractability)는 점과 \textbf{모델 degeneracy} 때문에, \(\theta\)를 정확하게 추정하는 것은 어렵다. 이 문제는 \textbf{varying truncation stochastic approximation MCMC} 를 사용하는 것으로 해결 가능.

Normalizing constant \(\kappa(\theta) = \sum_{\text{all possible }y} \exp \Big \{ \theta ' S(y)\Big\}\).

이로 인해 촉발되는 문제는?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  MPLE: dyadic 독립을 가정하는 것으로 해결해보고자 함. 이건 observed 네트워크가 무엇이냐에 대해 과하게 의존.
\item
  MCMLE: \(\theta^{(0)}\) 을 어떻게 고르느냐에 대해 과하게 의존. local 최적해로 수렴해버리거나 모델 degeneracy 로 수렴 자체가 실패하기도.
\end{enumerate}

\hypertarget{mcmc-stochastic-approximation-1}{%
\subsubsection{MCMC Stochastic Approximation}\label{mcmc-stochastic-approximation-1}}

\(h(\theta) = 0\) 형의 system 을 풀자. 고전적인 \textbf{SA 알고리즘}은 이하와 같은 형태를 띈다. (\(a_k\) , \(h\), \(\omgea_k\) 에 대한) 적절한 조건 하에서, 이 알고리즘은 해로 수렴한다는 것을 실제로 보이는 것이 가능하다.

\$\$
\begin{align}
\theta_{k+1} 
&= \theta_k + a_k Y_k 

\\

&=\theta_k + a_k \Big \{ h(\theta_k) + \omega_k \Big \}, && k \ge 0 
\end{align}
\$\$

\begin{itemize}
\tightlist
\item
  \(Y = h(\theta) + \omega\) 는 noisy estimate
\item
  \(\omega\) 는 mean-zero noise.
\end{itemize}

\(\theta_{MLE}\) 를 찾는 것은 exponential family 안에서 \(E_\theta \{ S(Y) \} = S(\mathbf y_{obs})\) 의 해를 찾는 것과 equivalent. 이는 이하의 단계를 거친다. 다만 이는 independent 네트워크 샘플을 생산하는데 있어 비효율적일 수밖에 없음. order of \(100n^2\) 이라 연산을 엄청 먹으니까.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\mathbf y^{k+1} \sim f(\mathbf y | \theta^{(k)}\)를 샘플링 (independence 네트워크 생산)
\end{enumerate}

각 arc 변수 \(Y_{ij}\)가 독립적으로 정해지는 랜덤 그래프에서 시작. 이 변수에는 0 혹은 1이 0.5 확률로 할당. 이 랜덤 그래프를 Gibbs 샘플러든 MH 알고리즘이든 써서 업데이트.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{SA} 를 통해 패러미터 estimate 업데이트.
\end{enumerate}

\$\$
\begin{align}
\theta^{(k+1)} &= \theta^{(k)} - a_k D^{-1} \Big \{ U( \mathbf y_{k+1}, \bar {\mathbf y}_{k+1} ) - \mathbf S (\mathbf y_{obs} ) \Big \},
\\
\\
\\
U( \mathbf y_{k+1}, \bar {\mathbf y}_{k+1} ) - \mathbf S (\mathbf y_{obs} ) \Big 
\} &= P(\bar {\mathbf y}_{k+1} \Big | \mathbf y_{k+1} ) \cdot \mathbf S (\mathbf {\bar y}_{k+1} ) 

\Big \{ 1-P(\mathbf {\bar y}_{k+1} \Big | \mathbf y_{k+1} ) \Big \} \cdot \mathbf S (\mathbf {\bar y}_{k+1} ) 

\\

\mathbf {\bar y}_{k+1} &= 1- \mathbf y_{k+1} 

\end{align}
\$\$

\hypertarget{model-degeneracy-1}{%
\paragraph{Model Degeneracy}\label{model-degeneracy-1}}

\(\theta\)을 어떻게 정하느냐에 따라 모델은 그것의 확률을 (Complete (fully connected) 거나 empty (entirely unconnected) 네트워크와 같은) 1개 혹은 소수의 그래프에만 한정시켜서 부어버릴 수도 있다. (탐색 효율 쓰레기됨) 이 문제를 해결하기 위해선 탐색 전에 degeneracy 리전을 거의 포함하지 않는 패러미터 스페이스를 가지는 모델로 특정할 필요가 있다. 근데 이게 진짜 드럽게 어려움.

\hypertarget{varying-truncation-samcmc-for-ergms}{%
\subsubsection{Varying Truncation SAMCMC for ERGMs}\label{varying-truncation-samcmc-for-ergms}}

\hypertarget{setup}{%
\paragraph{Setup}\label{setup}}

\$\$
\begin{align}

&a_k = C_a \left( \frac{k_0}{(k_0 \vee k)}\right)^\eta, &&b_k = C_b \left( \frac{k_0}{(k_0 \vee k)}\right)^\xi \tag{C_1, set}

\end{align}
\$\$

\[
\bigcup_{s \ge 0} \mathcal K_s = \Theta, \; \; \; \text{where } \mathcal K_s \subset \text{int}(\mathcal K_{s+1}) \tag{C_2}
\]

\begin{itemize}
\tightlist
\item
  for some constants \(k_0>1\), \(\eta \in (\frac{1}{2},1)\), \(\xi \in (\frac{1}{2},\eta)\), \(C_a > 0\), \(C_b >0\).
\end{itemize}

And also,

\begin{itemize}
\item
  \(\mathcal X\): a space of social network
\item
  \(\mathcal T\): \(\mathcal X \times \Theta \rightarrow \mathcal X_0 \times \mathcal K_0\) (reinitialization mechanism)
\item
  \(\sigma_k\): the number of reinitialization performed until iteration \(k\). (\(\sigma_0 = 0\))
\end{itemize}

\hypertarget{varying-truncation-samcmc-algorithm-for-ergms}{%
\paragraph{Varying truncation SAMCMC algorithm for ERGMs}\label{varying-truncation-samcmc-algorithm-for-ergms}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Gibbs 샘플러 사용해 \(m\) sweeps 번 interate 해서 auxiliary network \(y_{k+1} \sim f(y | \theta^{(k)}\) 생산
\item
  Set \(\theta^{(k + \frac{1}{2})} = \theta^{(k)} + a_k \Big \{ S(y_{k+1}) - S(y_{obs}) \Big \}\)
\item
  Set
\end{enumerate}

\$\$

\begin{cases}

\sigma_{k+1} = \sigma_k \; \text{ and } \left( y_{k+1}, \theta^{(k + {1})} \right) =  \left( y_{k+1}, \theta^{(k + \frac{1}{2})} \right)
\; \; \; \; \; \; \; \; \; \; 

& 
\| \theta^{(k + \frac{1}{2})} - \theta^{(k)} \| \le b_k, \; \; \theta^{(k + \frac{1}{2})} \in \mathcal K_{\sigma_k}
\\
\sigma_{k+1} = \sigma_k+1 \; \text{ and } \left( y_{k+1}, \theta^{(k + {1})} \right) =  \mathcal T \left( y_{k}, \theta^{(k)} \right)
&
o.w.
\end{cases}

\$\$

\hypertarget{trajectory-averaging-estimator}{%
\paragraph{Trajectory averaging estimator}\label{trajectory-averaging-estimator}}

trajectory averaging estimator \(\bar \theta_n = \frac{1}{n}\sum_{k=1}^n \theta^{(k)}\) 에 의해 \(\theta\) 를 estimate 가능.

실전에서는 estimate 의 variation 을 줄이기 위해 대신 \(\theta\) estimate 에 \(\bar \theta (n_0 , n) = \frac{1}{n-n_0}\sum_{k=n_0+1}^n \theta^{(k)}\) 을 자주 사용함. 이 때 \(n_0\) 는 burn-in 이터레이션의 숫자.

\begin{itemize}
\tightlist
\item
  Free parameters: \(\{a_k\}\), \(\{b_k\}\), \(\{\mathcal K_s, \; s \le 0\}\), \(m\)
\item
  \(k_0 = 100\), \(\eta = 0.65\), \(\xi = \frac{0.5 + \eta}{2}\).
\item
  \(C_a\), \(C_b\): adjusted for different examples
\item
  choose \(\mathcal K_0\) to be around MPLE.
\item
  In this artical, we set \(\mathcal K_{s, 1} = \Big [ -4(s+1), 4(s+1) \Big]\), \(\mathcal K_{s, 2} = \cdots = \mathcal K_{s, d} = \Big [ -2(s+1), 2(s+1) \Big]\).
\item
  \(m=1\).
\end{itemize}

\hypertarget{numerical-examples}{%
\paragraph{Numerical Examples}\label{numerical-examples}}

Methods: MCMLE, SAA (Stochastic Approximation Algorithm), Varying truncation SAMCMC
SAMCMC: independent 5 runs(each of 200,000 iterations) (m=1, Ca = 0.01, Cb = 1000, η, ξ, κs are defalut)

\hypertarget{ergm-for-dynamic-networks}{%
\section{ERGM for Dynamic Networks}\label{ergm-for-dynamic-networks}}

However, a need for statistical models representing the evolving phenomena ⇒ ''Dynamic Models'' with a temporal structure

\hypertarget{temporal-ergm}{%
\subsection{Temporal ERGM}\label{temporal-ergm}}

\begin{itemize}
\tightlist
\item
  \textbf{ERGM → TERGM → STERGM}
\end{itemize}

One-step transition probability \((t-1) → (t)\) (Markov Assumption)

\[
P_{\eta, g} \Big ( Y^t = y^t \Big | Y^{t-1} \; \; ; \; \; \theta \Big ) = \frac{\exp \Big \{ \eta(\theta) \cdot g(y^t, y^{t-1})\Big  \}}{c_{\eta, h}(\theta, y^{t-1})}
\]

\begin{itemize}
\tightlist
\item
  \textbf{TERGM: Temporal ERGM}
\end{itemize}

시간 t에서의 네트워크는, t-1 시점의 (어쩌면 t-2도 가능하고) 네트워크로 조건을 건 ERGM 으로부터의 단일 생산으로 생각될 수 있음. 소셜 네트워크의 변화를 간단히 하기 위해 \textbf{Markov assumption} 적용. 이는 곧, \(A^t\)가 t 시점에서의 단일-관계 소셜 네트워크의 weight 매트릭스를 표현하고, 우리에게 \(A^{t-1}\) 의 값이 주어져 있다면, \(A^t\) 는 \(A^1, \cdots, A^{t-2}\) 으로부터는 독립임을 의미한다는 뜻. 수식으로 표현하면 아래와 같다.

\[
P\Big(A^2, A^3, \cdots, A^t \Big | A^1 \Big ) = P\Big(A^t \Big | A^{t-1} \Big ) P\Big(A^{t-1} \Big | A^{t-2} \Big ) \cdots P\Big(A^2 \Big | A^1 \Big ) \tag{Temporal ERGM}
\]

마르코프 가정이 주어져 있음을 고려하면, evolving 네트워크 전반에 대해 ERGM 을 일반화하는 방법이란 \(A^t \vert A^{t-1}\) 가 ERGM 표현법을 채택했음을 가정하는 것. to assume \(A^t \vert A^{t-1}\) admits an ERGM representation.

함수 \(\Psi : \mathbb R_{n \times n} \times \mathbb R_{n \times n} \rightarrow \mathbb R^k\) 를 생각해보자. 이는 시간적으로 인접한 2개의 네트워크 (\(t\), \(t-1\) 등) 에 걸친 cliques 들의 잠재적은 potential로 인지될 수 있다. 이때 패러미터 벡터 \(\theta \in \mathbb R^k\) 는 이하와 같은 conditional pdf를 갖는다.

\[
P \bigg( A^t \Big | A^{t-1}, \theta \bigg) = \frac{1}{\kappa(\theta, A^{t-1})} \exp \left\{ \theta' \Psi \left ( A^t, A^{t-1} \right ) \right\}
\]

특히 우리는 해당 모델에서 이하와 같은 특수한 경우에 관심이 있다.

\[
\Psi \left ( A^t, A^{t-1} \right ) = \sum_{ij}\Psi_{ij} \left ( A^t_{ij}, A^{t-1} \right )
\]

이 형의 temporal potential 함수는

\(A^t | A^{t-1}\)의 조건부 분포의

This form of the temporal potential function represents situations where the conditional distribution of \(A^t | A^{t-1}\) factors over the entries \(A^t_{ij}\) of \(A^t\).

\hypertarget{network-statistics-for-temporal-ergm}{%
\subsubsection{Network Statistics for Temporal ERGM}\label{network-statistics-for-temporal-ergm}}

\$\$
\begin{align}
\Psi_D \left ( A^t , A^{t-1}\right)

&=

\frac{1}{n-1} \sum_{ij} A^t_{ij}

\tag{Density}

\\

\Psi_S \left ( A^t , A^{t-1}\right)

&=

\frac{1}{n-1} \sum_{ij}

\left \{ A^t_{ij} A^{t-1}_{ij} + \left (1-A^t_{ij} \right) \left (1-A^{t-1}_{ij} \right)
\right \}


\tag{Stability}

\\

\Psi_R \left ( A^t , A^{t-1}\right)


&=

n \left ( \frac{\sum_\limits{ij} A_{ij}^t A_{ij}^{t-1}}{\sum_\limits{ij}A_{ij}^{t-1}}\right )

\tag{Reciprocity}

\\

\Psi_T \left ( A^t , A^{t-1}\right)

&=

n \left ( \frac{\sum_\limits{ijk} A_{ik}^t A_{ij}^{t-1}A_{jk}^{t-1}}
{\sum_\limits{ijk}A_{ij}^{t-1}A_{jk}^{t-1}}\right )



\tag{Transitivity}

\end{align}

\$\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Density} : 전체 네트워크에 들어있는 총 tie의 숫자.
\item
  \textbf{Stability} : t-1 시점에 존재했던 link가 t 시점에도 여전히 존재하는 경향성
\item
  \textbf{Reciprocity} : t-1 시점에 i에서 j로 향하는 link가 있었다면 t 시점에 j→i 링크가 생겨날 경향
\item
  \textbf{Transitivity} : t-1 시점에 i→j와 j→k인 tie가 존재한다면, t에 i→k tie의 발생으로 이어지는 경향
\end{enumerate}

\hypertarget{estimation-1}{%
\subsubsection{Estimation}\label{estimation-1}}

\begin{itemize}
\tightlist
\item
  Notation \& Algorithm \& Convergence
\end{itemize}

observed 네트워크의 sequence \(N^1 , N^2 , \cdots, N^T\) 를 사용하자. 무엇을 위해? 실제 패러미터값 \(\theta\) 에 가까운 estimator \(\hat \theta\) 을 찾기 위해. normalizing constant 는 보통 계산해내는 것이 불가능하여 MLE 방법론의 도입은 불가. 따라서 MCMC stochastic approximation 를 사용해 패러미터 estimate. 이하와 같이 notation 한다. 이때 t 시점의 네트워크인 랜덤변수 \(\underline N^t\) 에 대해 기댓값들이 계산되었음을 notice.

LATEX

이때 이하의 기댓값들은 조건부 분포로부터 Gibbs 샘플링을 돌리는 것으로 근사 가능. Newton 방법론과 유사한 과정을 통해 unconstrained optimization 을 하자. 기댓값을 근사하고, Likelihood를 증가시키는 방향으로 패러미터값을 업데이트. 이 과정을 수렴하기까지 반복.

LATEX

\hypertarget{degeneracy-of-temporal-ergms}{%
\subsubsection{Degeneracy of Temporal ERGMs}\label{degeneracy-of-temporal-ergms}}

간단한 케이스에는, where the transition distribution factors over the edges, 이 모델들은 그러한 문제들에서 완전히 자유롭다는 것이 알려져 있음.

이는 직관적으로도 와닿음. \(A^t_{ij} | A^{t−1}\) 의 개개의 조건부 분포가 과하게 극단적이지 않은 한, \(A^{t-1}\)이 주어졌을 때 \(A^t\)의 edge는 조건부 독립이기 때문이지. 따라서 \(A^t | A^{t−1}\) 의 조건부 엔트로피는 커야 하며, 이에 의해 \(A^t\)의 조건부 엔트로피도 커야 할테니까.

물론 이 명제는 \(A^{t−1}\) 에 대한 \(A^t\) 의 의존이 그렇게 강하지 않을 때만 성립하는 것임. 이때 이 의존의 위력은 패러미터들의 위력에 의해 결정되지. 그러니까 패러미터가 이상하게 잡히면 해당 명제의 전제가 깨진다는 거.

동일한 확률값을 가진다는 것을 analytic 하게 보일 수 있는 그래프들의 class들, 즉 equivalence 클래스들에 대해서 이를 계산해보고, 엔트로피 계산에서 각각의 클래스의 크기에 따라서 weight를 부여하자.

첫 플랏의 경우를 생각해보자. \(A^2 | A^1\) 의 조건부 분포는 결국 \(A^2\) 에 존재하는 edge의 갯수와, 얼마나 많은 \(ij\) 값들에게서 \(A^2_{ij} = A^1_{ij}\)가 성립하고 있느냐, 의 2개의 값에 대한 함수일 뿐이다. 이에 더해 \(A^1\)의 edge들은 exchangeable 하다는 점도 있다. 이들을 모두 생각해보면 결국 우리는 \(A^2\)의 marginal 분포를 순수하게 edge의 숫자를 통해서만 서술하는 것이 가능하다.

따라서 우리는 \(n(n − 1)\)의 확률값만 계산해내면 되며, 따라서 엔트로피는 weighted sum이다. 이때 weight는 각각의 edge 숫자에 대해, that many edges 를 가지고 있는 그래프의 숫자가 반영된 combinatorial quantities 가 된다.

\hypertarget{assessing-statistic-importance-and-quality-of-fit}{%
\subsubsection{Assessing Statistic Importance and Quality of Fit}\label{assessing-statistic-importance-and-quality-of-fit}}

Three Parameter Model
Description of Network Statistics

Reverse-Transitivity:
Co-Supported:
Co-Supporting:
Popularity
Generosity

\hypertarget{separable-temporal-ergm}{%
\subsection{Separable Temporal ERGM}\label{separable-temporal-ergm}}

STERGM = A Separable Model for Dynamic Network

Dynamic: social networks that evolve over time
Time(discrete): \(\cdots (t-2) → (t-1) → (t) → \cdots\)
Shows longitudinal properties based on the ERGM

Separable
formation : new ties
duration : lasting ties

\hypertarget{temporal-ergm-interpretation}{%
\subsubsection{Temporal ERGM Interpretation}\label{temporal-ergm-interpretation}}

하지만 이때 패러미터 해석할 때 주의해야할 부분이 있음.

Property1: incidence of ties (the rate at which new ties are formed)
Property2: duration of ties (how long they tend to last once they do)

\begin{itemize}
\tightlist
\item
  Network statstic
\end{itemize}

(ex) edge count \(g(y^t , y^{t-1}) = | y^t |\)

coefficient on \(g\) \(\propto\) possibility of a network with many ties. 따라서 \(g\)의 계수가 올라가면 tie가 많은 네트워크의 발생 확률 올라감.

But, this term simultaneously increases the weight of preservation of extant ties (fewer dissolved) ⇒ Both incidence and duration ↑

The two-sided nature of these effects tends to muddle parameter interpretation. ⇒ STERGM which separates the incidence and duration of ties and allows for the separate interpretation.

\begin{itemize}
\tightlist
\item
  : incidence/tie formation \(y^+ = y^{t-1} \cup y^t\)
  -- : duration/tie dissolution \(y^- = y^{t-1} \cap y^t \Rightarrow y^t = y^- \cup (y^+ \setminus y^{t-1})\)
\end{itemize}

\hypertarget{application-study}{%
\subsubsection{Application Study}\label{application-study}}

\hypertarget{conclusion}{%
\subsubsection{Conclusion}\label{conclusion}}

\hypertarget{latent-network-models}{%
\section{Latent Network Models}\label{latent-network-models}}

\hypertarget{latent-position-model}{%
\subsection{Latent Position Model}\label{latent-position-model}}

ERGMs 와 다르게, 이 모델은 소셜 스페이스의 개념을 도입함. 이 소셜 스페이스에서는, 네트워크 관계에 있어 unobserved latent 특성이 potential transitive 경향을 represent, 즉 위력? 을 나타낼 수 있음. 이때 이 소셜 스페이스에서 각 actor (혹은 node) \(i\)는 알려지지 않은 포지션 \(z_i\)를 각각 차지하게 됨. 우리는 이를 \textbf{latent position} 이라고 부름.

여기서 우리는 주된 가정으로 ties 간의 \textbf{조건부 독립}을 가정한다. latent position이 주어진다면, 네트워크 안의 ties들은 조건부 독립임이 가정된다. 두 개인들 간의 특정한 tie의 확률은 그들의 positions 들의 함수로 모델링된다. 가령 소셜 스페이스 안에서의 두 actor 사이의 거리라던가.

이때 이를 노테이션으로 표기하자면 다음과 같다.

\[
P(Y | Z, X, \theta) = \prod_{i \not = j} P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)
\]

\begin{itemize}
\tightlist
\item
  sociomatrix \(Y_{n \times n}\), 이때 요소 \(y_{i,j}\)는 actor \(i\)로부터 \(j\)로의 관계를 의미하는 값.
\item
  additional covariate information \(X\)
\item
  이때 \(X\)와 \(x_{i,j}\)는 unobserved 성질이며, \(\theta\)는 estimate되어야 하는 패러미터, \(Z\)는 estimate 되어야 하는 포지션.
\end{itemize}

\hypertarget{methods}{%
\subsubsection{Methods}\label{methods}}

\hypertarget{distance-models}{%
\paragraph{Distance Models}\label{distance-models}}

\(P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)\)는 로지스틱 회귀모형을 쓰면 편하게 패러미터化 할 수 있다. 이렇게 패러미터化 할 때 tie의 확률은 \(z_i , z_j \in \mathbb R\) 인 \(z_i , z_j\) 사이의 유클리디안 거리에 의존한다. 수식은 아래와 같다.

\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = \alpha + \beta ' x_{i,j} - |z_i - z_j |
\]

\begin{itemize}
\tightlist
\item
  이때 \(|z_i - z_j |'\) 는 그 어떤 metric으로도 대체될 수 있다는 것을 notice. 삼각부등식 \(d_{i,j} \le d_{i,k} + d_{k,j}\)만 만족하면 됨.
\end{itemize}

latent 포지션 모델은 본질적으로 reciprocal 하고 transitive 함. 왜? 만약 \(i \rightarrow j\) 이고 \(j \rightarrow k\) 이라면, \(d_{i,j}\) 와 \(d_{j,k}\) 는 어쩌면 지나치게 크지는 않을 수도 있는 것이고, 이 경우에는 이하로 이어짐:
1. events \(j \rightarrow i\) (reciprocity)
2. 그리고 \(i \rightarrow k\) (transitivity)

\hypertarget{projection-models}{%
\paragraph{Projection Models}\label{projection-models}}

distance 모델은 본질적으로 symmetric 임. 즉 \(p(i → j) = p(j → i)\). 하지만 많은 (\textbf{directed}) 모델에서 이런 symmetry 는 성립을 안함. 예를 들어 actor \(i\) 가 대량의 ties 들을 보내는 반면 \(j\) 가 \(i\) 에게서 ties 들을 받은 actors 전체 중 작은 subset 에게만 보낸다면? 따라서 행위의 변수 레벨은 관계에서 확률의 transitivity 를 allow하는 latent 포지션 모델의 맥락 속에서 모델링될 필요가 있다. 개개인의 소셜 활동의 특정한 수준도 고려되어야 함은 물론이다.

actor \(i\)의 특성의 벡터 \(v_i\)를 \textbf{unit} \(k\)-dim 이라고 가정. \(i,j\) 사이의 angle이 작으면 우리는 둘 사이에 tie가 존재할 가능성이 높다고 생각하자. 직각이면 중립, 둔각이면 낮다. actor \(i\) 의 활동 레벨 \(a_i >0\) 를 설정한 후, \(i→j\)의 tie의 존재 확률을 \(a_i v_i ' v_i = \frac{z_i' z_j}{| z_j |}\) (이때 \(z_i = a_i v_i\)) 라고 설정한다면 이하의 등식이 성립.

\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = \alpha + \beta ' x_{i,j} + \frac{z_i' z_j}{| z_j |}
\]

\hypertarget{estimation-2}{%
\subsubsection{Estimation}\label{estimation-2}}

\textbf{Distance} 모델 상황을 생각해보자. 유클리드 공간에서 set points 간의 거리는 회전, 반사, 이동에 불변 (invariant). 따라서 모든 각각의 latent postion의 행렬 \(Z_{k \times n}\) 에 대해 같은 log-likelihood 를 갖는 다른 positions 을 표상하는 행렬이 존재한다.

\(\mathcal Z\) 를 회전, 반사, 이동에 불변한 \(Z\)와 equivalent 한 postions들의 class 라고 하자. 각각의 \(\mathcal Z\)에 대해 node 들 간의 거리를 모아 set 1개가 나옴. 이러한 positions 들의 class를 \textbf{configuration} 이라고 부름.

마찬가지로 Projection 모델에서의 \(Z\) 에 대해서도 Projection 모델들은 positions 들의 회전과 반사에는 불변하지만, 이동에 대해서는 불변이 아님.

조건부 독립 모델의 log-likelihood 모델은 다음과 같다:

\[
\log P(Y | \eta ) = \sum_{i \not = j} \Big \{  \eta_{i,j}y_{i,j} - \log (1+\exp(\eta_{i,j})
\Big \}
\]

※ Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  각 j 에서 \$z\_j ' \$ 샘플링하기 위해 MH 스텝 거침. proposal 분포 \(\varphi(\cdot)\) 으로부터 \(z_j'\) 생산하고 이를 이하의 확률 \(r_z \left ( z_j ' , z_j^{(t)} \right)\) 로 채택. 비슷환 과정을 따라서 \(\alpha, \beta\) 도 MH 이용해서 생산.
\end{enumerate}

\$\$
r\_z \left ( z\_j ' , z\_j\^{}\{(t)\} \right)

= \frac{\pi \Big (z_j '  \Big \vert Y, \alpha , \beta \Big )}{\pi \Big (z_j^{(t)}  \Big \vert Y, \alpha , \beta \Big )}

\frac{\varphi \Big (z_j ' \rightarrow z_j^{(t)} \Big )}{\varphi \Big ( z_j^{(t)}\rightarrow z_j ' \Big )}

\$\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Procrustes} 매칭 사용해서 MCMC 샘플 후처리.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    latent positions 들의 reference set 을 찾기 위해, MCMC 샘플로부터 latent positions들 중 full log posterior density가 가장 높은 latent positions들 \(Z_0\)를 하나 뽑아서 쟁여둠
  \item
    \(Z_0\)를 사용해서 각각의 MCMC 샘플에 Procrustes 매칭 적용
  \end{enumerate}
\end{enumerate}

\[
Z^\ast  = argmin_{TZ} \tr \Big \{ (Z_0 - TZ) ' (Z_0 - TZ) \Big \}
\]

\hypertarget{advantages}{%
\subsubsection{Advantages}\label{advantages}}

네트워크 관계에 대한 시각적이고 모델에 기반한 공간적인 표현을 제공. 해석 용이함.

It is flexible and can be easily generalized to allow for multiple
relationships, ties with varying strengths, and time-varying relations

deal easily with missing data, at least if information on ties is missing at
random

the model is inherently transitive, and so we can expect an improved fit
over models lacking such structure when the relations are transitive in
nature

\hypertarget{latent-position-cluster-model}{%
\subsection{Latent Position Cluster Model}\label{latent-position-cluster-model}}

\$\$
\begin{align}


\log \frac{P(y_{i, j} = 1\Big | z_i , z_j , x_{i,j}, \beta)}{1 - P(y_{i, j} = 1 \Big | z_i , z_j , x_{i,j}, \beta)} &= \beta_0 ' x_{i,j} - \beta_1 |z_i - z_j |

\\

P(Y | Z, X, \beta) &= \prod_{i \not = j} P(y_{i, j} \Big | z_i , z_j , x_{i,j}, \beta) \tag{Likelihood}


\end{align}
\$\$

\begin{itemize}
\tightlist
\item
  \(z_i \sim \sum\limits_{g=1}^G \lambda_g \cdot MVN_d )\mu_g , \sigma^2_g I_d )\), where \(\sqrt{\frac{1}{n} \sum_i |z_i|^2} = 1\).
\item
  \(\lambda_g\)는 individual distribution의 비율
\end{itemize}

\hypertarget{bayesian-estimation}{%
\subsubsection{Bayesian Estimation}\label{bayesian-estimation}}

※ Fully Bayesian Estimation Procedure
1. 모델 패러미터 \(\beta, \lambda_g, \mu_g, \sigma_g^2\) 들의 prior 분포 특정

\$\$
\begin{align}

\beta &\sim MVN_p \left( \ksi , \Psi \right)

\\

\lambda &\sim Dirichlet(\nu)

\\

\sigma^2_g &\sim \sigma_0^2 Inv- \chi_\alpha^2 && g = 1, \cdots, G

\\

\mu_g &\sim MVN_d \left( 0, \omega^2 \cdot I_d \right) && g = 1, \cdots, G


\end{align}
\$\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\mathbf z_i , \beta, \lambda, \mu_g ,\sigma^2_g, K_i\)의 full 조건부 posterior 분포 특정
\end{enumerate}

\$\$
\begin{alignat}



\end{alignat}
\$\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  MCMC Algorithm
\end{enumerate}

\hypertarget{high-dimension}{%
\chapter{High Dimension}\label{high-dimension}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

\hypertarget{concentration-inequalities}{%
\section{Concentration inequalities}\label{concentration-inequalities}}

\hypertarget{motivation}{%
\subsection{Motivation}\label{motivation}}

\[
\forall t \ge 0 : P( | \bar X - \mu | \ge t) \le 2 \exp \left( - \frac{nt^2}{2\sigma^2}\right)
\]

\hypertarget{section}{%
\subsection{}\label{section}}

\hypertarget{sub-gaussian-random-variables}{%
\subsection{sub-Gaussian random variables}\label{sub-gaussian-random-variables}}

:::\{.def ``sub-Gaussian''\}

평균이 \(\mu = E(X)\) 인 랜덤변수 X에 대해 \(\exists \sigma >0\) 에 대해 이하가 성립하면 이는 sub-Gaussian 이며 \(X \in SG(\sigma^2)\).

:::

\begin{itemize}
\tightlist
\item
  \(sigma\) 는 sub-Gaussian 패러미터
\item
  \(sigma^2\) 는 variance proxy
\end{itemize}

symmetry 해보면 \(X \in SG(\cdot)\) 일 경우에만 \(-X \in SG(\cdot)\).

\hypertarget{properties-of-sub-gaussian-random-variables}{%
\subsection{Properties of sub-Gaussian random variables}\label{properties-of-sub-gaussian-random-variables}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \in SG(\cdot)\) 일 경우 \(Var(X) \le \sigma^2\)
\item
  \textbf{Hoeffding's lemma}: almost surely 하게 \(a \le X-\mu \le b\) 한 실수 \(a, b\)가 있다면, \(X \in SG \Big ( (\frac{b-a}{2})^2\Big )\).
\item
  \(X \in SG(\sigma^2)\) 이며 \(Y \in SG(\tau^2)\) 일 경우,

  \begin{itemize}
  \tightlist
  \item
    \$\forall a \in \mathbb R: aX \in SG \Big ( a\^{}2 \sigma\^{}2 \Big )
  \item
    \(X+Y \in SG \Big ( (\sigma + \gamma)^2\Big )\)
  \item
    if \(X \perp Y\), then \$X + Y \in SG \Big ( \sigma\^{}2 + \gamma\^{}2 \Big )
  \end{itemize}
\end{enumerate}

\hypertarget{equivalent-definitions}{%
\subsection{Equivalent definitions}\label{equivalent-definitions}}

\hypertarget{sub-gaussian-random-vectors}{%
\subsection{Sub-Gaussian random vectors}\label{sub-gaussian-random-vectors}}

\hypertarget{hoeffdings-inequality}{%
\subsection{Hoeffding's inequality}\label{hoeffdings-inequality}}

\hypertarget{section-1}{%
\subsection{}\label{section-1}}

\hypertarget{maximal-inequalities}{%
\subsection{Maximal inequalities}\label{maximal-inequalities}}

\hypertarget{concentration-inequalities-1}{%
\section{Concentration inequalities}\label{concentration-inequalities-1}}

\hypertarget{sub-exponential-random-variables}{%
\subsection{Sub-exponential random variables}\label{sub-exponential-random-variables}}

\hypertarget{bernsteins-condition}{%
\subsection{Bernstein's condition}\label{bernsteins-condition}}

\(X\)의 polynomial moment를 조작하는 것으로 \(X\)의 sub-exponential 성질을 증명할 수 있다.

:::\{.def ``Bernstein's Condition''\}

let \(E(X) = \mu\), \(Var(X) = \sigma^2 = E(X^2) - \mu^2\) 인 랜덤변수 \(X\). 이하의 경우와 패러미터 \(b\) 에 대해 Bernstein's Condition 이 성립한다.

\$\$
\begin{align}

&\Bigg | E \Big [ (X-\mu)^k \Big ] \Bigg | \le \frac{1}{2} k! \sigma^2 b^{k-2}, && k = 2, 3, 4, \cdots

\end{align}
\$\$

이때, 모든 bounded 랜덤변수 (즉 \(|X-\mu| \le b\)) 에 대해 Bernstein's Condition 이 성립한다는 것을 파악해라.
:::

\(X\)가 Bernstein's condition 을 만족할 경우, X는 패러미터 \((\sqrt 2 \sigma, 2b)\) 인 sub-exponential.

:::\{.thm ``Bernstein-type inequality''\}

Bernstein's Condition 을 만족하는 모든 랜덤변수에 대해 이하가 성립한다.

\$\$
\begin{align}



&\forall |\lambda|< \tfrac{1}{b}: &&E \Big [ e^{\lambda(X-\mu)}\Big ] &&\le \exp \left( \frac{\frac{\lambda^2 \sigma^2}{2}}{1-b|\lambda|}\right)

\\

&\forall t \ge 0:

&&P \Big( |X-\mu| \ge t \Big) &&\le 2 \exp \left( - \frac{t^2}{2(\sigma^2 + bt)}\right)

\end{align}

\$\$
:::

\hypertarget{mcdiarmids-inequality}{%
\subsection{McDiarmid's inequality}\label{mcdiarmids-inequality}}

:::\{.thm ``McDiarmid's inequality''\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  랜덤변수 \(X_1 , \cdots, X_n\) 이 independent
\item
  함수 \(f: \mathbb R^n \mapsto \mathbb R\): \(\Big | f(x_1, \cdots, x_n) - f(x_1 , \cdots, x_{k-1} , x_k ' , x_{k+1} , \cdots, x_n) \Big | \le L_k\) (bounded condition)
\end{enumerate}

위 둘이 성립하면 이하가 성립한다.

\[
\forall t \ge 0: P \left( \Big | f(X_1 , \cdots, X_n) - E \big[ f(X_1 , \cdots, X_n) \big]\Big | \ge t \right) \le 2 \exp \left( - \frac{2 t^2}{\sum_{k=1}^n L_k^2}\right)
\]

:::

\hypertarget{section-2}{%
\subsection{}\label{section-2}}

\hypertarget{section-3}{%
\subsection{}\label{section-3}}

\hypertarget{section-4}{%
\subsection{}\label{section-4}}

\hypertarget{section-5}{%
\subsection{}\label{section-5}}

\hypertarget{section-6}{%
\subsection{}\label{section-6}}

\hypertarget{metric-entropy-and-its-uses}{%
\section{Metric entropy and its uses}\label{metric-entropy-and-its-uses}}

\hypertarget{metric-space}{%
\subsection{Metric space}\label{metric-space}}

\hypertarget{covering-numbers-and-metric-entropy}{%
\subsection{Covering numbers and metric entropy}\label{covering-numbers-and-metric-entropy}}

:::\{.def ``Covering number''\}

set \(\mathcal X\) 의 metric \(d\) 에 비춘 \(\delta\)-cover는 이하와 같다.

\(set \{\theta_1, \cdots, \theta_N\} \in \mathcal X\) s.t. \(\forall \theta \in \mathcal X, \exists i \in \{1 , \cdots, N \} : d(\theta, \theta_i) \le \delta\).

이때 \(\delta\)-covering number \$N(\delta; \mathcal X , d) 는 가장 작은 \(delta\)-cover 의 cardinality.

:::

\hypertarget{packing-numbers}{%
\subsection{Packing numbers}\label{packing-numbers}}

:::\{.def ``Packing number''\}

set \(\mathcal X\) 의 metric \(d\) 에 비춘 \(\delta\)-packing은 이하와 같다.

\(set \{\theta_1, \cdots, \theta_M\} \in \mathcal X\) s.t. \(\forall i \not = j \in \{1, 2, \cdots, M\}: d(\theta_i, \theta_j) \ge \delta\)

이때 \(\delta\)-packing number \$M(\delta; \mathcal X , d) 는 가장 큰 \(delta\)-packing 의 cardinality.

:::

\hypertarget{section-7}{%
\subsection{}\label{section-7}}

\hypertarget{section-8}{%
\subsection{}\label{section-8}}

\hypertarget{section-9}{%
\subsection{}\label{section-9}}

\hypertarget{covariance-estimation}{%
\section{Covariance estimation}\label{covariance-estimation}}

\hypertarget{matrix-algebra-review}{%
\subsection{Matrix algebra review}\label{matrix-algebra-review}}

:::\{.thm2 name =``a''\}
a
:::

\hypertarget{covariance-matrix-estimation-in-the-operator-norm}{%
\subsection{Covariance matrix estimation in the operator norm}\label{covariance-matrix-estimation-in-the-operator-norm}}

\begin{theorem}[Covariance estimation]
\(X_1 , \cdots, X_n \overset {iid}\sim SG(\sigma)\) s.t. \(E(X_1) = 0, Var(X_1) = \Sigma_{d \times d}\).

Let sample Cov matrix \(\hat \Sigma = \frac{1}{n} \sum X_i X_i '\) based on \(X_1 , \cdots, X_n\).

Then there exists a universal constant \(C >0\) s.t. below holds with probabilty at least \(1-\sigma\).

\[
\forall \sigma \in (0,1): \frac{\|\hat \Sigma - \Sigma \|_{op}}{\sigma^2} \le C \max \left \{ \sqrt{\frac{d + \log(\frac{2}{\sigma})}{n}}, \; {\frac{d + \log(\frac{2}{\sigma})}{n}}\right \}
\]
\end{theorem}

\begin{itemize}
\tightlist
\item
  이건 결국 \(\lim_{n \rightarrow \infty \frac{d}{n} \rightarrow 0}\) 일 때operator norm 안의 \(\Sigma\)를 계속해서 estimate 할 수 있다는 것을 말함. 실제로 추가적인 가정 없이는 이 rate 이상으로 측정을 정밀화할 수 없음.
\end{itemize}

증명을 2단계로 분할.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  discretization argument 를 써서 문제를 finitely 많은 랜덤변수의 maximum 을 제어하는 문제로 변경. 이하의 정보와 함께 finite maximum 라는 사실 사용해서 \(\|\hat \Sigma - \Sigma \|_{op}\) 에 대한 상한 생산.
\end{enumerate}

let \(A = A' \in \mathbb R^{d \times d}\) 로 하고, \(N_\epsilon = \{ y_1 , \cdots, y_N \}\) 을 \(\mathbb S^{d-1}\) 의 \(\epsilon\)-covering 으로 함.

이때 \(\| A \|_{op} \le \frac{1}{1-2\epsilon} \cdot \max_{y \in N_\epsilon} | y' A y |\).

이를 증명하자. \(x \in \mathbb S^{d-1}\) 에 대해 \(\| x-y \|_2 \le \epsilon\) 만족하는 \(y \in N_\epsilon\) 선택. 이때 \(A\)는 symmetric Matrix 이므로,

\$\$

\$\$

여기서 \(\hat \Sigma - \Sigma\) 는 symmetric Matrix 이므로, \(\|\hat \Sigma - \Sigma \|_{op} \le \frac{1}{1-2\epsilon} \max_{y \in N_\epsilon} | y' (\hat \Sigma - \Sigma) y |\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  standard concentration inequality 사용.
\end{enumerate}

\hypertarget{bounds-for-structured-covariance-matrices}{%
\subsection{Bounds for structured covariance matrices}\label{bounds-for-structured-covariance-matrices}}

우리의 주된 목적은 샘플 Cov를 경유하여 unstructured Cov Matrix를 estimate 하는 것. Cov Matrix 가 추가적인 structure 를 품고 있다면, 샘플 Cov 가 아니라 다른 estimator 를 사용해서 좀더 연산이 빠른 estimate 가 가능.

\begin{itemize}
\tightlist
\item
  \textbf{Diagonal matrix}
\end{itemize}

\textbf{Cov Matrix 가 diagonal이라는 정보}를 가지고 있다고 해보자. 이때 \(\hat \Sigma_{diag} = diag \{ \hat \Sigma_{11}, \cdots, \hat \Sigma_{dd}\) 로 estimate 하는 것은 자연스럽다. 이 경우 sub-Gaussinianity 를 가정한다면 어떻게 될까? unstructured 케이스에서 order 가 \(\sqrt{\frac{d}{n}}\) rates (단, \(d \le n\)) 였던 것과 대비되게 estimation error of the order \$\sqrt{\frac{\log d}{n}} 가 생산된다.

좀 더 자세히 살펴보자. diagonal 케이스에서, \(\hat \Sigma_{diag} - \Sigma\) 의 operator norm 은 본질적으로 \(d\) 개의 entry값 \(\{| \hat \Sigma_{diag,11} - \Sigma_{11} |, \cdots, | \hat \Sigma_{diag,dd} - \Sigma_{dd} |\}\) 중의 maximum 이다. 그렇다면 여기서 the union bound argument along with an exponential tail bound 를 통해 우리는 \(\sqrt{\frac{\log d}{n}} → 0\) 일 때 operator norm 이 0로 decay 된다는 것을 파악할 수 있다. See Theorem 2.11 for a similar argument.

\begin{itemize}
\tightlist
\item
  \textbf{Unknown sparsity and thresholding}
\end{itemize}

좀더 일반적인 케이스를 생각해보자. Cov Matrix가 상대적으로 sparse 하다는 사실이 알려져 있지만, 어느 entry가 non-zero인지는 알려져있지 않다. 이때 estimator가 thresholding 에 기반하고 있다고 생가가흔 넉승 나젼스럽다. 이때 \(\lambda >0\) 라는 패러미터가 주어져 있다고 생각할 때, hard-thresholding 을 통해 얻어지는 Cov estimator 의 \((i,j)\) entry 는 \([T_\lambda (\hat \Sigma)]_{ij} = \hat \Sigma_{ij} \cdot I(|\hat \Sigma_{ij}>\lambda)\).

let \(\Sigma\)의 adjacency matrix \(A \in \mathbb R^{d \times d}\), \(A_{ij} = I(\Sigma_{ij}) \not = 0\). adjacency matrix 의 operator norm \(\| A \|_{op}\) 는 sparsity 에 대한 natural measure 를 제공한다. 이때 우리는 \(\Sigma\) 가 row 별로 \(s\) 개의 non-zero entry를 갖고 있다면 \(\| A \|_{op} \le s\) 임을 보일 수 있다. 또한 thresholded 샘플 Cov Matrix 는 다음과 같은 concentration bound를 가짐.

::: \{..theorem name=``Thresholding-based covariance estimation''\}

\(X_1 , \cdots, X_n \overset {iid} \sim\), s.t. \(E(X_1) = 0, Var(X_1) = \Sigma_{d \times d}\), and suppose each component \(X_{ij}\) is sub-Gaussinian with 패러미터 at most \(\sigma\).

만약 \(n > 16 \log d\) 라면, \(\forall \delta>0\)에 대해, thresholded 샘플 Cov Matrix \(T_{\lambda_n} (\hat \Sigma)\) with \(\frac{\lambda_n}{\sigma^2} = 8 \sqrt{\frac{\log d}{n}} + \delta\) 는 이하를 만족한다.

\$\$
P \Big (

\textbar{} T\_\{\lambda\emph{n\} ( \hat \Sigma ) - \Sigma \textbar{}}\{op\} \ge 2 \textbar{} A \textbar\_\{op\} \cdot \lambda\_n

\Big)

\le 8 \exp \Big( -\frac{n}{16} (\delta \wedge \delta\^{}2)\Big)
\$\$

:::

\begin{itemize}
\item
  위의 부등식은 높은 확률로 \(\| T_{\lambda_n} ( \hat \Sigma ) - \Sigma \|_{op} \lesssim \| A \|_{op} \sqrt{\log d}{n}\) 임을 보여줌. 이에 더해서 \(\sigma\) 가 row 당 최대 \(s\) 개의 non-zero entry 를 가진다는 조건을 생각하자. 이는 곧 \(\|A\|_2 \le s\) 라는 의미가 됨. 그렇다면 thresholded Cov Matrix는 \(s\sqrt{\frac{\log d}{n}}→0\) 일 때 consistent 하며, 이는 곧 특히 \(s\) 가 작을 때 \(\sqrt{\frac{d}{n}}\) 보다 훨씬 빠르다.
\item
  thresholding 패러미터는 sub-Gaussian 패러미터 \(\sigma\)에 의존하는데, 이는 실전 상황에서는 대부분 unknown.
\end{itemize}

Proof: Let us denote the elementwise infinity norm of the error matrix ∆ = b Σb − Σ by
k∆bk∞ = max1≤i,j≤d \textbar∆bij \textbar. The proof of the theorem is based on two intermediate results:
1. Under the assumptions of the theorem,
P(k∆bk∞/σ2 ≥ t) ≤ 8e
− n
16 min\{t,t2\}+2 log d
for all t \textgreater{} 0. (5.3)
2. For any choice of λn such that k∆bk∞ ≤ λn, we are guaranteed that
kΣb − Σkop ≤ 2kAkopλn. (5.4)
Having these results in place, the theorem follows by taking t = λn/σ2 = 8p
(log d)/n + δ
in inequality (5.3) and see
8e
− n
16 min\{t,t2\}+2 log d ≤ 8e
− n
16 min\{δ,δ2\}
,
when n \textgreater{} 16 log d.~Thus
P(kTλn
(Σ) b − Σkop ≥ 2kAkopλn) ≤ P(k∆bk∞ ≥ λn) ≤ 8e
− n
16 min\{δ,δ2\}
.
It remains to prove inequality (5.3) and inequality (5.4), which are left as exercises (see
Section 6.5 of Martin's book)

\hypertarget{matrix-concentration-inequalities}{%
\section{Matrix concentration inequalities}\label{matrix-concentration-inequalities}}

이전 강의에서는 샘플 Cov Matrix의 tail bound를 discretization argument 를 통해 탐색했음. 여기선 Matrix Chernoff 테크닉을 통해 탐색한 후 랜덤 매트릭스에 Hoeffding bound 와 Bernstein bound 를 제시할거임.

\hypertarget{matrix-calculus}{%
\subsection{Matrix calculus}\label{matrix-calculus}}

symmetric Matrix 의 set \(\mathcal S^{d \times d} = \{ X \in \mathbb R^{d \times d} : X = X' \}\) 와 ev 가 non-negative 인 PSD Matrix의 subset \(\mathcal S^{d \times d}_+\) 를 사용할 것.

\hypertarget{matrix-chernoff}{%
\subsection{Matrix Chernoff}\label{matrix-chernoff}}

independent symmetric 랜덤 매트릭스의 collection \(X_1 , \cdots, X_n \in \mathcal S^{d \times d}\) 가 주어졌고 \(E(X_1) = 0\). 이때 \(\bar X\)의 maximum ev를 \$P(\lambda\_\{max\} (\hat X) \ge T) 와 같이 bound하고 싶다. Chernoff argument 를 쓰는 것이 일반적. 적용하면:

\$\$
\begin{align}

\forall s >0 :

P[\lambda_{max}(\bar X) \ge t]


&=
P[\exp \Big[ \lambda_{max}(s \bar X) \Big] \ge \exp(st)]
\\

&=
P[ \lambda_{max}(\exp \Big[s \bar X \Big]) \ge \exp(st)]
\\



&le
\exp(-st) \cdot E \Big [ \lambda_{max}(\exp \Big[s \bar X \Big]) \Big ]
\\


&le
\exp(-st) \cdot E \Big [ \tr (\exp \Big[s \bar X \Big]) \Big ]


\end{align}
\$\$

\begin{itemize}
\tightlist
\item
  2번째 등식에선 exponential 함수의 spectral mapping property 과 monotonicity 사용
  function
\item
  standard Markov 부등식
\item
  \(\exp(s \bar X)\) 가 PSD Matrix 라는 사실 활용
\item
  trace 가 linear operator이며, it can commute with expectation
\end{itemize}

위의 전개에서 모든 \(s>0\) 에 inf를 적용하면 Chernoff argument 완성. 이제 \(tr(E[exp(sX)])\) 를 bound 해야 함. 일반적인 스칼라 케이스에서 평균의 exponential 은 그냥 prod 로 쓰일 수 있음. 이를 연장하여 우리는 개별 랜덤변수들의 mgf 생산까지도 끌고갈 수 있음. 하지만 매트릭스 exponential 에서 \(e^{X+Y} = e^X e^Y\) 려면 \(XY=YX\) 여야 함. 따라서 우리는 \(X_1 , \cdots, X_n\)의 임의의 실현값에 직접적으로 factorization 적용하는 건 불가능함. 이때 \textbf{Lieb's inequality} 적용하면 이 난점 돌파 가능.

\hypertarget{sub-gaussian-and-sub-exponential-matrices}{%
\subsection{Sub-Gaussian and sub-exponential matrices}\label{sub-gaussian-and-sub-exponential-matrices}}

실값 랜덤변수의 케이스와 같이, 우리는 랜덤 매트릭스의 class 를 이들의 mgf 사용해서 특성을 드러내는 것이 가능.

:::\{..def ``Sub-Gaussian random matrices''\}

symmetric Matrix \(X \in \mathcal S^{d \times d}\), 이때 \(E(X) = 0\), 는 이하를 만족할 경우 matrix 패러미터 \(V \in \mathcal S^{d \times d}_+\) 를 가지는 sub-Gaussian.

\[
\forall t \in \mathbb R: E \Big [\exp(tX) \Big ] \le \exp \left( \frac{t^2 V}{2} \right)
\]
:::

\begin{itemize}
\tightlist
\item
  ※Remark: 패러미터 \(V\) 를 가지는 Sub-Gaussian 랜덤 매트릭스는 패러미터 \((V , 0)\)을 가지는 sub-exponential이기도 하다.
\end{itemize}

\hypertarget{uxb79cuxb364-uxb9e4uxd2b8uxb9aduxc2a4uxc5d0-uxb300uxd55c-hoeffding-and-bernstein-bounds}{%
\subsection{랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds}\label{uxb79cuxb364-uxb9e4uxd2b8uxb9aduxc2a4uxc5d0-uxb300uxd55c-hoeffding-and-bernstein-bounds}}

\hypertarget{hoeffding-bound}{%
\subsubsection{Hoeffding bound}\label{hoeffding-bound}}

:::\{..def ``Hoeffding bound for random matrices''\}

Let independent 한 zero-mean symmetric 랜덤 매트릭스의 sequence \(\{ X_i \}^n_{i=1}\), 이에 더해 이 랜덤 매트릭스들은 패러미터 \(\{ V_i \}^n_{i=1} \in S_+^{d \times d}\) 를 가지는 sub-Gaussian 조건을 만족한다. 이때 우리는 이하와 같은 upper tail bound 를 얻는다.

\$\$
\begin{align}
&P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le d \exp \left( - \frac{nt^2}{2\sigma^2}\right), &&\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n V_i \|_{op}
\end{align}
\$\$

:::

\hypertarget{bernstein-bound}{%
\subsubsection{Bernstein bound}\label{bernstein-bound}}

:::\{..def ``Variance of random matrices''\}

랜덤 매트릭스 \(X \in S^{d \times d}\)에 대해, 이의 Var을 아래와 같이 정의한다. 이때 Var(X)는 자연스럽게 PSD.

\[
Var(X) = E(X^2 ) - \left[ E(X) \right]^2
\]

:::

:::\{..def ``Bernstein bound for random matrices''\}

bounded operator norm 을 가지는, zero-mean independent symmetric 랜덤 매트릭스의 sequence 를 \(\{ X_i \}^n_{i=1}\) 로 하자. 이에 더해 \(\exists b>0, \forall i : \| X_i \|_{op}\). 이때

:::

Let independent 한 zero-mean symmetric 랜덤 매트릭스의 sequence \(\{ X_i \}^n_{i=1}\), 이에 더해 이 랜덤 매트릭스들은 패러미터 \(\{ V_i \}^n_{i=1} \in S^{d \times d}\) 를 가지는 sub-Gaussian 조건을 만족한다. 이때 우리는 이하와 같은 upper tail bound 를 얻는다.

\$\$
\begin{align}
&P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le d \exp \left( - \frac{nt^2}{2\sigma^2}\right), &&\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n V_i \|_{op}
\end{align}
\$\$

:::

\$\$
\begin{align}
&P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le 2d \exp \left( - \frac{nt^2}{2(\sigma^2  bt)}\right), &&\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n Var(X_i) \|_{op}
\end{align}
\$\$

\hypertarget{generalization-to-non-symmetricrectangular-matrices}{%
\subsubsection{Generalization to non-symmetric/rectangular matrices}\label{generalization-to-non-symmetricrectangular-matrices}}

이렇게 symmetric (그리고 당연히 square) 매트릭스의 concentration bounds 를 살펴봤음. 하지만 이 bounds는 non-symmetric 에도, 그리고 nonsquare 에도 적용할 수 있도록 확장 가능함. 바로 \textbf{self-adjoint dilation} 을 사용해서.

랜덤 매트릭스 \(X_i \in \mathbb R^{d_1 \times d_2}\) 가 주어졌음. 이제 다음과 같은 매트릭스 생산:

\[
Y_i = \begin{bmatrix} 0_{d_1 \times d_1} & X_i \\ X_i ' & 0_{d_2 \times d_2}\end{bmatrix} \in \mathbb R^{(d_1 + d_2) \times (d_1 + d_2)}
\]

\(Y_i\) 가 symmetric 임을 보이는 건 쉬움. 더욱 중요한 것은, \(\|X_i \|_{op} = \|Y_i \|_{op}\) 임을 보이는 것도 가능.\footnote{Tropp, Joel A. ''User-friendly tail bounds for sums of random matrices.'' Foundations of computational mathematics 12.4 (2012): 389-434} 따라서 이하와 같으며, \(Y_i\)의 mgf 에 특정한 조건을 부여하는 것으로 위에서 진행해온 프로세스를 그대로 적용할 수 있다.

\[
P(\| \bar X \|_{op} \ge t)= P(\| \bar Y \|_{op} \ge t) 
\]

\hypertarget{survival-analysis}{%
\chapter{Survival Analysis}\label{survival-analysis}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  SA의 결과물은 보통 \emph{time-to-event}, 즉슨 대부분의 경우에 nonnegative이며, 이는 곧 time domain을 한정함.
\item
  time-to-event의 distribution은 보통 \emph{skewed}.
\item
  Survival data은 자주 \emph{right censored}. 조사 대상자들은 조사 기간중에만 생존했음을 알며, 조사 기간 넘어서 죽으면 해당 시간이 정확히 기록되지 않음.
\item
  tail probability. 충분한 후속연구 후에는, tail of survival curve에 해당하는 subject들이 보통 되게 적음. estimation of the tail of the survival curve can be quite difficult. tail에서 survival density는 엄청 적어짐. 따라서 총 표본 수가 많이 확보되어 있지 않으면 tail에 해당하는 분석결과는 확보하기가 어렵다.
\item
  모든 연구의 시간은 finite이므로 모든 subjects들에게서 발생한 event of interest 중 일부는 육안으로 관찰 못 할수도 있다. 장기적으로 발생은 했는데, 그게 우리 손닿는 곳에서 터지지 않았음.
\item
  일반적으로 관측안된 failure time 들이 포함되어 있으면 기존 통계 테크닉은 사용할 수 없음.
\item
  failure time 이 관측되지 않은 subject들은 censored 되었다고 표현.
\item
  censored observations를 포함한 자료에서 정보를 뽑아내는 것이 SA의 estimation methods의 목적.
\end{enumerate}

\hypertarget{censoring-sources}{%
\subsubsection{Censoring Sources}\label{censoring-sources}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adminisitrative censoring
\end{enumerate}

\begin{itemize}
\tightlist
\item
  event 발생 전에 연구 종료
  often independent of failure time
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Loss to follow-up
\end{enumerate}

\begin{itemize}
\tightlist
\item
  subject들이 더이상 트랙 불과, 관찰 하에 있지 않음 (후속연구 개시했는데 예전에 살던 사람이 동네 떠났음)
  censoring may be related (indirectly) to the failure time
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  withdrawl from study
\end{enumerate}

\begin{itemize}
\tightlist
\item
  너무 아프거나 증상이 낫던가 해서 연구에서 이탈
  dependent censoring (\emph{informative drop-out}), censoring이 failure time에 연관되어 있다는 점이 고민해야할 거리가 된다.
\end{itemize}

임시방편

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  censor된 시간을 failure time으로 인식. \(\bar X \le E(X)\) (underestimate).
\item
  censor 관측치를 전부 삭제. loss of infomration.
\end{enumerate}

\hypertarget{notation-1}{%
\subparagraph{notation}\label{notation-1}}

\(T_i\): potential failure time for the i-th subject
\(C_i\): potential censoring time for the i-th subject
\(X_i = \min(T_i , C_i )\) observed time
\(\delta_i = \begin{cases} 1, & T_i \le C_i & \text{(uncensored)} \\ 0, & T_i > C_i & \text{(censored)} \end{cases}\)

\hypertarget{right-censoring-most-of-the-course}{%
\subsubsection{Right Censoring (most of the course)}\label{right-censoring-most-of-the-course}}

Fail이 확실하게 터진 경우에만 fail, 이외의 경우에는 censor. 조사기간 종료까지 발병하지 않았거나, 이외의 이유로 종료 이전에 연구 이탈하면 양쪽 모두 censored.

\hypertarget{type-of-data-to-be-analyzed-in-survival-analysis}{%
\subparagraph{Type of Data to be analyzed in survival analysis}\label{type-of-data-to-be-analyzed-in-survival-analysis}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Type Ⅰ Censoring:
  특정 시점이 왔을 때 연구 종료. ex) 쥐한테 특정 영양소 먹이고 언제까지 생존하는지
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Progressive Type Ⅰ Censoring: 대상들이 다른, 고정된 sacrifice time 보유 ex) 도즈 레벨 4개로 나누고 각 그룹에 다른 sacrifice 기간 적용, 비용 효율화
\item
  Generalized Type Ⅰ Censoring: subject들이 각각 다른 시기에 연구에 참여개시하고 정해진 시간에 연구 종료됨. subject가 참여할 때 censoring time 다 알려짐.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Type Ⅱ Censoring:
  reliabilty 분석에서 흔함. 특정 횟수 failure 발생시 연구 종료.
\end{enumerate}

※ Right Censoring: 개인의 정확한 survival time은 follow-up period의 우측에서는 incomplete해짐.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Random Censoring:
  Censoring times are random.
\end{enumerate}

※ let's focus on right censoring. Suppose \(T_1 , \cdots, T_n \sim f(t)\) and \(C_1 , \cdots, C_n \sim g(c)\). Then, we observe \(X_i = \min(T_i , C_i )\) for \(i = 1, \cdots, n\). In type Ⅰ censoring, \(C_i\) is fixed (at \(C_r\) or \(C_{r_i}\)). In random censoring, \(C_i\) is random.

\hypertarget{left-censoring}{%
\subsubsection{Left Censoring}\label{left-censoring}}

less common in practice

\$\$
\begin{align}

\lambda(t) S(t)&= f(t) \\

\lambda(t) &= \dfrac{f(t)}{S(t)} \\

\lambda(t) &= \dfrac{f(t)}{} \dfrac{d}{dS(t)}\log S(t) \\


\end{align}
\$\$

\$\$
\begin{align}

\lambda(t) &= - \dfrac{d}{dt} \log S(t) \\

\lambda(t) &= - \dfrac {dS(t)}{dt} \dfrac{d}{dS(t)} \log S(t) \\

\lambda(t) &= - \dfrac {d[1-F(t)]}{dt} \dfrac{1}{S(t)} \\

\lambda(t) &= - (-f(t)) \dfrac{1}{S(t)} \\

S(t)\lambda(t) &= f(t)

\end{align}
\$\$

\[
A = A'\; \; \; \Longrightarrow \; \; \; \exists \text{basis for } C(A):\text{constisting of evec of nonzero ev's.}
\]

linear transformation, span, trace, nonsingular, null space

\[
tr(ABC) = tr(BCA)=tr(CAB)
\]
\[
r(A_{n \times n})=r, \; \; \; r[\mathcal{N}(A)] = n-r
\]

\(\lambda\) is ev of \(A\), \(v\) is evec of \(A\).

\$\$
\begin{alignat}{3}

&\forall \lambda_i \not = 0 
&&\; \; \; \Longrightarrow \; \; \; 
&&
&& \forall v_i : 
&& span(v_i) \subset \mathcal{C}(A)

\\

&A = A', \; \lambda_i \not = \lambda_j 
&&\; \; \; \Longrightarrow \; \; \; 
&& v_i \perp v_j,
&&
&&span(v_i, v_j) \subset \mathcal{C}(A)


\\

&\exists A^{-1} 
&&\; \; \; \Longrightarrow \; \; \; 
&& \prod \lambda\not = 0
&&
&&

\\

&A = A'
&&\; \; \; \Longrightarrow \; \; \; 
&& 
&&
&&\exists \text{basis for } \mathcal{C}(A) \text{ consists of } v_i \text{ of } \lambda_i \not = 0



\\

&A_{n \times n} = A', \; \prod \lambda \not = 0 
&&\; \; \; \Longrightarrow \; \; \; 
&& \mathcal C (A)=\mathbb R^n,
&&
&&span( v) = \mathbb{R}^n



\\

&A_{n \times n} = A', \; \forall \lambda_i \not = 0 
&&\; \; \; \Longrightarrow \; \; \; 
&& 
&&
&&span(\forall v_i) = \mathcal{C}(A) \subset \mathbb{R}^n






\\

&A_{n \times n} = A', \; \forall \lambda_i  = 0 
&&\; \; \; \Longrightarrow \; \; \; 
&& 
&&
&&span(\forall v_i) = \mathcal{N}(A)

\\

&A = A'
&&\; \; \; \Longrightarrow \; \; \; 
&& 
&&
&&\mathcal{N}(A) = \mathcal C (A)^\perp

\\

&A_{n \times n} = A'
&&\; \; \; \Longrightarrow \; \; \; 
&& 
&&
&&


\exists v_i : span(v_i) = \mathcal C (A), \; v_i \perp v_j 
\; \; \tiny {\bigoplus} \; \; \normalsize \exists A^{-1} : \mathcal C(A) = \mathbb{R}^n
\; \; \tiny {\bigoplus} \; \; \normalsize \text{if normalized, orthonormal}

\end{alignat}
\$\$

\hypertarget{section-10}{%
\section{}\label{section-10}}

\hypertarget{section-11}{%
\section{}\label{section-11}}

\hypertarget{section-12}{%
\section{}\label{section-12}}

\hypertarget{cox-regression}{%
\section{Cox Regression}\label{cox-regression}}

\hypertarget{proportional-hazards-model}{%
\subsubsection{Proportional Hazards Model}\label{proportional-hazards-model}}

Proposed by Cox (1972, JRSS-B), primarily to model the relationship between \textbf{hazard function} and \textbf{covariates}. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science.

Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc.

※ Data Structure

Observed data: \(\Big \{ X_i = T_i \wedge C_i, \; \; \; \Delta_i = I(T_i < C_i), \; \;\; \mathbf Z_i (\cdot) \Big \} \overset {iid} \sim\)

추가로 \(N_i = I(X_i \le t , \; \Delta_i = 1)\), \(Z_i(t)\) = covariate vector (possibly time-dependent).

\hypertarget{cox-ph-model}{%
\subsubsection{Cox PH Model}\label{cox-ph-model}}

\[
\lambda_i (t) = \lambda (t \vert Z_i ) = \lambda_0 (t) \exp (\beta' Z_i) \tag{Cox Model}
\]

semiparametric model:

\begin{itemize}
\tightlist
\item
  \(\exp(\beta ' Z_i)\), parametric assumption on covariate effects
\item
  multiplicative model
\item
  \(\beta\) : \(p \times 1\) vector, \(p < \infty\)
\item
  \(\lambda_0(t)\), nonparametric; is \(\infty\) dimensional
\item
  shape of hazard function is unspecified
\end{itemize}

Due to nonparametric component, \textbf{standard maximum likelihood theory} does \textbf{not} apply

Let \(Z_{ij}\) be the \(j\)-th element of \(Z_i\)
- \(\beta_j\) = difference in log hazards
- \(\exp(\beta_j)\) = ratio of hazards; assumed constant for all \(t\)

\begin{itemize}
\tightlist
\item
  \(\lambda_0(t)\): baseline hazard; common to all subjects, \(\lambda_0(t) = \lambda_i(t \big | Z_i = \mathbf 0)\)
\end{itemize}

The hazard ratio, \(\exp(\beta_j)\), is sometimes referred to as a \textbf{relative risk}
- risk = \textbf{probability}, not a rate
- hazard is a \textbf{rate}, not a probability
- in ratio of hazards, time dimension cancels out

Direction of effect:
\$\$
\begin{align}

\beta_j > 0: &&\uparrow\lambda_i &&\downarrow S_i(t)
\\
\beta_j < 0: &&\downarrow\lambda_i &&\uparrow S_i(t)


\end{align}
\$\$

Magnitude of effect is easy to interpret w.r.t. \(\lambda_i(t)\)

Cumulative hazard function:

\$\$
\begin{align}

\lambda_i (t) &= \lambda_0(t) \exp(\beta Z_i)
\\
\Lambda_i (t) &= \int_0^t \lambda_0(s) \exp(\beta Z_i) ds
\\
&= \Lambda_0(t) \exp(\beta Z_i)

\end{align}
\$\$

Survival function:

\$\$
\begin{align}
S_i (t) &= \exp \Big \{ -\Lambda_i (t) \Big\}
\\
&= \exp \Big \{ -\Lambda_0 (t) \exp(\beta ' Z_i)\Big\}
\\
&= S_0(t)^{\exp \Big \{ \beta'Z_i \Big\}}


\end{align}
\$\$

By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard:
- ex) randomized trial: treatment (\(Z_i=1\)) versus placebo (\(Z_i=0\)); \(\hat \beta = 0.405\) (\(\exp(\hat \beta)=1.5\))
- \(\lambda_i(t)\) for treated patients is 50\% more of that of the controls.
- irrespective of \(\lambda_0(t)\)

Nevertheless, \(\Lambda_0(t)\) is required in order to \textbf{determine \(Z_i\)'s effect on \(S_i(t)\)}, e.g.,

\$\$
\begin{align}

S(t \Big | Z_i = 0) = 0.95 && vs. && S(t \Big | Z_i = 1) = 0.93


\\
S(t \Big | Z_i = 0) = 0.70 && vs. && S(t \Big | Z_i = 1) = 0.59



\end{align}
\$\$

\hypertarget{cox-model-independent-censoring}{%
\subparagraph{Cox Model: Independent Censoring}\label{cox-model-independent-censoring}}

Independent censoring assumption is less stringent than in nonparametric estimation.

Assumption is often written as \(T_i \perp C_i \Big \vert Z_i\):
\$\$
\begin{alignat}{2}

&\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i < t+ \delta \Big | T_i \ge t , \; C_i \ge t , &&\; Z_i)
\\
= &\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i < t+ \delta \Big | T_i \ge t ,  &&\; Z_i)

\end{alignat}
\$\$

※ Note: \(C_i\) is allowed to depend on \(Z_i\)

\hypertarget{semiparametric-ph-model-general}{%
\subsubsection{Semiparametric PH Model: General}\label{semiparametric-ph-model-general}}

\begin{itemize}
\tightlist
\item
  General expression for multiplicative proportional hazards model:
\end{itemize}

\[
\lambda_i (t) = \lambda_0 (t) g(\beta ' Z_i )
\]

\(g(x)\) is link function, specified. \(\forall x: g(x) \ge 0\), \(\exists g''(x)\), and in special case, \(g(x) = \exp(x)\).

\begin{itemize}
\tightlist
\item
  Other choices for link function (e.g., Self \& Prentice, 1983):
  \(g(x) = 1+x = (1+x)^{-1} = \log(1+x)\)
\end{itemize}

※ Notes:
- not all choices of \(g(x)\) lead to clear interpretation of \(\beta_j\)
- certain choices of \(g(x)\) lead to numerical issues; e.g., likelihood is flat; local maxima, etc.
- \(g(x) \not = exp(x)\) has received little attention in the literature

\hypertarget{multiplicative-model}{%
\subsubsection{Multiplicative Model}\label{multiplicative-model}}

\textbf{Cox model} is a \textbf{multiplicative model}, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard.

\begin{itemize}
\tightlist
\item
  Additive models also been proposed
\end{itemize}

\[
\]

\hypertarget{proportional-hazards-regression-and-multiplicative-intensity-model}{%
\subsubsection{Proportional Hazards Regression and Multiplicative Intensity Model}\label{proportional-hazards-regression-and-multiplicative-intensity-model}}

\begin{itemize}
\tightlist
\item
  Recall Counting process: martingale representation
\end{itemize}

\$\$
\begin{align}

N(t) &= I(X\le t , \; \Delta = 1)
\\
Y(t) &= I(X \ge t)
\\
M(t) &= N(t) - \int_0^t Y(u)\lambda_0(u) e^{\beta ' Z } du \tag{1}
\\
\mathcal F_t &= \sigma \Big \{ N(u) , Y(u+) , Z: \; \; 0 \le u \le t \Big \}



\end{align}

\$\$

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  intensity \(l(u) = Y(u)\lambda_0(u) e^{\beta ' Z }\), therefore integrated form is cumulative intensity \(A(t)\).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Multiplicative Intensity Model:
\end{itemize}

\[
l(t) = Y(t)\lambda_0(t) e^{\beta ' Z(t) }
\]

\begin{itemize}
\item
  Counting process: \(N(t)\) = Number of events of a specified type that have occurred by time \(t\)

  \begin{itemize}
  \tightlist
  \item
    \(N(t)\) may take more than one jump
  \item
    multiple infections, repeated breakdowns, hospital admissions
  \item
    \(EN(t) < \infty\)
  \end{itemize}
\item
  At-risk process: \(Y(t)\), left-continuous process, \(1\) if failure can be observed at time \(t\), otherwise \(0\).

  \begin{itemize}
  \tightlist
  \item
    \(Y(t)\) can be used to represent situation in which a subject enter and exit risk sets several times
  \item
    \(Y(t)\) may be \(1\) even after an observed failure
  \end{itemize}
\item
  Covariate process: \(Z(t)\) = (bounded) predictable process

  \begin{itemize}
  \tightlist
  \item
    time-dependent treatment, risk factors
  \item
    model checking and relaxing PH assumption
  \end{itemize}
\item
  Baseline hazard function: \(\lambda_0(\cdot)\) = an arbitrary deterministic function
\item
  Filtration: \(\mathcal F_t = \sigma \Big \{ N(u) , Y(u+) , Z(u): \; \; 0 \le u \le t \Big \}\)
\item
  Martingale: \(M(t) = N(t) - \int_0^t l(u) du\)
\item
  Intensity function: \$ E \Big \{ dN(t) \Big \textbar{} \mathcal F\_\{t-\} \Big\} = l(t) dt\$
\item
  Data: \(n\) independent observations on \$ \Big \{ N(\cdot), ; Y(\cdot), ; Z(\cdot) \Big \}\$
\end{itemize}

\hypertarget{likelihood-conditional-marginal-and-partial-likelihoods}{%
\subsubsection{Likelihood; conditional, marginal and partial likelihoods}\label{likelihood-conditional-marginal-and-partial-likelihoods}}

\begin{itemize}
\item
  \(X =\) vector of observations; \(f_X(x, \theta) =\) density of \(X\)
\item
  \(\theta =\) vector parameter; \(\theta = (\beta ' , \phi')'\)
\item
  \(\beta =\) parameter of interest; \(\phi =\) nuisance parameter
\item
  \textbf{likelihood}: \(f_X(x, \theta) = f_{W|V} (w \Big | v, \theta )f_V (v, \theta)\)

  \begin{itemize}
  \tightlist
  \item
    \(X = (V', W')'\)
  \item
    infinite-dimensional \(\phi\)
  \item
    \(f_{W|V} (w \Big | v, \theta )\) does not involve \(\phi\) \(\Rightarrow\) use \(f_{W|V} (w \Big | v, \beta )\) (conditional likelihood)
  \item
    \(f_V (v, \theta)\) does not involve \(\phi\) \(\Rightarrow\) use \(f_V (v, \beta)\) (marginal likelihood)
  \end{itemize}
\end{itemize}

\[
X = (V_1 , W_1 , \cdots, V_K , W_K)
\]

\$\$
\begin{align}


f_X(x, \theta) &= f_{V_1 , W_1 , \cdots, V_K , W_K} (v_1 , w_1 , \cdots, v_K , w_K\; ;\; \theta)
\\

&= 
f_{V_1}(v_1 \; ; \; \theta)

f_{W_1 | V_1}(w_1 | v_1\; ; \; \theta)

f_{V_2 | V_1, W_1}(v_2 |  v_1, w_1\; ; \; \theta) \times \cdots

\\

&= \left \{ \prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \theta) \right \}


\left \{ \prod_{i=1}^K f_{V_i | P_i } (v_i \Big | p_i \; ; \theta) \right \}

\end{align}
\$\$

\$\$
\begin{align}


P_1 = \phi,& && P_i =(V_1 , W_1 , \cdots, V_{i-1} , W_{i-1})
\\
Q_1 = V1,& && Q_i =(V_1 , W_1 , \cdots , W_{i-1}, V_i)

\end{align}
\$\$

\$\prod\emph{\{i=1\}\^{}K f}\{W\_i \textbar{} Q\_i \} (w\_i \Big \textbar{} q\_i ; ; \theta) \$ is free of \(\phi\) \(\Rightarrow\) use \$ \prod\emph{\{i=1\}\^{}K f}\{W\_i \textbar{} Q\_i \} (w\_i \Big \textbar{} q\_i ; ; \beta) \$ (partial likelihood)

\hypertarget{partial-marginal-likelihoods}{%
\subparagraph{Partial \& Marginal Likelihoods}\label{partial-marginal-likelihoods}}

Focus on Proportional Hazards Model: i.e., \((X_i, \; \delta_i, \; Z_i), \; i = 1, \cdots, n\) (\(n\) independent triplets)

\$\$
\begin{align}

&\lambda(t \Big | Z ) = \lambda_0 (t) e^{\beta ' Z} &&S(t \Big | Z) = \Big \{ S_0(t) \Big \}^{e^{\beta ' Z}} \tag{1}

\end{align}
\$\$

위에서 \$ \lambda\_0 (t)\$는 \textbf{unspecified}.

\begin{itemize}
\tightlist
\item
  \textbf{Partial Likelihood}: assume no ties, absolutely continuous failure distribution
\end{itemize}

Suppose there are L observed failures at \(\tau_1 < \cdots < \tau_L\) (set \(\tau_0 \equiv 0\) \& \(\tau_{L+1} \equiv \infty\))

16.png

Let (i) be the label for individual failing at \(\tau_i\) (set \((L + 1) \equiv n + 1\)). Note \(t_{(i)} = \tau_i\)

Covariates for \(L\) failures: \((Z_{(1)}, \cdots, Z_{(L)})\). (Hereafter, condition on \$ \Big \{ Z\_i : i = 1, \cdots, n \Big \}\$)

Censorship times in \([\tau_i; \tau_{i+1})\): \((\tau_{i1}, \cdots, \tau_{i, m_i})\) with covariates \((Z_{(i,1)}, \cdots, Z_{(i,m_i)})\), i.e., \((i, j)\) is label for item censored at \(\tau_{ij}\)

17.png

The data can be divided into sets

\[
(V_1 , W_1, \cdots, V_{L+1} ,  W_{L+1})
\]

where, for \(i = 1, \cdots, L, L+1\),

\$\$
\begin{align}
V_i &= \Big \{ \tau_i , \tau_{i-1, j}  \; \; ; \; \; (i-1, j):j = 1, \cdots, m_{i-1} \Big \}

\\

and \; \; \; \;W_i &= \Big \{ (i) \Big \}


\end{align}
\$\$

18.png

19.png

GOAL: Build a likelihood on a subset of the full data set
- carrying most of the information about \(\beta\)
- carrying no information on nuisance parameters \(\Big \{ \lambda_0 (t) : t \ge 0 \Big \}\)

PROPOSAL: Generate likelihood of \(\Big \{ W_1, \cdots, W_L \Big \}\)

JUSTIFICATION, WHY?:
- Timing of events \(\Big \{ \tau_1 , \cdots, \tau_L \Big \}\) can be explained by \(\lambda_0(\cdot)\).
- Censoring \textbf{times and labels} can be ignored if we assume \textbf{non-informative censorship} (independent censoring).

So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data.

If \(Q_i \equiv (V_1, W_1 , \cdots, V_{i-1}, W_{i-1}, V_i)\) and \(\mathcal F_{\tau_i} \equiv (Q_i, Z)\), the partial likelihood is \(\prod_{i=1}^L P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)\), i.e., given the risk set at \(\tau_i\), and given event occurs at \(\tau_i\).

Denote \(R_i \equiv \Big \{ j : X_j \ge \tau_i \Big \}\) as risk set at \(\tau_i\). Then, by the assumption of independent censoring,

\$\$
\begin{align}
P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)




&=
\frac{


P \Bigg \{ t_{(i)} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - (i)} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} 
}{

\sum\limits_{l \in R_i} 
\left[
P \Bigg \{ t_{l} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - l} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}
\right]
}
\tag{a}





\\
\\
\\


&=
\frac{
d\Lambda \Big( \tau_i \Big | Z_{(i)} \Big)
\prod\limits_{j \in R_i - (i)} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \}
}{
\sum\limits_{l \in R_i} \left [ d\Lambda \Big( \tau_i \Big | Z_{l} \Big)
\prod\limits_{j \in R_i - l} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \} \right ]
}


\; \; \; \div \; \; \; \frac{d\tau_i}{d\tau_i}

\tag{2}
\\
\\
\\

&= \frac{\lambda\Big(\tau_i \Big | Z_{(i)} \Big)}{ \frac{P \Big\{T\in [t, t+dt) \Big | T \ge t , Z \Big\}}{dt}= \sum\limits_{l\in R_i} \left[ \lambda\Big(\tau_i \Big | Z_{l} \Big) \right]}

\; \; \; \overset {(1)}{=}  \; \; \; 


\frac{\exp(\beta ' Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta ' Z_{l})}





\end{align}
\$\$
- at (a), \(P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} = 1 - P \Bigg \{ t_{j} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}\)
- at (2), \$ d\Lambda \Big( \tau\emph{i \Big \textbar{} Z}\{j\} \Big) = 0\$

Thus, the \textbf{Partial Likelihood} is

\[
\prod^L_{i=1}\frac{\exp(\beta ' Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta ' Z_{l})} = L(\beta)\tag{3}
\]

Note: unspecified \(\lambda_0(\cdot)\) + noninformative censoring \(\Rightarrow\) \(\prod\limits_{i=1}^L f_{V_i \big | P_i} (v_i \Big | p_i ; \theta)\) contains little or no information about \(\beta\).

\begin{itemize}
\tightlist
\item
  Counting process notation:
\end{itemize}

\$\$
\begin{align}
L(\beta) = \prod^n_{i=1}\prod_{t\ge0} \left \{ 

\frac{\exp(\beta ' Z_{i})}{\sum\limits_{j=1}^n Y_j(t) \exp(\beta ' Z_{j})}

\right\}^{dN_i(t)}


, && dN_i(t) = \begin{cases} 1 & N_i(t) - N_i {(t-)} =1\\0 & o.w.\end{cases}

\end{align}
\$\$

\begin{itemize}
\item
  Maximum partial likelihood estimator (MPLE): \(L( \hat \beta) = \max_\beta L(\beta)\) (using Newton-Raphson (NR) algorithm)

  \begin{itemize}
  \tightlist
  \item
    Specifically, the \textbf{log partial likelihood} is then
  \end{itemize}

  \[
  l(\beta) = \sum_{i=1}^n \int_0^\infty \left[ Y_i (t) Z_i \beta - \log\left( \sum_{j=1}^n Y_j(t) \exp(\beta ' Z_j ) \right) \right]dN_i(t)
  \]

  \begin{itemize}
  \tightlist
  \item
    \textbf{The score vector}, \(U(\beta)\), can be obtained by differentiating \(l(\beta)\) w.r.t. \(\beta\):
  \end{itemize}

  \$\$
  \begin{alignat}{2}
  U(\beta) &= \sum_{i=1}^n \int_0^\infty \Big \{ Z_i - \bar Z(\beta, t) \Big \}&&dN_i (t)

  \\

  &= \sum_{i=1}^n \int_0^\infty \left \{ Z_i - \frac{\sum_{i=1}^n Y_i (t) Z_i \exp(\beta ' Z_i)}{\sum_{i=1}^n Y_i (t) \exp(\beta ' Z_i)} \right \}&&dN_i (t)

  \end{alignat}
  \$\$

  \begin{itemize}
  \item
    where \(\bar Z(\beta, t)\) is a weighted mean of \(Z\) over those observations still at risk at time \(t\).
  \item
    The information matrix, \(\mathcal I(\beta)\), is the negative second derivative where
  \end{itemize}

  \$\$
  \begin{align}

  \mathcal I(\beta) &= \sum\limits_{i=1}^n \int_0^\infty V(\beta, t) dN_i(s)

  \\
  \\

  V(\beta, t) &= \frac{\sum\limits_{i=1}^n Y_i(t) \exp(\beta ' Z_i ) \Big \{ Z_i - \hat Z (\beta, t)\Big\}'\Big \{ Z_i - \hat Z (\beta, t)\Big\}}{\sum\limits_{i=1}^n Y_i(t) \exp(\beta ' Z_i )}

  \end{align}
  \$\$

  \begin{itemize}
  \tightlist
  \item
    and \(V(\beta, t)\) is the weighted variance of \(Z\) at time \(t\).
  \end{itemize}
\end{itemize}

Then, the MPLE, \(\hat \beta\), is found by solving the partial likelihood equation: \(U(\hat \beta) = 0\).

Under some regularity conditions, \(\hat \beta\) is consistent and asymptotically normally distributed with mean \(\beta\) and variance \(E \Big \{ \mathcal I(\beta) \Big\}^{-1}\) (will be shown later.)

The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value \(\hat \beta^{(0)}\)).

\[
\hat\beta^{(n+1)} = \hat\beta^{(n)} + \mathcal I ^{-1} \Big( \hat \beta^{(n)}\Big) \cdot U \Big( \hat \beta^{(n)}\Big)
\]

※ Note:
1. (incredibly) Robust algorithm!
2. \(\hat \beta^{(0)} = 0\) usually works.

\hypertarget{cox-proportional-hazards-model}{%
\subsubsection{Cox Proportional Hazards Model}\label{cox-proportional-hazards-model}}

Cox model:

\$\$
\begin{align}

\lambda_i(t) = \lambda(t \Big | Z_i ) 
&= \lambda_0 (t) \exp(\beta ' Z_i) 
\\
&= \lambda_0(t) \exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})
\\
&\Updownarrow
\\

\log \lambda(t \Big | Z_i ) &= \log \Big[ \lambda_0(t) \Big] +\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik}
\\
S(t \Big | Z_i ) &= 



\Big[ S_0(t) \Big]^{\exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})}


\end{align}
\$\$

※ Note:

\$\$
\begin{align}
\lambda_0 (t) &= \lambda(t \Big | Z_1 = \cdots = Z_k = 0)
\\
\\
\exp(\beta_1 Z_{1} + \cdots + \beta_k Z_{k}) &= RR 



\\
&= \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 = \cdots = Z_k = 0)} \tag{1}
\end{align}
\$\$
- (1) is relative risk of hazard of death comparing covariates values \(Z_1,\cdots, Z_k\) to \(Z_1 = \cdots = Z_k = 0\)

Interpreting Cox Model Coeffcients: \(\beta_k\) is the log RR (hazard ratio) for a unit change in \(Z_k\), given all other covariates remain constant, i.e.,

\$\$
\begin{align}


\frac
{\lambda\Big[t \Big | Z_1 , \cdots, (Z_{k'}+1), \cdots, Z_k \Big]}
{\lambda\Big[t \Big | Z_1 , \cdots, Z_{k'}, \cdots, Z_k \Big]} 


&= \exp \Big (\beta_1 \cdot 0 + \cdots + \beta_{k'} \cdot (Z_{k'} +1 - Z_{k'}) + \cdots + \beta_k \cdot 0 \Big)

\\

&= \exp(\beta_{k'})


\end{align}
\$\$

The RR comparing 2 sets of values for the covariates \((Z_1 , \cdots, Z_k)\) vs.~\((Z_1' , \cdots, Z_k')\):

\[
RR = \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 ', \cdots, Z_k')} =\exp \Big \{ \beta_1(Z_1 - Z_1') + \cdots + \beta_k(Z_k - Z_k') \Big \}
\]

20.png

\hypertarget{comparison-of-nested-models}{%
\subsubsection{Comparison of Nested Models}\label{comparison-of-nested-models}}

\begin{itemize}
\tightlist
\item
  Nested Models:
\end{itemize}

\$\$
\begin{align}

\lambda(t) &= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p + \beta_{p+1} Z_{p+1} +\cdots + \beta_{k} Z_{k}\Big) \tag{Full Model}

\\

&= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p \Big) \tag{Reduced Model}


\end{align}

\$\$

To test:

\begin{itemize}
\tightlist
\item
  Nested Models:
\end{itemize}

\$\$
\begin{align}

&H_0:  &&RM && \Leftrightarrow && H_0: \beta_{p+1} = \cdots = \beta_k = 0
\\
&H_A:  &&RM && \Leftrightarrow && H_A:  \not = \text{ somewhere}

\end{align}

\$\$

Use the \textbf{partial likelihood ratio statistic}, \(X^2_{Cox} = -2 \Big[ \log PL(RM) - \log PL(FM)\Big]\).

Under \(H_0\): Reduced model, and when \(n\) is large:
\[
\begin{align}
X^2_{Cox} \sim \chi^2_{k-p} && k-p \text{ is the ## of parameters set to 0 by }H_0
\end{align}
\]

20.png, 21.png

\hypertarget{stratification}{%
\subsubsection{Stratification}\label{stratification}}

Two Ways to Stratify. Suppose a confounder \(C\) has 3 levels on which we would like to stratify when comparin
g \(\lambda(t \Big | E )\) and \(\lambda ( t \Big | \bar E )\). How? \(X_E = \begin{cases}1&E&\text{(exposed)}\\0&\bar E&\text{(not exposed)}\end{cases}\)

22.png

\begin{itemize}
\tightlist
\item
  Which Way to Stratify?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder \(C\) may be inadequately controlled.
\item
  Proportionality assumption can be checked using time-dependent covariates.
\item
  True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If \(C\) can be measured continuously and the strata were formed by grouping values of it, better control for \(C\) might be achieved with continuous (could be time-dependent) covariate adjustment.
\item
  If \(C\) is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of \(C\). However, we can estimate \(\lambda_{0i}(t)\) for each stratum then we can estimate a RR function.
\item
  True stratification generally requires more data to obtain the same precision in coefficient estimates.
\end{enumerate}

23.png

24.png

\hypertarget{test-statistics}{%
\subsubsection{Test statistics}\label{test-statistics}}

The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood.

25.png

Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least.

26.png

When \(p = 1\) and the single covariate is categorical, the score test is identical to the log-rank test.

27.png

\hypertarget{handling-ties}{%
\subsubsection{Handling ties}\label{handling-ties}}

Real data sets often contain tied event times.

\begin{itemize}
\tightlist
\item
  When do we have ties?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Continuous event times are grouped into intervals.
\item
  Event time scale is discrete.
\end{enumerate}

Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood.

When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the \(i\)-th event at time \(t_i\) is \(\frac{\exp(\beta ' Z_i)}{ \sum\limits_{j \in R_i} Y_j(t_i) \exp(\beta ' Z_j)}\)

Two commonly used methods are
1. Breslow approximation
2. Efron approximation

Example: Assume 5 subjects are at risk of dying at time \(t\) and two die at the same time \(t\) (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either

28.png

29.png

30.png

\hypertarget{filtrationuxc758-uxac1cuxb150uxc744-uxc815uxbcf5uxd558uxc790}{%
\section{Filtration의 개념을 정복하자!}\label{filtrationuxc758-uxac1cuxb150uxc744-uxc815uxbcf5uxd558uxc790}}

도대체 Filtration(Filtration event)을 정복해야 하는 이유가 무엇인가?

금융공학 특히 금융수학을 공부하는데 있어서 가장 핵심이 되는 것 중에 하나가 Stochastic Differencial Equation 이다. 금융수학책들을 보면 다들 처음에는 확률(이 바닥에서는 측도론을 건드리는 것이 일반적)을 다룬 다음에 Stochastic Process를 다루고 Ito's lemma를 거쳐 Black Sholes PDE 한번 찍어주고 Girsanov를 돌아서 Feynmman-Kac Theory로 끝내곤 한다.

특히 표준 금융수학 전반에 걸쳐서 Stochastic Process가 들어가는데 개인적으로는 이거 처음에 개념잡기가 힘들었다.. 왜냐하면 확률을 측도론(Measure Theory)에서 접근을 해야 하니 측도론을 조금은 알아야 하고(덧붙여 약간의 함수해석학\ldots) Random process, Stopping Time\ldots{} 등등\ldots{} 이것들의 성질이 Ft-measurable이므로 Ft-measurable이라는 의미를 잘 알아야 할 필요성까지 있기 때문이다.

뭐 Ft-measurable, 좀더 분해해서 Ft라는 filtration 과 measurable이라는 성질을 논리적으로 완벽하게 정의하는데 드는 노력은 A4용지에 반정도 끄적이면 충분하다. 그러니 어디서 누가 물으면 답변하는 정도로는 그냥 암기해 버리면 그만이 아닐까 생각한다.

그러나 정의를 주저리주저리 외우고 다닌다고 하는 것은 그 대상을 아는 것은 아니다.\ldots{} 애매한 문제에 엄밀한 판결을 내릴 수 있도록 능력이 되려면 수학적 정의가 포함하는 세계가 머리속에 익숙해 져야 한다고 생각한다.

어째든지 Random process이던 Stopping Time 이건, Girsanov이건간에, 수학적인 내용이 나오면 적어도 머리속에는 간략화되고 가시적인 예제들이 Simulation되어야지 그 개념들이 `눈에' 보이게 되는데 Filtration의 구체적인 모습들이 떠오르지 않으니까 나머지도 거기서 더 이상 이해가 되지 않았다. 이것이 본인이 Filtration을 한번 손봐야 겠다고 맘먹은 직접적인 동기이다.

\hypertarget{random-processuxb97c-uxc774uxc57cuxae30-uxd558uxae30uxae4cuxc9c0uxc758-uxae34-uxc5ecuxc815uxc758-uxc694uxc57d}{%
\subsection{Random Process를 이야기 하기까지의 긴 여정의 요약}\label{random-processuxb97c-uxc774uxc57cuxae30-uxd558uxae30uxae4cuxc9c0uxc758-uxae34-uxc5ecuxc815uxc758-uxc694uxc57d}}

확률공간 (Ω, F, P)의 정의에 대해서 이야기하자면 많은 사람들이 이미 알겠지만 측도론(Measure Theory)에 대한 고된 과정을 거쳐야지만 비로서 이야기할 수 있게 된다. Measure Theory는 미적분 함수해석학 등을 최신(?)관점에서 접근하도록 만들어진 이론체계인데 실해석학(Real Analysis)이라는 과목에서 주로 다루게 된다. 여기에서 Measure라는 개념 -- 우리말로 하면 측도 라는 것은 말 그대로 측정한다는 것인데 이런 류로 쉽게 생각할 수 있는 것은 `길이' 이다\ldots. 혹은 넓이, 부피, 기타 등등. 여기에 쓰이는 측도의 개념을 확률에다가 접근 시킨 사람이 콜모고로프라는 라는 것은 이미 널리 알려진 바이다. 길이, 확률의 기초적 개념은 초딩때 이미 섭렵했는데 굳이 어렵게 이해할 필요가 있는가 할 수도 있겠지만 아무래도 무한대이고 연속의 세계에서는 별의별 해괴한 일이 벌어지기 때문에 유치한(유치하다는 것은 경멸적인 이야기가 아니라 덜 세련된\ldots{} 정도로 생각을 해주면 된다.) 차원의 접근방법은 더 이상 통하지 않고, 집합론, 해석학의 고등 주제들을 총 동원해야 모호한 문제에 비로소 해답을 내릴 수 있다. 그러니 해석학을 하기 위해서는 집합론을 먼저 알아야 하는데 이것도 중고딩때 하던 겉핥기 식의 집합론이 아닌 무한차원을 다룬 진검승부의 집합론이 필요하다. 하여튼지 간에 이렇게 금융수학을 공부하기 위해서 선행적으로 해야 할 아주 높은 산들이 산적해 있는데.. 이걸 다 언급하는 것은 이 글의 주제를 넘어서는 것 같구\ldots{} 차후에 `금융수학을 공부하기 위한 로드맵'에 좀더 자세히 언급하겠다. 여기서 이야기 하고 싶은 것은 \textbf{확률과정}(Random Process)를 실해석학 위에서 가지고 노는 것은 나름대로 다 이유가 있다는 말을 하고 싶은 것이다. 기존의 유치한 확률론으로 접근해서 나름대로 이론을 쌓을 수 있다면 아주 happy한 case이지만 그렇다 하더라도 표준적으로 쓰여있는 paper나 text가 마팅게일이니, Girsanov니.. 이런 식으로 쓰여져 있으니 뭐라고 하는지 이해는 할 수 있어야 할 것 아닌가, 더욱이 수학이 어렵다고 하는데 솔직히 공부하는 것은 아주 어려운 것 맞다. 하지만 어려운 것은 익숙지 않다는 것뿐이다. 익숙해지면 세상이 참 쉽게 보인다. 복잡한 것은 수학이 아니라 세상이다. 공부하기 어려운 수학에 익숙해지면 복잡하게만 보였던 세상이 수학에 의해서 간략하게 보이게 된다. 세상 만만하게 보인다는 이야기이다. 어렵게 공부한 사람만 볼 수 있으니 개인적 보람도 아주 크다.

\hypertarget{sigma-algebrasigma-field}{%
\subsubsection{Sigma-Algebra(Sigma-Field)}\label{sigma-algebrasigma-field}}

Sigma-Algebra 라는 것은 measure를 다루기 위한 기본 개념인데 Sigma-Field와 같은 개념이다. 확률을 다루는 바닥에서는 Sigma-algebra 대신에 Sigma-Field라는 말을 쓴다. 참고로 Algebra, Field 라는 것은 Abstract Algebra(추상대수학)이라는 수학의 큰 줄기와 그 안의 체(Field)를 연상시키는데 연결고리에 대해서 약간의 심증은 가지고 있지만 물증은 찾지 못했다. 하여튼 간에 집합 A 위의 Sigma-Algebra(본인은 이 용어를 쓰겠다)의 정의는 다음의 말이 되는 A의 부분집합 E 들의 모임이다.
1. 공집합과 A는 Sigma-Algebra에 속한다.
2. E가 Sigma-Algebra에 속하면 E의 여집합도 Sigma-Algebra에 속한다.
3. E1과 E2가 Sigma-Algebra에 속하면 E1과 E2의 합집합도 Sigma-Algebra에 속한다.

뭐 여기까지는 상식적으로 이해가 된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Ei(I는 집합의 첨수족이고 자연수N의 원소이다) 가 Sigma-Algebra에 속하면 모든 Ei 의 합집합도 Sigma-Algebra에 속한다.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  과 (4) 는 같은 이야기 인 것이 아닌가? 하는 의문이 있을 수 있겠다. 즉 (3)을 반복적으로 적용하면 결국 (4)가 아닌가 하는 생각이 바로 그것이다. 답은 ``같지 않다''이다. 이것이 다르다는 것을 이해하는데 에는 집합론을 깊이 아는 것이 필요하다. 뭐 그것은 그러려니 하자\ldots. 그런데 문제는 이것뿐만이 아니다. (4) 의 내용을 이렇게 바꾸어 말할 수 있는가?
\end{enumerate}

「Sigma-Algebra에 속하는 모든 E들을 무한히 합집합을 취한 것도 Sigma-Algebra에 속한다」

답의 yes, no 차원을 떠나서 위의 문제는 참으로 무책임한 질문이다. 왜냐하면 \textbf{무한히} 라는 것도 모호한 말이기 때문이다. 정확히는 \textbf{가부번수만큼} 합집합을 취한 것이 Sigma-algebra에 속한다. 가부번수라는 것은 자연수의 개수와 같으므로 위의 (4) 라는 표현을 쓴 것이다. 무한에는 가부번수라는 것도 있고 비가부번수가 있다. 짝수, 홀수, 자연수, 유리수등등 이것이 다 같은 개수를 가진다고 생각을 하고 그것을 가부번수라고 한다. 그리고 실수 무리수 같은 수는 비가부번 수이다. 그러므로 \textbf{(4) 에서 I 가 N 의 집합이 아닌 실수R의 집합이나. 무리수Qc 의 집합이라고 적어 놓으면 더 이상 Sigma-algebra가 아닌 다른 무엇이 되고 마는 것이다}.
참고로 (4)의 조건이 없어지면 Sigma-algebra가 아닌 Algebra가 된다. 참고로 컴퓨터 이론의 기초를 이루는 2진수 연산인 \textbf{Bool algebra}(불대수)도 따지고 보면 여기서 말하는 algebra이다. 그리고 (3) 의 조건을 비가부번수까지 포함해서의 합집합에 대해서 라는 조건으로 바꾸어주고 유한개의 교집합에 대해서 닫혀 있으면 \textbf{위상(Topology)}가 된다. 이렇듯 쉽게 보이는 것도 엄밀하게 따지지 않으면 안 되는 이유가 바로 이것이다.

무한이고 연속인 것을 머리 속에서 엄밀한 Simulation을 할 수가 없는데 이럴 경우 쉽게 볼 수 있는 간단한 discrete case를 가지고 머리 속에서 가지고 놀면 된다. 대상을 간단하게 한다고 하지만 그 대상에 대해서 무한과 연속을 다루는 규칙을 똑같이 적용하면 적어도 오류에 다다르지는 않는다. 그리고 때때로 그 결과는 그대로 연속일 때로 확장시켜 생각해도 된다. 물리학에서도 discrete로 모델을 만들고 모델을 미소변화량에 대한 연속모델로 만드는 것과 비슷하다. 게다가 \textbf{Caratheodory Extension}와 \textbf{Pi-System} 같은 도구들은 이론적으로 그러한 것이 타당하다는 보장까지 하니\ldots{} 맘놓고 생각해도 된다. Caratheodory Extension 이니 Pi system이니 하는 것은 일단은 몰라도 된다. 이제 Sigma-Algebra에 대해서 조금 더 생각해 보자.

A=\{w1,w2, w3\}

인 A의 \textbf{(2개의 원소를 가진)} Sigma Algebra \(F\)들을 구해보면

F1=\{ Ø, A\}

위 F1은 A위에서 Sigma Algebra의 1,2,3 을 만족시킨다. \textbf{유한집합이므로 3을 만족시키는 것은 4도 만족시킨다}. 하지만 \textbf{이것은 무한집합에서는 일반적인 것은 아니다}.

F2=\{ Ø, \{w1\}, \{w2,w3\}, \{w1,w2, w3\}\}

F3=\{ Ø, \{w1\}, \{w2\}, \{w3\}, \{w1, w2\}, \{w2, w3\}, \{w1, w3\}, \{w1, w2, w3\}\}

어째든지 F1, F2, F3 셋 다 A위의 Sigma -- Algebra이다. 그리고 F1⊆F2⊆F3이다.

F1, F2, F3, 중에서 \{w2, w3\}을 포함하는 Sigma-Algebra 는 F2, F3이다. 그런데 F2와 F3중에서 크기가 작은 것은 F2이다. 즉 \textbf{F2는 \{w2, w3\}을 포함하는 가장 작은 Sigma-Algebra}이다. 이것은 \{w2, w3\}이 생성(generate)하는 Sigma-Algebra이다. 기호로는 Sigma(\{w2,w3\}) 이다. 또한 Sigma(\{w1, w3\})=F3이다. 그리고 짐작을 했겠지만 A의 모든 부분집합의 모임인 \textbf{P(A)가 가장 큰 Sigma Field이다}.

어떤 집합(A)의 모든 열린집합들이 Generate하는 Sigma algebra를 \textbf{Borel Field} 라고 하고 B(A) 라고 쓰고 그 원소를 \textbf{Borel Set}이라고 한다. 어떤 집합이 실수의 집합이면 B(A)는 실수의 모든 열린집합들이 Generate하는 Sigma algebra 가 된다. 이딴거 어따쓰나 생각할지 모르겠지만 이것이 바로 \textbf{`길이'} 라고 부를 수 있는 대상들의 모임인 것이다. 길이measure도 어렵게 말하면 lebegue measure라고 한다.

머리에서 김 나겠지만 좀더 생각해 보자. **수직선 위의 어느 한 점으로 이뤄진 집합도, 그러한 점들이 자연수개수만큼씩 있는 집합도 다 \_\_Borel set\_\_이므로 길이를 생각할 수 있다\textbf{. 그 길이는 무엇일까? 답은 0 이다. 0과 1 사이의 모든 유리수 집합도 그 길이는 0이다. 가부번 집합의 길이는 0이 된다. }연속적인 실수의 구간은 역시 Borel set\textbf{이고 }양끝의 값의 차이가 당근 길이이다\textbf{. 그리고 그 구간에서 가부번 집합을 뺀 -- 예를 들어 실수에서 유리수를 뺀 무리수의-- 길이도 양끝 길이의 차이와 같다 왜냐하면 가부번 집합의 길이가 0이기 때문이다. }무리수구간의 길이\textbf{는 같은 끝점을 가진 실수 구간의 길이에서 유리수 길이를 빼야 하는데 }그 값, 즉 유리수의 길이,**이 0이므로 실수 구간의 길이와 같게 된다.

\textbf{가부번 집합}이 아닌 경우에 반드시 길이가 있는가? 답은 No 이다. 칸토르 집합의 경우 \textbf{비가부번 집합}이지만 전체 길이는 0 인 황당한 case 가 있기는 있다.

가부번, 비가부번 집합이란 둘 다 무한집합(원소의 개수가 무한개인 집합)을 의미한다.

참고로 측도가 0인 집합을 영집합(Null Set)이라고 하는데 해석학이건 확률론이건 확률미분방정식(Stochastic Differential Equation) 등에서 의외로 중요한 개념이므로 반드시 한번 더 보고 가자.

또한 실수에서 길이를 생각할 때 \textbf{\textbf{왜} 실수집합의 \textbf{모든 부분집합} 위에서 길이를 생각하지 않고 꼭 Borel Set위에서 정의를 하냐}고 생각할 수 있겠는데\ldots{} 이것은 아마도 실수의 부분집합들 중에 길이의 대상이 되기에 부적합한 부분집합들이 존재하기 때문이라고 생각된다.

솔직하게 이쯤 되면 이제 머리 속에서 속속들이 Simulation을 하는 것은 포기해야 한다. 어떤 집합은 (보통) 무한집합인데 무한집합의 Sigma-algebra를 적는 것은 사실상 불가능 할뿐더러 열린집합들의 모임이라는 것도 그리 생각하는 것이 쉽지 않다. 그러니 그것이 generate하는 것을 머리에 어떻게 떠올린다는 것인가? 수학도들은 숱한 반복적인 증명연습과 연습문제 풀이로 장님 코끼리 만지듯이 \textbf{감각을 키워나가지만} 문제는 시간이다\ldots{} 하루아침에 되는 것이 아니기 때문이다.

그렇지만 이것만 우선 먼저. 측도라는 것은 측정에 관한 이야기이다. 길이도 가장 간단한 측도이다. 길이의 대상이 되는 것들을 생각해 보자. 각각의 대상을 합해 놓아도 길이의 대상이 된다. 뿐만 아니라 \textbf{두 측도 값의 합이 바로 합집합의 측도값이 된다. Sigma--Algebra의 특성인 `합집합에 대해서 닫혀 있음'이 바로 이것을 의미한다. }

위의 A집합에 대해서 F2를 생각해 보자.

F2=\{ Ø, \{w1\}, \{w2,w3\}, \{w1,w2, w3\}\}

Ø → 0
\{w1\} → 0.4
\{w2, w3\} → 0.6
\{w1,w2,w3\} → 1

이렇게 Sigma Algebra의 각 값에 대해서 측도 값을 부여하였다. \textbf{물리적인 의미는 없고}, \textbf{측도의 논리}에 틀리지 않게 구성이 되어 있다. 한번 보자 ``어떠한 원소들의 여집합이 Sigma Algebra의 원소이다.''
확률의 경우를 생각해 보면 \textbf{어떤 사건이 일어난 확률이 \textbf{있다면} 그것이 일어나지 않을 확률이 반드시 \textbf{있다}}는 의미와 같다.

있다면 = \(\sigma\)-field에 속한다면
있다 = \(\sigma\)-field에 속한다

``어떠한 원소들의 합집합이 Sigma Algebra의 원소이다.''

또한 \textbf{두 독립적 사건의 확률을 각각 계산할 수 있다면 반드시 두 사건 중 하나가 일어날 확률도 계산할 수 있다}는 것을 의미한다.
또한 \textbf{두 독립적 사건의 동시에 일어날 확률(합집합)은 각 확률(measure)의 합}이다.

이러한 생각으로 위 측도값들을 보면 전혀 모순이 없다는 것을 알 수 있다. 물론 이러한 측도값은 하나만 있는 것이 아니다.

Ø → 0
\{w1\} → 0.2
\{w2, w3\} → 0.8
\{w1,w2,w3\} → 1

이렇게 해도 부여한 측도값에는 전혀 문제 없다.

\textbf{그런데 \{w2\}에 대해서 측도값(확률)을 부여할 수 있는가?} 예를 들어 \{w2\}라는 사건이 존재한다면 뭐 억지로 어떤 값을 부여 했다고 하자. 그러면 \{w2\}가 일어나지 않는 경우에 대한 확률을 구할 수 있을까? 게다가 \{w1\} 또는 \{w2\}가 일어날 사건도 생각할 수 있는가? 대답할 수 없을 것이다. \textbf{이러한 예는 왜 확률을 생각할 때 Sigma Algebra를 생각해야 하는지를 설명해 준다.}

즉, \{2\}는 가측(measurable)인가?

\hypertarget{ft-measurable}{%
\subsection{Ft-measurable}\label{ft-measurable}}

위의 내용은 초보자에게는 접근할 수 있는 흥미를, 이미 내용을 알고 있는 사람들에게는 일종의 쉬어가는 페이지가 되었을 것 같다. 이제는 좀더 엄밀하게 접근을 하려고 한다.

Ft-measurable 이라는 것은 Ft라는 Filtration에 measurable 하다는 이야기이다. \textbf{Filtration}은 Sample Space Ω 의 Sigma Algebra 들의 모임인데 Ft1⊆Ft2⊆Ft3 (t1\textless t2\textless t3) 로 되어 있어서 시간이 지날수록 점점 Sigma Algebra들이 이전 \(\sigma\)-Algebra를 포함하면서 커지도록 되어 있다. 이 절의 내용은 바로 이 Filtration의 몇 가지 가시적인 예제를 보여줄 것이고 그것이 엄밀한 수학적 정의와 어떻게 연결되는지를 따져 볼 것이다. 그렇게 해서 얻어진 가시적인 예제들은 장차 Stochastic Process에서 나오는 여러 가지 수학적인 개념들을 머리에서 Simulation 해서 각자의 이해의 영역으로 확보하는 과정에서 크나큰 역할을 하기만을 바랄 뿐이다.

\hypertarget{uxac00uxce21measurableuxc774uxb780}{%
\subsubsection{가측(measurable)이란}\label{uxac00uxce21measurableuxc774uxb780}}

먼저 measurable의 정의를 보자. Measurable의 의미를 따지기 전에 우선 임의의 하나의 함수를 생각해 보자. 그러한 함수는 집합A의 원소에서 실수로 간다고 하자. \$f:A \Longrightarrow R

위와 같은 예가 될 수 있겠다.

그 다음은 역상에 대해서 생각해 보자. (역상도 집합이다.) A의 부분집합 Ω 위로의 역상은 \(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\) 으로 정의된다.

\(f\)의 정의역은 \(A\), 치역은 \(E\). 단, E는 보렐집합 (가측집합).
역함수, 역상과 \(\sigma\)-algebra의 관계는?

조금만 생각해 보면 \(f^{-1}\)는 결국 다음과 같은 하나의 함수이다.

\[
f^{-1} : B(R) \rightarrow \sigma
\]

Sigma(\(\sigma\))는 (Ω 위의 = \(\Omega\)가 생성하는) Sigma algebra이다. 즉 정의구역은 Borel Set(\(B(R)\)) 들이고 공변역(치역)은 Ω의 Sigma algebra이다.

E는 실수의 Borel set 의 원소이다. 모든 E를 다 여기서 명세할 수는 없지만 몇가지 경우로 분류할 수는 있다.
1. r1을 원소로 포함한 E들 --- 이것들의 무리를 E1이라고 하자
2. r1를 원소로 포함하지 않는 E들 --- 이것들의 무리를 E1'이라고 하자

\[
\begin{align}
E &= E_1 \cup E_2
E_1 \cap E_2 &= \emptyset
\end{align}
\]

E1에 속한 E의 경우 \(f^{-1}(E)\) 는 Ω가 된다. Check it!
E1'에 속한 E의 경우 \(f^{-1}(E)\) 는 Ø가 된다. Check it!

이때 주의해야 할 점은 E의 원소로 r2, r3, r4, 가 있는 경우이다. 이 경우 이들에 대한 f의 역함수 값은 A에는 존재할 수도 있다. 하지만 Ω의 원소 중에는 그런 없기 때문에 Ø 되는 것이다. 다시 한번 정의를 살펴보자.
\(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\) 이다. x는 Ω의 원소이어야만 한다. 그런 원소가 아니면 공집합이 된다.
Ω 와 Ø 의 모임인 \{Ω , Ø\} 는 Ω 위의 Sigma algebra 이다. 특별히 Ω 가 Generate하는 Sigma algebra 라고 한번 생각해 주고 넘어가자.

이제 measurable의 정의를 보자.

함수 f: Ω → R이 F -- measurable 이면, \(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\) 가 Ω 위에서 Sigma Algebra F의 원소이다.

그런데 어떤 책에서는

함수 f: Ω → R이 F -- measurable 이면 \(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\) 가 Ω 위에서 Sigma Algebra 를 이룬다.

라고 해서 사람을 헷갈리게 만든다. 이게 왜 사람 헷갈리게 만드는가 하면 F 안의 원소인 e1의 상이 B(R) 의 원소가 아닐 경우 위의 두 개의 정의는 동치가 되기 때문이다.
아직 이 문제는 개인적으로는 해결이 안되었고 학습에는 그다지 큰 문제는 아니므로 첫 번째 정의를 받아들이자.

\hypertarget{filtration}{%
\subsubsection{Filtration}\label{filtration}}

\hypertarget{t-0-uxc77cuxb54c-ft}{%
\paragraph{t =0 일때 Ft}\label{t-0-uxc77cuxb54c-ft}}

Ω=\{w1, w2, w3, w4\} 라고 하자.

B(R) 들의 원소 들 E 들은 r1 을 원소로 같는 E 들의 무리 E1 이 있고 그렇지 못한 무리 E2 가 있을 수 있다.
앞의 경우에서 해설한 바 몇 가지 점을 유의하면 다음과 같은 결과를 얻는다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  무리 E1 들의 역상은 Ω 이다.
\item
  무리 E2 들의 역상은 Ø 이다.
\item
  따라서 B(R)의 모든 역상들의 모임은 \{Ω, Ø\} 이다.
\item
  Ft(t=0) = F0 을 \{Ω, Ø\}이라고 하면 함수 f 는 위 정의에 의하여 F0 measurable이다.
\item
  결과적으로 보니까. F0는 partition\{Ω, Ø\} 이 generate하는 Sigma Algebra로 볼 수 있다.
\end{enumerate}

\hypertarget{t-1-uxc77c-uxb54c-ft}{%
\paragraph{t =1 일 때 Ft}\label{t-1-uxc77c-uxb54c-ft}}

앞에서와 같이 B(R)을 다음과 같이 나눌 수 있다. 그리고 앞에서 한 분석을 다시 해보면 다음과 같은 결과가 나온다.

\begin{longtable}[]{@{}ccc@{}}
\toprule
E의 그룹 & 그룹의 성격 & 그룹내 모든 E들의 역상 \\
\midrule
\endhead
E1 & r1 을 원소로 갖는 E들 & \{w1\} \\
E2 & r2 을 원소로 갖는 E들 & \{w2, w3, w4\} \\
E12 & r1과 r2 모두를 원소로 갖는 E들 & \{w1, w2, w3, w4\} \\
En & r1과 r2 모두를 원소로 갖지 않는 E들 & Ø \\
\bottomrule
\end{longtable}

마지막 열의 집합들은 partition\{\{w1\}, \{w2, w3, w4\}\} 이 generate하는 F1 내에 속하게 된다.

\hypertarget{t-2-uxc77cuxb54c-ft}{%
\paragraph{t =2 일때 Ft}\label{t-2-uxc77cuxb54c-ft}}

앞의 분석을 여기서 다시 하면 다음과 같은 결과를 얻을 수 있다.

\begin{longtable}[]{@{}ccc@{}}
\toprule
E의 그룹 & 그룹의 성격 & 그룹내 모든 E 들의 역상 \\
\midrule
\endhead
E1 & r1 을 원소로 갖는 E들 & \{w1\} \\
E2 & r2 을 원소로 갖는 E들 & \{w2\} \\
E3 & r3 을 원소로 갖는 E들 & \{w3, w4\} \\
E12 & r1과 r2를 동시에 원소로 갖는 E들 & \{w1, w2\} \\
E13 & r1과 r3를 동시에 원소로 갖는 E들 & \{w1, w3, w4\} \\
E23 & r2과 r3를 동시에 원소로 갖는 E들 & \{w2, w3, w4\} \\
E123 & r1, r2, r3를 동시에 원소로 갖는 E & \{w1, w2, w3, w4\} \\
En & r1, r2, r3를 원소로 갖지 않는 E & Ø \\
\bottomrule
\end{longtable}

확인해보면 마지막 컬럼의 집합들은 \{\{1\},\{2\},\{3, 4\} \}이 Generate하는 Sigma algebra의 원소들이다.

이제 어느 정도 요령이 생기고 규칙 같은 것들이 생길 것이다. 쉽게 말하면 Sample space를 partition 해서 Sigma Algebra Ft들을 generate하는 것이다. t가 증가함에 따라 partition을 좀더 세분화 하면 Ft1⊆Ft2⊆Ft3\ldots{} 이런식으로 Filtration 을 만들 수 있다.

\hypertarget{uxc880uxb354-uxd604uxc2e4uxc801uxc778-uxc608}{%
\subsubsection{좀더 현실적인 예}\label{uxc880uxb354-uxd604uxc2e4uxc801uxc778-uxc608}}

좀더 많이 볼 수 있는 Random process 에 적합한 예를 만들어 보자. 동전을 던져서 앞이 나오면 1 뒤가 나오면 0을 점수에 더하는 것으로 하자. 점수는 random process(라고 보아도 되는 것)이다. 동전던지기는 (최대) 3회까지 하는 것으로 하자. Sample space Ω 는 다음과 같이 구성할 수 있다.

동전던지기 첫회 시행에 위, 그 다음 시행에 아래, 그 다음 시행에 위가 나오는 경우는 Wudu 이라고 보면 된다. T=0 시점은 동전던지기를 시행하기 전이다.

각 동전던지기 수행 시점에서 Random process인 점수를 다음 테이블에 표시하였다.

앞의 예제들로 요령이 생겼으니 각각의 시점에서 해당 Sigma -- algebra를 얻을 수 있을 것이다. T=0 일 경우에는 \{ Ø, Ω \} 가 generate하는 Sigma-algebra이고 t=1 인 경우에는 Ω 를 1인 값과 0인 값으로 partition을 하고 그것으로부터 Sigma-algebra를 생성(generate)할 수 있다.

각각에 대해서 증대하는 Sigma -- algebra인 filtration을 볼 수 있으면 random process가 Ft에 measurable이라는 것이 어떠한 것인지 적어도 논리적으로 알 수 있을 것이다.

\hypertarget{uxc815uxbcf4-uxc9d1uxd569uxc73cuxb85cuxc11cuxc758-filtration}{%
\subsubsection{정보 집합으로서의 Filtration}\label{uxc815uxbcf4-uxc9d1uxd569uxc73cuxb85cuxc11cuxc758-filtration}}

Stochastic process에서 나오는 이론적인 case에서는 위의 예제를 머리 속에서 굴려보면 충분히 이해가 될 듯 싶다. 그런데 간간히 들리는 이야기는 Filtration을 시장을 움직이는 정보들의 모임이라고 보는 견해가 있다. 이것을 알면 증대해 나가는 Sigma algebra에 대한 색다른 관점을 가지게 되는 것이고 또한 금융수학이 목적이면 우리가 사는 세상과 이 수학적 모델이 어떤 연결고리를 가지고 있는 것인지를 알아볼 수 있는 기회가 된다고 생각된다.

3개의 현실세계에서 주식가격을 움직이는 사건이 있다고 치자.

A. 2000년 4월 금리인하조치 발표 -- 발생될 경우 주식가격 10\% 상승
B. 2001년 9월 11일 뉴욕 무역센터 건물 붕괴 -- 발생될 경우 주식가격 30\% 하락
C. 2002년 3월 예상을 웃도는 회계실적 발표 -- 발생될 경우 주식가격 15\% 상승

일어난다면 대문자 일어나지 않는다면 소문자로 표기하면 WABc는 A는 일어나고 B도 일어나고 c는 일어나지 않는다는 case이다.

위의 세 사건말고는 절대 주식가격이 움직이지 않는다고 가정한다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  1999.12 에는 Sigma Algebra가 \{ Ø, Ω \} 이었다. 모든 사건들의 case는 아직 일어나지 않았다.
\item
  2000년 4월에 Sigma Algebra는 \{ \{WABC, WABc, WAbC, WAbc\}, \{WaBC, WaBc, WabC, Wabc\}\}이라는 partition이 Generate하는 것이다. W의 첨자 중에서 첫번째 첨자가 가격을 결정한 것이다. 100원이 될지 110원이 될지는 첫 번째 첨자에 해당하는 사건의 정보가 나타났기 때문이다. 다시 말하면 2000년 4월에 100원 또는 110원을 결정하는 것은 2000년 4월에 일어난 `사건'이다. 이런 식으로 점점 잘게 partition 을 쪼개어 나가고 그것이 generate하는 것이 Filtration 이고 정보가 점점 증가된다.
\item
  위의 모델을 잘 살펴보면 특정시점의 주식가격의 결정은 그때까지의 모든 발생된 정보에 의해서 결정된다. 2001년 9월 직후의 주식가격은 첨자A와 첨자 B에 해당하는 사건발생여부의 `정보'가 가격을 결정한다.
\end{enumerate}

\hypertarget{natural-filtration}{%
\subsubsection{Natural Filtration}\label{natural-filtration}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  실제로는 주식가격을 결정하는 정보는 무한이고 그에 따른 주식가격의 변화도 연속적으로 바뀐다. 하지만 모든 정보의 결과가 주식가격으로 나타나니까. t시점의 정보의 변화는 t시점의 가격으로 반영이 된다. Sigma algebra가 어떤 partition에 의해 generate되는 것이라면 그 partition들을 이루는 집합들은 마치 t시점의 주식가격을 index처럼 가지고 있는 것처럼 만들어야 한다. 다시 말하면 partition내의 집합마다 각각 다른 St값을 가지고 있어야 한다. 이를테면 \{ \ldots\{St=99, \ldots\}, \{St=100\ldots\}, \{St=101\ldots\}, \ldots\} 이런 식으로 partition을 하면 된다.
\item
  t에서 dt만큼 지난 t' 시점에서는 위의 각각의 partition 들을 다시 각각 쪼갠다. 쪼개는 방법은 각각의 partition의 집합들이 St와 St' 2개의 index로 가지도록 하면 된다. 이렇게\ldots{} \{\ldots\{St=99, St'=99\ldots\}, \{St=99, St'=100\ldots\}, \{St=99, St'=101\},\ldots{} \{St=100, St'=99\ldots\}, \{St=100, St'=100\ldots\}, \{St=100, St'=101\},\ldots{} ,\{St=101, St'=99\ldots\}, \{St=100, St'=100\ldots\}, \{St=99, St'=101\}\ldots\} 이런 식으로 말이다.
\item
  위의 식을 간략하게 말해보자. 첫 번째 t에서의 Partition(또는 책에 따라서는 Decomposition이라고 하기도 하더구먼)을 D(St)라고 표현해본다. St가 generate 하는 Partition이라고 생각하면 된다. 구체적인 방법은 위에 설명했다. T'에서는 어떻게 될까? D(St, St') 두 개의 주식가격(또는 Random variable)에 의해서 generate되는 partition인 것이다.
\item
  일반적으로 보면 D(S0, S1, S2,\ldots.St)가 된다. T시점의 Sigma algebra Ft는 D(S0, S1,S2, \ldots St)가 generate하는 Sigma-algebra이다. 이것을 σ(S0, S1, S2\ldots St)라고 표시한다.
\end{enumerate}

마지막 절을 다룬 것은 몇몇의 다른 책에 위와 같은 notation이 있기 때문이다.

\hypertarget{epilogue}{%
\subsection{EPILOGUE}\label{epilogue}}

하여튼지 수학책에는 St까지의 Random process가 generate하는 partition이니 Decomposition이니 또 그것이 Generate하는 Sigma-algebra니\ldots{} 이러니까. 논리적으로는 깔끔해 보이지만 그게 눈으로 들어오기까지는 참으로 죽을 맛이더라. 하긴 이렇게 깔끔한 표현이 도움이 되긴 한다. 앞에서도 말했지만 앞에서 13페이지가 넘게 주저리주저리 써 놓은 것을 수학책에서는 몇 줄로 표현을 하니까.. 깔끔스럽기는 이보다 더하지는 못할 것이다. 많이 생각한 수학의 정의는 대부분 암기하게 되는데\ldots{} 그게 외우려고 외워지는 것이 아니다. 애매한 예들을 적용하려고 Definition을 수십 번 들춰보게 되는데 그러면 자연스럽게 토씨 하나까지 암기 하게 된다. 이것은 토씨 하나에 따라 정말 많은 것이 좌우되기 때문인데 이때마다. 수학적 정의가 얼마나 정교하게 만들어진 것인지를 새삼 깨닫게 된다. 그렇다 하더라도 개인적으로는 수학자들에게 불만이 많다. 깔끔하게 써 놓은 것도 이해는 가지만, 좀 이해하기 좋게 주저리주저리 쓰는 개인교습교재를 함께 만들었으면 하는 바람 때문이다. 말이 나왔으니 말인데, 수학책들은 두께는 얇으면서도 내용은 많고 비싸기로 유명하다. 비싼 것은 대중적이지 않으니까 그렇다 쳐도, 내용이 많은 것은 그 많은 내용을 압축해서 썼기쓰여졌기 때문이다. 고딩 때 정석책도 그런 식으로 쓰면 아마 책 내용이 1/7로 줄을 것 같다. 반대로 중편소설책 같은 분량의 수학책도 고딩 때 정석책처럼 주저리주저리 설명을 하려면 아마도 백과사전 책의 몇 권이 될 것 같다. 실제로 수학책의 강의노트들은 두꺼운 파일로 정리해도 네댓 개는 나온다. 강의노트 없이 그리고 정식 수학과정을 밟지 않은 공돌이가 맨땅에 헤딩해보니까. 나오는 것은 머리에 피나는 일밖에 없더라. 방법은 그저 조금 더 생각해 보고 써보고 낮은 포복이라도 멈추지 않고 기어가는 길일 것이다. 그래도 이렇게 쓰는 일로 해서 다른 사람들이 좀더 빨리 이해하고 도움이 되면 그간의 고통이 보람이 될 것이라고 믿는다. 여기의 모든 예들은 본인이 직접 고안한 것이다. 뭐, 저작권을 이야기 하려는 것은 아니고 다만 공인된 내용이 아니라(그래도 곡학아세로 혹세무민하는 일은 결코 없다.)그래도 수학이니 엄밀성을 요하는 부분에 부족한 점이 있을 수 있다는 것을 말하려는 것이다. 해서 보다 고수님들이 이 부분을 지적해 주면 더할 나위 없이 고맙겠다. 또한 충분히 설명을 하려고 했으나, 생각지 못한 부분이 있을 수 있으니 보다가 모르는 부분이 있으면 같이 생각하는 것도 또한 쌍방의 유익이 될 것도 같다. 하나 알아둘 것은 본 내용은 Self-Contained이지 않다. 무슨 이야긴고 하면 Sigma-algebra이고 measure고 Random Process이고 생판 모르는 사람이 본 이 내용을 보고 예수가 장님 눈뜨게 하듯 번쩍 뜨일 것 같지는 않을 것 같다는 말이다. 적어도 한번은 수학책을 보고 고민해서 이 생각 저 생각쯤은 한번쯤 한 사람들에게 도움이 되지 않을까?

아직은 장마다. 주룩주룩 내리는 비속에서 스타벅스같은 데서 노트북이나 두드리는 한가함을 기대해보면서 이만 펜을 놓는다.

\hypertarget{concepts}{%
\section{Concepts}\label{concepts}}

\(S(t)\): survival function. 시점 \(t\)까지는 살아있을 확률.

\(h(t) = \lambda(t) = \frac{f(t)}{S(t)}\): hazard function. 시점 \(t\)에서 사망할 확률.

\hypertarget{appendix-00-00}{%
\appendix}


\hypertarget{r-bookdown}{%
\chapter{R Bookdown}\label{r-bookdown}}

\hypertarget{tutorial}{%
\section{Tutorial}\label{tutorial}}

\hypertarget{about}{%
\subsection{About}\label{about}}

This is a \emph{sample} book written in \textbf{Markdown}. You can use anything that Pandoc's Markdown supports; for example, a math equation \(a^2 + b^2 = c^2\).

\hypertarget{usage}{%
\subparagraph{Usage}\label{usage}}

Each \textbf{bookdown} chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter \emph{must} start with a first-level heading: \texttt{\#\#\#\ A\ good\ chapter}, and can contain one (and only one) first-level heading.

Use second-level and higher headings within chapters like: \texttt{\#\#\#\#\#\#\ A\ short\ section} or \texttt{\#\#\#\#\#\#\#\#\#\ An\ even\ shorter\ section}.

The \texttt{index.Rmd} file is required, and is also your first book chapter. It will be the homepage when you render the book.

\hypertarget{render-book}{%
\subparagraph{Render book}\label{render-book}}

You can render the HTML version of this example book without changing anything:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find the \textbf{Build} pane in the RStudio IDE, and
\item
  Click on \textbf{Build Book}, then select your output format, or select ``All formats'' if you'd like to use multiple formats from the same book source files.
\end{enumerate}

Or build the book from the R console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bookdown}\SpecialCharTok{::}\FunctionTok{render\_book}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

To render this example to PDF as a \texttt{bookdown::pdf\_book}, you'll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): \url{https://yihui.org/tinytex/}.

\hypertarget{preview-book}{%
\subparagraph{Preview book}\label{preview-book}}

As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in ``Preview book'', or from the R console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bookdown}\SpecialCharTok{::}\FunctionTok{serve\_book}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{hello-bookdown}{%
\subsection{Hello bookdown}\label{hello-bookdown}}

All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (\texttt{\#\#\#}) per .Rmd file.

\hypertarget{a-section}{%
\subparagraph{A section}\label{a-section}}

All chapter sections start with a second-level (\texttt{\#\#\#\#\#\#}) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter.

An unnumbered section

Chapters and sections are numbered by default. To un-number a heading, add a \texttt{\{.unnumbered\}} or the shorter \texttt{\{-\}} at the end of the heading, like in this section.

\hypertarget{cross-references}{%
\subsection{Cross-references}\label{cross-references}}

Cross-references make it easier for your readers to find and link to elements in your book.

\hypertarget{chapters-and-sub-chapters}{%
\subparagraph{Chapters and sub-chapters}\label{chapters-and-sub-chapters}}

There are two steps to cross-reference any heading:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Label the heading: \texttt{\#\#\#\ Hello\ world\ \{\#\#\#nice-label\}}.

  \begin{itemize}
  \tightlist
  \item
    Leave the label off if you like the automated heading generated based on your heading title: for example, \texttt{\#\#\#\ Hello\ world} = \texttt{\#\#\#\ Hello\ world\ \{\#\#\#hello-world\}}.
  \item
    To label an un-numbered heading, use: \texttt{\#\#\#\ Hello\ world\ \{-\#\#\#nice-label\}} or \texttt{\{\#\#\#\ Hello\ world\ .unnumbered\}}.
  \end{itemize}
\item
  Next, reference the labeled heading anywhere in the text using \texttt{\textbackslash{}@ref(nice-label)}; for example, please see Chapter \texttt{\textbackslash{}@ref(cross)}.

  \begin{itemize}
  \tightlist
  \item
    If you prefer text as the link instead of a numbered reference use: \protect\hyperlink{ux5cux23ux5cux23cross}{any text you want can go here}.
  \end{itemize}
\end{enumerate}

\hypertarget{captioned-figures-and-tables}{%
\subparagraph{Captioned figures and tables}\label{captioned-figures-and-tables}}

Figures and tables \emph{with captions} can also be cross-referenced from elsewhere in your book using \texttt{\textbackslash{}@ref(fig:chunk-label)} and \texttt{\textbackslash{}@ref(tab:chunk-label)}, respectively.

See Figure \ref{fig:nice-fig}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(pressure, }\AttributeTok{type =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{_main_files/figure-latex/nice-fig-1} 

}

\caption{Here is a nice figure!}\label{fig:nice-fig}
\end{figure}

Don't miss Table \ref{tab:nice-tab}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
  \FunctionTok{head}\NormalTok{(pressure, }\DecValTok{10}\NormalTok{), }\AttributeTok{caption =} \StringTok{\textquotesingle{}Here is a nice table!\textquotesingle{}}\NormalTok{,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nice-tab}Here is a nice table!}
\centering
\begin{tabular}[t]{rr}
\toprule
temperature & pressure\\
\midrule
0 & 0.0002\\
20 & 0.0012\\
40 & 0.0060\\
60 & 0.0300\\
80 & 0.0900\\
\addlinespace
100 & 0.2700\\
120 & 0.7500\\
140 & 1.8500\\
160 & 4.2000\\
180 & 8.8000\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{parts}{%
\subsection{Parts}\label{parts}}

You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file.

Add a numbered part: \texttt{\#\#\#\ (PART)\ Act\ one\ \{-\}} (followed by \texttt{\#\#\#\ A\ chapter})

Add an unnumbered part: \texttt{\#\#\#\ (PART\textbackslash{}*)\ Act\ one\ \{-\}} (followed by \texttt{\#\#\#\ A\ chapter})

Add an appendix as a special kind of un-numbered part: \texttt{\#\#\#\ (APPENDIX)\ Other\ stuff\ \{-\}} (followed by \texttt{\#\#\#\ A\ chapter}). Chapters in an appendix are prepended with letters instead of numbers.

\hypertarget{footnotes-and-citations}{%
\subsection{Footnotes and citations}\label{footnotes-and-citations}}

\hypertarget{footnotes}{%
\subparagraph{Footnotes}\label{footnotes}}

Footnotes are put inside the square brackets after a caret \texttt{\^{}{[}{]}}. Like this one \footnote{This is a footnote.}.

\hypertarget{citations}{%
\subparagraph{Citations}\label{citations}}

Reference items in your bibliography file(s) using \texttt{@key}.

For example, we are using the \textbf{bookdown} package \citep{R-bookdown} (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and \textbf{knitr} \citep{xie2015} (this citation was added manually in an external file book.bib).
Note that the \texttt{.bib} files need to be listed in the index.Rmd with the YAML \texttt{bibliography} key.

The RStudio Visual Markdown Editor can also make it easier to insert citations: \url{https://rstudio.github.io/visual-markdown-editing/\#\#\#/citations}

\hypertarget{blocks}{%
\subsection{Blocks}\label{blocks}}

\hypertarget{equations}{%
\subparagraph{Equations}\label{equations}}

Here is an equation.

\begin{equation} 
  f\left(k\right) = \binom{n}{k} p^k\left(1-p\right)^{n-k}
\end{equation}

You may refer to using \texttt{\textbackslash{}@ref(eq:binom)}, like see Equation \texttt{\textbackslash{}@ref(eq:binom)}.

\hypertarget{theorems-and-proofs}{%
\subparagraph{Theorems and proofs}\label{theorems-and-proofs}}

Labeled theorems can be referenced in text using \texttt{\textbackslash{}@ref(thm:tri)}, for example, check out this smart theorem .

::: \{.theorem \#\#\#tri\}
For a right triangle, if \(c\) denotes the \emph{length} of the hypotenuse
and \(a\) and \(b\) denote the lengths of the \textbf{other} two sides, we have
\[a^2 + b^2 = c^2\]
:::

Read more here \url{https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html}.

\hypertarget{callout-blocks}{%
\subparagraph{Callout blocks}\label{callout-blocks}}

The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: \url{https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html}

\hypertarget{sharing-your-book}{%
\subsection{Sharing your book}\label{sharing-your-book}}

\hypertarget{publishing}{%
\subparagraph{Publishing}\label{publishing}}

HTML books can be published online, see: \url{https://bookdown.org/yihui/bookdown/publishing.html}

\hypertarget{pages}{%
\subparagraph{404 pages}\label{pages}}

By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you'd like to customize your 404 page instead of using the default, you may add either a \texttt{\_404.Rmd} or \texttt{\_404.md} file to your project root and use code and/or Markdown syntax.

\hypertarget{metadata-for-sharing}{%
\subparagraph{Metadata for sharing}\label{metadata-for-sharing}}

Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the \texttt{index.Rmd} YAML. To setup, set the \texttt{url} for your book and the path to your \texttt{cover-image} file. Your book's \texttt{title} and \texttt{description} are also used.

This \texttt{gitbook} uses the same social sharing data across all chapters in your book- all links shared will look the same.

Specify your book's source repository on GitHub using the \texttt{edit} key under the configuration options in the \texttt{\_output.yml} file, which allows users to suggest an edit by linking to a chapter's source file.

Read more about the features of this output format here:

\url{https://pkgs.rstudio.com/bookdown/reference/gitbook.html}

Or use:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?bookdown}\SpecialCharTok{::}\NormalTok{gitbook}
\end{Highlighting}
\end{Shaded}

\hypertarget{noname}{%
\chapter{NoName}\label{noname}}

모먼트, MLE (2차까지 확인)

MLE 불변성

MSE를 통해 통계량 성능 비교 가능함
bias

MSE = precision + accuracy

UMVUE 7.5

크래머-라오 부등식 : 최저 분산 뽑아내는 수단

피셔 정보

2차원 피셔 정보

라오-블랙웰 : uniform better UE 뽑아내는 수단

unique best UE

best UE는 오직 하나뿐

(레만쉐페) CSS에 기반한 UE는 오직 유일함

W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7

consistent (점근성)

충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일

test으 unbaised 8.8

네이만 피어슨

카를린 루빈 8.3

빅 샘플 추정자들과 8.5

스코어 스탯 8.12

왈드 테스트 8.13

1-a confidence iterval = acceptance region of level 알파 test

뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨

pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT.

MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량.

cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2.

감마와 포아송간 변환

유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5.

dog-tired

Bubble Plot
3D Scatter Plot
Star Plot
Chernoff Faces
Parallel Coordinate Plot

1.Q-Q Plot
Shapiro-Wilks Test
Kolmogorov-Smirnov Test
Skewness Test ( )
Kurtosis Test: ( )
Lin and Mudholkar

Scatter Plot
Squared Generalized Distances
Chi-Square Plot (Gamma Plot)

nqplot
contour plot
cqplot

(Python -- assumption check)

\hypertarget{abstract-1}{%
\chapter{ABSTRACT}\label{abstract-1}}

Graph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data, Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore, Cluster-GCN allows us to train much deeper GCN without much time and memory overhead, which leads to improved prediction accuracy---using a 5-layer Cluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI dataset, while the previous best result was 98.71 by {[}16{]}. Our codes are publicly available at \url{https://github.com/google-research/google-research/} tree/master/cluster\_gcn

1 INTRODUCTION

Graph convolutional network (GCN) {[}9{]} has become increasingly popular in addressing many graph-based applications, including semi-supervised node classification {[}9{]}, link prediction {[}17{]} and recommender systems {[}15{]}. Given a graph, GCN uses a graph convolution operation to obtain node embeddings layer by layer---at each layer, the embedding of a node is obtained by gathering the embeddings of its neighbors, followed by one or a few layers of linear transformations and nonlinear activations. The final layer embedding is then used for some end tasks. For instance, in node classification problems, the final layer embedding is passed to a classifier to predict node labels, and thus the parameters of GCN can be trained in an end-to-end manner.

Since the graph convolution operator in GCN needs to propagate embeddings using the interaction between nodes in the graph, this makes training quite challenging. Unlike other neural networks that the training loss can be perfectly decomposed into individual terms on each sample, the loss term in GCN (e.g., classification loss on a single node) depends on a huge number of other nodes, especially when GCN goes deep. Due to the node dependence, GCN's training is very slow and requires lots of memory -- backpropagation needs to store all the embeddings in the computation graph in GPU memory

Previous GCN Training Algorithms: To demonstrate the need of developing a scalable GCN training algorithm, we first discuss the pros and cons of existing approaches, in terms of 1) memory requirement1 , 2) time per epoch2 and 3) convergence speed (loss reduction) per epoch. These three factors are crucial for evaluating a training algorithm. Note that memory requirement directly restricts the scalability of algorithm, and the later two factors combined together will determine the training speed. In the following discussion we denote N to be the number of nodes in the graph, F the embedding dimension, and L the number of layers to analyze classic GCN training algorithm.

• Full-batch gradient descent is proposed in the first GCN paper {[}9{]}. To compute the full gradient, it requires storing all the intermediate embeddings, leading to O(N F L) memory requirement, which is not scalable. Furthermore, although the time per epoch is efficient, the convergence of gradient descent is slow since the parameters are updated only once per epoch. {[}memory: bad; time per epoch: good; convergence: bad{]}

Mini-batch SGD is proposed in {[}5{]}. Since each update is only based on a mini-batch gradient, it can reduce the memory requirement and conduct many updates per epoch, leading to a faster convergence. However, mini-batch SGD introduces a significant computational overhead due to the neighborhood expansion problem---to compute the loss on a single node at layer L, it requires that node's neighbor nodes' embeddings at layer L − 1, which again requires their neighbors' embeddings at layer L − 2 and recursive ones in the downstream layers. This leads to time complexity exponential to the GCN depth. GraphSAGE {[}5{]} proposed to use a fixed size of neighborhood samples during back-propagation through layers and FastGCN {[}1{]} proposed importance sampling, but the overhead of these methods is still large and will become worse when GCN goes deep. {[}memory: good; time per epoch: bad; convergence: good{]}

Mini-batch SGD is proposed in {[}5{]}. Since each update is only based on a mini-batch gradient, it can reduce the memory requirement and conduct many updates per epoch, leading to a faster convergence. However, mini-batch SGD introduces a significant computational overhead due to the neighborhood expansion problem---to compute the loss on a single node at layer L, it requires that node's neighbor nodes' embeddings at layer L − 1, which again requires their neighbors' embeddings at layer L − 2 and recursive ones in the downstream layers. This leads to time complexity exponential to the GCN depth. GraphSAGE {[}5{]} proposed to use a fixed size of neighborhood samples during back-propagation through layers and FastGCN {[}1{]} proposed importance sampling, but the overhead of these methods is still large and will become worse when GCN goes deep. {[}memory: good; time per epoch: bad; convergence: good{]}

loiting the graph clustering structure. We find that the efficiency of a mini-batch algorithm can be characterized by the notion of ``embedding utilization'', which is proportional to the number of links between nodes in one batch or within-batch links. This finding motivates us to design the batches using graph clustering algorithms that aims to construct partitions of nodes so that there are more graph links between nodes in the same partition than nodes in different partitions. Based on the graph clustering idea, we proposed Cluster-GCN, an algorithm to design the batches based on efficient graph clustering algorithms (e.g., METIS {[}8{]}). We take this idea further by proposing a stochastic multi-clustering framework to improve the convergence of Cluster-GCN. Our strategy leads to huge memory and computational benefits. In terms of memory, we only need to store the node embeddings within the current batch, which is O(bF L) with the batch size b. This is significantly better than VR-GCN and full gradient decent, and slightly better than other SGD-based approaches. In terms of computational complexity, our algorithm achieves the same time cost per epoch with gradient descent and is much faster than neighborhood searching approaches. In terms of the convergence speed, our algorithm is competitive with other SGD-based approaches. Finally, our algorithm is simple to implement since we only compute matrix multiplication and no neighborhood sampling is needed. Therefore for Cluster-GCN, we have {[}memory: good; time per epoch: good; convergence: good{]}.

We conducted comprehensive experiments on several large-scale graph datasets and made the following contributions:

• Cluster-GCN achieves the best memory usage on large-scale graphs, especially on deep GCN. For example, Cluster-GCN uses 5x less memory than VRGCN in a 3-layer GCN model on Amazon2M. Amazon2M is a new graph dataset that we construct to demonstrate the scalablity of the GCN algorithms. This dataset contains a amazon product co-purchase graph with more than 2 millions nodes and 61 millions edges.

• Cluster-GCN achieves a similar training speed with VR-GCN for shallow networks (e.g., 2 layers) but can be faster than VRGCN when the network goes deeper (e.g., 4 layers), since our complexity is linear to the number of layers L while VR-GCN's complexity is exponential to L.

• Cluster-GCN is able to train a very deep network that has a large embedding size. Although several previous works show that deep GCN does not give better performance, we found that with proper optimization, deeper GCN could help the accuracy. For example, with a 5-layer GCN, we obtain a new benchmark accuracy 99.36 for PPI dataset, comparing with the highest reported one 98.71 by {[}16{]}.

Implementation of our proposed method is publicly available.3

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  BACKGROUND
\end{enumerate}

Suppose we are given a graph G = (V, E,A), which consists of N = \textbar V \textbar{} vertices and \textbar E \textbar{} edges such that an edge between any two vertices i and j represents their similarity. The corresponding adjacency matrix A is an N ×N sparse matrix with (i, j) entry equaling to 1 if there is an edge between i and j and 0 otherwise. Also, each node is associated with an F -dimensional feature vector and X ∈ R N ×F denotes the feature matrix for all N nodes. An L-layer GCN {[}9{]} consists of L graph convolution layers and each of them constructs embeddings for each node by mixing the embeddings of the node's neighbors in the graph from the previous layer:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
\end{enumerate}

where X (l) ∈ R N ×Fl is the embedding at the l-th layer for all the N nodes and X (0) = X; A ′ is the normalized and regularized adjacency matrix andW (l) ∈ R Fl ×Fl+1 is the feature transformation matrix which will be learnt for the downstream tasks. Note that for simplicity we assume the feature dimensions are the same for all layers (F1 = · · · = FL = F ). The activation function σ(·) is usually set to be the element-wise ReLU. Semi-supervised node classification is a popular application of GCN. When using GCN for this application, the goal is to learn weight matrices in (1) by minimizing the loss function

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
\end{enumerate}

where YL contains all the labels for the labeled nodes; z (L) i is the i-th row of Z (L) with the ground-truth label to be yi , indicating the final layer prediction of node i. In practice, a cross-entropy loss is commonly used for node classification in multi-class or multi-label problems.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  PROPOSED ALGORITHM
\end{enumerate}

We first discuss the bottleneck of previous training methods to motivate the proposed algorithm.

In the original paper {[}9{]}, full gradient descent is used for training GCN, but it suffers from high computational and memory cost. In terms of memory, computing the full gradient of (2) by backpropagation requires storing all the embedding matrices \{Z (l) \} L l=1 which needs O(N F L) space. In terms of convergence speed, since the model is only updated once per epoch, the training requires more epochs to converge.

It has been shown that mini-batch SGD can improve the training speed and memory requirement of GCN in some recent works {[}1, 2, 5{]}. Instead of computing the full gradient, SGD only needs to calculate the gradient based on a mini-batch for each update. In this paper, we use B ⊆ {[}N{]} with size b = \textbar B\textbar{} to denote a batch of node indices, and each SGD step will compute the g

to perform an update. Despite faster convergence in terms of epochs, SGD will introduce another computational overhead on GCN training (as explained in the following), which makes it having much slower per-epoch time compared with full gradient descent.

Why does vanilla mini-batch SGD have slow per-epoch time?: We consider the computation of the gradient associated with one node i : ∇loss(yi , z (L) i ). Clearly, this requires the embedding of node i, which depends on its neighbors' embeddings in the previous layer. To fetch each node i's neighbor nodes' embeddings, we need to further aggregate each neighbor node's neighbor nodes' embeddings as well. Suppose a GCN has L + 1 layers and each node has an average degree of d, to get the gradient for node i, we need to aggregate features fromO(d L ) nodes in the graph for one node. That is, we need to fetch information for a node's hop-k (k = 1, · · · , L) neighbors in the graph to perform one update. Computing each embedding requires O(F 2 ) time due to the multiplication withW (l) , so in average computing the gradient associated with one node requires O(d L F 2 ) time.

Embedding utilization can reflect computational efficiency.: If a batch has more than one node, the time complexity is less straightforward since different nodes can have overlapped hopk neighbors, and the number of embedding computation can be less than the worst case O(bdL ). To reflect the computational efficiency of mini-batch SGD, we define the concept of ``embedding utilization'' to characterize the computational efficiency. During

the algorithm, if the node i's embedding at l-th layer z (l) i is computed and is reused u times for the embedding computations at layer l + 1, then we say the embedding utilization of z (l) i is u. For mini-batch SGD with random sampling, u is very small since the graph is usually large and sparse. Assume u is a small constant (almost no overlaps between hop-k neighbors), then mini-batch SGD needs to compute O(bdL ) embeddings per batch, which leads to O(bdL F 2 ) time per update and O(NdL F 2 ) time per epoch.

We illustrate the neighborhood expansion problem in the left panel of Fig. 1. In contrary, full-batch gradient descent has the maximal embedding utilization---each embedding will be reused d (average degree) times in the upper layer. As a consequence, the original full gradient descent {[}9{]} only needs to compute O(N L) embeddings per epoch, which means on average only O(L) embedding computation is needed to acquire the gradient of one node.

To make mini-batch SGD work, previous approaches try to restrict the neighborhood expansion size, which however do not improve embedding utilization. GraphSAGE {[}5{]} uniformly samples a fixed-size set of neighbors, instead of using a full-neighborhood set. We denote the sample size as r. This leads to O(r L ) embedding computations for each loss term but also makes gradient estimation less accurate. FastGCN {[}1{]} proposed an important sampling strategy to improve the gradient estimation. VR-GCN {[}2{]} proposed a strategy to store the previous computed embeddings for all the N nodes and L layers and reuse them for unsampled neighbors. Despite the high memory usage for storing all the N L embeddings, we find their strategy very useful and in practice, even for a small r (e.g., 2) can lead to good convergence.

We summarize the time and space complexity in Table 1. Clearly, all the SGD-based algorithms suffer from exponential complexity with respect to the number of layers, and for VR-GCN, even though r can be small, they incur huge space complexity that could go beyond a GPU's memory capacity. In the following, we introduce our Cluster-GCN algorithm, which achieves the best of two worlds--- the same time complexity per epoch with full gradient descent and the same memory complexity with vanilla SGD.

3.1 Vanilla Cluster-GCN

Our Cluster-GCN technique is motivated by the following question: In mini-batch SGD updates, can we design a batch and the corresponding computation subgraph to maximize the embedding utilization? We answer this affirmative by connecting the concept of embedding utilization to a clustering objective.

Consider the case that in each batch we compute the embeddings for a set of nodes B from layer 1 to L. Since the same subgraph AB, B (links within B) is used for each layer of computation, we can then see that embedding utilization is the number of edges within this batch ∥AB, B ∥0. Therefore, to maximize embedding utilization, we should design a batch B to maximize the within-batch edges, by which we connect the efficiency of SGD updates with graph clustering algorithms.

Now we formally introduce Cluster-GCN. For a graph G, we partition its nodes into c groups: V = {[}V1, · · · Vc {]} where Vt consists of the nodes in the t-th partition. Thus we have c subgraphs as

where each Et only consists of the links between nodes in Vt . After reorganizing nodes, the adjacency matrix is partitioned into c 2 submatrices as

where each diagonal block At t is a \textbar Vt \textbar{} × \textbar Vt \textbar{} adjacency matrix containing the links within Gt . A¯ is the adjacency matrix for graph G¯; Ast contains the links between two partitions Vs and Vt ; ∆ is the matrix consisting of all off-diagonal blocks of A. Similarly, we can partition the feature matrix X and training labels Y according to the partition {[}V1, · · · , Vc {]} as {[}X1, · · · ,Xc {]} and {[}Y1, · · · ,Yc {]} where Xt and Yt consist of the features and labels for the nodes in Vt respectively.

The benefit of this block-diagonal approximation G¯ is that the objective function of GCN becomes decomposible into different batches (clusters). Let A¯′ denotes the normalized version of A¯, the final embedding matrix becomes

due to the block-diagonal form ofA¯(note thatA¯′ t t is the corresponding diagonal block of A¯′ ). The loss function can also be decomposed into

The Cluster-GCN is then based on the decomposition form in (6) and (7). At each step, we sample a cluster Vt and then conduct SGD to update based on the gradient of LA¯′ t t , and this only requires the sub-graph At t , the Xt , Yt on the current batch and the models \{W (l) \} L l=1 . The implementation only requires forward and backward propagation of matrix products (one block of (6)) that is much easier to implement than the neighborhood search procedure used in previous SGD-based training methods.

We use graph clustering algorithms to partition the graph. Graph clustering methods such as Metis {[}8{]} and Graclus {[}4{]} aim to construct the partitions over the vertices in the graph such that withinclusters links are much more than between-cluster links to better capture the clustering and community structure of the graph. These are exactly what we need because: 1) As mentioned before, the embedding utilization is equivalent to the within-cluster links for each batch. Intuitively, each node and its neighbors are usually located in the same cluster, therefore after a few hops, neighborhood nodes with a high chance are still in the same cluster. 2) Since we replace A by its block diagonal approximation A¯ and the error is proportional to between-cluster links ∆, we need to find a partition to minimize number of between-cluster links.

In Figure 1, we illustrate the neighborhood expansion with full graph G and the graph with clustering partition G¯. We can see that cluster-GCN can avoid heavy neighborhood search and focus on the neighbors within each cluster. In Table 2, we show two different node partition strategies: random partition versus clustering partition. We partition the graph into 10 parts by using random partition and METIS. Then use one partition as a batch to perform a SGD update. We can see that with the same number of epochs, using clustering partition can achieve higher accuracy. This shows using graph clustering is important and partitions should not be formed randomly.

Time and space complexity.: Since each node in Vt only links to nodes inside Vt , each node does not need to perform neighborhoods searching outside At t . The computation for each batch will purely be matrix products A¯′ t tX (l) t W (l) and some element-wise operations, so the overall time complexity per batch isO(∥At t ∥0F + bF 2 ). Thus the overall time complexity per epoch becomesO(∥A∥0F+ N F 2 ). In average, each batch only requires computingO(bL) embeddings, which is linear instead of exponential to L. In terms of space complexity, in each batch, we only need to load b samples and store their embeddings on each layer, resulting in O(bLF ) memory for storing embeddings. Therefore our algorithm is also more efficient than all the previous algorithms. Moreover, our algorithm only requires loading a subgraph into GPU memory instead of the full graph (though graph is usually not the memory bottleneck). The detailed time and memory complexity are summarized in Table 1.

3.2 Stochastic Multiple Partitions

Although vanilla Cluster-GCN achieves good computational and memory complexity, there are still two potential issues:

• After the graph is partitioned, some links (the ∆ part in Eq. (4)) are removed. Thus the performance could be affected.
• Graph clustering algorithms tend to bring similar nodes together. Hence the distribution of a cluster could be different from the original data set, leading to a biased estimation of the full gradient while performing SGD updates.

In Figure 2, we demonstrate an example of unbalanced label distribution by using the Reddit data with clusters formed by Metis. We calculate the entropy value of each cluster based on its label distribution. Comparing with random partitioning, we clearly see that entropy of most clusters are smaller, indicating that the label distributions of clusters are biased towards some specific labels. This increases the variance across different batches and may affect the convergence of SGD.

To address the above issues, we propose a stochastic multiple clustering approach to incorporate between-cluster links and reduce variance across batches. We first partition the graph into p clusters V1, · · · , Vp with a relatively large p.~When constructing a batch B for an SGD update, instead of considering only one cluster, we randomly choose q clusters, denoted as t1, . . . ,tq and include their nodes \{Vt1 ∪ · · · ∪Vtq \} into the batch. Furthermore, the links between the chosen clusters,

are added back. In this way, those between-cluster links are reincorporated and the combinations of clusters make the variance across batches smaller. Figure 3 illustrates our algorithm---for each epochs, different combinations of clusters are chosen as a batch. We conduct an experiment on Reddit to demonstrate the effectiveness of the proposed approach. In Figure 4, we can observe that using multiple clusters as one batch could improve the convergence. Our final Cluster-GCN algorithm is presented in Algorithm 1.

3.3 Issues of training deeper GCNs

Previous attempts of training deeper GCNs {[}9{]} seem to suggest that adding more layers is not helpful. However, the datasets used in the experiments may be too small to make a proper justification. For example, {[}9{]} considered a graph with only a few hundreds of training nodes for which overfitting can be an issue. Moreover, we observe that the optimization of deep GCN models becomes difficult as it may impede the information from the first few layers being passed through. In {[}9{]}, they adopt a technique similar to residual connections {[}6{]} to enable the model to carry the information from a previous layer to a next layer. Specifically, they modify (1) to add the hidden representations of layer l into the next layer.

Here we propose another simple technique to improve the training of deep GCNs. In the original GCN settings, each node aggregates the representation of its neighbors from the previous layer. However, under the setting of deep GCNs, the strategy may not be suitable as it does not take the number of layers into account. Intuitively, neighbors nearby should contribute more than distant nodes. We thus propose a technique to better address this issue. The idea is to amplify the diagonal parts of the adjacency matrix A used in each GCN layer. In this way, we are putting more weights on the representation from the previous layer in the aggregation of each GCN layer. An example is to add an identity to A¯ as follows.

While (9) seems to be reasonable, using the same weight for all the nodes regardless of their numbers of neighbors may not be suitable. Moreover, it may suffer from numerical instability as values can grow exponentially when more layers are used. Hence we propose a modified version of (9) to better maintain the neighborhoods information and numerical ranges. We first add an identity to the original A and perform the normalization, (10)

and then consider

Experimental results of adopting the ``diagonal enhancement'' techniques are presented in Section 4.3 where we show that this new normalization strategy can help to build deep GCN and achieve SOTA performance.

4 EXPERIMENTS

We evaluate our proposed method for training GCN on two tasks: multi-label and multi-class classification on four public datasets. The statistic of the data sets are shown in Table 3. Note that the Reddit dataset is the largest public dataset we have seen so far for GCN, and the Amazon2M dataset is collected by ourselves and is much larger than Reddit (see more details in Section 4.2). We include the following state-of-the-art GCN training algorithms in our comparisons:

• Cluster-GCN (Our proposed algorithm): the proposed fast GCN training method.
• VRGCN4 {[}2{]}: It maintains the historical embedding of all the nodes in the graph and expands to only a few neighbors to speedup training. The number of sampled neighbors is set to be 2 as suggested in {[}2{]}5 .
• GraphSAGE6 {[}5{]}: It samples a fixed number of neighbors per node. We use the default settings of sampled sizes for each layer (S1 = 25, S2 = 10) in GraphSAGE.

We implement our method in PyTorch {[}13{]}. For the other methods, we use all the original papers' code from their github pages. Since {[}9{]} has difficulty to scale to large graphs, we do not compare with it here. Also as shown in {[}2{]} that VRGCN is faster than FastGCN, so we do not compare with FastGCN here. For all the methods we use the Adam optimizer with learning rate as 0.01, dropout rate as 20\%, weight decay as zero. The mean aggregator proposed by {[}5{]} is adopted and the number of hidden units is the same for all methods. Note that techniques such as (11) is not considered here. In each experiment, we consider the same GCN architecture for all methods. For VRGCN and GraphSAGE, we follow the settings provided by the original papers and set the batch sizes as 512. For Cluster-GCN, the number of partitions and clusters per batch for each dataset are listed in Table 4. Note that clustering is seen as a preprocessing step and its running time is not taken into account in training. In Section 6, we show that graph clustering only takes a small portion of preprocessing time. All the experiments are conducted on a machine with a NVIDIA Tesla V100 GPU (16 GB memory), 20-core Intel Xeon CPU (2.20 GHz), and 192 GB of RAM.

4.1 Training Performance for median size datasets

Training Time vs Accuracy: First we compare our proposed method with other methods in terms of training speed. In Figure 6, the x-axis shows the training time in seconds, and y-axis shows the accuracy (F1 score) on the validation sets. We plot the training time versus accuracy for three datasets with 2,3,4 layers of GCN. Since GraphSAGE is slower than VRGCN and our method, the curves for GraphSAGE only appear for PPI and Reddit datasets. We can see that our method is the fastest for both PPI and Reddit datasets for GCNs with different numbers of layers.

For Amazon data, since nodes' features are not available, an identity matrix is used as the feature matrix X. Under this setting, the shape of parameter matrix W (0) becomes 334863x128. Therefore, the computation is dominated by sparse matrix operations such as AW (0) . Our method is still faster than VRGCN for 3-layer case, but slower for 2-layer and 4-layer ones. The reason may come from the speed of sparse matrix operations from different frameworks. VRGCN is implemented in TensorFlow, while Cluster-GCN is implemented in PyTorch whose sparse tensor support are still in its very early stage. In Table 6, we show the time for TensorFlow and PyTorch to do forward/backward operations on Amazon data, and a simple two-layer network are used for benchmarking both frameworks. We can clearly see that TensorFlow is faster than PyTorch. The difference is more significant when the number of hidden units increases. This may explain why Cluster-GCN has longer training time in Amazon dataset.

Memory usage comparison: For training large-scale GCNs, besides training time, memory usage needed for training is often more important and will directly restrict the scalability. The memory usage includes the memory needed for training the GCN for many epochs. As discussed in Section 3, to speedup training, VRGCN needs to save historical embeddings during training, so it needs much more memory for training than Cluster-GCN. GraphSAGE also has higher memory requirement than Cluster-GCN due to the exponential neighborhood growing problem. In Table 5, we compare our memory usage with VRGCN's memory usage for GCN with different layers. When increasing the number of layers, Cluster-GCN's memory usage does not increase a lot. The reason is that when increasing one layer, the extra variable introduced is the weight matrix W (L) , which is relatively small comparing to the sub-graph and node features. While VRGCN needs to save each layer's history embeddings, and the embeddings are usually dense and will soon dominate the memory usage. We can see from Table 5 that Cluster-GCN is much more memory efficient than VRGCN. For instance, on Reddit data to train a 4-layer GCN with hidden dimension to be 512, VRGCN needs 2064MB memory, while Cluster-GCN only uses 308MB memory.

4.2 Experimental results on Amazon2M

A new GCN dataset: Amazon2M. By far the largest public data for testing GCN is Reddit dataset with the statistics shown in Table 3, which contains about 200K nodes. As shown in Figure 6 GCN training on this data can be finished within a few hundreds seconds. To test the scalability of GCN training algorithms, we constructed a much larger graph with over 2 millions of nodes and 61 million edges based on Amazon co-purchasing networks {[}11, 12{]}. The raw co-purchase data is from Amazon-3M7 . In the graph, each node is a product, and the graph link represents whether two products are purchased together. Each node feature is generated by extracting bag-of-word features from the product descriptions followed by Principal Component Analysis {[}7{]} to reduce the dimension to be 100. In addition, we use the top-level categories as the labels for that product/node (see Table 7 for the most common categories). The detailed statistics of the data set are listed in Table 3.

In Table 8, we compare with VRGCN for GCNs with a different number of layers in terms of training time, memory usage, and test accuracy (F1 score). As can be seen from the table that 1) VRGCN is faster than Cluster-GCN with 2-layer GCN but slower than ClusterGCN when increasing one layer while achieving similar accuracy. 2) In terms of memory usage, VRGCN is using much more memory than Cluster-GCN (5 times more for 3-layer case), and it is running out of memory when training 4-layer GCN, while Cluster-GCN does not need much additional memory when increasing the number of layers, and achieves the best accuracy for this data when training a 4-layer GCN.

4.3 Training Deeper GCN

In this section we consider GCNs with more layers. We first show the timing comparisons of Cluster-GCN and VRGCN in Table 9. PPI is used for benchmarking and we run 200 epochs for both methods. We observe that the running time of VRGCN grows exponentially because of its expensive neighborhood finding, while the running time of Cluster-GCN only grows linearly.

Next we investigate whether using deeper GCNs obtains better accuracy. In Section 4.3, we discuss different strategies of modifying the adjacency matrix A to facilitate the training of deep GCNs. We apply the diagonal enhancement techniques to deep GCNs and run experiments on PPI. Results are shown in Table 11. For the case of 2 to 5 layers, the accuracy of all methods increases with more layers added, suggesting that deeper GCNs may be useful. However, when 7 or 8 GCN layers are used, the first three methods fail to converge within 200 epochs and get a dramatic loss of accuracy. A possible reason is that the optimization for deeper GCNs becomes more difficult. We show a detailed convergence of a 8-layer GCN in Figure 5. With the proposed diagonal enhancement technique (11), the convergence can be improved significantly and similar accuracy can be achieved.

State-of-the-art results by training deeper GCNs.: With the design of Cluster-GCN and the proposed normalization approach, we now have the ability for training much deeper GCNs to achieve better accuracy (F1 score). We compare the testing accuracy with other existing methods in Table 10. For PPI, Cluster-GCN can achieve the state-of-art result by training a 5-layer GCN with 2048 hidden units. For Reddit, a 4-layer GCN with 128 hidden units is used.

5 CONCLUSION

We present ClusterGCN, a new GCN training algorithm that is fast and memory efficient. Experimental results show that this method can train very deep GCN on large-scale graph, for instance on a graph with over 2 million nodes, the training time is less than an hour using around 2G memory and achieves accuracy of 90.41 (F1 score). Using the proposed approach, we are able to successfully train much deeper GCNs, which achieve state-of-the-art test F1 score on PPI and Reddit datasets.

Acknowledgement: CJH acknowledges the support of NSF via IIS-1719097, Intel faculty award, Google Cloud and Nvidia.

  \bibliography{book.bib,packages.bib}

\end{document}
