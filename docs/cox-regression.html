<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.5 Cox Regression | Self-Study</title>
  <meta name="description" content="9.5 Cox Regression | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="9.5 Cox Regression | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="https://github.com/lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.5 Cox Regression | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="section-6.html"/>
<link rel="next" href="filtration의-개념을-정복하자.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="part"><span><b>I 20-02</b></span></li>
<li class="chapter" data-level="1" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>1</b> Categorical</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="overview.html"><a href="overview.html#data-type-and-statistical-analysis"><i class="fa fa-check"></i><b>1.1.1</b> Data Type and Statistical Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian</a>
<ul>
<li class="chapter" data-level="2.1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>2.1</b> Abstract</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="abstract.html"><a href="abstract.html#변수의-독립성"><i class="fa fa-check"></i><b>2.1.1</b> 변수의 독립성</a></li>
<li class="chapter" data-level="2.1.2" data-path="abstract.html"><a href="abstract.html#교환가능성"><i class="fa fa-check"></i><b>2.1.2</b> 교환가능성</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continual-aeassessment-method.html"><a href="continual-aeassessment-method.html"><i class="fa fa-check"></i><b>2.2</b> Continual Aeassessment Method</a></li>
<li class="chapter" data-level="2.3" data-path="horseshoe-prior.html"><a href="horseshoe-prior.html"><i class="fa fa-check"></i><b>2.3</b> Horseshoe Prior</a></li>
</ul></li>
<li class="part"><span><b>II 21-01</b></span></li>
<li class="chapter" data-level="3" data-path="mathematical-stats.html"><a href="mathematical-stats.html"><i class="fa fa-check"></i><b>3</b> Mathematical Stats</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>3.1</b> Inference</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference.html"><a href="inference.html#rao-blackwell-thm."><i class="fa fa-check"></i><b>3.1.1</b> Rao-Blackwell thm.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="completeness.html"><a href="completeness.html"><i class="fa fa-check"></i><b>3.2</b> Completeness</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="completeness.html"><a href="completeness.html#레만-쉐페-thm."><i class="fa fa-check"></i><b>3.2.1</b> 레만-쉐페 thm.</a></li>
<li class="chapter" data-level="3.2.2" data-path="completeness.html"><a href="completeness.html#rao-blackwell-thm.-1"><i class="fa fa-check"></i><b>3.2.2</b> Rao-Blackwell thm.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Test</a></li>
<li class="chapter" data-level="3.4" data-path="power-fucntion.html"><a href="power-fucntion.html"><i class="fa fa-check"></i><b>3.4</b> Power Fucntion</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="power-fucntion.html"><a href="power-fucntion.html#significance-probability-p-value"><i class="fa fa-check"></i><b>3.4.1</b> Significance Probability (p-value)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="optimal-testing-method.html"><a href="optimal-testing-method.html"><i class="fa fa-check"></i><b>3.5</b> Optimal Testing Method</a></li>
<li class="chapter" data-level="3.6" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>3.6</b> Data Reduction</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="data-reduction.html"><a href="data-reduction.html#sufficiency-principle"><i class="fa fa-check"></i><b>3.6.1</b> Sufficiency Principle</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="borel-paradox.html"><a href="borel-paradox.html"><i class="fa fa-check"></i><b>3.7</b> Borel Paradox</a></li>
<li class="chapter" data-level="3.8" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html"><i class="fa fa-check"></i><b>3.8</b> Neyman–Pearson lemma</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#overview-1"><i class="fa fa-check"></i><b>3.8.1</b> Overview</a></li>
<li class="chapter" data-level="3.8.2" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#generalized-lrt"><i class="fa fa-check"></i><b>3.8.2</b> Generalized LRT</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="개념.html"><a href="개념.html"><i class="fa fa-check"></i><b>3.9</b> 개념</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>4</b> MCMC</a>
<ul>
<li class="chapter" data-level="4.1" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>4.1</b> Importance Sampling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="importance-sampling.html"><a href="importance-sampling.html#independent-monte-carlo"><i class="fa fa-check"></i><b>4.1.1</b> Independent Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.2</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mh-algorithm"><i class="fa fa-check"></i><b>4.2.1</b> MH Algorithm</a></li>
<li class="chapter" data-level="4.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used"><i class="fa fa-check"></i><b>4.2.2</b> Random Walk Chains (Most Widely Used)</a></li>
<li class="chapter" data-level="4.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler"><i class="fa fa-check"></i><b>4.2.3</b> Basic Gibbs Sampler</a></li>
<li class="chapter" data-level="4.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#implementation"><i class="fa fa-check"></i><b>4.2.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html"><i class="fa fa-check"></i><b>4.3</b> Advanced MCMC (wk08)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#data-augmentation"><i class="fa fa-check"></i><b>4.3.1</b> 1. Data Augmentation</a></li>
<li class="chapter" data-level="4.3.2" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm"><i class="fa fa-check"></i><b>4.3.2</b> 2. Hit-and-Run Algorithm</a></li>
<li class="chapter" data-level="4.3.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm"><i class="fa fa-check"></i><b>4.3.3</b> 3. Metropolis-Adjusted Langevin Algorithm</a></li>
<li class="chapter" data-level="4.3.4" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm"><i class="fa fa-check"></i><b>4.3.4</b> 4. Multiple-Try Metropolis Algorithm</a></li>
<li class="chapter" data-level="4.3.5" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm"><i class="fa fa-check"></i><b>4.3.5</b> 5. Reversible Jump MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html"><i class="fa fa-check"></i><b>4.4</b> Auxiliary Variable MCMC</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#introduction"><i class="fa fa-check"></i><b>4.4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.4.2" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution"><i class="fa fa-check"></i><b>4.4.2</b> Multimodal Target Distribution</a></li>
<li class="chapter" data-level="4.4.3" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants"><i class="fa fa-check"></i><b>4.4.3</b> Doubly-intractable Normalizing Constants</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html"><i class="fa fa-check"></i><b>4.5</b> Approximate Bayesian Computation</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#simulator-based-models"><i class="fa fa-check"></i><b>4.5.1</b> Simulator-Based Models</a></li>
<li class="chapter" data-level="4.5.2" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods"><i class="fa fa-check"></i><b>4.5.2</b> ABCifying Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.5.3" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm"><i class="fa fa-check"></i><b>4.5.3</b> ABC-MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Hamiltonian Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>4.6.1</b> Introduction to Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html"><i class="fa fa-check"></i><b>4.7</b> Population Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#adaptive-direction-sampling"><i class="fa fa-check"></i><b>4.7.1</b> Adaptive Direction Sampling</a></li>
<li class="chapter" data-level="4.7.2" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#conjugate-gradient-mc"><i class="fa fa-check"></i><b>4.7.2</b> Conjugate Gradient MC</a></li>
<li class="chapter" data-level="4.7.3" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#parallel-tempering"><i class="fa fa-check"></i><b>4.7.3</b> Parallel Tempering</a></li>
<li class="chapter" data-level="4.7.4" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#evolutionary-mc"><i class="fa fa-check"></i><b>4.7.4</b> Evolutionary MC</a></li>
<li class="chapter" data-level="4.7.5" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#sequential-parallel-tempering"><i class="fa fa-check"></i><b>4.7.5</b> Sequential Parallel Tempering</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="stochastic-approximation-monte-carlo.html"><a href="stochastic-approximation-monte-carlo.html"><i class="fa fa-check"></i><b>4.8</b> Stochastic Approximation Monte Carlo</a></li>
<li class="chapter" data-level="4.9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>4.9</b> Review</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="review.html"><a href="review.html#wk01"><i class="fa fa-check"></i><b>4.9.1</b> Wk01</a></li>
<li class="chapter" data-level="4.9.2" data-path="review.html"><a href="review.html#wk03"><i class="fa fa-check"></i><b>4.9.2</b> wk03</a></li>
<li class="chapter" data-level="4.9.3" data-path="review.html"><a href="review.html#wk04-05"><i class="fa fa-check"></i><b>4.9.3</b> wk04, 05</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="else.html"><a href="else.html"><i class="fa fa-check"></i><b>4.10</b> Else</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="else.html"><a href="else.html#hw4.-rasch-model"><i class="fa fa-check"></i><b>4.10.1</b> Hw4. Rasch Model</a></li>
<li class="chapter" data-level="4.10.2" data-path="else.html"><a href="else.html#da-example-mvn"><i class="fa fa-check"></i><b>4.10.2</b> DA) Example: MVN</a></li>
<li class="chapter" data-level="4.10.3" data-path="else.html"><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><i class="fa fa-check"></i><b>4.10.3</b> Bayesian adaptive clinical trial with delayed outcomes</a></li>
<li class="chapter" data-level="4.10.4" data-path="else.html"><a href="else.html#nmar의-종류"><i class="fa fa-check"></i><b>4.10.4</b> NMAR의 종류</a></li>
<li class="chapter" data-level="4.10.5" data-path="else.html"><a href="else.html#wk10-bayesian-model-selection"><i class="fa fa-check"></i><b>4.10.5</b> wk10) Bayesian Model Selection</a></li>
<li class="chapter" data-level="4.10.6" data-path="else.html"><a href="else.html#autologistic-model"><i class="fa fa-check"></i><b>4.10.6</b> Autologistic model</a></li>
<li class="chapter" data-level="4.10.7" data-path="else.html"><a href="else.html#wk10-bayesian-model-averaging"><i class="fa fa-check"></i><b>4.10.7</b> wk10) Bayesian Model Averaging</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mva.html"><a href="mva.html"><i class="fa fa-check"></i><b>5</b> MVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html"><i class="fa fa-check"></i><b>5.1</b> Overview of mva (not ended)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#notation"><i class="fa fa-check"></i><b>5.1.1</b> Notation</a></li>
<li class="chapter" data-level="5.1.2" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#summary-statistics"><i class="fa fa-check"></i><b>5.1.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation"><i class="fa fa-check"></i><b>5.1.3</b> Statistical Inference on Correlation</a></li>
<li class="chapter" data-level="5.1.4" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#standardization"><i class="fa fa-check"></i><b>5.1.4</b> Standardization</a></li>
<li class="chapter" data-level="5.1.5" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#missing-value-treatment"><i class="fa fa-check"></i><b>5.1.5</b> Missing Value Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html"><i class="fa fa-check"></i><b>5.2</b> Multivariate Nomral (wk2)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#overview-2"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#spectral-decomposition"><i class="fa fa-check"></i><b>5.2.2</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="5.2.3" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#properties-of-mvn"><i class="fa fa-check"></i><b>5.2.3</b> Properties of MVN</a></li>
<li class="chapter" data-level="5.2.4" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#chi2-distribution"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\Chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="5.2.5" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors"><i class="fa fa-check"></i><b>5.2.5</b> Linear Combination of Random Vectors</a></li>
<li class="chapter" data-level="5.2.6" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood"><i class="fa fa-check"></i><b>5.2.6</b> Multivariate Normal Likelihood</a></li>
<li class="chapter" data-level="5.2.7" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s"><i class="fa fa-check"></i><b>5.2.7</b> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></a></li>
<li class="chapter" data-level="5.2.8" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#assessing-normality"><i class="fa fa-check"></i><b>5.2.8</b> Assessing Normality</a></li>
<li class="chapter" data-level="5.2.9" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#power-transformation"><i class="fa fa-check"></i><b>5.2.9</b> Power Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html"><i class="fa fa-check"></i><b>5.3</b> Inference about Mean Vector (wk3)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#overview-3"><i class="fa fa-check"></i><b>5.3.1</b> Overview</a></li>
<li class="chapter" data-level="5.3.2" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#confidence-region"><i class="fa fa-check"></i><b>5.3.2</b> 1. Confidence Region</a></li>
<li class="chapter" data-level="5.3.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#simultaneous-ci"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simultaneous CI</a></li>
<li class="chapter" data-level="5.3.4" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison"><i class="fa fa-check"></i><b>5.3.4</b> 3. Note: Bonferroni Multiple Comparison</a></li>
<li class="chapter" data-level="5.3.5" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector"><i class="fa fa-check"></i><b>5.3.5</b> 4. Large Sample Inferences about a Mean Vector</a></li>
<li class="chapter" data-level="5.3.6" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5"><i class="fa fa-check"></i><b>5.3.6</b> 1. Profile Analysis (wk4, 5)</a></li>
<li class="chapter" data-level="5.3.7" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend"><i class="fa fa-check"></i><b>5.3.7</b> 2. Test for Linear Trend</a></li>
<li class="chapter" data-level="5.3.8" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix"><i class="fa fa-check"></i><b>5.3.8</b> 3. Inferences about a Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of Several MV Means (wk5)</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#paired-comparison"><i class="fa fa-check"></i><b>5.4.1</b> Paired Comparison</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations"><i class="fa fa-check"></i><b>5.4.2</b> Comparing Mean Vectors from Two Populations</a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2"><i class="fa fa-check"></i><b>5.4.3</b> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means"><i class="fa fa-check"></i><b>5.4.4</b> Comparing Several Multivariate Population Means</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html"><i class="fa fa-check"></i><b>5.5</b> Multivariate Multiple Regression (wk6)</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#overview-4"><i class="fa fa-check"></i><b>5.5.1</b> Overview</a></li>
<li class="chapter" data-level="5.5.2" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression"><i class="fa fa-check"></i><b>5.5.2</b> Multivariate Multiple Regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.5.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.5.4" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#example"><i class="fa fa-check"></i><b>5.5.4</b> Example)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>5.6</b> PCA</a></li>
<li class="chapter" data-level="5.7" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>5.7</b> Factor</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="factor.html"><a href="factor.html#method-of-estimation"><i class="fa fa-check"></i><b>5.7.1</b> Method of Estimation</a></li>
<li class="chapter" data-level="5.7.2" data-path="factor.html"><a href="factor.html#factor-rotation"><i class="fa fa-check"></i><b>5.7.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="5.7.3" data-path="factor.html"><a href="factor.html#varimax-criterion"><i class="fa fa-check"></i><b>5.7.3</b> Varimax Criterion</a></li>
<li class="chapter" data-level="5.7.4" data-path="factor.html"><a href="factor.html#factor-scores"><i class="fa fa-check"></i><b>5.7.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html"><i class="fa fa-check"></i><b>5.8</b> Discrimination and Classification</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#bayes-rule"><i class="fa fa-check"></i><b>5.8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="5.8.2" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations"><i class="fa fa-check"></i><b>5.8.2</b> Classification with Two mv <span class="math inline">\(N\)</span> Populations</a></li>
<li class="chapter" data-level="5.8.3" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#evaluating-classification-functions"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating Classification Functions</a></li>
<li class="chapter" data-level="5.8.4" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-several-populations-wk13"><i class="fa fa-check"></i><b>5.8.4</b> Classification with several Populations (wk13)</a></li>
<li class="chapter" data-level="5.8.5" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#other-discriminant-analysis-methods"><i class="fa fa-check"></i><b>5.8.5</b> Other Discriminant Analysis Methods</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html"><i class="fa fa-check"></i><b>5.9</b> Clustering, Distance Methods, and Ordination</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#overview-5"><i class="fa fa-check"></i><b>5.9.1</b> Overview</a></li>
<li class="chapter" data-level="5.9.2" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering"><i class="fa fa-check"></i><b>5.9.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="5.9.3" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#k-means-clustering"><i class="fa fa-check"></i><b>5.9.3</b> K-means Clustering</a></li>
<li class="chapter" data-level="5.9.4" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법"><i class="fa fa-check"></i><b>5.9.4</b> 군집의 평가방법</a></li>
<li class="chapter" data-level="5.9.5" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14"><i class="fa fa-check"></i><b>5.9.5</b> Clustering using Density Estimation (wk14)</a></li>
<li class="chapter" data-level="5.9.6" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>5.9.6</b> Multidimensional Scaling (MDS)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>6</b> Linear</a>
<ul>
<li class="chapter" data-level="6.1" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>6.1</b> SVD</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="svd.html"><a href="svd.html#spectral-decomposition-1"><i class="fa fa-check"></i><b>6.1.1</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="6.1.2" data-path="svd.html"><a href="svd.html#singular-value-decomposition-general-version"><i class="fa fa-check"></i><b>6.1.2</b> Singular value Decomposition: General-version</a></li>
<li class="chapter" data-level="6.1.3" data-path="svd.html"><a href="svd.html#singular-value-decomposition-another-version"><i class="fa fa-check"></i><b>6.1.3</b> Singular value Decomposition: Another-version</a></li>
<li class="chapter" data-level="6.1.4" data-path="svd.html"><a href="svd.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1.4</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.1.5" data-path="svd.html"><a href="svd.html#partitioned-matrices"><i class="fa fa-check"></i><b>6.1.5</b> Partitioned Matrices</a></li>
<li class="chapter" data-level="6.1.6" data-path="svd.html"><a href="svd.html#geometrical-aspects"><i class="fa fa-check"></i><b>6.1.6</b> Geometrical Aspects</a></li>
<li class="chapter" data-level="6.1.7" data-path="svd.html"><a href="svd.html#column-row-and-null-space"><i class="fa fa-check"></i><b>6.1.7</b> Column, Row and Null Space</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>6.2</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-1.html"><a href="introduction-1.html#what"><i class="fa fa-check"></i><b>6.2.1</b> What</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-1.html"><a href="introduction-1.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.2.2</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-1.html"><a href="introduction-1.html#multivariate-normal-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Multivariate Normal Distributions</a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-1.html"><a href="introduction-1.html#distributions-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2.4</b> Distributions of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>6.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation.html"><a href="estimation.html#identifiability-and-estimability"><i class="fa fa-check"></i><b>6.3.1</b> Identifiability and Estimability</a></li>
<li class="chapter" data-level="6.3.2" data-path="estimation.html"><a href="estimation.html#estimation-least-squares"><i class="fa fa-check"></i><b>6.3.2</b> Estimation: Least Squares</a></li>
<li class="chapter" data-level="6.3.3" data-path="estimation.html"><a href="estimation.html#estimation-best-linear-unbiased"><i class="fa fa-check"></i><b>6.3.3</b> Estimation: Best Linear Unbiased</a></li>
<li class="chapter" data-level="6.3.4" data-path="estimation.html"><a href="estimation.html#estimation-maximum-likelihood"><i class="fa fa-check"></i><b>6.3.4</b> Estimation: Maximum Likelihood</a></li>
<li class="chapter" data-level="6.3.5" data-path="estimation.html"><a href="estimation.html#estimation-minimum-variance-unbiased"><i class="fa fa-check"></i><b>6.3.5</b> Estimation: Minimum Variance Unbiased</a></li>
<li class="chapter" data-level="6.3.6" data-path="estimation.html"><a href="estimation.html#sampling-distributions-of-estimates"><i class="fa fa-check"></i><b>6.3.6</b> Sampling Distributions of Estimates</a></li>
<li class="chapter" data-level="6.3.7" data-path="estimation.html"><a href="estimation.html#generalized-least-squaresgls"><i class="fa fa-check"></i><b>6.3.7</b> Generalized Least Squares(GLS)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>6.4</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way-anova.html"><a href="one-way-anova.html#one-way-anova-1"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way-anova.html"><a href="one-way-anova.html#more-about-models"><i class="fa fa-check"></i><b>6.4.2</b> More About Models</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way-anova.html"><a href="one-way-anova.html#estimating-and-testing-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating and Testing Contrasts</a></li>
<li class="chapter" data-level="6.4.4" data-path="one-way-anova.html"><a href="one-way-anova.html#cochrans-theorem"><i class="fa fa-check"></i><b>6.4.4</b> Cochran’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>6.5</b> Testing</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="testing.html"><a href="testing.html#more-about-models-two-approaches-for-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> More About Models: Two approaches for linear model</a></li>
<li class="chapter" data-level="6.5.2" data-path="testing.html"><a href="testing.html#testing-models"><i class="fa fa-check"></i><b>6.5.2</b> Testing Models</a></li>
<li class="chapter" data-level="6.5.3" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure"><i class="fa fa-check"></i><b>6.5.3</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.4" data-path="testing.html"><a href="testing.html#testing-linear-parametric-functions"><i class="fa fa-check"></i><b>6.5.4</b> Testing Linear Parametric Functions</a></li>
<li class="chapter" data-level="6.5.5" data-path="testing.html"><a href="testing.html#theoretical-complements"><i class="fa fa-check"></i><b>6.5.5</b> Theoretical Complements</a></li>
<li class="chapter" data-level="6.5.6" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure-1"><i class="fa fa-check"></i><b>6.5.6</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.7" data-path="testing.html"><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace"><i class="fa fa-check"></i><b>6.5.7</b> Testing Single Degrees of Freedom in a Given Subspace</a></li>
<li class="chapter" data-level="6.5.8" data-path="testing.html"><a href="testing.html#breaking-ss-into-independent-components"><i class="fa fa-check"></i><b>6.5.8</b> Breaking SS into Independent Components</a></li>
<li class="chapter" data-level="6.5.9" data-path="testing.html"><a href="testing.html#general-theory"><i class="fa fa-check"></i><b>6.5.9</b> General Theory</a></li>
<li class="chapter" data-level="6.5.10" data-path="testing.html"><a href="testing.html#two-way-anova"><i class="fa fa-check"></i><b>6.5.10</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.5.11" data-path="testing.html"><a href="testing.html#confidence-regions"><i class="fa fa-check"></i><b>6.5.11</b> Confidence Regions</a></li>
<li class="chapter" data-level="6.5.12" data-path="testing.html"><a href="testing.html#tests-for-generalized-least-squares-models"><i class="fa fa-check"></i><b>6.5.12</b> Tests for Generalized Least Squares Models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>6.6</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#a-direct-solution-via-inner-products"><i class="fa fa-check"></i><b>6.6.1</b> A direct solution via inner products</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="flat.html"><a href="flat.html"><i class="fa fa-check"></i><b>6.7</b> Flat</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="flat.html"><a href="flat.html#flat-1"><i class="fa fa-check"></i><b>6.7.1</b> 1.Flat</a></li>
<li class="chapter" data-level="6.7.2" data-path="flat.html"><a href="flat.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>6.7.2</b> 2. Solutions to systems of linear equations</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="unified-approach-to-balanced-anova-models.html"><a href="unified-approach-to-balanced-anova-models.html"><i class="fa fa-check"></i><b>6.8</b> Unified Approach to Balanced ANOVA Models</a></li>
</ul></li>
<li class="part"><span><b>III 21-02</b></span></li>
<li class="chapter" data-level="7" data-path="network-stats.html"><a href="network-stats.html"><i class="fa fa-check"></i><b>7</b> Network Stats</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-2.html"><a href="introduction-2.html#types-of-network-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Types of Network Analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-2.html"><a href="introduction-2.html#network-modeling-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Network Modeling and Inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-2.html"><a href="introduction-2.html#network-processes"><i class="fa fa-check"></i><b>7.1.3</b> Network Processes</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html"><i class="fa fa-check"></i><b>7.2</b> Descriptive Statistics of Networks</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics"><i class="fa fa-check"></i><b>7.2.1</b> Vertex and Edge Characteristics</a></li>
<li class="chapter" data-level="7.2.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion"><i class="fa fa-check"></i><b>7.2.2</b> Characterizing Network Cohesion</a></li>
<li class="chapter" data-level="7.2.3" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#graph-partitioning"><i class="fa fa-check"></i><b>7.2.3</b> Graph Partitioning</a></li>
<li class="chapter" data-level="7.2.4" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing"><i class="fa fa-check"></i><b>7.2.4</b> Assortativity and Mixing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html"><i class="fa fa-check"></i><b>7.3</b> Data Collection and Sampling</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#sampling-designs"><i class="fa fa-check"></i><b>7.3.1</b> Sampling Designs</a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#coping-strategies"><i class="fa fa-check"></i><b>7.3.2</b> Coping Strategies</a></li>
<li class="chapter" data-level="7.3.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#big-data-solves-nothing"><i class="fa fa-check"></i><b>7.3.3</b> Big Data Solves Nothing</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html"><i class="fa fa-check"></i><b>7.4</b> Mathematical Models for Network Graphs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models"><i class="fa fa-check"></i><b>7.4.1</b> Classical Random Graph Models</a></li>
<li class="chapter" data-level="7.4.2" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models"><i class="fa fa-check"></i><b>7.4.2</b> Generalized Random Graph Models</a></li>
<li class="chapter" data-level="7.4.3" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms"><i class="fa fa-check"></i><b>7.4.3</b> Network Graph Models Based on Mechanisms</a></li>
<li class="chapter" data-level="7.4.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics"><i class="fa fa-check"></i><b>7.4.4</b> Assessing Significance of Network Graph Characteristics</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html"><i class="fa fa-check"></i><b>7.5</b> Introduction to ERGM</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#exponential-random-graph-models"><i class="fa fa-check"></i><b>7.5.1</b> Exponential Random Graph Models</a></li>
<li class="chapter" data-level="7.5.2" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation"><i class="fa fa-check"></i><b>7.5.2</b> Difficulty in Parameter Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html"><i class="fa fa-check"></i><b>7.6</b> Parameter Estimation of ERGM</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm"><i class="fa fa-check"></i><b>7.6.1</b> Approximation-based Algorithm</a></li>
<li class="chapter" data-level="7.6.2" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches"><i class="fa fa-check"></i><b>7.6.2</b> Auxiliary Variable MCMC-based Approaches</a></li>
<li class="chapter" data-level="7.6.3" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc"><i class="fa fa-check"></i><b>7.6.3</b> Varying Trunction Stochastic Approximation MCMC</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html"><i class="fa fa-check"></i><b>7.7</b> ERGM for Dynamic Networks</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#temporal-ergm"><i class="fa fa-check"></i><b>7.7.1</b> Temporal ERGM</a></li>
<li class="chapter" data-level="7.7.2" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm"><i class="fa fa-check"></i><b>7.7.2</b> Separable Temporal ERGM</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="latent-network-models.html"><a href="latent-network-models.html"><i class="fa fa-check"></i><b>7.8</b> Latent Network Models</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-model"><i class="fa fa-check"></i><b>7.8.1</b> Latent Position Model</a></li>
<li class="chapter" data-level="7.8.2" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-cluster-model"><i class="fa fa-check"></i><b>7.8.2</b> Latent Position Cluster Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="high-dimension.html"><a href="high-dimension.html"><i class="fa fa-check"></i><b>8</b> High Dimension</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html"><i class="fa fa-check"></i><b>8.2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation</a></li>
<li class="chapter" data-level="8.2.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#from-markov-to-chernoff"><i class="fa fa-check"></i><b>8.2.2</b> From Markov to Chernoff</a></li>
<li class="chapter" data-level="8.2.3" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.3</b> sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.4" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.4</b> Properties of sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.5" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#equivalent-definitions"><i class="fa fa-check"></i><b>8.2.5</b> Equivalent definitions</a></li>
<li class="chapter" data-level="8.2.6" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-vectors"><i class="fa fa-check"></i><b>8.2.6</b> Sub-Gaussian random vectors</a></li>
<li class="chapter" data-level="8.2.7" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#hoeffdings-inequality"><i class="fa fa-check"></i><b>8.2.7</b> Hoeffding’s inequality</a></li>
<li class="chapter" data-level="8.2.8" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#maximal-inequalities"><i class="fa fa-check"></i><b>8.2.8</b> Maximal inequalities</a></li>
<li class="chapter" data-level="8.2.9" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#section"><i class="fa fa-check"></i><b>8.2.9</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html"><i class="fa fa-check"></i><b>8.3</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#sub-exponential-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Sub-exponential random variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#bernsteins-condition"><i class="fa fa-check"></i><b>8.3.2</b> Bernstein’s condition</a></li>
<li class="chapter" data-level="8.3.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#mcdiarmids-inequality"><i class="fa fa-check"></i><b>8.3.3</b> McDiarmid’s inequality</a></li>
<li class="chapter" data-level="8.3.4" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#levys-inequality"><i class="fa fa-check"></i><b>8.3.4</b> Levy’s inequality</a></li>
<li class="chapter" data-level="8.3.5" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#quadratic-form"><i class="fa fa-check"></i><b>8.3.5</b> Quadratic form</a></li>
<li class="chapter" data-level="8.3.6" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma"><i class="fa fa-check"></i><b>8.3.6</b> The Johnson–Lindenstrauss Lemma</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html"><i class="fa fa-check"></i><b>8.4</b> Metric entropy and its uses</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#metric-space"><i class="fa fa-check"></i><b>8.4.1</b> Metric space</a></li>
<li class="chapter" data-level="8.4.2" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy"><i class="fa fa-check"></i><b>8.4.2</b> Covering numbers and metric entropy</a></li>
<li class="chapter" data-level="8.4.3" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#packing-numbers"><i class="fa fa-check"></i><b>8.4.3</b> Packing numbers</a></li>
<li class="chapter" data-level="8.4.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-1"><i class="fa fa-check"></i><b>8.4.4</b> </a></li>
<li class="chapter" data-level="8.4.5" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-2"><i class="fa fa-check"></i><b>8.4.5</b> </a></li>
<li class="chapter" data-level="8.4.6" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-3"><i class="fa fa-check"></i><b>8.4.6</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="covariance-estimation.html"><a href="covariance-estimation.html"><i class="fa fa-check"></i><b>8.5</b> Covariance estimation</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="covariance-estimation.html"><a href="covariance-estimation.html#matrix-algebra-review"><i class="fa fa-check"></i><b>8.5.1</b> Matrix algebra review</a></li>
<li class="chapter" data-level="8.5.2" data-path="covariance-estimation.html"><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm"><i class="fa fa-check"></i><b>8.5.2</b> Covariance matrix estimation in the operator norm</a></li>
<li class="chapter" data-level="8.5.3" data-path="covariance-estimation.html"><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices"><i class="fa fa-check"></i><b>8.5.3</b> Bounds for structured covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html"><i class="fa fa-check"></i><b>8.6</b> Matrix concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-calculus"><i class="fa fa-check"></i><b>8.6.1</b> Matrix calculus</a></li>
<li class="chapter" data-level="8.6.2" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-chernoff"><i class="fa fa-check"></i><b>8.6.2</b> Matrix Chernoff</a></li>
<li class="chapter" data-level="8.6.3" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices"><i class="fa fa-check"></i><b>8.6.3</b> Sub-Gaussian and sub-exponential matrices</a></li>
<li class="chapter" data-level="8.6.4" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><i class="fa fa-check"></i><b>8.6.4</b> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>9</b> Survival Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>9.2</b> </a></li>
<li class="chapter" data-level="9.3" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>9.3</b> </a></li>
<li class="chapter" data-level="9.4" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>9.4</b> </a></li>
<li class="chapter" data-level="9.5" data-path="cox-regression.html"><a href="cox-regression.html"><i class="fa fa-check"></i><b>9.5</b> Cox Regression</a></li>
<li class="chapter" data-level="9.6" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html"><i class="fa fa-check"></i><b>9.6</b> Filtration의 개념을 정복하자!</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약"><i class="fa fa-check"></i><b>9.6.1</b> Random Process를 이야기 하기까지의 긴 여정의 요약</a></li>
<li class="chapter" data-level="9.6.2" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#ft-measurable"><i class="fa fa-check"></i><b>9.6.2</b> Ft-measurable</a></li>
<li class="chapter" data-level="9.6.3" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#epilogue"><i class="fa fa-check"></i><b>9.6.3</b> EPILOGUE</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>9.7</b> Concepts</a></li>
</ul></li>
<li class="appendix"><span><b>00-00</b></span></li>
<li class="chapter" data-level="A" data-path="r-bookdown.html"><a href="r-bookdown.html"><i class="fa fa-check"></i><b>A</b> R Bookdown</a>
<ul>
<li class="chapter" data-level="A.1" data-path="tutorial.html"><a href="tutorial.html"><i class="fa fa-check"></i><b>A.1</b> Tutorial</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="tutorial.html"><a href="tutorial.html#about"><i class="fa fa-check"></i><b>A.1.1</b> About</a></li>
<li class="chapter" data-level="A.1.2" data-path="tutorial.html"><a href="tutorial.html#hello-bookdown"><i class="fa fa-check"></i><b>A.1.2</b> Hello bookdown</a></li>
<li class="chapter" data-level="A.1.3" data-path="tutorial.html"><a href="tutorial.html#cross-references"><i class="fa fa-check"></i><b>A.1.3</b> Cross-references</a></li>
<li class="chapter" data-level="A.1.4" data-path="tutorial.html"><a href="tutorial.html#parts"><i class="fa fa-check"></i><b>A.1.4</b> Parts</a></li>
<li class="chapter" data-level="A.1.5" data-path="tutorial.html"><a href="tutorial.html#footnotes-and-citations"><i class="fa fa-check"></i><b>A.1.5</b> Footnotes and citations</a></li>
<li class="chapter" data-level="A.1.6" data-path="tutorial.html"><a href="tutorial.html#blocks"><i class="fa fa-check"></i><b>A.1.6</b> Blocks</a></li>
<li class="chapter" data-level="A.1.7" data-path="tutorial.html"><a href="tutorial.html#sharing-your-book"><i class="fa fa-check"></i><b>A.1.7</b> Sharing your book</a></li>
<li class="chapter" data-level="" data-path="tutorial.html"><a href="tutorial.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="noname.html"><a href="noname.html"><i class="fa fa-check"></i><b>B</b> NoName</a></li>
<li class="chapter" data-level="C" data-path="abstract-1.html"><a href="abstract-1.html"><i class="fa fa-check"></i><b>C</b> ABSTRACT</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cox-regression" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Cox Regression</h2>
<div id="proportional-hazards-model" class="section level4" number="9.5.0.1">
<h4><span class="header-section-number">9.5.0.1</span> Proportional Hazards Model</h4>
<p>Proposed by Cox (1972, JRSS-B), primarily to model the relationship between <strong>hazard function</strong> and <strong>covariates</strong>. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science.</p>
<p>Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc.</p>
<p>※ Data Structure</p>
<p>Observed data: <span class="math inline">\(\Big \{ X_i = T_i \wedge C_i, \; \; \; \Delta_i = I(T_i &lt; C_i), \; \;\; \mathbf Z_i (\cdot) \Big \} \overset {iid} \sim\)</span></p>
<p>추가로 <span class="math inline">\(N_i = I(X_i \le t , \; \Delta_i = 1)\)</span>, <span class="math inline">\(Z_i(t)\)</span> = covariate vector (possibly time-dependent).</p>
</div>
<div id="cox-ph-model" class="section level4" number="9.5.0.2">
<h4><span class="header-section-number">9.5.0.2</span> Cox PH Model</h4>
<p><span class="math display">\[
\lambda_i (t) = \lambda (t \vert Z_i ) = \lambda_0 (t) \exp (\beta&#39; Z_i) \tag{Cox Model}
\]</span></p>
<p>semiparametric model:</p>
<ul>
<li><span class="math inline">\(\exp(\beta &#39; Z_i)\)</span>, parametric assumption on covariate effects</li>
<li>multiplicative model</li>
<li><span class="math inline">\(\beta\)</span> : <span class="math inline">\(p \times 1\)</span> vector, <span class="math inline">\(p &lt; \infty\)</span></li>
<li><span class="math inline">\(\lambda_0(t)\)</span>, nonparametric; is <span class="math inline">\(\infty\)</span> dimensional</li>
<li>shape of hazard function is unspecified</li>
</ul>
<p>Due to nonparametric component, <strong>standard maximum likelihood theory</strong> does <strong>not</strong> apply</p>
<p>Let <span class="math inline">\(Z_{ij}\)</span> be the <span class="math inline">\(j\)</span>-th element of <span class="math inline">\(Z_i\)</span>
- <span class="math inline">\(\beta_j\)</span> = difference in log hazards
- <span class="math inline">\(\exp(\beta_j)\)</span> = ratio of hazards; assumed constant for all <span class="math inline">\(t\)</span></p>
<ul>
<li><span class="math inline">\(\lambda_0(t)\)</span>: baseline hazard; common to all subjects, <span class="math inline">\(\lambda_0(t) = \lambda_i(t \big | Z_i = \mathbf 0)\)</span></li>
</ul>
<p>The hazard ratio, <span class="math inline">\(\exp(\beta_j)\)</span>, is sometimes referred to as a <strong>relative risk</strong>
- risk = <strong>probability</strong>, not a rate
- hazard is a <strong>rate</strong>, not a probability
- in ratio of hazards, time dimension cancels out</p>
<p>Direction of effect:
$$
<span class="math display">\[\begin{align}

\beta_j &gt; 0: &amp;&amp;\uparrow\lambda_i &amp;&amp;\downarrow S_i(t)
\\
\beta_j &lt; 0: &amp;&amp;\downarrow\lambda_i &amp;&amp;\uparrow S_i(t)


\end{align}\]</span>
$$</p>
<p>Magnitude of effect is easy to interpret w.r.t. <span class="math inline">\(\lambda_i(t)\)</span></p>
<p>Cumulative hazard function:</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_i (t) &amp;= \lambda_0(t) \exp(\beta Z_i)
\\
\Lambda_i (t) &amp;= \int_0^t \lambda_0(s) \exp(\beta Z_i) ds
\\
&amp;= \Lambda_0(t) \exp(\beta Z_i)

\end{align}\]</span>
$$</p>
<p>Survival function:</p>
<p>$$
<span class="math display">\[\begin{align}
S_i (t) &amp;= \exp \Big \{ -\Lambda_i (t) \Big\}
\\
&amp;= \exp \Big \{ -\Lambda_0 (t) \exp(\beta &#39; Z_i)\Big\}
\\
&amp;= S_0(t)^{\exp \Big \{ \beta&#39;Z_i \Big\}}


\end{align}\]</span>
$$</p>
<p>By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard:
- ex) randomized trial: treatment (<span class="math inline">\(Z_i=1\)</span>) versus placebo (<span class="math inline">\(Z_i=0\)</span>); <span class="math inline">\(\hat \beta = 0.405\)</span> (<span class="math inline">\(\exp(\hat \beta)=1.5\)</span>)
- <span class="math inline">\(\lambda_i(t)\)</span> for treated patients is 50% more of that of the controls.
- irrespective of <span class="math inline">\(\lambda_0(t)\)</span></p>
<p>Nevertheless, <span class="math inline">\(\Lambda_0(t)\)</span> is required in order to <strong>determine <span class="math inline">\(Z_i\)</span>’s effect on <span class="math inline">\(S_i(t)\)</span></strong>, e.g.,</p>
<p>$$
<span class="math display">\[\begin{align}

S(t \Big | Z_i = 0) = 0.95 &amp;&amp; vs. &amp;&amp; S(t \Big | Z_i = 1) = 0.93


\\
S(t \Big | Z_i = 0) = 0.70 &amp;&amp; vs. &amp;&amp; S(t \Big | Z_i = 1) = 0.59



\end{align}\]</span>
$$</p>
<div id="cox-model-independent-censoring" class="section level6" number="9.5.0.2.0.1">
<h6><span class="header-section-number">9.5.0.2.0.1</span> Cox Model: Independent Censoring</h6>
<p>Independent censoring assumption is less stringent than in nonparametric estimation.</p>
<p>Assumption is often written as <span class="math inline">\(T_i \perp C_i \Big \vert Z_i\)</span>:
$$
<span class="math display">\[\begin{alignat}{2}

&amp;\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i &lt; t+ \delta \Big | T_i \ge t , \; C_i \ge t , &amp;&amp;\; Z_i)
\\
= &amp;\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i &lt; t+ \delta \Big | T_i \ge t ,  &amp;&amp;\; Z_i)

\end{alignat}\]</span>
$$</p>
<p>※ Note: <span class="math inline">\(C_i\)</span> is allowed to depend on <span class="math inline">\(Z_i\)</span></p>
</div>
</div>
<div id="semiparametric-ph-model-general" class="section level4" number="9.5.0.3">
<h4><span class="header-section-number">9.5.0.3</span> Semiparametric PH Model: General</h4>
<ul>
<li>General expression for multiplicative proportional hazards model:</li>
</ul>
<p><span class="math display">\[
\lambda_i (t) = \lambda_0 (t) g(\beta &#39; Z_i )
\]</span></p>
<p><span class="math inline">\(g(x)\)</span> is link function, specified. <span class="math inline">\(\forall x: g(x) \ge 0\)</span>, <span class="math inline">\(\exists g&#39;&#39;(x)\)</span>, and in special case, <span class="math inline">\(g(x) = \exp(x)\)</span>.</p>
<ul>
<li>Other choices for link function (e.g., Self &amp; Prentice, 1983):
<span class="math inline">\(g(x) = 1+x = (1+x)^{-1} = \log(1+x)\)</span></li>
</ul>
<p>※ Notes:
- not all choices of <span class="math inline">\(g(x)\)</span> lead to clear interpretation of <span class="math inline">\(\beta_j\)</span>
- certain choices of <span class="math inline">\(g(x)\)</span> lead to numerical issues; e.g., likelihood is flat; local maxima, etc.
- <span class="math inline">\(g(x) \not = exp(x)\)</span> has received little attention in the literature</p>
</div>
<div id="multiplicative-model" class="section level4" number="9.5.0.4">
<h4><span class="header-section-number">9.5.0.4</span> Multiplicative Model</h4>
<p><strong>Cox model</strong> is a <strong>multiplicative model</strong>, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard.</p>
<ul>
<li>Additive models also been proposed</li>
</ul>
<p><span class="math display">\[
\]</span></p>
</div>
<div id="proportional-hazards-regression-and-multiplicative-intensity-model" class="section level4" number="9.5.0.5">
<h4><span class="header-section-number">9.5.0.5</span> Proportional Hazards Regression and Multiplicative Intensity Model</h4>
<ul>
<li>Recall Counting process: martingale representation</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

N(t) &amp;= I(X\le t , \; \Delta = 1)
\\
Y(t) &amp;= I(X \ge t)
\\
M(t) &amp;= N(t) - \int_0^t Y(u)\lambda_0(u) e^{\beta &#39; Z } du \tag{1}
\\
\mathcal F_t &amp;= \sigma \Big \{ N(u) , Y(u+) , Z: \; \; 0 \le u \le t \Big \}



\end{align}\]</span></p>
<p>$$</p>
<ol style="list-style-type: decimal">
<li>intensity <span class="math inline">\(l(u) = Y(u)\lambda_0(u) e^{\beta &#39; Z }\)</span>, therefore integrated form is cumulative intensity <span class="math inline">\(A(t)\)</span>.</li>
</ol>
<ul>
<li>Multiplicative Intensity Model:</li>
</ul>
<p><span class="math display">\[
l(t) = Y(t)\lambda_0(t) e^{\beta &#39; Z(t) }
\]</span></p>
<ul>
<li><p>Counting process: <span class="math inline">\(N(t)\)</span> = Number of events of a specified type that have occurred by time <span class="math inline">\(t\)</span></p>
<ul>
<li><span class="math inline">\(N(t)\)</span> may take more than one jump</li>
<li>multiple infections, repeated breakdowns, hospital admissions</li>
<li><span class="math inline">\(EN(t) &lt; \infty\)</span></li>
</ul></li>
<li><p>At-risk process: <span class="math inline">\(Y(t)\)</span>, left-continuous process, <span class="math inline">\(1\)</span> if failure can be observed at time <span class="math inline">\(t\)</span>, otherwise <span class="math inline">\(0\)</span>.</p>
<ul>
<li><span class="math inline">\(Y(t)\)</span> can be used to represent situation in which a subject enter and exit risk sets several times</li>
<li><span class="math inline">\(Y(t)\)</span> may be <span class="math inline">\(1\)</span> even after an observed failure</li>
</ul></li>
<li><p>Covariate process: <span class="math inline">\(Z(t)\)</span> = (bounded) predictable process</p>
<ul>
<li>time-dependent treatment, risk factors</li>
<li>model checking and relaxing PH assumption</li>
</ul></li>
<li><p>Baseline hazard function: <span class="math inline">\(\lambda_0(\cdot)\)</span> = an arbitrary deterministic function</p></li>
<li><p>Filtration: <span class="math inline">\(\mathcal F_t = \sigma \Big \{ N(u) , Y(u+) , Z(u): \; \; 0 \le u \le t \Big \}\)</span></p></li>
<li><p>Martingale: <span class="math inline">\(M(t) = N(t) - \int_0^t l(u) du\)</span></p></li>
<li><p>Intensity function: $ E { dN(t) | F_{t-} } = l(t) dt$</p></li>
<li><p>Data: <span class="math inline">\(n\)</span> independent observations on $ { N(), ; Y(), ; Z() }$</p></li>
</ul>
</div>
<div id="likelihood-conditional-marginal-and-partial-likelihoods" class="section level4" number="9.5.0.6">
<h4><span class="header-section-number">9.5.0.6</span> Likelihood; conditional, marginal and partial likelihoods</h4>
<ul>
<li><p><span class="math inline">\(X =\)</span> vector of observations; <span class="math inline">\(f_X(x, \theta) =\)</span> density of <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\theta =\)</span> vector parameter; <span class="math inline">\(\theta = (\beta &#39; , \phi&#39;)&#39;\)</span></p></li>
<li><p><span class="math inline">\(\beta =\)</span> parameter of interest; <span class="math inline">\(\phi =\)</span> nuisance parameter</p></li>
<li><p><strong>likelihood</strong>: <span class="math inline">\(f_X(x, \theta) = f_{W|V} (w \Big | v, \theta )f_V (v, \theta)\)</span></p>
<ul>
<li><span class="math inline">\(X = (V&#39;, W&#39;)&#39;\)</span></li>
<li>infinite-dimensional <span class="math inline">\(\phi\)</span></li>
<li><span class="math inline">\(f_{W|V} (w \Big | v, \theta )\)</span> does not involve <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use <span class="math inline">\(f_{W|V} (w \Big | v, \beta )\)</span> (conditional likelihood)</li>
<li><span class="math inline">\(f_V (v, \theta)\)</span> does not involve <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use <span class="math inline">\(f_V (v, \beta)\)</span> (marginal likelihood)</li>
</ul></li>
</ul>
<p><span class="math display">\[
X = (V_1 , W_1 , \cdots, V_K , W_K)
\]</span></p>
<p>$$
<span class="math display">\[\begin{align}


f_X(x, \theta) &amp;= f_{V_1 , W_1 , \cdots, V_K , W_K} (v_1 , w_1 , \cdots, v_K , w_K\; ;\; \theta)
\\

&amp;= 
f_{V_1}(v_1 \; ; \; \theta)

f_{W_1 | V_1}(w_1 | v_1\; ; \; \theta)

f_{V_2 | V_1, W_1}(v_2 |  v_1, w_1\; ; \; \theta) \times \cdots

\\

&amp;= \left \{ \prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \theta) \right \}


\left \{ \prod_{i=1}^K f_{V_i | P_i } (v_i \Big | p_i \; ; \theta) \right \}

\end{align}\]</span>
$$</p>
<p>$$
<span class="math display">\[\begin{align}


P_1 = \phi,&amp; &amp;&amp; P_i =(V_1 , W_1 , \cdots, V_{i-1} , W_{i-1})
\\
Q_1 = V1,&amp; &amp;&amp; Q_i =(V_1 , W_1 , \cdots , W_{i-1}, V_i)

\end{align}\]</span>
$$</p>
<p>$<em>{i=1}^K f</em>{W_i | Q_i } (w_i | q_i ; ; ) $ is free of <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use $ <em>{i=1}^K f</em>{W_i | Q_i } (w_i | q_i ; ; ) $ (partial likelihood)</p>
<div id="partial-marginal-likelihoods" class="section level6" number="9.5.0.6.0.1">
<h6><span class="header-section-number">9.5.0.6.0.1</span> Partial &amp; Marginal Likelihoods</h6>
<p>Focus on Proportional Hazards Model: i.e., <span class="math inline">\((X_i, \; \delta_i, \; Z_i), \; i = 1, \cdots, n\)</span> (<span class="math inline">\(n\)</span> independent triplets)</p>
<p>$$
<span class="math display">\[\begin{align}

&amp;\lambda(t \Big | Z ) = \lambda_0 (t) e^{\beta &#39; Z} &amp;&amp;S(t \Big | Z) = \Big \{ S_0(t) \Big \}^{e^{\beta &#39; Z}} \tag{1}

\end{align}\]</span>
$$</p>
<p>위에서 $ _0 (t)$는 <strong>unspecified</strong>.</p>
<ul>
<li><strong>Partial Likelihood</strong>: assume no ties, absolutely continuous failure distribution</li>
</ul>
<p>Suppose there are L observed failures at <span class="math inline">\(\tau_1 &lt; \cdots &lt; \tau_L\)</span> (set <span class="math inline">\(\tau_0 \equiv 0\)</span> &amp; <span class="math inline">\(\tau_{L+1} \equiv \infty\)</span>)</p>
<p>16.png</p>
<p>Let (i) be the label for individual failing at <span class="math inline">\(\tau_i\)</span> (set <span class="math inline">\((L + 1) \equiv n + 1\)</span>). Note <span class="math inline">\(t_{(i)} = \tau_i\)</span></p>
<p>Covariates for <span class="math inline">\(L\)</span> failures: <span class="math inline">\((Z_{(1)}, \cdots, Z_{(L)})\)</span>. (Hereafter, condition on $ { Z_i : i = 1, , n }$)</p>
<p>Censorship times in <span class="math inline">\([\tau_i; \tau_{i+1})\)</span>: <span class="math inline">\((\tau_{i1}, \cdots, \tau_{i, m_i})\)</span> with covariates <span class="math inline">\((Z_{(i,1)}, \cdots, Z_{(i,m_i)})\)</span>, i.e., <span class="math inline">\((i, j)\)</span> is label for item censored at <span class="math inline">\(\tau_{ij}\)</span></p>
<p>17.png</p>
<p>The data can be divided into sets</p>
<p><span class="math display">\[
(V_1 , W_1, \cdots, V_{L+1} ,  W_{L+1})
\]</span></p>
<p>where, for <span class="math inline">\(i = 1, \cdots, L, L+1\)</span>,</p>
<p>$$
<span class="math display">\[\begin{align}
V_i &amp;= \Big \{ \tau_i , \tau_{i-1, j}  \; \; ; \; \; (i-1, j):j = 1, \cdots, m_{i-1} \Big \}

\\

and \; \; \; \;W_i &amp;= \Big \{ (i) \Big \}


\end{align}\]</span>
$$</p>
<p>18.png</p>
<p>19.png</p>
<p>GOAL: Build a likelihood on a subset of the full data set
- carrying most of the information about <span class="math inline">\(\beta\)</span>
- carrying no information on nuisance parameters <span class="math inline">\(\Big \{ \lambda_0 (t) : t \ge 0 \Big \}\)</span></p>
<p>PROPOSAL: Generate likelihood of <span class="math inline">\(\Big \{ W_1, \cdots, W_L \Big \}\)</span></p>
<p>JUSTIFICATION, WHY?:
- Timing of events <span class="math inline">\(\Big \{ \tau_1 , \cdots, \tau_L \Big \}\)</span> can be explained by <span class="math inline">\(\lambda_0(\cdot)\)</span>.
- Censoring <strong>times and labels</strong> can be ignored if we assume <strong>non-informative censorship</strong> (independent censoring).</p>
<p>So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data.</p>
<p>If <span class="math inline">\(Q_i \equiv (V_1, W_1 , \cdots, V_{i-1}, W_{i-1}, V_i)\)</span> and <span class="math inline">\(\mathcal F_{\tau_i} \equiv (Q_i, Z)\)</span>, the partial likelihood is <span class="math inline">\(\prod_{i=1}^L P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)\)</span>, i.e., given the risk set at <span class="math inline">\(\tau_i\)</span>, and given event occurs at <span class="math inline">\(\tau_i\)</span>.</p>
<p>Denote <span class="math inline">\(R_i \equiv \Big \{ j : X_j \ge \tau_i \Big \}\)</span> as risk set at <span class="math inline">\(\tau_i\)</span>. Then, by the assumption of independent censoring,</p>
<p>$$
<span class="math display">\[\begin{align}
P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)




&amp;=
\frac{


P \Bigg \{ t_{(i)} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - (i)} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} 
}{

\sum\limits_{l \in R_i} 
\left[
P \Bigg \{ t_{l} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - l} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}
\right]
}
\tag{a}





\\
\\
\\


&amp;=
\frac{
d\Lambda \Big( \tau_i \Big | Z_{(i)} \Big)
\prod\limits_{j \in R_i - (i)} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \}
}{
\sum\limits_{l \in R_i} \left [ d\Lambda \Big( \tau_i \Big | Z_{l} \Big)
\prod\limits_{j \in R_i - l} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \} \right ]
}


\; \; \; \div \; \; \; \frac{d\tau_i}{d\tau_i}

\tag{2}
\\
\\
\\

&amp;= \frac{\lambda\Big(\tau_i \Big | Z_{(i)} \Big)}{ \frac{P \Big\{T\in [t, t+dt) \Big | T \ge t , Z \Big\}}{dt}= \sum\limits_{l\in R_i} \left[ \lambda\Big(\tau_i \Big | Z_{l} \Big) \right]}

\; \; \; \overset {(1)}{=}  \; \; \; 


\frac{\exp(\beta &#39; Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta &#39; Z_{l})}





\end{align}\]</span>
$$
- at (a), <span class="math inline">\(P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} = 1 - P \Bigg \{ t_{j} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}\)</span>
- at (2), $ d( <em>i | Z</em>{j} ) = 0$</p>
<p>Thus, the <strong>Partial Likelihood</strong> is</p>
<p><span class="math display">\[
\prod^L_{i=1}\frac{\exp(\beta &#39; Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta &#39; Z_{l})} = L(\beta)\tag{3}
\]</span></p>
<p>Note: unspecified <span class="math inline">\(\lambda_0(\cdot)\)</span> + noninformative censoring <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\prod\limits_{i=1}^L f_{V_i \big | P_i} (v_i \Big | p_i ; \theta)\)</span> contains little or no information about <span class="math inline">\(\beta\)</span>.</p>
<ul>
<li>Counting process notation:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}
L(\beta) = \prod^n_{i=1}\prod_{t\ge0} \left \{ 

\frac{\exp(\beta &#39; Z_{i})}{\sum\limits_{j=1}^n Y_j(t) \exp(\beta &#39; Z_{j})}

\right\}^{dN_i(t)}


, &amp;&amp; dN_i(t) = \begin{cases} 1 &amp; N_i(t) - N_i {(t-)} =1\\0 &amp; o.w.\end{cases}

\end{align}\]</span>
$$</p>
<ul>
<li><p>Maximum partial likelihood estimator (MPLE): <span class="math inline">\(L( \hat \beta) = \max_\beta L(\beta)\)</span> (using Newton-Raphson (NR) algorithm)</p>
<ul>
<li>Specifically, the <strong>log partial likelihood</strong> is then</li>
</ul>
<p><span class="math display">\[
l(\beta) = \sum_{i=1}^n \int_0^\infty \left[ Y_i (t) Z_i \beta - \log\left( \sum_{j=1}^n Y_j(t) \exp(\beta &#39; Z_j ) \right) \right]dN_i(t)
\]</span></p>
<ul>
<li><strong>The score vector</strong>, <span class="math inline">\(U(\beta)\)</span>, can be obtained by differentiating <span class="math inline">\(l(\beta)\)</span> w.r.t. <span class="math inline">\(\beta\)</span>:</li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}
U(\beta) &amp;= \sum_{i=1}^n \int_0^\infty \Big \{ Z_i - \bar Z(\beta, t) \Big \}&amp;&amp;dN_i (t)

\\

&amp;= \sum_{i=1}^n \int_0^\infty \left \{ Z_i - \frac{\sum_{i=1}^n Y_i (t) Z_i \exp(\beta &#39; Z_i)}{\sum_{i=1}^n Y_i (t) \exp(\beta &#39; Z_i)} \right \}&amp;&amp;dN_i (t)

\end{alignat}\]</span>
$$</p>
<ul>
<li><p>where <span class="math inline">\(\bar Z(\beta, t)\)</span> is a weighted mean of <span class="math inline">\(Z\)</span> over those observations still at risk at time <span class="math inline">\(t\)</span>.</p></li>
<li><p>The information matrix, <span class="math inline">\(\mathcal I(\beta)\)</span>, is the negative second derivative where</p></li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

\mathcal I(\beta) &amp;= \sum\limits_{i=1}^n \int_0^\infty V(\beta, t) dN_i(s)

\\
\\

V(\beta, t) &amp;= \frac{\sum\limits_{i=1}^n Y_i(t) \exp(\beta &#39; Z_i ) \Big \{ Z_i - \hat Z (\beta, t)\Big\}&#39;\Big \{ Z_i - \hat Z (\beta, t)\Big\}}{\sum\limits_{i=1}^n Y_i(t) \exp(\beta &#39; Z_i )}

\end{align}\]</span>
$$</p>
<ul>
<li>and <span class="math inline">\(V(\beta, t)\)</span> is the weighted variance of <span class="math inline">\(Z\)</span> at time <span class="math inline">\(t\)</span>.</li>
</ul></li>
</ul>
<p>Then, the MPLE, <span class="math inline">\(\hat \beta\)</span>, is found by solving the partial likelihood equation: <span class="math inline">\(U(\hat \beta) = 0\)</span>.</p>
<p>Under some regularity conditions, <span class="math inline">\(\hat \beta\)</span> is consistent and asymptotically normally distributed with mean <span class="math inline">\(\beta\)</span> and variance <span class="math inline">\(E \Big \{ \mathcal I(\beta) \Big\}^{-1}\)</span> (will be shown later.)</p>
<p>The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value <span class="math inline">\(\hat \beta^{(0)}\)</span>).</p>
<p><span class="math display">\[
\hat\beta^{(n+1)} = \hat\beta^{(n)} + \mathcal I ^{-1} \Big( \hat \beta^{(n)}\Big) \cdot U \Big( \hat \beta^{(n)}\Big)
\]</span></p>
<p>※ Note:
1. (incredibly) Robust algorithm!
2. <span class="math inline">\(\hat \beta^{(0)} = 0\)</span> usually works.</p>
</div>
</div>
<div id="cox-proportional-hazards-model" class="section level4" number="9.5.0.7">
<h4><span class="header-section-number">9.5.0.7</span> Cox Proportional Hazards Model</h4>
<p>Cox model:</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_i(t) = \lambda(t \Big | Z_i ) 
&amp;= \lambda_0 (t) \exp(\beta &#39; Z_i) 
\\
&amp;= \lambda_0(t) \exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})
\\
&amp;\Updownarrow
\\

\log \lambda(t \Big | Z_i ) &amp;= \log \Big[ \lambda_0(t) \Big] +\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik}
\\
S(t \Big | Z_i ) &amp;= 



\Big[ S_0(t) \Big]^{\exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})}


\end{align}\]</span>
$$</p>
<p>※ Note:</p>
<p>$$
<span class="math display">\[\begin{align}
\lambda_0 (t) &amp;= \lambda(t \Big | Z_1 = \cdots = Z_k = 0)
\\
\\
\exp(\beta_1 Z_{1} + \cdots + \beta_k Z_{k}) &amp;= RR 



\\
&amp;= \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 = \cdots = Z_k = 0)} \tag{1}
\end{align}\]</span>
$$
- (1) is relative risk of hazard of death comparing covariates values <span class="math inline">\(Z_1,\cdots, Z_k\)</span> to <span class="math inline">\(Z_1 = \cdots = Z_k = 0\)</span></p>
<p>Interpreting Cox Model Coeffcients: <span class="math inline">\(\beta_k\)</span> is the log RR (hazard ratio) for a unit change in <span class="math inline">\(Z_k\)</span>, given all other covariates remain constant, i.e.,</p>
<p>$$
<span class="math display">\[\begin{align}


\frac
{\lambda\Big[t \Big | Z_1 , \cdots, (Z_{k&#39;}+1), \cdots, Z_k \Big]}
{\lambda\Big[t \Big | Z_1 , \cdots, Z_{k&#39;}, \cdots, Z_k \Big]} 


&amp;= \exp \Big (\beta_1 \cdot 0 + \cdots + \beta_{k&#39;} \cdot (Z_{k&#39;} +1 - Z_{k&#39;}) + \cdots + \beta_k \cdot 0 \Big)

\\

&amp;= \exp(\beta_{k&#39;})


\end{align}\]</span>
$$</p>
<p>The RR comparing 2 sets of values for the covariates <span class="math inline">\((Z_1 , \cdots, Z_k)\)</span> vs. <span class="math inline">\((Z_1&#39; , \cdots, Z_k&#39;)\)</span>:</p>
<p><span class="math display">\[
RR = \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 &#39;, \cdots, Z_k&#39;)} =\exp \Big \{ \beta_1(Z_1 - Z_1&#39;) + \cdots + \beta_k(Z_k - Z_k&#39;) \Big \}
\]</span></p>
<p>20.png</p>
</div>
<div id="comparison-of-nested-models" class="section level4" number="9.5.0.8">
<h4><span class="header-section-number">9.5.0.8</span> Comparison of Nested Models</h4>
<ul>
<li>Nested Models:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

\lambda(t) &amp;= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p + \beta_{p+1} Z_{p+1} +\cdots + \beta_{k} Z_{k}\Big) \tag{Full Model}

\\

&amp;= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p \Big) \tag{Reduced Model}


\end{align}\]</span></p>
<p>$$</p>
<p>To test:</p>
<ul>
<li>Nested Models:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

&amp;H_0:  &amp;&amp;RM &amp;&amp; \Leftrightarrow &amp;&amp; H_0: \beta_{p+1} = \cdots = \beta_k = 0
\\
&amp;H_A:  &amp;&amp;RM &amp;&amp; \Leftrightarrow &amp;&amp; H_A:  \not = \text{ somewhere}

\end{align}\]</span></p>
<p>$$</p>
<p>Use the <strong>partial likelihood ratio statistic</strong>, <span class="math inline">\(X^2_{Cox} = -2 \Big[ \log PL(RM) - \log PL(FM)\Big]\)</span>.</p>
<p>Under <span class="math inline">\(H_0\)</span>: Reduced model, and when <span class="math inline">\(n\)</span> is large:
<span class="math display">\[
\begin{align}
X^2_{Cox} \sim \chi^2_{k-p} &amp;&amp; k-p \text{ is the ## of parameters set to 0 by }H_0
\end{align}
\]</span></p>
<p>20.png, 21.png</p>
</div>
<div id="stratification" class="section level4" number="9.5.0.9">
<h4><span class="header-section-number">9.5.0.9</span> Stratification</h4>
<p>Two Ways to Stratify. Suppose a confounder <span class="math inline">\(C\)</span> has 3 levels on which we would like to stratify when comparin
g <span class="math inline">\(\lambda(t \Big | E )\)</span> and <span class="math inline">\(\lambda ( t \Big | \bar E )\)</span>. How? <span class="math inline">\(X_E = \begin{cases}1&amp;E&amp;\text{(exposed)}\\0&amp;\bar E&amp;\text{(not exposed)}\end{cases}\)</span></p>
<p>22.png</p>
<ul>
<li>Which Way to Stratify?</li>
</ul>
<ol style="list-style-type: decimal">
<li>Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder <span class="math inline">\(C\)</span> may be inadequately controlled.</li>
<li>Proportionality assumption can be checked using time-dependent covariates.</li>
<li>True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If <span class="math inline">\(C\)</span> can be measured continuously and the strata were formed by grouping values of it, better control for <span class="math inline">\(C\)</span> might be achieved with continuous (could be time-dependent) covariate adjustment.</li>
<li>If <span class="math inline">\(C\)</span> is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of <span class="math inline">\(C\)</span>. However, we can estimate <span class="math inline">\(\lambda_{0i}(t)\)</span> for each stratum then we can estimate a RR function.</li>
<li>True stratification generally requires more data to obtain the same precision in coefficient estimates.</li>
</ol>
<p>23.png</p>
<p>24.png</p>
</div>
<div id="test-statistics" class="section level4" number="9.5.0.10">
<h4><span class="header-section-number">9.5.0.10</span> Test statistics</h4>
<p>The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood.</p>
<p>25.png</p>
<p>Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least.</p>
<p>26.png</p>
<p>When <span class="math inline">\(p = 1\)</span> and the single covariate is categorical, the score test is identical to the log-rank test.</p>
<p>27.png</p>
</div>
<div id="handling-ties" class="section level4" number="9.5.0.11">
<h4><span class="header-section-number">9.5.0.11</span> Handling ties</h4>
<p>Real data sets often contain tied event times.</p>
<ul>
<li>When do we have ties?</li>
</ul>
<ol style="list-style-type: decimal">
<li>Continuous event times are grouped into intervals.</li>
<li>Event time scale is discrete.</li>
</ol>
<p>Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood.</p>
<p>When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the <span class="math inline">\(i\)</span>-th event at time <span class="math inline">\(t_i\)</span> is <span class="math inline">\(\frac{\exp(\beta &#39; Z_i)}{ \sum\limits_{j \in R_i} Y_j(t_i) \exp(\beta &#39; Z_j)}\)</span></p>
<p>Two commonly used methods are
1. Breslow approximation
2. Efron approximation</p>
<p>Example: Assume 5 subjects are at risk of dying at time <span class="math inline">\(t\)</span> and two die at the same time <span class="math inline">\(t\)</span> (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either</p>
<p>28.png</p>
<p>29.png</p>
<p>30.png</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-6.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="filtration의-개념을-정복하자.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/212505_Cox.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
