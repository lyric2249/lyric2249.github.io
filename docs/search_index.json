[["index.html", ". Intro", " . Intro "],["introduction.html", "Chapter 1 Introduction 1.1 Censoring Sources 1.2 1. Right Censoring (most of the course) 1.3 2. Left Censoring", " Chapter 1 Introduction SA의 결과물은 보통 time-to-event, 즉슨 대부분의 경우에 nonnegative이며, 이는 곧 time domain을 한정함. time-to-event의 distribution은 보통 skewed. Survival data은 자주 right censored. 조사 대상자들은 조사 기간중에만 생존했음을 알며, 조사 기간 넘어서 죽으면 해당 시간이 정확히 기록되지 않음. tail probability. 충분한 후속연구 후에는, tail of survival curve에 해당하는 subject들이 보통 되게 적음. estimation of the tail of the survival curve can be quite difficult. tail에서 survival density는 엄청 적어짐. 따라서 총 표본 수가 많이 확보되어 있지 않으면 tail에 해당하는 분석결과는 확보하기가 어렵다. 모든 연구의 시간은 finite이므로 모든 subjects들에게서 발생한 event of interest 중 일부는 육안으로 관찰 못 할수도 있다. 장기적으로 발생은 했는데, 그게 우리 손닿는 곳에서 터지지 않았음. 일반적으로 관측안된 failure time 들이 포함되어 있으면 기존 통계 테크닉은 사용할 수 없음. failure time 이 관측되지 않은 subject들은 censored 되었다고 표현. censored observations를 포함한 자료에서 정보를 뽑아내는 것이 SA의 estimation methods의 목적. 1.1 Censoring Sources Adminisitrative censoring event 발생 전에 연구 종료 often independent of failure time Loss to follow-up subject들이 더이상 트랙 불과, 관찰 하에 있지 않음 (후속연구 개시했는데 예전에 살던 사람이 동네 떠났음) censoring may be related (indirectly) to the failure time withdrawl from study 너무 아프거나 증상이 낫던가 해서 연구에서 이탈 dependent censoring (informative drop-out), censoring이 failure time에 연관되어 있다는 점이 고민해야할 거리가 된다. 1.1.0.0.0.1 임시방편 censor된 시간을 failure time으로 인식. \\[\\bar X \\le E(X)\\] (underestimate). censor 관측치를 전부 삭제. loss of infomration. 1.1.0.1 notation \\[T_i\\]: potential failure time for the i-th subject \\[C_i\\]: potential censoring time for the i-th subject \\[X_i = \\min(T_i , C_i )\\] observed time \\[\\delta_i = \\begin{cases} 1, &amp; T_i \\le C_i &amp; \\text{(uncensored)} \\\\ 0, &amp; T_i &gt; C_i &amp; \\text{(censored)} \\end{cases}\\] 1.2 1. Right Censoring (most of the course) Fail이 확실하게 터진 경우에만 fail, 이외의 경우에는 censor. 조사기간 종료까지 발병하지 않았거나, 이외의 이유로 종료 이전에 연구 이탈하면 양쪽 모두 censored. 1.2.0.1 Type of Data to be analyzed in survival analysis Type Ⅰ Censoring: 특정 시점이 왔을 때 연구 종료. ex) 쥐한테 특정 영양소 먹이고 언제까지 생존하는지 Progressive Type Ⅰ Censoring: 대상들이 다른, 고정된 sacrifice time 보유 ex) 도즈 레벨 4개로 나누고 각 그룹에 다른 sacrifice 기간 적용, 비용 효율화 Generalized Type Ⅰ Censoring: subject들이 각각 다른 시기에 연구에 참여개시하고 정해진 시간에 연구 종료됨. subject가 참여할 때 censoring time 다 알려짐. Type Ⅱ Censoring: reliabilty 분석에서 흔함. 특정 횟수 failure 발생시 연구 종료. ※ Right Censoring: 개인의 정확한 survival time은 follow-up period의 우측에서는 incomplete해짐. Random Censoring: Censoring times are random. ※ let’s focus on right censoring. Suppose \\[T_1 , \\cdots, T_n \\sim f(t)\\] and \\[C_1 , \\cdots, C_n \\sim g(c)\\]. Then, we observe \\[X_i = \\min(T_i , C_i )\\] for \\[i = 1, \\cdots, n\\]. In type Ⅰ censoring, \\[C_i\\] is fixed (at \\[C_r\\] or \\[C_{r_i}\\]). In random censoring, \\[C_i\\] is random. 1.3 2. Left Censoring less common in practice $$ \\[\\begin{align} \\lambda(t) S(t)&amp;= f(t) \\\\ \\lambda(t) &amp;= \\dfrac{f(t)}{S(t)} \\\\ \\lambda(t) &amp;= \\dfrac{f(t)}{} \\dfrac{d}{dS(t)}\\log S(t) \\\\ \\end{align}\\] $$ $$ \\[\\begin{align} \\lambda(t) &amp;= - \\dfrac{d}{dt} \\log S(t) \\\\ \\lambda(t) &amp;= - \\dfrac {dS(t)}{dt} \\dfrac{d}{dS(t)} \\log S(t) \\\\ \\lambda(t) &amp;= - \\dfrac {d[1-F(t)]}{dt} \\dfrac{1}{S(t)} \\\\ \\lambda(t) &amp;= - (-f(t)) \\dfrac{1}{S(t)} \\\\ S(t)\\lambda(t) &amp;= f(t) \\end{align}\\] $$ \\[ A = A&#39;\\; \\; \\; \\Longrightarrow \\; \\; \\; \\exists \\text{basis for } C(A):\\text{constisting of evec of nonzero ev&#39;s.} \\] linear transformation, span, trace, nonsingular, null space \\[ tr(ABC) = tr(BCA)=tr(CAB) \\] \\[ r(A_{n \\times n})=r, \\; \\; \\; r[\\mathcal{N}(A)] = n-r \\] \\(\\lambda\\) is ev of \\(A\\), \\(v\\) is evec of \\(A\\). $$ \\[\\begin{alignat}{3} &amp;\\forall \\lambda_i \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; \\forall v_i : &amp;&amp; span(v_i) \\subset \\mathcal{C}(A) \\\\ &amp;A = A&#39;, \\; \\lambda_i \\not = \\lambda_j &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; v_i \\perp v_j, &amp;&amp; &amp;&amp;span(v_i, v_j) \\subset \\mathcal{C}(A) \\\\ &amp;\\exists A^{-1} &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; \\prod \\lambda\\not = 0 &amp;&amp; &amp;&amp; \\\\ &amp;A = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;\\exists \\text{basis for } \\mathcal{C}(A) \\text{ consists of } v_i \\text{ of } \\lambda_i \\not = 0 \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\prod \\lambda \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; \\mathcal C (A)=\\mathbb R^n, &amp;&amp; &amp;&amp;span( v) = \\mathbb{R}^n \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\forall \\lambda_i \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;span(\\forall v_i) = \\mathcal{C}(A) \\subset \\mathbb{R}^n \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\forall \\lambda_i = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;span(\\forall v_i) = \\mathcal{N}(A) \\\\ &amp;A = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;\\mathcal{N}(A) = \\mathcal C (A)^\\perp \\\\ &amp;A_{n \\times n} = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp; \\exists v_i : span(v_i) = \\mathcal C (A), \\; v_i \\perp v_j \\; \\; \\tiny {\\bigoplus} \\; \\; \\normalsize \\exists A^{-1} : \\mathcal C(A) = \\mathbb{R}^n \\; \\; \\tiny {\\bigoplus} \\; \\; \\normalsize \\text{if normalized, orthonormal} \\end{alignat}\\] $$ "],["cox-regression.html", "Chapter 2 Cox Regression 2.1 Proportional Hazards Model 2.2 Cox PH Model 2.3 Semiparametric PH Model: General 2.4 Multiplicative Model 2.5 Proportional Hazards Regression and Multiplicative Intensity Model 2.6 Likelihood; conditional, marginal and partial likelihoods 2.7 Cox Proportional Hazards Model 2.8 Comparison of Nested Models 2.9 Stratification 2.10 Test statistics 2.11 Handling ties", " Chapter 2 Cox Regression 2.1 Proportional Hazards Model Proposed by Cox (1972, JRSS-B), primarily to model the relationship between hazard function and covariates. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science. Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc. ※ Data Structure Observed data: \\(\\Big \\{ X_i = T_i \\wedge C_i, \\; \\; \\; \\Delta_i = I(T_i &lt; C_i), \\; \\;\\; \\mathbf Z_i (\\cdot) \\Big \\} \\overset {iid} \\sim\\) 추가로 \\(N_i = I(X_i \\le t , \\; \\Delta_i = 1)\\), \\(Z_i(t)\\) = covariate vector (possibly time-dependent). 2.2 Cox PH Model \\[ \\lambda_i (t) = \\lambda (t \\vert Z_i ) = \\lambda_0 (t) \\exp (\\beta&#39; Z_i) \\tag{Cox Model} \\] semiparametric model: \\(\\exp(\\beta &#39; Z_i)\\), parametric assumption on covariate effects multiplicative model \\(\\beta\\) : \\(p \\times 1\\) vector, \\(p &lt; \\infty\\) \\(\\lambda_0(t)\\), nonparametric; is \\(\\infty\\) dimensional shape of hazard function is unspecified Due to nonparametric component, standard maximum likelihood theory does not apply Let \\(Z_{ij}\\) be the \\(j\\)-th element of \\(Z_i\\) - \\(\\beta_j\\) = difference in log hazards - \\(\\exp(\\beta_j)\\) = ratio of hazards; assumed constant for all \\(t\\) \\(\\lambda_0(t)\\): baseline hazard; common to all subjects, \\(\\lambda_0(t) = \\lambda_i(t \\big | Z_i = \\mathbf 0)\\) The hazard ratio, \\(\\exp(\\beta_j)\\), is sometimes referred to as a relative risk - risk = probability, not a rate - hazard is a rate, not a probability - in ratio of hazards, time dimension cancels out Direction of effect: $$ \\[\\begin{align} \\beta_j &gt; 0: &amp;&amp;\\uparrow\\lambda_i &amp;&amp;\\downarrow S_i(t) \\\\ \\beta_j &lt; 0: &amp;&amp;\\downarrow\\lambda_i &amp;&amp;\\uparrow S_i(t) \\end{align}\\] $$ Magnitude of effect is easy to interpret w.r.t. \\(\\lambda_i(t)\\) Cumulative hazard function: $$ \\[\\begin{align} \\lambda_i (t) &amp;= \\lambda_0(t) \\exp(\\beta Z_i) \\\\ \\Lambda_i (t) &amp;= \\int_0^t \\lambda_0(s) \\exp(\\beta Z_i) ds \\\\ &amp;= \\Lambda_0(t) \\exp(\\beta Z_i) \\end{align}\\] $$ Survival function: $$ \\[\\begin{align} S_i (t) &amp;= \\exp \\Big \\{ -\\Lambda_i (t) \\Big\\} \\\\ &amp;= \\exp \\Big \\{ -\\Lambda_0 (t) \\exp(\\beta &#39; Z_i)\\Big\\} \\\\ &amp;= S_0(t)^{\\exp \\Big \\{ \\beta&#39;Z_i \\Big\\}} \\end{align}\\] $$ By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard: - ex) randomized trial: treatment (\\(Z_i=1\\)) versus placebo (\\(Z_i=0\\)); \\(\\hat \\beta = 0.405\\) (\\(\\exp(\\hat \\beta)=1.5\\)) - \\(\\lambda_i(t)\\) for treated patients is 50% more of that of the controls. - irrespective of \\(\\lambda_0(t)\\) Nevertheless, \\(\\Lambda_0(t)\\) is required in order to determine \\(Z_i\\)’s effect on \\(S_i(t)\\), e.g., $$ \\[\\begin{align} S(t \\Big | Z_i = 0) = 0.95 &amp;&amp; vs. &amp;&amp; S(t \\Big | Z_i = 1) = 0.93 \\\\ S(t \\Big | Z_i = 0) = 0.70 &amp;&amp; vs. &amp;&amp; S(t \\Big | Z_i = 1) = 0.59 \\end{align}\\] $$ 2.2.1 Cox Model: Independent Censoring Independent censoring assumption is less stringent than in nonparametric estimation. Assumption is often written as \\(T_i \\perp C_i \\Big \\vert Z_i\\): $$ \\[\\begin{alignat}{2} &amp;\\lim_{\\delta \\rightarrow 0} \\frac{1}{\\delta} P(t \\le T_i &lt; t+ \\delta \\Big | T_i \\ge t , \\; C_i \\ge t , &amp;&amp;\\; Z_i) \\\\ = &amp;\\lim_{\\delta \\rightarrow 0} \\frac{1}{\\delta} P(t \\le T_i &lt; t+ \\delta \\Big | T_i \\ge t , &amp;&amp;\\; Z_i) \\end{alignat}\\] $$ ※ Note: \\(C_i\\) is allowed to depend on \\(Z_i\\) 2.3 Semiparametric PH Model: General General expression for multiplicative proportional hazards model: \\[ \\lambda_i (t) = \\lambda_0 (t) g(\\beta &#39; Z_i ) \\] \\(g(x)\\) is link function, specified. \\(\\forall x: g(x) \\ge 0\\), \\(\\exists g&#39;&#39;(x)\\), and in special case, \\(g(x) = \\exp(x)\\). Other choices for link function (e.g., Self &amp; Prentice, 1983): \\(g(x) = 1+x = (1+x)^{-1} = \\log(1+x)\\) ※ Notes: - not all choices of \\(g(x)\\) lead to clear interpretation of \\(\\beta_j\\) - certain choices of \\(g(x)\\) lead to numerical issues; e.g., likelihood is flat; local maxima, etc. - \\(g(x) \\not = exp(x)\\) has received little attention in the literature 2.4 Multiplicative Model Cox model is a multiplicative model, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard. Additive models also been proposed \\[ \\] 2.5 Proportional Hazards Regression and Multiplicative Intensity Model Recall Counting process: martingale representation $$ \\[\\begin{align} N(t) &amp;= I(X\\le t , \\; \\Delta = 1) \\\\ Y(t) &amp;= I(X \\ge t) \\\\ M(t) &amp;= N(t) - \\int_0^t Y(u)\\lambda_0(u) e^{\\beta &#39; Z } du \\tag{1} \\\\ \\mathcal F_t &amp;= \\sigma \\Big \\{ N(u) , Y(u+) , Z: \\; \\; 0 \\le u \\le t \\Big \\} \\end{align}\\] $$ intensity \\(l(u) = Y(u)\\lambda_0(u) e^{\\beta &#39; Z }\\), therefore integrated form is cumulative intensity \\(A(t)\\). Multiplicative Intensity Model: \\[ l(t) = Y(t)\\lambda_0(t) e^{\\beta &#39; Z(t) } \\] Counting process: \\(N(t)\\) = Number of events of a specified type that have occurred by time \\(t\\) \\(N(t)\\) may take more than one jump multiple infections, repeated breakdowns, hospital admissions \\(EN(t) &lt; \\infty\\) At-risk process: \\(Y(t)\\), left-continuous process, \\(1\\) if failure can be observed at time \\(t\\), otherwise \\(0\\). \\(Y(t)\\) can be used to represent situation in which a subject enter and exit risk sets several times \\(Y(t)\\) may be \\(1\\) even after an observed failure Covariate process: \\(Z(t)\\) = (bounded) predictable process time-dependent treatment, risk factors model checking and relaxing PH assumption Baseline hazard function: \\(\\lambda_0(\\cdot)\\) = an arbitrary deterministic function Filtration: \\(\\mathcal F_t = \\sigma \\Big \\{ N(u) , Y(u+) , Z(u): \\; \\; 0 \\le u \\le t \\Big \\}\\) Martingale: \\(M(t) = N(t) - \\int_0^t l(u) du\\) Intensity function: $ E { dN(t) | F_{t-} } = l(t) dt$ Data: \\(n\\) independent observations on $ { N(), ; Y(), ; Z() }$ 2.6 Likelihood; conditional, marginal and partial likelihoods \\(X =\\) vector of observations; \\(f_X(x, \\theta) =\\) density of \\(X\\) \\(\\theta =\\) vector parameter; \\(\\theta = (\\beta &#39; , \\phi&#39;)&#39;\\) \\(\\beta =\\) parameter of interest; \\(\\phi =\\) nuisance parameter likelihood: \\(f_X(x, \\theta) = f_{W|V} (w \\Big | v, \\theta )f_V (v, \\theta)\\) \\(X = (V&#39;, W&#39;)&#39;\\) infinite-dimensional \\(\\phi\\) \\(f_{W|V} (w \\Big | v, \\theta )\\) does not involve \\(\\phi\\) \\(\\Rightarrow\\) use \\(f_{W|V} (w \\Big | v, \\beta )\\) (conditional likelihood) \\(f_V (v, \\theta)\\) does not involve \\(\\phi\\) \\(\\Rightarrow\\) use \\(f_V (v, \\beta)\\) (marginal likelihood) \\[ X = (V_1 , W_1 , \\cdots, V_K , W_K) \\] $$ \\[\\begin{align} f_X(x, \\theta) &amp;= f_{V_1 , W_1 , \\cdots, V_K , W_K} (v_1 , w_1 , \\cdots, v_K , w_K\\; ;\\; \\theta) \\\\ &amp;= f_{V_1}(v_1 \\; ; \\; \\theta) f_{W_1 | V_1}(w_1 | v_1\\; ; \\; \\theta) f_{V_2 | V_1, W_1}(v_2 | v_1, w_1\\; ; \\; \\theta) \\times \\cdots \\\\ &amp;= \\left \\{ \\prod_{i=1}^K f_{W_i | Q_i } (w_i \\Big | q_i \\; ; \\theta) \\right \\} \\left \\{ \\prod_{i=1}^K f_{V_i | P_i } (v_i \\Big | p_i \\; ; \\theta) \\right \\} \\end{align}\\] $$ $$ \\[\\begin{align} P_1 = \\phi,&amp; &amp;&amp; P_i =(V_1 , W_1 , \\cdots, V_{i-1} , W_{i-1}) \\\\ Q_1 = V1,&amp; &amp;&amp; Q_i =(V_1 , W_1 , \\cdots , W_{i-1}, V_i) \\end{align}\\] $$ ${i=1}^K f{W_i | Q_i } (w_i | q_i ; ; ) $ is free of \\(\\phi\\) \\(\\Rightarrow\\) use $ {i=1}^K f{W_i | Q_i } (w_i | q_i ; ; ) $ (partial likelihood) 2.6.1 Partial &amp; Marginal Likelihoods Focus on Proportional Hazards Model: i.e., \\((X_i, \\; \\delta_i, \\; Z_i), \\; i = 1, \\cdots, n\\) (\\(n\\) independent triplets) $$ \\[\\begin{align} &amp;\\lambda(t \\Big | Z ) = \\lambda_0 (t) e^{\\beta &#39; Z} &amp;&amp;S(t \\Big | Z) = \\Big \\{ S_0(t) \\Big \\}^{e^{\\beta &#39; Z}} \\tag{1} \\end{align}\\] $$ 위에서 $ _0 (t)$는 unspecified. Partial Likelihood: assume no ties, absolutely continuous failure distribution Suppose there are L observed failures at \\(\\tau_1 &lt; \\cdots &lt; \\tau_L\\) (set \\(\\tau_0 \\equiv 0\\) &amp; \\(\\tau_{L+1} \\equiv \\infty\\)) 16.png Let (i) be the label for individual failing at \\(\\tau_i\\) (set \\((L + 1) \\equiv n + 1\\)). Note \\(t_{(i)} = \\tau_i\\) Covariates for \\(L\\) failures: \\((Z_{(1)}, \\cdots, Z_{(L)})\\). (Hereafter, condition on $ { Z_i : i = 1, , n }$) Censorship times in \\([\\tau_i; \\tau_{i+1})\\): \\((\\tau_{i1}, \\cdots, \\tau_{i, m_i})\\) with covariates \\((Z_{(i,1)}, \\cdots, Z_{(i,m_i)})\\), i.e., \\((i, j)\\) is label for item censored at \\(\\tau_{ij}\\) 17.png The data can be divided into sets \\[ (V_1 , W_1, \\cdots, V_{L+1} , W_{L+1}) \\] where, for \\(i = 1, \\cdots, L, L+1\\), $$ \\[\\begin{align} V_i &amp;= \\Big \\{ \\tau_i , \\tau_{i-1, j} \\; \\; ; \\; \\; (i-1, j):j = 1, \\cdots, m_{i-1} \\Big \\} \\\\ and \\; \\; \\; \\;W_i &amp;= \\Big \\{ (i) \\Big \\} \\end{align}\\] $$ 18.png 19.png GOAL: Build a likelihood on a subset of the full data set - carrying most of the information about \\(\\beta\\) - carrying no information on nuisance parameters \\(\\Big \\{ \\lambda_0 (t) : t \\ge 0 \\Big \\}\\) PROPOSAL: Generate likelihood of \\(\\Big \\{ W_1, \\cdots, W_L \\Big \\}\\) JUSTIFICATION, WHY?: - Timing of events \\(\\Big \\{ \\tau_1 , \\cdots, \\tau_L \\Big \\}\\) can be explained by \\(\\lambda_0(\\cdot)\\). - Censoring times and labels can be ignored if we assume non-informative censorship (independent censoring). So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data. If \\(Q_i \\equiv (V_1, W_1 , \\cdots, V_{i-1}, W_{i-1}, V_i)\\) and \\(\\mathcal F_{\\tau_i} \\equiv (Q_i, Z)\\), the partial likelihood is \\(\\prod_{i=1}^L P \\Big ( W_i = (i) \\Big | \\mathcal F_{\\tau_i} \\Big)\\), i.e., given the risk set at \\(\\tau_i\\), and given event occurs at \\(\\tau_i\\). Denote \\(R_i \\equiv \\Big \\{ j : X_j \\ge \\tau_i \\Big \\}\\) as risk set at \\(\\tau_i\\). Then, by the assumption of independent censoring, $$ \\[\\begin{align} P \\Big ( W_i = (i) \\Big | \\mathcal F_{\\tau_i} \\Big) &amp;= \\frac{ P \\Bigg \\{ t_{(i)} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\cdot \\prod\\limits_{j \\in R_i - (i)} P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} }{ \\sum\\limits_{l \\in R_i} \\left[ P \\Bigg \\{ t_{l} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\cdot \\prod\\limits_{j \\in R_i - l} P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\right] } \\tag{a} \\\\ \\\\ \\\\ &amp;= \\frac{ d\\Lambda \\Big( \\tau_i \\Big | Z_{(i)} \\Big) \\prod\\limits_{j \\in R_i - (i)} \\bigg \\{ 1 - d\\Lambda \\Big( \\tau_i \\Big | Z_{j} \\Big) \\bigg \\} }{ \\sum\\limits_{l \\in R_i} \\left [ d\\Lambda \\Big( \\tau_i \\Big | Z_{l} \\Big) \\prod\\limits_{j \\in R_i - l} \\bigg \\{ 1 - d\\Lambda \\Big( \\tau_i \\Big | Z_{j} \\Big) \\bigg \\} \\right ] } \\; \\; \\; \\div \\; \\; \\; \\frac{d\\tau_i}{d\\tau_i} \\tag{2} \\\\ \\\\ \\\\ &amp;= \\frac{\\lambda\\Big(\\tau_i \\Big | Z_{(i)} \\Big)}{ \\frac{P \\Big\\{T\\in [t, t+dt) \\Big | T \\ge t , Z \\Big\\}}{dt}= \\sum\\limits_{l\\in R_i} \\left[ \\lambda\\Big(\\tau_i \\Big | Z_{l} \\Big) \\right]} \\; \\; \\; \\overset {(1)}{=} \\; \\; \\; \\frac{\\exp(\\beta &#39; Z_{(i)})}{\\sum\\limits_{l\\in R_i} \\exp(\\beta &#39; Z_{l})} \\end{align}\\] $$ - at (a), \\(P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} = 1 - P \\Bigg \\{ t_{j} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\}\\) - at (2), $ d( i | Z{j} ) = 0$ Thus, the Partial Likelihood is \\[ \\prod^L_{i=1}\\frac{\\exp(\\beta &#39; Z_{(i)})}{\\sum\\limits_{l\\in R_i} \\exp(\\beta &#39; Z_{l})} = L(\\beta)\\tag{3} \\] Note: unspecified \\(\\lambda_0(\\cdot)\\) + noninformative censoring \\(\\Rightarrow\\) \\(\\prod\\limits_{i=1}^L f_{V_i \\big | P_i} (v_i \\Big | p_i ; \\theta)\\) contains little or no information about \\(\\beta\\). Counting process notation: $$ \\[\\begin{align} L(\\beta) = \\prod^n_{i=1}\\prod_{t\\ge0} \\left \\{ \\frac{\\exp(\\beta &#39; Z_{i})}{\\sum\\limits_{j=1}^n Y_j(t) \\exp(\\beta &#39; Z_{j})} \\right\\}^{dN_i(t)} , &amp;&amp; dN_i(t) = \\begin{cases} 1 &amp; N_i(t) - N_i {(t-)} =1\\\\0 &amp; o.w.\\end{cases} \\end{align}\\] $$ Maximum partial likelihood estimator (MPLE): \\(L( \\hat \\beta) = \\max_\\beta L(\\beta)\\) (using Newton-Raphson (NR) algorithm) Specifically, the log partial likelihood is then \\[ l(\\beta) = \\sum_{i=1}^n \\int_0^\\infty \\left[ Y_i (t) Z_i \\beta - \\log\\left( \\sum_{j=1}^n Y_j(t) \\exp(\\beta &#39; Z_j ) \\right) \\right]dN_i(t) \\] The score vector, \\(U(\\beta)\\), can be obtained by differentiating \\(l(\\beta)\\) w.r.t. \\(\\beta\\): $$ \\[\\begin{alignat}{2} U(\\beta) &amp;= \\sum_{i=1}^n \\int_0^\\infty \\Big \\{ Z_i - \\bar Z(\\beta, t) \\Big \\}&amp;&amp;dN_i (t) \\\\ &amp;= \\sum_{i=1}^n \\int_0^\\infty \\left \\{ Z_i - \\frac{\\sum_{i=1}^n Y_i (t) Z_i \\exp(\\beta &#39; Z_i)}{\\sum_{i=1}^n Y_i (t) \\exp(\\beta &#39; Z_i)} \\right \\}&amp;&amp;dN_i (t) \\end{alignat}\\] $$ where \\(\\bar Z(\\beta, t)\\) is a weighted mean of \\(Z\\) over those observations still at risk at time \\(t\\). The information matrix, \\(\\mathcal I(\\beta)\\), is the negative second derivative where $$ \\[\\begin{align} \\mathcal I(\\beta) &amp;= \\sum\\limits_{i=1}^n \\int_0^\\infty V(\\beta, t) dN_i(s) \\\\ \\\\ V(\\beta, t) &amp;= \\frac{\\sum\\limits_{i=1}^n Y_i(t) \\exp(\\beta &#39; Z_i ) \\Big \\{ Z_i - \\hat Z (\\beta, t)\\Big\\}&#39;\\Big \\{ Z_i - \\hat Z (\\beta, t)\\Big\\}}{\\sum\\limits_{i=1}^n Y_i(t) \\exp(\\beta &#39; Z_i )} \\end{align}\\] $$ and \\(V(\\beta, t)\\) is the weighted variance of \\(Z\\) at time \\(t\\). Then, the MPLE, \\(\\hat \\beta\\), is found by solving the partial likelihood equation: \\(U(\\hat \\beta) = 0\\). Under some regularity conditions, \\(\\hat \\beta\\) is consistent and asymptotically normally distributed with mean \\(\\beta\\) and variance \\(E \\Big \\{ \\mathcal I(\\beta) \\Big\\}^{-1}\\) (will be shown later.) The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value \\(\\hat \\beta^{(0)}\\)). \\[ \\hat\\beta^{(n+1)} = \\hat\\beta^{(n)} + \\mathcal I ^{-1} \\Big( \\hat \\beta^{(n)}\\Big) \\cdot U \\Big( \\hat \\beta^{(n)}\\Big) \\] ※ Note: 1. (incredibly) Robust algorithm! 2. \\(\\hat \\beta^{(0)} = 0\\) usually works. 2.7 Cox Proportional Hazards Model Cox model: $$ \\[\\begin{align} \\lambda_i(t) = \\lambda(t \\Big | Z_i ) &amp;= \\lambda_0 (t) \\exp(\\beta &#39; Z_i) \\\\ &amp;= \\lambda_0(t) \\exp(\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik}) \\\\ &amp;\\Updownarrow \\\\ \\log \\lambda(t \\Big | Z_i ) &amp;= \\log \\Big[ \\lambda_0(t) \\Big] +\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik} \\\\ S(t \\Big | Z_i ) &amp;= \\Big[ S_0(t) \\Big]^{\\exp(\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik})} \\end{align}\\] $$ ※ Note: $$ \\[\\begin{align} \\lambda_0 (t) &amp;= \\lambda(t \\Big | Z_1 = \\cdots = Z_k = 0) \\\\ \\\\ \\exp(\\beta_1 Z_{1} + \\cdots + \\beta_k Z_{k}) &amp;= RR \\\\ &amp;= \\frac{\\lambda(t \\Big | Z_1 , \\cdots, Z_k)}{\\lambda(t \\Big | Z_1 = \\cdots = Z_k = 0)} \\tag{1} \\end{align}\\] $$ - (1) is relative risk of hazard of death comparing covariates values \\(Z_1,\\cdots, Z_k\\) to \\(Z_1 = \\cdots = Z_k = 0\\) Interpreting Cox Model Coeffcients: \\(\\beta_k\\) is the log RR (hazard ratio) for a unit change in \\(Z_k\\), given all other covariates remain constant, i.e., $$ \\[\\begin{align} \\frac {\\lambda\\Big[t \\Big | Z_1 , \\cdots, (Z_{k&#39;}+1), \\cdots, Z_k \\Big]} {\\lambda\\Big[t \\Big | Z_1 , \\cdots, Z_{k&#39;}, \\cdots, Z_k \\Big]} &amp;= \\exp \\Big (\\beta_1 \\cdot 0 + \\cdots + \\beta_{k&#39;} \\cdot (Z_{k&#39;} +1 - Z_{k&#39;}) + \\cdots + \\beta_k \\cdot 0 \\Big) \\\\ &amp;= \\exp(\\beta_{k&#39;}) \\end{align}\\] $$ The RR comparing 2 sets of values for the covariates \\((Z_1 , \\cdots, Z_k)\\) vs. \\((Z_1&#39; , \\cdots, Z_k&#39;)\\): \\[ RR = \\frac{\\lambda(t \\Big | Z_1 , \\cdots, Z_k)}{\\lambda(t \\Big | Z_1 &#39;, \\cdots, Z_k&#39;)} =\\exp \\Big \\{ \\beta_1(Z_1 - Z_1&#39;) + \\cdots + \\beta_k(Z_k - Z_k&#39;) \\Big \\} \\] 20.png 2.8 Comparison of Nested Models Nested Models: $$ \\[\\begin{align} \\lambda(t) &amp;= \\lambda_0(t) \\exp \\Big ( \\beta_1 Z_1 + \\cdots \\beta_p Z_p + \\beta_{p+1} Z_{p+1} +\\cdots + \\beta_{k} Z_{k}\\Big) \\tag{Full Model} \\\\ &amp;= \\lambda_0(t) \\exp \\Big ( \\beta_1 Z_1 + \\cdots \\beta_p Z_p \\Big) \\tag{Reduced Model} \\end{align}\\] $$ To test: Nested Models: $$ \\[\\begin{align} &amp;H_0: &amp;&amp;RM &amp;&amp; \\Leftrightarrow &amp;&amp; H_0: \\beta_{p+1} = \\cdots = \\beta_k = 0 \\\\ &amp;H_A: &amp;&amp;RM &amp;&amp; \\Leftrightarrow &amp;&amp; H_A: \\not = \\text{ somewhere} \\end{align}\\] $$ Use the partial likelihood ratio statistic, \\(X^2_{Cox} = -2 \\Big[ \\log PL(RM) - \\log PL(FM)\\Big]\\). Under \\(H_0\\): Reduced model, and when \\(n\\) is large: \\[ \\begin{align} X^2_{Cox} \\sim \\chi^2_{k-p} &amp;&amp; k-p \\text{ is the # of parameters set to 0 by }H_0 \\end{align} \\] 20.png, 21.png 2.9 Stratification Two Ways to Stratify. Suppose a confounder \\(C\\) has 3 levels on which we would like to stratify when comparin g \\(\\lambda(t \\Big | E )\\) and \\(\\lambda ( t \\Big | \\bar E )\\). How? \\(X_E = \\begin{cases}1&amp;E&amp;\\text{(exposed)}\\\\0&amp;\\bar E&amp;\\text{(not exposed)}\\end{cases}\\) 22.png Which Way to Stratify? Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder \\(C\\) may be inadequately controlled. Proportionality assumption can be checked using time-dependent covariates. True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If \\(C\\) can be measured continuously and the strata were formed by grouping values of it, better control for \\(C\\) might be achieved with continuous (could be time-dependent) covariate adjustment. If \\(C\\) is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of \\(C\\). However, we can estimate \\(\\lambda_{0i}(t)\\) for each stratum then we can estimate a RR function. True stratification generally requires more data to obtain the same precision in coefficient estimates. 23.png 24.png 2.10 Test statistics The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood. 25.png Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least. 26.png When \\(p = 1\\) and the single covariate is categorical, the score test is identical to the log-rank test. 27.png 2.11 Handling ties Real data sets often contain tied event times. When do we have ties? Continuous event times are grouped into intervals. Event time scale is discrete. Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood. When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the \\(i\\)-th event at time \\(t_i\\) is \\(\\frac{\\exp(\\beta &#39; Z_i)}{ \\sum\\limits_{j \\in R_i} Y_j(t_i) \\exp(\\beta &#39; Z_j)}\\) Two commonly used methods are 1. Breslow approximation 2. Efron approximation Example: Assume 5 subjects are at risk of dying at time \\(t\\) and two die at the same time \\(t\\) (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either 28.png 29.png 30.png "],["tutorial.html", "A Tutorial A.1 Hello bookdown A.2 Cross-references A.3 Parts A.4 Footnotes and citations A.5 Blocks A.6 Sharing your book References", " A Tutorial A.0.1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). A.0.1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: ## A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: #### A short section or ###### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. A.0.1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. A.0.1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book,” or from the R console: bookdown::serve_book() A.1 Hello bookdown All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (##) per .Rmd file. A.1.0.1 A section All chapter sections start with a second-level (####) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. A.2 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. A.2.0.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: ## Hello world {##nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, ## Hello world = ## Hello world {##hello-world}. To label an un-numbered heading, use: ## Hello world {-##nice-label} or {## Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter \\@ref(cross). If you prefer text as the link instead of a numbered reference use: any text you want can go here. A.2.0.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure A.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure A.1: Here is a nice figure! Don’t miss Table A.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table A.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 A.3 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: ## (PART) Act one {-} (followed by ## A chapter) Add an unnumbered part: ## (PART\\*) Act one {-} (followed by ## A chapter) Add an appendix as a special kind of un-numbered part: ## (APPENDIX) Other stuff {-} (followed by ## A chapter). Chapters in an appendix are prepended with letters instead of numbers. A.4 Footnotes and citations A.4.0.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one.1 A.4.0.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2021) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/##/citations A.5 Blocks A.5.0.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation \\@ref(eq:binom). A.5.0.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem . ::: {.theorem ##tri} For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] ::: Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. A.5.0.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html A.6 Sharing your book A.6.0.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html A.6.0.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. A.6.0.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
