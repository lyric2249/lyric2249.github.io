[["index.html", "Self-Study Intro", " Self-Study Intro "],["categorical.html", "Chapter 1 Categorical ", " Chapter 1 Categorical "],["overview.html", "1.1 Overview", " 1.1 Overview 1.1.1 Data Type and Statistical Analysis "],["bayesian.html", "Chapter 2 Bayesian ", " Chapter 2 Bayesian "],["abstract.html", "2.1 Abstract", " 2.1 Abstract 조건부 확률은 sample sapce가 \\(S\\)에서 \\(B\\)로 축소되었다는 것을 의미한다. Bayesian의 Multiplication Rule은 사건이 시간순서대로 발생할 때 유용하게 사용될 수 있다. set of events become partition of sample space \\(S\\): 1. mutually exclusive(disjoint) 2. Pr of union \\(=1\\) event \\(H\\)와 event \\(A\\), \\(B\\)가 주어져 있다. \\(A\\)와 \\(B\\) 가 서로 독립이라면, \\(H\\)가 주어졌을 때 \\(A\\)가 추가되는 것이 \\(B\\)에 대한 정보를 아는데 영향을 미치지 않는다. 수식으로 증명가능. \\(Dirichlet\\), \\(Wishart\\) \\(posterior odds\\) 2.1.1 변수의 독립성 \\(X_1 , \\cdots, X_n\\)이 공통 sample space \\(S\\)를 갖는 변수이고 \\(\\theta\\) is unknown parameter. if \\(S\\), with for any subset(events) \\(A_1 , \\cdots, A_n\\), $Pr(X_1 A_1 , , X_n A_n ) = Pr(X_1 A_1 ) * Pr(X_n A_n ), then \\(X_1 , \\cdots, X_n\\) 는 \\(\\theta\\)가 주어졌을 때 조건부 독립이다. 이는 앞서 말한 event의 독립성에 대응된다. 위의 독립성은 event의 독립성과 마찬가지로 $Pr(X_i A_i , X_j A_j) = Pr(X_i A_i ) 가 성립. 이는 \\(\\theta\\)가 주어졌을 때 \\(X_j\\)의 정보가 \\(X_i\\)에 대하여 아무런 추가정보를 주지 못함을 의미한다. 만약 세타가 주어진 상태에서 X1~Xn이 조건부 독립이라면 조건부 joint pdf는 각 조건부 margianl pdf의 곱과 같다. 만약 X-i가 모두 같은 분포를 따르면~. 이때 X_i들은 세타가 주어졌을 때 conditionally iid. 이는 marginal iid와는 구변된다. marginal iid는 X_i들의 marginal iid가 모두 같고 또한 독립이라는 소리. 2.1.2 교환가능성 독립성은 엄격한 조건. 만족안되는 경우 많음. 이것보다는 약조건이 교환가능성. 독립성 \\(\\rightarrow\\) 교환가능성이지만 교환가능성 \\(\\not \\rightarrow\\) 독립성. 교환가능성까지만 만족되면 De Finetti thm은 성립함. "],["continual-aeassessment-method.html", "2.2 Continual Aeassessment Method", " 2.2 Continual Aeassessment Method "],["horseshoe-prior.html", "2.3 Horseshoe Prior", " 2.3 Horseshoe Prior "],["mathematical-stats.html", "Chapter 3 Mathematical Stats ", " Chapter 3 Mathematical Stats "],["inference.html", "3.1 Inference", " 3.1 Inference \\(T(X)\\)가 \\(\\theta\\)의 추정량. * bias $ = E - $ * if bias\\(=0\\), \\(T(X)\\)는 \\(\\theta\\)의 UE. 이때, \\(\\theta\\) can be \\(g(\\theta)\\). 즉슨, \\(\\theta\\)는 패러미터 그 자체만이 아니라 패러미터의 함수를 패러미터 삼아 이를 추정하려고 들 수도 있다. 이하의 전개에서는 \\(\\theta = g(\\theta)\\) 로 이해하자. \\(\\theta\\)의 추정량 \\(T(X)\\)의 MSE는 $MSE = Var +(bias)^2 $. \\(T_1(X)\\), \\(T_2(X)\\)는 \\(\\theta\\)의 UE. \\(T_1(X)\\)의 \\(T_2(X)\\)에 대한 Relative Efficiency \\(RE= \\dfrac {Var \\left[ T_2 (X) \\right]} {Var \\left[ T_1 (X) \\right]}\\) rv $X_1 , , X_n f(x_1 , , x_n ) $. 이하의 조건 하에서 추정량 \\(T^\\ast (X)\\)는 \\(\\theta\\)의 MVUE. 1. \\(E \\left [ T^\\ast (X) \\right] = \\theta\\). 즉 \\(T^\\ast (X)\\)는 \\(\\theta\\)의 UE. 2. $T(X):Var $. Fisher’s Information $I() = E { ^2 } $ regularity condition: 1. The partial derivative of \\(f(X; \\theta)\\) with respect to \\(\\theta\\) exists almost everywhere. (It can fail to exist on a null set, as long as this set does not depend on \\(\\theta\\).) 2. The integral of \\(f(X; \\theta)\\) can be differentiated under the integral sign with respect to \\(\\theta\\). 3. The support of \\(f(X; \\theta)\\) does not depend on \\(\\theta\\). e.g., 패러미터 다르면 pdf 다름. 즉, \\(\\theta \\not = \\theta&#39;: f(x;\\theta) \\not = f(x;\\theta&#39;)\\) set \\(A = \\{ x: f(x;\\theta)&gt;0 \\}\\)은 패러미터 \\(\\theta\\)에 의존하지 않고, \\(\\forall x \\in A, \\theta \\in \\Omega : \\log f(x;\\theta)\\)는 \\(\\theta\\)에 대해 두 번 미분 가능하고 도함수가 연속이다. 통계량 \\(T(X)\\)가 \\(\\forall \\theta \\in \\Omega: E \\left [ T (X) \\right] &lt; \\infty\\) 라면, $ {} E $에 있어 미분과 적분의 순서를 바꿀 수 있다. Information inequality: under regularity condition, \\(\\forall g^{-1}(\\theta) \\in \\Omega, Var \\left [ T^\\ast (X) \\right] &lt; \\infty, E \\left [ T^\\ast (X) \\right] = \\theta, 0&lt;I(\\theta)&lt; \\infty:\\) \\(\\theta\\) is differentiable, and \\(Var \\left [ T^\\ast (X) \\right] \\ge \\dfrac {1}{n} \\dfrac {\\left[ g&#39;(\\theta) \\right]^2}{I (\\theta)}\\). rv $X_1 , , X_n f(x_1 , , x_n ) $. \\(l\\)개 stats(통계량)의 벡터 \\(\\pmb {S(X)} = \\left[ S_1(X), \\cdots, S_l(X) \\right]\\). 이때 rv $X_1 , , X_n $의 분포가 패러미터 $ = (_1 , , _k )$에 의존하지 않으면 stats \\(\\pmb {S(X)}\\)는 joint SS. rv $X_1 , , X_n f(x_1 , , x_n ) $. 1개 stats(통계량) \\(S(X)\\). 이때 rv \\(X_1 , \\cdots, X_n \\rvert S(X)\\) 의 분포가 패러미터 \\(\\theta = (\\theta_1 , \\cdots, \\theta_k )\\)에 의존하지 않으면 stats \\(S(X)\\)는 SS. Decomposition thm.: rv $X_1 , , X_n f(x_1 , , x_n ) $. \\(k\\)개 stats(통계량) \\(\\pmb {S(X)} = \\left[ S_1(X), \\cdots, S_k(X) \\right]\\). stats \\(\\pmb {S(X)}\\)는 joint SS \\(\\iff\\) $f(x_1 , , x_n ; ) = g h(x_1 , , x_n) $ 3.1.1 Rao-Blackwell thm. 패러미터의 함수 \\(\\theta\\), \\(S\\)는 SS, \\(T(X)\\)는 UE. let \\(\\delta (S) = E \\left [ T(X) \\rvert S \\right]\\). 이때 \\(\\delta (S)\\)는 \\(\\theta\\)의 UE. 따라서 $$ \\[\\begin{align*} Var \\left[ \\delta (S) \\right ] &amp;= E \\left\\{ \\left[ \\delta (S) - \\theta \\right]^2 \\right\\} \\\\ &amp;\\le E \\left\\{ \\left[ T(X) - \\theta \\right]^2 \\right\\} = Var \\left [ T(X) \\right] \\end{align*}\\] $$ "],["completeness.html", "3.2 Completeness", " 3.2 Completeness rs $X_1 , , X_n $의 stats $ T (X_1 , , X_n ) $에 대해, let \\[ \\forall \\theta \\in \\Omega: \\; \\; E \\left[ g(T) \\right]=0 \\] 이때 이를 만족하는 \\(\\theta\\)에 무관한 함수 \\(g\\)가 \\(g(\\cdot) \\equiv 0\\) 뿐이라면, \\(T\\)는 CS. \\(T\\)가 \\(\\theta\\)에 대한 SS라면, 이는 CSS. stats \\(Y\\)가 분포모임 \\(\\{g(y;\\theta);\\theta \\in \\Theta \\}\\)의 한 원소를 pdf로 가진다고 하자. \\[ \\forall \\theta \\in \\Theta: \\; \\; E_{\\theta} \\left[ \\varphi(Y) \\right] \\overset{\\theta}{=}{0} \\; \\; \\; \\rightarrow \\; \\; \\; \\varphi(y) \\overset{y}{=} 0 \\] 위의 명제가 성립할 때 위 분포족은 completeness를 지닌다. * 여기서 \\(\\varphi\\)는 \\(\\theta\\)에 무관한 함수이다. * 피명제는 보다 엄밀히는 \\(\\forall \\theta: P_{\\theta} \\{ \\varphi (Y)=0 \\}=1\\). * \\(\\overset{\\theta}{=}\\)는 모든 \\(\\theta \\in \\Omega\\)에 대해 등호가 성립함을 나타낸다. Remarks: 1. completeness는 본질적으로 확률분포의 패러미터 \\(\\theta\\)가 통계량 \\(Y\\)를 통해 추정될 수 있음을 보장하는 조건으로 이해될 수 있다. * 즉, completeness는 서로 다른 패러미터값을 지니는 두 분포는 서로 구분(distinct)됨을 보장해주는 조건이다. 2. 통계량 \\(Y\\)의 분포족이 completeness를 만족하면, \\(Y\\)를 완비통계량 CS라고 부른다. 3. 완비성은 CS의 함수로 이루어지는 UE는 unique하다는 사실을 보이는 도구로 이용된다. 레만-쉐페 thm 참조. 3.2.1 레만-쉐페 thm. 패러미터 \\(\\theta\\)에 대해 \\(T\\)가 CSS, \\(S(X)\\)는 \\(\\theta\\)의 UE. 이때 $(T)=E $는 \\(\\theta\\)의 UMVUE. rs \\(X_1 , \\cdots, X_n \\overset{iid}{\\sim} f(x;\\theta)\\). \\(\\theta\\)에 대한 CSS \\(Y=u(X_1 , \\cdots, X_n)\\). 이때 임의의 UE \\(\\hat \\theta\\)에 대해 \\[ \\varphi (Y) = E(\\hat \\theta \\rvert Y) \\] 는 \\(\\theta\\)에 대한 UMVUE. 이는 unique. 3.2.2 Rao-Blackwell thm. rs \\(X_1 , \\cdots, X_n \\overset{iid}{\\sim} f(x;\\theta), \\theta \\in \\Theta\\). 1. \\(Y= u(X_1 , \\cdots, X_n)\\)는 \\(\\theta\\)의 CSS. 2. \\(Z= v(X_1 , \\cdots, X_n)\\)의 분포는 \\(\\theta\\)에 의존하지 않는다. 이상의 조건이 만족되면 \\(Y \\perp Z\\). exponentail family: pdf가 적절한 함수 \\(a, b, c_i, t_i (i=1,\\cdots, k)\\)에 대해 \\(f(x;\\theta) = a(\\theta) b(x) \\exp \\left[ \\sum_{i=1}^k c_i (\\theta) t_i (x) \\right], -\\infty\\) 지수족에 속하는 pdf로부터 rs $X_1 , , X_n $를 얻었다면, 통계량 $S_1 = {i=1}^n t_1 (X_i), , S_k = {i=1}^n t_k (X_i) $ 는 패러미터 $_1 , , _k $에 대한 joint (C) SS이다. \\(g(\\theta)\\)에 대한 est \\(\\tau(\\pmb X)\\)가 \\(\\forall \\epsilon &gt;0: \\lim_{n \\rightarrow \\infty} P \\left( \\vert \\tau(\\pmb X) - g(\\theta) \\vert \\le \\epsilon \\right) =1\\)을 만족하면 est \\(\\tau(\\pmb X)\\)는 consistency를 가진다. 이는 표본의 크기가 커짐에 따라 est \\(\\tau(\\pmb X)\\)가 \\(g(\\theta)\\)에 확률적으로 수렴한다는 것. 표본의 크기가 매우 클 때, est \\(\\tau(\\pmb X)\\)로부터 계산된 추정값 estimates는 높은 확률로 참모수값에 매우 가까이 있다는 뜻. est \\(\\tau(\\pmb X)\\)를 \\(g(\\theta)\\)의 것일 때, \\(\\forall \\theta \\in \\Theta: \\lim_{n \\rightarrow \\infty} P E \\left\\{ \\tau(\\pmb X)-g(\\theta)\\right\\}^2 = 0\\)이 성립하면 est \\(\\tau(\\pmb X)\\)는 consistent. est \\(\\tau(\\pmb X)\\)가 \\(\\theta\\)의 consistent이고, \\(g(x)\\)가 \\(\\theta\\)에서 연속인 함수라면, \\(g\\tau(\\pmb X)\\) "],["hypothesis-test.html", "3.3 Hypothesis Test", " 3.3 Hypothesis Test 통계적 가설 | Statistical Hypothesis | 관심있는 population의 성질에 대한 단정이나 추측 등의 표현 (statement) 이러한 가설은 흔히 모집단의 성질을 나타내는 rv의 분포에 대한 표현으로 나타난다. | 단순가설 | Simple Hypothesis | 어떤 가설이 확률분포 (pd) 를 완전히 결정한다 | 복합가설 | Composite Hypothesis | 그렇지 않다 | 다양한 검정법에서 우선순위를 정하는 것은 옳은 결론을 내리는 빈도가 높은, 즉 잘못된 결정을 내릴 확률이 낮은 검정법이 좋은 검정법이라는 것. 검정통계량(Test Statistics): 주어진 rs에 근거하여 통계적 가설에 대한 증거를 살펴볼 때 사용되는 통계량 기각영역(Rejection Region, Critical Region): \\(H_0\\)를 기각하게 되는 검정통계량의 값을 가지는 sample space의 부분집합 (event) | \\(H_0\\) True | \\(H_0\\) False | reject \\(H_0\\) | | Type 2 Error (\\(\\beta\\)) 유죄인데 석방 | accept \\(H_0\\) | Type 1 Error (\\(\\alpha\\)) 무죄인데 사형 | | 제1종 오류를 범활 확률 \\(\\alpha\\)는 유의확률(Significance Level) 라고 따로 칭함. \\(H_1\\)은 기존으로부터의 변화이므로 채택에 있어 훨씬 엄격해야 함. 따라서 \\(\\alpha\\)가 \\(\\beta\\)보다 훨씬 더 중시됨. let Rejection Region \\(C\\). then $$ \\[\\begin{alignat*}{2} \\alpha &amp;= P(\\text{Type 1 Error}) \\\\ &amp;= P(\\text{accept }H_1 \\vert H_0) \\\\ &amp;= P(\\pmb X_n \\in C \\vert H_0) \\begin{aligned}[t] &amp; = \\int_C f(\\pmb x \\vert H_0) d \\pmb x\\\\ &amp;= \\sum_C f(\\pmb x \\vert H_0) \\end{aligned} \\end{alignat*}\\] $$ This can also be written as Loss Function. $$ \\[\\begin{align*} L(H_i ; H_j ) = \\begin{cases} 0, &amp; \\text{if } i = j \\\\ 1, &amp; \\text{for } i \\not = j, \\; \\; (i,j = 0, 1) \\end{cases} \\end{align*}\\] $$ $$ \\[\\begin{align*} E \\left [ L(H_1 ; H_0 ) \\right] &amp;= P(\\text{Type 1 Error}) \\\\ E \\left [ L(H_0 ; H_1 ) \\right] &amp;= P(\\text{Type 2 Error}) \\end{align*}\\] $$ "],["power-fucntion.html", "3.4 Power Fucntion", " 3.4 Power Fucntion 여기서, \\(H_0\\)에 대한 기각영역이 \\(C\\)인 test의 검정력함수 (power function)은 이하와 같다. 즉, 이는 \\(H_0\\)를 기각하는 확률로 정의된다. \\[ \\pi(\\theta) = P (\\pmb X_n \\in C \\vert \\theta) \\] 이는 패러미터 \\(\\theta\\)의 참값이 무엇이냐에 따라 다른 값을 가지므로 \\(\\theta\\)의 함수이다. 주어진 \\(\\theta\\)에서의 power function의 값 \\(\\pi(\\theta)\\)은 이 \\(\\theta\\)에서의 검정력 (power). power는 \\(H_0\\)를 기각할 확률. * if \\(\\theta \\in H_0\\), power는 작을수록 좋다. * \\(\\theta = \\theta_0 \\in H_1\\), 이 경우 power \\(\\pi(\\theta) = \\pi(\\theta_0) = \\alpha\\). * if \\(\\theta \\in H_1\\), power는 클수록 좋다. * \\(\\theta \\in H_1\\), and \\(H_1\\)이 simple hypothesis, 이 경우 power \\(\\pi(\\theta) = 1- \\beta\\). 이와 같이 power function은, 마치 MSE가 점추정의 기준이 되었던 것처럼, \\(\\alpha\\) (유의수준)이 고정되었을 때 test 방법의 성능을 결정하는 기준이 된다. 3.4.1 Significance Probability (p-value) 앞에서 언급했던 것과 같이, 좋은 검정법을 찾기 위해 sample space를 \\(C\\)와 채택영역 \\(C^c\\)로 나누고 \\(\\alpha\\)와 \\(\\beta\\)를 계산하여 오류의 확률을 작게 만드는 검정법을 고르게 된다. 사용할 검정법을 결정하고 나면, 자료에서 관측된 값이 \\(C\\)에 속할 경우 \\(H_0\\)를 기각하고, 이외에는 \\(H_0\\)를 기각하지 않는다고 결론을 내리게 된다. 그런데 관찰된 test stat의 값이 \\(C\\)에 속한다 하더라도 값의 크기 등에 따라 통계적 유의성에 대한 의미가 다를 수 있다. 따라서 기각할 것인지, 하지 않을 것인지 이분법적인 결론만을 제시하기보다, 관측한 자료가 \\(H_0\\)에 대하여 어느 정도의 반증이 되는지를 수치적으로 나타낼 수 있는 \\(\\alpha\\) (유의확률)을 이용하여 test의 결론에 이르는 경우가 많이 있다. p값 (p-value), 즉 관측된 유의수준 (observed significance level), 혹은 유의확률 (Significance Probability), 는 \\(H_0\\)가 참이라는 가정 하에, 우리가 관측한 값과 같거나 더 극단적인 값을 얻을 확률 (ex. \\(P(T \\ge t \\vert H_0 )\\)) 로 정의된다. 여기서 더 극단적이라는 것은, 관측한 값보다 \\(H_1\\)에 더 가까운 것을 의미한다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 아주 작은 값이 나왔다면, 우리가 관측한 값 자체가 이미 매우 극단적이라서 이보다 더 강한 \\(H_1\\)에 대한 증거를 관측할 확률이 작다는 것이다. 즉, 관측값이 \\(H_0\\) 하에서 나오기 어려운 값이라는 뜻이므로 \\(H_0\\)를 기각할 근거가 된다고 할 수 있다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 작지 않은 값이 나왔다면, 우리가 관측한 값이 \\(H_0\\) 하에서 흔히 나올 수 있는 값이라는 것이고, 즉 \\(H_0\\)를 기각할 근거가 되지 않는다고 할 수 있다. p값이 \\(H_0\\)를 기각할만큼 작은지를 결정하는 것은 보통 결과를 해석하는 사람에게 달려있다. 그러나 가설검정을 할 때는 흔히 적당한 유의수준 \\(\\alpha\\)의 값을 생각하고 있기 마련이므로, p값이 \\(\\alpha\\)보다 작으면 관측된 자료가 대립 가설에 대한 충분한 증거가 된다고 판단하여 \\(H_0\\)를 기각하게 된다. 정리하자면, p값은 \\(H_0\\) 하에서 test stat의 관찰값 (test stats) 이 \\(H_0\\)를 기각하는 방향으로 나타나는 확률을 의미한다. 주어진 유의수준 \\(\\alpha\\)보다 p값이 작으면 \\(H_0\\)를 기각하며, 그렇지 않은 경우에는 \\(H_0\\)를 받아들이게 된다. "],["optimal-testing-method.html", "3.5 Optimal Testing Method", " 3.5 Optimal Testing Method 항상 옳은 결과를 가져다주는 검정법을 사용할 수 있다면 가장 좋겠지만, 샘플에서 주어지는 정보만을 가지고 모집단의 특성에 대한 결론을 내려야 하는 상황에서 언제나 옳은 결과를 가져다주는 test 방법을 찾을 수는 없다. 그렇기에 이 장의 목표는 옳은 결과를 가져다주는 빈도가 높은 test 방법을 찾는 것이 된다. 잘못된 결론을 내릴 확률은 두 가지 오류로 표현되므로, 제 1종 오류와 제 2종 오류의 발생확률을 낮게 하는 test 방법을 찾아야 한다. 불행히도, 샘플의 크게가 정해져 있는 경우 둘 다를 최소로 하는 test 방법을 찾는 거은 불가능하다. 예를 들면, \\(\\alpha\\)를 최소로 하는 가장 간단한 방법은 언제나 \\(H_0\\)를 채택하는 것이지만 (\\(\\alpha = 0\\)), 이는 \\(H_1\\)에서의 power를 0으로 최소화시키고, 즉, \\(\\beta\\)를 극대화시킨다. let \\(\\pmb X_{25} \\overset {\\text{iid}} {\\sim} N(\\mu, 10^2 )\\). \\[ H_0 : \\mu = 100, \\; \\; \\; \\; \\; H_1 : \\mu &gt; 100 \\] 이때. \\(\\mu=100\\)에서의 power는 유의수준 \\(\\alpha\\)와 같고, \\(\\mu&gt;100\\)일 경우에는 \\(\\pi(\\mu) = 1-\\beta(\\mu)\\). 이인즉 $$ \\[\\begin{align*} \\lim_{\\mu \\downarrow 100} \\beta(\\mu) &amp;= 1- \\pi(100) \\\\ &amp;= 1- \\alpha \\end{align*}\\] $$ 따라서 \\(H_0\\)와 \\(H_1\\)의 경계점에서 \\(\\alpha + \\beta = 1\\)이 된다. 즉, 샘플의 크기가 일정할 때 \\(\\alpha\\)를 줄이고자 하면 경계점에서 \\(\\beta\\)의 값이 커지며, 이 역 또한 성립한다. 이를 power로 표현하면, \\(H_0\\) 하에서 power는 큰 것이 바람직하나 power \\(\\pi (\\mu)\\)를 늘이고자 하면 \\(\\alpha\\)의 값이 같이 커지게 되므로 제1종 오류의 확률 (\\(\\alpha\\))의 확률을 최소화하면서 power를 최대화하는 일은 sample의 크기가 정해져 있는 경우 불가능하다. 만약 sample의 크기를 늘인다면, \\(\\alpha\\)의 값을 고정시킨 상태에서 주어진 \\(H_1\\) 하에서의 \\(\\mu\\) 값에서의 power를 크게 할 수 있다. 이 절에서는 power function \\(\\pi(\\cdot)\\)을 기준으로 하는 Optimal Testing Method (최량검정법)에 대해 살펴볼 것이다. 우선, \\(H_0\\)와 \\(H_1\\)이 모두 simple인 경우를 생각해보자. 위에서 이야기하였듯 \\(\\alpha\\)를 최소화하면서 \\(H_0\\) 하에서의 power를 최대화하는 것은 불가능하므로, 이에 대한 합리적 대안으로 \\(\\alpha\\) (제1종 오류를 범할 확률)을 주어진 작은 값으로 제한한 상태에서, power를 최대화하는 의미에서의 OTM을 다음과 같이 정의한다. $$ H_0: = _0, ; ; ; ; ; H_1: = _1 $$ 에 대한 rejection region \\(C^\\ast\\) 가 다음 조건을 만족할 때 이를 유의수준 \\(\\alpha\\) 에서의 MPT의 RR, 또는 MPRR이라고 한다. \\(\\pi^\\ast\\)가 \\(C^\\ast\\)에 해당하는 power function이라 하면, 1. \\(\\pi^\\ast (\\theta_0) = \\alpha\\), 2. \\(\\forall \\text{ RR } C, \\; \\text{whose 유의수준과 power function } \\alpha, \\pi: \\pi^\\ast(\\theta_1) \\ge \\pi(\\theta_1)\\). "],["data-reduction.html", "3.6 Data Reduction", " 3.6 Data Reduction 3.6.1 Sufficiency Principle \\(X \\vert T(X)\\)의 분포가 \\(\\theta\\)에 의존하지 않는다면, \\(T(X)\\)는 \\(\\theta\\)의 SS. - \\(T(X)\\)가 \\(\\theta\\)의 SS라면, \\(\\theta\\)에 대한 모든 추론은 \\(T(X)\\)를 거쳐서만이 \\(X\\)에 의존함. 즉 \\(T(X)\\) 값만 알 수 있다면 모든 \\(X\\)에 대해 알지 못해도 무관. 비율 \\(\\dfrac{f_X(x \\vert \\theta)}{f_T(X) \\left( T(x) \\vert \\theta \\right)}\\)가 \\(\\forall x \\in \\Omega\\)에 대해 \\(\\theta\\)의 함수로서 constant 하다면, \\(T(X)\\)는 \\(\\theta\\)의 SS. 이인즉 \\(f(x \\vert T(x))\\) 는 \\(\\theta\\)에 의존하지 않는다. - rs itself와 rs의 order statistics는 SS이다. Factorization thm.: sample point \\(x\\), parameter points \\(\\theta\\) $$ T(X) x, : g , h(x) : f(x ) = g h(x) $$ SS를 찾기 위해 factorization thm.을 쓰려면, 우리는 샘플의 joint pdf를 두 부분으로 나눠야 한다. 이는 \\(\\theta\\)를 포함하지 않는 (의존하지 않는) \\(h(x)\\)와 \\(\\theta\\) 를 포함하는 \\(g \\left[ T(x) \\vert \\theta \\right]\\) 이다. \\(\\theta\\)를 포함하는 \\(g\\) 쪽의 식이 \\(T(x)\\)로 표시될 수 있으면, 즉 \\(x\\)에 의존하는 바가 \\(T(x)\\)를 통해서만 의존한다면, \\(T(x)\\)는 \\(\\theta\\)의 SS이다. proof) \\(X_1 , \\cdots, x_n \\overset {iid} {\\sim} f(x \\vert \\pmb \\theta) = h(x)c(\\pmb \\theta) \\exp \\left( \\sum_{i=1}^k w_i (\\pmb \\theta)t_i(x) \\right)\\), s.t. exponential family, where \\(\\pmb \\theta = (\\theta_1 , \\cdots, \\theta_d), d \\le k\\). then \\[ T(X) = \\left( \\sum_{j=1}^n t_1 (X_j) , \\cdots, \\sum_{j=1}^n t_k (X_j) \\right) \\] is SS for \\(\\theta\\). "],["borel-paradox.html", "3.7 Borel Paradox", " 3.7 Borel Paradox Throughout this chapter, for continuous rv \\(X, Y\\), we have been writing expressions such as \\(E(Y \\rvert X=x)\\) and \\(P(Y \\le y \\rvert X=x)\\). Thus far, we have not gotten into trouble. However, we might have. Formally, the conditioning in a conditional expectation is done with respect to a sub sigma-algebra(1.2.1), and the conditional E $E(Y G) $ is defined as a rv whose integral, over any set in the sub sigma-algebra \\(G\\), agrees with that of \\(X\\). This is quite an advanced concept in probatbility theory (see Billingsley 1995, Section 34). Since the conditional E is only defined in terms of its integral, it may not be unique even if the conditioning is well-defined. However, when we condition on sets of probatbility 0 (such as $ { X=x }$), conditioning may not be well defined, so different conditional expectations are more likely to appear. To see how this could affect us, it is easiest to look at conditional distributions, which amounts to calculating \\(E \\left[ I(Y \\le y) \\rvert X=x \\right]\\). Proschan and Presnell (1998) tell the story of a statistics exam that had the question “If \\(X\\) and \\(Y\\) are independent standard normals, what is the conditional distributions of \\(Y\\) given that \\(Y=X\\)?” Different students interpreted the condition \\(Y=X\\) in the following ways: 1. \\(Z_1 = 0\\), where \\(Z_1 = Y-X\\); 2. \\(Z_2 = 1\\), where \\(Z_2 = Y/X\\); 3. \\(Z_3 = 1\\), where \\(Z_3 = I(Y=X)\\). Each condtion is a correct interpretation of the conditon \\(Y=X\\), and each leads to a different conditional distribution (see Excercise 4.60.). This is the Borel Paradox and arises b/c different (Correct) interpretations of the probatbility 0 conditioning sets result in different conditional E. How can we avoid the paradox? One way is to avoid conditioning on sets probatbility 0. That is, compute only \\(E(Y \\rvert X \\in B )\\), where \\(B\\) is a set with \\(P (X \\in B)&gt;0\\). So to compute something like \\(E(Y \\rvert X =x )\\), take a sequence \\(B_n \\downarrow x\\), and define \\(E(Y \\rvert X =x )= \\lim_{n \\rightarrow \\infty} E(Y \\rvert X \\in B_n )\\). We now avoid the paradox, as the different answers for \\(E(Y \\rvert X =x )\\) will arose from different sequences, so there should be no surprises (Exercise 4.61). "],["neymanpearson-lemma.html", "3.8 Neyman–Pearson lemma", " 3.8 Neyman–Pearson lemma rs \\(X_1 , \\cdots, X_n \\overset {iid}{\\sim} f(x_1 , \\cdots, x_n ; \\theta)\\)이고, $H_0 : =_0, ; ; ; H_1 : =_1 $. 이때 이하를 만족하면 rejection region \\(R\\)은 MP test의 기각역. \\(\\exists k \\ge 0\\): \\(\\pmb x \\in R\\) if \\(f(\\pmb x \\vert \\theta_1) &gt; k f(\\pmb x \\vert \\theta_0)\\). \\(\\pmb x \\in R^c\\) if \\(f(\\pmb x \\vert \\theta_1) &lt; k f(\\pmb x \\vert \\theta_0)\\). \\(\\mathbb{P}_{\\theta_0} \\left( \\pmb X \\in R \\right) = \\alpha\\) for the prefiexed significance level \\(\\alpha\\). Proof: \\[\\begin{align} P(\\pmb X \\in A \\vert \\theta) &amp;= \\int_A L(\\theta ; \\pmb x) d \\pmb x \\\\ &amp;= \\int_A f(\\pmb x ; \\theta) d \\pmb x \\end{align}\\] 이므로, \\(A \\subset C^\\ast\\)라면 \\[\\begin{alignat}{4} \\int_A f(\\pmb x ; \\theta) d \\pmb x &amp;\\le \\int_A &amp;&amp; k \\ast f(\\pmb x ; \\theta) d \\pmb x \\\\ \\\\ P(\\pmb X \\in A \\vert \\theta_0) &amp;\\le &amp;&amp; k \\ast P(\\pmb X \\in A \\vert \\theta_1) \\end{alignat}\\] 마찬가지 방법으로 \\(A \\subset \\left( C^\\ast \\right)^c\\)라면 \\(P(\\pmb X \\in A \\vert \\theta_0) \\ge k \\ast P(\\pmb X \\in A \\vert \\theta_1)\\). \\(C^\\ast\\)의 유의수준이 \\(\\alpha\\)라 하고, 유의수준이 동일한 임의의 RR \\(C\\)를 가정하자. 이때 두 RR은 각각 \\[\\begin{align} C^\\ast &amp;= (C^\\ast \\cap C) \\cup (C^\\ast \\cap C^c) \\\\ C &amp;= (C^\\ast \\cap C) \\cup ({C^\\ast}^c \\cap C) \\end{align}\\] 로 표현할 수 있으며, 두 RR에 대한 power function은 각각 \\[\\begin{alignat}{4} \\pi^\\ast(\\theta) &amp;= P(\\pmb X \\in C^\\ast \\vert \\theta) &amp;&amp;= P(\\pmb X \\in C^\\ast \\cap C \\vert \\theta) &amp;&amp;+ P(\\pmb X \\in C^\\ast \\cap C^c \\vert \\theta) \\\\ \\pi(\\theta) &amp;= P(\\pmb X \\in C \\vert \\theta) &amp;&amp;= P(\\pmb X \\in C^\\ast \\cap C \\vert \\theta) &amp;&amp;+ P(\\pmb X \\in {C^\\ast}^c \\cap C \\vert \\theta) \\\\ \\end{alignat}\\] 이때 \\(H_0\\)에서 두 power의 차이는 \\[\\begin{alignat}{4} \\pi^\\ast(\\theta_1) -\\pi(\\theta_1) &amp;= &amp;&amp; P(\\pmb X \\in C^\\ast \\cap C^c \\vert \\theta_1) - P(\\pmb X \\in {C^\\ast}^c \\cap C \\vert \\theta_1) \\\\ &amp;\\ge \\dfrac{1}{k} &amp;&amp; \\left\\{ P(\\pmb X \\in C^\\ast \\cap C^c \\vert \\theta_0) - P(\\pmb X \\in {C^\\ast}^c \\cap C \\vert \\theta_0) \\right\\} \\\\ &amp;= \\dfrac{1}{k} &amp;&amp; \\left\\{ P(\\pmb X \\in C^\\ast \\cap C^c \\vert \\theta_0) - P(\\pmb X \\in {C^\\ast}^c \\cap C \\vert \\theta_0) \\\\ + P(\\pmb X \\in C^\\ast \\cap C \\vert \\theta_0) - P(\\pmb X \\in C^\\ast \\cap C \\vert \\theta_0) \\right\\} \\\\ &amp;= \\dfrac{1}{k} &amp;&amp; \\left\\{ \\pi^\\ast (\\theta_0) - \\pi (\\theta_0) \\right \\} \\\\ &amp;=0 &amp;&amp; \\end{alignat}\\] 이에 의해 MP test의 정의를 만족한다. 이때 \\(C\\)의 유의수준이 \\(&lt; \\alpha\\)인 경우, \\(\\pi^\\ast (\\theta_1) &gt; \\pi (\\theta_1)\\)이 되므로, \\(C^\\ast\\)의 \\(H_1\\)에서의 power인 \\(\\pi^\\ast(\\theta_1)\\)은 유의수준이 \\(\\le \\alpha\\)인 모든 RR의 power보다 크거나 같음을 알 수 있다. 3.8.1 Overview Example \\(x\\) 1 2 3 4 5 6 \\(f(x \\vert \\theta_0)\\) .01 .02 .02 .05 .10 .80 \\(f(x \\vert \\theta_1)\\) .03 .05 .15 .10 0 .67 $ $ .33 .4 .13 .5 \\(\\infty\\) 1.19 유의수준이란 기본적으로 \\(H_0\\)이 사실인데 \\(H_1\\)을 선택할 확률. 선택한 RR에 해당하는 \\(H_0\\)와 \\(H_1\\)에서의 density가 각각 있다면, \\(H_0\\)에서의 density의 합이 된다. 기각을 해버렸는데 \\(H_0\\)가 발생해버렸다는 소리니까. power란 RR에서의 \\(H_1\\)이 발생할 확률. test 자체가 \\(H_1\\)에 마음을 두고 시작하는 거임. power는 무조건 \\(H_1\\)에만 직결. 실패하면 어쩌지? 무지성으로 \\(H_1\\) 골라버리자. 이랬다가 \\(H_0\\) 발생해버리면? 난 망하는거잖아. 이 망함의 risk를 고정해두자. 이게 \\(\\alpha\\). power function은 \\(H_0\\)와 \\(H_1\\) 각각에 대해서 존재한다. 이는 각각에서의 pdf이다. 즉, 표본을 통한 $ $의 값이 크면 \\(H_0\\)를 기각할 이유가 없고, 작으면 기각할 근거를 갖는다. 이 값이 얼마나 작아야 기각할 수 있는가는 유의수준에 의해 결정. 이와 같이 rs의 LR을 통해 MP test의 RR을 찾을 수 있다. 이때 RR과 검정법은 실제로 동일한 것이므로 혼돈이 없다는 전제 하에 test라는 단어를 주로 사용한다. \\(LR(\\theta_0, \\theta_1 ; \\pmb x) = \\dfrac{L(\\theta_0 ; \\pmb x)} {L(\\theta_1 ; \\pmb x)}\\) 는 표본의 \\(\\theta_0\\)에 대한 지지 (그리고 \\(\\theta_1\\)에 대한 반증)의 정도를 표현한다고 볼 수 있다. 3.8.2 Generalized LRT rs \\(\\pmb X_n \\overset {iid}{\\sim} f(\\pmb x ; \\theta)\\), \\(H_0: \\theta \\in \\Omega_0\\), \\(H_0: \\theta \\in \\Omega_1 (=\\Omega - \\Omega_0)\\). $ (x) = = $ rs \\(X_1, \\cdots, X_n\\)의 pdf가 \\(f(x ; \\theta), \\; \\; \\; \\theta \\in \\Omega\\)라고 하자. 확률구간 \\(\\left[ L(\\pmb X_n ), U(\\pmb X_n ) \\right]\\)가 \\[ P \\left[ L(\\pmb X_n ) \\le \\theta \\le U(\\pmb X_n ) \\right] = 1- \\alpha \\] 를 만족하면 이를 패러미터 \\(\\alpha\\)의 \\(100(1-\\alpha) \\%\\) CI라 부른다. rs \\(\\pmb X_n\\) 의 분포가 pdf \\(f(x ; \\theta), \\; \\; \\; \\theta \\in \\Omega\\)를 따른다 하자. 이때 샘플과 패러미터 \\(\\theta\\)의 함수인 random quantity \\(T(\\pmb X_n ; \\theta)\\)의 분포가 패러미터 \\(\\theta\\)에 의존하지 않으면 이는 pivotal quantity. \\(H_0: \\theta \\in \\Omega_0, H_1: \\theta \\in \\Omega - \\Omega_0\\) 에 대한 RR \\(C^\\ast\\)가 이하를 만족하면 이는 UMP test. \\(\\pi^\\ast\\)가 이 test의 power function이라면 $$ { ^() _0 } =, $$ 모든 다른 power function에 대해 위의 기각역에서의 power 가 최대. rs $X_n $ 의 joint pdf가 \\(f(\\pmb X_n ; \\theta)\\)일 때, \\(LR( \\theta_1 ,\\theta_2 ; \\pmb X_n) = \\dfrac{L(\\theta_1 ; \\pmb X_n)}{L(\\theta_1 ; \\pmb X_n)}\\)가 \\(\\theta_1 &lt; \\theta_2\\)에 대해 \\(T(\\pmb X_n)\\)의 non-dec 혹은 non-inc라면 \\(L(\\theta)\\)는 \\(T(\\pmb X_n)\\)에 대해 monotone LR를 갖는다. Karlin-Rubin \\(H_0: \\theta \\le \\theta_0, H_1: \\theta \\ge \\theta_0\\). \\(T\\)가 \\(\\theta\\)에 대한 SS임을 가정하고, \\(T\\)의 pdf의 family는 MLR을 가짐. then \\(\\forall t_0\\), reject \\(H_0 \\; \\; \\; \\iff \\; \\; \\; T&gt;t_0\\) 하는 test는 level \\(\\alpha\\)의 UMP test이다. 이때, \\(\\alpha = P_{\\theta_0} (T&gt;t_0)\\). \\(L(\\theta ; \\pmb X_n)\\)이 \\(T(\\pmb X_n)\\)에 대해 non-inc인 MLR. 이때 \\(H_0: \\theta \\le \\theta_0, H_1: \\theta \\ge \\theta_0\\)에 대한 level \\(\\alpha\\)의 UMP test는 \\(C = \\left\\{ \\pmb X_n : T(\\pmb X_n) \\ge k \\right\\}\\) 이며, 상수 \\(k\\)는 \\(P[T(\\pmb X_n) \\ge k \\vert H_0 ] = \\alpha\\)에 의해 결정. \\(H_0: \\theta \\ge \\theta_0, H_1: \\theta \\le \\theta_0\\)는 \\(C = \\left\\{ \\pmb X_n : T(\\pmb X_n) \\le k \\right\\}\\). MLE의 불변성 MLE의 함수는 MLE 서로 독립인 rv X Y의 공통된 성공 확률 p의 MLE. f(X)와 f(Y)를 곱해서 쓴다. \\(\\pmb X_n \\sim U(\\theta - \\tfrac{1}{2}, \\theta + \\tfrac{1}{2})\\). 이때 LF로 MLE 구하는 건 굳이 log 안 거쳐도 가능함. 안 거쳐야 증명이 깔끔한 부분이 있음. $$ = f(x;) $$ 에 의해 $$ E { f(X;) }^2 E { f(X;) } =0 $$ \\(X \\sim U(0, \\theta)\\)일 때, \\(\\theta^2\\)의 UE는? \\(E(X^2) = \\dfrac{\\theta^2}{3}\\)이므로 \\(T(X)=3X^2\\)는 \\(\\theta\\)의 UE. \\(\\pmb X_n \\sim U(-\\theta, \\theta)\\)일 때, \\(c(X_{(n)}-X_{(1)}\\)가 \\(\\theta\\)의 UE가 되기 위한 c의 값은? \\(\\pmb X_n \\sim N(\\mu, \\sigma^2 )\\). 이때 \\(cS = c \\sqrt{\\dfrac{\\sum (X_i - \\bar X)^2}{n-1}}\\)가 \\(\\sigma\\)의 UE가 되도록 하는 c의 값은? \\(Y=(n-1)\\dfrac{S^2}{sigma^2}\\)이 카이제곱을 따르는 rv임을 이용하여 \\(E(\\sqrt{Y})\\)를 구하라. \\(Var \\left( \\sum a_i \\hat \\theta_i \\right)\\)는 \\(a_i = \\dfrac{\\tfrac{1}{\\sigma^2_i}}{\\sum \\tfrac{1}{\\sigma^2_i}}\\)일 때 최소화. 통계량 \\(S(X)\\)의 분포가 패러미터 \\(\\theta\\)에 의존하지 않는다면 이는 ancillary statistic. 최소 SS가 존재한다면, 모든 CSS는 MSS이다. "],["개념.html", "3.9 개념", " 3.9 개념 충분통계량 분해정리 Minimum 충분통계량 Completeness 6.3. ancillary 통계량 (분포가 모수에 의존 안함) 바수정리 complete고 minimum 충분통계량이면 모든 ancillary랑 독립 지수족 만족하면 뭐의 묶음은 complete 충분통계량 (추가조건, 6.6 minimum 충분통계량 존재하면 모든 Complete 통계량은 동시에 minimum 충분통계량 모먼트, MLE (2차까지 확인) MLE 불변성 MSE를 통해 통계량 성능 비교 가능함 bias MSE = precision + accuracy UMVUE 7.5 크래머-라오 부등식 : 최저 분산 뽑아내는 수단 피셔 정보 2차원 피셔 정보 라오-블랙웰 : uniform better UE 뽑아내는 수단 unique best UE best UE는 오직 하나뿐 (레만쉐페) CSS에 기반한 UE는 오직 유일함 W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7 consistent (점근성) 충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일 test으 unbaised 8.8 네이만 피어슨 카를린 루빈 8.3 빅 샘플 추정자들과 8.5 스코어 스탯 8.12 왈드 테스트 8.13 1-a confidence iterval = acceptance region of level 알파 test 뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨 pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT. MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량. cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2. 감마와 포아송간 변환 유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5. dog-tired Bubble Plot 3D Scatter Plot Star Plot Chernoff Faces Parallel Coordinate Plot 1.Q-Q Plot Shapiro-Wilks Test Kolmogorov-Smirnov Test Skewness Test ( ) Kurtosis Test: ( ) Lin and Mudholkar Scatter Plot Squared Generalized Distances Chi-Square Plot (Gamma Plot) nqplot contour plot cqplot (Python – assumption check) "],["mcmc.html", "Chapter 4 MCMC ", " Chapter 4 MCMC "],["importance-sampling.html", "4.1 Importance Sampling", " 4.1 Importance Sampling 4.1.1 Independent Monte Carlo 타겟분포 \\(f\\)로부터의 시뮬레이션의 랜덤 draws $ X_1 , , X_n $. 적분 범위에 걸쳐 (over) support가 펼쳐져 있는 분포로부터 무작위로 포인트를 추출해서 해당 포인트들의 적분값을 종합하여 만들어내는, 적분값에 대한 통계적 측정. let \\(f\\)는 \\(X\\)의 density, \\(\\mu = E_f \\left[ h(X) \\right]\\). 이때 $ {MC} = {i=1}^n h(X_i ) h(x)f(X) dx =; ; ; ; ; n $ let $ v(x) = { h(x)-}^2$, $ E_f { ^2 } &lt; $. Then, sampling \\(Var\\) of $ _{MC} $ is $ = E { }. This can be written as $ ({MC}) = {n-1} {i=1}^n ^2 $ when ^2 exists, by CLT, \\(\\hat \\mu_MC \\overset {\\cdot} {\\sim} N\\), for large \\(n\\). 수치해석은 다차원 문제에는 적용하기 어렵다. 하지만, MC integration은 \\(p\\)차원의 \\(f\\)의 support에 걸쳐서 \\(f\\)에서 랜덤하게 샘플링 한 후 이 영역에 대한 그 어떤 체계적인 탐색도 시도하지 않는다. 샘플링 후에는 그냥 냅둬버림. 따라서 MC는 고차원에서도 덜 피곤함. 4.1.1.0.1 Inverse-cdf \\(\\forall F, X=F^{-1}(U) = \\text{inf}\\{ x:F(x) \\ge U \\}\\)는 \\(F\\)와 같은 cdf를 가짐. 이때 \\(F\\)는 continuous distribution function, \\(U \\sim U(0, 1)\\). 이때, linear interpolation을 활용해, \\(F^{-1}\\) 계산 없이 \\(F\\)만으로 난수 샘플링 가능. 1. \\(f\\)의 supoprt를 span하는 grid \\(x_1 , \\cdots, x_m\\) 정의 2. 각 grid point에서 \\(u_i = F(x_i)\\) 계산하거나 approximate 3. 가장 가까운 grid points \\(u_i , u_j\\)에 대해, \\(u_i \\le U \\le u_j\\)에 해당하는 영역을 이하에 따라 linearly interpotate. \\(X = \\dfrac{u_j-U}{u_j - u_i}x_i + \\dfrac{U-u_i}{u_j - u_i}x_j\\). 이때 \\(U \\sim U(0, 1)\\). - illustration of Rejection Sampling for a target distribution \\(f\\) using a Rejection Sampling envelope \\(e\\). 4.1.1.0.2 Rejection Sampling \\(f(x)\\)의 상수배 (proportionality constant) 만이라도 계산될 수 있다면, 정확한 타겟분포 \\(f(x)\\)로부터의 샘플링을 위하여 Rejection Sampling 사용 가능. 이는 더 간단한 후보 (candidate) 분포로부터 샘플링한 후 이렇게 샘플링한 것 중 일부를 확률에 기반하여 랜덤하게 쳐냄으로써 샘플링 확률을 보정하는 것. * \\(g\\)는 우리가 분포의 형태를 정확히 알고 있고 \\(g(x)\\) 계산도 쉬운 덴시티라고 정의. * \\(e\\)는 envelope, 이하의 성질을 갖는다. \\(\\forall x \\; \\; \\; \\text{s.t. for a given constant } \\alpha \\le 1, f(x)&gt;0 \\; \\; \\; : \\; \\; \\; e(x) = \\dfrac {g(x)}{\\alpha} \\ge f(x)\\). 방법은 이하와 같다. 1. \\(Y \\sim g\\)에서 샘플링. 2. \\(U&gt;\\dfrac {f(y)}{e(Y)}\\)일 경우 \\(Y\\)를 기각. 기각된다면 \\(Y\\)값을 target random sample의 요소로 기록하지 않음. step 1으로. 3. \\(U \\le \\dfrac {f(y)}{e(Y)}\\)일 경우 set \\(X=Y\\)로 한 후 \\(X\\)를 타겟 랜덤샘플의 요소로 넣음. step 1으로. 여기서 \\(\\alpha\\)는 채택될 후보들의 expected 비율로 해석될 수 있다. good RS envelope의 요건: * 간단하게 제작되거나, 모든 값에서 타겟분포를 넘김이 간단하게 확인되어야 한다. * 샘플링이 쉬어야 한다. * rejected draws가 적어야 한다. Example: Normal From Double Exponential, Sampling a Bayesian Posterior 4.1.1.0.3 Variants of the RS: Squeeze RS \\(f\\) 계산해내는 게 비용이 많이 들고 RS가 매력적인 상황이면 Squeeze RS에 의해 더 빠른 연산속도를 획득할 수 있음. nonnegative squeezing function \\(s(x)\\)를 정의하고 이를 사용함. 이때 \\(s\\)가 적합한 squeezing function이기 위해선 \\(f\\)의 모든 support에서 \\(s&lt;f\\). * illustration of squeezed Rs for a target distribution \\(f\\), using envelope \\(e\\) and squeezing function \\(s\\). Keep First and Keep Later correspond to steps 3 and 4 of the algorithm, respectively. proceeds: 1. \\(Y \\sim g\\)에서 샘플링. 2. if \\(U \\le \\dfrac {s(Y)}{e(Y)}\\), keep \\(Y\\). 3. if not, whether if \\(U \\le \\dfrac {f(Y)}{e(Y)}\\), keep \\(Y\\). 4. both are not, reject \\(Y\\). 2번에선 \\(s\\), 3번에선 \\(f\\)임에 주목. 샘플링 쉬운 \\(s\\)에서 먼저 비교해서 우선권 시드 주고, 그 후에 \\(f\\)로 본선 해보는거. Example: Lower Bound for Normal Generation 4.1.1.0.3.1 Variants of the RS: Adaptive RS 적절한 envelope \\(e\\)를 어떻게 만들 것인가? squeezed RS를 위해, support의 connected region에 대해 continuous, differentiable, log-concave인 덴시티를 만드는 자동화된 envelope 생산 전략에 해당함. 패키지로 실행. * envelopes \\(e\\) and squeezing function \\(s\\) for adaptive RS. The target density \\(f\\) is smooth, nearly bell-shaped curve. The first method discussed in the text, using the derivative of \\(l\\), produces the envelope \\(e\\) shown as upper boundary of the lighter shaded region. This correponds to Equation (6.9) and Figure 6.4. Later in the text, a derivative-free method is presented. That envelope is the upper bound of the darker shaed region and corresponds to (6.11) and Figure 6.6. The squeezing function \\(s\\) for both approaches is given by the dotted curve. 4.1.1.0.4 Importance Sampling Importance Sampling 접근법은 \\(E\\{h(x)\\}\\) w.r.t. its density는 이하처럼 alternative form으로 쓰일 수 있다는 것에 기반한다. 이때 \\(g\\)는 envelope의 importance sampling function. $ \\[\\begin{align*} \\mu &amp;= \\int h(x)f(x)dx &amp;= \\int \\left( h(x) \\dfrac {f(x)}{g(x)} \\right)g(x)dx \\tag{1} \\\\ \\\\ \\\\ &amp;= \\dfrac {\\int h(x)f(x) dx}{\\int f(x) dx} &amp;= \\dfrac {\\int \\left( h(x) \\dfrac {f(x)}{g(x)} \\right) g(x) dx}{\\int \\left( \\dfrac {f(x)}{g(x)} \\right) g(x) dx} \\tag{2} \\end{align*}\\] $ (1)은 \\(E \\{ h(X) \\}\\)를 측정하기 위한 MC 접근법이 이하임을 제시한다. \\(X_1 , \\cdots, X_n \\overset {\\text{iid}}{\\sim} g\\)처럼 \\(g\\)에서 랜덤샘플을 뽑고, 이의 (이를 활용한) estimator는 이하. 이때 \\(w^{\\ast} (X_i)\\)는 unstandardized weights, i.e., importance ratios. $ {IS}^{} = {i=1}^n h(X_i) w^{}(X_i) = _{i=1}^n h(X_i) $ (2)는 \\(g\\)에서 \\(X_1 , \\cdots, X_n \\overset {\\text{iid}}{\\sim} g\\)의 랜덤샘플을 뽑고 이하를 계산. 이때 \\(w(X_i)\\)는 standardized weight. 이 (2)는 \\(f\\)의 상수배 (proportionality constant) 까지만 알 수 있더라도 적용할 수 있다는 점에서 매우 중요함. \\(f\\)의 상수배까지만 알 수 있는 상황은 베이지안 분석의 post에서 빈번하게 발생함. Both estimators converge by the same argument applied to the simple Monte Carlo estimator. $ {IS} = {i=1}^n h(X_i) w(X_i) = _{i=1}^n h(X_i) $ Proceeds: 1. Sample \\(X_j \\sim g(\\cdot)\\). 2. Calculate \\(w(X_j) = \\dfrac {f(X_j)}{g(X_j)}\\) 3. 지정 샘플 갯수까지 반복 then, $ \\[\\begin{align*} E\\{\\hat h(x)\\} &amp;= \\dfrac {1}{n} \\sum_{j=1}^n w(X_j)h(X_j) \\\\ \\hat \\sigma^2 &amp;= \\dfrac {1}{n-1} \\sum_{j=1}^n \\left\\{ h(X_j) - E\\left[ \\hat h(x) \\right] \\right\\}^2 \\end{align*}\\] $ 과도한 변동성을 회피하기 위해, \\(\\dfrac {f(x)} {g(x)}\\)는 bounded여야 하며 또한 \\(g\\)는 \\(f\\)보다 heavier tail을 가져야 한다. 이것이 만족되지 않는다면 standardized importance weight는 제법 커질 수 있음. 함수 \\(g\\)는, \\(h(x)\\)가 매우매우 작을 경우에만 \\(\\dfrac {f(x)} {g(x)}\\)가 커지게 만드는 녀석으로 잘 골라야 한다. 가령 \\(h\\)가 아주 드문 상황에서만 1을 반환하는 indicator function이라면, 우리는 \\(g\\)로 하여금 샘플링의 편의성을 위해 해당 사건을 좀 더 빈번하게 발생시키도록 하는 녀석을 고를 수도 있을 것이다. 이를 택한다면 우리는 우리의 관심사가 아닌 사건, 가령 \\(h(x)=0\\)에 대한 적절한 샘플링 power을 어느정도 희생하게 된다. 이는 낮은 확률에 해당하는 case의 측정에 특히 잘 들어맞는 방법론이다. $_{IS}^$ 자체는 unbiased지만, 이를 importance weight로 standardize 하는 과정에서 \\(\\hat \\mu_{IS}\\)에 다소 bias가 생겨버린다. standardized weight를 쓰는 건 \\(w^\\ast(X)\\)와 \\(h(X)w^\\ast(X)\\)가 서로 강하게 상관관계가 있는 상황에서 더욱 우수한 estimator를 반환한다. standardized weight는 \\(f\\)의 비례상수를 요구하지 않는다. (우리가 갖고 있는 덴시티가 \\(f\\)의 얼마만큼의 상수배인지를 알지 않아도 된다) IS 방법론의 매력은 시뮬레이션의 reusability이다. 같은 sample points들과 weight들이 다양한 다른 quantity의 MC 적분 estimates를 구하는데 사용될 수 있다. (컴퓨팅 파워가 증가한 오늘날에 와서는 유의미한 장점은 아니다.) Example: Small Tail Probabilities 4.1.1.0.5 Antithetic Sampling let \\(\\hat \\mu_1, \\hat \\mu_2\\). 이 둘은 identically distributed, UE, and \\(Corr(\\hat \\mu_1, \\hat \\mu_2)&lt;0\\). 이 estimator 둘을 평균한 \\(\\hat \\mu_{AS} = \\dfrac{\\hat \\mu_1 + \\hat \\mu_2}{2}\\)는 각 estimator들의 샘플을 2배 한 것보다 우월함. \\(Corr(\\hat \\mu_1, \\hat \\mu_2)&lt;0\\)이기 때문에 성립한다는 것을 유의. $ Var(_{AS}) = ( Var(_1) + Var(_2) ) + Cov(_1, _2) = {n} (1+) $ \\(\\hat \\mu_1 (X)\\)를 MC integral estimate로 잡는다면, 이는 $ 1 (X) = {i=1}^n h_1 { F_1^{-1}(U_{i1}), , F_m^{-1}(U_{im}) } $ 이때 \\(h_1\\)은 그의 arguments에 monotone이며, \\(F_j\\)는 각 \\(X_{ij}, \\; j=1,\\cdots,m\\)의 cdf이며 \\(U_{ij} \\sim U(0,1)\\). 이에 의해 \\(1-U_{ij} \\sim U(0,1)\\)이기도 하며, 이에 의해 이하도 성립. $ 2 (X) = {i=1}^n h_1 { F_1^{-1}(1-U_{i1}), , F_m^{-1}(1-U_{im}) } $ 이는 \\(\\mu\\)의 2번째 estimator이며, 이는 \\(\\hat \\mu_1 (X)\\)와 같은 분포를 가짐. 따라서 \\(\\hat \\mu_{AS} = \\dfrac{\\hat \\mu_1 + \\hat \\mu_2}{2}\\)는 \\(\\hat \\mu_1\\)의 샘플을 2배 한 것(2n)보다 더 작은 \\(Var\\)을 가지며, 따라서 더 우월함. 4.1.1.0.6 Control Variates 우리는 알지 못하는 quantity \\(\\mu = E \\{ h(X) \\}\\)를 알고자 하며, 이에 연관된 quantity \\(\\theta = E[c(Y)]\\)에 대해서는 알고 있음. 후자는 수치적으로 획득 가능. \\((X_1 , Y_1 ) ,\\cdots, (X_n , Y_n )\\)은 simulation outcom에서 독립적으로 관측된 pairs of rv. 이때 MC estimator는 이하와 같다. \\(\\hat \\mu_{MC}, \\hat \\theta_{MC}\\) 간에 상호연관이 있음을 유의. $ \\[\\begin{align*} \\hat \\mu_{MC} = \\dfrac {1}{n} \\sum_{i=1}^n h(X_i), &amp; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\hat \\theta_{MC} = \\dfrac {1}{n} \\sum_{i=1}^n c(Y_i) \\end{align*}\\] $ 즉 우리는 여기서 \\(\\mu = E[h(x)]\\) \\(\\theta = E[c(Y)]\\) MC (ex. \\(\\theta_{MC}\\)) able able itself able 즉 \\(\\theta\\)와 \\(\\theta_{MC}\\) 간의 차이를 알아내고, 이 차이를 적당히 스케일링해서 \\(\\mu\\)에 적용한다는 것이 기본 메커니즘. 여기서 Control Variate Estimator는 \\(\\hat \\mu_{CV} = \\hat \\mu_{MC} + \\lambda(\\hat \\theta_{MC} - \\theta)\\). \\(\\lambda\\)는 사용자에 의해 정해지는 임의의 parameter. 이에 의해 $ Var({CV} ) = Var ({MC}) + ^2 Var ({MC}) + 2 Cov({MC}, _{MC}) $ 이며 이가 최소가 된 경우의 분산은 아래와 같으며, 이를 최소로 하는 \\(\\lambda\\)는 아래와 같다. when \\(\\lambda = - \\dfrac {Cov(\\hat \\mu_{MC}, \\hat \\theta_{MC})}{Var(\\hat \\theta_{MC})}\\), \\(\\min_\\lambda \\left( Var(\\hat \\mu_{CV} ) \\right) = Var(\\hat \\mu_{MC}) - \\dfrac{\\left[ Cov(\\hat \\mu_{MC}, \\hat \\theta_{MC}) \\right]^2} {Var(\\hat \\theta_{MC})}\\). 4.1.1.0.7 Rao-Blackwellizaiton rs \\(X_1 , \\cdots, X_n \\overset {\\text{iid}}{\\sim} f\\)를 활용해 \\(\\mu = E \\{ h(X) \\}\\)를 estimation. 각각의 \\(X_i = (X_{i1}, X_{i2})\\)라고 가정하고, 조건부 기댓값 \\(E\\{ h(X_i) \\rvert x_{i2} \\}\\)가 수치적으로 풀릴 수 있다고 가정하자. $ E{h(X_i)} = E_{X_{i2}}{ E }$라는 사실을 활용하여 $ _{MC} $ 에 대한 다른 estimator를 구축해보자. Rao-Blackwellized estimator \\(\\hat \\mu_{RB} = \\dfrac 1 n \\sum_{i=1}^n E \\{ h(X_i) \\rvert X_{i2} \\}\\). 이는 ordinary MC estimator \\(\\hat \\mu_{MC}\\)와 같은 mean을 갖는다. Note that $ Var({MC}) = {n^2} Var { E} + {n^2} E { Var } Var ({RB}) $ 따라서 Mean Squared Error, MSE 관점에서 \\(\\hat \\mu_{RB}\\)는 \\(\\hat \\mu_{MC}\\) 보다 우수하다. 4.1.1.0.8 Sampling Importance Resampling SIR 알고리즘은 몇 타겟분포에서 실현값을 모사적으로 시뮬레이트한다. SIR은 Importance Sampling의 개념에 기초하고 있다. IS에서 우리는 IS function \\(g\\)에서 샘플링하는 식으로 진행했었다. 샘플의 각 point는 샘플링 확률을 보정 (correct)하기 위해 weighted 되었었으며, 이에 의해 weighted 샘플들은 타겟분포 \\(f\\)와 연결지어질 수 있었다. 타겟분포 \\(f\\)를 획득하기 위해 샘플링 확률 보정 목적으로 가해지는 weight는 standardized importance weight \\(w(x_i)\\)로 불렸으며, $ w(x_i) = 이 만으로 난수 샘플링 가능. {} {_{i=1}^m } $ 이렇게 획득했던 standardized weight는 이후에 출신 density가 아닌 다른 타겟 \\(f\\)에서 다른 샘플을 생산할 때 재사용되는 것이 가능하다. for a collection of values, \\(x_i , \\cdots, x_m \\overset {\\text{iid}} {\\sim} g\\), 이때 \\(g\\)는 Importance Sampling Function. proceeds: 1. sample candidates \\(Y_1 , \\cdots, Y_m \\overset {\\text{iid}} {\\sim}\\) 타겟분포 \\(g\\). \\(g\\)가 타겟분포라고?????? 수업발언 2. caculate the standardized importance weights, \\(w(Y_1) , \\cdots, w(Y_m)\\). 3. resample \\(X_1 , \\cdots, X_m\\) from \\(Y_1 , \\cdots, Y_m\\) with probabilities, \\(w(Y_1) , \\cdots, w(Y_m)\\). for \\(n\\) samples Rejection Sampling SIR perfect not perfect distribution of generation draw is exactly \\(f\\) random degree of approxiamtion to \\(f\\) required number of draws random determined It is important to consider the relative sizes of the initial sample and the resample. In principle, we require \\(\\dfrac n m \\rightarrow 0\\) for distributional convergence of the sample. 1만개를 생산해놓고 이 안에서 추가적으로 공정을 진행해서 목표했던 랜덤한 샘플을 뽑아내는 것이 SIR. 그러나 전 영역에서 체크하는것과 생산해놓은 1만개에 randomness를 첨가하여 만들어낸 샘플은 퍼포먼스 차이가 당연히 존재. 그러나 전 영역 대비 1만개라는 한정된 영역에서 추가공정을 진행하므로 cost down. 기존에 만들어두었던 weight를 재사용하므로 시뮬레이션을 다시 할 필요가 없음. 시간 down. Rejection Sampling | envelope \\(e\\)를 만들고 이 안에서 뽑음. 이는 continuous point. | perfect, exact | SIR | n개의 candidate point를 이미 선택해놓고 이 안에서 뽑음. discrete. | approximate sampling | candidate \\(m\\)개, 샘플 \\(n\\)개. 당연하지만 candidate \\(m\\)의 숫자가 커질수록 효율성 (approximate 성능) 은 높아짐. The maximum tolerable ratio \\(\\dfrac n m\\) depends on the quality of the envelope, bsed on \\(m\\) candidate samples and their weights. 이상적으로는 \\(m\\)이 무한해지면 SIR 조차도 exact sampling일 수 있다. The SIR algorithm can be sensitive to the choice of \\(g\\). * The support of \\(g\\) must include the entire support of \\(f\\), for a reweighted sample from \\(g\\) is to approximate a sample from \\(f\\). * \\(g\\) should have heavier tails than \\(f\\), or more generally \\(g\\) should be chosen to ensure that $ $ never grows to o large. * If \\(g(x)\\) is nearly zero anywhere where \\(g(x)\\) is positive, then a draw from this region will happen only extremely rarely, but when it does it will receive a huge weight. * weight-degeneracy problem Example: Slash Distribution Example: Sampling a Bayesian Posterior 4.1.1.0.9 Sequential Monte Carlo When the target density \\(f\\) becomes high dimensional, SIR is increasingly inefficient and can be difficult to implement. Specifying a very good high-dimensional envelope that closely approximates the target with sufficiently heavy tails but little waste can be challenging. Sequential Monte Carlo methods address the problem by splitting the high-dimensional task into a sequence of simpler steps, each of which updates the previous one. \\(\\pmb X_{1:t} = (X_1 , \\cdots, X_t )\\) represents a discrete time stochastic process with \\(X_t\\) being the observation at time \\(t\\). \\(\\pmb X_{1:t}\\) represents the entire history of the sequence. Suppose the density of \\(\\pmb X_{1:t}\\) is \\(f_t\\) and we wish to estimate the expected value of \\(h(\\)X_{1:t}\\()\\) w.r.t. \\(f_t\\). A direct application of the SIR approach would be to draw a sample \\(\\pmb x_{1:t}\\) sequences from an envelope gt and then calculate the importance weighted average of this sample of \\(h(\\pmb X_{1:t})\\) values. This SIR approach overlooks a key aspect of the problem. * As t increases, \\(\\pmb X_{1:t}\\) and the expected value of \\(h(\\pmb x_{1:t})\\) evlove. * At time \\(t\\) it would be better to update previous inferences than to act as if we had no previous information. Inefficient !!! Need to develop a strategy that will simulate \\(X_t\\) from previously simulated \\(\\pmb X_{1:t-1}\\) and adjust the previous importance weights in order to estimate the expected value of \\(h(\\pmb X_{1:t})\\) . Sequential Importance Sampling. 4.1.1.0.10 SIS for Markov Process Simplify assumption that \\(\\pmb X_{1:t}\\) is a Markov process. The target density \\(f_t (\\pmb x_{1:t})\\) may be expressed as $ \\[\\begin{align*} f_t (\\pmb x_{1:t}) &amp;= f_1 (x_1) &amp;\\ast f_2 (x_2 \\rvert \\pmb x_{1:1}) &amp;\\ast f_3 (x_3 \\rvert \\pmb x_{1:2}) &amp;\\cdots &amp;\\ast f_t (x_t \\rvert \\pmb x_{1:t-1}) \\\\ &amp;= f_1 (x_1) &amp;\\ast f_2 (x_2 \\rvert x_1) &amp;\\ast f_3 (x_3 \\rvert x_2) &amp;\\cdots &amp;\\ast f_t (x_t \\rvert x_{t-1}) \\end{align*}\\] $ Suppose that we adopt the same Markov form for the envelope, namely $ g_t (x_{1:t})= g_1 (x_1) g_2 (x_2 x_1) g_3 (x_3 x_2) g_t (x_t x_{t-1}) $ Sample from \\(g_t (\\pmb x_{1:t})\\) and reweight each \\(\\pmb x_{1:t}\\) value by \\(w_t = \\dfrac {f_t (\\pmb x_{1:t})}{g_t (\\pmb x_{1:t})}\\). The weight at time \\(t\\) is \\(w_t = \\dfrac {f_1 (x_1) \\ast f_2 (x_2 \\rvert x_1) \\ast \\cdots} {g_1 (x_1) \\ast g_2 (x_2 \\rvert x_1) \\ast \\cdots}\\). A sample of \\(n\\) such points and their weights can be used to approximate \\(f_t (\\pmb x_{1:t} )\\) and calculate the expected value of \\(h(\\pmb x_{1:t} )\\). The sequential Monte Carlo algorithm for generating one sample is 1. Sample $X_1 g_1 $. Let \\(w_1 = u_1 = \\dfrac {f_1(x_1)}{g_1(x_1)}\\). Set \\(t = 2\\). 2. Sample \\(X_t \\rvert x_{t-1} \\sim g_t (x_t \\rvert x_{t-1})\\). 3. Append \\(x_t\\) to \\(\\pmb x_{1:t-1}\\), obtaining \\(\\pmb x_{1:t}\\). 4. \\(u_t = \\dfrac{f_t (x_t \\rvert x_{t-1})}{g_t (x_t \\rvert x_{t-1})}\\). 5. let \\(w_t = w_{t-1}u_t\\). \\(w_t\\) is the importance weight for \\(\\pmb x_{1:t}\\) . 6. Increment t and return to step 2. The weighted average \\(\\sum_{i=1}^n \\left( \\dfrac {w_t^{(i)}}{\\sum_{i=1}^n w_t^{(i)}} \\right) \\ast h(\\pmb X_{1:t}^{(i)})\\) serves as the estimate of \\(E_{f_T} h(\\pmb X_{1:t})\\). 4.1.1.0.11 Generalized Sequential Importance Sampling Assume that \\(\\pmb X_{1:t}\\) is not a Markov process. target density \\(f_t (\\pmb x_{1:t})\\) and envelope \\(g_t (\\pmb x_{1:t})\\) may be expressed as $ \\[\\begin{align*} f_t (\\pmb x_{1:t}) &amp;= f_1 (x_1) \\ast f_2 (x_2 \\rvert \\pmb x_{1:1}) \\ast f_3 (x_3 \\rvert \\pmb x_{1:2}) &amp;\\cdots &amp;\\ast f_t (x_t \\rvert \\pmb x_{1:t-1}) \\\\ g_t (\\pmb x_{1:t}) &amp;= g_1 (x_1) \\ast g_2 (x_2 \\rvert \\pmb x_{1:1}) \\ast g_3 (x_3 \\rvert \\pmb x_{1:2}) &amp;\\cdots &amp;\\ast g_t (x_t \\rvert \\pmb x_{1:t-1}) \\end{align*}\\] $ the importance weight at time \\(t\\) is $ w_t (x_{1:t}) = {g_1 (x_1) g_2 (x_2 x_{1:1}) g_3 (x_3 x_{1:2}) g_t (x_t x_{1:t-1})} $ and the recursive updating expression for the importance weights is \\(w_t(\\pmb x_{1:t}) = w_t(\\pmb x_{1:t}) \\dfrac {f_t (x_t \\rvert \\pmb x_{1:t-1})}{g_t (x_t \\rvert \\pmb x_{1:t-1})}, \\; \\; \\; \\; \\; \\; \\; \\; \\text{for }t&gt;1\\) "],["markov-chain-monte-carlo.html", "4.2 Markov Chain Monte Carlo", " 4.2 Markov Chain Monte Carlo $ f $ 가 측정은 되는데 샘플화가 안되면, MC를 통해 유사한 샘플을 만들어낼 수 있었다. 이를 넘어서 MCMC는 $ f $ 의 모사함수에서 샘플링하는 게 가능하지만, 이 이상으로 이는 임의의 함수 \\(p\\)에 대해 \\(E[p(X)]\\)가 신뢰도 높게 측정되는 경우에만 샘플링 가능한 별개의 방법론으로 보는 게 정확하다. MC MCMC numerical integration approach iterative nature can be customized to very diverse &amp; difficult problem 무관하며 implementation이 complex하지도 않음 문제가 고차원이면 수렴이 느려짐 시퀀스 $ { ^{(t)} } $는 MC, $ t = 0, 1, 2, …. $. $ ^{(t)} = (X_1^{t} , , X_p^{(t)})$ 와 state space 는 양쪽 모두 연속이거나 discrete. For the types of Markov chains, $ { ^{(t)} } $의 분포는 체인의 limiting stationary distribution으로 수렴한다. 체인이 irreducible, aperiodic 할 때. MCMC의 샘플링 전략은 irreducible, aperiodic MC를 만드는 것. stationary distribution이 목표분포 $ f $ 와 일치하는. t가 충분히 크다면 이 체인으로부터의 $ ^{(t)} $의 실현값은 근사적으로 마지널 분포 $ f $ 를 갖는다. 이런 MCMC의 특성은 베이지안 추론에 크게 도움이 되며 자주 쓰인다. Markov Chain 자체는 어떤 상태에서 다른 상태로 넘어갈 때, 바로 전 단계의 상태에만 영향을 받는 (Markov Property) 확률 과정을 의미한다. * 보통 사람들은 전날 먹은 식사와 유사한 식사를 하지 않으려는 경향이 있다. * 가령, 어제 짜장면을 먹었다면 오늘은 면종류의 음식을 먹으려고 하지 않는다. 4.2.1 MH Algorithm MCMC 중 가장 유명한 적용법은 MH 알고리즘. $ t=0 $에서 시작. 시작 distribution $ g $에서 추출한, $ f(^{(0)} )&gt; 0 $ 을 만족하는 $^{(0)} $를 $ ^{(0)} = ^{(0)} $ 로 잡고 개시한다. 이때 제안분포 $ g $ 에서 후보 $ ^{( )} $ 를 하나 만들고, MH ratio $R (^{(t)}, ^{} ) $ 는 $ R (^{(t)}, ^{} ) = {f(^{( )}) g(^{( t )} | ^{( )})} {f(^{( t )}) g(^{( )} | ^{( t )}) } = { {f(^{( )})} {g(^{( )} | ^{( t )})} } { {f(^{( t )})} {g(^{( t )} | ^{( )})} } = { {f(^{( t+1 )})} {g(^{( t+1 )} | ^{( t )})} } { {f(^{( t )})} {g(^{( t )} | ^{( t+1 )})} } $ 여기서 단순 Metropolis 알고리즘은 단순히 $ \\dfrac {f(x_1)} {f(x_0)}$ &gt; $1 $ 이기만 하면 새로운 샘플을 수용한다. 이인즉 $ g $로 표준화해주는 것의 가장 주요한 요점은 둘의 시작 높이, 즉 쥐고 나온 수저가 다를 수 있으므로 이를 표준화해준다는 것이다. 아웃풋이 높은 $x_i$를 선택하는 것은 MLE 관점에 기반한다. 단 언제나 그렇듯 이렇게 샘플을 다쳐내면 오히려 음질의 결과가 나온다. 따라서 샘플의 풀을 넓히기 위해 탈락할 녀석들도 확률적으로 살려서 합류시킨다. 이게 고정된 기준점으로 샘플을 쳐내는 것이 아닌, $ \\dfrac {f(x_1)} {f(x_0)}$ &gt; $u \\sim U {(0,1)} $ 을 기준으로 삼아 샘플을 생존시키는 것이다. 이 조건을 실패하면 생산해두었던 샘플 $\\textbf X^{(t)}$ 는 버려지고 새로운 샘플을 $t+1$으로 설정해 재진행한다. 이후 $ ^{(t+1)} = { \\[\\begin{array}{@{}lr@{}} \\textbf {X}^{\\ast}, &amp; \\text{with probability } min \\left\\{ R \\left( \\textbf {x}^{(t+1)}, \\textbf {X}^{\\ast} \\right), 1 \\right\\} \\\\ \\textbf {x}^{(t)}, &amp; o.w. \\end{array}\\] } $ 이러한 MH 알고리즘에 의해 생성된 MC가 aperiodic &amp; irreducible 이라면, 해당 체인은 정적분포로 수렴. 우리는 이러한 MH 체인에 의해 생성된 정적분포의 실현값들을 평균함으로써 rv의 함수의 기댓값을 구할 수 있다. \\(E \\left[ h \\left( \\textbf {X} \\right) \\right] \\approx \\dfrac {1} {n} \\sum_{i=1}^n {h \\left( \\textbf {x}^{(i)} \\right)},\\) $E { { h ( ) - E } }^2, $ \\(E \\{ I_{h ( \\textbf {X} \\le q )} \\}\\) 시퀀스 $ { ^{()} } $ 는 state space의 몇몇 포인트들의 multiple copies를 가질 수 있다는 것을 명심. 이는 \\(\\textbf {X}^{(t+1)}\\)가 제안값 \\(\\textbf {x}^{(\\ast )}\\)가 아니라 \\(\\textbf {x}^{(t)}\\)를 채택했을 때 발생. Burn-in Period: 체인의 초기값에 대한 persistent dependence는 이의 성능을 심각하게 낮출 수 있다. 이는 샘플 평균을 계산할 때 체인의 초기 실현값 일부를 제하는 것으로 보정될 수 있다. consistent 결과들을 관측하기 위해 MCMC를 여러 시작점에서 각각 돌려본다. 잘 골라진 제안분포 $ g $가 생산하는 후보값들은 stationary 분포의 서포트를 합리적인 반복 안에서 전부 커버하고, 내놓는 후보값들이 지나치게 여러번 accepted되거나 rejected 되지 않는다. * proposal 분포 $ g $ 가 지나치게 퍼져있으면, 후보값들은 자주 reject되고 체인은 타겟분포 $ f $ 의 space를 탐색하기 위해 많은 반복을 요구하게 된다. * proposal 분포 $ g $ 가 지나치게 모여있으면, 체인은 다회의 반복동안 타겟분포 $ f $의 한 작은 구역에 모여있게 된다. 따라서 타겟분포의 다른 영역은 적절하게 탐색되지 못한다. 4.2.1.0.1 Independent Chains acceptance 여부 결정시에 ratio 자체는 MH ratio를 사용한다. 이 MC ratio에는 과거 실현값(\\(x^{(t)}\\))이 들어있다. 따라서 이는 MCMC 방법론에 해당한다. 하지만 새로운 value \\(g(x&#39;)\\)을 생산할 때, 이 자체는 \\(g(x&#39;\\rvert x^{(t)})=g(x&#39; \\rvert \\cdot )\\)을 따르게, 즉 \\(g(x&#39;\\rvert x^{(t)})=g(x&#39; )\\) 마냥 과거의 실현값에 dependent 하지 않게 새로운 값을 생산해내는 방법론. 즉 새로이 제시되는 candidate value가 과거의 실현값들과 independent 하므로 명칭이 저러한 것이다. 즉 MH ratio 자체는 과거의 샘플을 이용해서 MCMC 범주에 들어가나 샘플 자체는 과거의 샘플과 independent하게 생산. MH 알고리즘의 제안분포는 고정된 덴시티 \\(g\\)에 대해서 $ g ( ^{} ^{(t)} )$ 따위로 생성. 이는 independent chain 이라고 불리며, 이에 사용되는 각 후보값들은 과거에서 독립적으로 추출되었다. MH ratio는 $R (^{(t)}, ^{} ) = {f(^{( )}) g(^{( t )} | ^{( )})} {f(^{( t )}) g(^{( )} | ^{( t )}) } = {f(^{( )}) g(^{( t )})} {f(^{( t )}) g(^{( )}) } = { {f(^{( )})} {g(^{( t )})} } { {f(^{( t )})} {g(^{( )})} } = { {f(^{( )})} {g(^{( )})} } { {f(^{( t )})} {g(^{( t )})} } = {w^{(t)}} $ importance ratio of \\(X&#39;\\), importance ratio of \\(X^{(t)}\\). This can be seen as weight also. 이때 가장 우측의 등식은 importance ratio ($ r $)의 등식으로 재표현된 것이며, 이때 $ f $ 는 타겟분포, $ g $ 는 그것의 envelope로 본 것이다. 4.2.1.0.1.1 Example: Bayesian Inference, Mixture Distribution MCMC 알고리즘은 $ p(y ) = c , {*} , p() L(y) $ 로 표현될 수 있는 베이지안 추론에서 특히 강력하다. 베이지안 추론에서 \\(c\\)의 계산이 드럽게 어렵다는 것이 이것 이상의 다른 추론전략을 방해하기 때문이다. 보유하는 stationary 분포가 타겟 post인 MCMC에서 생산된 샘플들은 post 모먼트, tail 확률, 그리고 다른 유용한 quantity 계산에 쓰일 수 있다. independent 체인에서 prior를 proposal 분포(\\(g\\))로 쓰자. 즉 \\(f\\)가 post, \\(g\\)가 prior다. 이런다면 $ R ({}^{(t)}, ^{} ) = { {f(^{( )})} {g(^{( )})} } { {f(^{( t )})} {g(^{( t )})} } = {c ; ; ( ^{} ) L( ^{} y )} {c ; ; ( ^{(t)} ) L( ^{(t)} y )} = { {(^{} y)} {(^{})} } { {(^(t) y)} {(^{(t)})} } = {L ( ^{} y )} {L ( ^{(t)} y )} $ Mixing Properties: Good Mixing: 첫번째 그림의 MC는 시작점에서 빠르게 멀어지며 \\(\\delta\\)에 대한 post에서의 모든 서포트에 해당하는 패러미터 space의 모든 부분을 훑으면서 샘플을 뽑아내는게 쉬워보인다. Bad Mixing: 두번째 그림은 starting value에서 멀어지는 것도 느리고, posterior support의 영역을 탐색하는 게 시원찮아보인다. Burn-in 이후의 실현값들을 히스토그램으로 만들어서 살펴보면 \\(BETA(1,1)\\) proposal 덴시티를 쓴 MCMC만이 \\(\\delta\\)의 참값을 잘 모사하는듯. 4.2.2 Random Walk Chains (Most Widely Used) MH method 에 해당. let $ ^{} = ^{(t)} + , h().$ 이때 $ h $는 임의의 덴시티. * $ h $ 로 자주 선택되는건 $ U, , t $. 이러면 proposal 덴시티 \\(g\\)는 어떻게 되는가? \\(x^{&#39;} g \\sim N( \\cdot \\rvert x^{(t)}, \\sigma^2 )\\). 가장 빈번하게 쓰이는게 \\(N\\)이므로 \\(N\\)으로 설명. 여기서 $ x^{(t)} $는 평균으로 사용되었고, $^2 $은 Jumping Rule에 해당한다. * proposal can be * too diffused: Jumping rule is too big * too focused: Jumping rule is too small * Random Walk 1. generate \\(x^{&#39;} g \\sim N( \\cdot \\rvert x^{(t)}, \\sigma^2 )\\) 2. $ u U(0,1) $. 3. calculate MH ratio: \\(r = \\dfrac {f(x&#39;)}{f(x^{(t)}} \\dfrac {g(x&#39; \\rightarrow x^{(t)}} {g(x^{(t)} \\rightarrow x&#39;} = \\dfrac {f(x&#39;)}{f(x^{(t)}}\\), cause it’s \\(N\\). 4. if \\(u&lt;r\\), \\(x^{(t+1)} = x&#39;\\). o.w., \\(x^{(t+1)} = x^(t)\\). 4.2.2.0.1 Example: Mixture Distribution let proposal $^{(t+1)} = ^{(t)} + U(-a, a) $ [* random increment]. 이인즉 몇몇 proposal들은 $ [0, 1] $ 이외에서 생산된다. * note that $ $, post is zero, * Reparameterize the problem by letting $ U = $(logit). 왜? Probabilty Space is bounded: \\(0 \\le P(\\cdot) \\le 1\\). Run a random walk chain on \\(U\\) by adding \\(U(-b,b)\\). Two ways of Reparamaterization: * Run MCMC in \\(\\delta\\)-space. \\(u\\) 값을 다시 T해와서 \\(\\delta\\)-space에서 돌림. * Run MCMC in \\(u\\)-space. \\(u\\)-space에서 돌리고 마지막에 모델 샘플들을 전부 \\(\\delta\\)-space로 환원. 4.2.2.0.1.1 \\(\\delta\\)-space에서 돌리는 방법 개략적으로는 $ T^{-1}: ’ u’ g( u^{(t)}) $ 와 같은 형을 띤다. 조건부 proposal \\(g\\)에서 생산된 u를 하나하나마다 \\(\\delta\\)로 역변환해서 그 하나하나의 역변환 값으로 MH 알고리즘을 돌린다. proposal 덴시티 $ g( u^{(t)} )$ 는 \\(\\delta\\)-space에서의 proposal 덴시티로 변환되어야 한다. 이경우 MH ratio는 $ R (^{(t)}, ^{} ) = { {f(^{})} {g ( logit(^{}) logit(^{(t)}) ) | J(^{})|} } { {f(^{(t)})} {g ( logit({(t)})|logit({}) ) | J(^{(t)})|} } $ $J(^{(t)}) $ 는 $T: u $에 대한 \\(J\\)를 \\(\\delta^{(t)}\\)에서 측정한 값. 주의해야 할 것이 해당 방법론에서는 \\(T\\)한 value를 사용하였으므로 \\(g\\)에 대한 \\(J\\)를 구해야 한다. 4.2.2.0.1.2 \\(u\\)-space에서 돌리는 방법 이 상황에서 쓰이는 proposal은 $ {g(u’ u^{(t)})}$. \\(\\delta\\)에 대한 타겟 덴시티는 \\(u\\)에 대한 덴시티로 변형되어야 한다. 이때 \\(\\delta = logit^{-1}(U) = \\dfrac{\\exp(U)}{1+\\exp(U)}\\) 였으므로, $ U^{} = u^{} $ 로 두었을 때 생산되는 MH ratio는 $ R (^{(t)}, ^{} ) = { {f(logit^{-1} {(u^{})})} {g (u{}|u{(t)}) ) * | J(u^{(t)})|} } { {f(logit^{-1} {(u^{(t)})})} {g (u{(t)}|u{()}) ) * | J(u^{})|} } $ 우리가 transform value를 사용한데가 \\(f\\) 덴시티이므로 \\(f\\) 덴시티에 대한 야코비안을 붙여줘야 하는데 그 덴시티에 대한 야코비안은 \\(u\\)에 대한 야코비안이므로 쓰인 야코비안은 위와 같다. 이때 $ J(u^{}) = {J(^{}) }$ 이므로 위와 아래에서 만들어지는 MH ratio는 같다. 따라서 두 관점은 equivalent한 체인을 생산한다. * Sample paths for \\(\\delta\\) from RW chains in Ex. 7.3, run in \\(u\\)-space iwth b=1 (top) and b=0.01 (bottom). 4.2.2.0.2 Example: Autocorrelation Plot (ACF) 배우지 않은 MCMC 방법론 중 하나. reminder. thinning을 하더라도 거의 줄지 않아서 MCMC 샘플로서 거의 가치가 없는 케이스가 존재한다. no 4.2.3 Basic Gibbs Sampler {:.bg-green-lighter} - need to derive the conditional density for all, 모든 joint density에 대해 coefficient를 1개씩 제한 상황의 모든 conditional density를 구한 후 GS 제작이 가능 - if conditional densities are not available, we can use MH algorithm when updating \\(x_i\\) -&gt; 이런식으로 접근할 경우 이를 MH-within-Gibbs라고 부른다. - 1PL IRT HW let \\(\\textbf {X} = (X_1 , \\cdots, X_p )^{&#39;}\\) , \\(\\textbf {X}_{-i} = (X_1 , \\cdots, X_{i-1}, X_{i+1}, \\cdots, X_p )^{&#39;}\\). 시작값 $^{(0)} $를 잡고, \\(t=0\\)으로 설정한다. 이후 각각을 \\(t+1\\) 단계의 시퀀스의 구성요소 각각을 $ X_i^{(t+1)} ; ; f ( x_1 x_2^{(t)}, , x_p^{(t)} )$ 에 따라서 생산한다. Gibbs Sampler의 stationary 분포는 \\(f\\). \\(X_i^{(t)}\\)의 limiting 마지널 분포는 \\(i\\)번째 coordinate에 따른 타겟분포의 단변량 마지널化와 같다. MH 알고리즘과 마찬가지로, 우리는 \\(X\\)의 임의의 함수 \\(g(X)\\)에 대해 \\(E \\left[ g(X) \\right]\\) 를 추정하기 위해 체인에서의 실현값을 사용할 수 있다. 4.2.3.0.1 Example: Fur Seal Pup Capture-Recapture Model 1800년대 후반 (by the late 1800s) 뉴질랜드 물범은 거의 전멸했다가 요즘 들어 폭증함 (abundance). 물범의 고름 숫자를 capture-recapture 사용해서 해보자. 사이즈 불명인 모집단의 크기 파악 위에 반복 연구 실행. 각 연구마다 포획었던 개체는 표식 새기고 풀어줌. 후속 연구에서 또 포획되면 재포획으로 표기. 높은 재포획 비율은 참 모집단 사이즈값이 포획되었던 개체들의 총량을 크게 넘지 않을 것임을 암시. \\(N\\): 불명인 모집단 사이즈. \\(l\\)회의 조사 통해 얻어진 각 회의 총 포획 숫자는 각각 \\(c=(c_1, \\cdots, c_l)\\)로 저장. 모집단 사이즈는 샘플링 동안에는 변동 없다(죽음, 출생, 이주 없음 inconsequential)고 가정한다. \\(r\\): 연구 동안에 포획되었던 이질 동물들의 총 숫자. 각 연구 시도에서 상응하는 구분되고 알려지지 않은 포획 확률은 \\(\\alpha = (\\alpha_1 , \\cdots, \\alpha_l )\\). 이 모델은 모든 동물들이 각 1회의 포획 발생에서 잡힐 가능성 자체는 각각의 동물에 대해서 동일하나, 이 被포획 확률은 시간이 지남에 따라 변할 수 있다는 것을 말함. 이 모델의 likelihood는 $ L ( N, c, r ) _{=1}^{l} _i^{c_i} $ Fur Seal Data for Seven Studies in One Season on the Otago Peninsula가 주어졌으며, prior은 \\(\\pi(N) \\propto 1\\), \\(\\pi (\\alpha_i ) = BETA(\\theta_1 , \\theta_2)\\) 이다. 계산하라. 해당 모델의 conditional posterior distribution에서 시뮬레이트하는 것으로 Gibbs Sampler를 제작할 수 있다. $ N^{(t+1)}-r Negative Binomial ( r+1, 1- _{i=1}^7 ( 1- _i^{(t)} ) ) $ $ _i^{(t+1)} BETA ( c_i + , N^{(t+1)} - c_i + ) $ for \\(i= 1, \\cdots, 7\\), \\(r = \\sum_{i=1}^7 {m_i} =84\\). 이는 unique fur seals were observed during the sampling period. * Split boxplots of \\(\\bar {\\alpha}^{(t)}\\) against $N^{(t)} $ for the seal pup example. * Estimated marginal posterior probabilities for \\(N\\) for the seal pup example. 4.2.3.0.2 MH-within-Gibbs Sampler 실제 implementation에 무지막지 유용하다. 이는 각각의 사이클을 GS의 사이클로 만들어놓고, conditional density는 MH 알고리즘으로 획득하는 것이다. Gibbs Sampler는 MH Sampler의 특별한 경우라고 볼 수 있다. MH 알고리즘의 proposal 분포를 시간에 따라 변화하도록 함으로써, GS와 MH 알고리즘 사이에 연결고리가 생긴다. 각 Gibbs 사이클은 \\(p\\) 개의 MH 스텝으로 구성되어 있다. 사이클 내에서의 \\(i\\)번째 Gibbs 스텝은, 체인의 현 상태 \\((x_{1}^{(t+1)}, \\cdots, x_{i-1}^{(t+1)}, x_{i+1}^{(\\underline{t})}, \\cdots, x_{p}^{(\\underline{t})})\\) 가 주어졌을 때, 효과적으로 후보 벡터 \\((x_{1}^{(t+1)}, \\cdots, x_{i-1}^{(t+1)}, {\\underline{X_i^{*}}}, x_{i+1}^{(\\underline{t})}, \\cdots, x_{p}^{(\\underline{t})})\\) 를 생산한다. 밑줄 차이점에 주목. \\(i\\)번째 단변량 Gibbs 업데이트는 이하와 같이 MH 스텝 drawing으로 볼 수 있다. $ {\\underline{X_i^{*}}} (x_{1}^{(t+1)}, , x_{i-1}^{(t+1)}, x_{i+1}^{()}, , x_{p}^{()}) g_i ( (x_{1}^{(t+1)}, , x_{i-1}^{(t+1)}, x_{i+1}^{()}, , x_{p}^{()}) ) $ where $ g_i ( (x_{1}^{(t+1)}, , x_{i-1}^{(t+1)}, x_{i+1}^{()}, , x_{p}^{()})) = { \\[\\begin{array}{@{}lr@{}} f(x_i^{*} \\rvert x_i^{(t)} ), &amp; \\text{if } \\; \\; \\; X_i^{*} = x_i^{(t)} \\\\ 0 &amp; o.w. \\end{array}\\] } $ 이 경우, MH ratio는 1과 같아진다. 즉슨 모든 후보들은 언제나 accept 된다. 즉슨 GS는 MH 알고리즘에서 acceptance ratio가 항상 1인 경우에 해당한다. 따라서 conditional density을 구할 수만 있으면 GS를 사용하는게 좋다. 샘플을 버릴 필요가 없고, 버려지는 샘플이 없기 때문. 4.2.3.0.3 Update Ordering Random Scan Gibbs Sampling: 기본 GS에서 $ $ 에 가해지는 업데이트의 순서는 한 사이클에서 다음 사이클로 넘어갈 때마다 바뀔 수 있다. 패러미터들이 높은 수준에서 상호연관되어있을 경우, 각 사이클을 랜덤하게 순서배치하는 것은 효과적일 수 있다. [^1] 특정 모델에 대한 전문화된 지식이 없다면, 한 이터레이션에서 다음으로 넘어갈 때 패러미터끼리 높이 상호연관되어있다면 deterministic 한 방법과 RSGS 양쪽 모두를 시도해보는 것이 권장된다. [^1] The ordering of updates made to the components of X in the basic Gibbs sampler can change from one cycle to the next. Random ordering each cycle can be effective when parameters are highly correlated. In practice without specialized knowledge for a particular model, we recommend trying both deterministic and random scan Gibbs sampling when parameters are highly correlated from one iterations to the next. 4.2.3.0.4 Blocking with \\(p=4\\), e.g., 각 사이클을 다음 절차를 따르면서 업데이트: 1. \\(X_1^{(t+1)}\\rvert \\cdot \\sim f \\left(x_1 \\rvert x_2^{(t)}, x_3^{(t)}, x_4^{(t)} \\right)\\). 2. \\(X_2^{(t+1)}, X_3^{(t+1)}\\rvert \\cdot \\sim f \\left(x_2, x_3 \\rvert x_1^{(t+1)}, x_4^{(t)} \\right)\\). 3. \\(X_4^{(t+1)}\\rvert \\cdot \\sim f \\left(x_4 \\rvert x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)} \\right)\\). Blocing은 \\(X\\)의 구성요소들이 서로 상관관계가 있을 때 \\(X_i\\) 내부가 상관이라는 건가, 아니면 \\(X_t, X_{t+1}\\) 이 상관이라는 건가? 유용함. 해당 알고리즘을 통해 더욱 상관된 구성요소끼리는 한 블럭 안에서 샘플링됨. 4.2.3.0.5 Hybrid Gibbs Sampling 하나 이상의 \\(X\\)에 대한 조건부 분포는 대부분 closed form으로 만들 수 없음. 깁스 샘플러의 주어진 스텝에서, 적절한 조건부 분포에서 샘플링하기 위해 MH 알고리즘이 쓰인다면 Hybrid MCMC 알고리즘이 완성됨. with \\(p=5\\), e.g., 하이브리드 MCMC 알고리즘은 다음 절차를 따르면서 업데이트: 1. Update $X_1^{(t+1)} ( x_2^{(t)}, x_3^{(t)}, x_4^{(t)}, x_5^{(t)} ) $ with 깁스 스텝. 2. Update ( x_2^{(t+1)}, x_3^{(t+1)} ) $ ( x_1^{(t+1)}, x_4^{(t)}, x_5^{(t)} ) $ with MH 스텝. 3. Update $X_4^{(t+1)} ( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_5^{(t)} ) $ with 랜덤워크. 4. Update $X_5^{(t+1)} ( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_4^{(t+1)} ) $ with 깁스 스텝. 4.2.3.0.5.1 Example: Fur Seal Pup Capture-Recapture Study 4.2.4 Implementation MCMC의 목적은 타겟분포 \\(f\\)의 특징들을 알아내는 것. 모든 MCMC는 정답인 limiting 정적분포를 가지고 있음. 실전에는 체인을 얼마나 충분히 오래 돌릴지를 결정하는 게 중요함. \\(X\\)의 dimensionality(차원)이 높다면 수렴이 엄청 느려서 엄청 긴 run을 요할 수도 있음. 이하의 요건들을 생각해서 long run을 결정해야 함. * Has the chain run long enough? * Is the first portion of the chain highly influenced by the starting value? * Should the chain be run from several different starting values? * Has the chain traversed all portions of the region of support of \\(g\\)? * Are the sampled values approximate draws from \\(f\\)? * How shall the chain output be used to produce estimates and assess their precision? 4.2.4.0.1 Ensuring Good Mixing and Convergence MCMC 알고리즘이 대상 문제에 얼마나 쓸만한 정보를 주는지 고민해야 함. 이는 곧 1. 체인이 얼마나 빠르게 체인의 starting value를 까먹는가 2. 얼마나 빠르게 체인이 타겟분포 \\(f\\)의 모든 서포트를 훑는가 3. 체인이 그것의 정적분포에 근사적으로나마 닿는가를 고민. 4. There is substantial overlap between the goals of diagnosing convergence to the stationary distribution and investigating the mixing properties of the chain. 4.2.4.0.2 Simple Graphical Diagnostics 트레이스 플롯 (sample path)은 이터레이션 횟수 \\(t\\)와 \\(X^{(t)}\\)의 실현값 간의 플롯이다. * 체인의 mixing이 구리면 이는 장기간의 이터레이션동안 동일값 근처에서 머무르게 됨. * 체인의 mixing이 좋으면 시작값에서 빠르게 떠나서 \\(f\\)의 서포트에 해당하는 영역을 열심히 훑음. autocorrelation 플롯은 \\(X^{(t)}\\)의 시퀀스에서 다른 이터레이션 래그에서의 상관관계를 서술한다. 래그 \\(i\\)에서의 autocorrelation은 \\(i\\) 이터레이션만큼 떨어진 이터레이트 간의 상관관계이다. 구린 mixing 프로퍼티를 가지는 체인은 이터레이션 간의 래그가 증가하더라도 autocorrelation의 부식(decay)이 느림. MCMC 체인에서의 첫 \\(D\\) 개의 값은 보통 burn-in period라고 해서 버려짐. 체인의 시작점에 대한 의존이 강하게 남아있을지도 모르기 때문. 어느정도가 적절한 번인 피리어드인가는 Gelman-Rubin diagnostics에 의해 결정된다. 결정된 번인 피리어드가 제대로 된 값을 못내면 \\(D\\)가 늘어나던가 \\(L\\)이 늘어나던가 둘다 늘리던가 해야함. * Motivated by an Analysis of Variance * 사슬간 분산 (between-chain variance)이 사슬내 분산 (within-chain variance)보다 유의하게 크면 번인 피리어드나 MCMC 길이가 늘어나야 함 * Difficulties * multimodal \\(f\\)에서 적절한 스타팅 밸류를 찾는건 어렵고, 체인이 로컬 region이나 mode에서 갇힐수 있음 * 이의 단일차원성 (uni-dimensionality) 때문에 타겟분포 \\(f\\)가 멀티디멘션이면 타겟분포의 수렴에 대한 정보에 대한 잘못된 직관을 줘버릴 수 있음 proposal \\(g\\) 선택할 때 고려해야할 요소는? mixing은 proposal 분포 \\(g\\)의 특질에 큰 영향을 받으며 특히 이의 스프레드(spread)에 큰 영향을 받음. 타겟분포 \\(f\\)와 \\(g\\)간의 닮음에 있어서, 프로포절 \\(g\\)의 tail behavior의 닮음은 high density의 닮음보다 훨씬 중요함. \\(f/g\\)가 bounded 라면, MC의 정적분포로의 수렴은 대체로(overall) 빠름. 실전에선 정보를 줄 수 있는 이터레이티브 프로세스를 통해 proposal 분포의 분산이 택해질 수 있음. (In practice, the variance of the proposal distribution can be selected through an informal iterative process.) 20%~50% 사이의 acceptance rate가 선호되어야 함. Reparameterization. 모델의 reparameterization은 MCMC 알고리즘의 mixing behavior에 상당한 기능향상을 가져올 수 있음. reparameterization은 dependence를 낮추기 위해 가장 우선되어야 할 전략 중 하나임. 서로 다른 모델들은 서로 다른 reparameterization 전략을 적용해야 함. reparameterization 접근법은 보통 특정 모델에 대한 원오프로서 채택되므로 일반화된 조언을 하기에는 어려운 부분이 있음. Comparing Chains. MCMC 실현값이 크게 상관관계있다면, MCMC의 각 이터레이션에서 주어지는 정보는 run length에서 주어지는 정보 대비 보잘것 없다(will be less than suggested by the run length). 여기서 reduced information은 effective sample size라고 칭해지는 더 작은 iid 샘플에 담겨있는 정보와 동등하다. 여기서 샘플의 총 숫자와 effective sample size 사이의 차이는 잃게 된 효율을 의미한다. 관심있는 변량을 확인하기 위해 우리가 MC 체인에서의 correlated 샘플들을 사용했을 때 잃게된 효율. Number of Chains. 모델 진단에 있어서 가장 진단을 어렵게 하는 부분은 체인이 타겟분포 \\(f\\)의 1개 이상의 모드에 걸리냐 안걸리냐 하는 부분. 이 경우 모든 수렴진단은 체인이 수렴하긴 한다는 결론을 내리게 된다. 정작 체인이 타겟분포 \\(f\\)의 모든 특성을 나타내지 못하는데도. 그래서 여러번 돌려보게 되는 것. 최소한 그 여러번의 run들 중 체인 1개에서라도 타겟분포 \\(f\\)의 모든 흥미로운 특질들이 드러났으면 하니까. 이러한 특질을을 찾아내는데 실패한 개별 체인들의 경우에는 mixing을 더 좋게 만들기 위해 체인 길이가 늘어나거나 문제가 reparameterize 되어야 함. "],["advanced-mcmc-wk08.html", "4.3 Advanced MCMC (wk08)", " 4.3 Advanced MCMC (wk08) 1, 3, 5번이 자주 사용됨 2, 3, 4의 목적은 proposal density 개선 1번은 missing data handling 5번은 variable selection 기본적으로 \\(f(x) = c \\psi (x) = c \\exp \\left( -\\dfrac{U(x)}{t} \\right)\\)의 개형을 따름. 4.3.1 1. Data Augmentation Missing Pattern MCAR MAR NMAR in missingness in missing on a variable No patterns can be predicted by other variables Missing values related to variable? not to any other variables the variable itself complete data considered as a random subsample from the original target sample whether data is NMAR is a theoretical and conceptual considerate Assumption power 3 2 1 missing을 의식할 필요가 있는 상황인가? No.missing 자체를 무시 (ignore). Yes.predict missing by other variable Yes.impute with seperate model bayesian 분석에서 Handling Missing Data에 자주 사용된다. Data Augmentation(DA) 알고리즘은, 불완전 데이터에 대한 bayesian 분석으로 설명될 수 있다. \\(X_{obs}\\) | observed data | \\(X_{mis}\\) | missing data | $X_{com}= (X_{obs},X_{mis} ) $ | complete data | assume complete 데이터 모델 \\(X_{com} = (X_{obs}, X_{mis}) \\sim g \\left( X_{obs}, X_{mis} \\rvert \\theta \\right)\\), where 패러미터 $^d, d ^+ $. 여기서 목적은 패러미터 \\(\\theta\\)에 대한 prior 분포 \\(\\pi (\\theta)\\)와 함께 bayesian 추론을 만드는 것. 이는 곧 \\(g \\left( X_{obs}, X_{mis} \\rvert \\theta \\right) \\ast \\pi(\\theta)\\) 를 말한다. Multiple Imputation | 데이터 impute, 그 impute한걸로 패러미터 업데이트, 다시 impute, …. 여기선 impute 셋을 여러개를 만들어놓고, 그걸 패러미터를 계산을 해서 패러미터 분포를 갖고 inference. | Data Augmentation | interatively하게 패러미터 impute, 업데이트, impute, 업데이트, …. | proceeds: MCMC로 DA let observed-data model \\(f(X_{obs} \\rvert \\theta)\\). 이는 아래와 같이 joint pdf에서 마지널을 뽑아냄으로써 (integrate) 단독 pdf를 획득하는 것이 가능함. MCMC 방법론을 사용해 \\(\\theta\\)에 대한 Bayesian 추론을 진행하면 true or observed-data post를 샘플링하거나, 혹은 더욱 일반적으로는 \\(\\theta\\)와 \\(X_{mis}\\)의 joint 분포를 샘플링할 것을 요구한다. 이의 각각을 수식으로 나타내면 다음과 같다. $ \\[\\begin{alignat}{4} &amp; &amp;&amp;f(X_{obs} \\rvert \\theta) &amp;&amp; &amp;&amp;= \\int_{\\mathbb{X}_{mis}} g(X_{obs}, X_{mis} \\rvert \\theta) \\; dX_{mis}, \\; \\; \\; &amp;&amp; \\theta \\in \\Theta \\\\ \\\\ \\pi (\\theta \\lvert X_{obs}) &amp;\\propto \\; &amp;&amp;f (X_{obs} \\lvert \\theta) &amp;&amp; \\pi(\\theta), &amp;&amp; \\; \\; \\; \\; \\; \\; \\; &amp;&amp; \\theta \\in \\Theta \\tag{1}\\\\ \\\\ \\pi (\\theta, X_{mis} \\lvert X_{obs}) &amp;\\propto \\; &amp;&amp;g (X_{obs}, X_{mis} \\lvert \\theta) &amp;&amp; \\pi(\\theta), &amp;&amp; \\; \\; \\; \\; \\; \\; \\; &amp;&amp; \\theta \\in \\Theta \\tag{2}\\\\ \\end{alignat}\\] $ integrate하여 획득한 위의 likelihood \\(f(X_{obs} \\rvert \\theta)\\)에 post를 곱하여 direct하게 업데이트 하는 1번 방법 missing을 하나의 unknown 패러미터로 두고, 이 missing 업데이트 한 다음에 missing까지 포함하여 \\(\\theta\\)를 inference하고, 그 후에 다시 missing을 업데이트 하는 방법. 1번에서는 마지널化한 pdf를 사용했고, 2번에서는 complete의 pdf를 통채로 사용했다. 1번에서는 마지널 시켜서 missing의 영향력을 삭제했다는 것을 발견할 수 있어야 한다. 의 2가지 방법을 취하는 것이 가능하다. let \\(h( X_{mis} \\lvert \\theta, X_{obs})\\)는 \\(X_{mis}, X_{obs}\\)의 conditional 분포. 이때, 이 분포와 $ (X_{obs}, X_{mis}) g (X_{mis}, X_{obs} ) () $ 상기의 분포 2개가 양쪽 모두 샘플링이 간단하다고 가정하자. 이 두 조건부 분포 2개에 기반한 2단계 GS로 이를 해결하고자 하는 것은 당연한 귀결이다. 이를 Data Augmentation 알고리즘 (DA)라 칭한다. 이는 이하와 같이 설명될 수 있다. take \\(\\theta^{(0)} \\in \\Theta\\), and iterate for \\(t=1,2, \\cdots\\). 1. Imputation-step: generate \\(X_{mis}^{(t)} \\sim f_{mis}(X_{mis} \\rvert \\theta^{(t-1)}, X_{obs})\\). (이는 정식적인 likelihood가 아니라 missing variable과 observed variable 간의 관계를 의미하는 것). 해당 스텝에서 missing을 대체. 다른 조건들 (패러미터, obs) 들이 주어졌을 때의 mis의 조건부분포를 구하여 이를 기반으로 mis를 imputation. 2. Parameter update-step: generate \\(\\theta^{(t)} \\sim \\pi (\\theta \\lvert X_{obs}, X_{mis} )\\). 해당 스텝에서 패러미터를 갱신. 위에서 채운 mis와 obs를 합쳐 com 데이터로 삼고 이를 토대로 패러미터 추정한다. As a two-step GS, DA creates two interleaving Markov Chain: $ \\[\\begin{align*} \\{ \\theta(t) &amp;: t=1,2,\\cdots \\} \\\\ \\{ X_{mis}^{(t)} &amp;: t=1,2,\\cdots \\} \\end{align*}\\] $ Example: Multivariate Normal Distribution 4.3.2 2. Hit-and-Run Algorithm for improving the inefficiency of the RW 이를 위해 proposal 분포에 대한 수정이 요구된다. 이는 RW에 추가적인 요소를 넣어 변형하는 것인데, RW의 거리와 방향을 거리에 대응하는 pdf, 방향에 대응하는 pdf를 각각 만들어 거기서 랜덤하게 생산하는 것이다. draw below two parameters, and compute an MH acceptance probability \\(\\alpha(x,y)\\), where \\(x = x^{(t)} = X^{(t)}\\). direction \\(d \\sim g(d) \\; \\; \\;(d \\in \\mathbb{O})\\). distance \\(\\lambda \\sim I(\\lambda \\rvert d,x )\\) over \\(\\mathcal{X}_{x,d}\\). $ X^{(t+1)} = \\[\\begin{cases} x^{(t)}+ \\lambda d, &amp; \\text{if } \\; U \\le \\alpha(x,y) = \\dfrac{f(x&#39;)}{f(x^{(t)})}\\dfrac{g(x&#39; -&gt; x^{(t)})}{g(x^{(t)}-&gt; x&#39; ))}\\\\ x^{(t)}, &amp; o.w.\\\\ \\end{cases}\\] $. 이때, \\(g(d)\\)에 대한 가장 흔한 choice는 \\(\\mathbb{O}\\)에 대한 \\(U\\). 이외에 \\(g(\\cdot \\rvert x, d)\\), \\(\\alpha(x,y)\\)에 대한 가장 흔한 choice도 논해졌던 바가 있다. 이는 특히 sharply constrained 패러미터 space (\\(\\Theta\\)) 와 함께하는 문제에 효과적이다. - Wrapped Normal Distribution 4.3.3 3. Metropolis-Adjusted Langevin Algorithm how do we propose a new value? proposal improvement에 자주 사용된다. 또한, Hamiltonian MC와 아주 밀접한 관련이 있다. Langevin 방정식에 기반하여 생성된 알고리즘. 해당 알고리즘은 기본적으로 \\(f\\)를 정적 (stationary) 분포로서 내버려두게 된다. gradient flow에 의해 발생하면 얘도 로컬트랩 가능성 있는거 아님? $ dX_t = dB_t + f(X_t ) $ 이때 \\(B_t\\)는 표준 브라운 운동. 이의 실적용은 Langevin diffusion process를 RW-like Transition으로 대체한 discretion step을 포함하는 아래의 식으로 이루어진다. $ x^{(t+1)} = x^{(t)} + f(X^{(t)} ) + _t, ; ; ; ; ; ; _t N_d (0, I_d) $ 이때 \\(\\sigma\\)는 step size of discretization. 하지만 discretized 된 프로세스는 transient (일시적, 해당 성질이 이후에도 이어질 것이라 장담 불가) 할 우려가 있으며 \\(f\\)에 대해 더이상 reversible 하지 않음. 이 negative behavior (악영향)을 보정 (correct)하기 위해서 discretization step을 MH acceptance-rejection rule에 기반하여 완화하는 것이 제기됨. 이인즉슨 실적용되는 수식을 conventional MH 제안 (proposal) 분포로서 취급하자는 것. 새로운 state: Langevin Dynamics 사용해서 제안 새로운 state의 accept 여부: MH 알고리즘 사용해서 평가 따라서 Langevin 알고리즘의 1회의 이터레이션은: 1. 새로운 state \\(x^\\ast = x^{(t)} + \\dfrac {\\sigma^2} {2} \\bigtriangledown \\log f(x^{(t)}) + \\sigma \\epsilon_t\\). 이때 \\(\\sigma\\)는 user-specified 패러미터. For limited classes of target distributions, the optimal acceptance rate for this algorithm can be shown to be 0.574. 2. MH ra tio \\(r = \\dfrac {f(x^\\ast)}{f(x^{(t)})} \\ast \\dfrac {\\exp \\left\\{ - \\dfrac {1} {2\\sigma^2} \\left[ x^{(t)} - x^\\ast - \\dfrac {\\sigma^2} {2} \\bigtriangledown \\log f(x^\\ast) \\right]^2 \\right\\}}{\\exp \\left\\{ - \\dfrac {1} {2\\sigma^2} \\left[ x^{\\ast} - x^{(t)} - \\dfrac {\\sigma^2} {2} \\bigtriangledown \\log f(x^{(t)}) \\right]^2 \\right\\}}\\). 3. set \\(x^{(t+1)} = x^\\ast\\) with probability \\(\\min (1, r)\\), 남는 확률로는 \\(x^{(t+1)} = x^{(t)}\\) Advantages gradient flow 방법론에 따라 높은 density region으로 향하도록 RW를 충동질함. RW 대비 mixing이나 convergence 관점에서 효과적. 고차원 분포에서 유리 Disadvantages gradient 계산에 자원 다쳐먹는 경우 있음 multi-mode 관장 불가 이때 with probability \\(\\min (1, r)\\)라는 것은 \\(u &lt; min(1,r), \\; \\; \\; \\; \\; u \\sim U(0,1)\\)과 동치라는 것을 알아두자. 앞으로는 모두 이렇게 서술할 것. 4.3.4 4. Multiple-Try Metropolis Algorithm H&amp;R, MALA, MTMA + HMC는 모두 proposal의 성능을 높이기 위함 MH Transition rule에 기반한 MC에서, 이의 효율성은 제안 (proposal) 분포에 크게 의존한다. 여러번의 이동을 거치면 과거의 실값과는 멀어지기 때문에 independent하기 때문에 어떤 측면에선 효율적이지만 acceptance 측면에선 떨어짐. let \\(\\lambda(x,y)\\) non-negative symmetric function. \\(q(y \\rvert x) &gt;0\\) 이면 항상 \\(\\lambda(x,y)&gt;0\\)임을 가정. define \\(w(x,y)=f(x) \\ast q(y \\rvert x) \\ast \\lambda(x,y)\\). At here, when \\(q(y \\rvert x)\\) is symmetric, for example, one can choose \\(\\lambda(x,y) = \\dfrac {1} {q(y \\rvert x)}\\), and then \\(w(x, y) = f(x)\\). 이 경우, MTM 알고리즘은 orientational bias MC 알고리즘으로 축소되는데, 이는 molecular simulation에서 사용되는 방법론 중 하나다. See Liu, Liang and Wong (2000) for the details. 위의 수식에서 proposal인 \\(q(y \\vert x)\\)에 symmetric이라는 조건을 붙이자. 그러면 \\(q(y \\vert x) = {1}{\\lambda(x,y)}\\)라는 상황을 가정하는 것이 가능하다. Current state is at $x $. Proceeds: draw \\(y_1 , \\cdots, y_k \\sim T(\\pmb x \\rightarrow \\pmb y)\\), \\(T\\) is proposal. select \\(\\pmb y = y_j\\) with probability \\(\\propto w(y_j , \\pmb x)\\). draw \\(x_1^\\ast, \\cdots, x_{k-1}^\\ast\\) from \\(T(y \\rightarrow x)\\). let \\(x_k^\\ast = \\pmb x\\). 이때 ** 3번에서 원본 데이터로 돌아가는 프로세스가 포함된 이유는 MHMCMC 알고리즘에서는 얼마만큼 original proposal로 잘 돌아갈 수 있는지를 항상 고려해주어야 함. for reversability. ** accept proposed \\(\\pmb y\\) with probability \\(p = \\min \\left\\{ 1, \\dfrac{w(y_1, \\pmb x) + \\cdots + w(y_k, \\pmb x)} {w(x_1^\\ast, \\pmb y) + \\cdots + w(x_k^\\ast, \\pmb y)} \\right \\} \\tag{1}\\). (1)의 확률 자체가 결정된 메커니즘은 고급확률론이 필요하므로 이해 불가능함 current state \\(\\pmb x\\)에서, \\(\\pmb x \\rightarrow y_1\\rightarrow y_2 \\rightarrow \\cdots \\rightarrow y_k\\)로 가도록 한다. 이때 각 y에 대해 weight값이 존재. 4.3.5 5. Reversible Jump MCMC Algorithm number of variable이 작을 때, 베이지안 Variable Selection에 자주 사용됨 4.3.5.0.1 Bayesian Variable Dimension Model A Bayesian variable dimension model is defined as a collection of models $ _k = { f(_k ) ; ; ; _k _k }, ; ; ; ; ; k=1, , K $ with a collection of priors \\(\\pi_k (\\theta_k)\\) on the 패러미터 of these models. 이는 곧 model의 변화에 따라 각각의 model들 또한 다른 prior를 갖는다는 이야기이다. and a prior distribution \\(\\rho_k, \\; \\; \\; k=1, \\cdots, K\\) on the indices of these models. ※ Note: 당연히 각각의 model space \\(\\Theta_k\\)들은 may have different dimensions. may라고 했지만 대부분의 경우 다름. In this setting one can compute the posterior probability of models, i.e. $ p ( _k y ) = {_j _j f_j (y _j) _j (_j) d_j } $ RJMCMC 알고리즘이란, 패러미터 space의 dim이 정해지지 않은 상황에서, 이 dim과 상관없이 모델 space 자체를 이동할 수 있게 만들어준 MCMC 알고리즘. 단, 패러미터 space의 dim은 모르지만, 여기서는 모델의 총 갯수인 \\(k\\)로 fix가 되어 있다. 모델 간을 이동시키면서 모델 셀렉션 이와 동시에 패러미터 estimation까지 동시에 한다 는 것이 RJMCMC 알고리즘. 즉 RJMCMC 중에는 2가지 공정이 동시에 돌아간다 A variable dimension model is a “model where one among things you do not know is the number of things you do now know,” 연구자 모르는 것들 중 하나에, 니가 지금 알고 있는 것들의 갯수가 있는 모델. 즉, 내가 지금 알고 있는 것이 총 몇개인지조차도 모른다는 이야기이다. 그럼 대체 아는게 뭐야; e.g., 패러미터 space의 dimension이 고정되어 있지 않음. model selection, checking, improvement, 등등 다양한 상황에서 발생 가능. 모델 \\(\\mathcal{M}_k\\) 사이에서의 움직임을 설계하는데 있어 적절한 framework를 구축하고 싶다. 즉슨 모델에 대한 다양한 예상들이 있고, 이러한 모델의 예상도를 확률적으로 옮겨다니면서 이게 맞나? 이게 맞나? 를 체크한다는 이야기. 이를 위한 Green의 원칙: - 모델 한 쌍 간의 움직임(채택 모델의 변경)만을 고려. - “dimension matching” moves를 설계. - MH 알고리즘과 유사하게 움직임을 with probability로 수용. 여기서의 probability 노테이션은 \\(q\\). let \\(x_t = (k^{(t)}, \\theta_k^{(t)} )\\)가 현 상태를 나타내고, \\(x^{(t+1)}\\)에 대한 proposed state \\(x&#39; = (k&#39;, \\theta_k&#39;)\\). - if \\(k&#39;=k\\), proposed move 가 같은 subspace \\(\\mathcal{X}_k\\)에서 다른 위치를 탐색한다는 것이다. 따라서 dimension-matching problem 자체가 발생하지 않는다. - if \\(k&#39; \\not= k\\), 분포 \\(\\psi_{k^{(t)} \\rightarrow k&#39;} (u)\\)로부터의 \\(s\\)개의 rv \\(\\pmb u = (u_1 , \\cdots, u_s)\\) 를 생산한다. 그리고 bijection \\((\\theta_k &#39; , u&#39; ) = T(\\theta_k^{(t)}, u)\\)를 생각하자. 이때 \\(s&#39;\\) 차원의 rvec\\(u&#39; = (u_1 , \\cdots, u_{s&#39;})\\)이며, \\(s\\)와 \\(s&#39;\\)는 dimension-matching condition \\(s+d_k = s&#39; + d_{k&#39;}\\)를 만족한다. Proceeds: 1. 모델 \\(\\mathcal{M}_k\\) with probability \\(q(k^{(t)}, k&#39;)\\)에 의해 선택. 2. generate \\(u_1 , \\cdots, u_s \\sim \\psi_{k^{(t)} \\rightarrow k&#39;} (u)\\) 3. \\((\\theta_{k&#39;}&#39;, u&#39;) = T(\\theta_k^{(t)}, u)\\). 4. Compute MH ratio \\(r = \\dfrac {f(k&#39;, \\theta&#39;_{k&#39;} \\rvert Y) } {f(k^{(t)}, \\theta^{(t)}_{k} \\rvert Y) } \\dfrac {g(k^{(t)} \\rvert k&#39;)} {g(k&#39; \\rvert k^{(t)})} \\dfrac {\\psi_{k&#39; \\rightarrow k^{(t)}} (u&#39;)} {\\psi_{k^{(t)} \\rightarrow k&#39;} (u)} \\left\\lvert {\\dfrac{\\partial (\\theta&#39;_{k&#39;}, u&#39;)}{\\partial (\\theta^{(t)}_{k}, u)}} \\right\\rvert\\)where $ $ is Jacobian of Transformation. 5. set \\(X^{(t+1)} = (k&#39;, \\theta&#39;_{k})\\) with probability \\(\\min (1,r)\\). 그러나 이렇게 무제한 모델을 만들면 너무 어려움. 따라서 보통 제약식을 추가해서 간단한 모델을 사용함. 사용되는 제약식은 각 이터레이션에서 이전 것과 이후 것 간의 dim 차이가 ±1 이라는 것. Example: Reversible Jump MCMC Algorithm "],["auxiliary-variable-mcmc.html", "4.4 Auxiliary Variable MCMC", " 4.4 Auxiliary Variable MCMC 실전에서 마주치는 대부분의 상황에서 ABC나 HMC 문제를 제외하고는 대부분의 경우 MCMC 문제를 완벽하게 풀어내는 건 불가능. 이때 주어진 variable 말고 보조변수 (Auxiliary Variable)을 추가함으로써 시뮬레이션 품질을 좀 더 높일 수 있지 않을까 하는 것이 논하고자 하는 바. 4.4.1 Introduction Difficulties with MH Algorithm. 일반적인 MH 알고리즘으로 풀어낼 수 없는 2가지 상황이 존재: Local-trap problem: 에너지 계가 울퉁불퉁한 complex system에서 시뮬레이션을 진행했을 때 끝없이 로컬 최적값에서 빠져나오지 못함. 시뮬레이션을 비효율적으로 만듬. density가 높다는 것은 해당 파트의 에너지가 낮다는 것이며, density가 낮은 에너지가 많은 파트에서 high density로 가는 것은 쉽고 자주 일어나도 역은 드뭄. 조밀하면 움직일 여력이 없으니까. 이것이 local trap의 원인 에너지는 이하로 표시 가능: energy function \\(= -log \\pi(\\theta \\vert x)\\), 즉 negative log posterior, 혹은 negative log density. Doubly-intractable normalizing constants problem: Inability to sample from distributions with intractable integrals 보통이라면, \\(pi(\\theta \\vert x) \\propto \\kappa(x) f(x\\vert\\theta)\\pi(\\theta)\\). \\(r= \\dfrac{pi(\\theta &#39; \\vert x)}{pi(\\theta^{(t)} \\vert x)} = \\dfrac{\\kappa(x) f(x\\vert\\theta &#39; )\\pi(\\theta &#39; )}{\\kappa(x) f(x\\vert\\theta^{(t)})\\pi(\\theta^{(t)})}\\) 과정에서 normarlizing constant \\(\\kappa\\)가 알아서 캔슬되어 MH 돌리는데 문제가 없음. let \\(f(x) \\propto \\kappa(x;\\theta) \\psi(x)\\) 는 알고자 하는 분포. 여기서 \\(\\kappa(x)\\)는 unnormalized density의 함수. 이때 \\(\\kappa(x)\\)는 패러미터의 함수이며 각 이터레이션의 다른 패러미터 추정값마다 변화해버려서 캔슬되지 않음. 그러면 계산하면 되는거 아님? 계산 불가능한 상황 존재 - nearly infinite summation or integration 포함하는 경우. (ex:) 이는 곧 intractable integral. acceptance \\(Pr\\)이 알 수 없는 비 \\(\\kappa(x&#39;)/\\kappa(x)\\)를 포함하므로 MH 알고리즘은 사용불가. 이러한 문제는 bayesian 추론에서 spatial statistical models, random effects models, 그리고 exponential random graph models 등 다양한 통계적 모형에서 부딪히게 된다. ex: Lattice system of areal model (Lattice의 승만큼 연산 필요) e.g., Random Effect Model. 이때는 각 individual별로 Random Effect를 integration 해줘야 하므로 문제터짐 ex: Exponential Random Graph model: 네트워크에 사용되는 모델. 얘도 power임. 이러한 상황에서는 대부분의 optimization 알고리즘도 다 먹통됨 이러한 2개의 문제점을 극복하기 위해 다양한 진보된 MCMC 방법론이 제시되었음. Auxiliary variable-based methods Population-based methods Importance weight-based methods Stochastic approximation-based methods 4.4.1.0.1 Auxiliary Variable MCMC Methods \\(f(x)\\)를 가지는 mv 분포에서의 샘플링을 생각해보자. Rao-Blackwellization이 MC 시뮬레이션에의 최우선원칙임은 알려져 있다. 시뮬레이션의 수렴을 좀 더 강화하기 위해 우리는 가능한한 많은 \\(x\\)의 구성물을 integrate하는 것을 시도해보아야 한다. 하지만 이하의 두가지 경우(이외에도 존재)에 시뮬레이션을 양질로 만들기 위해 우리는 1개 이상의 변수를 추가하는 상황을 고려할 수 있다. 1. 타겟분포 \\(f(x)\\)가 multimodal. 온도 혹은 아직 관측되지 않은 측정값과 같은 auxiliary variable이 계가 로컬 트랩에서 빠져나올 수 있도록 도움을 줌. multimodal 상황. 2. 타겟분포 \\(f(x)\\)가 intractable normalizing constant 포함. \\(X\\)의 auxiliary 실현값이 시뮬레이션에 포함됨으로써 시뮬레이션에서 normalizing constant 를 무력화시킴. MH 알고리즘 $ $은 이하의 2가지 기본적인 부품을 가지고 있다. 1. 타겟분포 (左) 2. proposal 분포 (右) 이에 더해서 auxiliary variable 방법론은 이하의 2가지 방법으로 행해질 수 있다. 타겟과 제안 어느쪽에 변수를 추가하는지에 대한 이야기이다. 1. 타겟분포 augmentation 방법론: Augmenting auxiliary variables to the target distribution * auxiliary variable \\(u\\)와 조건부 분포 \\(f(u \\rvert x )\\)를 정의한다. joint 분포 \\(f(x,u) = f(u \\rvert x) f(x)\\)를 만들기 위해. 이후 MH 알고리즘이나 GS를 사용해 \\((x,u)\\)를 업데이트. \\(f(x)\\)의 샘플은 \\((X, U)\\)의 실현값 \\((x_1, u_1), \\cdots, (x_N, u_N)\\)를 이용해 marginalization이나 프로젝션 등을 이용해 획득될 수 있다. 2. Method of Proposal Distribution Augmentation: Augmenting auxiliary variables to the proposal distribution. * proposal 분포 \\(T(x&#39;, u \\rvert x)\\)를 특정하고, 이의 reversible version \\(T(x, u \\rvert x&#39;)\\)도 특정한다. 즉슨 \\(\\int T(x&#39;, u \\vert x)du = T(x&#39; \\vert x)\\), \\(\\int T(x, u \\vert x&#39;)du = T(x \\vert x&#39;)\\)의 관계가 성립한다. 이제 proposal \\(T(x&#39;, u \\vert x)\\) 로부터 후보 (candidate) 샘플 \\(x&#39;\\)를 생산하고, 이를 with probability \\(\\min \\left\\{ 1, r(x, x&#39;, u) \\right \\}\\). 이때 \\(r(x, x&#39;, u) = \\dfrac {f(x&#39;)} {f(x)} \\dfrac {T(x,u \\vert x&#39;)} {T(x&#39;,u \\vert x)}\\). 실현값 (realizations) \\(x_1 , \\cdots, x_N\\)을 생산할 때까지 이를 반복한다. 이제 \\(N\\)이 충분히 크다면, 이 실현값들은 근사적으로 \\(f(x)\\)에 의해 분포되어 있다. 이러한 방법론의 타당성은 이하를 통해 보일 수 있다. $ K(x’ x) = _{} s(x, x’, u) du + (x=x’) $ 이는 \\(x\\)로부터 \\(x&#39;\\)로의 integrated transition kernel을 의미하며, 이때 \\(s(x, x&#39;, u) = T(x&#39;, u \\rvert x) \\ast r(x, x&#39;, u)\\). Then, $ f(x) {} s(x, x’, u) du = {} du $ 이는 \\(x\\)와 \\(x&#39;\\) 에 대해 symmetric. 이는 곧 \\(f(x)K(x&#39; \\vert x) = f(x&#39;)K(x \\vert x&#39;)\\) 임을 의미한다. original density 4.4.2 Multimodal Target Distribution 4.4.2.0.1 Simulated Tempering 분포 \\(f(x) \\propto \\exp \\left(-H(x) \\right), x \\in X\\) 에서 샘플링하는데에 관심이 있다고 하자. simulated annealing에서 그러했던 것처럼, simulated tempering \\(f(x, T) \\propto \\exp \\left( -\\dfrac {H(x)} {T} \\right)\\)로 타겟 분포를 확장시켰다. 이는 auxiliary variable인 temperture \\(T\\)를 포함함으로서 이루어진다. \\(T\\)는 사용자가 미리 지정한 값들의 finite set이 된다. \\(H(x)\\)는 사실상 energy function. Temperatur Transition Matrix \\(T = \\begin{bmatrix} q_{11} &amp; q_{12} &amp; \\cdots &amp; q_{1n} \\\\ q_{21} &amp; \\ddots &amp; &amp; \\\\ \\vdots &amp; &amp; \\ddots &amp; \\\\ q_{n1} &amp; \\cdots &amp; &amp; q_{nn} \\end{bmatrix}\\). 이때 row는 current 온도 \\(T_1, \\cdots, T_n\\), column은 행선지 온도. Parallel Tempering은 인접한 온도로만 이동 가능 (가장 높은 온도에서 가장 낮은 온도로 한단계 한단계씩). 온도 자체를 시뮬레이션한게 아니라 온도의 chain이 주어져 있어 각 온도 간의 움직임을 만드는 것에 그친다. 따라서 이는 multiple chain을 이용하는 population MC 방법론 쪽에 소속됨. Simulated Tempering과는 이 점에서 차이를 보임. 후자는 어느 온도로든 다 이동. 온도 매트릭스 만들어놓고, \\(U(0,1)\\) 분포에서 온도 하나 생산하고 이 온도로 이동할 것인지의 여부를 MH 알고리즘으로 결정. \\(U(0,1)\\)에서 랜덤하게 숫자를 뽑고, \\(j\\)의 값을 proposal transition matrix \\((q_{ij})\\)에 따라서 정한다. \\(u&lt;q_{11}\\)이면 \\(T_1 \\rightarrow T_1\\), \\(q_{11}&lt;u&lt;q_{11} + q_{12}\\)이면 \\(T_1 \\rightarrow T_2\\), …. - if \\(j=i_t\\), let \\(i_{t+1}=i_t\\), and let \\(x_{t+1}\\)을 MH kernal \\(K_{i_t}(x,y)\\)에서 뽑는다. 이때 \\(K_{i_t}(x,y)\\)는 \\(f(x, T_{i_t})\\)을 invariant distribution로 허용하는 아이이다. 즉 새로운 \\(x\\)를 생산하면 된다. - if \\(j \\not= i_t\\), let \\(x_{t+1}=x_t\\)하고 proposal을 이하의 \\(Pr\\)에 따라 채택한다. 이때 \\(Z\\)는 \\(Z_i\\)의 측정값이다. 채택된다면 \\(i_{t+1} = j\\)이고, 그외의 경우에는 \\(i_{t+1} = i_t\\)로 한다. 새로운 \\(x\\)를 생산하는 것이 아니라 들고 있던 \\(x\\)를 쓰되, 이걸 accept 할건지 안할건지를 체크한다. $ $ 이때 $ {q_{i_t , j}} $는 proposal distribution이라고 생각할 수 있다. 나머지는 Likelihood part이며, 이때 \\(\\dfrac {\\hat Z_j} {\\hat Z_{i_t}}\\)가 normalizing constant의 ratio이다. 온도가 변화하였으므로 두 식의 normalizing constant가 같지 않기 때문이다. ** ~~Issues on Simulated Tempering: ~~ ** Temperature Ladder를 어떻게 고를 것인가. -&gt; 각 chain별로 이동이 원활하게 잡는 것이 핵심. 가장 높은 온도 \\(T_1\\)은 대부분의 uphill move가 해당 레벨에서 accept 될 수 있도록 설정되어야 한다. 사이의(intermediate) 온도들은 sequential manner로 설정될 수 있다. \\(T_1\\)에서 시작해서, 점차적으로 다음으로 낮은 온도를 \\(Var_i \\left\\{ H(x) \\right\\} \\ast \\delta^2 = O(1)\\)을 만족하도록 설정하는 것이다. 이때 \\(\\delta = \\dfrac {1}{T_{i+1}} - \\dfrac{1}{T_i}\\)이며, \\(Var_i(\\cdot)\\)은 \\(H(x)\\) (taken with respect to \\(f(x, T_i)\\)) 의 분산을 의미한다. 이러한 조건들은 \\(f(x,T_i), f(x,T_{i+1})\\) 사이에 상당히 겹치는 점이 많아야 한다는 것을 의미하기도 한다. 실전에선 \\(Var_i \\left( H(x) \\right)\\)는 샘플러를 레벨 \\(T_i\\)에서 예비적으로(preliminary) 돌려보았던 결과에서 러프하게나마 예측될 수 있다. \\(Z_i\\)를 어떻게 estimate 할 것인가. -&gt; accept 여부가 normalizing constant에도 의존해서 이거 이상하게 고르면 효율 떨어짐. 엄청난 단점이라서 요즘은 이 알고리즘 자체를 잘 안씀 이는 simulated tempering의 효율에 직결되는 부분이다. \\(Z_i\\)들이 잘 estimate 되었다면, simulated tempering은 temperature ladder을 따라 symmetric RW처럼 동작한다. (\\(x\\)-updating step을 제하고 볼 경우) 그렇지 않다면 이는 특정 temperature 레벨에서 멈춰버린다. 시뮬레이션이 실패함은 물론이다(rendering). 실전에서 \\(Z_i\\)들은 stochastic approximation MC 방법론을 사용해서 estimate 가능하다. 혹은 reverse logistic regression 방법론을 사용해서도 \\(Z_i\\)를 estimate 할 수 있다. 4.4.2.0.2 Slice Sampler density \\(f(x), \\; \\; \\; x \\in \\chi\\)에서 샘플링하고자 한다. $ x f(x)$에서 샘플링하는 것은, \\(f(x)\\) 그래프 이하의 영역에서 uniform하게 샘플링하는 것과 동등하다. 해당 영역은 \\(A = \\{ (x,u): 0 \\le u \\le f(x) \\}\\)이며, 이것이 acceptance-rejection 알고리즘의 기초(basis)였다. 이 목적을 달성하기 위해 우리는 타겟분포 \\(f\\)를 auxiliary variable \\(U\\)를 사용하여 확장해볼 수 있다. 이 \\(U\\)는, \\(x\\)에 대해서 조건부일 때, 구간 \\([0, f(x)]\\)에서 uniform하게 분포되어 있다. 따라서, \\((X, U)\\)의 joint density function은 \\(f(x,u)=f(x)f(u \\rvert x) \\propto I_{(x,u)\\in \\textit A}\\). 후자의 인디케이터는 언급되었던 영역 안에 속한다는 의미. 이는 GS에 의해 이하와 같이 샘플링 가능하다. 1. draw \\(u_{t+1} \\sim U[0, f(x_t)]\\). 2. draw \\(x_{t+1}\\) uniformly from the region \\(\\{ x: f(x) \\ge u_{t+1} \\}\\). 위의 샘플러는 slice sampler라고 불림. 이는 multimodal 분포들에 대해 단순 MH 알고리즘보다 더 나을 가능성이 있음. slice 때문에 b/w-mode-transition에 자유롭기 때문. 현재도 핫한 샘플러중 하나임. horseshoe prior 에서의 패러미터 estimate에 대표적으로 이녀석이 쓰인다. 4.4.3 Doubly-intractable Normalizing Constants Spatial models, e.g., the autologistic model, the Potts model, and the autonormal model (Besag, 1974)는 많은 과학적 문제들을 위한 모델링에 쓰이고 있음. 이러한 모델들에 해당하는 주요한 문제는 normalizing constant가 doubly-intractable하다는데 있음. for dataset \\(X\\), 패러미터 \\(\\theta\\), normalizing constant \\(\\kappa (\\theta)\\). 이때 \\(\\kappa (\\theta)\\)는 \\(\\theta\\)에 의존하나 closed form으로는 만들 수 없음. 이하는 dataset을 생산한 likelihood function. $ \\[\\begin{align*} X \\sim f(x \\vert \\theta) = \\dfrac{1}{\\kappa (\\theta)} exp \\{ -U(x, \\theta) \\}, &amp;x \\in \\mathcal{X}, &amp;\\theta \\in \\Theta \\end{align*}\\] $ \\(\\pi(\\theta)\\)는 \\(\\theta\\)의 prior. 이 경우 post는 \\(f(\\theta \\vert x) \\propto \\dfrac{1}{\\kappa (\\theta)} exp \\{ -U(x, \\theta) \\} \\ast \\pi(\\theta)\\). 4.4.3.0.1 Boltzmann Density known as Ising Model, 그리고 ~로 확장될 경우 autologistic model. Consider a 2-D Ising model with the Boltzmann density $ f(x) { K _{ij} x_i x_j } $ spins \\(x_i = \\pm 1\\) (S극이 -1) \\(K\\)는 inverse temperature (measure for interaction : \\(x_i\\)가 주변에 있는 값과 얼마나 많은 같은 값을 가지는지, 다른 값을 가지는지에 대해 측정해주는 패러미터) 온도가 낮을수록 interaction가 강해지며, 이에 의해 동일값 확률이 높아짐. \\(i\\sim j\\)는 lattice 상의 가장 가까운 neighbors. 온도가 높다면, 이 모델은 GS를 사용해 쉽게 시뮬레이션 가능하다. 조건부 분포에 따라 각 spin의 값을 iteratively 초기화한다. 아래의 식에서 \\(n(i)\\)는 spin \\(i\\)의 neighbors의 집합 (set). 이하의 수식은 autologistic 과 그 과정이 유사하다. $ \\[\\begin{align*} P(x_i =1 \\vert x_j, \\; \\; j \\in n(i)) &amp;= \\dfrac {1}{1+ \\exp \\left \\{ -2K \\sum_{j \\in n(i)} \\right\\}} \\\\ P(x_i =-1 \\vert x_j, \\; \\; j \\in n(i)) &amp;= \\dfrac {\\exp \\left \\{ -2K \\sum_{j \\in n(i)} \\right\\}}{1+ \\exp \\left \\{ -2K \\sum_{j \\in n(i)} \\right\\}} &amp;= 1- P(x_i =1 \\vert x_j, \\; \\; j \\in n(i)) \\end{align*}\\] $ 하지만, GS는 temperature가 critical temperature로 근접하거나 이하로 내려갈 경우 GS가 빠르게 느려진다. 온도가 낮으면 interaction이 강해져, 주변값과 비슷한 값을 generate 해야만 하기 때문이다. 이렇게 샘플링이 어려워지는 지점, 온도를 critical point라고 부른다. 이는 대략 \\(\\theta \\approx 0.43\\). 이것이 소위 critical slowing down 이라고 불리는 현상이다. 4.4.3.0.1.1 Perfect Sampler 과거 샘플들의 굉장히 많은 조합을 커플링해서 샘플을 생산. previous realization 전체에 대해 (이는 그 이전의 샘플, 아니면 그 이전의 샘플, 혹은 original 데이터에 대해서조차도) independent한 샘플을 생산해내는 sampler. 즉 그 어떤 것에서도 independent한 sample을 생산해낸다. 문제는 이 샘플러는 \\(\\theta&gt;0.43\\)인 순간 바로 작동을 안함. \\(\\theta&gt;0.32, 0.35\\) 정도로 엔간 크기만 해도 드럽게 느림. 4.4.3.0.1.2 Swendsen-Wang Algorithm slice sampling에서 Boltzmann 덴시티는 이하의 형으로 다시 쓰여진다. 이때 \\(\\beta = 2K\\). indicator function으로 변형했을 때 저 둘이 어떻게 equation이 성립하는지 유의. $ f(x) ; ; _{ij} { K(1+x_i x_j) } ; = ; _{ij} { (x_i = x_j) } $ 이때 우리가 auxiliary variable \\(\\pmb u = (u_{i \\sim j})\\), where each component \\(u_{i \\sim j}\\), conditional on \\(x_i\\) and \\(x_j\\), is uniformly distributed on \\(\\left[ 0, \\; \\exp \\{\\beta \\ast \\mathbf{1}(x_i = x_j)\\} \\right]\\), then $ f(x, u) ; ; {i j} ( 0 u{i j } { (x_i = x_j) } ) $ 이때 \\(u_{i \\sim j}\\) 자체는 bond variable이라고 명명된다. 이는 spin \\(i\\)와 spin \\(j\\) 사이의 가장자리에 물리적으로 앉아 있는 변수로서 생각될 수 있다. (i와 j가 묶여져 있는지, 같은 group 안에 존재하는 것인지 아닌지에 대한 indicator가 되는 variable) * if \\(u_{i \\sim j}&gt;1\\), then \\(\\exp \\left\\{ \\beta \\ast \\mathbf{1}(x_i = x_j) \\right \\}&gt;1\\), 따라서 반드시 \\(x_i = x_j\\). * if \\(u_{i \\sim j}&lt;1\\), 이 경우 \\(x_i, x_j\\)에 제약 (constraint) 이 없다. \\(b_{i \\sim j}\\)가 제약에 대한 indicator variable이라고 정의하자. 즉, \\(x_i, x_j\\)가 같도록 제약되었다면, \\(b_{i \\sim j}=1\\)이며 이외엔 0이다. for any 2개의 “like-spin” (i.e. 2개의 spin이 같은 값을 가진다) neighbors에 대해서, 이 둘은 with probability \\(1-\\exp (-\\beta)\\)를 따라 bonded 될 수 있는 가능성이 있음을 기억하라. \\(\\pmb u\\)의 설정 (configuration)에 따라, “mutual bond” (i.e., \\(b_{i \\sim j}=1\\)) 을 통하여 연결될 수 있는지 없는지 여부에 따라 spin들을 군집 (cluster) 할 수 있다. (위에서 i와 j가 같다고 indicator가 판별했을 경우에만 이런 cluster 로 묶는 것이 가능하다) Then 동일 클러스터 내의 모든 spin은 같은 값을 가질 것이다. 또한 군집 내부의 모든 spin을 동시에 뒤집는 (flip) 것은 \\(f(\\pmb x , \\pmb u)\\)의 평형 (equilibrium)을 해치지 않을 것이다. Proceeds: 1. Update the bond values: check all “like-spin” neighbors, and set \\(b_{i \\sim j}=1\\) with probability \\(1-\\exp (-\\beta)\\). 2. Update the spin values: Cluster spins by connecting neighboring sites with a mutual bond, and then flip each cluster with probability \\(0.5\\). For the Ising model, the introduction of the auxiliary variable \\(\\pmb u\\) has the dependence between neighboring spins partially decoupled, and the resulting sampler can thus converge substantially faster than the single site updating algorithm. As demonstrated by Swendsen and Wang (1987), this algorithm can eliminate much of the critical slowing down. 같은 값들이 모여있는 cluster를 판별하여 각각을 grouping. grouping을 랜덤으로 하므로 인접해 있는 동일값임에도 그룹에 포함되지 못하는 경우가 존재함. Swendsen-Wang에서는 이렇게 그룹을 만든 후, 해당 그룹을 통채로 toggling. group을 통채로 토글링하기 때문에 dependency가 있는 것들이 통채로 toggling되어서 dependency가 있는 것들은 나머지 것들과 인제 이렇게 independent한 것도 있지만 dependent한 것을 통채로 묶어서 하는 것이므로 좀더 한꺼번에 뒤집으니까 실제로 우리가 업데이트하는 것은 group 내부 말고 group 외부 간들에는 independent하다고 가정될 수 있는 몇몇개의 group들만이 남음. 이 덩어리들을 한꺼번에 업데이트하므로 따라서 샘플러 generate가 상대적으로 쉬움. 하지만 이 만든 덩어리는 매 이터레이션마다 덩어리를 새로 만들어야 함. 매 이터레이션마다 클러스터를 새로 만들고 flip하여 이를 accept할지 말지를 결정하는 이런 형태의 구조를 가짐. 4.4.3.0.2 Møoller’s Algorithm auxiliary variable \\(y\\), 이는 \\(x\\)와 같은 state space를 공유한다고 정의. 그 경우 이하의 joint pdf \\(f\\) 를 생각해볼 수 있다. \\(f(y \\vert \\theta , x)\\)는 \\(y\\)의 분포. $ f(, y x) = f(x ) f() f(y , x) $ $ f(, y x) $ 에서 MH 알고리즘을 통해 시뮬레이트하기 위해서는 이하와 같은 제안분포 \\(q\\) 를 사용해볼 수 있다. 이는 패러미터 벡터 \\(\\theta \\rightarrow \\theta&#39;\\)의 usual change에 상응하며, 이 후에는 \\(q(\\cdot \\vert \\theta &#39; )\\)에서 \\(y&#39;\\)를 추출하는 exact sampling step이 따른다. $ q(’ , y’ , y) = q(‘, y) q(y’ ’) $ \\(q(y&#39; \\vert \\theta &#39; )\\)가 \\(f(y&#39; \\vert \\theta)\\)로 설정되었다면, MH ratio \\(r\\)은 이하와 같이 쓰일 수 있다. 이때 unknown normalizing constant \\(\\kappa(\\theta)\\)가 상쇄 (cancel) 되었음에 주목하라. $ \\[\\begin{align*} r(\\theta, y, \\theta&#39;, y&#39; \\vert x) &amp;= \\dfrac {f(x \\vert \\theta&#39;) f(\\theta&#39;) f(y&#39; \\vert \\theta&#39; , x) \\ast q(\\theta\\vert \\theta&#39; , y&#39;) q(y \\vert \\theta)} {f(x \\vert \\theta) f(\\theta) f(y \\vert \\theta , x) \\ast q(\\theta&#39;\\vert \\theta , y) q(y&#39; \\vert \\theta&#39;)} \\\\ &amp;= \\dfrac {f(\\theta&#39;, y&#39; \\vert x)}{f(\\theta, y \\vert x)} \\ast \\dfrac {q(\\theta , y \\vert \\theta&#39; , y&#39;))}{q(\\theta&#39; , y&#39; \\vert \\theta , y)} \\\\ &amp;= \\dfrac { \\dfrac {f(\\theta&#39;, y&#39; \\vert x)}{q(\\theta&#39; , y&#39; \\vert \\theta , y)} } { \\dfrac{f(\\theta, y \\vert x) }{q(\\theta , y \\vert \\theta&#39; , y&#39;))} } \\end{align*}\\] $ 여기서 계산을 간단하게 하기 위해 제안분포 \\(q\\)와 auxiliary distribution을 이하와 같이 정리하는 것을 생각해볼 수 있다. 이때 \\(\\hat \\theta\\)는 \\(\\theta\\)의 estimate로써, 예를 들어 pseudo-likelihood function을 극대화하는 것으로 얻어진 값이다. $ \\[\\begin{align*} q(\\theta&#39; \\vert \\theta , y) &amp;= q(\\theta&#39; \\vert \\theta ) , q(\\theta \\vert \\theta &#39;, y&#39;) &amp;= q(\\theta \\vert \\theta &#39;) \\\\ f(y \\vert \\theta , x) &amp;= f(y \\vert \\hat \\theta ), f(y&#39; \\vert \\theta&#39; , x) &amp;= f(y&#39; \\vert \\hat \\theta ) \\end{align*}\\] $ 분포 \\(f(x \\vert \\theta)\\)를 auxiliary variable, 가령 normalizing constant ratio \\(\\dfrac {\\kappa(\\theta)} {\\kappa(\\theta&#39;)}\\) 등으로 살찌워놓은 것은, 시뮬레이션 진행 과정에서 상쇄시키는 것이 가능하다. 1. generate \\(\\theta \\sim q(\\theta&#39; \\vert \\theta_t)\\) 2. generate exact sample \\(y&#39; \\sim f(y \\vert \\theta&#39;)\\) 3. accept \\((\\theta&#39;, y&#39;)\\) with probability \\(\\min (1, r)\\), \\(r=\\dfrac {f(x \\vert \\theta&#39;) f(\\theta&#39;) f(y&#39; \\vert \\hat \\theta&#39;) \\ast q(\\theta_t \\vert \\theta&#39;) q(y \\vert \\theta_t)} {f(x \\vert \\theta_t) f(\\theta_t) f(y \\vert \\hat \\theta) \\ast q(\\theta&#39;\\vert \\theta_t) q(y&#39; \\vert \\theta&#39;)}\\). * 채택된다면, set \\((\\theta_{t+1}, y_{t+1}) = (\\theta&#39;, y&#39; )\\). * o.w., \\((\\theta_{t+1}, y_{t+1}) = (\\theta_t, y&#39;_t)\\). 4.4.3.0.3 Exchange Algorithm Møller’s 알고리즘을 parallel tempering 개념을 도입하여 개선. 1. propose candidate point $’ $ proposal distribution \\(q(\\theta&#39; \\vert \\theta, x)\\). 2. propose auxiliary variable \\(y \\sim\\) perfect sampler \\(f(y \\vert \\theta &#39; )\\). 3. accept $’ $ with probability \\(\\min \\{ 1, r(\\theta, \\theta&#39; \\vert x) \\}\\). - \\(r(\\theta, \\theta&#39; \\vert x) = \\dfrac{\\pi(\\theta&#39;) }{\\pi(\\theta) } \\ast \\dfrac{f(x \\vert \\theta &#39;) }{f(x \\vert \\theta)} \\ast \\dfrac{f(y \\vert \\theta) }{f(y \\vert \\theta&#39;)} \\ast \\dfrac{f(\\theta \\; \\vert \\theta&#39;, x) }{f(\\theta&#39; \\vert \\theta, x)}\\) The exchange algorithm can be viewed as an auxiliary variable MCMC algorithm with the proposal distribution being augmented, for which the proposal distribution can be written as $ \\[\\begin{align} T \\left( \\theta \\rightarrow (\\theta&#39; , y) \\right) &amp;= q(\\theta &#39; \\vert \\theta) f(y \\vert \\theta &#39;) \\\\ T \\left( \\theta&#39; \\rightarrow (\\theta , y) \\right) &amp;= q(\\theta \\vert \\theta &#39; ) f(y \\vert \\theta) \\end{align}\\] $ This simply validates the algorithm, following the arguments for auxiliary variable Markov chains. The exchange algorithm generally improves the performance of the Møller algorithm, as it avoids an initial estimation step (for \\(\\theta\\)) that required by the Møller. Although the Møller’s and exchange algorithms work well for some discrete models, such as the Ising and autologistic models, they cannot be applied to many other models for which perfect sampling is not available. Even for the Ising and autologistic models, perfect sampling may be very expensive when the temperature is near or below the critical point. 4.4.3.0.4 Adaptive Exchange Algorithm Object An adaptive exchange algorithm (AEX) is an adaptive Monte Carlo version of the exchange algorithm, where the auxiliary variables are generated via an importance sampling procedure from a Markov chain running in parallel. Advantage Removes the requirement of perfect sampling Overcomes its theoretical difficulty caused by inconvergence of finite MCMC runs AEX consists of two chains running in parallel. The first chain is auxiliary, which is run in the space \\({\\mathcal{x}}\\) with an aim to draw samples from a family of distributions \\(f(X \\vert \\theta^{(1)}), \\; \\; \\cdots, \\; \\; f(X \\vert \\theta^{(m)})\\) for a set of pre-specified parameter values \\(\\theta^{(1)}, \\; \\cdots, \\; \\theta^{(m)}\\). The second chain is the target chain, which is run in the space \\(\\theta\\) with an aim to draw samples from the target posterior \\(\\pi(\\theta \\vert y)\\). For a candidate point \\(\\theta&#39;\\), the auxiliary variable \\(x\\) is resampled from the past samples of the auxiliary chain via an importance sampling procedure. Assume that the neighboring distributions \\(f(X \\vert \\theta^{(i)})\\)’s have a reasonable overlap and the set \\(\\left \\{ \\theta^{(1)}, \\; \\cdots, \\; \\theta^{(m)} \\right \\}\\) has covered the major part of the support of \\(\\pi (\\theta \\vert y)\\). ALGORITHM: PART 1 - (Auxiliary Chain) Auxiliary Sample Collection via SAMC (Sampling) Choose to update \\(\\vartheta\\) or \\(\\pmb z_t \\vert \\vartheta\\) with pre-specified probabilities, e.g., \\(0.75\\) for updating \\(\\vartheta\\) and \\(0.25\\) for updating \\(z_t\\). 1-a. Update \\(\\vartheta_{t}\\) : Draw \\(\\vartheta &#39;\\) from the set \\(\\left \\{ \\theta^{(1)}, \\; \\cdots, \\; \\theta^{(m)} \\right \\}\\) according to a proposal distribution \\(T_1 ( \\; \\cdot \\; \\vert \\vartheta_{t})\\), set \\((\\vartheta_{t+1}, \\pmb z_{t+1}) = (\\vartheta &#39; , \\pmb z_{t+1} )\\) with probability \\(\\min \\left\\{ 1, \\; \\; \\dfrac{\\omega_t^{J(\\vartheta_t)}}{\\omega_t^{J(\\vartheta &#39;)}} \\ast \\dfrac {\\varphi (\\pmb z_{t} \\vert \\vartheta &#39;)} {\\varphi (\\pmb z_{t} \\vert \\vartheta_{t})} \\ast \\dfrac{T_1 (\\vartheta_{t} \\vert \\vartheta &#39; )}{T_1 (\\vartheta &#39; \\vert \\vartheta_{t} )} \\right\\}\\), and set \\((\\vartheta_{t+1}, \\pmb z_{t+1}) = (\\vartheta_{t}, \\pmb z_t)\\) with remaining probability, where \\(J(\\vartheta_t)\\) denotes the index of \\(\\vartheta_t\\), i.e., \\(J(\\vartheta_t) = j\\) if \\(\\vartheta_t = \\theta_i^{(k)}\\) and \\(\\varphi(\\pmb z \\vert \\vartheta)\\) is an unnormalized density of \\(f(\\pmb z \\vert \\vartheta)\\). 1-b. Update \\(\\pmb z_t\\) : Draw \\(\\pmb z &#39;\\) according to a proposal distribution \\(T_2 ( \\; \\cdot \\; \\vert \\pmb z_t)\\), set \\((\\pmb z_{t+1} , \\vartheta_{t+1}) = (\\pmb z &#39; , \\vartheta_{t})\\) with probability \\(\\min \\left\\{ 1, \\; \\; \\dfrac {\\varphi (\\pmb z &#39; \\vert \\vartheta_{t})} {\\varphi (\\pmb z_{t} \\vert \\vartheta_{t})} \\ast \\dfrac{T_2 (\\pmb z_{t} \\vert \\pmb z &#39; )}{T_2 (\\pmb z &#39; \\vert \\pmb z_{t} )} \\right\\}\\), and set \\((\\pmb z_{t+1} , \\vartheta_{t+1}) = (\\pmb z_t , \\vartheta_{t})\\) (Abundance Factor Updating) Set $ ({t+0.5}^{(j)}) =({t}^{(j)}) + a_{t+1} (e_{t+1, ; j} - p_j), ; ; ; ; ; j=1, , m $ where \\(e_{t+1, \\; j} = \\begin{cases} 1 &amp; &amp;&amp; \\vartheta^{t+1} = \\theta^{(j)} \\\\ 0 &amp; &amp;&amp; o.w. \\end{cases}\\). If \\(\\omega_{t+0.5}^{(j)} \\in \\mathcal{K}_{\\varsigma_t}\\), set \\((\\omega_{t+1}, \\pmb z_{t+1}) = (\\omega_{t+0.5}, \\pmb z_{t+1})\\) and \\(\\varsigma_{t+1} = \\varsigma_t\\). o.w., set \\((\\omega_{t+1}, \\pmb z_{t+1}) = \\mathbb{T}(\\omega_{t}, \\pmb z_{t})\\) and \\(\\varsigma_{t+1} = \\varsigma_t + 1\\). (Auxiliary Sample Collection) Append the sample \\(\\left(\\pmb z_{t+1} , \\vartheta_{t+1}, \\omega_{t+1}^{J(\\vartheta_{t+1}} \\right)\\) to the collection \\(S_t\\). Denote the new collection by \\(S_{t+1}\\) which is set by \\(S_{t+1} = S_t \\cup \\left\\{ \\left(\\pmb z_{t+1} , \\vartheta_{t+1}, \\omega_{t+1}^{J(\\vartheta_{t+1}} \\right) \\right\\}\\). ALGORITHM: PART 2 - (Target Chain) Adaptive Exchange Sampler (Proposal) Propose a candidate point \\(\\theta &#39;\\) from a proposal distribution \\(q(\\theta &#39; \\vert \\theta)\\) (Resampling for Auxiliary Variables) Resample an auxiliary variable \\(\\pmb x\\) from the collection \\(S_{t+1}\\) via a dynamic importance sampling procedure; that is, setting \\(\\pmb x = \\pmb z_k\\) with probability $ P(x = z_k) {{j=1}^{S{t+1} } _t^{( J(j) )} {(z_k j ’ )} I(z_j = z_k )} {{j=1}^{S{t+1} } _t^{( J(_j) )} {(z_k _j ’ )}} $ \\(\\left(\\pmb z_{j} , \\vartheta_{j}, \\omega_{t}^{J(\\vartheta_{j}} \\right)\\) denotes the \\(j\\)-th element of the set \\(S_{t+1}\\). \\(\\vert S_{t+1} \\vert\\)는 \\(S_{t+1}\\)의 size. (Exchange Algorithm) Set \\(\\theta_{t+1} = \\theta &#39;\\) with the probability \\(\\alpha(\\theta_t , \\pmb x, \\theta&#39; )\\), and \\(\\theta_{t+1} = \\theta_{t}\\) with probability \\(1-\\alpha(\\theta_t , \\pmb x, \\theta&#39; )\\). $ (_t , x, ’ ) = {(_t )} {(y _t )} {q(’ _t )} {(x ’ )} $ Why this algorithm is adaptive? Since the underlying true proposal distribution for generating auxiliary variables in part II is changing from iteration to iteration, the new algorithm falls into the class of adaptive MCMC algorithms (for which the proposal distribution is changing from iteration to iteration). "],["approximate-bayesian-computation.html", "4.5 Approximate Bayesian Computation", " 4.5 Approximate Bayesian Computation Likelihood를 사용하지 않고 Summary Stat을 사용함. 이와 같은 성질로 인해 Likelihood-free inference라고도 불리며, 이의 근거는 simulator-based model (모델 자체를 data generation process라고 보는 것. 모델을 통해 data를 생산해내는 것이 가능하다는 소리). 모델이 있으면, 이 모델과 대응하는 패러미터가 존재할 것. 이 모델 자체를 하나의 data generating process라고 본다면, 당연히 우리는 Auxiliary Data를 생산하는 것 또한 가능. 이 AD를 생산하는 것이 가능하기 때문에, 이렇게 생산한 AD 데이터가 기존 데이터 (original data) 와 얼마만큼 가까운지, 아니면 얼마만큼 떨어져 있는지를 체크하는 것이 ABC 방법론. 이것이 충분히 가깝다면 우리가 가지고 있는 패러미터를 패러미터의 샘플로 인정하는 것이 가능하다는 것. 이때 직접 AD와 OD를 비교하는 것인 대단히 어려우므로 대체재로 Summary Stat을 사용함. 이것이 ABC 방법론의 핵심. 이는 genetics에서 개발됨. 4.5.1 Simulator-Based Models deterministic model은 뭐임? 모든 모델이 pdf \\(p(y \\vert \\theta)\\)의 family로 특정되는 것은 아님. Simulator-based Models: Models which are specified via a mechanism (rule) for generating data. Models specified via a data generating mechanism occur in multiple and diverse scientific fields. Different communities use different names for simulator-based models: Generative Models: 데이터를 생성해주는 메커니즘을 연구하는 모델 Implicit Models Stochastic Simulation Models Probabilistic Programs Examples Astrophysics: Simulating the formation of galaxies, stars, or planets. Evolutionary Biology: Simulating Evolution Neuroscience: Simulating Neural Circuits Ecology: Simulating Species Migration Health Science: Simulating the spread of an infectious disease Advantages of Simulator-Based Models Direct implementation of hypotheses of how the observed data were generated. obs가 어떻게 생산되었는지에 대한 가설을 입증할 수 있는 하나의 방법이 됨. Neat interface with physical or biological models of data. 갖고 있는 데이터는 한둘에서 끝나고 이의 variation을 고려하는 것이 중요한데 이 variation을 연구하는건 데이터 한둘로는 어려움. 이때 가지고 있는 데이터를 replicate하고 simulator-based model을 이용해 비슷한 데이터를 만들어내서 variation을 연구해 좀더 정확한 inference를 가능케 하고, 그러면서 uncertainty quantification도 가능하게 함. Modeling by replicating the mechanisms of nature which produced the observed/measured data. (“Analysis by synthesis”) Possibility to perform experiments. Disadvantages of Simulator-Based Models Generally elude analytical treatment. analytic한 solution이 없어 수학적 증명이 어려움. Approximate BC인 이유가 여기 있음 Can be easily made more complicated than necessary. Statistical inference is difficult but possible. Family of pdfs Induced by the Simulator: For any fixed \\(\\theta\\) (패러미터 \\(\\theta\\) 는 주어져 있다는 소리), the output of the simulator \\(y_\\theta = g( \\cdot \\; , \\theta)\\) is a random variable. 즉 \\(\\theta \\longrightarrow y_\\theta\\). No closed-form available for \\(p(y \\vert \\theta)\\), and Simulator defines the model pdfs \\(p(y \\vert \\theta)\\) implicitly. ### Approximate Bayesian Computation (ABC) ##### Intractability $ (D ) = $ - Usual intractability in Bayesian inference is not knowing \\({\\pi (D)}\\), which is marginal Likelihood of Data. - \\(\\pi (D \\vert \\theta) = \\kappa(\\theta)\\pi (D \\vert \\theta)\\) 인 경우라면, MH 알고리즘을 사용하면 됨. 계산 과정에서 \\(\\pi (D \\vert \\theta)\\)가 캔슬되니까. 그러나 \\(\\pi (D \\vert \\theta) = \\kappa(\\theta)f (D \\vert \\theta)\\), \\(f (D \\vert \\theta)\\) 가 unnormalized density인 경우라면 이는 doubly-intractable 케이스. 캔슬도 안되고 고려해줄수밖에 없음. (with \\(\\kappa(\\theta)\\) unknown.) - ABC가 해법이 된다. 만능은 아님. 적용에 약간 회의적. - A problem is completely-intractable if \\(\\pi (D \\vert \\theta)\\) is unknown and cannot be evaluated (unknown is subjective). That is, if the analytic distribution of the simulator, \\(f(\\theta)\\) run at \\(\\theta\\) is unknown. 모델이 지나치게 복잡해서 명시적으로 Likelihood 자체가 주어지지 않는 경우가 존재함. Completely intractable models are where we need to resort to ABC methods. (Likelihood가 intractable한 모델에서 ABC가 많이 사용된다. 전 챕터에서 언급된 Doubly Intractable 모델이 대표적인 예. 단 ABC가 스켈레톤 키는 아님. ABC도 패러미터 튜닝이 요구되고, 이 패러미터 튜닝은 상당히 어려움. 따라서 ABC도 상당히 약점이 많음.) - Genetic Background of ABC - ABC is a recent computational technique that only requires being able to sample from the likelihood \\(f(\\cdot \\; \\theta)\\) - This technique stemmed from population genetics models, about 15 years ago, and population geneticists still contribute significantly to methodological developments of ABC. - Population Genetics - Describe the genotypes (AA, AO, etc ⇔ penotypes A) , estimate the alleles frequencies, determine their distribution among individuals, populations and between populations. - Predict and understand the evolution of gene frequencies in populations as a result of various factors. - Analyses the effect of various evolutive forces (mutation, drift, migration, selection) on the evolution of gene frequencies in time and space. If the likelihood function is intractable, then ABC (approximate Bayesian computation) is one of the few approaches we can use to do inference. ABC algorithms are a collection of Monte Carlo methods used for calibrating simulators. ABC 자체는 simulator-based model을 calibration한 모델이기 때문에 우리가 Likelihood function에 대해 명시적으로 알 필요가 없다. - they do not require explicit knowledge of the likelihood function. - inference is done using simulation from the model (they are ‘likelihood-free’). ABC methods are popular in biological disciplines, particularly genetics. They are - Simple to implement - Intuitive - Embrassingly parallelizable (MCMC 모델이 아니기 때문에 생기는 성질. multiple chain으로 돌려도 괜찮다는 이야기이다.) MCMC의 사용 상황은 아래의 그림과 같이 도식화된다. - Can usually be applied - Proceeds: Target is \\(\\pi(\\theta)f(x \\vert \\theta)\\). When likelihood \\(f(x \\vert \\theta)\\) not in closed form, likelihood-free rejection technique of ABC Algorithm is: \\(y \\sim f(y \\vert \\theta)\\), under the prior \\(\\pi(\\theta)\\) (population genetics에서는 prior information이 대단히 강력하다. 따라서 prior에서 샘플을 생산해도 무관하며, ABC의 이러한 성질은 이의 연장선이다.), keep jointly simulating $ ’ () \\ \\ z f(z ’ ) $ until the \\(z\\) is equal to the observed value \\(y\\). \\(z = y\\)라는 결과를 얻을 때까지 위의 과정을 반복. \\(z = y\\)가 된다면 $’ $를 accept. - Proof $ \\begin{alignat}{4} f(i) &amp;{z } (_i) f(z _i) l_y(z) &amp;&amp; \\ &amp;(_i) f(y _i) &amp;&amp;= (_i y) \\end{alignat} $ - Tolerance Condition When \\(y\\) is a continuous rv, \\(z = y\\) is replaced with a tolerance condition, \\(\\rho(y,z) \\le \\epsilon\\), where \\(\\rho\\) is a distance. Output distributed from $ () P_{ (y,z) &gt; } ; ; ; ; ( (y,z) &gt; ) $ 하지만 이 방법은 - \\(\\epsilon\\) 결정이 어려움 - distance \\(d(z,y)\\) 계산이 어려움 The idea behind ABC is that the summary statistics coupled with a small tolerance should provide a good approximation of the posterior: 위의 난점을 해결하기 위해 summary statistics \\(\\eta(z), \\eta(y)\\)를 사용하여 \\(dist\\left\\{ \\eta(z), \\eta(y) \\right\\}\\)를 구하여 이를 기준점으로 사용. $ \\[\\begin{align} \\pi_\\epsilon (\\theta \\vert y) &amp;= \\int \\pi_\\epsilon (\\theta , z \\vert y)dz \\\\ &amp;\\approx \\pi \\left( \\theta \\vert \\eta(y) \\right) \\end{align}\\] $ where \\(\\eta(y)\\) defines a (not necessarily sufficient) statistic. 하지만 대부분의 경우에는 SS를 이용은 함. - Proceeds: For each iteration, 1. Repeat followings until \\(\\rho \\left( \\eta(z), \\eta(y) \\right) \\le \\epsilon\\). - Generate \\(\\theta &#39;\\) from the prior distribution \\(\\pi(\\cdot)\\). - Generate \\(z\\) from the likelihood \\(f(\\cdot \\; \\vert \\theta &#39; )\\). 2 Set $_i = ’ $. However, Simulating from the prior is often poor in efficiency. (population genetics에서는 strong prior를 사용했기 때문에 이러한 문제가 표면화되지 않았었음. 그러나 통계적 상황에서는 Bayesian prior를 사용하는 경우도 많으므로 이러한 문제가 유의해짐. 특히 non-informative prior를 쓸 때 poor performance 가능성 높아짐) - By modifying the proposal distribution on \\(\\theta\\) to increase the density of \\(x\\)’s within the vicinity of \\(y\\). \\(\\theta\\)의 proposal 제안할 때 그 과정을 개선한다는 소리. - By viewing the problem as a conditional density estimation and by developing techniques to allow for larger \\(\\epsilon\\). \\(\\epsilon\\) 잡기가 너무 어려워서 ABC 자체가 애매해짐. summary statistics 따라 \\(\\epsilon\\)이 항상 바뀌고 이거에 대한 규칙성도 현재로서는 없음. Summary Statistics가 모든 정보를 담고 있지 않아서, summary statistics로 model selection을 하려는 시도는 있었지만 실패했음. summary statistics가 담고 있는 정보가 데이터의 성질을 온전히 드러내고 있는지조차도 불명확함. - By including \\(\\epsilon\\) in the inferential framework. \\(\\epsilon\\) reflects the tension between computability and accuracy. - As \\(\\epsilon \\rightarrow \\infty\\), we get observations from the prior, \\(\\pi(\\theta)\\). - If \\(\\epsilon=0\\), we generate observations from \\(\\pi(\\theta \\vert D)\\). posterior에서 뽑는 것이라고 생각할 수 있다. \\(\\epsilon=0\\)에 가까우면 (최소한 summary statistics로는) \\(y=z\\) 조건을 만족하는 것. ABC가 사용 불가한 상황은? - if the data are too high dimensional, we never observe simulations that are ‘close’ to the field data. - 데이터가 고차원이라면, 데이터의 차원들간의 interaction이 반드시 존재할 수밖에 없으므로, 기존 데이터와 같은 데이터를 생산해내는 것은 사실상 불가능 -Reduce the dimension using summary statistics. - 1개의 실현값 \\(\\theta&#39;\\) 에서 summary statistics를 10000개 \\(\\eta(z^{(1)}), \\cdots, \\eta(z^{(10000)})\\) 를 가령 생산한 상황이라면, 이 summary statistics의 distribution이 multimodal이면 절대로 사용불가. 4.5.1.0.1 Potential Risks and Remedies in ABC Non-zero tolerance \\(\\epsilon\\) - The inexactness introduces a bias in the computed posterior distribution. - Practical studies of the sensitivity of the posterior distribution to the tolerance. - sensitivity analysis, specification difficult - summary statistics를 쓰지 sufficient statistics를 쓰는게 아니기 때문에 필연적으로 information loss가 있고 CI가 넓어짐 Non-sufficient summary statistics - The information loss causes inflated credible intervals. - Automatic selection/semi-automatic identification of sufficient statistics. Model validation check. Small number of models/Mis-specified models - The investigated models are not representative/lack predictive power. - Careful selection of models. Evaluation of the predictive power. Priors and parameter ranges - Conclusions may be sensitive to the choice of priors. Model choice may be meaningless. - Check sensitivity of Bayes factors to the choice of priors. Use alternative methods for model validation. Curse-of-dimensionality - Low parameter acceptance rates. Model errors cannot be distinguished from an insufficient exploration of the parameter space. Risk of overfitting. - Methods for model reduction if applicable. Methods to speed up the parameter exploration. Quality controls to detect overfitting. Model ranking with summary statistics - The computation of Bayes factors on summary statistics may not be related to the Bayes factors on the original data, which may therefore render the results meaningless. - Only use summary statistics that fulfill the necessary and sufficient conditions to produce a consistent Bayesian model choice. Use alternative methods for model validation. Implementation - Low protection to common assumptions in the simulation and the inference process. - Sanity checks of results. 4.5.2 ABCifying Monte Carlo Methods Rejection ABC is the basic ABC algorithm: rejection 알고리즘임 - Inefficient as it repeatedly samples from prior More efficient sampling algorithms allow us to make better use of the available computational resource: spend more time in regions of parameter space likely to lead to accepted values. - allows us to use smaller values of \\(\\epsilon\\), and hence finding better approximations. Most Monte Carlo algorithms now have ABC versions for when we don’t know the likelihood 이를 개선하기 위해 제안되는 모델이 아래의 ABC-MCMC 알고리즘 4.5.3 ABC-MCMC Algorithm 이 알고리즘에서는 Embrassingly parallelizable 성질을 잃어버리게 된다. We are targeting the joint distribution $ {ABC} (, x D) {} (D x) (x ) () $ To explore the \\((\\theta, x)\\) space, proposals of the form $ Q ( (, x), (‘, x’) ) = q(, ‘) (x’ ’ ) $ seem to be inevitable. The MH acceptance probability is then $ \\[\\begin{align} r &amp;= \\dfrac{\\pi_{ABC} (\\theta&#39; , x&#39; \\vert D) Q \\left( (\\theta&#39;, x&#39;), (\\theta, x) \\right)}{\\pi_{ABC} (\\theta , x \\vert D) Q \\left( (\\theta, x), (\\theta&#39;, x&#39;) \\right)} \\\\ &amp;= \\dfrac{\\pi_{\\epsilon} (D \\vert x&#39;) \\pi (x&#39; \\vert \\theta&#39;) \\pi(\\theta&#39;)}{\\pi_{\\epsilon} (D \\vert x) \\pi (x \\vert \\theta) \\pi(\\theta)} \\dfrac{q(\\theta&#39;, \\theta) \\pi (x&#39; \\vert \\theta )}{q(\\theta, \\theta&#39;) \\pi (x&#39; \\vert \\theta &#39; )} &amp;= \\dfrac{\\pi_{\\epsilon} (D \\vert x&#39;) \\pi(\\theta&#39;)}{\\pi_{\\epsilon} (D \\vert x) \\pi(\\theta)} \\dfrac{q(\\theta&#39;, \\theta) }{q(\\theta, \\theta&#39;) } \\end{align}\\] $ For each iteration, Repeat followings until \\(\\rho \\left( \\eta(z), \\eta(y) \\right) \\le \\epsilon\\). Propose \\(\\theta &#39;\\) from a transition kernel \\(g(\\theta &#39; \\vert \\theta^{(t)})\\) Generate \\(z\\) from the likelihood \\(f(\\cdot \\vert \\theta &#39;)\\) accept or stay $ = \\[\\begin{cases} \\theta &#39; &amp; \\text{with probability MH ratio } \\alpha = \\min \\left( 1, \\; \\; \\dfrac{\\pi(\\theta &#39;)}{\\pi(\\theta^{(t)})} \\dfrac{g(\\theta^{(t)} \\vert \\theta &#39;)}{g(\\theta &#39; \\vert \\theta^{(t)} )} \\right) \\\\ \\theta &amp; o.w. \\end{cases}\\] $ 즉 \\(\\theta &#39;\\)를 MH 알고리즘에서 생산하며, MH 알고리즘에서 생산하였으므로 \\(z\\)와 \\(\\theta &#39;\\) 양쪽 모두가 수용할지 여부의 평가 대상. \\(z\\)가 수용되지 않았다면 \\(\\theta &#39;\\)도 수용되지 않고 \\(\\theta&#39;\\)를 새로 생산한다. 4.5.3.0.1 Sequential ABC Algorithms The most popular efficient ABC algorithms are those based on sequential methods. We aim to sample N particles successively from a sequence of distributions $ _1 () , , _T () = $ For ABC, we decide upon a sequence of tolerance \\(\\epsilon_1 &gt;\\epsilon_2 &gt; \\cdots &gt; \\epsilon_T\\), and let \\(\\pi_t\\) be the ABC distribution found by the ABC algorithm when we use tolerance \\(\\epsilon_t\\). 4.5.3.0.2 Synthetic Likelihood The synthetic likelihood approach of Wood (2010) is an ABC algorithm which uses a Gaussian likelihood. However, instead of using $ \\[\\begin{align} \\pi_\\epsilon(D \\vert X) &amp;= N(D; X, \\epsilon) \\\\ \\pi_{ABC}(D \\vert \\theta) &amp;= \\int N(D; X, \\epsilon)\\pi(X \\vert \\theta) dX \\end{align}\\] $ they repeatedly run the simulator at \\(\\theta\\), generating \\(X_1, \\cdots, X_n\\), and then use $ (D ) = N ( D ; , ) $ where \\(\\mu_\\theta\\) and \\(\\Sigma_\\theta\\) is the sample mean and covariance of the (summary of the) simulator output. "],["hamiltonian-monte-carlo.html", "4.6 Hamiltonian Monte Carlo", " 4.6 Hamiltonian Monte Carlo RW의 단점 (randomness에서 오는 inefficiency를 줄이기 위해) 을 보완하기 위해 나온 개념. Hamiltonian Monte Carlo borrows an idea from physics to suppress the local random walk behavior in the Metropolis algorithm, thus allowing it to move much more rapidly through the target distribution. Version of Metropolis where you take many “steps” per “iteration” Use “Hamiltonian dynamics” and a latent “momentum (\\(\\phi_j\\))” vector so the steps within an iteration move along a “trajectory.” Requires computation of gradient of log target density. 한번의 스텝에서 어느정도 움직이는지를 알기 위해선 이것이 요구되기 때문. Take \\(L\\) leapfrog steps (leapfrog를 몇번을 할 것인지), each of distance \\(\\epsilon\\) (1번의 leapfrog에서 얼마만큼을 움직일 것인지), then accept/reject. In a leapfrog step, both \\(\\theta\\) and \\(\\phi\\) are changed, each in relation to the other. Effecitive Sample Size \\(=ESS/S\\): correlated되지 않았을 경우에 샘플 사이즈로 볼 수 있는 크기. MCMC는 과거 체인에 dependent하므로 당연히 correlated되어 있으며, 따라서 10000개를 생산했다고 치면 10000개의 샘플 사이즈에서 independent한 샘플의 사이즈가 얼마만큼인지를 체크하는 것. 따라서 ESS가 크면 클 수록 좋음. 마지막에 computation time \\(S\\)로 나누어준 이유는 단위시간 당 샘플로 비교해야 하니까. 해당 개념은 알고리즘 comparison에서 대단히 많이 사용됨. Rstan은 GS가 아니라 HMC를 사용함. 그래서 샘플 크기가 상대적으로 작아도 OK. How far to jump in each step? - If \\(\\epsilon\\) is too small, you waste time shuffling along. - If \\(\\epsilon\\) is too large, the physical approximation breaks and you find yourself rejecting. How many steps? (No U-turn Sampler) - If \\(L\\) is too small, you might not go far enough in each iteration. - If \\(L\\) is too large, you’ll waste time circling around and around. Still HMC can be much better than Gibbs or Metropolis in high dimensions. Energy Barrier. Multimodal에 취약. Proceeds: 우선 momentum부터 만들어야 함. 운동에너지를 위치에너지로 바꾸는 것이 Hamiltonian의 기본적인 메커니즘. 이때 운동에너지 + 위치에너지는 항상 일정한 상수로 일정하다. 이를 위해 momentum을 생산해야 하는데, 이때 가장 손쉽게 momentum을 생산할 수 있는 방법이 \\(M=I\\) 로 잡는 것. 단, 어떤 측면에서는 \\(I\\)가 inefficient하기도 함. 다른 제안으로 Inverse Fisher’s Information 사용이 제안된 적도 있음. 하지만 중간중간에 fixed point iteration으로 패러미터를 정해줘야 한다고? 경사가 완만할 때 더 많은 거리 이동 가능. A. The iteration begins by updating \\(\\phi\\) with a random draw from its posterior distribution - which is the same as its prior distribution \\(\\phi \\sim N(0, M)\\). B. A simultaneous update of \\((\\theta, \\phi)\\) conducted in an elaborate but effective fashion via a discrete mimicking of physical dynamics. B step의 1회 이터레이션이 leapfrog Step 1회에 해당한다. Use the gradient of the log-posterior density of \\(\\theta\\) to make a half-step of \\(\\phi\\). $ \\[\\begin{align} \\phi_{half.new} \\; \\; \\; &amp;\\leftarrow \\; \\; \\; \\phi + \\dfrac {1}{2} \\epsilon \\ast \\dfrac{d \\log \\pi(\\theta \\vert y)}{d \\theta} \\\\ &amp;= \\; \\; \\; \\dfrac{1}{2} \\epsilon \\bigtriangledown_{\\pmb \\theta} \\log f(\\theta^\\ast) \\\\ &amp;= \\; \\; \\; \\phi + \\dfrac {1}{2} \\epsilon \\ast \\dfrac{d \\log \\pi(\\theta \\vert y)}{d \\theta} \\Bigg \\vert_{\\theta^\\ast} \\end{align}\\] $ {:start=“2”} Use the ‘momentum’ vector \\(\\phi\\) to update the ‘position’ vector \\(\\theta\\): $ ; ; ; ; ; ; + M^{-1} $ {:start=“3”} Use the gradient of \\(\\theta\\) to half-update \\(\\phi\\): $ {new} ; ; ; ; ; ; {half.new} + $ C. label \\(\\theta^{t-1}, \\phi^{t-1}\\) as the value of the parameter and momentum vectors at the start of the leapfrog process and \\(\\theta^{\\ast}, \\phi^{\\ast}\\) as the value after the \\(L\\) steps. In the accept-reject step, we compute $ r = $ D. Set \\(\\theta^t = \\begin{cases} \\theta^\\ast &amp; \\text{with probability } \\min(1,r) \\\\ \\theta^{t-1} &amp; o.w. \\end{cases}\\) 4.6.0.0.1 HMC Example Trajectory Blue ellipse is contour of target distribution Initial position at black solid circle. Arrows indicate a U-turn in momentum “One practical impediment to the use of Hamiltonian Monte Carlo is the need to select suitable values for the leapfrog stepsize, \\(\\epsilon\\), and the number of leapfrog steps \\(L\\). Tuning HMC will usually require preliminary runs with trial values for \\(\\epsilon\\) and \\(L\\). Unfortunately, preliminary runs can be misleading….” 4.6.1 Introduction to Hamiltonian Monte Carlo Hamiltonian Monte Carlo (HMC) was originally developed in the late 1980s as Hybrid Monte Carlo to tackle calculations in Lattice Quantum Chromodynamics, a field focused on understanding the structure of the protons and neutrons. Neal (1995, 2011) introduced the Hamiltonian Monte Carlo into the mainstream of statistical computing. HMC is built upon a rich theoretical foundation, which is formulated in terms of differential geometry, that makes it uniquely suited to the high-dimensional problems of applied interest. 4.6.1.0.1 Foundations of Hamiltonian Monte Carlo Most Markov Transitions are diffusive, concentrating around the initial point such that the corresponding MArkov chains linger in small neighborhoods of the typical set for long periods of time. In order to maximize the utility of our computational resources, we need coherent Markov Transitions that are able to glide across the typical set towards new, unexplored neighborhoods. In order to make large jumps away from the initial point, and into new, unexplored regions of the typical set, we need to exploit information about the geometry of the typical set. HMC is the unique procedure for automatically generating this coherent exploration for sufficiently well-behaved target distributions. Introduce some intuition to motivate how we can generate the desired exploration by carefully exploiting the differential structure of the target probability density. Discuss the procedure with the complete construction of the Hamiltonian Markov transition. A vector field is the assignment of a direction at every point in parameter space. When those directions are aligned with the typical set, we can follow them like guide posts, generating coherent exploration of the target distribution. When the sample space is continuous, a natural way of encoding this direction information is with a vector field aligned with the typical set. A vector field is the assignment of a direction at every point in parameter space, and if those directions are aligned with the typical set then they act as a guide through this neighborhood of largest target probability. By construction this, we follow the direction assigned to each at point for a small distance. Continuing this process traces out a coherent trajectory through the typical set that efficiently moves us far away from the initial point to new, unexplored regions of the typical set as quickly as possible. The gradient of the target pdf encodes information about the geometry of the typical set, but not enough to guide us through the typical set by itself. Follwing along the gradient instead pulls us away from the typical set and towards the mode of the target density. In order to generate motion through the typical set we need to introduce additional structure that carefully twists the gradient into alignment with the typical set. Need to construct a vector field aligned with the typical set using only information that we can extract from the target distribution. The natural information is the differential structure of the target distribution which we can query through the gradient of the target probability density. The gradient defines a vector field in parameter space sensitive to the structure of the target distribution. Unfortunately, that sensitivity is not sufficient as the gradient will never be aligned with the typical set. Following the guidance of the gradient pulls us away from the typical set and towards the mode of the target density. Without enough transverse momentum to balance againts the gravitational attraction of the planet, a satellte will still crash into the planet. On the other hand, if the satelite is given too much momentum then the gravitational attraction will be too weak to capture the satelite in a stable orbit, which will instead abandon the planet for the depths of space. When we introduce exactly the right amount of momentum to the physical system, the equations describing the evolution of the satelite define a vector field aligned with the orbit. The subsequent evolution of the system will then trace out orbital trajectories. The gradient can direct us towards only parameterization sensitive neighborhoods like that around the mode, and not the parameterization-invariant neighborhoods within the typical set. To utilize the information in the gradient we need to complement it with additional geometric constraints, carefully removing the dependence on any particular parameterization while twisting the directions to align with the typical set. If we add the right amount of momentum, then the momentum will exactly balance against the gradient information, and the corresponding dynamics of the system will be conservative. The key is twisting the gradient vector field into a vector field aligned with the typical set, and hence once capable of generating efficient exploration, is to expand our original probabilistic system with the introduction of auxiliary momentum parameters. There is only one procedure for introducing auxiliary momentum with such a probabilistic structure: Hamiltonian Monte Carlo. 4.6.1.0.2 Phase Space and Hamilton’s Equations A defining feature of conservative dynamics is the preservation of volume in position-momentum phase space. For example, althou dynamics might compress volumes in position space, the corresponding volume in momentum space expands to compensate and ensure that the total volume is invariant. Such volume-preserving mapping are also known as shear Transformations. Conservative dynamics in physical systems requires that volumes are exactly preserved. As the system evolves, any compression or expansion in position space must be compensated with a respective expansion or compression in momentum space to ensure that the volume of any neighborhood in position-momentum phase space is unchanged. In order to mimic this behavior in our probabilistic system we need to introduce auxiliary momentum parameter, \\(p_n\\), to complement each dimension of our target parameter space, \\(q_n\\), expanding the D-dimensional into a 2D-dimensional phase space. $ q_n ( q_n, p_n ) $ Moreover, these auxiliary momentum have to be dual to the target parameters, transforming in the opposite way under any reparameterization so that phase space volumes are invariant. Having expanded the target parameter space to phase space, we can lift the target distribution onto a joint probability distribution on phase space called the canonical distribution. Then, the choice of a conditional probability distribution over the auxiliary momentum, $ (q, p) = (p q) (q) $, which ensures that if we marginalize out the momentum we immediately recover our target distribution. By constructing a probability distribution on phase space that marginalizes to the target distribution, we ensure that the typical set on phase space projects to the typical set of the target distribution. In particular, if we can construct trajectories that efficiently explore the joint distribution (black) they will project to trajectories that efficientyl explore the target distribution (green). The canonical density \\(\\pi(q, p)\\) does not depend on a particular choice of parameterization, and we can write it in terms of an invariant Hamiltonian function, \\(H(q, p)\\), $ (q,p) = ( - H(q, p) ) $ Because \\(H(q, p)\\) is independent of the details of any parameterization, it captures the invariant probabilistic structure of the phase space distribution and, the geometry of its typical set. The value of the Hamiltonian at any point in phase space is called the energy at that point. Hamiltonian decomposes into two terms, Density over the auxiliary momentum, \\(K(p,q)\\) is called the kinetic energy (unconstrained and specified by the implementation), while the term corresponding to the density of the target distribution, \\(V(q)\\) is known as the potential energy (determined by the target distribution). $ H(q,p) (q,p) = - (p q) - (q) K(p,q) + V(q) $ Because the Hamiltonian captures the geometry of the typical set, it should be able to use it to generate a vector field oriented with the typical set of the canonical distribution. The desired vector field can be generated from a given Hamiltonian with $ = + {p} = {p}, ; ; ; ; ; = - {q} = - {q} - {q} $ By channeling the gradient through the momentum instead of the target parameter directly, Hamilton’s equations twist differential information to align with the typical set of canonical distribution. Following the Hamiltonian vector field for some time, \\(t\\), generates trajectories \\(\\phi_t (q, p)\\), that rapidly move through phase space while being constrained to the typical set. Projecting these trajectories back down onto the target parameter space finally yields the efficient exploration of the target typical set for which we are searching. Every Hamiltonian Markov Transition is comprised of a random lift from the target parameter space onto phase space (light red), a deterministic Hamiltonian trajectory through phase space (dark red), and a projection back down to the target parameter space (light red). Need a mechanism for introducing momentum to a given point in thetarget parameter space. To lift an initial point in parameter space into one on phase space, we simply sample from the conditional distribution over the momentum, \\(p \\sim \\pi(p \\vert q)\\). Once on phase space we can explore the joint typical set by integrating Hamilton’s equations for some time, \\((q,p) \\rightarrow \\phi_t (q,p)\\). By construction these trajectories coherently push the Markov transition away from the initial point, and neighborhoods that we have already explored, while staying confined to the joint typical set. After integrating Hamilton’s equations, we can return to the target parameter space by simply projecting away the momentum, \\((q,p) \\rightarrow q\\). "],["population-monte-carlo.html", "4.7 Population Monte Carlo", " 4.7 Population Monte Carlo Population-Based MCMC. population이란? 즉, multiple 체인을 돌린다는 것. 로컬 트랩 문제를 회피하기 위해서. 이는 이하의 조건을 탄다. 각 체인이 가지는 분포는 서로 달라야 하지만, 아예 그 분포들끼리 아예 무관해서는 안된다. (2번을 위해) 체인들 간에 정보의 교환이 이루어져야 한다. 서로가 가지고 있는 정보를 공유하는 것으로 체인들의 타겟 분포로의 수렴을 가속시키는 것이 이 여러개의 체인의 존재 목적이기 때문이다. 이는 패러렐 컴퓨팅을 가능하게 한다. Embarrassingly Parallel MCMC 언급하였듯 위의 다중체인은 서로간에 정보의 교환이 이루어져 속도가 다소 느려지는 측면이 분명히 생긴다. 이러한 발목잡힘을 피하기 위해 체인간의 정보교환이 전혀 없는 MCMC. 타겟분포 \\(f(x)\\)에서 샘플 생산. f(x_1 , , x_N)=_{i=1}^N f_i (x_i) 이때 f(x)와 f_i(x_i) 사이에는 반드시 연관이 존재해야 하며, 적어도 하나의 i값에 대해 f(x) = f_i(x_i)를 만족해야 함. N은 체인의 갯수, 혹은 population의 size. 4.7.1 Adaptive Direction Sampling 가장 기본적인 형태. 여러개의 체인을 돌린 후 특정 방향으로 다른 샘플을 이동시키는 방법. 4.7.2 Conjugate Gradient MC 4.7.3 Parallel Tempering temperature 개념 사용. 따라서 T_1&gt;T_2&gt;&gt;T_n=1 이어야 하며, T_n은 타겟분포에 상응한다. 이때 각 temperature에 대응하는 pdf f_i(x) ( - ) simulated tempering은 temperature를 생산해서 해당 temperature를 accept한 후 해당 temperature로 이동. Parallel Tempering은 n개의 온도에 대응하는 체인 n개를 만들어 각각의 온도에 대응시킨 후 n개의 체인을 병렬적으로 돌림. 이때 높은 온도인 T_1은 넓은 space를 탐색하고 낮은 온도인 T_n은 좁은 space를 탐색. 이때 태생의 온도에 따라 탐색시키는 것은 탐색 효율이 떨어지므로 체인이 일정 경과할 때마다 swapping (Exhange) opertation을 하여 출신 이외의 다른 체인과 서로 바꿈. 이 바꿈은 인접한 체인과만 발생. 이를 통해 상황이 맞아떨어지면 T_1 출신의 탐색자가 T_n까지 가서 탐색하는 상황도 나올 수 있음. 이러한 swapping opertation을 Auxiliary Variable Generation까지 확장시킨 것이 Exhange Algorithm. Proceeds: 1. local MH. MH 알고리즘을 통해 X_i^{(t)} X_i^{(t+1)} 로 업데이트. 2. Exhange 스텝. 인접한 체인이 2개라면 각각으로 이동할 확률을 0.5로 잡고, 1개라면 서로밖에 교환 못하니 이는 1로 설정. 이후 해당 교환을 accept할지 여부는 확률 { 1, ; ; ; }에 따라 결정. 이외면 교환 안 한 채로 남긴다. 이를 고차원으로 확장시키면 Sequential Parallel Tempering. 4.7.3.0.1 Exchange Algorithm 4.7.4 Evolutionary MC Combinatorial Optimization Problem, 무수히 많은 조합 중에 local optimal 찾는 문제에서 가장 자주 사용되는 방법론인 genetic Algorithm, 의 MC 버전이라고 볼 수 있다. 다른 모델, 크로스오버 (스위치), 뮤테이션. 다만 Evolutionary MC 자체는 Combinatorial Optimization을 푼다기보단 Multimodal 문제를 푸는 용도에 가까움. genetic Algorithm과 Evolutionary MC 둘 모두 local mode를 찾는 알고리즘, local Trap 문제를 해결하는 알고리즘. 또한 Evolutionary MC는 local trap 해결 이외에 Variable Selection에도 아주 유용하며 자주 사용됨. 이 Variable Selection 자체가 일종의 Combinatorial Optimization 문제로 생각될 수 있음. 가용 변수의 조합 중 어떤 조합을 써야 효율이 잘 나올 것인가를 고민하는 거니까. Evolutionary MC 또한 temperature 개념을 사용하므로 parallel Tempering과 유사. 온도 설정과 온도에 따른 체인 설정 후 탐색은 완전히 똑같지만, parallel tempering의 swapping operator가 바로 인접한 체인과의 교환만 발생했던 반면 evolutionary MC는 crossover operator를 사용하여 인접한 것만이 아닌 모든 체인 중에 교환할 체인을 선정. 이렇게 교환 범위가 넓기 때문에 parallel tempering보다 성능이 훨씬 좋음. Proceeds: 1. Mutation은 자주 일어나는 일이 아니므로 확률로 판정하여 Mutation과 Crossover 둘 중 하나만 일어나도록 함. Mutation의 확률은 q_m, Crossover의 확률은 1-q_m. 이 확률 q_m은 uniform에서 획득. 잘 모르면 0.5. 1. Local MH. 이는 genetic Algorithm에서의 Mutation에 대응. x_1 , , x_N 중 1개를 균일확률로 선정해서 뽑고 뽑은 그 x_k 1개에 대응하는 y_k = x_k + e_k 를 만들어 이로 대체할 것을 제안. 이는 (1, r_m)의 확률로 accept되고, 이때 accpetance ratio r_m = { - } . 이때 뒤쪽의 fraction은 proposal density에 해당. 2. Crossover Operator: (1) 현 population x에서 x_i를 고른 후, (2) x / x_i 에서 x_j 를 고른다. 이때 x_j를 선정할 때 ( - )의 확률에 따라 선정한다. k는 앞서 선정되었던 i를 제외한 모든 수. (3) e=x_i - x_j, y_i = x_j + r e. 이때 r은 direction에 해당하며 모든 실수일 수 있고, r의 선정은 density f(r) r ^{d-1} f(x_i + re)에 따른다. (4) 여기서 획득한 y_i로 x_i를 교체한 후 이렇게 교체한 집합을 새로운 population으로 삼는다. 3. Exchange 스텝. 이를 통해 X 내용물을 구성하는 \\(x_i\\), 즉 각 온도 H(x_i) 에 대응하는 chromosome들의 교환이 이루어짐. Exchange Operator: parallel tempering과 마찬가지로 양옆의 것들과 확률 판정해서 교환. 4.7.5 Sequential Parallel Tempering "],["stochastic-approximation-monte-carlo.html", "4.8 Stochastic Approximation Monte Carlo", " 4.8 Stochastic Approximation Monte Carlo Neural Network의 Multimodality issue. 패러미터는 p개인데 equation은 q개. q가 p보다 훨씬 작아서 관계성이 식으로밖에 나오지 않음. 따라서 identifiability 이슈가 발생하기 때문. gradient descent 방법으로 최적해 찾아내다 뭐 이렇게 말을 하는데 사실 이걸 최적해로 말할 수 없음. combinatorial optimization에도 로컬 최적해가 다수 존재하고 글로벌 최적해 파악이 어려우므로 유사하게 multimodal issue 존재. SAMC는 과거의 샘플 전체를 이용하므로 Monte Carlo긴 하나 MCMC는 아님. 에너지 펑션 \\(-\\log \\psi (x)\\), $ (x)$는 unnormalized density. 이 에너지 펑션을 U(X)로 둔다면 이는 결국 y축에 대응되는 값. 이 U(X)를 파티션한다. 이렇게 나눈 영역 E_i들은 각각 고유한 weight를 보유하고 있음. 난수 1개를 샘플링했을 때 이 난수가 영역 E_i에서 나왔다고 한다면, 이 영역 E_i에 배정되었던 weight를 줄이고 다른 모든 구간의 weight를 높인다. 이를 통해서 모든 영역에서의 고른 샘플링을 기대할 수 있음. 이 weight의 증감량을 얼마만큼 시킬 것인지가 stochastic Approximation을 통해서 얻어짐. 이를 모두 반영한 식은 c (x) _{i=1}^m I(X E_i) 이때 이의 denominator는 E_i에 대한 weight이며, 이것이 결국 c에 대응하는 부분인데 영역이 partition되었으므로 이를 mixture distribution의 형태로 나타내줌. 여기서 ^{(i)}=log g_i이고, g_i = _{E_i} (x). 따라서 이를 exp의 승으로 만드는 것은 log를 취했던 것을 벗기는 작업임. _i : 구간 i에서 얼마만큼의 샘플을 생산할 것인가. 보통은 구간별 생산 갯수를 동일하게 하는 것을 목적으로 함. 이에 의해서 보통 이 알고리즘을 flat-histrogram 알고리즘이라고 부름. gain factor sequence { k }{k=0}^. 이는 Stochastic Approximation에 필요함. gain factor _k = . 이때 t_0는 prospected value. 따라서 첫 이터레이션때는 1로 유지되고, 이후에 빠르게 감소함. 따라서 weight도 이에 영향받아 첫번째 이터레이션때는 일정하게 유지되다가 이후에 떨어진다. t_0가 크면 수렴이 빠르지만 그렇기 때문에 지나치게 커서는 안됨. 이렇게 생산한 샘플을 그냥 써서는 안되고, 획득한 샘플 ^{(t)}와 weight (theta^{(t)} )= g_i를 사용하여 Importance Sampling을 한번 해서 그 결과물을 사용해야 함. ???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? 3시 18분 "],["review.html", "4.9 Review", " 4.9 Review 4.9.1 Wk01 Write the inverse-CDF method and state how we can generate random numbers from \\(W(\\alpha, \\beta)\\). inverse-CDF method는, 우리가 알다싶이 \\(0 \\le F(x) \\le 1\\). 즉 \\(F(x) \\sim U(0,1)\\)나 다름없다. \\(u \\sim U(0,1)\\)을 하나 샘플링. 이는 \\(F(x)\\)의 range와 일치한다. 따라서 \\(F(x)=u \\iff x=F^{-1} (u)\\). Weibull Dist: shape parameter \\(k\\), scale parameter \\(\\lambda\\)에 대해 $ f(x) = \\[\\begin{cases} \\left( \\dfrac {k}{\\lambda} \\right) \\left( \\dfrac {x}{\\lambda} \\right)^{k-1} \\exp{- \\left( \\dfrac{x}{\\lambda} \\right) } &amp; x\\ge 0 \\\\ \\\\ 0 &amp; o.w. \\end{cases}\\] $ let quantity \\(X\\) is “time-to-failure.” $ \\[\\begin{align} F(x) = 1- \\exp{- \\left( \\dfrac{x}{\\lambda} \\right) } &amp;= u \\\\ \\Longrightarrow x &amp;= \\lambda \\left[ -\\log (1-u) \\right]^{\\tfrac{1}{k}} \\end{align}\\] $ State the RS algorithm. target density \\(f(x)\\) proposal density \\(g(x)\\) envelope density \\(e(x) = c \\ast g(x)\\) evaluate easy easy generate difficult easy cover all areas of \\(f(x)\\), in all parameter supports, \\(f(x) \\le e(x)\\) State how we can generate random numbers using RS. generate sample \\(x\\) from \\(g(x)\\) generate \\(u \\sim U(0,1)\\) 위에서 언급하였듯, envelope는 proposal의 상수배이며, envelope는 target보다 항상 크므로 \\(\\dfrac{f(x)}{e(x)}\\)는 항상 0 이상이며 1 이하. 이는 곧 \\(U(0,1)\\)에서 생산되는 값과 동일한 분포를 지니며, \\(e(x)\\) 아래의 값들 중 \\(f(x)\\) 아래에도 해당하는 값들은 곧 \\(f(x)\\)에서 생산된 난수라고 볼 수 있었다. 따라서 if \\(u \\le \\dfrac{f(x)}{e(x)}\\), sample \\(x\\)를 accept, 이외엔 reject. 4.9.2 wk03 State one iteration of squeezing RS. \\(f(x)\\)가 evaluate 자체는 가능한데 그거조차도 비용이 expensive 한 경우를 가정. \\(f(x)\\)가 샘플 generate가 어려우니 RS를 쓰는건데 평가 비용조차 높으니 샘플링 과정이 비효율적일 수밖에 없음. 따라서 squeeze function \\(s(x)\\)를 설정하여 확실하게 \\(f(x)\\)에 속하는 샘플들은 먼저 우선선발 시켜서 패스시키고, 우선선발이 아닌 샘플들만 \\(f(x)\\)를 직접 사용해서 조건을 통과하였는지 여부를 체크. 당연하지만 \\(s(x)\\)는 모든 support에서 \\(f(x)\\)보다 작아야 하며, evaluate 비용이 cheap해야 함. proceeds: 1. \\(Y \\sim g\\)에서 샘플링. 2. sample \\(u \\sim U(0,1)\\). 3. if \\(U \\le \\dfrac {s(Y)}{e(Y) = c \\ast g(y)}\\), keep \\(Y\\). 4. if not, whether if \\(U \\le \\dfrac {f(Y)}{e(Y)}\\), keep \\(Y\\). 5. both are not, reject \\(Y\\). 이때 \\(s(x)\\)를 생산하기 위해 Talyor Series Expansion을 사용하는 경우 잦다. State the adaptive RS. Make envelope function \\(e(x)\\) adaptively to the shape of \\(f(x)\\). adaptive RS 자체에는 제약이 있다. 이는 log concave function인 density에만 적용이 가능하다는 것. 즉슨 multimodal인 density에는 적용이 불가하다. 이 제약을 해소하기 위해 Adaptive Rejection Metropolis Sampling이 존재. mode가 필수라는 게 RS 자체가 mode가 필수라는 소리인가? State the Importance Sampling \\(\\mu = E[h(x)]\\). 이때 \\(h(x)\\)는 \\(x\\)의 함수이며, \\(x\\)는 \\(f(x)\\)를 따르므로 \\(h(x)\\)의 기댓값 계산 또한 이를 따르지만, 이는 기댓값 계산에서 density를 \\(g\\)로 바꾸고 이의 각 확률에 발생하는 값들을 \\(h \\ast \\dfrac{f}{g}\\)로 바꾸는 것과 다르지 않음. 이는 \\(f\\)에서 샘플 생산이 힘들때 \\(f\\)를 거치지 않고도 샘플을 생산하여 기댓값을 계산할 수 있다는 점에서 빛을 발함. 즉 확률은 \\(g\\)를 참조하고, 이 확률에서 발생하는 값들이 있을 것이고, 이 값들을 다시 한번 함수에 넣어서 역변환하면 \\(f\\)의 확률에서 발생했었을 각 값들을 획득하는 것이 가능하다는 소리. 이러한 역변환 함수에서 \\(f, g\\)가 차지하는 부분을 weight라고 부르는 것이고, 이를 weight의 총합으로 표준화하면 standardized weight. \\(g\\)의 support가 \\(f\\)의 그것을 다 덮을 필요는 없음. 하지만 1. \\(\\dfrac{f}{g}\\)는 bounded여야 하고, 가장 중요하게, \\(g\\)는 \\(f\\)보다 꼬리가 두꺼워야 함. 이는 극단적인 \\(x\\)값이 나왔을 때 \\(g\\)의 확률이 \\(f\\)보다 지나치게 작으면 해당 부분에서의 weight가 너무너무 커져서 다른 샘플 실값들의 영향력을 다 잡아먹어버리는 weight-degeneracy가 발생해버리기 때문. State the polar methods for generating normal random variable. $ X, Y {} N(0,1)$ f(x,y) = {2} ( - (x^2 + y^2 )) \\(\\theta \\sim U(0, 2\\pi)\\), \\(R^2 \\sim \\EXP (\\tfrac{1}{2})\\). \\(X\\)와 \\(Y\\)를 모은 만큼의 샘플이 \\(N\\)을 따른다. 4.9.3 wk04, 05 State the effect of proposaldensity \\(g\\) in IS. 과도한 variability를 피하기 위해, \\(\\dfrac{f}{g}\\)로 설정하고 \\(g\\)가 \\(f\\)보다 두꺼운 꼬리를 지니도록 설정해야 함. \\(g\\)가 너무 작으면 weight-degeneracy. \\(h\\)가 너무 작다면, \\(\\dfrac{f}{g}\\)를 크게 할 수 있는 \\(g\\)를 선정한다. State the antithetic sampling, Control Variate, and Rao-Balckwellization. antithetic: use two id UE, whose \\(Corr(\\hat \\mu_1 , \\hat \\mu_2)&lt;0\\). State one iteration of sampling Importance Resampling. 왜 옛날에는 variance reduction 하고 요즘엔 안함? "],["else.html", "4.10 Else", " 4.10 Else 4.10.1 Hw4. Rasch Model $ \\[\\begin{align} L(\\theta, \\beta) &amp;= \\prod_{k=1}^n \\prod_{i=1}^p \\left\\{ \\dfrac{\\exp(\\theta_k + \\beta_i)}{1 + \\exp(\\theta_k + \\beta_i)}\\right\\}^{y_{ki}} \\left\\{ \\dfrac{1}{1 + \\exp(\\theta_k + \\beta_i)}\\right\\}^{1-y_{ki}} \\\\ \\pi (\\theta, \\beta \\vert y) &amp;= \\pi(\\theta) \\pi(\\beta) \\ast \\prod_{k=1}^n \\prod_{i=1}^p \\left\\{ \\dfrac{\\exp(\\theta_k + \\beta_i)}{1 + \\exp(\\theta_k + \\beta_i)}\\right\\}^{y_{ki}} \\left\\{ \\dfrac{1}{1 + \\exp(\\theta_k + \\beta_i)}\\right\\}^{1-y_{ki}} \\end{align}\\] $ $ 0&lt;{ }^{y_{ki}} &lt;1, ; ; ; ; ; 0&lt;{ }^{1-y_{ki}}&lt;1 $ underflow problem. log 취하면 해결. $ (_k) N(0, ^2), ; ; ; ; ; (^2 ) IG(0.001, 0.001) $ update \\(\\theta_k , k=1, \\cdots, n\\)\" $ (r) = (k ’ y, ^{(t)}. {-k}^{(t)} - (^{(t)} y, ^{(t)}. _{-k}^{(t)} $ if \\(\\log U &lt; min(\\log(r), 0))\\), accept. else, reject. 4.10.2 DA) Example: MVN for DA 알고리즘, I-step과 P-step이 존재. 4.10.2.0.1 1. I-Step $ \\[\\begin{alignat}{4} Y_2 \\vert Y_1 &amp;\\sim N &amp;&amp; \\Big( \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1} (Y_1 - \\mu_1) , &amp;&amp; \\Sigma_{22} - \\Sigma_{21}\\Sigma_{11}^{-1} \\Sigma_{12} \\Big) \\\\ Y_{i, mis} \\vert Y_{i, obs}, \\mu, \\Sigma &amp;\\sim N_{dim(Y_{mis}^{(i)})} &amp;&amp; \\Big( \\mu_{mis}^{(i)} + \\Sigma_{mis, obs}^{(i)} \\Sigma_{obs, obs}^{-1} (Y_{i, obs} - \\mu_{i, mis}^{(i)}) , &amp;&amp; \\Sigma_{mis,mis}^{(i)} - \\Sigma_{mis,obs}^{(i)}[\\Sigma_{obs,obs}^{(i)}]^{-1} \\Sigma_{obs,mis}^{(i)} \\Big) \\end{alignat}\\] $ 상기의 conditional pdf로 우리는 \\(Y_{i, mis}\\)를 impute 가능. for \\(i=1, \\cdots, n\\), \\(Y_{i, mis} \\vert Y_{i, obs}\\) 에서 \\(Y_{i, mis}\\)를 draw. 4.10.2.0.2 2. P-Step 베이지안 분석을 위해선 prior가 필요. 여기서 prior는 이하로 설정하자. \\(q\\)는 known integer이며, \\(q=p\\)인 상황에 이는 \\(\\Sigma\\)에 대한 Jefferey’s prior. $ (, ) ^{-} $ 위와 같이 식들을 구성하였을 때, com 데이터에 대한 posterior distribution \\(\\pi(\\mu, \\Sigma \\vert Y_1 , \\cdots, Y_n)\\)는 이하와 같이 characterized 가능. 이는 inverse-Wishart 분포. $ Y_1 , , Y_n { - tr( ^{-1} S ) } $ 이렇게 획득해온 패러미터들을 사용해 \\(\\mu\\)의 post를 구하면 이하와 같다. $ , Y_1 , , Y_n N_p ( Y ) $ \\(\\Sigma \\vert Y_1 , \\cdots, Y_n\\)에서 \\(\\Sigma\\) 를 생산 이후 \\(\\mu \\vert \\Sigma, Y_1 , \\cdots, Y_n\\)에서 \\(\\mu\\) 를 생산 4.10.3 Bayesian adaptive clinical trial with delayed outcomes 4.10.3.0.1 Continual Reassessment Method Clinical Trial: Toxicity -&gt; Efficacy -&gt; Confirmation 희귀병 케이스에서는 도즈 레벨을 1~n까지 정해둔 후, 샘플을 slice 하여 1번 subsample에 도즈1 투입. 유효하면 (1차시에 3명 투입했다고 하고 그중에 1명이 독성 나왔으면 독성 확률은 1/3. 해당 여부로 도즈2로 넘어갈 것인지를 판단) 2투입. 2에서 문제 생기면 1로 복귀하고 2번 subsample에 도즈1 투입해봐서 유효한지 검증. 이렇게 모든 서브샘플에 도즈레벨 오가면서 투입해보고 최적 도즈레벨 결정. 이때 CRM을 시작하기 전 대략적으로 이정도의 도즈레벨이 최적 도즈레벨일 것이라는 예측 (Skeleton)을 정하고 CRM을 시작함. delay outcome 이전 환자들의 evaluation이 끝나기 전에 (evaluation period가 경과하기 전이나, 결과가 나오기 전에) 환자 풀이 증가하는 상황 이 상황에서는 관측이 더 된 환자보다 덜 된 환자에서 outcome이 발생할 확률이 높음. 9개월 누워있던 놈보다 2개월 누워있던 놈이 12개월 경과 전에 뭔가 변화를 보이기 쉽다는 소리. 이때 아직 결과를 관찰하지 못한 환자들을 mis로 지정. 이 상황은 누워있던 기간이 결과 발생 여부라는 variant와 직결되어 있으므로 NMAR. 그러니까, 여기서 결과값은 outcome이 발생했는지 안했는지, 그리고 variable은 환자나 누워있던 기간. 위에서 언급했듯 누워있던 기간이 짧으면 변이확률 높음. 따라서 각각에 대해 다른 survival function을 적용하여 각각의 다른 확률 뽑아낸 후 이거 기반으로 DA 진행하면 해결. 4.10.4 NMAR의 종류 \\(m_i\\)는 missing indicator. \\(Y_i\\)가 mis면 1. $ f(M, Y X, , ) = _{i=1}^n f(m_i , y_i x_i , , psi) $ interested in direct relationship b/w \\(X\\) and \\(Y\\), rather than in subpopulation defined by missing-data pattern. Selection Model | characterize \\(y\\) | missing mechanism | \\(f(m_i, y_i \\vert x_i, \\theta, \\psi) =\\) | \\(f_y(y_i \\vert x_i, \\theta)\\) | \\(\\ast f_{m \\vert y}(m_i \\vert x_i, y_i, \\psi)\\) | \\(f(m_i, y_i \\vert x_i, \\xi, \\psi) =\\) | \\(f(y_i \\vert x_i, \\xi)\\) | \\(\\ast f(m_i \\vert x_i, \\xi)\\) | Pattern Mixture model | mis 데이터의 다른 패턴들에 의해 정의되는 각각 다른 strata에서의 \\(y_i \\vert x_i\\)의 분포 | probability of different patterns in missingness | missing의 다른 패턴에 따라 \\(x_i\\)가 결정이 되고, 그 \\(x_i\\)를 기준으로 놓았을 때의 \\(y_i\\)의 분포가 궁금. 4.10.5 wk10) Bayesian Model Selection 해당 문제는 prior을 어떻게 고르느냐에 따라서 해결될 수 있음. 이하는 해당 문제에 대한 다양한 해결책들. 4.10.5.0.1 1. Spike-and-Slab prior let \\(X_{n \\times p} , Y_{n \\times 1}\\), then \\(Y = X \\beta\\), where \\(\\beta_{p \\times 1}\\). p가 많다, 즉 배리어블이 많다는 이야기는 실제 각각의 x의 정보량이 중첩될 가능성이 큼. 그러면 수학적으로는 x’x가 full rank matrix가 아닐 것이며, 이는 곧 몇몇 변수들 간에 서로간의 의존관계가 강하여 의미없는 정보를 포함하는 변수들이 많아질 것. 이러한 의미없는 변수를 삭제하고 실제로 필요한 변수들만 골라내어 y에 대한 inference를 하고 싶음. 이것이 모델 셀렉션 문제이며 이걸 베이지안적으로 풀어내는 것이 곧 Bayesian Model Selection. 무지성 prior로는 \\(\\pi(\\beta) \\sim N(0, \\sigma^2)\\)가 쓰이지만, 이로는 variable selection이 불가. \\(\\beta\\) 중 하나의 component가 0에 가깝게 나왔다고 한들 이것을 0으로 판정할 indicator가 없기 때문. (HPD interval을 구성해서 이것이 0을 포함하면 내치는 식의 방법도 있지만 일단은.) 따라서 다른 prior를 필요로 함. 바로 여기서 사용되는 것이 Spike-and-Slab prior. 이름에서 알 수 있듯이 mixture distribution을 prior로 사용함. \\(\\beta\\)의 component가 spike 부분에 포함되면 이를 0으로 판정함, 즉 not significant로 판정. 이의 역은 slab part. 이는 곧 prior로 variable selection을 한다는 이야기이다. 즉 이 상황에서는 prior가 패널티로 들어간 것이 된다. 정의적으로 엄밀하게 패널티는 아니지만 사실상의 패널티로 작동. 패널티 term (error penalty)으로 골라내는 것은 full context에서 많이 사용? 이때는 라플라스 프라이어를 쓰고, 노멀을 프라이어 주면? 패널티 텀을 베이지안 인퍼런스로 연결지어서 생각할 수 있지만, 이 배리어블 셀렉션은 디멘션 셀렉션과 연관이 있기 때문에 위와는 정확하게는 다른 개념? variable selection에는 3가지 방법: 1. 패널티 텀 2. mixture prior 3. 컴퓨테이셔널 (reversible jump, dimension selection) (gradient descent는 아님!) spike 파트 (아래에서는 \\((1-\\lambda)N(0, \\sigma^2)\\)) 에는 double exponential을 쓰거나, normal 을 변형해서 사용함. 혹은 극단적으로는 dirac 분포 (point mass) 를 쓸 수도 있음. 이하에서 예시로 제시된 수식은 SS prior이며, 이는 spike와 slab 모두 Normal을 사용하였음. $ () (1-)N(0, ^2) + N(0, ^2), ; ; ; ; ; w $ 위에서 \\(\\sigma^2\\)는 spike variance, \\(w \\sigma^2\\)는 slab variance. 여기서 \\(\\lambda\\)가 취할 수 있는 값은 0 아니면 1. 확인할 수 있듯이 1이면 slab part, 즉 significant하고, 0이면 역으로 not significant. 우리는 이에 MCMC 알고리즘을 적용하게 되며, 따라서 MCMC 샘플로 계산을 하면 해당 샘플에서 0인 propotion과 1인 비율이 나오게 될 것. 이때 1인 비율이 0.5 이상이면? 해당 component (변수) 는 significant 하다고 결론짓는 것이 가능하다. $ \\[\\begin{alignat}{3} \\pi(\\beta, \\lambda, \\sigma^2, \\omega \\vert y, x) &amp;\\sim \\pi(\\beta \\vert \\lambda, \\sigma^2, \\omega ) \\pi(\\lambda, \\sigma^2, \\omega) &amp;&amp; f(y \\vert x, \\beta, \\lambda, \\sigma^2, \\omega) \\\\ &amp;\\sim \\pi(\\beta \\vert \\lambda, \\sigma^2, \\omega ) \\pi(\\lambda, \\sigma^2, \\omega) &amp;&amp;L( x, \\beta, \\lambda, \\sigma^2, \\omega \\vert y) \\\\ \\\\ \\pi(\\lambda) &amp;\\sim BETA(1,1), \\; \\; \\; \\pi(\\sigma^2) \\sim \\cdot \\tag{1}, \\; \\; \\; \\omega \\sim 1 + GAM(\\alpha, \\beta) \\end{alignat}\\] $ 이때 \\(\\sigma^2\\)는 우리가 임의로 fixed 해서 given으로 잡거나, 위처럼 prior로 해서 시뮬레이션 중에 생산되도록 할수도 있다. 여기선 \\(\\dfrac{1}{U(4,100)}\\)을 사용. accept를 하기 위해선 위를 돌리면 됨. 이는 Stochastic Search Variable Selection (SSVS)라고 불림. 이는 GS를 통하여 패러미터를 sequentially update. 이의 결과값은 다음과 같으며, 프로세스는 그 다음과 같다. $ (_1 , , _p, _1, , _p, ^2, ) $ Proceeds: update model parameter \\(\\beta_i^{(t+1)} \\sim \\pi( \\beta_{i} \\vert y, x, \\beta_{-i}^{(t)}, \\lambda_{i}^{(t)}, {\\sigma^2}^{(t)}, \\omega^{(t)} )\\) where \\(\\beta_{-i}^{(t)} = \\left( \\beta_{1}^{(t+1)}, \\cdots, \\beta_{i-1}^{(t+1)}, \\beta_{i+1}^{(t)}, \\cdots, \\beta_{p}^{(t)} \\right)\\) Simple GS로도 가능하고, MH-within-Gibbs로도 가능함 update \\(\\lambda_I^{(t+1)} \\sim \\pi(\\lambda_i \\vert y, x, \\lambda_{-i}^{(t)}, \\beta_{i}^{(t+1)}, {\\sigma^2}^{(t)}, \\omega^{(t)} )\\) where $P( {i}^{(t+1)} = 1 y, x, {-i}^{(t)}, _{i}^{(t+1)}, {2}{(t)}, ^{(t)} )= {a+b} BER( {a+b} ) $. \\(a = \\pi( \\beta_{i}^{(t+1)} \\vert y, x, \\lambda_{i}^{(t+1)}=1, {\\sigma^2}^{(t)}, \\omega^{(t)} )\\). \\(b = \\pi( \\beta_{i}^{(t+1)} \\vert y, x, \\lambda_{i}^{(t+1)}=0, {\\sigma^2}^{(t)}, \\omega^{(t)} )\\), update \\(\\sigma^2\\) update \\(\\omega\\) 4.10.5.0.2 2. Horseshoe prior (Scale-mixture prior) distribution에서 scale이란 Variance. 위와 동일 케이스 가정. 그 경우 $ \\[\\begin{alignat}{4} \\pi(\\beta \\vert y, x) \\propto f(y \\vert x, \\beta) \\pi(\\beta), \\; \\; \\; \\; \\; &amp;\\pi(\\beta) &amp;&amp; \\sim N(0, \\sigma^2) \\\\ \\Longrightarrow &amp;\\pi(\\beta_i \\vert \\tau, \\lambda_i) &amp;&amp; \\sim N(0, \\tau^2 \\lambda_i^2) \\end{alignat}\\] $ where \\(pi(\\tau^2), \\pi(\\lambda_i^2) \\sim Cauchy^{+}(0,1)\\) 이때 common variance component \\(\\tau\\)는 각 component마다 공유하는 1개의 variance component, 그리고 각 component마다 indiviually 고유한 individual parameter variance component \\(\\lambda_i\\)를 설정한 것. 4.10.6 Autologistic model 4.10.7 wk10) Bayesian Model Averaging 해당 상황에서 연구자는 다양한 모델 예측 후보를 생각해볼 수 있음. 보통은 프로세스를 거쳐 이 모델들 중의 하나를 선택하게 됨. 하지만 완벽한 모델이라는 건 (보통) 존재할 수 없음, 어떤 모델 후보를 선택하든 해당 후보가 내포하고 있는 uncertainty가 존재하며 이를 수용하게 됨. 따라서 모델을 선택한다는 것은 동시에 over-confidence inference 문제를 발생시킨다. 따라서 모델 후보군을 하나만 골라야 한다는 고정관념을 벗어나 다양한 모델 후보군들 각각을 동시에 반영하자. 이 동시 반영할 때 각 모델이 내포하고 있는 확률 (uncertainty)에 의해 각 모델의 반영 정도를 가감하게 된다. BMA는 패러미터 estimate를 획득할 때, 이러한 model uncertainty를 설명하기 위한 일관된 메커니즘을 제공한다. given 데이터 \\(D\\), posterior prob of \\(\\mathcal{M}_k\\) \\(= P(\\mathcal{M}_k \\vert D) = \\dfrac{L(D \\vert \\mathcal{M}_k) P(\\mathcal{M}_k)}{\\sum_{k=1}^k L(D \\vert \\mathcal{M}_k) P(\\mathcal{M}_k)}\\). 이때 marginal likelihood under \\(\\mathcal{M}_k)\\) \\(L(D \\vert \\mathcal{M}_k) = \\int L(D \\vert \\theta \\mathcal{M}_k) \\pi(\\theta \\vert \\mathcal{M}_k) d \\theta\\)이며, integral 안의 수식은 posterior of model의 상수배 In brief, BMA는 model uncertainty를 설명할 수 있는 posterior density를 획득하기 위해 integral을 취한다 (model에 대해 마지널化). (각각의 모델에 대한 model uncertainty를 구한다) 이를 통해 최종적으로 posterior sample 같은 경우에는 각 모델 별로 model probability에 posterior sample의 probability를 다 더해준 값이 실제로 우리의 \\(\\theta\\)에 대한 post가 된다. 즉슨 BMA란 다양한 모델 후보군들이 존재할 때, 그 어떤 상황에서도 robust inference를 가능케 하는 tool이 바로 BMA. 4.10.7.0.1 Ex: BMA-CRM CRM 시작 전에 skeleton 정하고 시작하는 건 자명. 근데 이 skeleton이 잘못 선정되었다면 제대로된 도즈 selection이 불가능해지므로 skeleton의 선정이 잘못되어 있다면 이는 치명적임. 상식적으로, 하나의 skeleton으로만 도즈 셀렉션을 진행한다면 문제가 생길 확률은 당연히 높음. 이런 리스크를 희석하기 위해 skeleton을 다수를 정하고 CRM을 시작하면 이런 문제를 다소 회피할 수 있지 않을까? 이때 이 각각의 스켈레톤 하나하나를 모델로 인식한다. 이 각각의 모델에 따라서 CRM을, 즉 도즈레벨을 업데이트할 확률을, 즉 업데이트 할 때 패러미터 evaluation을 하는데, 그때 나오는 패러미터 값과 그 각각의 모델 probability를 비교하여 그 모델 averaging을 해주면 그 어떤 상황이 와도 굉장히 robust 한 값을 획득할 수 있을 것. Main research question Justification for your research question (why is it important to answer the question?) Data source Data analysis Summary of the data analysis results and conclusion Appendix (if needed) – R scripts (scripts or codes for any other software) 1 – Technical details regarding the statistical tools used in the analysis 비교적 오랜 기간 데이터가 잘 정립된 MLB 기록 활용을 위해 수업 시 활용하였던 Lahman package(R) 사용 야구는 공격과 수비로 이루어지며, 따라서 분석을 진행함에 있어 야구는 야구 스탯들 간에 상당한 수준의 선형성이 보장되어 이 타자의 가치 = α∗Batting+β∗Fielding, α,β는 임의의 패러미터 선수의 타격능력은 이른바 클래식 스탯으로 불리는 다양한 구형 통계량으로도 표기하는데 문제가 없지만, 수비능력은 선수별로 할당된 수비범위가 천차만별이며 선수가 수비시도를 하지 않으면 선수의 실책으로 이어지지 않는다는 점 때문에 선수 개별의 수비능력이 객관적으로 평가되기 시작한 것은 구장의 정보를 훨씬 자세하게 담을 수 있게 된 2000년대 중반부 이후부터의 이야기. 최신야구에서 선수 수비능력의 평가는 주로 Ultimate Zone Rating (UZR) 로 이루어지며, 해당 스탯은 ARM (달린거리), DPR (병살), RngR (수비커버리지), ErrR (에러빈도) 등 수비에 관련된 스탯을 총집합하여 망라하는 고밀도 스탯이다. 그러나 해당 스탯의 계산은 2002년 BIS (Baseball Info Solutions)라는 회사에서 제공하는 유료 데이터셋과 15년 도입된 스탯캐스트 데이터에 거의 전적으로 의존하고 있다. 스탯캐스트 데이터는 민간에 어느정도는 공개되어 있어 접근이 불가능하지 않지만 (https://baseballsavant.mlb.com/statcast_leaderboard), BIS 데이터는 접근이 어렵다. 이와 같은 이유로 선수별 수비 스탯을 구하기를 시도하기보단 팀별 수비력에 대한 척도인 Defensive Efficiency Ratio (DER)를 사용하고자 한다. 최대 12개의 팀인만큼 팀 간의 차이를 포착하기 쉬우며, 12개의 팀으로 표준화되니만큼 아웃라이어들이 평준화되어 전반적인 경향성으로 기능하는 것을 기대해볼 수 있다. DER의 수식은 다음과 같다. DER의 계산법은 이하와 같다. DER=1−(Hits+Reached.On.Error−HomeRunsPlate.Appearance−BB(Walks)−Strike.Out−Hit.By.Pitch−HomeRuns) Teams %&gt;% mutate(., DER = 1-((H + E - HR)/((AB + SF) - SO - HR))) %&gt;% ##select(., yearID, teamID, Rank, SO, SOA) select(.,yearID, teamID, franchID, Rank, G,DER) -&gt; Teams_DER 물론 같은 팀에 속했다는 이유만으로 모든 선수들에게 동급의 수비스탯을 배정하는 건 합리적이라고 말하기 어렵다. 팀의 수비에 기여하는 정도가 높은 선수가 있다면 낮은 선수도 있을 것이 자명하기 때문이다. 따라서 팀별로 획득한 DER을 수비에 대한 클래식 스탯인 각 선수의 Fielding Percentage(FPCT) 나 Range Factor(RF)의 비율로 스케일링해서 부여하자. 두 스탯은 각각 수비능력과 개인의 수비범위 평가를 위해 시도되었던 스탯들이지만, 전자는 개인의 수비범위가 좁으면 더 좋은 값이 나온다는 한계, 후자는 공이 본인 위치로 떨어졌을 때 스탯계산에서 이득을 본다는 한계를 넘지 못해 좋은 스탯으로는 평가받지 못했던 값들이다. 그러나 팀 단위로 한번 수비력을 표준화한 후 팀 내에서 상대적인 기여도를 보는 식으로 보정이 한 번 들어갔으므로 어느정도 기준선으로서는 기능할 것이라고 기대된다. 이를 위해 선수생활 중의 메인 수비포지션 지정하고 해당 포지션에서의 통계량만 사용. "],["mva.html", "Chapter 5 MVA ", " Chapter 5 MVA "],["overview-of-mva-not-ended.html", "5.1 Overview of mva (not ended)", " 5.1 Overview of mva (not ended) Find relationships b/w \\(\\pmb x_p, \\pmb y_q\\), e.g., * Response variables (variable directed) * PCA * Factor Analysis * mv Regression * Cannonical Correlation Analysis * Experiment units (individual directed) * Discriminant Analysis * Cluster Analysis * MANOVA Multivariate techniques tend to be exploratory. * i.e. not hypothesis testing type Experimental units must be independent. Time series data are not appropriate for this course. 5.1.1 Notation Variable \\(y_1 , \\cdots, y_p\\) One observation \\(\\pmb y &#39; = (y_1 , \\cdots, y_p )\\) Data Matrix \\(Y_{n \\times p} = \\begin{bmatrix} \\pmb y &#39; = (y_1 , \\cdots, y_p ) \\\\ \\vdots \\\\ \\pmb y &#39; = (y_1 , \\cdots, y_p ) \\end{bmatrix}\\) Random Samples: Suppose we intend to collect n sets of measurements on p variables, but not been observed yet. If $x_1 ‘, , x_n’ $ are independent observation from pdf \\(f(\\pmb x) = f(x_1, \\cdots, x_p)\\), then $x_1 ‘, , x_n’ $ are said to be rs from \\(f(\\pmb x)\\). rvec \\(\\pmb X = X_{p \\times n} = \\begin{bmatrix} \\pmb x_1 \\\\ \\vdots \\\\ \\pmb x_p \\end{bmatrix}\\) mean vector \\(\\pmb \\mu = E (\\pmb x) = \\begin{bmatrix} \\mu1 \\\\ \\vdots \\\\ \\mup \\end{bmatrix}\\) Covariance Matrix \\(\\Sigma\\) Correlation Matrix \\(\\rho\\), \\(\\rho_{ij} = \\tfrac{\\sigma_{ij}}{\\sigma_{ii}\\sigma_{jj}}\\) * Correlation measures linear association. * Correlation is 0 if symmetric non-linear association exists. 5.1.2 Summary Statistics Sample Mean Vector \\(\\bar X=\\) estimate of \\(\\pmb \\mu\\) Sample Covariance Matrix Sample Correlation Matrix 5.1.3 Statistical Inference on Correlation $ H_0: = 0 $ test stat \\(T=\\dfrac {r \\sqrt{n-2}}{\\sqrt{1-r^2}} \\sim t_{n-2}\\), where \\(r=Corr(x,y)\\) and \\(x \\sim N_2, y \\sim N_2\\) Notes: 1. Correlation measures a linear relationships 2. it is still difficult to get a CI for \\(\\rho\\). 5.1.3.0.1 CI for \\(\\rho\\) Fisher’s Method: \\(100(1-\\alpha)%\\) CI for \\(\\rho\\) $=((r) ) Ruben’s Method let \\(u=z_{\\alpha/2}, r^\\ast = \\dfrac {r}{\\sqrt{1-r^2}\\) $ \\[\\begin{align*} a &amp;= 2n-3-u^2 b &amp;= r^\\ast \\ast \\sqrt{(2n-3)(2n-5)} c &amp;= (2n-5-u^2} \\ast (r^\\ast)^2 - 2u^2 \\end{align*}\\] $ set \\(ay^2 - 2by +c =0\\), then root of this equation will be \\(y_1, y_2 = \\dfrac{b}{a} \\pm \\dfrac {\\sqrt{b^2-ac}}{a}\\). 이때 \\(100(1-\\alpha)%\\) CI for \\(\\rho\\) \\(=\\left[ \\dfrac{y_1}{\\sqrt{1+y_1^2}, \\dfrac{y_2}{\\sqrt{1+y_2^2}, \\right]\\) * 이때, input은 \\(n, \\alpha, r\\), output은 \\(\\rho\\)의 CI. 5.1.4 Standardization 5.1.5 Missing Value Treatment "],["multivariate-nomral-wk2.html", "5.2 Multivariate Nomral (wk2)", " 5.2 Multivariate Nomral (wk2) 5.2.1 Overview let rvec \\(Z=(Z_1 , \\cdots, Z_p)&#39;, Z_i \\overset {iid}{\\sim} N(0,1)\\). then \\(X=(X_1 , \\cdots, X_p)&#39; = A_{k \\times p} Z + \\pmb \\mu_{k \\times 1}\\) follows MVN. at here, if \\(rank(A)=p(\\le k), AA&#39; = \\Sigma\\), then \\(X \\sim N_p (0, \\Sigma)\\). notation: \\(\\pmb y \\sim N_p (\\pmb \\mu , \\Sigma)\\) rvec \\(\\pmb y &#39; = [y_1 , \\cdots , y_p ]\\) have Multivariate Normal Distribution, if \\(\\sum_{i=1}^p a_i y_u = \\pmb a&#39; y\\) has Univariate Normal Distribution, for every possible set of values for the elements in \\(\\pmb a\\). pdf for \\(f(\\pmb y) = \\dfrac{1}{(2\\pi)^p {\\vert \\Sigma \\vert}^{1/2}} \\exp \\left\\{ -\\dfrac{1}{2} (\\pmb y - \\pmb \\mu)&#39; \\Sigma^{-1} (\\pmb y - \\pmb \\mu) \\right\\}\\). Ellipsoid: - path of \\(\\pmb y\\) values yielding a constant height for the density, i.e., all \\(\\pmb y\\) s.t. \\(\\{ (\\pmb y - \\pmb \\mu)&#39; \\Sigma^{-1} (\\pmb y - \\pmb \\mu)=c^2 \\}\\). Standard Normal Distribtion: - \\(\\pmb z = \\left( {\\Sigma^{1/2}}\\right)^{-1} (\\pmb y -\\pmb \\mu) \\sim N_p (\\pmb 0, I_p)\\), where \\(\\left( {\\Sigma^{1/2}}\\right)^{-1}\\) satiesfy $ = ( {{1/2}}){-1} ( {{1/2}}){-1}$. Property of \\(\\Sigma\\): 1. symmetric Matrix 2. positive definite Matrix 3. $Cov(A y + b) = A A’ $. ※ if \\(A\\) is symmetric and non-singular, then \\(A=CC&#39;\\), where \\(C\\) is lower triangular Matrix. This is called Cholesky Decomposition of \\(A\\). \\(E(X)=\\mu, Cov(X)=AA&#39; = \\Sigma\\) \\(M_X (t) = \\exp (t&#39; \\mu + \\dfrac {1}{2} t&#39; \\Sigma t\\) if \\(\\Sigma=AA&#39;\\) is non-singular Matrix \\(\\iff rank(A)=p\\) \\(\\Sigma = Cov(X)\\)는 symmetric, n.n.d. 이상의 \\(X\\)에 대해 이하는 TFAE. 1. \\(X \\sim N_p (0, \\Sigma)\\). 2. 3. 4. 5. 5.2.2 Spectral Decomposition if \\(A\\) is symmetric, non-singular, then \\(A=E \\Lambda E&#39;\\), where \\(\\lambda_i\\) are ev (\\(\\lambda_1 \\ge \\cdots \\ge \\lambda_n\\)), and \\(\\pmb e_i\\) are evec (\\(E&#39;E = I_p)\\). This is called Spectral Decomposition of \\(A\\). $ = \\[\\begin{bmatrix} \\lambda_1 &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; &amp; \\lambda_n \\end{bmatrix}\\] , ; ; ; ; ; E= $ 이때 \\(\\Sigma = E \\Lambda E&#39; = E \\Lambda \\Lambda^{1/2} E&#39; = E \\Lambda E&#39; E \\Lambda^{1/2} E&#39; = \\Sigma^{1/2} \\Sigma^{1/2}\\). Center &amp; Axis of ellipsoids of \\(\\{ (\\pmb y - \\mu)&#39; \\Sigma^{-1} (\\pmb y - \\mu)=c^2 \\}\\): * center: \\(\\pmb \\mu\\) * axis : \\(\\pm c \\sqrt{\\lambda_i \\pmb e_i}\\) Square root Matrix: let symmetric non-negative Matrix \\(A_{p \\times p}\\). the square root matrix of \\(A\\) is defined as \\(A^{1/2} = E \\Lambda^{1/2} E&#39;\\), where $ ^{1/2} = \\[\\begin{bmatrix} \\sqrt{\\lambda_1} &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; &amp; \\sqrt{\\lambda_n } \\end{bmatrix}\\] $ Negative Square Root Matrix: Let \\(A\\) be of full rank and all of its \\(\\lambda_i\\) are positive, in addition to symmetry. \\(A^{-1/2} = E \\Lambda^{-1/2} E&#39;\\), where $ ^{-1/2} = \\[\\begin{bmatrix} \\dfrac{1}{\\sqrt{\\lambda_1}} &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; &amp; \\dfrac{1}{\\sqrt{\\lambda_n }} \\end{bmatrix}\\] $ Generalized Inverse: let \\(A\\) be a non-negative M. if \\(\\lambda_1&gt; \\lambda_2 &gt; \\cdots &gt; \\lambda_r &gt; 0 = \\lambda_{r+1} = \\cdots = \\lambda_{p}\\), i.e., not full rank, then the Moore-Penrose generalized inverse of \\(A\\) is given by $ A^{-} = e_1 e_1 ’ + + e_r e_r ’ $ where $ ^{-} = \\[\\begin{bmatrix} \\dfrac{1}{\\lambda_1} &amp; &amp; &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; &amp; &amp; \\\\ &amp; &amp; \\dfrac{1}{\\lambda_n } &amp; &amp; &amp; \\\\ &amp; &amp; &amp; 0 &amp; &amp; \\\\ &amp; &amp; &amp; &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; &amp; &amp; &amp; &amp; 0 \\\\ \\end{bmatrix}\\] $ Marginal Distribtion: $ \\[\\begin{align*} \\pmb y \\sim N_p (\\pmb \\mu , \\Sigma) &amp;\\Longrightarrow y_i \\sim N(\\mu_i, \\sigma^{ii}), \\; \\; \\; i= 1, \\cdots, p \\\\ &amp;\\not \\Longleftarrow \\end{align*}\\] $ 5.2.3 Properties of MVN linear combination of the components of \\(\\pmb y\\) are normally distributed. any subset of \\(\\pmb y\\) have MVN. conditional distribution of the components of \\(\\pmb y\\) are MVN: $ y N_p(, ) a ’ y N( a ’ , a ’ a ) $ $ y N_p(, ) , ; ; A_{n times p} = \\[\\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1p} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; \\cdots &amp; a_{np} \\end{bmatrix}\\] A y N_n(A , A A’) $ 즉슨 dimension 변화 if $ y N_p(, )$, and cvec \\(\\pmb d\\), then $ y + d N_p(+ d , )$. If we partition y, μ, S ! ! as follows Let 1 11 2 ~ ( , ) p y y N y μ é ù ê ú = ê ú S ê ú ë û !\" ! ! ! with 5.2.4 \\(\\Chi^2\\) distribution if \\(\\pmb z \\sim N_p ( \\pmb 0 , I_p )\\), then \\(\\pmb z &#39; \\pmb z = \\sum_{i=1}^p z_i^2 \\sim \\Chi_p^2\\). if $ y N_p(, )$, then $(y - )’ ^{-1} (y - ) _p^2 $ the \\(N_p(\\pmb \\mu , \\Sigma)\\) distribution assigns probability \\(1-\\alpha\\) to the solid ellipsoid \\(\\left \\{ \\pmb y : (\\pmb y - \\pmb \\mu)&#39; \\Sigma^{-1} (\\pmb y - \\pmb \\mu) \\le \\chi_p^2 (\\alpha) \\right \\}\\), where \\(\\chi_p^2 (\\alpha)\\) denotes upper \\((100 \\ast \\alpha)\\) th percentile of the \\(\\chi_p^2\\) distribution. 5.2.5 Linear Combination of Random Vectors 5.2.6 Multivariate Normal Likelihood 5.2.7 Sampling Distribtion of \\(\\bar {\\pmb y}, S\\) let rvec $ y_1, y_n N_p(, )$. \\(\\bar {\\pmb y} \\sim N_p (\\pmb \\mu , \\dfrac{1}{n} \\Sigma)\\) (n-1) S $ Wishart distribution, with \\(df=n-1\\) * \\(S\\) is random Matrix, e.g., Wishart is distribution of rM. \\(\\bar {\\pmb y} \\perp S\\). 5.2.7.0.1 Wishart Distribtion ※ \\(\\dfrac {\\sum (x_i - \\barx )^2}{\\sigma^2} = \\dfrac {S^2} {\\dfrac{\\sigma^2}{n-1}} \\sim \\chi_{n-1}^2\\), i.e., \\(\\sum (x_i - \\barx )^2 = (n-1)S^2 \\sim \\sigma^2 \\ast \\chi_{n-1}^\\) for let rvec $ y_1, y_n N_p(, )$, $ \\[\\begin{align*} \\sum_{i=1}^n(\\pmb y - \\pmb \\mu)(\\pmb y - \\pmb \\mu)&#39; &amp;\\sim W_p (n, \\Sigma) \\\\ \\\\ (n-1)S^2 = \\sum_{i=1}^n(\\pmb y - \\bar {\\pmb y} )(\\pmb y - \\bar {\\pmb y} )&#39; &amp;\\sim W_p (n-1, \\Sigma) \\end{align*}\\] $ if \\(A \\sim W_p (n, \\Sigma), B \\sim W_p (m, \\Sigma)\\), and \\(A \\perp B:\\) \\(A+B \\sim W_p (n+m, \\Sigma)\\) if \\(A \\sim W_p (n, \\Sigma)\\), then \\(CAC&#39; \\sim W_p (n, C \\Sigma C&#39;)\\) if \\(A \\sim W_p (n-1, \\Sigma)\\), \\(f(A)\\), where gamma function. 5.2.7.0.2 MV t-Distribtion ※ univariate t-Distribtion \\(t=\\tfrac{\\tfrac{U}{\\sigma}}{\\sqrt{\\tfrac{V}{nu}}} \\sim t_{\\nu}\\), where \\(U \\sim N(0, \\sigma^2), V \\sim \\chi_{\\nu}^2\\), and \\(U \\perp V\\). let $ y = (y_1, , y_n)’ N_p(, )$, and \\(V \\sim \\chi_{\\nu}^2\\), and \\(\\pmb y \\perp V\\). assume rvec \\(\\pmb t = (t_1 , \\cdots, t_p)&#39;\\),\\(t_i = \\tfrac {\\tfrac{y_i - \\mu_I}{\\sigma_i}{\\sqrt{V/\\nu}}, i=1, \\cdots, p\\) * Note that each \\(t_i \\sim t\\). at here, joint distribution of \\(\\pmb t\\) is called MV t-distribution, with \\(df=\\nu\\) and matrix parameter \\(\\Sigma\\). denote this distribution by 5.2.7.0.3 Dirichlet Distribution ※ is MV generalization of \\(BETA\\). let $ y D_p(1 , {p+1})$ * parameters: \\(\\{\\nu_i, i=1, \\cdots, p+1\\}\\) * pdf: f(y) = _{i=1}^p y_i^{v_i - 1}$ ????????????????????????????????????????????????? 5.2.7.0.4 CLT let $ y_1 , , y_n {} , &lt; $. then $ \\[\\begin{align*} \\sqrt {n} (\\hat {\\pmb y} - \\pmb \\mu) &amp;\\overset {d} {\\rightarrow} N_p (\\pmb 0 , \\Sigma) \\\\ n (\\hat {\\pmb y} - \\pmb \\mu)&#39; S^{-1} (\\hat {\\pmb y} - \\pmb \\mu) &amp;\\overset {d} {\\rightarrow} \\chi_p^2 \\end{align*}\\] $ 5.2.8 Assessing Normality 5.2.8.0.1 1. Univariate Marginal Distribtion 5.2.8.0.1.1 a. Q-Q Plot ※ Sample quantile vs. quantile of N distribution let order statitics, or sample quantiles \\(x_{(1)} \\le \\cdots \\le x_{(n)}\\). the proportion of sample below \\(x_{(j)}\\) is approximated by \\(\\tfrac{j-\\tfrac{1}{2}}{n}\\). the quantiles \\(q_{(j)}\\) for std. N are defined as $ P(z q_{j)}) = {-}^{q{(j)}} ( - z^2 ) dz $ if the data arise from a N population, then \\((\\sigma \\ast q_{(j)} + \\mu \\congruent x_{(j)}\\). Similarly, the pairs \\((q_{(j)}, x_{(j)})\\) will be linearly related. Proceeds: 1. get \\(x_{(1)} \\le \\cdots \\le x_{(n)}\\) from original obs. 2. calculate probability values \\(\\tfrac{j-1/2}{n}, \\; \\; j= 1, \\cdots, n\\) 3. calculate standard normal quantities \\(q_{(1)}, \\cdots, q_{(n)}\\) 4. plot the pairs of observations $(q_{(1)}, x_{(1)}), , \\((q_{(n)}, x_{(n)})\\) Checking the straightness of Q-Q plot: * using corr coef * Hypothesis tesiting: \\(H_0: \\rho=0\\), $T= t_{n-2} 5.2.8.0.1.2 b. others Shapiro-Wilks Test: Test of correlation coefficient b/w \\(x_{(j)}, r_{(j)}\\). \\(r_{(j)}\\) is function of the expected value of standard normal order statistics, and their \\(Cov\\). Kolmogorov-Smirnov Test Compare cdf’s: If the data arise from a normal population, the differences are small. $ T = _x F(x) - S(x) $ where cdf \\(F(x)\\), empirical cdf \\(S(x)\\). Skewness Test skewness \\(\\sqrt{b_1} = \\tfrac{\\sqrt{n} \\sum_{i=1}^n (x_i - \\bar x)^3} {\\left[ \\sum_{i=1}^n (x_i - \\bar x)^2 \\right]^{\\tfrac{3}{2}}}\\) When the population is normal, the skewness = 0. Kurtosis Test: kurtosis \\({b_2} = \\tfrac{n \\sum_{i=1}^n (x_i - \\bar x)^4} {\\left[ \\sum_{i=1}^n (x_i - \\bar x)^2 \\right]^{3}}\\) When the population is normal, the kurtosis is 3. Lin and Mudholkar (1980): $ Z = ^{-1}(r) = ( ) $ where \\(r\\) is the sample \\(corr\\) of \\(n\\) pair \\((x_i , q_i), \\; \\; i=1, \\cdots, n\\) with \\(q_i = \\tfrac {1}{n} \\left( \\sum_{i \\not = j} x_j^2 - \\tfrac{1}{n-1} \\left( \\sum_{i \\not = j} x_j\\right)^2 \\right)^{\\tfrac{1}{3}}\\). if the data arise from a normal population, \\(Z \\sim N(0, \\tfrac 3 n)\\). 5.2.8.0.2 2. Bivariate Normality ※ If the data are generated from a multivariate normal, each bivariate distribution would be normal. Scatter Plot the contours of bivariate normal density are ellipses. The pattern of the scatter plot must be near elliptical. Squared Generalized Distances ※ \\(\\pmb y \\sim N_p (\\pmb \\mu, \\Sigma) \\; \\; \\; \\Longrightarrow \\; \\; \\; (\\pmb y - \\pmb \\mu)&#39; \\Sigma^{-1} (\\pmb y - \\pmb \\mu) \\sim \\chi_p^2\\). it means, for bivariate cases, Squared Generalized Distances \\(d_j^2 = (\\pmb x_j - \\hat {\\pmb x})&#39; S^{-1} (\\pmb x_j - \\hat {\\pmb x}) \\sim \\chi_2^2\\). Chi2 Plot (Gamma Plot) \\(d_1^2 , \\cdots, d_n^2\\) should behave like \\(\\chi_2^2\\) rv. 1. order the squared distances \\(d_{(1)}^2 \\le \\cdots \\le d_{(n)}^2\\) 2. calculate the probabilitt values \\(\\tfrac{j-1/2}{n}\\), \\(j=1,\\cdots, n\\) 3. Calculate quantiles of \\(\\chi_2^2\\) distribution \\(q_{(1)}, \\cdots, q_{(n)}\\). 4. Plot the pairs \\((q_{(j)}, d_{(j)}^2 ), \\; \\; j=1, \\cdots, n\\) where \\(q_{(j)} = \\chi_2^2 \\left( \\tfrac{j-1/2}{n} \\right)\\) The plot should resemble a straight line through the origin having slope 1. 5.2.8.0.3 2. Multivariate Normality Practically, it is usually sufficient to investigate the univariate and bivariate distributions. Chi-square plot is still useful. When the parent population is multivariate normal, and both \\(n\\) and \\(n-p\\) are greater than 25 or 30, the squared generalized distance \\(d_{1}^2 \\le \\cdots \\le d_{n}^2\\) should behave like \\(\\chi_p^2\\). 5.2.9 Power Transformation $ x^= \\[\\begin{cases} \\tfrac{1}{x}, &amp; \\lambda = -1 \\tag{\\text{Reciprocal Transformation}}\\\\ \\tfrac{1}{\\sqrt{x}}, &amp; \\lambda = -\\tfrac{1}{2} \\\\ \\ln(x), &amp; \\lambda = 0 \\\\ \\sqrt{x}, &amp; \\lambda = \\tfrac{1}{2} \\\\ x, &amp; \\lambda = 1 \\tag{\\text{No Transformation}} \\end{cases}\\] $ Examine Q-Q plot to see whether the normal assumption is satisfactory after power transformation. 5.2.9.0.1 Power Transformation $ x^() = \\[\\begin{cases} \\tfrac{x^\\lambda - 1}{\\lambda}, &amp; \\lambda \\not = 0 \\\\ \\ln(x), &amp; \\lambda = 0 \\end{cases}\\] $ at here, find \\(\\lambda\\) that maximizes $ l() = - ln+ () _{j=1}^n x_j $ where \\(\\hat{x_j}^{(\\lambda)} = \\tfrac{1}{n} \\sum_{j=1}^n x_j^{(\\lambda)}\\) x^{()} is the most feasible values for normal distribution, but not guaranteed to follow normal distribution. * Transformation (Box-Cox) usually improves the approximation to normality. * Trial-and-error calculations may be necessary to find \\(\\lambda\\) that maximizes \\(l(\\lambda)\\) * Usually, change \\(\\lambda\\) values from -1 to 1 with increment 0.1. * Examine Q-Q plot after the Box-Cox transformation. 5.2.9.0.2 nqplot, contour plot, cqplot, cqplot and box-cox plot "],["inference-about-mean-vector-wk3.html", "5.3 Inference about Mean Vector (wk3)", " 5.3 Inference about Mean Vector (wk3) 5.3.1 Overview Recall: univariate case \\(x_1 , \\cdots, x_n \\overset {iid} {\\sim} N(\\mu, \\sigma^2)\\) \\(H_0 : \\mu = \\mu_0\\) $ \\[\\begin{alignat*}{2} \\text{test stat } &amp;t &amp;&amp;=\\tfrac{\\bar X - \\mu_0}{\\tfrac{S}{\\sqrt{n}}} &amp;\\overset{H_0}{\\sim} t_{n-1} \\\\ &amp;t^2 &amp;&amp;=\\tfrac{(\\bar X - \\mu_0)^2}{\\tfrac{S^2}{n}} &amp;\\overset{H_0}{\\sim} F_{1, \\; n-1} \\end{alignat*}\\] $ reject \\(H_0\\) if as below, which means upper \\((100-\\alpha)\\)th percentile. $ \\[\\begin{alignat*}{1} \\tfrac{(\\bar X - \\mu_0)^2}{\\tfrac{S^2}{n}} = n(\\bar X - \\mu_0)\\tfrac{1}{S^2}(\\bar X - \\mu_0) &amp;&gt; F_{1,n-1}(\\alpha) \\end{alignat*}\\] $ therefore, with assumption \\(\\pmb X_1 , \\cdots, \\pmb X_n \\overset {iid} {\\sim} N_p (\\pmb \\mu , \\Sigma)\\), $ H_0 : = _0 $ $ \\[\\begin{alignat*}{3} \\text{Hotelling&#39;s }T^2 \\; \\; T^2 &amp;= n(\\bar {\\pmb X} - \\pmb \\mu_0)&#39; S^{-1} (\\bar {\\pmb X} - \\pmb \\mu_0) \\\\ &amp;\\overset{H_0}{\\sim} \\tfrac{(n-1)p}{(n-p)} F_{p,n-p} \\\\ \\iff \\; \\; \\tfrac {(n-p)} {(n-1)p} T^2 &amp;\\overset{H_0}{\\sim} F_{p,n-p} \\end{alignat*}\\] $ reject \\(H_0\\), if \\(T^2 &gt; \\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\\alpha)\\). assumption check: \\(\\pmb X_1 , \\cdots, \\pmb X_n \\overset{iid}{\\sim} N_p (\\pmb \\mu , \\Sigma)\\). 5.3.1.0.1 Remark stat \\(T^2\\)는 측정 단위에 invariant. proof) let $Y_{p } = C_{p p} X_{p } + d_{p } $. then $ \\[\\begin{align*} \\bar {\\pmb Y} &amp;= C \\bar {\\pmb X} + \\pmb d \\\\ \\\\ S_{\\pmb y} &amp;= CSC&#39;\\\\ \\\\ \\mu_y &amp;= E(\\pmb Y) \\\\ &amp;=C \\ast E(\\pmb X) + \\pmb d \\\\ &amp;= C \\pmb \\mu_0 + \\pmb d \\end{align*}\\] $ therefore, $ \\[\\begin{align*} T^2 &amp;= n(\\bar {\\pmb Y} - \\pmb \\mu_y)&#39; S_y^{-1} (\\bar {\\pmb Y} - \\pmb \\mu_y) \\\\ &amp;= n \\left[ C(\\bar {\\pmb X} - \\pmb \\mu_0) \\right]&#39; (CSC&#39;)^{-1} \\left[ C(\\bar {\\pmb X} - \\pmb \\mu_0) \\right] \\\\ &amp;= n (\\bar {\\pmb X} - \\pmb \\mu_0)&#39; C&#39; (C&#39;)^{-1} S^{-1}(C)^{-1} C(\\bar {\\pmb X} - \\pmb \\mu_0) \\\\ &amp;= n (\\bar {\\pmb X} - \\pmb \\mu_0)&#39; S^{-1}(\\bar {\\pmb X} - \\pmb \\mu_0) \\end{align*}\\] $ 여기서 \\(C^{-1}\\)이 존재한다는게 뭔수로 보장되는거지? 5.3.2 1. Confidence Region 5.3.2.0.1 Confidence Region region \\(R(\\pmb X)\\), is $100(1-) % $ CR of $ \\[\\begin{alignat*}{3} &amp;P \\left\\{ R(\\pmb X) \\text{ will cover the true } \\pmb \\theta \\right\\} &amp;&amp;= 1-\\alpha \\\\ &amp;P \\left\\{ n (\\hat {\\pmb X} - \\pmb \\mu)&#39; S^{-1}(\\hat {\\pmb X} - \\pmb \\mu) \\le \\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\\alpha) \\right\\} &amp;&amp;= \\end{alignat*}\\] $ the inequality \\(n (\\bar {\\pmb X} - \\pmb \\mu)&#39; S^{-1}(\\bar {\\pmb X} - \\pmb \\mu) \\le \\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\\alpha)\\) will define a region \\(R(\\pmb X)\\). The region is an ellipsoid centered at \\(\\bar {\\pmb X}\\). Testing \\(H_0 : \\mu = \\mu_0\\) at \\(\\alpha =.05\\) is equivalent to see whether \\(\\mu_0\\) falls within the CR. with ev \\(\\lambda_1 , \\cdots, \\lambda_p\\), evec \\(\\pmb e_1 , \\cdots, \\pmb e_p\\) of \\(S\\), CR Axis: \\(\\pm \\sqrt{\\lambda}\\sqrt{\\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\\alpha)} \\ast \\pmb e_i&#39;\\) CR half-length: $ $ 5.3.3 2. Simultaneous CI let \\(\\pmb X \\sim N_p (\\pmb \\mu, \\Sigma)\\), then linear combination \\(\\pmb a&#39; \\pmb X \\sim N_p (\\pmb a&#39; \\pmb \\mu, \\pmb a&#39; \\Sigma \\pmb a)\\) $ \\[\\begin{align*} t=\\dfrac{\\bar X - \\mu} {S / \\sqrt{n}} &amp;\\sim t_{n-1} \\tag{recall: univariate}\\\\ t= \\dfrac {\\pmb a &#39; \\bar X - \\pmb a &#39; \\pmb \\mu} {\\sqrt{\\pmb a &#39; S \\pmb a / n } } = \\dfrac {\\sqrt{n}(\\pmb a &#39; \\bar X - \\pmb a &#39; \\pmb \\mu)} {\\sqrt{\\pmb a &#39; S \\pmb a} } &amp;\\sim t_{n-1} \\tag{MV} \\end{align*}\\] $ therefore, \\(100(1-\\alpha)\\%\\) CI for \\(\\pmb a &#39; \\mu\\) (at here, \\(\\pmb a\\)is fixed) is \\(\\pmb a &#39; \\bar {\\pmb X} \\pm t_{n-1} \\dfrac {\\alpha} {2} \\dfrac{\\sqrt{\\pmb a &#39; S \\pmb a} } {\\sqrt{n}}\\). This is not a simultaneous CI. let each \\((a_1 , a_2), (b_1, b_2)\\) be CI for \\(\\mu_1 , \\mu_2\\). then simultaneous CI \\((a_1 , a_2), (b_1, b_2)\\) has confidence \\(95\\% \\ast 95\\% = 90.25\\%\\). need a wider interval. let rs \\(\\pmb X_1 , \\cdots, \\pmb X_n \\overset {iid} {\\sim} N_p (\\pmb \\mu , \\Sigma)\\). then, simultaneously for all \\(\\pmb a\\), the interval \\(\\pmb a &#39; \\bar {\\pmb X} \\pm \\sqrt{\\dfrac{n-1}{n} \\dfrac{p}{n-p} F_{p,n-p} (\\alpha) \\pmb a &#39; S \\pmb a}\\) will contain \\(\\pmb a &#39; \\pmb \\mu\\) with probability \\(1-\\alpha\\). $ \\[\\begin{alignat*}{3} \\because 1-\\alpha &amp;= P \\left[ n (\\bar {\\pmb X } - \\pmb \\mu)&#39; S^{-1} (\\bar {\\pmb X } - \\pmb \\mu) \\le (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\right] \\\\ &amp;= P \\left[ (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu)&#39; (\\pmb a&#39; S \\pmb a)^{-1} (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu) \\le \\dfrac{1}{n} (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\right] \\\\ &amp;= P \\left[ (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu)&#39; (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu) \\le \\dfrac{1}{n} (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\; \\ast \\; (\\pmb a&#39; S \\pmb a) \\right] \\tag{∵ Scalar} \\\\ &amp;= P \\left[ (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu)^2 \\le \\dfrac{1}{n} (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\; \\ast \\; (\\pmb a&#39; S \\pmb a) \\right] \\\\ &amp;= P \\left[ - \\sqrt{\\dfrac{1}{n} (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\; \\ast \\; (\\pmb a&#39; S \\pmb a)} \\le (\\pmb a&#39; \\bar {\\pmb X } - \\pmb a&#39; \\pmb \\mu) \\le \\sqrt{\\dfrac{1}{n} (n-1) \\dfrac {p}{n-p} F_{p,n-p} (\\alpha) \\; \\ast \\; (\\pmb a&#39; S \\pmb a)} \\right] \\end{alignat*}\\] $ 5.3.3.0.1 Simultaneous CI for \\(\\mu_i - \\mu_k\\) let \\(\\pmb a &#39; = [0,\\cdots, 0, a_i, 0, \\cdots, 0, a_k, 0, \\cdots, 0]\\). then as below, where \\(S =\\begin{bmatrix} S_{11} &amp; \\cdots &amp;S_{1p} \\\\ &amp; \\ddots &amp; \\\\ S_{p1} &amp; \\cdots &amp; S_{pp} \\end{bmatrix}\\). $ \\[\\begin{align*} \\pmb a &#39; \\pmb \\mu &amp;= \\mu_i - \\mu_k \\\\ \\pmb a &#39; S \\pmb a =S_{ii} -2 S_{ik} + S_kk \\end{align*}\\] $ therefore, the simultaneous CI for \\(\\mu_i - \\mu_k\\), is \\((\\bar x_i - \\bar x_k ) \\pm \\sqrt{\\dfrac{n-1}{n} \\dfrac{p}{n-p} F_{p, n-p}(\\alpha)S_{ii} -2 S_{ik} + S_kk}\\). at here, if we let \\(\\pmb a &#39; = [1, 0, \\cdots, 0]\\). then $ \\[\\begin{align*} \\pmb a &#39; \\pmb \\mu &amp;= \\mu_1\\\\ \\pmb a &#39; S \\pmb a =S_{11} \\end{align*}\\] $ therefore, the simultaneous CI for $_1 $, is \\(\\bar x_1 \\pm \\sqrt{\\dfrac{n-1}{n} \\dfrac{p}{n-p} F_{p, n-p}(\\alpha)S_{11}}\\). 5.3.4 3. Note: Bonferroni Multiple Comparison Bonferroni’s CI, \\(\\bar x_1 \\pm \\left\\{ t_{n-1} \\left( \\dfrac{\\alpha}{2p} \\right) \\right\\} \\sqrt{\\dfrac{S_11}{n}}\\), is more precise (narrower) than simultaneous CI. 5.3.5 4. Large Sample Inferences about a Mean Vector Recall mv CLT: let \\(\\pmb X_1 , \\cdots, \\pmb X_n {\\sim} ?(\\pmb \\mu, \\Sigma)\\) and for \\(n-p\\) large. then $ \\[\\begin{align*} \\sqrt{n} (\\bar {\\pmb X} - \\pmb \\mu) &amp;\\overset {d}{\\Longrightarrow} N_p (\\pmb 0, \\Sigma) \\\\ n (\\bar {\\pmb X} - \\pmb \\mu)&#39; S^{-1}(\\bar {\\pmb X} - \\pmb \\mu) &amp;\\overset {d}{\\Longrightarrow} \\chi^2_p \\end{align*}\\] $ when the sample size is large, the MVN assumption is less critical. therefore, let \\(\\pmb X_1 , \\cdots, \\pmb X_n {\\sim} ?(\\pmb \\mu, \\Sigma)\\). $ H_0: = _0 $ when \\(n-p\\) is large, the \\(H_0\\) is rejected if \\(n (\\bar {\\pmb X} - \\pmb \\mu)&#39; S^{-1}(\\bar {\\pmb X} - \\pmb \\mu) &gt; \\chi^2_p (\\alpha)\\). Note: \\((n-1) \\dfrac{p}{n-p} F_{p,n-p} )\\alpha \\simeq \\chi_p^2(\\alpha)\\), for large \\(n-p\\). CI: $ P = 1- $ the inequality $ n ({X } - )’ S^{-1} ({X } - ) _p^2 () $ will define a region, which means, \\(100(1-\\alpha) \\%\\) region. Simultaneous CI: let \\(\\pmb X_1 , \\cdots, \\pmb X_n {\\sim} ?(\\pmb \\mu, \\Sigma)\\) and for \\(n-p\\) large. then \\(\\forall \\pmb a\\), \\(100(1-\\alpha) \\%\\) simultaneous CI for \\(\\pmb a &#39; \\pmb \\mu\\) \\(= \\pmb a &#39; \\bar {\\pmb X} \\pm \\sqrt{ \\chi_p^2 (\\alpha)} \\sqrt{ \\dfrac{\\pmb a &#39; S \\pmb a} {n}}\\). Simultaneous CI for \\(\\mu_i\\) $ x_i $ Bonferroni’s CI for \\(\\mu_i\\) $ x_i z_{} $ - Bonferroni’s CI is more precise. as also. 5.3.6 1. Profile Analysis (wk4, 5) if \\(\\pmb X \\sim N_p (\\pmb \\mu, \\Sigma)\\), and the variables in \\(\\pmb X\\) are measured in the same unit, we may with to compare the means \\(\\mu_1 , \\cdots, \\mu_p\\) in \\(\\pmb \\mu\\). ex) repeated measure: a measurement is taken at the same experimental unit \\(p\\) successive times. A profile is a plot, connecting \\((i, \\mu_i), i= 1, \\cdots, p\\) Question: is the profile flat? $ \\[\\begin{align*} &amp;H_0: \\mu_1 = \\cdots = \\mu_p \\\\ \\iff &amp;H_0: C_1 \\pmb \\mu = \\pmb 0 , \\left[ C_1\\right]_{(p-1) \\times p} \\\\ \\iff &amp;H_0: C_2 \\pmb \\mu = \\pmb 0 , \\left[ C_2\\right]_{(p-1) \\times p} \\end{align*}\\] $ if \\(\\pmb X \\sim N_p (\\pmb \\mu, \\Sigma)\\), then \\(C \\pmb X \\sim N_{p-1} (C \\pmb \\mu, C \\Sigma C&#39;)\\), thus when \\(H_0 : C \\pmb \\mu = 0\\) is true, then \\(C \\bar X \\sim N_{p-1} (C \\pmb \\mu, C \\Sigma C&#39;)\\). test stat \\(T^2 = n (C \\bar {\\pmb X})&#39; (C S C&#39;)^{-1} (C \\bar {\\pmb X}) \\overset{H_0}{\\sim} (n-1) \\dfrac{p-1}{n-p+1} F_{p-1,n-p+1}\\) reject \\(H_0\\), if \\(T^2 &gt; (n-1) \\dfrac{p-1}{n-p+1} F_{p-1,n-p+1} (\\alpha)\\). **Note: \\(C_{(p-1) \\times p}\\) is not square, so there’s no inverse. thus \\(C\\) in test stat doesn’t be canceled. $ H_0 : C = 0 $ where \\(C_{q \\times p} (q \\le p)\\), and \\(rank(C)=q\\). then test stat \\(T^2 = n (C \\bar {\\pmb X})&#39; (C S C&#39;)^{-1} (C \\bar {\\pmb X}) \\overset{H_0}{\\sim} (n-1) \\dfrac{q}{n-q} F_{q,n-q}\\) which means \\(p-1\\) become \\(q\\). 5.3.7 2. Test for Linear Trend suppose \\(p\\) variables are measured across equally spaced time periods. Also suppose \\(H_0 : \\mu_1 = \\cdots = \\mu_p\\) is rejected. Question: Do the means fall onto a straight line? $ \\[\\begin{align*} &amp;H_0: \\mu_2-\\mu_1 = \\cdots = \\mu_p-\\mu_{p-1} \\\\ \\iff &amp;H_0: \\mu_3 -2 \\mu_2+\\mu_1 = 0, \\; \\; \\cdots, \\; \\; \\mu_p - 2 \\mu_{p-1} + \\mu_{p-2} = 0 \\\\ \\iff C_{(p-2) \\times p}, &amp;H_0: C \\pmb \\mu = \\pmb 0 \\end{align*}\\] $ at here, we acquire test stat \\(T^2 \\overset {H_0} {\\sim} (n-1) \\dfrac{p-2}{n-p+2} F_{p-2,n-p+2}\\). 5.3.8 3. Inferences about a Covariance Matrix let rs \\(\\pmb X_1 , \\cdots, \\pmb X_n \\overset {iid} {\\sim} N_p (\\pmb \\mu , \\Sigma)\\). $ H_0 : = _0 $ let \\(W = (n-1)S = \\sum_{i=1}^n (\\pmb X_i - \\bar {\\pmb X})(\\pmb X_i - \\bar {\\pmb X})&#39;\\). then $ ^ = ( )^{} _0^{-1} W ^{} , ; ; ; ; ; ; ; v=n-1 $ then calculate \\(L=-2 ln \\Lambda^\\ast \\; \\; \\; \\; \\; \\; \\; \\overset {H_0}{\\sim}\\) function of \\(\\chi^2\\)-distribution. Test for Sphericity (Test for no Correlation) $ H_0 : = ^2 I $ $ = $ function of \\(\\chi^2\\)-distribution. Test for Compound Symmetry if \\(\\Sigma = \\begin{bmatrix} \\sigma^2 &amp; \\rho &amp; \\cdots &amp; \\rho \\\\\\rho &amp; \\sigma^2 &amp; &amp; \\vdots \\\\ \\vdots &amp; \\rho &amp; \\ddots &amp; \\rho \\\\ \\rho &amp; \\cdots &amp; \\rho &amp; \\sigma^2 \\\\ \\end{bmatrix}\\), then \\(\\Sigma\\) has compound symmetry. $ H_0: $ Compute \\(\\Lambda = \\dfrac{\\vert S \\vert} {(S^2)^p (1-r)^{p-1} (1+ (p-1)r)}\\), where - $S^2 = {i=1}^p S{ii} $. - $r = {i&lt;j}^p S{ij} $. reject \\(H_0\\) if \\(Q&gt; \\chi_f^2 (\\alpha), \\; \\; \\; \\; \\; f= \\tfrac{p(p+1)-4}{2}\\) - \\(Q = -\\dfrac{(N-1)-p(p+1)^2(2p-3)}{6(p-1)(p^2+p-4)} \\ast \\ln\\Lambda\\). "],["comparison-of-several-mv-means-wk5.html", "5.4 Comparison of Several MV Means (wk5)", " 5.4 Comparison of Several MV Means (wk5) 5.4.1 Paired Comparison Recall: for univariate, let \\(X_i - Y_i = D_i \\sim N(\\delta, \\sigma_d^2)\\), \\(i=1, \\cdots, n\\) then for \\(H_0 : \\delta = 0\\), test stat \\(t = \\tfrac{\\bar D}{\\tfrac{S_d}{\\sqrt{n}}} \\overset {H_0}{\\sim} t_{n-1}\\). Assume independent rvec \\(\\pmb D_1 , \\cdots, \\pmb D_n \\sim N_p (\\pmb \\delta , \\Sigma_{\\pmb d})\\). then test stat \\(T^2 = n(\\bar {\\pmb D} - \\pmb \\delta)&#39; S^{-1}_{\\pmb d} (\\bar {\\pmb D} - \\pmb \\delta) \\sim (n-1)\\tfrac{p}{n-p} F_{p, n-p}\\). Hypothesis Testing: $ H_0 : = $ $ T^2 = n({D} )’ S^{-1}{d} ({D} ) F{p, n-p} $ reject \\(H_0\\) if \\(T^2 &gt; \\tfrac{(n-1)p}{n-p} F_{p, n-p} (\\alpha)\\). $100(1-) % $ CR for \\(\\pmb \\delta\\): $ ({D} - )’ S^{-1}{d} ({D} - ) F{p, n-p} () $ $100(1-) % $ simultaneous CI for individual \\(\\delta_i\\): Bonferroni’s $100(1-) % $ simultaneous CI for individual \\(\\delta_i\\): $ \\[\\begin{alignat*}{3} \\bar d_i \\pm &amp;\\sqrt{\\tfrac{(n-1)p}{n-p} F_{p, n-p} (\\alpha)} &amp;\\sqrt{\\tfrac{S^2_{d_i}}{n}} \\tag{2} \\\\ \\bar d_i \\pm &amp;t_{n-1} \\left( \\tfrac {\\alpha} {2p} \\right) &amp;\\sqrt{\\tfrac{S^2_{d_i}}{n}}\\tag{3} \\end{alignat*}\\] $ – ==== 5.4.1.0.1 Different Approach let \\(\\pmb X = \\left[ x_{11}, \\cdots, x_{1p}, x_{21}, \\cdots, x_{2p} \\right]_{1 \\times 2p}&#39; \\sim N_{2p}(\\pmb \\mu, \\Sigma)\\). then \\(\\pmb D = C \\pmb X\\), where $C = ( \\[\\begin{matrix} 1 &amp; &amp; \\pmb 0 &amp; \\vdots &amp; -1 &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; &amp; \\vdots &amp; &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; &amp; 1 &amp; \\vdots &amp; \\pmb 0 &amp; &amp; -1 \\end{matrix}\\] )_{p 2p} $. at here, $ \\[\\begin{align*} E(\\pmb D) &amp;= E(C \\pmb X) = C \\pmb \\mu \\\\ &amp;= \\pmb \\delta\\\\ \\\\ Cov(\\pmb D) &amp;= Cov(C \\pmb X) = C \\Sigma C&#39; \\\\ &amp;= \\Sigma_d\\\\ \\\\ \\pmb D &amp;= C \\pmb X \\sim N_p (C \\pmb \\mu, C \\Sigma C&#39;) \\end{align*}\\] $ therefore, given \\(H_0 : C \\pmb \\mu = \\pmb 0\\), test stat \\(T^2 = n (C \\bar {\\pmb X})&#39; (CSC&#39;)^{-1} (C \\bar {\\pmb X}) \\overset {H_0}{\\sim} \\tfrac{(n-1)p}{n-p} F_{p, n-p}\\) graph, check normality: 5.4.2 Comparing Mean Vectors from Two Populations Recall: univariate, $ t = {sqrt{S_p^2 ( + )}} t_{n_1 + n_2 - 2}$ for MV, assume below, where \\((\\pmb X_{11}, \\cdots, \\pmb X_{1n_1})\\) and \\((\\pmb X_{21}, \\cdots, \\pmb X_{2n_2})\\) are independent. $ X_{11}, , X_{1n_1} N_p (_1 , _1 ) $ $ X_{21}, , X_{2n_2} N_p (_2 , _2 ) $ at here, $ H_0 : _1 - _2 = $ 5.4.2.0.1 case 1: $ _1 = _2 = $ 이하 대부분은 벡터에 관한 이야기이다. \\(\\bar X_i\\) estimates \\(\\mu_i\\), \\(i=1,2\\). \\(S_p\\) estimates \\(\\Sigma\\), where $S_p = {(n_1-1) + (n_2-1)} $. the test stats Hotelling’s $ T^2 = ( {X_1 } - {X_2} ) ’ S_p^{-1} ( {X_1 } - {X_2} ) $ where $ {p [ (n_1 - 1) + (n_2 - 1) ]} ; T^2 = {p [ (n_1 + n_2 - 2) ]} ; T^2 F_{p, n_1 + n_2 -p - 1}$. (p.285 for pf) CR for \\(\\mu_1 - \\mu_2\\) will be $ Pr = 1- $ where $ c^2= {n_1 + n_2 - p - 1} ; T^2 F_{p, n_1 + n_2 -p - 1} ()$. * 이때 constant가 역수가 되었음을 눈치. * The equality will define the boundary of a region. * The region is an ellipsoid centered at \\((\\bar X_1 - \\bar X_2)\\). 5.4.2.0.1.1 Example) Testing \\(H_0 : \\mu_1 - \\mu_2 = 0\\) at \\(\\alpha=0.05\\) is equivalent to see whether falls within the confidence region Axes of the confidence region * let \\(\\lambda_1 , \\cdots, \\lambda_p\\) are ev of \\(S_p\\). * let \\(e_1 , \\cdots, e_p\\) are evc of \\(S_p\\). then \\(e_i\\)’s are the direction of CI $ $are the half-length of the CR Link let $ c^2= {n_1 + n_2 - p - 1} ; T^2 F_{p, n_1 + n_2 -p - 1} ()$. \\(100(1-\\alpha)%\\) simultaneous CI for \\(a&#39;(\\mu_1 - \\mu_2)\\), \\(\\forall a\\): $ a’ ( X_1 - X_2 ) c $ 5.4.2.0.1.2 Example) simultaneous CI for \\((\\mu_{1i} - \\mu_{2i}), i=1, \\cdots, p\\). let \\(a&#39; = \\left[0, \\cdots, 0, 1, 0, \\cdots, 0 \\right]\\). 이때 \\(a&#39;\\)가 하나만 1이고 나머지 0이면, 어떤 특별한 한 axis로 proj하라는 의미. link let \\(\\mu_1 - \\mu_2 = \\left[ \\mu_{1i} - \\mu_{2i} \\right]_{i=1,\\cdots,p}\\). $ a’(X_1 - X_2) = X_{1i} - X_{2i}$, \\(a&#39; \\left( \\dfrac {1}{n_1} + \\dfrac {1}{n_2} \\right) S_p a = \\left( \\dfrac {1}{n_1} + \\dfrac {1}{n_2} \\right) S_{p \\; ii}\\) * \\(S_{p \\; ii}\\) : p번째 변수의 표본 cov. 이는 단변량에서 나왔던 공통 cov, 즉 샘플 se와 표기법이 동일해지며 유사하다. (ch1) link the Bonferroni’s $100(1-)% $ simultaneous CI for \\((\\mu_{1i} - \\mu_{2i})\\) is $ (X_1 - X_2) t_{n_2 + n_2 -2, ()} $. 5.4.2.0.2 case 2: $ _1 = _2 $ assume \\(n_1 - p , \\; n_2 - p\\) are large. for \\(H_0 : \\mu_1 - \\mu_2 = 0\\), test stat becomes \\(T^2 = (\\bar X_1 - \\bar X_2 )&#39; \\left[ \\dfrac{1}{n_1} S_1 + \\dfrac {1}{n_2} S_2 \\right]^{-1} (\\bar X_1 - \\bar X_2 ) \\overset{H_0}{\\sim} \\chi_p^2\\). $ E(\\bar X_1 - \\bar X_2 ) = \\mu_1 - \\mu_2 $ $ Cov(\\bar X_1 - \\bar X_2 ) = Cov(\\bar X_1) + Cov(\\bar X_2 ) - 2 Cov(\\bar X_1, \\bar X_2 ) = \\dfrac{1}{n_1} \\Sigma_1 + \\dfrac {1}{n_2} \\Sigma_2 - 0 $ $ \\bar X_1 - \\bar X_2 \\overset{\\cdot}{\\sim} N_p \\left( \\mu_1 - \\mu_2, \\dfrac{1}{n_1} \\Sigma_1 + \\dfrac {1}{n_2} \\Sigma_2 \\right) \\tag{∵ CLT} $ $\\\\[3ex] $ $ \\text{under } H_0, $ $ S_1 \\overset{p}{\\to} \\Sigma_1, S_2 \\overset{p}{\\to} \\Sigma_2 \\tag{∵ WLLN} $ $ (\\bar X_1 - \\bar X_2 )&#39; \\left[ \\dfrac{1}{n_1} S_1 + \\dfrac {1}{n_2} S_2\\right]^-1 (\\bar X_1 - \\bar X_2 ) \\overset{app}{\\sim} \\chi_p^2 \\tag{∵ Slutsky&#39;s thm} $ why Cov become 0??? i.e. reject \\(H_0\\) if \\(T^2 &gt; \\chi_p^2 (\\alpha)\\). CI becomes $ Pr = 1- $ 차이는~~ Remark: if \\(n_1 = n_2 = 2\\), $ \\[\\begin{align*} \\dfrac{1}{n_1} S_1 + \\dfrac{1}{n_2} S_2 &amp;= \\dfrac{1}{n} (S_1 + S_2) \\\\ &amp;= \\dfrac{1}{n} \\left[ \\dfrac{1}{n-1} \\sum_{n=1}^n (\\pmb X_{1i} - \\bar {\\pmb X_1})(\\pmb X_{1i} - \\bar {\\pmb X_1})&#39; + \\dfrac{1}{n-1} \\sum_{n=1}^n (\\pmb X_{2i} - \\bar {\\pmb X_2})(\\pmb X_{2i} - \\bar {\\pmb X_2})&#39; \\right] \\\\ &amp;= \\dfrac{1}{n} \\dfrac{1}{n-1} S_p \\ast 2(n-1) = \\dfrac{2}{n} S_p \\end{align*}\\] $ i.e. case 1 and case 2 are the same procedure when the sample sizes are the same for large sample sizes. \\(100(1-\\alpha)%\\) simultaneous CI for \\(\\pmb a&#39;(\\pmb \\mu_1 - \\pmb \\mu_2)\\), \\(\\forall \\pmb a\\): $ a’ ( {X_1} - {X_2} ) $ 5.4.2.0.3 Other Statistics for Testing two Mean Vectors let \\(W=(n_1-1)S_1 + (n_2-1)S_2\\): within SS, \\(B=n_1 (\\bar {\\pmb X_1} - \\bar {\\pmb X})(\\bar {\\pmb X_1} - \\bar {\\pmb X})&#39; + n_2 (\\bar {\\pmb X_2} - \\bar {\\pmb X})(\\bar {\\pmb X_2} - \\bar {\\pmb X})&#39;\\) Wilk’s Lambda: when two-sample procedure, Hotelling’s \\(T^2\\) $ ^= $ Lawley-Hotelling’s Trace: $ tr(BW^{-1}) $ Pillai Trace: $ tr $ Roy’s Largest Root: maximum ev of \\(B(B+W)^{-1}\\). 5.4.2.0.4 Testing Equality of Covariance Matrices $ H_0 : _1 = _2 $ let \\(S_p = \\dfrac{1}{n_1 + n_2 - 2} \\left[ (n_1 - 1) S_1 + (n_2 - 1) S_2 \\right]\\). $ \\[\\begin{align*} M &amp;= (n_1 + n_2 - 2) \\ln \\vert S_p \\vert - (n_1 - 1) \\ln \\vert S_1 \\vert - (n_2 - 1) \\ln \\vert S_2 \\vert \\tag{test stat} \\\\ C^{-1} &amp;= 1 - \\dfrac{2p^2 + 3p -1}{6(p+1)} \\left( \\dfrac {n_1 + n_2 - 2}{(n_1-1)(n_2 - 1)} - \\dfrac {1}{n_1 + n_2 - 2} \\tag{Scale Factor} \\\\ MC^{-1} &amp;\\sim \\chi_v^2, \\; \\; \\; \\; \\; v=\\dfrac{p(p+1)}{2} \\end{align*}\\] $ reject \\(H_0\\) if \\(MC^{-1} &gt; \\chi_v^2(\\alpha)\\) 5.4.3 Profile Analysis (for \\(g=2\\)) Recall: \\(H_0: \\pmb \\mu_1 = \\pmb \\mu_2\\), when \\(\\Sigma_1 = \\Sigma_2 = \\Sigma\\) $ \\[\\begin{align*} T^2 &amp;= (\\bar {\\pmb X_1} - \\bar {\\pmb X_2})&#39; \\left[ \\left( \\tfrac{1}{n_1} + \\tfrac{1}{n_2} \\right) S_p \\right]^{-1} (\\bar {\\pmb X_1} - \\bar {\\pmb X_2}) \\\\ &amp;\\overset {H_0} {\\sim} \\tfrac {(n_1 + n_2 -2)p} {n_1 + n_2-p-1} F_{p, \\; \\; n_1 + n_2 -p -1} \\end{align*}\\] $ let’s \\(H_0: C \\pmb \\mu_1 = C \\pmb \\mu_2\\), when \\(\\Sigma_1 = \\Sigma_2 = \\Sigma\\), where \\(C_{q \\times p}\\), \\(q \\le p\\) and \\(rank(C)=q\\). $ \\[\\begin{align*} T^2 &amp;= (\\bar {\\pmb X_1} - \\bar {\\pmb X_2})&#39; C&#39; \\left[ \\left( \\tfrac{1}{n_1} + \\tfrac{1}{n_2} \\right) CS_p C&#39;\\right]^{-1} C(\\bar {\\pmb X_1} - \\bar {\\pmb X_2}) \\\\ &amp;\\overset {H_0} {\\sim} \\tfrac {(n_1 + n_2 -2)q} {n_1 + n_2-q-1} F_{p, \\; \\; n_1 + n_2 -p -1} \\end{align*}\\] $ Profiles are constructed for each group. Consider two groups. Questions: Are the profiles parallel? $ \\[\\begin{alignat*}{3} &amp;&amp;H_0 : \\mu_{11}-\\mu{12} = \\mu_{21}-\\mu{22}, \\mu_{12}-\\mu{13} = \\mu_{22}-\\mu{23}, \\mu_{13}-\\mu{14} = \\mu_{23}-\\mu{24}, \\cdots, \\mu_{1,p-1}-\\mu{1,p} = \\mu_{2,p-1}-\\mu{2,p} \\\\ &amp;\\iff &amp; H_0 : \\mu_{11}-\\mu{21} = \\mu_{12}-\\mu{22} = \\cdots = \\mu_{1p}-\\mu{2p}} \\\\ &amp;\\iff C_{(p-1) \\times p} &amp;H_0: C \\pmb \\mu_1 = C \\pmb \\mu_2 \\end{alignat*}\\] $ This is equivalent to test the equal mean vector of the transformed data \\(C \\pmb X_1\\) and \\(C \\pmb X_2\\). Populations 1: \\(C \\pmb X_{11}, \\cdots, C \\pmb X_{1n_1} \\sim N_{p-1} (C \\pmb \\mu_1 , C \\Sigma C&#39;)\\) Populations 2: \\(C \\pmb X_{21}, \\cdots, C \\pmb X_{2n_2} \\sim N_{p-1} (C \\pmb \\mu_2 , C \\Sigma C&#39;)\\) reject \\(H_0: C \\pmb \\mu_1 = C \\pmb \\mu_2\\) (i.e. paralle profiles), if $ T^2 = ({X_1} - {X_2})‘C’ ^{-1} C({X_1} - {X_2}) &gt; d^2 = (n_1 + n_2 - 2) F_{p-1,n_1+n_2-p} () $ 5.4.3.0.1 2. Coincident Profiles Assuming that the profiles are parallel, are the profiles coincident? $ \\[\\begin{align*} &amp;H_0 : \\mu_{1i} = \\mu_{2i}, i=1, \\cdots, p \\\\ \\iff &amp; H_0 : \\pmb 1 &#39; \\pmb \\mu_1 = \\pmb 1 &#39; \\pmb \\mu_2 \\end{align*}\\] $ is the case where \\(C\\) is replaced by \\(\\pmb 1 &#39;\\). reject \\(H_0\\) if $ \\[\\begin{alignat*}{2} T^2 &amp;= \\pmb 1 &#39; (\\bar {\\pmb X_1} - \\bar {\\pmb X_2}) \\left[ \\left(\\dfrac{1}{n_1} + \\dfrac{1}{n_2} \\right) \\pmb 1 &#39; S_p \\pmb 1 \\right]^{-1} (\\bar {\\pmb X_1} - \\bar {\\pmb X_2}) &amp;&amp; \\\\ &amp;= \\left( \\dfrac{\\pmb 1 &#39; (\\bar {\\pmb X_1} - \\bar {\\pmb X_2})}{\\sqrt{\\left(\\dfrac{1}{n_1} + \\dfrac{1}{n_2} \\right) \\pmb 1 &#39; S_p \\pmb 1}} \\right)^2 &amp;&amp;&gt; F_{1, n_1 + n_2 -2} (\\alpha) (n_1 + n_2 - 2) \\dfrac{p-1}{n_1 + n_2 - p } F_{p-1,n_1+n_2-p} (\\alpha) \\end{alignat*}\\] $ 5.4.3.0.2 3. Flat Profiles 3.Assuming that the profiles are coincident, are the profiles level? $ H_0 : {11} = {12} = } = {1p} = {21} = {22} = } = {2p} $ by 1 and 2, we can collapse two groups into one. $ X_{11}, , X_{1n_1}, X_{21}, , X_{2n_2} N_p (, ) $ this is one population problem $ C_{(p-1) p}, H_0: C = 0 $ reject \\(H_0\\), iff $ T^2 = (n_1+n_2) {X}‘C’ [CSC’]^{-1} C {X} &gt; d^2 = (n_1 + n_2 - 1) F_{p-1,n_1+n_2-p+1} () $ 이는 1번에서의 그것과는 \\(F\\)분포의 df가 변화했다는 점에 주목. - \\(\\bar {\\pmb X} = \\tfrac{1}{n_1 + n_2} \\left( \\sum_{j=1}^{n_1} \\pmb X_{1j}+ \\sum_{j=1}^{n_2} \\pmb X_{2j} right)\\). - \\(S = n_1 + n_2\\) sample covariance matrix, using data. 5.4.4 Comparing Several Multivariate Population Means Recall: In univariate, two-sample t-test is extended to Analysis of Variance(ANOVA). $ H_0:_1 = =_g $ $ F^= {SSE/df_2} F_{df_1 , df_2} $ - where - SSR: sum of squared regression, - SSE: sum of squared error, - SST: sum of squared total - \\(df_1 = g-1, df_2 = N-g, N=\\sum_{i=1}^g n_i\\). Assume \\(g\\) population or treatment groups, and each groups are independent. 각 population은 같은 Cov를 갖고 같은 숫자의 패러미터를 갖되 총 observation 숫자랑 각각의 population mean은 다름. Population 1~g: \\(\\pmb X_{i1}, \\cdots, \\pmb X_{in_i} \\sim N_p(\\pmb \\mu_i , \\Sigma)\\). Model $ X_{ij} = {i} + {ij}, ; ; ; ; ; i=1, , g, ; ; j = 1, , n_i $ $ H_0: _1 = _g $ $ X_{ij} = \\[\\begin{bmatrix} X_{ij1} \\\\ X_{ij2} \\\\ \\vdots \\\\X_{ijp} \\end{bmatrix}\\] {p } , {ij} = \\[\\begin{bmatrix} \\mu_{i1} \\\\ \\mu_{i2} \\\\ \\vdots \\\\ \\mu_{ip} \\end{bmatrix}\\] {p }, {ij} = \\[\\begin{bmatrix} \\epsilon_{ij1} \\\\ \\epsilon_{ij2} \\\\ \\vdots \\\\ \\epsilon_{ijp} \\end{bmatrix}\\] _{p } $ Assumptions The random samples from different populations are independent. All populations have a common covariance matrix \\(\\Sigma\\). Each population is Multivariate Normal. This assumption can be relaxed by C.L.T., when the sample sizes \\(n_1 , \\cdots, n_g\\) are large. 5.4.4.0.1 One-Way MANOVA The quantities SSR, SSE and SST become matrices in MANOVA. $ \\[\\begin{align*} B &amp;= \\sum_{i=1}^g n_i (\\pmb X_i - \\pmb X) (\\pmb X_i - \\pmb X)&#39; \\tag{SSR} \\\\ W &amp;= \\sum_{i=1}^g \\sum_{j=1}^{n_i} (\\pmb X_{ij} - \\pmb X_i) (\\pmb X_{ij} - \\pmb X_i)&#39; \\\\ &amp;= (n_1 -1)S_1 + \\cdots + (n_g -1)S_g \\tag{SSE} \\end{align*}\\] $ Note: $ \\[\\begin{alignat*}{3} (\\pmb X_{ij} - \\bar {\\pmb X}) &amp;= (\\bar {\\pmb X_i} - \\bar {\\pmb X}) + (\\pmb X_{ij} - \\bar {\\pmb X_i})&amp;&amp; \\\\ (\\pmb X_{ij} - \\bar {\\pmb X}) (\\pmb X_{ij} - \\bar {\\pmb X}) &#39; &amp;= (\\bar {\\pmb X_i} - \\bar {\\pmb X}) (\\bar {\\pmb X_i} - \\bar {\\pmb X}) &#39; + &amp;&amp;(\\bar {\\pmb X_i} - \\bar {\\pmb X}) (\\pmb X_{ij} - \\bar {\\pmb X_i})&#39; + (\\pmb X_{ij} - \\bar {\\pmb X_i}) (\\bar {\\pmb X_i} - \\bar {\\pmb X}) &#39; + (\\pmb X_{ij} - \\bar {\\pmb X_i})(\\pmb X_{ij} - \\bar {\\pmb X_i})&#39; \\\\ \\sum_{i=1}^g \\sum_{j=1}^{n_i} (\\pmb X_{ij} - \\bar {\\pmb X}) (\\pmb X_{ij} - \\bar {\\pmb X}) &#39; &amp;= \\sum_{i=1}^g n_i (\\bar {\\pmb X_i} - \\bar {\\pmb X}) (\\bar {\\pmb X_i} - \\bar {\\pmb X}) &#39; &amp;&amp;+ \\sum_{i=1}^g \\sum_{j=1}^{n_i} (\\pmb X_{ij} - \\bar {\\pmb X_i})(\\pmb X_{ij} - \\bar {\\pmb X_i})&#39; \\\\ T &amp;= B &amp;&amp;+ W \\end{alignat*}\\] $ B: Between Sum of Squares W: Within Sum of Squares Any test statistic will be a function of B and W. Popular test statistics use eigenvalues of \\(BW^{-1}\\). let \\(\\lambda_1, \\cdots, \\lambda_r\\) be ev of \\(BW^{-1}\\), where \\(r=\\) ## of non-zero ev’s. Wilk’s Lambda (LRT) $ = = = _{i=1}^r (1+_1)^{-1} $ Pillai’s Trace $ \\[\\begin{align*} V &amp;= tr[B(B+W)^{-1}] = tr[B(B(I+B^{-1}W))^{-1}] = tr[B(I+B^{-1}W)^{-1}B^{-1}] \\\\ &amp;=tr[B^{-1}B(I+B^{-1}W)^{-1}] = tr[(I+B^{-1}W)^{-1}] = tr[I+(B^{-1}W)^{-1}]\\\\ &amp;=\\sum_{i=1}^r \\left( \\dfrac{\\lambda_i}{1+\\lambda_i}\\right) \\end{align*}\\] $ Lawley-Hotelling’s Trace $ T = tr(BW^{-1}) = _{i=1}^r _i $ Roy’s Largest Root $ U = _{i=1,,r} { _i } $ Sampling Distribution of Wilk’s Lambda $ \\[\\begin{alignat*}{2} p=1, g \\ge 2: &amp;\\left(\\dfrac{\\sum_{i=1}^g n_i - g}{g-1}\\right) \\left(\\dfrac{1-\\Lambda^\\ast}{\\Lambda^\\ast}\\right) &amp;&amp;\\overset{H_0}{\\sim} F_{g, \\sum_{i=1}^g n_i - g} \\\\ p=2, g \\ge 2: &amp;\\left(\\dfrac{\\sum_{i=1}^g n_i - g-1}{g-1}\\right) \\left(\\dfrac{1-\\sqrt{\\Lambda^\\ast}}{\\sqrt{\\Lambda^\\ast}}\\right) &amp;&amp;\\overset{H_0}{\\sim} F_{2(g-1), 2(\\sum_{i=1}^g n_i - g-1)} \\\\ p\\ge1, g = 2: &amp;\\left(\\dfrac{n_1 + n_2 - p -1}{p}\\right) \\left(\\dfrac{1-\\Lambda^\\ast}{\\Lambda^\\ast}\\right) &amp;&amp;\\overset{H_0}{\\sim} F_{p, n_1 + n_2 - p -1} \\\\ p \\ge 1, g \\ge 3: &amp;\\left(\\dfrac{\\sum_{i=1}^3 n_i - p-2}{p}\\right) \\left(\\dfrac{1-\\sqrt{\\Lambda^\\ast}}{\\sqrt{\\Lambda^\\ast}}\\right) &amp;&amp;\\overset{H_0}{\\sim} F_{2p, 2(\\sum_{i=1}^g n_i - p-2)} \\\\ \\text{large sample sizes}: &amp;- \\left( \\sum_{i=1}^g n_i -1 -\\dfrac{p+q}{2}\\right) \\ln \\Lambda^\\ast &amp;&amp;\\overset{H_0}{\\sim} \\chi^2_{p(g-1)} \\tag{Why?} \\end{alignat*}\\] $ "],["multivariate-multiple-regression-wk6.html", "5.5 Multivariate Multiple Regression (wk6)", " 5.5 Multivariate Multiple Regression (wk6) 5.5.1 Overview Recall: univariate Linear Regression: repsponse variable \\(Y\\), \\(r\\) predictor variables \\(Z_1 , \\cdots, Z_r\\). model: $ \\[\\begin{alignat*}{3} Y_j &amp;= \\beta_0 + \\beta_1 Z_{j1} + \\cdots + \\beta_j Z_{jr} + \\epsilon_j , \\; \\; \\; \\; \\; &amp;E(\\epsilon_j) = 0, Var(\\epsilon_j) = \\sigma^2 \\pmb Y_{n \\times 1} &amp;= \\pmb Z_{n \\times (r+1)} \\pmb \\beta_{(r+1) \\times 1} + \\pmb \\epsilon_{n \\times 1}, \\; \\; \\; \\; \\; &amp;E(\\pmb \\epsilon) = 0, Var(\\pmb \\epsilon) = \\sigma^2 I \\end{alignat*}\\] $ estimation: $ \\[\\begin{alignat*}{3} \\hat {\\pmb \\beta} &amp;= (\\pmb Z &#39; \\pmb Z )^{-1} \\pmb Z &#39; \\pmb Y \\\\ \\hat {\\pmb \\epsilon} &amp;= (\\pmb Y - \\pmb Z \\hat {\\pmb \\beta}) = \\pmb Y - \\pmb Z (\\pmb Z &#39; \\pmb Z )^{-1} \\pmb Z &#39; \\pmb Y = (I - \\pmb Z (\\pmb Z &#39; \\pmb Z )^{-1} \\pmb Z &#39;) \\pmb Y \\\\ &amp;= (I-H)\\pmb Y \\end{alignat*}\\] $ inference: let \\(\\epsilon \\sim N_n (\\pmb 0, \\sigma^2 I)\\). then $ \\[\\begin{alignat*}{3} \\hat {\\pmb \\beta} &amp;\\sim N_{r+1} (\\pmb \\beta , \\sigma^2(\\pmb Z &#39;\\pmb Z )^{-1}) \\\\ \\hat {\\pmb \\epsilon} &#39; \\hat {\\pmb \\epsilon} &amp;\\sim \\sigma^2 \\chi^2_{n-r-1} \\\\ \\\\ E(\\hat {\\pmb \\epsilon} ) &amp;= \\pmb 0 \\\\ Cov(\\hat {\\pmb \\epsilon} ) &amp;= \\sigma^2 (I - \\pmb Z (\\pmb Z &#39; \\pmb Z )^{-1} \\pmb Z &#39;) \\\\ E\\left( \\dfrac{\\hat {\\pmb \\epsilon} &#39; \\hat {\\pmb \\epsilon}}{n-r-1} \\right) &amp;= \\sigma^2 \\end{alignat*}\\] $ 5.5.2 Multivariate Multiple Regression Notation Model $ Y_{n m} = Z_{n (r+1)} {(r+1) m} + {n m}, ; ; ; ; ; E({(i)} ) = , Cov({(i)}, {(j)}) = {ik} I, ; ; ; i,k = 1, , m $ Cov of \\(m\\) responses: $ \\[\\begin{alignat*}{3} &amp;\\Sigma = \\begin{bmatrix} \\sigma_{11} &amp; &amp; \\sigma_{1m} \\\\ &amp; \\ddots &amp; \\\\ \\sigma_{m1}&amp;&amp; \\sigma_{mm} \\end{bmatrix}, \\; \\; \\; \\; \\; &amp;&amp;Var(\\pmb \\epsilon_{(i)}) = \\sigma_{ii} I,\\; \\; \\; \\; \\; &amp;&amp;Cov(\\pmb \\epsilon_{(i)}, \\pmb \\epsilon_{(j)}) = \\begin{bmatrix} \\sigma_{ik} &amp; &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; \\\\ \\pmb 0 &amp;&amp; \\sigma_{ik} \\end{bmatrix} \\end{alignat*}\\] $ the meaning of \\(0\\): observations from different trials, are uncorrelated \\(\\sigma_{ik}\\): errors for different responses on the same trial are correlated \\(i\\)th response \\(\\pmb Y_{(i)}\\): $ Y_{(i)} = Z {(i)} + {(i)}, ; ; ; ; ; Corr({(i)}) = {ii}I , = (Z ’ Z )^{-1} Z ’ Y_{(i)} $ 5.5.2.0.1 Least Square Collecting Univariate Least Squares Estimates (LSE) Errors $ Y - Z = $ Error Sum of Squares (SSE) diagonal elements: Error SS for univariate least squares \\((\\pmb Y_{(i)}-\\pmb Z \\pmb \\beta_{(i)})&#39; (\\pmb Y_{(i)}-\\pmb Z \\pmb \\beta_{(i)})\\) is minimized. the generalized \\(Var\\) \\(\\lvert (\\pmb Y-\\pmb Z \\pmb \\beta)&#39; (\\pmb Y-\\pmb Z \\pmb \\beta) \\rvert\\) is also minimized. Properties $ \\[\\begin{align*} \\hat {Y} &amp;= Z \\hat \\beta = Z(Z&#39;Z)^{-1} Z&#39; Y \\\\ &amp;= HY \\tag{Predicted Values}\\\\ \\hat {\\pmb \\epsilon} &amp;= Y - \\hat Y = \\left[ I - Z(Z&#39;Z)^{-1} Z&#39; \\right] Y \\\\ &amp;= (I-H)Y \\tag{residuals} \\\\ Z&#39; \\hat {\\pmb \\epsilon} &amp;= Z&#39; \\left[ I - Z(Z&#39;Z)^{-1} Z&#39; \\right] Y \\\\ &amp;= [Z-Z&#39;] Y =\\pmb 0 \\tag{3} \\hat Y&#39; \\hat {\\pmb \\epsilon} &amp;= \\hat {\\beta} &#39; Z&#39; \\left[ I - Z(Z&#39;Z)^{-1} Z&#39; \\right] Y \\\\ &amp;= [\\hat {\\beta} &#39; Z- \\hat {\\beta} &#39; Z&#39;] Y =\\pmb 0 \\tag{4} \\end{align*}\\] $ - - by (3), residuals are orthogonal to \\(Z\\) - by (4), residuals are orthogonal to \\(\\hat Y\\) Error Sum of Squares $ \\[\\begin{align*} Y&#39;Y &amp;= (\\hat Y \\hat {\\pmb \\epsilon} ) &#39; (\\hat Y \\hat {\\pmb \\epsilon} ) \\\\ &amp;= \\hat Y &#39; \\hat Y + \\hat{\\pmb \\epsilon}&#39; \\hat{\\pmb \\epsilon} \\\\ \\\\ \\hat {\\pmb \\epsilon}&#39; \\hat {\\pmb \\epsilon}&amp;= Y&#39;Y - \\hat Y &#39; \\hat Y \\\\ &amp;= \\hat Y &#39; \\hat Y - \\hat \\beta &#39; Z&#39; Z \\hat \\beta \\end{align*}\\] $ Results 1 $ \\begin{alignat*}{2} E() &amp;= , ; ; ; ; ; Cov(, ) &amp;= _{il} (Z’Z)^{-1} \\ \\ E() = , ; ; ; ; ;E ( ’ ) = \\end{alignat*} $ - - at here, \\(\\hat {\\pmb \\epsilon}\\) and \\(\\hat {\\pmb \\beta}\\) are correlated. Results 2 If \\(\\pmb \\epsilon_j\\) has a \\(N_m (\\pmb 0 , \\Sigma)\\), then \\(\\hat {\\pmb \\beta}= (\\pmb Z &#39; \\pmb Z )^{-1}\\pmb Z &#39;Y\\) is MLE of \\(\\pmb \\beta\\) $ \\[\\begin{align*} \\hat {\\pmb \\beta_{(i)}} &amp;\\sim N_{r+1} ({\\pmb \\beta_{(i)}}, \\sigma_{ii} (\\pmb Z &#39; \\pmb Z )^{-1}) \\\\ \\hat \\Sigma &amp;= \\dfrac{1}{n} \\hat {\\pmb \\epsilon} &#39; \\hat {\\pmb \\epsilon} \\\\ &amp;= \\dfrac{1}{n} (\\pmb Y - \\pmb Z \\hat {\\pmb \\beta}) &#39; (\\pmb Y - \\pmb Z \\hat {\\pmb \\beta}) \\tag{5} \\end{align*}\\] $ is MLE of \\(\\Sigma\\) \\(n \\hat \\Sigma \\sim W_{p,n-r-1} (\\Sigma)\\). Comment Multivariate regression requires no new computational problems. Univariate least squares \\(\\hat {\\pmb \\beta_{(i)}}\\) are computed individually for each response variable. Diagnostics check must be done as in univariate regression. Residual vectors \\([ \\pmb \\epsilon_{j1}, \\cdots, \\pmb \\epsilon_{jm} ]\\) can be examined for multivariate normality. 5.5.3 Hypothesis Testing Note: $ \\[\\begin{align*} &amp;H_0: \\text{ responses do not depend on } Z_{q+1}, Z_{q+2}, \\cdots, Z_{r} \\\\ \\iff &amp;H_0: \\begin{bmatrix} \\beta_{(q+1)1} &amp; \\beta_{(q+2)1} &amp; \\cdots &amp; \\beta_{(q+1)m} \\\\ \\vdots &amp;&amp;&amp; \\vdots \\\\ \\beta_{r1} &amp; \\beta_{r1} &amp; \\cdots &amp; \\beta_{rm} \\end{bmatrix} = 0 \\\\ \\iff &amp;H_0: \\pmb{\\beta_{(2)}} = \\pmb 0, \\; \\; \\; \\; \\; \\ \\pmb \\beta = \\begin{bmatrix} \\pmb{\\beta_{(1)}}_{(q+1) \\times m} \\\\ cdots \\\\ \\pmb{\\beta_{(2)}}_{(r-q) \\times m} \\end{bmatrix} \\end{align*}\\] $ 5.5.3.0.1 Full Model vs. Reduced Model let \\(Z = \\begin{bmatrix} Z_1 &amp; \\vdots Z_2 \\end{bmatrix}\\), then \\(Z \\beta = Z_1 \\beta_{(1)} + Z_2 \\beta_{(2)}\\). under \\(H_0\\), \\(Y = Z \\beta_{(1)} + \\epsilon\\), let $ \\[\\begin{align*} E &amp;= n \\hat \\Sigma &amp;\\\\ &amp;= (\\pmb Y - \\pmb Z \\hat{\\pmb \\beta})&#39;(\\pmb Y - \\pmb Z \\hat{\\pmb \\beta})&amp; \\tag{Full Model}\\\\ \\\\ H &amp;= n(\\hat \\Sigma_1 - \\hat \\Sigma), &amp;\\text{ where } E_1 = n(\\hat \\Sigma_1) = (\\pmb Y - \\pmb Z \\hat{\\pmb \\beta_{(1)}})&#39;(\\pmb Y - \\pmb Z \\hat{\\pmb \\beta_{(1)}}) \\tag{under H0} \\end{align*}\\] $ $ E=n $. 여기서 E라는 것은 오차행렬이기 때문에, 즉 univariate 를 4번 반복해서 나온 오차를 모은 것이 바로 이 \\(E\\)라는 행렬. let \\(\\lambda_1 \\ge \\cdots \\ge \\lambda_s\\) be non-zero ev of \\(HE^{-1}\\), \\(s=min(m, r-q)\\). Four Test Stat: Wilk’s Lambda: $ = _{i=1}^s $ Pillai Trace: $ tr = _{i=1}^s $ Lawley-Hotelling’s Trace: $ tr(HE^{-1}) = _{i=1}^s {_i} $ Roy’s Largest Root: maximum ev of \\(H(H+E)^{-1} = \\lambda_1\\). 5.5.4 Example) fit FM \\(Y = Z \\beta + \\epsilon\\). fit \\(Y_1 , Y_2 , Y_3 , Y_4 = X_1,X_2,X_3\\), then we acquire \\(E=n \\hat \\Sigma\\). 1. $~H_0: \\begin{bmatrix} \\beta_{31},\\beta_{32},\\beta_{33},\\beta_{34} \\end{bmatrix} =0~$, \\(H_0: \\begin{bmatrix} \\beta_{21},\\beta_{22},\\beta_{23},\\beta_{24}\\\\\\beta_{31},\\beta_{32},\\beta_{33},\\beta_{34} \\end{bmatrix} =0\\), under \\(H_0\\), \\(Y=Z \\beta_{(1)} + \\epsilon\\) $ Z_1 = \\[\\begin{bmatrix} 1 &amp; X_{11} \\\\ \\cdots &amp; \\cdots \\\\ 1 &amp; X_{n1} \\end{bmatrix}\\] _{n }, ; ; ; ; ; _{(1)} = \\[\\begin{bmatrix} \\beta_{01} &amp; \\cdots &amp; \\beta_{0m} \\\\ \\beta_{11} &amp; \\cdots &amp; \\beta_{1m} \\end{bmatrix}\\] _{2 m} $ now, fit \\(Y_1 , Y_2 , Y_3 , Y_4 = X_1\\) (X_2, X_3 excluded), then we acquire \\(E_1 =n \\hat \\Sigma_1, H = n \\hat \\Sigma_1 - n \\hat \\Sigma = E_1 - E\\). let’s calculate ev of \\(HE^{-1}\\), and compute Wilk’s Lambda \\(\\Lambda^\\ast = \\dfrac{\\vert E \\vert }{\\vert E+H\\vert }\\). 5.5.4.0.1 Sampling Distribution of the Wilk’s Lambda let Z be full rank of \\(r+1\\), and \\((r+1) + m \\le n\\). let \\(\\epsilon\\) be normally distributed. under \\(H_0\\), $ - (^) ^2_{m(r-q)}$. 5.5.4.0.2 Prediction $ {n m} = Z {(r+1) m} $ assume fixed values \\(\\pmb {Z_0}_{(r+1) \\times 1}\\) of the predictor variables. then \\(\\hat {\\pmb \\beta}&#39;_{m \\times (r+1)} \\pmb Z_0 \\sim N_m(\\pmb \\beta &#39; \\pmb Z_0 , \\pmb Z_0 &#39; (\\pmb Z &#39; \\pmb Z)^{-1} \\pmb Z_0 \\Sigma)\\). \\(100(1-\\alpha)\\%\\) simultaneous CI for \\(E(Y_i) = \\pmb Z_0 &#39; \\pmb \\beta_{(i)}\\): $ Z_0 ’ _{(i)} , ; ; ; ; ; i=1,, m $ where \\(\\pmb \\beta_{(i)}\\) is the \\(i\\)th column of \\(\\pmb \\beta\\). \\(\\hat \\sigma_{ii}\\) is the \\(i\\)th diagonal element of \\(\\hat \\Sigma\\). \\(100(1-\\alpha)\\%\\) simultaneous C.I. for the individual responses \\(Y_{0i} = \\pmb Z_0 &#39; \\pmb \\beta_{(i)} + \\epsilon_{0i}\\): $ Z_0 ’ _{(i)} , ; ; ; ; ; i=1,, m $ "],["pca.html", "5.6 PCA", " 5.6 PCA PCA는 상관관계 있는 반응변수 \\(y\\)의 집합을 상관관계 없는 더 작은 집합으로 바꿈. 이 더 작은 직합들의 이름은 principal components. 이는 더 작은 principal components들이 어쩌면 원본 데이터에 들어있는(available) 거의 대부분의 정보를 보유하고 있을지도 모른다는 생각에서 출발함. 1. Outlier 2. Cluster 3. Discriminant: Cov 매트릭스 invert 하려면 필요. 샘플 사이즈 작으면 \\((n&lt;p)\\) 문제터져서 변수 갯수를 줄임. 4. Regression: predictors 사이에 multicollinearity 존재하는지 체크 5. Multivariate Nomality semi-positive definite 벡터의 매트릭스 \\(\\textbf {X}_{1 \\times p}\\) 의 Cov 매트릭스 \\(\\Sigma\\), 이의 \\(ev\\) \\(\\lambda_1 \\le \\cdots \\le \\lambda_p \\le 0\\). \\(\\textbf a&#39;_i\\)는 $ p $인 열벡터. 이것이 \\(i=1~p\\)개만큼 존재. \\(Y_i = \\textbf a&#39;_i \\textbf {X}_{i}\\), 즉 \\(Y\\)는 \\(a\\)와 \\(X\\)의 선형결합. $Cov(Y_1 , Y_2) = Cov(’_1 , ’_2 ) = _1 ’ _2 ( = 0 ) $ 벡터와 스칼라 여부 주의. Transpose 여부 주의. 0이 되는 건 $_1 ’ $과 $ _2 $ 가 orthogonal. Var가 클수록 정보량 많음. 1번은 분산이 가장 큼. 2번은 분산이 2번째로 크되 1번째의 ${1} $과 orthogonal 해야함. e.g. $ Cov ( {1}’ _{2}’ )$. 이를 반복. 1st principal component: \\(= \\textbf e_1 &#39; \\textbf X\\). * \\(Var \\left( \\textbf e_1 &#39; \\textbf X \\right)= \\textbf e_1 &#39; \\Sigma \\textbf e_1 = \\lambda_1\\). * 이때, \\(e \\textbf v\\)의 정의에 의해 $_1 = _1 _1 $ . * \\(Var \\left( \\textbf e_1 &#39; \\textbf X \\right)\\) 는 $_1 ’ _1 $ 를 만족하는 값들 중 \\(Var \\left( \\textbf e_1 &#39; \\textbf X \\right)\\)를 최대화시키는 값. 2nd principal component: \\(= \\textbf e_2 &#39; \\textbf X\\). * \\(Var \\left( \\textbf e_2 &#39; \\textbf X \\right)= \\textbf e_2 &#39; \\Sigma \\textbf e_2 = \\lambda_2\\) 는 모든 \\(\\textbf a_2 &#39; \\textbf X\\) 중 $Cov ( _1 ’ _1 _2 ’ ) = 0 $ 과 $_2 ’ _2 $를 만족하는 녀석. 즉 PC 자체는 \\(\\textbf e_i &#39; \\textbf X\\) 로 정해짐. note ***이건 proj의 일종인 모양.*** 근데 이걸로 정해지는 이유가 상기의 조건을 만족해야 한다는 거고, 해당 체크 조건들을 \\(\\textbf e_i &#39; \\textbf X\\) 가 모두 통과할 수 있으므로 이걸 PC로 삼는 것에 문제가 없다는 것. $ \\[\\begin{align*} \\sum_{i=1}^p Var(\\textbf X_i) &amp;=tr(\\Sigma) \\\\ &amp;= \\sigma_{11} + \\sigma_{22} + \\cdots + \\sigma_{pp} \\\\ &amp;= \\lambda_1 + \\lambda_2 + \\cdots + \\lambda_p \\\\ &amp;= \\sum_{i=1}^p Var(\\textbf Y_i) \\end{align*}\\] $ 따라서 kth PC에 의해 유발되는 총 Var의 비율은 $ = $. 이인즉 PCA를 거쳐도 p개의 variable 갯수를 유지한다면 설명력의 총합은 동일함. 하지만 우리는 설명력을 1만큼 잃고 변수를 10만큼 줄이기를 원함. 따라서 어느정도 설명력을 잃더라도 그 이상으로 변수의 갯수를 줄이는 선이면 하꼬변수를 쳐냄. 이는 PCA 분석때 기본적으로 분산의 80% 설명을 기준으로 함. Cov 매트릭스 \\(\\Sigma\\), PC \\(Y_i = \\textbf e_i &#39; \\textbf X\\). 이때 \\(\\rho_{Y_i , X_k } = Corr (Y_i , X_k ) = \\dfrac {e_{ik} \\sqrt{\\lambda_i}} {\\sqrt{\\sigma_{kk}}}, \\; \\; \\; i,k=1,\\cdots,p\\). 다룰 때의 편의를 위해 PC 구성 단계에서 \\(Y_i =\\textbf {e}_i ( \\pmb {X} - \\pmb {\\mu} )\\) 로 구성하는 경우도 잦음. PC Score. n개의 관측 중에서 r번째 관측의 variable의 벡터를 $r $이라고 설정하자. 그렇다면 \\(Y_{ri} = \\textbf e_i &#39; (\\textbf X_r - \\pmb \\mu_r)\\). 이때 \\(r=1,\\cdots, n\\). 이때 PC Score는 $ Y{ri} = ’ (_r - { _r})$ 로 추정될 수 있다. ***elbow*** PCA prerequisite * variable들이 same unit * variable들이 have similar Var 해결책 * $ $로 표준화하고 PCA. \\(E(\\textbf Z) = 0, Cov(\\textbf Z )=\\rho\\) * PCA 자체를 corr 매트릭스에 적용 $ \\[\\begin{align*} \\sum_{i=1}^p Var(\\textbf Y_i) &amp;= \\sum_{i=1}^p Var(\\lambda_i) \\\\ &amp;= tr(\\pmb \\rho) \\\\ &amp;= \\sum_{i=1}^p Var(\\textbf Z_i) \\\\ &amp;= p \\end{align*}\\] $ 따라서 이때의 kth PC에 의해 유발되는 총 Var의 비율은 $ = $. \\(Corr\\)을 썼을 때 PC를 어디까지 쓸지를 솎아낼 때는 scree plot이나 \\(ev&gt;1\\)인지를 기준으로 한다. 모든 기존 변수들의 분산이 1이므로 최소한의 설명력이 1이라는건데, 1도 안되면 그냥 쓰레기들이므로. Checking Multivariate Normal: 기존 데이터가 mv normal이라면, 각 PC Score는 normal로 분포되어 있다. 각 PC들을 QQ plot 사용해서 체크하면 답나옴. "],["factor.html", "5.7 Factor", " 5.7 Factor PCA FA concern with explaining \\(Cov\\) and/or \\(Corr\\) structure among measured variables Variability in the variables Objectives 1. Partition the \\(p\\) response variables into \\(m\\) subsets, each consisting of a group of variables tending to be more highly related to others. 2. Create a new set of uncorrelated variables, called underlying factors or underlying characteristics. 3. Use the new variables in future analysis. Warnings 1. If the original variables are already uncorrelated, no reason to consider FA.2. Subjective decisions are necessary to determine number of factors, to determine the method to get the underlying factors 3. FA solutions are not unique. 5.7.0.0.1 Orthogonal Factor Model \\(\\pmb X \\sim \\pmb \\mu , \\Sigma\\). Common Factors $F_1 , F_m $은 $X $와 linearly dependent. errors, Specific Factors $_1 , , _p $. $ $ loading \\(l_{ij}\\)은 \\(i\\)번째 variable의 \\(j\\)번째 factor에 대한 loading. matrix of Factor Loadings \\(\\pmb L\\) 즉슨, \\(X_i - \\mu_i\\)는 \\(F_j\\)의 선형결합과 \\(\\epsilon_i\\)를 더하는 것으로 서술될 수 있다는 게 요지. 다만 관측되지 않은 quantity가 너무 많아서 Factor Model의 직접적인 검증은 사실상 불가능함. 따라서 \\(\\pmb F\\)와 \\(\\pmb \\epsilon\\)에 추가적인 조건을 덧붙인 후, \\(Cov\\) 관계성을 체크하는 것으로 대신한다. \\(E(\\pmb F) = \\pmb 0, Cov(\\pmb F) = E(\\pmb F \\pmb F&#39; ) = I_{m \\times m}\\) $E() = , Cov() = E(’) = _{p p} = \\[\\begin{bmatrix}\\Psi_1 &amp; &amp; 0 \\\\ &amp; \\ddots &amp; \\\\ 0 &amp; &amp; \\Psi_p \\end{bmatrix}\\] _{p p} $ $ F $, so $Cov(, F ) = E(’) = _{p m} $ 이때 $ \\[\\begin{align*} \\Sigma = Cov(\\pmb X) &amp;= E \\left[ (\\pmb X - \\pmb \\mu) (\\pmb X - \\pmb \\mu) &#39; \\right] \\\\ &amp;= E \\left[ \\pmb{LF (LF)&#39; + \\epsilon(LF)&#39; + (LF) \\epsilon&#39; + \\epsilon \\epsilon&#39;} \\right] \\\\ &amp;= \\pmb {LE(FF&#39;)L&#39; + E(\\epsilon \\epsilon&#39;)} \\\\ &amp;= \\pmb{LL&#39; + \\Psi} \\end{align*}\\] $ ㅁㄴㅇㄹ $ \\[\\begin{align*} Cov (\\pmb {X, F}) = \\pmb {E \\left[ (X-\\mu)(F-0)&#39; \\right]} &amp;= E \\left[ \\pmb {(X-\\mu)F&#39; }\\right] \\\\ &amp;= \\pmb { E \\left[ (LF + \\epsilon)F&#39; \\right]} \\\\ &amp;= \\pmb { LE(FF&#39;) + E(\\epsilon F&#39;) }\\\\ &amp;= \\pmb { L} \\end{align*}\\] $ 따라서 Total Variation은: communality \\(h_j^2 = \\sum_{j=1}^m l_{ij}^2\\). * contribution by \\(m\\) column factors * $ ’ = \\[\\begin{bmatrix}h_1^2 &amp; &amp; \\sigma_{1p} \\\\ &amp; \\ddots &amp; \\\\ \\sigma_{p1} &amp; &amp; h_p^2 \\end{bmatrix}\\] _{p p}$. specific variance \\(\\Psi_i\\) $ Var(X_i) = {j=1}^m l{ij}^2 + i \\ Cov(X_i, X_k) = {j=1}^m l_{ij}l_{kj} \\ Cov(X_i, F_j) = l_{ij} $ Notes: * When \\(m=p\\), any \\(Cov\\) matrix \\(S\\) can be reproduced exactly as \\(\\pmb{LL}&#39;\\), so \\(\\pmb \\Psi\\) is the zero matrix. * When \\(m &lt; p\\), the FA is most useful. The FA model provides a “simple” explanation of covariance in \\(\\pmb X\\). * When \\(m \\lll p\\), most \\(Cov\\) matrices cannot be factored as \\(\\pmb{LL}&#39;+\\pmb \\Psi\\)(while maintaining basic statistical properties). 5.7.0.0.2 Uniqueness Orthogonal factor model is not unique, b/c rotation. 5.7.1 Method of Estimation Choosing the appropriate Number of Factors: 1. Similar to PCA. Determine the number of factors using scree plot or eigenvalue \\(\\ge 1\\) 2. Do not include trivial factors (only one variable assigned to one factor). 3. Test the adequacy of the chosen number of factors.(Use ML method and LRT) for standardized variable. 4. Use AIC. Choose m that produces the minimum value for AIC. 5. Use SBC (Schwarz’s Bayesian Criterion). Notes: * $= ’ + * objective is estimating \\(\\pmb L\\) 5.7.1.0.1 1. Principal Component Method $ = = $. 여기서 기여도가 낮은 \\(\\lambda_i\\)에 해당하는 ev를 뒤에서부터 쳐내서 적당한 ev만으로 구성. 그 경우 \\(=\\pmb {L_{p \\times m} L_{m \\times p}&#39;}\\). 여기서 specific factors \\(\\pmb \\Psi\\)의 \\(Var\\)을 \\(\\Sigma - \\pmb {LL&#39;}\\)의 diagonal elements 를 사용해서 구할 수 있다. 근사는 \\(\\Sigma \\approx \\pmb {LL&#39; + \\Psi}\\). $ i = i^2 - {j=1}^m l{ij}^2 = i^2 - {j=1}^m j e{ij}^2 $ 이는 위에서 \\(l_{ij} = \\sqrt {\\lambda_j e_{ij}}\\)임을 보여놨기에 가능. the importance of \\(j\\)th factor $ \\[\\begin{align*} = \\dfrac {\\lambda_j}{\\sum_{i=1}^p \\lambda_i} &amp;= \\dfrac {\\sum_{i=1}^p l_{ij}^2} {\\sum_{i=1}^p \\sigma^2} \\\\ &amp;= \\dfrac {\\sum_{i=1}^p l_{ij}^2} {p} \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\text{if} \\; \\; \\Sigma=\\pmb \\rho \\end{align*}\\] $ at here, communality \\(h_i^2 = \\sum_{j=1}^m l_{ij}^2\\). 5.7.1.0.2 3. ML Method assumption is needed: \\(\\pmb X \\sim N_p (\\pmb mu , \\Sigma)\\), where $= + $. 이때 \\(L(\\pmb \\mu, \\Sigma)\\)는 $= + $ 이기에 \\(\\pmb L\\), \\(\\Psi\\)에 의존. \\(\\hat \\pmb L_{MLE}\\), \\(\\hat \\pmb \\Psi_{MLE}\\)는 수치해석으로 찾아짐. estimated communalities들은 $ h_i^2 = {j=1}^m l{ij}^2$, \\(i=1, \\cdots, p\\). The importance of \\(j\\)th factor는~. 5.7.1.0.2.1 3.5. Test for the number of factors \\(H_0: \\; \\; \\Sigma_{p \\times p} = \\pmb L_{p \\times m} \\pmb L&#39;_{m \\times} + \\pmb \\Psi_{p \\times p}\\) \\(H_1: \\Sigma_{p \\times p}\\)는 any other positive definite matrix. assume \\(\\pmb X \\sim N_p (\\pmb mu , \\Sigma)\\). under \\(H_0\\), $= + $. 이때 $_{MLE} = + $. under \\(H_1\\), \\(\\hat \\Sigma_{MLE} = S_n\\). 이떄 $ S_n$은 sample \\(Cov\\) matrix. LRT for testing \\(H_0\\): $ -2log = n log ( ) = n log ( ) $ 5.7.1.0.2.2 3.7. Bartlett’s Approx. reject \\(H_0\\) if~. 5.7.1.0.3 3. Minimum Residual Method let $Cov(X) = = + $, and mv regression \\(pmb{Y_{n \\times m}=Z_{n \\times (r+1)} \\beta_{(r+1)\\times m)} + \\epsilon_{n \\times m}\\)와 유사한 개형. estimate factor loadings so that the sum of squares of off-diagonal residuals be minimized. \\(\\hat \\pmb L_{MLE}\\), \\(\\hat \\pmb \\Psi_{MLE}\\)는 수치해석으로 찾아짐. estimated communalities들은 $ h_i^2 = {j=1}^m l{ij}^2$, \\(i=1, \\cdots, p\\). The importance of \\(j\\)th factor는~. 5.7.2 Factor Rotation All factor loadings obtained from the initial loading by an orthogonal transformation have the same ability to reproduce the covariance matrix. * $= + = + = + $. at here, must be \\(TT&#39; = I\\) by characteristics of rotation in linear algebra. From matrix algebra, we know that an orthogonal transformation corresponds to a rigid rotation of the coordinate axes. An orthogonal transformation of factor loading is called factor rotation. The communalities \\(\\hat h_i^2\\) and the specific variances \\(\\hat \\Psi_i\\) are not changed, b/c $ = $, and diagonal elements of this is communalities. Rationale: Since the original loadings \\(L\\) may not be easily interpretable, it is usual practice to rotate them until a “simpler structure” is achieved. 5.7.3 Varimax Criterion define \\(\\hat l_{ij}^\\ast = \\dfrac {l_{ij}^\\ast}{\\hat h_j}\\) to be the rotated coefficients. Then the Varimax procedure selects the orthogonal transformation T that makes \\(V=\\) as large as possible. 이는 일종의 분산으로서 관점될 수 있다. In words, $V _{j=1}^mVar( l_j^2 ) $ , which is variance of squares of loading for jth factor. Maximizing \\(V\\) corresponding to “spreading out” the squares of loadings on each factor as much as possible. 5.7.3.0.1 Oblique Rotation It is not possible to rotate the axes so that one axes goes through each cluster of variables while keeping the axes orthogonal to one another. Such rotation can be achieved by multiplying L by a matrix Q where Q is not an orthogonal matrix. Oblique rotations do not produce new factors that remain uncorrelated, which is a contradiction of the initial FA assumptions \\(\\rightarrow\\) not good! 5.7.4 Factor Scores In "],["discrimination-and-classification.html", "5.8 Discrimination and Classification", " 5.8 Discrimination and Classification 여러개의 다른 모집단으로부터 나온 데이터들을 설명. discriminants (구분자) 들의 발견. 관찰치를 분류하여 이를 클래스로 묶고 싶다. why인지는 크게 중요하지 않고, 예측을 하고 싶다. 5.8.1 Bayes Rule let r\\(v\\) for populations \\(\\pi_1 , \\pi_2\\), \\(\\pmb X = (x_1 , \\cdots, x_p)&#39;\\). 이때, \\(f_i(\\pmb X)\\)는 \\(\\pi_i\\)의 pdf. \\(R_i\\)는 우리가 해당 object를 \\(\\pi_i\\)로 분류하는 \\(\\pmb X\\) 값들의 set. $ R_1 : {f_2 ( X)} , ; ; ; ; ; R_2 : {f_2 ( X)} $ let prior of each \\(P_i\\) be \\(\\pi_i\\), and \\(\\sum_{i=1}^n P_i = 1\\). $ R_1 : {f_2 ( X)} , ; ; ; ; ; R_2 : {f_2 ( X)} $ let the costs of misclassification can be defined by a cost matrix: | classify \\(\\pi_1\\)| \\(\\pi_2\\) | True Population \\(\\pi_1\\) | 0 | \\(C(2 \\vert 1)\\) | \\(\\pi_2\\) | \\(C(1 \\vert 2)\\) | 0 | $ R_1 : {f_2 ( X)} , ; ; ; ; ; R_2 : {f_2 ( X)} $ and let both. $ R_1 : {f_2 ( X)} , ; ; ; ; ; R_2 : {f_2 ( X)} $ 5.8.2 Classification with Two mv \\(N\\) Populations assume \\(\\pmb X_1 \\sim N_p( \\pmb \\mu_1 , \\Sigma_1), \\pmb X_2 \\sim N_p( \\pmb \\mu_2 , \\Sigma_2)\\) 5.8.2.0.1 1. if \\(\\Sigma_1 = \\Sigma_2 = \\Sigma\\) (LDA) this is called Linear Discriminant Analysis, e.g., LDA. $ f_i ( X ) = {(2)^{p/2} {}^{1/2}} $ suppose the populations parameters, \\(\\pmb \\mu_1, \\pmb \\mu_2, \\Sigma\\) are known. The minimum expected cost rule is $ \\[\\begin{alignat*}{2} &amp;R_1 : \\dfrac {f_1 ( \\pmb X)} {f_2 ( \\pmb X)} &amp; &amp;\\ge \\dfrac {P_2}{P_1} \\ast \\dfrac {C(1\\vert2)}{C(2\\vert1)} \\\\ &amp;\\exp \\left[ -\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_1)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_1)&#39; +\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_2)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_2) \\right]&amp; &amp;\\ge \\\\ &amp;-\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_1)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_1)&#39; +\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_2)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_2) &amp; &amp;\\ge \\log \\left[ \\dfrac {P_2}{P_1} \\ast \\dfrac {C(1\\vert2)}{C(2\\vert1)} \\right] \\\\ \\\\ \\\\ \\Rightarrow \\; \\; \\; \\; \\; &amp;(\\pmb \\mu_1 - \\pmb \\mu_2)&#39; \\Sigma^{-1} \\pmb X - \\dfrac {1}{2} (\\pmb \\mu_1 - \\pmb \\mu_2)&#39; \\Sigma^{-1} (\\pmb \\mu_1 + \\pmb \\mu_2) &amp; &amp;\\ge \\\\ \\\\ \\Rightarrow \\; \\hat R_1 \\colon \\; \\; \\; \\; \\; &amp;(\\bar {\\pmb X}_1 - \\bar {\\pmb X}_2)&#39; {S_p}^{-1} \\pmb X - \\dfrac {1}{2} (\\bar {\\pmb X}_1 - \\bar {\\pmb X}_2)&#39; {S_p}^{-1} (\\bar {\\pmb X}_1 + \\bar {\\pmb X}_2) &amp; &amp;\\ge \\tag{1} \\\\ \\\\ \\Rightarrow \\; \\hat R_1 \\colon \\; \\; \\; \\; \\; &amp; \\hat {\\pmb a}&#39; \\pmb X - \\dfrac {1}{2} ( \\hat {\\pmb a}&#39; \\bar {\\pmb X_1} + \\hat {\\pmb a}&#39; \\bar {\\pmb X_2}) &amp; &amp;\\ge \\tag{2} \\end{alignat*}\\] $ Allocate (Classify) \\(\\pmb X_0\\) to \\(\\pi_1\\) if \\(R_1\\) holds. Note that \\(R_1\\) has changed to $ R_1$ at last expression. \\((1):\\) However, in practice, \\(\\pmb \\mu_1, \\pmb \\mu_2, \\Sigma\\) are unknown. 따라서 해당 룰은 상응하는 패러미터를 샘플 패러미터로 대체해서 이루어짐. \\(\\pmb \\mu_i\\)는 ${X}_i $ 로 대체. we assumed \\(\\Sigma_1 = \\Sigma_2 = \\Sigma\\), therefore \\(\\Sigma\\) can be replaced by \\(S_p = \\dfrac{n_1 - 1 } {n_1 + n_2 -2} S_1 + \\dfrac{n_2 - 1 } {n_1 + n_2 -2} S_2\\). \\((2):\\) Note that \\((\\bar {\\pmb X}_1 - \\bar {\\pmb X}_2)&#39; {S_p}^{-1} \\pmb X\\) is linear combination of variable \\(\\pmb X\\). let \\((\\bar {\\pmb X}_1 - \\bar {\\pmb X}_2)&#39; {S_p}^{-1} = \\hat {\\pmb a}&#39;\\). 5.8.2.0.1.1 LDA intuition 5.8.2.0.1.2 Posterior assuming equal prior, equal misclassification cost: $ \\[\\begin{alignat*}{1} P(\\pi_1 \\vert \\pmb X) &amp;= \\dfrac{f_1 ( \\pmb X) } {f_1 ( \\pmb X) + f_2 ( \\pmb X) } \\\\ &amp;= \\dfrac {\\exp \\left[ - \\dfrac {1}{2} (\\pmb X - \\pmb \\mu_1)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_1)&#39; \\right] } {\\exp \\left[ - \\dfrac {1}{2} (\\pmb X - \\pmb \\mu_1)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_1)&#39;\\right] + \\exp \\left[ - \\dfrac {1}{2} (\\pmb X - \\pmb \\mu_2)&#39; \\Sigma^{-1} (\\pmb X - \\pmb \\mu_2)&#39;\\right]} \\end{alignat*}\\] $ Allocate \\(\\pmb X_0\\) to \\(\\pi_1\\), if $P(_1 X_0) P(_2 X_0) $. This is equivalent to the Bayes Rule $R_1 f_1 (X) f_2 (X) $. 5.8.2.0.2 2. \\(\\Sigma_1 \\not = \\Sigma_2\\) (QDA) This is called Quadratic Discriminant Analysis (QDA). suppose the populations parameters, \\(\\pmb \\mu_1, \\pmb \\mu_2, \\Sigma_1, \\Sigma_2\\) are known. $ \\[\\begin{alignat*}{2} R_1 \\colon \\; &amp;-\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_1)&#39; \\Sigma_1^{-1} (\\pmb X - \\pmb \\mu_1)&#39; +\\dfrac {1} {2} (\\pmb X - \\pmb \\mu_2)&#39; \\Sigma_2^{-1} (\\pmb X - \\pmb \\mu_2)&#39;&amp; &amp;\\ge \\log \\left[ \\dfrac {P_2}{P_1} \\ast \\dfrac {C(1\\vert2)}{C(2\\vert1)} \\right] \\\\ \\\\ \\Rightarrow \\; \\; \\; \\; \\; &amp;(\\pmb \\mu_1 \\Sigma_1 ^{-1} - \\pmb \\mu_2 \\Sigma_2 ^{-1} )&#39; \\pmb X - \\dfrac {1}{2} \\pmb X &#39; (\\Sigma_1^{-1} - \\Sigma_2^{-1} ) \\pmb X \\; \\; \\; \\; \\; -k&amp; &amp;\\ge \\tag{3} \\\\ \\\\ \\Rightarrow \\; \\hat R_1 \\colon \\; \\; \\; \\; \\; &amp;(\\pmb \\mu_1 S_1 ^{-1} - \\pmb \\mu_2 S_2 ^{-1} )&#39; \\pmb X - \\dfrac {1}{2} \\pmb X &#39; (S_1^{-1} - S_2^{-1} ) \\pmb X \\; \\; \\; \\; \\; - k&amp; &amp;\\ge \\end{alignat*}\\] $ allocate \\(\\pmb X_0\\) to \\(\\pi_1\\) if \\(R_1\\) holds. \\((3)\\) where $ \\[\\begin{alignat*}{2} k &amp;= \\dfrac {1} {2} \\log \\left( \\dfrac {\\vert \\Sigma_1 \\vert}{\\vert \\Sigma_2 \\vert}\\right) + \\dfrac {1}{2} (\\pmb \\mu_1 &#39; \\Sigma_1^{-1} \\pmb \\mu_1 - \\pmb \\mu_2 &#39; \\Sigma_2^{-1} \\pmb \\mu_2) \\\\ &amp;= \\dfrac {1} {2} \\log \\left( \\dfrac {\\vert S_1 \\vert}{\\vert S_2 \\vert}\\right) + \\dfrac {1}{2} (\\hat {\\pmb X}_1 &#39; S_1^{-1} \\hat {\\pmb X}_1 - \\hat {\\pmb X}_2 &#39; S_2^{-1} \\hat {\\pmb X}_2) \\end{alignat*}\\] $ When \\(\\Sigma_1 = \\Sigma_2\\), \\(\\pmb X &#39; (\\Sigma_1^{-1} - \\Sigma_2^{-1} ) \\pmb X\\) disappears, which means LDA. This regions \\(R_1\\) is defined by quadratic functions of \\(\\pmb X\\). 5.8.3 Evaluating Classification Functions The misclassification probability is \\(P(1 \\vert 2) + P(2 \\vert 1)\\). . If \\(R_1, R_2\\) are selected by Bayes Rule, then this misclassification probability is the minimum. Sample Misclassification Probability: $P_1 {R_2} f_1 (x) dx + P_2 {R_1} f_2 (x) dx $ assume \\(f_1(\\pmb x), f_2(\\pmb x)\\) are unkown. 우리가 분포를 가정하지 않으면 이를 측정하는 것은 상당히 어렵다. 5.8.3.0.1 Apparent Error Rate (APER) 이는 training 샘플 중에서 sample classification function에 의해 분류될 때 잘못 분류된 관찰값들의 분수. * Training Sample: classification function 제작을 위해 사용되는 데이터 * Test Sample: classification function 평가를 위해 사용되는 데이터. 이는 training sample과는 독립. 5.8.3.0.1.1 Confusion Matrix | Predicted Membership \\(\\pi_1\\) | \\(\\pi_2\\) | | Actual\\(\\pi_1\\) | \\(n_{11}\\) | \\(n_{12}\\) | \\(n_1\\) | \\(\\pi_2\\) | \\(n_{21}\\) | \\(n_{22}\\) | \\(n_2\\) | the APER \\(= \\dfrac {n_{21} + n_{12}} {n_1 + n_2}\\): 오분류된 item들의 비율. APER은 true 오분류 확률을 과소평가한다. 이는 classification function 생산에 활용된 데이터들이 또한 이를 평가하기 위해서도 사용되기 때문. 생산에 쓰였던 놈들인만큼 생산된 classification function은 얘들한테 좀 더 최적화되어있을 수밖에 없고 이에 의해 에러율이 낮아진다. 5.8.3.0.2 Test Sample Error Rate training 샘플과 독립인, test 샘플이 따로 존재한다면,우리는 misclassification probability를 test 샘플에서 오분류된 비율로 misclassification probability를 계산하는 것이 가능하다. test 샘플이 없다면, 총 데이터를 training과 test 샘플로 쪼갠다. training 샘플은 classification function의 구축에 사용되고, test 샘플은 이를 평가하는데 쓰인다. 이 과정은 large sample을 필요로 한다. 5.8.3.0.3 Hold-out Error Rate \\(= \\dfrac {n_{21}^{(H)} + n_{12}^{(H)}} {n_1 + n_2}\\) Also called ‘leave-one-out’ or ‘cross-validation’ error rate. 1. 관측값 1개를 뽑아서 (omit) 제외한 후 나머지 데이터들을 사용해서 cf 생산. 2. 위에서 생산한 function을 써서 hold-out 관측값을 분류. 3. 모든 관측값들이 분류될 때까지 1, 2를 반복. 이에 의해, 역으로 1-LOO는 accuracy rate. 5.8.4 Classification with several Populations (wk13) let associated with \\(\\pi_i , i = 1, \\cdots, g\\): * density $f_i (x) $ * Prior distribution \\(P_i\\) * misclassification cost \\(C(k \\vert i)\\) * set of \\(\\pmb x\\) classified as, \\(R_k\\) \\(R_k\\) is the region that * \\(f_k(\\pmb x) \\propto P_k f_k(\\pmb x)\\) is largest * \\(\\sum_{\\not k} f_i(\\pmb x) \\propto \\sum_{\\not k} P_i f_i(\\pmb x) \\propto \\sum_{\\not k} C(k \\vert i) P_i f_i(\\pmb x)\\) is smallest under equal misclassification cost, allocate \\(\\pmb X_0\\) to \\(\\pi_k\\) if: $ \\[\\begin{alignat*}{3} \\forall i \\not = &amp;k: P_k f_k (\\pmb x) &amp;&amp;&gt;P_i f_i (\\pmb x) \\\\ &amp;\\log P_k f_k (\\pmb x) &amp;&amp;&gt;\\log P_i f_i (\\pmb x) \\\\ \\end{alignat*}\\] $ the Bayes rule is identical to the rule that maximizes Posterior Probability \\(P(\\pi \\vert \\pmb X) = \\dfrac{P_k f_k (\\pmb x)}{\\sum_{i=1}^g P_i f_i (\\pmb x)}\\) 5.8.4.0.1 Classification with several Normal Populations assume \\(f_i (\\pmb x) \\sim N_p (\\pmb \\mu_i , \\Sigma_i )\\), and equal misclassification cost. 5.8.4.0.1.1 1. \\(\\Sigma_1 = \\cdots = \\Sigma_g = \\Sigma\\) (LDA) MVN을 따르는 것에서 \\(f_k\\)의 형은 알 수 있다. according to Bayes rule, we allocate \\(\\pmb x_0\\) to \\(\\pi_k\\) if $ P_k f_k ( x_0 ) = _i P_i f_i ( x_0 ) $ 이때 constant $- (2 ) - () - x_0 ’ ^{-1} x_0 $는 모든 \\(\\log P_i f_i (\\pmb x_0)\\)에 대해 공통 (\\(k\\)에 의존하지 않으므로). 따라서 해당 constant 부위는 비교 목적으로는 무시될 수 있음. $ \\[\\begin{align*} d_i (\\pmb x) &amp;= \\pmb \\mu_i &#39; \\Sigma^{-1} \\left( \\pmb x \\right) - \\tfrac{1}{2} \\pmb \\mu_i &#39; \\Sigma^{-1} \\pmb \\mu_i + \\log P_i \\tag{1} \\\\ \\\\ S_p &amp;= \\tfrac{1}{(n_1 + \\cdots +n_g) - g} \\left[ (n_1-1)S_1 + \\cdots (n_g - 1)S_g \\right] \\tag{2} \\\\ \\\\ \\Longrightarrow \\hat d_i (\\pmb x) &amp;= \\bar { \\pmb x_i} S_p^{-1} \\ast \\pmb x - \\tfrac{1}{2} \\bar { \\pmb x_i} &#39; S_p^{-1} \\bar { \\pmb x_i} + \\log P_i \\tag{3} \\end{align*}\\] $ define linear discriminant function (LDF) \\(d_i (\\pmb x)\\), where \\(i=1, \\cdots, g\\). \\(\\Sigma\\)’s pooled estimate \\(S_p\\) \\(d_i (\\pmb x)\\)’s estimate \\(\\hat d_i (\\pmb x)\\), 실질적으로 사용할 LDF function. Estimated Bayes Rule: allocate \\(\\pmb x_0\\) to \\(\\pi_k\\), if \\(\\hat d_k(\\pmb x_0) = \\max \\{ \\hat d_1(\\pmb x_0), \\cdots, \\hat d_g(\\pmb x_0) \\}\\). 뒤의 조건을 만족하는 것이 Likelihood의 키가 가장 큰 population이므로. 5.8.4.0.1.2 2. \\(\\not = \\Sigma\\) (QDA) $ P_k f_k ( x_0 ) = _i P_i f_i ( x_0 ) $ constant \\(-\\dfrac{p}{2} \\log(2 \\pi)\\)는 모든 \\(\\log P_i f_i (\\pmb x_0)\\)에 대해 공통, 무시 가능. define quadratic discriminant function \\(d_i^Q (\\pmb x)\\), where \\(i=1, \\cdots, g\\): $ \\[\\begin{align*} d_i^Q (\\pmb x) &amp;= -\\dfrac{1}{2} \\log\\vert\\Sigma_i \\vert -\\dfrac{1}{2} (\\pmb x - \\pmb \\mu_i)&#39; \\Sigma_i^{-1} (\\pmb x - \\pmb \\mu_i) +\\log P_i \\\\ \\\\ \\hat {d}_i^Q (\\pmb x) &amp;= -\\dfrac{1}{2} \\log\\vert S_i \\vert -\\dfrac{1}{2} (\\pmb x - \\bar {\\pmb x_i})&#39; S_i^{-1} (\\pmb x - \\bar {\\pmb x_i}) +\\log P_i \\tag{Sample} \\end{align*}\\] $ Estimated Bayes Rule: allocate \\(\\pmb x_0\\) to \\(\\pi_k\\), if \\(\\hat d_k^Q(\\pmb x_0) = \\max \\{ \\hat d_1^Q(\\pmb x_0), \\cdots, \\hat d_g^Q(\\pmb x_0) \\}\\) 5.8.5 Other Discriminant Analysis Methods Nearest Neighbor Discriminant Analysis (거리 함수 사용) Nonparametric approach – no assumption on distribution Idea *For a new observation, first find the observation in the training sample that is closest to the new observation. (i.e. its Mahalanobis distance is smallest) Then assign the new observation to the group from which the observation’s nearest neighbor comes. Variations: K-nearest neighbor assign each new observation to the group to which a majority of its k nearest neighbors belongs. e.g. k=5. 5.8.5.0.1 KNN \\(K_1\\) belongs to group 1, \\(K_2\\) belongs to group 2. 우리는 \\(K_1 + K_2 =K =5\\) 로 설정함. 즉 가장 가까운 이웃 5개를 뽑되 Group 1과 Group 2에서 뽑은 애들을 합하면 총 5개여야 함. assign \\(\\pmb x_0\\) to group 1 (\\(\\pi1\\)) if \\(K_1 \\ge K_2\\). - if \\(n_1 \\not = n_2\\), then assign \\(\\pmb x_0\\) to \\(\\pi1\\) if \\(\\dfrac{K_1}{n_1} \\ge \\dfrac{K_2}{n_2}\\). - if \\(P_1 \\not = P_2\\), then assign \\(\\pmb x_0\\) to \\(\\pi1\\) if \\(P_1\\dfrac{K_1}{n_1} \\ge P_2\\dfrac{K_2}{n_2}\\). choice of hyper-parameters \\(K\\): \\(K = \\sqrt{n_1}\\). select \\(K\\) s.t. minimizes the error rate 5.8.5.0.2 Kernel (Density Estimation) Discriminant Analysis (KDA) Bayes Rule 이론에서 출발, Likelihood 함수 사용 (KNN과는 이 부분부터 다름. KNN은 Bayes Rule 안썼음): allocate \\(\\pmb x_0\\) to \\(\\pi_k\\), if \\(\\dfrac{f_1 (\\pmb x)}{f_2 (\\pmb x)} \\ge \\dfrac{P_2 C(1 \\vert 2)}{P_1 C(2 \\vert 1)}\\) 분포에 대한 가정 없이 개시하므로, 밀도함수 자체를 추정해버리자. density estimation: estimate f_1 (x) and f_2 (x) for each point \\(\\pmb x\\), where \\(N(\\pmb x_0)\\) is neighborhood around \\(\\pmb x_0\\) of width \\(\\lambda\\) 이동 히스토그램 람다는 벽돌 하나의 넓이이며, 람다값이 달라지면 추정된 pdf의 형 또한 조금씩 바뀔 수 있음 $ f(x_0) = $ this estimate is bumpy. 더 발전된 추정법을 찾아내자. 개선된 추정법: Parzen Estimate $ f(x_0) = {i=1}^N K{} (x_0 , x_i) $ 위의 초기형 추정에서 사용된 커널함수는 uniform. 가우시안 커널은 정규분포의 형을 따르므로 이는 당연히 분산을 필요로 함. 여기서 분산 부분에 들어가는건 람다이며, 따라서 람다는 벽돌의 넓이, width를 결정하게 된다. 따라서 람다는 called as smoothing parameters, or bandwidth. 추정의 성능은 거의 전적으로 람다의 selection에 달려있음. 람다 잘 고르면 추정 성능 높고, 람다 잘못 고르면 떡락함. 람다를 너무 좁게 잡으면 삐쭉삐쭉해서 과반영되고, 너무 넓게 잡으면 민둥산이 나와서 값 간의 density가 다 비슷비슷한 나쁜 pdf가 추정됨. at here, popular choice of \\(K_{\\lambda}\\) is Gaussian kernal: $ K_{} (x_0 , x) = ( ) = { ( x_i - x_0 )^2 } $ estimated Bayes Rule: allocate \\(\\pmb x_0\\) to \\(\\pi_1\\), if \\(\\dfrac{\\hat f_1 (\\pmb x_0)}{\\hat f_2 (\\pmb x_0)} \\ge \\dfrac{P_2 C(1 \\vert 2)}{P_1 C(2 \\vert 1)}\\) 이런 식의 비율 접근법은 클래스가 2개인 경우 한정. 늘어나면 달라? 5.8.5.0.3 Modern Classification Methods: Decision Trees Classification Trees Regression Trees Neutral Networks Support Vector Machines Ensemble "],["clustering-distance-methods-and-ordination.html", "5.9 Clustering, Distance Methods, and Ordination", " 5.9 Clustering, Distance Methods, and Ordination 5.9.1 Overview Example: Customer Segmentation 5.9.1.0.1 Clustering 군집화의 기준 동일한 군집에 속하는 개체 (또는 개인) 은 여러 속성이 비슷하고, 서로 다른 군집에 속한 관찰치는 그렇지 않도록 (여러 속성이 비슷하지 않도록) 군집을 구성 군집화를 위한 변수: 전체 개체 (개인) 의 속성을 판단하기 위한 기준 인구통계적 변인 (성별, 나이, 거주지, 직업, 소득, 교육 등) 구매패턴 변인 (상품, 주기, 거래액 등) 군집분석에서는 관측값들이 서로 얼마나 유사한지, 또는 유사하지 않은지를 측정할 수 있는 측도가 필요하다. - 군집분석에서는 보통 유사성(similarity)보다는 비유사성(dissimilarity)를 기준으로 하며, 거리(distance)를 사용한다. \\(x\\)가 연속형일 때 CA의 위력이 최고로 발휘됨. 유사성의 척도로 거리가 사용되는데, 카테고리컬 변수에는 거리 계산이 불가능하기 때문. 꼭꼭 카테고리컬 변수로 CA를 해야겠다면 지시변수로 대체하여 CA를 시도할 수는 있겠으나, 이는 어느정도 억지로 하는 것이고 오점없는 CA는 아님. 5.9.1.0.2 Distance Measures 거리 (Distance) 라는 함수. CA에서 사용되는 모든 거리는 pairwise 거리. Euclid 거리 (Euclidean) : 가장 메이저함 p차원 공간에서 주어진 두 점 \\(\\pmb x=(x_1 , \\cdots, x_p), \\; \\; \\pmb y=(y_1 , \\cdots, y_p)\\) 사이의 유클리드 거리는 $ d(x, y) = $ if \\(p=2\\), {:start=“2”} Minkowski 거리 $ d(x, y) = { {_{i=1}^p (x_i - y_i)^m} }^{} $ \\(m=2\\)일 때 이는 Euclidean과 같아진다. 보통은 m의 값으로 짝수를 많이 씀. 민코프는 결국 Euclidean의 일반화. {:start=“3”} Mahalanobis 거리 위에서 A와 B의 거리만을 보는 것이 아니라 위의 점들의 군집의 패턴 또한 고려함. x축과 y축에 해당하는 변수들 사이에 correlation이 있다는 것을 반영함. 중앙의 \\(S^{-1}\\)으로 corr 구조를 반영하는 것. 뭔 메커니즘으로? 위 케이스를 생각하면 A는 전체적인 패턴의 연장선 상에서 멀리 있는데, B는 패턴에서 직교해서 벗어나면서 가까이 있음. 따라서 A보다 B가 멀다고 평가 가능. $ d(x, y) = $ {:start=“4”} Manhattan 거리 $ d_{Manhattan} (x, y) = {_{i=1}^p x_i - y_i } $ Standardization CA는 자료 사이의 거리를 이용하여 수행되기 때문에, 각 자료의 단위가 결과에 큰 영향을 미친다. 이러한 문제를 해결하기 위하여, 가장 널리 쓰이는 방법이 표준화 방법이다. 표준화 방법이란 각 변수의 관찰값으로부터 그 변수의 평균을 빼고, 그 변수의 표준편차로 나누는 것이다. 표준화된 모든 변수가 평균이 0이고 표준편차가 1이 된다. 사실상 필수. Graphical Tools Scatter Plot Scatter Plot using PCA Andrews Plot Star Plot Chernoff Faces 5.9.2 Hierarchical Clustering Start with \\(N\\) clusters, each containing a single entity and an \\(N \\times N\\) symmetric matrix of distances, \\(D=\\{d_{ik}\\}\\). Search the distance Matrix \\(D\\) for the nearest pair of clusters. Let the distance b/w the most similar (가장 거리가 작은) clusters \\(U\\) and \\(V\\) be \\(d_{UV}\\). Mearge clusters \\(U\\) and \\(V\\). Label the newly formed cluster \\((UV)\\). Update the entries in the distance Matrix \\(D\\) by squences below. The distance b/w \\((UV)\\) and other cluster \\(W\\) is denoted by \\(d_{(UV)W}\\). deleting rows and columns corresponding to clusters \\(U\\) and \\(V\\), then adding a row and a column giving the distance b/w \\((UV)\\) and the remaining clusters. repeat steps 2 and 3 a total of \\(N-1\\) times. Then, all observations will be in single clusters. Record the identity of clusters that are merged and the levels at which the mergers take place. 5.9.2.0.1 계층적 군집분석 Example distance Matrix \\(D\\)는 \\(n^2\\)에 의존하여 변수 숫자가 증가하면 연산 시간도 기하급수적으로 증가. {:start=“5”} 5. 계층적 분석에서만 덴드로그램을 그릴 수 있음. a graphical tool to illustrate the merges or divisions. python 라이브러리 함수 기준 총 distance의 70%에서 짤라서 clutser를 판정. color_threshold. 5.9.2.0.2 HCA의 종류 Single Linkage, 단일 연결 (mimum distance, or nearest neighbor) $ d_{(UV)W} = ( d_{UW}, d_{VW} ) $ {:start=“2”} 2. Complete Linkage, 완전 연결 (maximum distance, or farthest neighbor) $ d_{(UV)W} = ( d_{UW}, d_{VW} ) $ {:start=“3”} 3. Average Linkage, 평균 연결 (average distance) - 위의 둘이 변동이 너무 심해서 이를 해결하기 위해 제시됨 $ d_{(UV)W} = ( {i=1}^{n{UV}} {j=1}^{n{W}} d_{ij} ) $ {:start=“4”} 4. Centriod Method, 중심점 연결 (For each cluster, compute the centroid) $ d_{(UV)W} = U V $ {:start=“5”} 5. Ward’s Method bold들이 무난함 5.9.2.0.3 HCA의 장단점 Advantage: - cluster의 수를 알 필요가 없음 - 덴드로그램 통해 군집화 프로세스와 결과물을 표현 가능 Disadvantage: - 계산속도가 느림 - 아웃라이어 (이상치) 가 존재할 경우, 초기 단계에 잘못 분류된 군집은 분석이 끝날때까지 소속 cluster가 변하지 않음 - 아웃라이어에 대한 사전검토 필요, Centroid 방법이 아웃라이어에 덜 민감함 5.9.3 K-means Clustering K-평균 군집분석법. 사전에 결정된 군집수 \\(k\\)에 기초하여 전체 데이터를 상대적으로 유사한 k개의 군집으로 구분한다. Proceeds: 1. 군집수 k를 결정한다 2. 초기 k개 군집의 중심을 선택한다 (랜덤하게) 3. 각 관찰치를 그 중심과 가장 가까운 거리에 있는 군집에 할당한다. 4. 형성된 군집의 중심 (centroid) 을 계산한다. 5. 3-4의 과정을 기존의 중심과 새로운 중심의 차이가 없을 때까지 반복한다. 5.9.3.0.1 Determination of K KCA의 결과는 초기 군집수 k의 결정에 민감하게 반응한다. 여러가지의 k값을 선택하여 CA를 수행한 후 가장 좋다고 생각되는 k값을 이용. Elbow point 계산하여 k 선택 Silhouette plot으로 k 선택 자료의 시각화를 통하여 K를 결정 (ex. star plot을 2차원 df로 바꾸어 평균 체크했었음) 자료의 시각화를 위해서는 차원축소가 필수적이고, 이를 위하여 PCA가 널리 사용된다. 대용량 데이터에서 sampling한 데이터 (이것이 스몰데이터가 됨) 로 HCA를 우선 수행하여 (여기서 덴드로그램이 얻어짐) k의 값을 선택 (즉 HCA와 KCA를 둘 다 쓰므로 hybrid) 5.9.4 군집의 평가방법 Silhouette Score (Silhouette Plot) $ s(i) = = \\[\\begin{cases} 1-\\dfrac{a(i)}{b(i)}, &amp; if \\; \\; a(i) &lt; b(i) \\\\ 0, &amp; if \\; \\; a(i) = b(i) \\\\ \\dfrac{b(i)}{a(i)} - 1, &amp; if \\; \\; a(i) &gt; b(i) \\end{cases}\\] $ \\(a(i)\\): 개체 \\(i\\)로부터 같은 군집 내에 있는 모든 다른 개체들 사이의 평균 거리. 작을수록 좋다. 작을수록 해당하는 군집 안에서 중앙 부분에 components가 모여 있다는 소리이므로. \\(b(i)\\): 개체 \\(i\\)로부터 다른 군집 내에 있는 개체들 사이의 평균 거리 중 가장 작은 값. 클수록 좋다. 클수록 다른 군집에 헷갈려서 속할 일 없이 확실하게 현재 소속되어 있는 군집에 소속되어 구분된다는 소리이므로. 1을 넘어갈 수 없으며, 1에 가까울수록 군집화가 잘 된 관찰값. 몇개의 cluster가 설정되었을 때 가장 해당 stat이 높게 나오는지를 통해 판정하는 것이 이 접근법. 평균 Silhouette Score는 모든 obs마다 \\(s(i)\\)를 구하여 이를 평균낸 값이므로, 평균 Silhouette Score가 1에 가까울수록 군집분석이 잘됐다고 판단 가능. 5.9.5 Clustering using Density Estimation (wk14) Based on nonparametric density estimation The clusters may be viewed as high-density regions in the space separated by low-density regions between them. No need to specify the number of clusters. It is determined by the method itself. 밀도기반 추정에 요구되는 (hyper) Parameter: bandwidth. 해당 값이 달라지면 결과도 달라짐. Iris 데이터 예 5.9.5.0.1 Kernel Density Estimation (KDE) $ f(x_0) = _{i=1}^N K ( ) , ; ; ; ; ; x R $ N은 샘플사이즈, 람다는 밴드위스, K는 스무딩 커널, x_i는 obs closed form처럼 보이지만 그냥 상징적인 공식일 뿐. closed form이 있는게 아니라 데이터 포인트마다 고유한 값이 추정되는 것으로 진행됨. 밀도추정에서 가장 많이 쓰는 방법. 추정하고 싶은 포인트는 \\(x_0\\). \\(x_0\\)라는 포인트에 대해 density를 추정하고 싶다. \\(x_0\\) 인근의 관찰치는 더 많은 가중치를 가짐. \\(x_0\\) 로 부터 멀어질수록 가중치는 감소함. 각 obs 별로 커널함수 부여하고 최종적으로 그 커널함수 다 더한 다음에 스케일링하면 끝. K의 가장 흔한 선택은 정규분포함수, 즉 Gaussian Kernel Bandwidth 의 효과: 커널함수의 좌우 넓이에 해당하는 것으로서, 가우시안 커널에서는 표준편차에 해당함. Bandwith가 크면 x값들 간에 차별화가 덜되어서 추정 위력이 떨어짐 봉우리의 갯수는 군집의 갯수로 생각할 수 있음. 지나치게 밴드위스가 좁으면 뾰족한 부분이 다수 튀어나와 군집의 과다추정 발생 그래프는 1차원 밀도 추정에 해당 회색: 정답. 표준정규분포 붉은색: undersmoothed,  = 0.05 (too small) 녹색: oversmoothed,  = 2 (too large) 검정색: optimally smoothed,  = 0.337 Bandwidth 추정 2D Kernel Density Estimation: 2차원에서의 KDE는 어떻게 확장될 것인가? 5.9.6 Multidimensional Scaling (MDS) Dimension Reduction Methods - PCA : x변수들끼리의 분산을 최대화시키는 방향으로 차원축소. 한 변수의 분산이 최대화되어야 함 - Factor: 변수간의 correlation을 최대한 깨트리지 않고 반영하는 방향으로 DR. Corr 구조가 최대한 유지 - MDS - Canonical Discriminant Analysis 이중 위의 둘은 original data의 Variance 설명에 집중함. (ex. 1명이 401호, 1명이 501호에 있다고 하면, 둘의 직선 거리가 그렇게 크게 떨어져있다고 하기는 어렵지만 위의 두 분석법은 멀리 떨어져 있는 것처럼 그래프에 표현될 수 있음. 거리 개념이 없기 땨문) MDS Fit (projection) the original data into a low-dimensional coordinate system such that any distortion caused by a reduction in dimensionality is minimized. Map the distances between points in a high dimensional space into a lower dimensional space. distortion이란? dissimilarity (distance) among the original data points For a given set of observed similarities (or distances) between every pair of N items, find a representative of the items in as few dimensions as possible such that the similarities (or distances) in the lower dimensions match, as close as possible with the original similarities (or distances). Nonmetric MDS Only the rank orders of the N(N-1)/2 original similarities are used to arrange N items in a lower-dimensional coordinate system. 거리 없이 rank만 주어져있음. rank만 안무너지도록 Metric MDS (자주씀. Principal Coordinate Analysis) The actual magnitudes of the original similarities are used to obtain a geometric representation. 5.9.6.0.1 Kruskal’s Stress so-called Badness of fit criterion. MDS가 잘됐다면 기존 오리지널 차원의 거리나 차원축소된 이후의 거리나 비슷해야 함. 크루스칼 스트레스가 작으면 왜곡도 작은 것. 스트레스가 최소인 DR이 최고의 DR. Let \\(D_{rs}\\) denote the actual distance (or dissimilarity) between item r and item s, then the ordered distances are $D_{r_1 s_1 } &lt;D_{r_2 s_2 } &lt; &lt; D_{r_M s_M }, ; ; ; M= \\[\\begin{pmatrix} N \\\\ 2 \\end{pmatrix}\\] $. Let \\(d_{rs}\\) denote the distance between item r and item s in the lower dimensional space. MDS seeks (iteratively) to find a set of \\(d\\)’s such that \\(d_{r_1 s_1 } &lt;d_{r_2 s_2 } &lt; \\cdots &lt; d_{r_M s_M }\\) and \\(Stress = \\left\\{ \\dfrac{\\sum_{i=1}^N \\sum_{j=1}^{i-1}(D_{ij} - d_{ij})^2} {\\sum_{i=1}^N \\sum_{j=1}^{i-1} \\left( D_{ij} \\right)^2} \\right\\}^{\\tfrac{1}{2}}\\) is minimized. Interpretation Guideline Stress Goodness of Fit 20% Poor 10% Fair 5% Good 2.5% Excellent 0% Perfect Goodness of fit = monotonic relationship between the similarities and the final distances. Takane’s Stress $ Stress = { {{i=1}^N {j=1}{i-1}(D_{ij}2)^2} }^{} $ Algorithm: 1. For N items, obtain \\(M=\\dfrac{N(N-1)}{2}\\) 개의 distances \\(D_{r_1 s_1 }, D_{r_2 s_2 } , \\cdots , D_{r_M s_M }\\). Tehn an \\(N \\times N\\) matrix \\(D = \\{D_{ij} \\}\\) is constructed. Using a trial configuration in q dimensions, determine distances \\(d_{ij}^{(q)}\\). The method to get initial \\(d_{ij}^{(q)}\\) is given later. Using the \\(d_{ij}^{(q)}\\), move the points around to obtain an improved configurations. A new configuration: new \\(d_{ij}^{(q)}\\) and smaller stress (e.g. Newton-Raphson method) The process is repeated until the best (minimum stress) representation is obtained. Plot minimum stress (q) versus q and choose the best number of dimensions, \\(q^\\ast\\) from an examination of this plot. x축은 축소된 차원, y축은 stress. 차원이 작아질수록 Stress는 높고, 차원이 p라면 (original 차원과 같다면) Stress는 0. PCA와 달리 여기서는 elbow에서 멈춤. similar to scree plot Note: 1. The larger the dimension, the better the fit. 2. Higher dimension means harder to visualize. 5.9.6.0.2 Algorithm to find 초기값 \\(d_{ij}^{(q)}\\) q값을 줄이려면 수치해석을 시작하기 전에 넣어줄 초기값에 해당하는 초기좌표들이 필요함. 그 값을 구하는 방법. Construct the \\(N \\times N\\) matrix \\(A = \\{ a_{ij} \\} = \\left\\{ -\\dfrac{1}{2} D_{ij}^2 \\right\\}\\). Construct the \\(N \\times N\\) matrix \\(B = \\left(I - \\dfrac{1}{N} J \\right) A \\left(I - \\dfrac{1}{N} J \\right) = \\{ b_{ij} \\} = \\{ \\bar a_{ij} - \\bar a_{i.} - \\bar a_{.j} + \\bar a_{..} \\}\\). where $ a_{..} = ^N ^N , ; ; ; ; ; J = \\[\\begin{bmatrix} 1 &amp; \\cdots &amp; 1 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; \\cdots &amp; 1 \\end{bmatrix}\\] $ {:start=“3”} D행렬은 distance들의 SSE 행렬 정도에 해당. Since \\(B\\) is a symmetric matrix, use the spectral decomposition to write \\(B\\) in the \\(B = V \\Lambda V&#39;\\). If B is positive semidefinite of rank q (p차원 아님!! \\(q \\le p\\). 거리행렬이 일정 ev까지는 유의할 수 있는데 그 후로는 0만 튀어나올 수 있으며 DR은 바로 이상황에서 일어남. p는 위에서 보였던 유사 scree plot에서 original data의 차원으로 지정되었던 숫자) , there are q positive eigenvalues. if $ _1 = \\[\\begin{bmatrix} \\lambda_1 &amp; \\cdots &amp; \\pmb 0 \\\\ &amp; \\ddots &amp; \\\\ \\pmb 0 &amp; \\cdots &amp; \\lambda_q \\end{bmatrix}\\] _{q q}, ; ; ; ; ; V_1 = \\[\\begin{bmatrix} \\pmb v_1 , \\pmb v_2 , \\cdots, \\pmb v_q \\end{bmatrix}\\] _{N q} $ then we can express $ B = { V_1 }{N q} { 1 }{q q} { V_1 ’ }{q N} = V_1 _1^{1/2} _1^{1/2} V_1 ’ = ZZ’ $ where $ Z = V_1 _1^{1/2} = \\[\\begin{bmatrix} \\sqrt{\\lambda_1} \\pmb v_1 , \\sqrt{\\lambda_2} \\pmb v_2 , \\cdots, \\sqrt{\\lambda_q} \\pmb v_q \\end{bmatrix}\\] = \\[\\begin{bmatrix} \\pmb z_1 &#39; \\\\ \\pmb z_2 &#39; \\\\ \\vdots \\\\ \\pmb z_q &#39; \\end{bmatrix}\\] _{N q} $ {:start=“4”} The rows $z_1 ’ , z_2 ’ , , z_q $ of \\(Z\\) are the points whose interpoint distance \\(d_{ij}^{(q)} = (\\pmb z_i - \\pmb z_j)&#39;(\\pmb z_i - \\pmb z_j)\\) match $D_{ij} $s in the original distance matrix \\(D\\). Since \\(q\\) will typically be too large to be of practical interest and we would prefer a smaller dimension \\(k\\) for plotting, we can use the first \\(k\\) eigenvalues and corresponding eigenvectors to obtain \\(N\\) points whose distances \\(d_{ij}^{(k)}\\) are approximately equal to the corresponding \\(D_{ij}\\). 오리지널 데이터의 차원 p가 15개였다면, 이 차원을 SVD했을 때 ev 중 5개가 0이어서 q는 15개로 하였다. 여기서 차원을 더 줄이고 싶다면, 가령 k=5개까지 임의로 내려버리고 싶다면, 뒤쪽의 ev 10개에 해당하는 걸 쳐내는 것 Rank is clearly rank 2. 즉 차원을 2차원까지 줄여도 손실되는 정보가 전혀 없다. 따라서 orginal data Distance Matrix에서 보였던 특성이 그대로 똑같이 드러난다. "],["linear.html", "Chapter 6 Linear ", " Chapter 6 Linear "],["svd.html", "6.1 SVD", " 6.1 SVD 6.1.1 Spectral Decomposition $ \\[\\begin{align} A = \\begin{pmatrix} a_{11} &amp; &amp; \\cdots &amp; &amp; a_{1n} \\\\ \\vdots &amp; \\ddots &amp; &amp; &amp; \\vdots \\\\ a_{i1} &amp; &amp; \\ddots &amp; &amp; a_{1n} \\\\ \\vdots &amp; &amp; &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; &amp; \\cdots &amp; &amp; a_{mn} \\end{pmatrix} = (a_{ij}) &amp;\\; \\; \\; \\; \\; \\; \\;= \\begin{pmatrix} \\pmb r_1 \\\\ \\vdots \\\\ \\pmb r_m \\end{pmatrix} \\\\\\ \\\\\\ &amp;\\; \\; \\; \\; \\; \\; \\;= \\begin{pmatrix} \\pmb c_1 &amp; \\cdots &amp; \\pmb c_m \\end{pmatrix} \\end{align}\\] $ for symmetric matrix \\(A\\): $ A_{p p} = ^{T} = _{j=1}^p _j _j _j^T $ $ \\[\\begin{alignat}{2} &amp;\\Lambda = diag \\{\\lambda_1 , \\cdots, \\lambda_p \\} &amp;&amp;\\; \\; \\; \\; \\;= \\begin{pmatrix} \\lambda_1 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; \\cdots &amp; \\lambda_p \\end{pmatrix} _{p \\times p} \\\\ &amp;\\Gamma &amp;&amp;\\; \\; \\; \\; \\;= \\begin{pmatrix} \\pmb\\gamma_1 ,&amp; \\cdots, &amp;\\pmb\\gamma_p \\end{pmatrix}_{p \\times p} \\end{alignat}\\] $ where \\(\\pmb \\gamma_j\\) is evec of \\(A\\). Therefore \\(\\Gamma\\) is orthogonal Matrix. let symmetric Matrix of rank \\(r\\), \\(A_{p \\times p}\\), \\((r \\le p)\\). Then there exists orthogonal Matrix \\(\\Gamma_{p \\times p}\\), which means \\(\\Gamma^T \\Gamma = I_p\\) and $ A = ^T = \\[\\begin{pmatrix} \\Lambda_1 &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\] ^T = _1 _1 ^T_1 $ where letting \\(\\delta_i=\\) i-th ev, \\(i=1, \\cdots, r\\), then $ \\ \\ = \\[\\begin{pmatrix} \\{\\Gamma_1\\}_{p \\times r} , \\; \\; \\; \\{\\Gamma_0\\}_{p \\times (p-r)} \\end{pmatrix}\\] \\ \\ = diag {_1 , , _r } = \\[\\begin{pmatrix} \\lambda_1 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; \\cdots &amp; \\lambda_r \\end{pmatrix}\\] _{r r} $ then \\(\\Gamma_1^T \\Gamma_1 = I_r, \\; \\; \\; \\; \\Gamma_1^T \\Gamma_0 = 0\\) and $ A^2 = A’A = AA’ = (_1 _1 ^T_1)’ _1 _1 ^T_1 = _1 _1 ^T_1 _1 _1 ^T_1 = _1 _1^2 ^T_1 $ let \\(\\{\\pmb \\gamma_i\\}_{p \\times 1}\\) be i-th column vector of \\(\\Gamma\\). then $ _i’ _i = \\[\\begin{cases} 1 &amp; &amp; i=j \\\\ 0 &amp; &amp; i \\not = j \\end{cases}\\] $ thus $ \\[\\begin{alignat}{2} A &amp;= \\Gamma_1 \\Lambda_1 \\Gamma^T_1 &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ A&#39;A &amp;= \\Gamma_1 \\Lambda_1^2 \\Gamma^T_1 &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ AA&#39;&amp;= &amp;&amp; \\\\ \\gamma_k &#39; A &amp;= \\lambda_k \\gamma_k &#39; \\gamma_k \\gamma_k &#39; &amp;&amp;= \\lambda_k \\pmb\\gamma_k &#39; \\\\ A \\gamma_k &amp;= \\lambda_k \\gamma_k \\gamma_k &#39; \\gamma_k &amp;&amp;= \\lambda_k \\pmb \\gamma_k \\end{alignat}\\] $ 6.1.1.0.1 remark let orthogonal Matrix \\(\\Gamma\\), therefore \\(\\Gamma &#39; \\Gamma = I\\), and \\(\\det(\\Gamma) = \\vert \\Gamma \\vert = 1\\). let symmetric Matrix \\(A_{p \\times p}\\) with full rank. then by SVD, $ (A) = A = ^T = = \\[\\begin{vmatrix} \\lambda &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; \\lambda_p \\end{vmatrix}\\] = _{i=1}^p _i $ let symmetric Matrix \\(A_{p \\times p}\\) with full rank. then by SVD, $ n: ; ; ; A^n = (‘) (’)(‘) = ^n ’ $ in particular, a Cov Matrix \\(\\Sigma\\) can be written by $ = ^T = _{i=1}^r _i _i _i’ \\ ^{-1} = ^{-1} ^T = _{i=1}^r _i^{-1} _i _i’ \\ ^{-} = ^{-} ^T = _{i=1}^r _i^{-} _i _i’ $ 6.1.2 Singular value Decomposition: General-version decomposition of any aribtrary Matrix with rank \\(r\\), \\(A_{n \\times p} = \\Gamma_{n \\times r} \\Lambda \\triangle_{p \\times r} &#39; = \\sum_{j=1}^r \\lambda_j \\pmb \\gamma_j \\pmb \\delta_j &#39;\\). \\(\\Lambda = diag(\\lambda_1 , \\cdots, \\lambda_r), \\; \\; \\; \\; \\lambda_j &gt;0\\). 이때 \\(\\lambda_i\\)는 \\(AA&#39;\\)나 \\(A&#39;A\\)의 non-zero ev. \\(\\Gamma, \\triangle\\)는 \\(AA&#39;\\)와 \\(A&#39;A\\)의 corresponding \\(r\\) evec으로 구성. 따라서 Both $’ = ’ = I_r $, i.e., are column orthogonal. thus $ \\[\\begin{alignat}{2} A &amp;= \\Gamma \\Lambda \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\delta_i &#39; \\\\ A&#39;A &amp;= \\triangle \\Lambda^2 \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\delta_i \\pmb \\delta_i &#39; \\\\ AA&#39;&amp;= \\Gamma \\Lambda^2 \\Gamma^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ \\gamma_k &#39; A &amp;= \\gamma_k &#39; \\Gamma \\Lambda \\triangle^T &amp;&amp;= \\lambda_k \\pmb \\delta_k &#39; \\\\ A \\delta_k &amp;= \\Gamma \\Lambda \\triangle^T \\delta_k &amp;&amp;= \\lambda_k \\pmb \\gamma_k \\end{alignat}\\] $ a b \\(\\begin{alignat}{2} A &amp;= \\Gamma \\Lambda \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\delta_i &#39; \\\\ A&#39;A &amp;= \\triangle \\Lambda^2 \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\delta_i \\pmb \\delta_i &#39; \\\\ AA&#39;&amp;= \\Gamma \\Lambda^2 \\Gamma^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ \\gamma_k &#39; A &amp;= \\gamma_k &#39; \\Gamma \\Lambda \\triangle^T &amp;&amp;= \\lambda_k \\pmb \\delta_k &#39; \\\\ A \\delta_k &amp;= \\Gamma \\Lambda \\triangle^T \\delta_k &amp;&amp;= \\lambda_k \\pmb \\gamma_k \\end{alignat}\\) $\\[\\begin{alignat}{2} A &amp;= \\Gamma_1 \\Lambda_1 \\Gamma^T_1 &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ A&#39;A &amp;= \\Gamma_1 \\Lambda_1^2 \\Gamma^T_1 &amp;&amp;=\\sum_{i=1}^r \\lambda_i^2 \\pmb \\gamma_i \\pmb \\gamma_i &#39; \\\\ AA&#39;&amp;= &amp;&amp; \\\\ \\gamma_k &#39; A &amp;= \\lambda_k \\gamma_k &#39; \\gamma_k \\gamma_k &#39; &amp;&amp;= \\lambda_k \\pmb\\gamma_k &#39; \\\\ A \\gamma_k &amp;= \\lambda_k \\gamma_k \\gamma_k &#39; \\gamma_k &amp;&amp;= \\lambda_k \\pmb \\gamma_k \\end{alignat}\\] $ c d therefore, generalized inverse matrix, G-inverse Matrix \\(A^-\\) will be $ \\[\\begin{alignat}{2} A &amp;= \\Gamma \\Lambda \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\delta_i &#39; \\\\ A^- &amp;= \\triangle \\Lambda^{-1} \\Gamma&#39; &amp;&amp;=\\sum_{i=1}^r \\lambda_i^{-1} \\pmb \\delta_i \\pmb \\gamma_i &#39; \\\\ AA^- A &amp;= \\Gamma \\Lambda \\triangle^T \\ast \\triangle \\Lambda^{-1} \\Gamma&#39; \\ast \\Gamma \\Lambda \\triangle^T &amp;&amp;=\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\delta_i &#39; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; = A \\end{alignat}\\] $ 6.1.3 Singular value Decomposition: Another-version rank \\(r\\) arbitrary Matrix \\(A_{n \\times p} = \\Gamma_{n \\times r} \\Lambda \\triangle^T_{p \\times r} =\\sum_{i=1}^r \\lambda_i^{\\tfrac{1}{2}} \\pmb \\gamma_i \\pmb \\delta_i &#39;\\) \\(\\Lambda = diag(\\lambda_1^{\\tfrac{1}{2}} , \\cdots, \\lambda_r^{\\tfrac{1}{2}}), \\; \\; \\; \\; \\; \\lambda_j^{\\tfrac{1}{2}} &gt;0\\). 이때 \\(\\lambda_i\\)는 \\(AA&#39;\\)와 \\(A&#39;A\\)의 non-zero ev. \\(\\Gamma, \\triangle\\)는 \\(AA&#39;\\)와 \\(A&#39;A\\)의 corresponding \\(r\\) evec으로 구성. 따라서 Both $’ = ’ = I_r $, i.e., are column orthogonal. 6.1.4 Quadratic Forms for symmetric Matrix \\(A_{p \\times p}\\), vector \\(\\pmb x \\in \\mathbb{R}^p\\): $ Q(x) = x’ A x = {i=1}^p {j=1}^p a_{ij} x_i x_j $ $ \\[\\begin{align} \\forall x \\not = 0: Q(x) &amp;&gt; 0 \\tag{positive definite} \\\\ \\\\ \\forall x \\not = 0: Q(x) &amp;\\ge 0 \\tag{positive semi-definite} \\end{align}\\] $ if corresponding quadratic form \\(Q(\\cdot)\\) is positive definite(semi-definite), \\(A\\) is called positive definite(semi-definite). This is written by \\(A&gt;0 \\; \\; \\; (\\ge 0)\\). 6.1.4.0.1 propositions if \\(A=A&#39;\\), and \\(Q(x) = \\pmb x &#39; A \\pmb x\\) is corresponding quadratic form, then $y = ^T x: ; ; ; Q(x) = x’ A x = _{i=1}^p _1 y_i^2 $, \\(\\lambda_i\\) is ev of \\(A\\). $ A&gt;0 _i&gt;0, ; ; ; i=1, , p $ $ A&gt;0 ; ; ; ; ; ; A &gt;0, ; A^{-1} $ \\(A=A&#39;, \\; B=B&#39;, \\; B&gt;0\\), then maximum of \\(\\dfrac{\\pmb x &#39; A \\pmb x}{\\pmb x &#39; B \\pmb x}\\) is given by the largest ev of \\(B^{-1}A\\). the vector which maximizes(minimizes) \\(\\dfrac{\\pmb x &#39; A \\pmb x}{\\pmb x &#39; B \\pmb x}\\) is the corresponding evec of \\(B^{-1}A\\) for largest(smallest) ev of \\(B^{-1}A\\). more generally, for ev of \\(B^{-1}A\\), \\(\\lambda_1, \\cdots, \\lambda_p\\), $ ( ) = ; ; ; ; ;_1 _p ; ; ; ; ; = ( ) $ if \\({\\pmb x &#39; B \\pmb x}=1\\), then $ ( {x ’ A x} ) = ; ; ; ; ;_1 _p ; ; ; ; ; = ( {x ’ A x} ) $ 6.1.5 Partitioned Matrices \\(A_{n \\times p}, B_{p \\times n}\\) and \\(n \\ge p\\). then $ \\[\\begin{vmatrix} -\\lambda I_n &amp; -A \\\\ B &amp; I_p \\end{vmatrix}\\] = (-)^{n-p} BA - I_n = AB - I_n $ for \\(A_{n \\times p}, B_{p \\times n}\\), the non-zero ev of \\(AB\\) and \\(BA\\) are the same and have the same multiplicity. if \\(\\pmb x\\) is evec of \\(AB\\) for an ev \\(\\lambda \\not = 0\\), then \\(y=B \\pmb x\\) is an evec of \\(BA\\). for \\(A_{n \\times p}, B_{q \\times n}, \\pmb a_{p \\times 1}, \\pmb b_{q \\times 1}\\), if \\(rank \\left( A \\pmb a \\pmb b B \\right) \\le 1\\), then non-zero ev, if it exists, equals \\(\\pmb b&#39; BA \\pmb a\\) with evec \\(A \\pmb a\\). 6.1.6 Geometrical Aspects mutually orthogonal \\(\\pmb x_1 , \\cdots, \\pmb x_k \\iff \\forall {i,j}: \\; \\pmb x_i &#39; \\pmb x_j\\) In that case, $X= ( x_1 , , x_k ) $ has rank \\(k\\), and \\(X&#39;X\\) is a diagonal Matrix with \\(x_i &#39; x_i\\) in the i-th diagonal position. let’s consider bivariate data \\((x_i , y_i), \\; \\; \\; i= 1, \\cdots, n\\), and let \\(\\tilde x_i = x_i - \\bar {\\pmb x}, \\; \\tilde y_i = y_i - \\bar {\\pmb y}\\). then correlation b/w \\(x\\) and \\(y\\) is $ {_{i=1}^n (x_i - {x})(y_i - {y})} {} = {x ’ y} {x y} = () $ where \\(\\theta\\) is the angle b/w the deviation vectors \\({\\tilde x}\\) and \\({\\tilde y}\\). For two dimensions, the rotation can be expressed: $ \\[\\begin{alignat}{2} \\pmb y &amp;= \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} &amp;&amp;= \\begin{pmatrix} \\cos(\\theta) &amp; \\sin(\\theta) \\\\ -\\sin(\\theta) &amp; \\cos(\\theta) \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} &amp;&amp; = \\Gamma \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\\\ &amp;= \\Gamma \\pmb x \\tag{clockwise rotation} \\\\\\ \\\\\\ \\pmb y &amp; &amp;&amp;= \\begin{pmatrix} \\cos(\\theta) &amp; -\\sin(\\theta) \\\\ \\sin(\\theta) &amp; \\cos(\\theta) \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} &amp;&amp;= \\Gamma &#39; \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\\\ &amp; = \\Gamma &#39; \\pmb x \\tag{counter-clockwise rotation} \\end{alignat}\\] $ 6.1.7 Column, Row and Null Space Matrix \\(X_{n \\times p}\\): $ \\[\\begin{alignat}{2} \\mathcal{C}(X) &amp;= \\{ \\pmb x \\in \\mathbb{R}^n \\; \\vert \\; \\exists \\pmb a \\in \\mathbb{R}^p \\; \\; s.t. \\; \\; X \\pmb a = \\pmb x\\} &amp;&amp;\\subseteq \\mathbb{R}^n \\tag{column (range) space} \\\\ \\mathcal{N}(X) &amp;= \\{ \\pmb y \\in \\mathbb{R}^p \\; \\vert \\; X \\pmb y = 0 \\} &amp;&amp;\\subseteq \\mathbb{R}^p \\tag{null space} \\\\ \\mathcal{R}(X) &amp;= \\{ \\pmb z \\in \\mathbb{R}^p \\; \\vert \\; \\exists \\pmb b \\in \\mathbb{R}^n \\; \\; s.t. \\; \\; X&#39; \\pmb b = \\pmb z \\} &amp;&amp;\\subseteq \\mathbb{R}^p \\tag{row space} \\\\ &amp;= \\mathcal{C}(X&#39;) \\tag{column space of X`} \\end{alignat}\\] $ Spaces by Singular Value Decomposition: General-version, Matrix \\(X_{n \\times p}\\) with \\(rank(X)=r\\): $ \\ \\[\\begin{alignat}{2} X &amp;= \\Gamma \\Lambda \\triangle^T \\\\ &amp; =\\sum_{i=1}^r \\lambda_i \\pmb \\gamma_i \\pmb \\delta_i &#39; \\\\ \\mathcal{C}(X) &amp;= \\{ \\gamma_1 , \\cdots, \\gamma_r \\} \\\\ \\mathcal{N}(X) &amp;= \\{ \\delta_{r+1} , \\cdots, \\delta_{p} \\} \\\\ \\mathcal{R}(X) &amp;= \\{ \\delta_{1} , \\cdots, \\delta_{r} \\} \\end{alignat}\\] $ note: Matrix \\(X_{n \\times p}\\) with \\(rank(X)=r\\) $ \\[\\begin{alignat}{2} \\mathcal{N}(X) &amp;= \\mathcal{C}(X&#39;)^{\\perp} = \\mathcal{R}(X)^{\\perp} \\\\ \\mathcal{N}(X)^{\\perp} &amp;= \\mathcal{C}(X&#39;) = \\mathcal{R}(X) \\\\ \\\\ \\\\ \\mathcal{C}(X&#39;X) &amp;= \\mathcal{C}(X&#39;) = \\mathcal{R}(X) \\\\ \\\\ \\\\ \\dim \\left( \\mathcal{C}(X) \\right) &amp;= \\dim \\left( \\mathcal{R}(X) \\right) \\\\ = \\; \\; \\; \\; \\; rank(X) &amp;= rank(X&#39;) = rank(X&#39;X) \\\\ &amp;= r \\le \\min(n, p) \\end{alignat}\\] $ \\(X&#39;X\\) has full rank (is nonsingular) \\(\\iff\\) if \\(X\\) has full column rank (\\(X\\) has linearly independent columns). "],["introduction-1.html", "6.2 Introduction", " 6.2 Introduction 6.2.1 What for linear model \\[Y = X \\beta + \\epsilon\\] $$ Y_{n } = \\[\\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\] ; ; ; ; ; ; ; _{(p+1) } = \\[\\begin{pmatrix} \\beta_0 \\\\ \\vdots \\\\ \\beta_p \\end{pmatrix}\\] ; ; ; ; ; ; ; _{n } = \\[\\begin{pmatrix} \\epsilon_1 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\] \\ \\ \\ \\ X_{n (p+1)} = \\[\\begin{pmatrix} 1 &amp; X_{11} &amp; \\cdots &amp; X_{1p} \\\\ 1 &amp; X_{21} &amp; \\cdots &amp; X_{2p} \\\\ \\vdots &amp; &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; X_{n1} &amp; \\cdots &amp; X_{np} \\\\ \\end{pmatrix}\\] $$ linear regression $$ \\[\\begin{alignat}{2} y_i &amp;= \\beta_0 + \\beta_1 x_i &amp;&amp;+ \\epsilon_i \\tag{Simple} \\\\ y_i &amp;= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} &amp;&amp;+ \\epsilon_i \\tag{Multiple} \\end{alignat}\\] $$ ANOVA $$ \\[\\begin{alignat}{2} y_{ij} &amp;= \\mu + \\alpha_i &amp;&amp;+ \\epsilon_{ij} \\tag{One-Way} \\\\ y_{ij} &amp;= \\mu + \\alpha_i + \\beta_j + (\\alpha \\beta)_{ij} &amp;&amp;+ \\epsilon_{ij} \\tag{Two-Way with interaction} \\end{alignat}\\] $$ 6.2.2 Random Vectors and Matrices let rv \\[Y = \\begin{pmatrix} y_1, &amp; \\cdots &amp;, y_n \\end{pmatrix}&#39;\\] with \\[E(y_i) = \\mu_i , \\; \\; \\; Var(y_i)=\\sigma_{ii} \\; \\; (=\\sigma_i^2), \\; \\; \\; Cov(y_i , y_j) = \\sigma_{ij}\\]. define the statistics of \\[Y\\] $$ \\[\\begin{alignat}{2} &amp;E(Y) &amp;&amp;= \\begin{pmatrix} E(y_1), &amp; \\cdots &amp; E(y_n) \\end{pmatrix}&#39; = \\begin{pmatrix} \\mu_1, &amp; \\cdots &amp; \\mu_n \\end{pmatrix}&#39; &amp;&amp;= \\pmb \\mu \\tag{Expected Value of Y elementwise as } \\\\ &amp;Cov(Y) &amp;&amp;= E \\left[ (Y-\\pmb \\mu) (Y-\\pmb \\mu) &#39; \\right] &amp;&amp;= (\\sigma_{ij}) \\tag{Covariance Matrix} \\end{alignat}\\] $$ Note: $$ \\[\\begin{alignat}{2} E(AY+\\pmb b) &amp;= A \\pmb \\mu + \\pmb b \\\\ Cov(AY+\\pmb b) &amp;= A \\ast Cov(Y) \\ast A &#39; \\end{alignat}\\] $$ Prove or disprove that Cov(Y) is nonnegative definite. how? Covariance of \\[W_{r \\times 1}, \\; Y_{s \\times 1}\\] with \\[E(W)=\\gamma, \\; E(Y) = \\mu\\]: $$ \\[\\begin{alignat}{2} Cov(W, Y) &amp;= E \\left [(W-\\gamma)(Y-\\mu)&#39; \\right ]_{r \\times s} &amp;&amp; \\\\ Cov(AW+a, NY+b) &amp;= A \\ast Cov(W,Y) \\ast B &#39; &amp;&amp; \\\\ Cov(AW+NY) &amp;= A \\ast Cov(W) \\ast A&#39; + N \\ast Cov(Y) \\ast B&#39; \\\\ &amp;\\; \\; \\; \\; \\; \\; \\; + A \\ast Cov(W,Y) \\ast B&#39; + B \\ast Cov(W) \\ast A&#39; \\tag{why?} \\end{alignat}\\] $$ 6.2.3 Multivariate Normal Distributions $$ Z = (z_1 , , z_n) ’ N_n (0, ; I_n), ; ; ; ; ; z_1 , , z_n N(0,1) $$ which means \\[E(Z)=\\pmb 0, \\; Cov(Z)=I_n\\]. \\[ A_{r \\times n}, \\; b \\in \\mathbb{R}^r \\] Y has an r-dimensional MVN distribution Definition 1.2.1. Let A be r  n and b 2 Rr . Then Y has an r-dimensional multivariate normal distribution : Y = AZ + b  Nr (b;AAT ): Theorem 1.2.2. Let Y  N(;V) and W  N(;V). Then Y and W have the same distribution (Proof: p.5) The density of nonsingular \\[Y \\sim N(\\mu,V)\\] is given by $$ f(y) = (2)^{-} ^{-} $$ Theorem 1.2.3. Let Y  N(;V) and Y = Y1 Y2 ! . Then Cov(Y1;Y2) = 0 if and only if Y1 Y2 Corollary 1.2.4. Let Y  N(; 2I) and ABT = 0. Then AY BY Definition 1.3.1. Quadratic Form of Y: for n  n; A YTAY = X ij aijyiyj Theorem 6.2.4 Distributions of Quadratic Forms \\[E(Y) = \\mu, \\; Cov(Y) = V\\]. then \\[E(Y&#39;AY) = tr(AV) + \\mu &#39; A \\mu\\]. prf) let’s consider \\[Z \\sim N_n (\\mu, I_n)\\]. then \\[ Z&#39;Z \\sim \\chi^2 \\left(n, \\; \\dfrac{\\mu&#39; \\mu}{2} \\right) \\tag{second one is non-centrality parameter}\\] Let \\[Y \\sim N(\\mu , I)\\] and any orthogonal projection Matrix \\[M\\]. then \\[Y&#39;MY \\sim \\chi^2 \\left(r(M), \\dfrac{\\mu &#39; M \\mu}{2} \\right)\\] Let \\[Y \\sim N(\\mu , \\sigma^2 I)\\] and any orthogonal projection Matrix \\[M\\]. then \\[Y&#39;MY \\sim \\chi^2 \\left(r(M), \\dfrac{\\mu &#39; M \\mu}{2\\sigma^2} \\right)\\] Let \\[Y \\sim N(\\mu , M)\\]with \\[\\mu \\in \\mathcal{C}(M)\\] and \\[M\\] be an orthogonal projection Matrix. then \\[Y&#39;Y \\sim \\chi^2 \\left(r(M), \\dfrac{\\mu &#39; M \\mu}{2\\sigma^2} \\right)\\]. let \\[E(Y)=\\mu, \\; Cov(Y)=V\\]. then \\[Pr \\left[ (Y-\\mu) \\in \\mathcal{C}(V) \\right]=1\\]. Exercise 1.6. Let \\[Y\\] be a vector with \\[E(Y) = 0\\] and \\[Cov(Y) = 0\\]. Then \\[Pr(Y = 0) = 1\\]. let \\[Y \\sim N(\\mu, \\; V)\\]. then \\[Y&#39; A Y \\sim \\chi^2 \\left( tr(AV), \\dfrac{\\mu&#39; A \\mu}{2}\\right)\\], provided that 1. \\[VAVAV=VAV\\]. 2. \\[\\mu &#39; AVA \\mu = \\mu &#39; a \\mu\\]. 3. \\[VAVA \\mu = VA \\mu\\] prf) Exercise 1.7. Show that if \\[V\\] is nonsingular, then the three conditions in Theorem 1.3.6 reduce to \\[AVA = A\\]. Show that \\[Y&#39;V^{-} Y\\] has a chi-squared distribution with \\[r(V)\\] degrees of freedom when \\[\\mu \\in \\mathcal{C}(V)\\]. let \\[Y \\sim N(\\mu, \\; \\sigma^2 I)\\] and \\[BA=0\\]. then, for \\[A=A&#39;\\], 1. \\[Y&#39;AY \\perp BY\\]. 2. \\[Y&#39;AY \\perp Y&#39; BY\\] for \\[B=B&#39;\\]. let \\[Y \\sim N(\\mu, \\; V)\\] and \\[A \\ge 0, \\; B \\ge 0\\], and \\[VAVBV=0\\]. then \\[Y&#39;AY \\perp Y&#39;BY\\]. let \\[Y \\sim N(\\mu, \\; V)\\]. provided that 1. \\[VAVBV=0\\]. 2. \\[VAVB \\mu = 0\\]. 3. \\[VBVA \\mu = 0\\]. 4. \\[\\mu &#39; ABV \\mu = 0\\]. and also conditions of above thm, 1. \\[VAVAV=VAV\\]. 2. \\[\\mu &#39; AVA \\mu = \\mu &#39; a \\mu\\]. 3. \\[VAVA \\mu = VA \\mu\\] prf) hold for both \\[Y&#39;AY\\] and \\[Y&#39;BY\\], then \\[Y&#39;AY \\perp Y&#39;BY\\]. "],["estimation.html", "6.3 Estimation", " 6.3 Estimation 이하와 같은 linear model 고려. 이때 \\(x_i &#39;\\)는 \\(X\\)의 i번째 row vector이며, \\(E(\\epsilon)=0, \\; Cov(\\epsilon)=\\sigma^2 I = \\sigma^2 \\Sigma\\). $ Y_{n } = X_{n p} {p } + {n } = \\[\\begin{pmatrix} x_i &#39; \\beta \\end{pmatrix}\\] $ 6.3.1 Identifiability and Estimability 6.3.1.1 Identifiable 모델에서의 무한한 갯수의 관측치를 보유한다면, 모델의 underlying 패러미터의 참값을 획득하는 것이 가능한 성질. A general linear model is a parameterization $ \\[\\begin{align} E(Y) &amp;= f(X) \\\\ &amp;= E(X\\beta + \\epsilon)\\\\ &amp;= X\\beta + E(\\epsilon) \\\\ &amp;= X\\beta + 0 \\\\ &amp;= X\\beta \\end{align}\\] $ The parameter \\(\\beta\\) is identifiable if for any \\(\\beta_1\\) and \\(\\beta_2\\) \\(f(\\beta_1) = f(\\beta_2)\\) implies \\(\\beta_1 = \\beta_2\\). If \\(\\beta\\) is identifiable, we say that the parameterization \\(f(\\beta)\\) is identifiable. (패러미터 \\(\\beta\\)가 identifiable하다면, 우리는 해당 패러미터의 parameterization \\(f(\\beta)\\) 또한 identifiable 하다) Moreover, a vector-valued function \\(g(\\beta)\\) is identifiable if \\(f (\\beta_1) = f(\\beta_2)\\) implies \\(g (\\beta_1) = g(\\beta_2)\\). For regression models for which \\(r(X) = p\\), the parameters are identifiable: \\(X&#39;X\\) is nonsingular, so if \\(X\\beta_1 = X\\beta_2\\), then $ _1 = (X’X)^{-1} X’X _1 = (X’X)^{-1} X’X _2 = _2 $ A function \\(g(\\beta)\\) is identifiable \\(\\iff\\) \\(g(\\beta)\\) is a function of \\(f(\\beta)\\). 6.3.1.2 Estimable The results in the last section suggest that some linear combinations of \\(\\beta\\) in the less than full rank case will not be estimable. The linear parametric function \\(c&#39;β\\) is an estimable function if there exists a vector \\(a \\in \\mathbb{R}^n\\) such that \\(\\forall \\beta: E(a &#39; y ) = c &#39; \\beta\\). A vector-valued linear function of \\(\\beta\\), \\(\\Lambda &#39; \\beta\\) is estimable if \\(\\Lambda &#39; \\beta = P &#39; X \\beta\\) for some matrix P; In other words, \\(\\Lambda &#39; \\beta\\) is estimable if \\(\\Lambda = X &#39; P \\in \\mathcal{C}(X&#39;)\\). Clearly, if \\(\\Lambda &#39; \\beta\\) is estimable, it is identifiable and therefore it is a reasonable thing to estimate. estimable \\(\\rightarrow\\) identifiable For estimable functions \\(\\Lambda&#39; \\beta = P &#39; X \\beta\\), although \\(P\\) need not be unique, its perpendicular projection (columnwise) onto \\(\\mathcal{C}(X)\\) is unique: let \\(P_1 , \\; P_2\\) be matrices with \\(\\Lambda &#39; = P_1 &#39; X = P_2 &#39; X\\), then $ MP_1 = X(X’X)^{-}X’P_1 = X(X’X)^{-}= X(X’X)^{-}X’P_2 = MP_2 $ Example 2.1.4 and 2.1.5 \\(g(\\beta)\\)’s estimate, \\(f(Y)\\), is unbiased if \\(\\forall \\beta: \\; E[f(Y)] = g(\\beta)\\). if \\(f (Y) = a_0 + a&#39; Y\\) for some scalar \\(a_0\\) and vector \\(a\\), \\(f(Y)\\) is a linear estimate of \\(\\Lambda &#39; \\beta\\). if \\(\\Lambda &#39; \\beta\\) \\(\\iff\\) \\(a_0 = 0\\) and \\(a &#39; X = \\Lambda&#39;\\); say, \\(\\Lambda = X &#39; a \\in \\mathcal{C}(X&#39;)\\), then a linear estimate \\(a_0 + a &#39; Y\\) is unbiased \\(\\Lambda &#39; \\beta\\) is estimable \\(\\iff\\) there exists \\(\\rho\\) such that \\(E(\\rho &#39; Y ) = \\Lambda &#39; \\beta\\) for any \\(\\beta\\). 6.3.2 Estimation: Least Squares Estimating \\(E(Y)\\) is to take a vector in \\(\\mathcal{C}(X)\\) closest to \\(Y\\); $ \\[\\begin{alignat}{2} E(Y) &amp;= X\\beta \\; &amp;&amp;\\in \\; \\mathcal{C}(X)\\\\ \\\\ \\hat \\beta &amp;= \\min_\\beta \\left\\{ (Y-X \\beta) &#39; (Y-X \\beta) \\right\\} \\\\ &amp;= \\min_\\beta \\left\\{ \\Vert Y-X \\beta \\Vert^2 \\right\\} \\tag{Least Squares Estimate of beta} \\end{alignat}\\] $ for any Least Squares Estimate \\(\\hat \\beta\\), LSE of \\(\\Lambda &#39; \\beta is \\Lambda &#39; \\hat \\beta\\), e.g., \\(\\hat {\\Lambda &#39; \\beta}_{LSE} = \\Lambda &#39; \\hat \\beta\\). Theorem 2.2.1 where \\(M\\) is the perpendicular projection operator onto \\(\\mathcal{C}(X)\\), then $ $ is a LSE of \\(\\beta\\) \\(\\iff\\) $X = M Y $ Corollary 2.2.2 \\(\\hat \\beta_{LSE} = X(X&#39;X)^{-}X&#39; Y\\) Corollary 2.2.3 The unique LSE of \\(\\rho &#39; X \\beta = \\rho &#39; M Y\\). ※ Note: the unique LSE of \\(\\Lambda &#39; \\beta = \\Lambda &#39; \\hat \\beta = P&#39; M Y\\). Theorem 2.2.4 the LSE of \\(\\Lambda &#39; \\beta\\) is unique only if \\(\\Lambda &#39; \\beta\\) is estimable: \\(\\Lambda = X&#39;\\rho\\) if \\(\\Lambda &#39; \\hat \\beta_1 =\\Lambda &#39; \\hat \\beta_2\\), so that \\(X \\hat \\beta_1 = X \\hat \\beta_2 = MY\\). ※ Note: When \\(\\beta\\) is not identifiable, we need side conditions imposed on the parameters to estimate nonidentifiable parameters. ※ Note: With \\(r = r (X) &lt; p\\) (overparameterized model), we need \\(p - r\\) individual side conditions to identify and estimate the parameters. Proposition 2.2.5 If \\(\\Lambda = X &#39; \\rho\\), then \\(E(\\rho &#39; MY) = \\Lambda &#39; \\beta\\). let’s decompose $ \\[\\begin{alignat}{2} Y &amp;= X \\hat \\beta &amp;&amp;+ Y - X \\hat \\beta \\\\ &amp;= MY &amp;&amp;+ (I-M)Y \\\\ &amp;= \\hat Y &amp;&amp;+ e \\end{alignat}\\] $ 이때 $ \\[\\begin{align} \\hat Y &amp;\\in \\mathcal{C}(X) \\tag{fitted values of Y} \\\\ e &amp;\\in \\mathcal{C}(X)^{\\perp} \\tag{residuals} \\end{align}\\] $ Theorem 2.2.6 Let \\(r (X) = r\\) and \\(Cov(\\epsilon) = \\sigma^2 I\\). At below formula, denominator is degrees of freedom for error. Then an UE of \\(\\sigma^2\\), MSE, is as below. $ ^2 = = $ 6.3.3 Estimation: Best Linear Unbiased Definition 2.3.1 \\(a&#39;Y\\) is a Best Linear Unbiased Estimate(BLUE) of \\(\\lambda &#39; \\beta\\) if \\(a &#39; Y\\) is unbiased. e.g., \\(E(a &#39; Y) = \\lambda &#39; \\beta\\) and if for any other linear unbiased estimate \\(b &#39; Y\\), \\(Var(a &#39; Y) \\le Var(b&#39;Y)\\). Theorem 2.3.2: Gauss-Markov thm Consider \\(Y = X \\beta + \\epsilon\\) with \\(E(\\epsilon) = 0\\), \\(Cov(\\epsilon) = \\sigma^2 I\\). Let \\(\\lambda &#39; \\beta\\) be estimable. Then LSE of \\(\\lambda &#39; \\beta=\\) BLUE of \\(\\lambda &#39; \\beta\\). Corollary 2.3.3 Let \\(\\sigma^2 &gt; 0\\). Then there exists a unique BLUE for any estimable function \\(\\lambda &#39; \\beta\\). 6.3.4 Estimation: Maximum Likelihood Assume that \\(Y \\sim N_n(X\\beta , \\; \\sigma^2 I_n)\\). Then the Maximum Likelihood Estimates (MLEs) of \\(\\beta\\) and \\(\\sigma^2\\) are obtained by maximizing the log of the likelihood so that $ \\[\\begin{align} \\left( \\hat \\beta , \\; \\hat \\sigma^2 \\right) &amp;= \\text{ MLE of } \\left( \\beta , \\; \\sigma^2 \\right) \\\\ &amp;= \\max_{\\left( \\beta , \\; \\sigma^2 \\right)} \\left\\{ -\\dfrac{n}{2}log(2 \\pi) - \\dfrac{1}{2} \\log \\left[ (\\sigma^2 )^n\\right] - \\dfrac{(Y-X\\beta)&#39;(Y-X\\beta)}{2\\sigma^2} \\right\\} \\end{align}\\] $ $ \\[\\begin{align} \\hat \\beta &amp;= \\text{ LSE of } \\beta \\\\ \\\\\\ \\hat \\sigma^2 &amp;= \\dfrac{1}{n} \\left\\{Y&#39;(I-M)Y \\right\\} \\end{align}\\] $ 6.3.5 Estimation: Minimum Variance Unbiased Assume that \\(Y = X \\beta + \\epsilon\\) with \\(\\epsilon \\sim N_n(0, \\; \\sigma^2 I_n)\\). if \\(\\forall \\beta, \\sigma^2: \\; E \\left \\{h[T(Y)] \\right\\} = 0\\) implies that \\(Pr[h(T(Y)) = 0] = 1\\), A vector-valued sufficient statistic \\(T(Y)\\) is said to be complete If \\(T(Y)\\) is a complete sufficient statistic, then \\(f(T(Y))\\) is a Minimum Variance Unbiased Estimate (MVUE) of \\(E \\Big [ f (T(Y)) \\Big ]\\). Theorem 2.5.3 let \\(\\theta = (\\theta_1 , \\cdots, \\theta_s)&#39;\\) and let \\(Y\\) be a rvec with pdf as below. then \\(T(Y) = \\Big( T_1(Y), \\cdots, T_s(Y) \\Big)&#39;\\) is a complete sufficient statistics provided that neither \\(\\theta\\) nor \\(T(Y)\\) satisfies any linear constraints. $ f(Y) = c() h(Y) $ Theorem 2.5.4 MSE is a $_{MVUE} $, and \\(\\hat { \\rho &#39; X \\beta }_{MVUE} = \\rho &#39; M Y\\) whenever \\(\\epsilon \\sim N(0, \\; I)\\). 6.3.6 Sampling Distributions of Estimates Assume that \\(Y = X \\beta + \\epsilon\\) with \\(\\epsilon \\sim N_n(0, \\; \\sigma^2 I_n)\\). Then \\(Y \\sim N_n(X \\beta, \\; \\sigma^2 I_n)\\). then $ \\[\\begin{alignat}{4} \\Lambda &#39; \\hat \\beta &amp;= P&#39; M Y &amp;&amp;\\sim N(\\Lambda &#39; \\beta , \\; &amp;&amp;\\sigma^2 P&#39;MP&amp;&amp;\\; \\; \\; ) &amp;&amp; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\;&amp;&amp; &amp;&amp; &amp;&amp; \\\\ &amp; &amp;&amp;\\sim N(\\Lambda &#39; \\beta , \\; &amp;&amp;\\sigma^2 \\Lambda &#39; (X&#39;X)^{-} \\Lambda&amp;&amp;\\; \\; \\; ) &amp;&amp; &amp;&amp; \\because &amp;&amp; \\;M &amp;&amp; =X(X&#39;X)^- X&#39; \\\\ &amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; \\; \\hat Y &amp;&amp; = MY &amp;&amp;\\sim N(X\\beta, \\sigma^2 M) \\\\ \\hat \\beta &amp;= (X&#39;X)^- X&#39;Y &amp;&amp;\\sim N(\\beta , \\; &amp;&amp;\\sigma^2 (X&#39;X)^{-1}) &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; (\\text{if X is of full rank}) \\end{alignat}\\] $ Do Exercise 2.1. Show that $ ^2 ( r(I-M), ; ) $ 6.3.7 Generalized Least Squares(GLS) Assume that for some known positive definite \\(\\Sigma\\), $ Y = X + , ; ; ; ; ; $ $ \\[\\begin{alignat}{3} Y &amp;= X \\beta &amp;&amp;+ \\epsilon &amp;&amp; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; &amp;&amp; E(\\epsilon)&amp;&amp;=0, \\; \\; &amp;&amp;\\; Cov(\\epsilon) &amp;&amp;= \\sigma^2 \\Sigma \\tag{1}\\\\ \\Sigma^{-\\tfrac{1}{2}}Y &amp;= \\Sigma^{-\\tfrac{1}{2}} X \\beta &amp;&amp;+ \\Sigma^{-\\tfrac{1}{2}} \\epsilon &amp;&amp; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; &amp;&amp; E(\\Sigma^{-\\tfrac{1}{2}} \\epsilon)&amp;&amp;=0, &amp;&amp;\\; Cov(\\Sigma^{-\\tfrac{1}{2}} \\epsilon) &amp;&amp;= \\sigma^2 I \\tag{2, by SVD} \\\\ Y_\\ast &amp;= X_\\ast \\beta &amp;&amp;+ \\epsilon_\\ast &amp;&amp; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; &amp;&amp; E( \\epsilon_\\ast)&amp;&amp;=0, &amp;&amp;\\; Cov( \\epsilon_\\ast) &amp;&amp;= \\sigma^2 I \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} \\hat \\beta_{GLS} &amp;= \\min_\\beta (Y_\\ast - X_\\ast \\beta)&#39;(Y_\\ast - X_\\ast \\beta) \\\\ &amp;= \\min_\\beta \\Vert Y_\\ast - X_\\ast \\beta \\Vert^2 \\\\ &amp;= \\min_\\beta (Y - X \\beta)&#39; \\Sigma^{-1} (Y - X \\beta) \\tag{Generalized LSE (GLSE) of β} \\end{alignat}\\] $ Theorem 2.7.1 \\(\\lambda &#39; \\beta\\) estimable in model (1) \\(\\iff\\) if \\(\\lambda &#39; \\beta\\) is estimable in model (2). $$ is GLSE of \\(\\beta\\) \\(\\iff\\) \\(X(X&#39; \\Sigma^{-1} X)^{-}X&#39; \\Sigma^{-1}Y = X \\hat \\beta\\), which is Normal Equation of GLS. For any estimable function, there exists a unique GLSE. GLSE estimate of estimable \\(\\lambda&#39; \\beta\\), is BLUE of $’ $. let \\(\\epsilon \\sim N(0, \\; \\Sigma^2 \\Sigma)\\). then, GLSE of estimable \\(\\lambda &#39; \\beta\\), is MVUE. let \\(\\epsilon \\sim N(0, \\; \\Sigma^2 \\Sigma)\\). then, \\(\\hat \\beta_{GLS} = \\hat \\beta_{MLE}\\). Normal Equation of GLS can be rewritten as $ \\[\\begin{align} X(X&#39; \\Sigma^{-1} X)^{-}X&#39; \\Sigma^{-1}Y &amp;= X \\hat \\beta \\\\ AY &amp;= \\end{align}\\] $ \\(A\\) is a projection operator onto \\(\\mathcal{C}(X)\\). \\(Cov(X \\hat \\beta_{GLS}) = \\sigma^2 \\ast X(X&#39; \\Sigma^{-1} X)^{-}X&#39;\\) Let \\(\\lambda &#39; \\beta\\) be estimable. Then \\(Var(\\lambda &#39; \\hat \\beta_{GLS}) = \\sigma^2 \\ast \\lambda &#39; (X&#39; \\Sigma^{-1} X)^- \\lambda\\). Note: \\((I-A)Y\\) is residual vector of GLSE. $ \\[\\begin{align} SSE_{GLS} &amp;= (Y_\\ast - \\hat Y_\\ast)&#39; (Y_\\ast - \\hat Y_\\ast) \\\\ &amp;\\; \\; \\vdots \\\\ &amp;= Y&#39;(I-A)&#39; \\Sigma^{-1}(I-A)Y \\\\ \\\\\\ MSE_{GLS} &amp;= \\hat \\sigma^2 \\\\ &amp; = \\dfrac{1}{n-r(X)} \\ast SSE_{GLS}\\\\ \\\\\\ \\dfrac{1}{\\hat \\sigma^2} \\dfrac{\\lambda&#39; \\Big(\\hat \\beta_{GLS} - \\beta_{GLS} \\Big)}{ \\lambda &#39; (X&#39; \\Sigma^{-1} X)^- \\lambda} &amp;\\sim t\\Big( n-r(x) \\Big) \\end{align}\\] $ denominator는 \\(Var(\\lambda &#39; \\hat \\beta_{GLS}) = \\sigma^2 \\ast \\lambda &#39; (X&#39; \\Sigma^{-1} X)^- \\lambda\\). Let \\(\\Sigma\\) be nonsingular and \\(\\mathcal{C}(\\Sigma X) \\subset \\mathcal{C}(X)\\). Then least squares estimates are BLUEs. Note: for diagonal \\(\\Sigma\\), GLS is referred to as Weighted Least Squares (WLS). Exercise 2.5. Show that \\(A\\) is the perpendicular projection operator onto \\(\\mathcal{C}(X)\\) when the inner product between two vectors \\(\\pmb x\\) and \\(\\pmb y\\) is defined as \\((\\pmb x, \\pmb y)_\\Sigma \\equiv \\pmb x&#39; \\Sigma^{-1} \\pmb y\\). "],["one-way-anova.html", "6.4 One-Way ANOVA", " 6.4 One-Way ANOVA 6.4.1 One-Way ANOVA General form of One-Way ANOVA model is $ y_{ij} = + {i} + {ij}, ; ; ; ; ; i=1, , a ; ; ; ; ; j=1, , N_i $ $ n=_{i=1}^a N_i \\ \\ E({ij})=0, ; Var({ij})=^2, ; Cov({ij}, {ab})=0 $ i-th treatment (group) effect \\(a_i\\) Balanced model is \\(\\forall i: N_i = b\\) Unbalanced model is \\(\\forall i: N_i\\)’s are different 6.4.2 More About Models Example 4.1.1: \\(a = 3, \\; N_1 = 5, \\; N_2 = 3, \\; N_3 = 3\\), $ Y = X + = \\[\\begin{pmatrix} J_5 &amp; J_5 &amp; 0 &amp; 0 \\\\ J_3 &amp; 0 &amp; J_3 &amp; 0 \\\\ J_3 &amp; 0 &amp; 0 &amp; J_3 \\end{pmatrix}\\] \\[\\begin{pmatrix} \\mu \\\\ \\alpha_1 \\\\ \\alpha_2 \\\\ \\alpha_3 \\end{pmatrix}\\] \\[\\begin{pmatrix} \\epsilon_{11} \\\\ \\epsilon_{12} \\\\ \\vdots \\\\ \\epsilon_{33} \\end{pmatrix}\\] $ let \\(N_1 = N_2 = N_3 = 5\\). then $ X = \\[\\begin{pmatrix} J_3 \\otimes J_5 &amp; I_3 \\otimes J_5 \\end{pmatrix}\\] $ In general, balanced design such as \\(i = 1, \\cdots, a \\; \\; \\; \\; \\; j = 1, \\cdots, b\\): $ X = \\[\\begin{pmatrix} J_a \\otimes J_b &amp; I_a \\otimes J_b \\end{pmatrix}\\] $ Notation: \\(J_r^c \\equiv J_r J_c&#39; = J_r \\otimes J^c\\) is a \\(r \\times c\\) matrix of \\(1\\)’s. Let \\(Z\\) be the model matrix for the alternative one-way analysis of variance model $ y_{ij} = i + {ij} ; ; ; ; ; i=1, , a ; ; ; ; ; k= 1, , N_i $ then, letting \\(X_i X_j = \\delta_{ij}\\) with 1 for \\(i=j\\) and 0 for \\(i \\not = j\\), $ \\[\\begin{align} X &amp;= \\begin{bmatrix}J &amp; Z\\end{bmatrix} &amp;&amp;= \\begin{bmatrix}J &amp; (X_1 , \\cdots, X_a)\\end{bmatrix} \\\\ \\Longrightarrow \\; \\; \\; \\; \\; \\mathcal{C}(X) &amp;=\\mathcal{C}(Z) \\\\ Z&#39;Z &amp;= diag(N_1 , N_2 , \\cdots, N_a) \\\\ Z(Z&#39;Z)^{-1}Z&#39; &amp;=Blk \\; \\; diag \\Big[ N_i^{-1} J_{N_i}^{N_i} \\Big] \\\\ M &amp;=X (X&#39;X)^{-1}X&#39; \\\\ M_\\alpha &amp;= Z_\\ast(Z_\\ast &#39; Z_\\ast)^{-1} Z_\\ast &#39; &amp;&amp;=M- M_J = M-\\dfrac{1}{n}J_n^n \\\\ Z_\\ast &amp;=(I-M_j)Z \\\\ M &amp;= M_j + M_\\alpha \\end{align}\\] $ 6.4.3 Estimating and Testing Contrasts A contrast in the one-way ANOVA $ ’ = _{i=1}^a i i ; ; ; ; ; with ; ; ; ’ J{a+1} = {i=1}^a _i = 0 $ For estimable \\(\\lambda &#39; \\beta\\), find \\(\\rho\\) so that $‘X = ’ $, \\(\\rho &#39; = \\begin{pmatrix} \\dfrac{J_{N_i} &#39; \\lambda_i}{N_i} \\end{pmatrix}\\). Proposition 4.2.1. \\(\\lambda &#39; \\alpha = \\rho &#39; X \\beta\\) is a contrast \\(\\iff\\) \\(\\rho &#39; J = 0\\). Proposition 4.2.2. \\(\\lambda &#39; \\alpha = \\rho &#39; X \\beta\\) is a contrast \\(\\iff\\) \\(M_\\rho \\in \\mathcal{C}(M_\\alpha)\\). since \\(\\sum_{i=1}^a \\lambda_i =0\\), $ _{i=1}^a _i i ={i=1}^a _i {+ i} = {i=1}^a i y{i+} $ because \\(\\mu + \\alpha_i\\) is estimable, and its unique LSE is \\(\\bar y_{i+}\\). At significance level \\(\\alpha\\), \\(H_0: \\lambda &#39; \\alpha=0\\) is rejected if $ \\[\\begin{alignat}{2} &amp;F &amp;&amp;= \\dfrac { \\dfrac{ \\Big( \\sum_{i=1}^a \\lambda_i \\bar y_{i+} \\Big) ^2} {\\dfrac{\\sum_{i=1}^a \\lambda_i^2}{N_i}} } {MSE} &amp;&amp;&gt; F \\Big(1-\\alpha, \\; \\; 1, \\; \\; dfE \\Big) \\\\ \\\\ \\\\ \\iff \\; \\; \\; \\; \\; &amp; t \\ &amp;&amp;= \\dfrac {\\Bigg \\vert \\sum_{i=1}^a \\lambda_i \\bar y_{i+} \\Bigg \\vert} {\\sqrt{MSE \\left( \\sum_{i=1}^a\\dfrac{\\lambda_i^2}{N_i}\\right) }} &amp;&amp;&gt; t \\left( 1-\\dfrac{\\alpha}{2}, \\; \\; dfE \\right) \\end{alignat}\\] $ 6.4.4 Cochran’s Theorem let \\(A_1 , \\cdots, A_m\\) be \\(n \\times n\\) symmetric Matrices, and \\(A = \\sum_{j=1}^m A_j\\) with \\(rank(A_j) = n_j\\). consider the following four statements: \\(A_j\\) is an orthogonal projection for all \\(j\\). \\(A\\) is an orthogonal projection (possibly \\(A=I\\)). \\(A_j A_k = 0\\) for all \\(j \\not = k\\). \\(\\sum_{j=1}^m n_j = n\\). If any two of these conditions hold, then all four hold. Note: Cochran’s theorem is a standard result that is the basis of the ANalysis Of VAriance. If we can write the total sum of squares as a sum of sum of squares components, and if the degree of freedom add up, then the \\(A_j\\) must be projections, they are orthogonal to each other, and they jointly span \\(\\mathbb{R}^n\\). "],["testing.html", "6.5 Testing", " 6.5 Testing 6.5.1 More About Models: Two approaches for linear model $ \\[\\begin{alignat}{2} Y &amp;= E(Y) &amp;&amp;+ Y - E(Y) \\\\ &amp;= \\mu &amp;&amp;+ \\epsilon \\tag{Parameter-free approach } \\\\ \\\\ Y &amp;= E(Y) &amp;&amp;+ Y - E(Y) \\\\ &amp;= X \\beta &amp;&amp;+ \\epsilon \\tag{Parameter approach} \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} E(\\epsilon) &amp;= 0, \\; \\; \\; &amp;&amp; Cov(\\epsilon) &amp;&amp;= \\sigma^2 I \\tag{Ordinary Least Square, OLS} \\\\ E(\\epsilon) &amp;= 0, &amp;&amp; Cov(\\epsilon) &amp;&amp;= \\sigma^2 \\Sigma \\tag{Generalized Least Square, GLS} \\end{alignat}\\] $ Consider $ Y=X + , ; ; ; ; ; E()=0, ; Cov() = ^2 I $ \\(\\mathcal{C}(X)\\) \\(\\mathcal{C}(X)^\\perp\\) itslef Estimation Space Error Space orthogonal projection onto \\(M \\\\ = X(X&#39;X)^-X&#39;\\) \\(I - M \\\\= I - X(X&#39;X)^-X&#39;\\) \\(E(Y) = X \\beta \\in \\mathcal{C}(X)\\) \\(E(\\epsilon) \\in \\mathcal{C}(X)^\\perp\\) \\(Cov(Y) = \\sigma^2 I\\) \\(Cov(\\epsilon) = \\sigma^2 I\\) One-Way ANOVA $ \\[\\begin{alignat}{4} y_{ij} &amp;= \\mu_i &amp;&amp;+ \\epsilon_{ij} \\\\ &amp;= E(y_{ij}) &amp;&amp;+ \\epsilon_{ij} \\\\ &amp;= \\mu + \\alpha_i &amp;&amp;+ \\epsilon_{ij} \\\\ \\\\\\ \\bar \\mu &amp;= \\mu + \\bar \\alpha_+ \\\\ \\mu_1 - \\mu_2 &amp;= \\alpha_1 - \\alpha_2 \\end{alignat}\\] $ the parameters in the two models are different, but they are related. Simple Linear Regression $ \\[\\begin{alignat}{4} y_i &amp; = \\beta_0 + \\beta_1 x_i &amp;&amp;+\\epsilon_i \\\\ &amp; = E(y_i) &amp;&amp;+\\epsilon_i \\\\ &amp; = \\gamma_0 + \\gamma_1(x_i - \\bar x) &amp;&amp;+\\epsilon_i \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} \\mathcal{C}(X_1) = \\mathcal{C}(X_2) \\; \\; \\Longrightarrow \\; \\;\\; \\; \\; X_1 &amp;= X_2 T \\\\ X_1 \\beta_1 &amp;= X_2 T \\beta_1 &amp;&amp; = X_2 \\beta_2 \\\\ &amp; &amp;&amp;= X_2 (T \\beta_1 + \\nu), \\; \\; \\; \\forall\\nu \\in \\mathcal{C}(X_2&#39;)^\\perp \\end{alignat}\\] $ ※ Note: A unique parameterization for \\(X_j, \\; j=1,2\\) occurs \\(\\iff\\) \\(X_j &#39; X_j\\) is nonsingular. Exercise: Show that a unique parameterization for \\(X_j, \\; j=1,2\\) means \\(\\mathcal{C}(X_2 &#39; )^\\perp = \\{0\\}\\). 6.5.2 Testing Models Consider $ Y=X + , ; ; ; ; ; N(0, ; I_n) $ let’s partition \\(X\\) into $X = \\[\\begin{pmatrix} X_0, &amp; X_1 \\end{pmatrix}\\] : ; (X_0) (X) $ $ \\[\\begin{alignat}{2} Y &amp;= X_0 \\beta_0 + X_1 \\beta_1 &amp;&amp;+ \\epsilon \\tag{Full Model, FM} \\\\ Y &amp;= X_0 \\gamma &amp;&amp;+ \\epsilon \\tag{Reduced Model, RM} \\end{alignat}\\] $ 이때 Hypothesis testing procedure can be described as \\(H_0:\\) Reduced Model, \\(H_1:\\) Full Model. (Example 3.2.0: pp. 52–54). Let \\(M\\) and \\(M_0\\) be the orthogonal projection onto \\(\\mathcal{C}(X)\\) and \\(\\mathcal{C}(X_0)\\) respectively. Note that with \\(\\mathcal{C}(X_0) \\subset \\mathcal{C}(X)\\), \\(M - M_0\\) is the orthogonal projection onto the orthogonal complement of \\(\\mathcal{C}(X_0)\\) with respect to \\(\\mathcal{C}(X)\\), that is, $ \\[\\begin{align} \\mathcal{C}(X_0)_{\\mathcal{C}(X)}^\\perp &amp;= \\mathcal{C}(M - M_0) \\\\ &amp;= \\mathcal{C}(M \\cap M_0^\\perp ) \\\\ \\\\\\ \\hat\\mu &amp;= \\hat E(Y) = MY \\tag{under FM} \\\\ \\hat\\mu_0 &amp;= \\hat E(Y) = M_0 Y \\tag{under RM} \\end{align}\\] $ If RM is true, then \\(MY-M_0 Y = (M - M_0)Y\\) should be reasonably small. Note that \\(E(M-M_0)Y = 0\\). The decision about whether RM is appropriate hinges on deciding whether the vector \\((M - M_0)Y\\) is large. The size of \\((M - M_0)Y\\)’s obvious measure is \\([(M - M_0)Y]&#39;[(M - M_0)Y] = Y&#39;(M-M_0)Y\\). The size of \\((M - M_0)Y\\)’s reasonable measure is given by \\(\\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}\\). ※ Note that $E ( ) = ^2 + $. Theorem 3.2.1. Consider $ Y=X + , ; ; ; ; ; N(0, ; I_n) , ; ; ; ; ; (X_0) (X) \\ \\ \\ \\[\\begin{alignat}{2} Y &amp;= X_0 \\beta_0 + X_1 \\beta_1 &amp;&amp;+ \\epsilon \\tag{Full Model, FM} \\\\ Y &amp;= X_0 \\gamma &amp;&amp;+ \\epsilon \\tag{Reduced Model, RM} \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} \\dfrac {\\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}} {\\dfrac{Y&#39;(I-M)Y}{r(I-M)}} &amp;= \\dfrac {\\dfrac{Y&#39;(M-M_0)Y}{df_1}} {\\dfrac{Y&#39;(I-M)Y}{df_2}} &amp;&amp;\\sim F \\Bigg( df_1 , df_2, \\dfrac{\\beta&#39; X&#39; (M-M_0)X \\beta }{2 \\sigma^2} &amp;&amp; \\Bigg) \\tag{Under the FM} \\\\ \\\\\\ \\\\\\ \\dfrac {\\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}} {\\dfrac{Y&#39;(I-M)Y}{r(I-M)}} &amp;= \\dfrac {\\dfrac{Y&#39;(M-M_0)Y}{df_1}} {\\dfrac{Y&#39;(I-M)Y}{df_2}} &amp;&amp;\\sim F \\big( df_1 , df_2, 0 &amp;&amp; \\big) \\tag{Under the RM} \\end{alignat}\\] $ Note: Example 3.2.2.; pp. 58–59 $ \\[\\begin{alignat}{2} M-M_0 &amp;= (I-M_0) &amp;&amp;-(I-M) \\\\ Y&#39;(M-M_0)Y &amp;= Y&#39;(I-M_0)Y &amp;&amp;-Y&#39;(I-M)Y \\\\ &amp;= SSE_{RM} &amp;&amp;-SSE_{FM} \\end{alignat}\\] $ 6.5.3 A Generalized Test Procedure Assume that \\(Y = X \\beta + \\epsilon\\) is correct. Want to test the adequacy of a model \\(Y = X_0 \\gamma + Xb + \\epsilon\\), where \\(\\mathcal{C}(X_0) \\subset \\mathcal{C}(X)\\) and some known vector \\(Xb=\\) offset. Example 3.2.3.; Multiple Regression $ Y = _0 J + _1 X_1 + _2 X_2 + _3 X_3 + $ want to test \\(H_0: \\beta_2 = \\beta_3+5, \\; beta_1 = 0, \\cdots\\). $ \\[\\begin{alignat}{2} Y &amp;= X \\beta &amp;&amp; &amp;&amp;+ \\epsilon \\tag{FM} \\\\ Y^\\ast &amp;\\equiv Y &amp;&amp; - X b &amp;&amp; \\\\ &amp;=X \\beta &amp;&amp; - Xb &amp;&amp;+ \\epsilon \\\\ &amp;=X (\\beta &amp;&amp; - b) &amp;&amp;+ \\epsilon \\\\ &amp;=X \\beta^\\ast &amp;&amp; &amp;&amp;+ \\epsilon \\tag{FM} \\\\ \\\\\\ \\\\\\ Y &amp;= X_0 \\gamma &amp;&amp; + Xb &amp;&amp;+ \\epsilon \\tag{RM} \\\\ Y^\\ast &amp;\\equiv Y &amp;&amp; &amp;&amp; &amp;&amp; - X b \\\\ &amp;=X \\gamma &amp;&amp; &amp;&amp;+ \\epsilon \\tag{RM} \\end{alignat}\\] $ In addition, when \\(Y^\\ast = Y_\\ast\\), $ \\[\\begin{alignat}{2} \\dfrac {\\dfrac{ Y_\\ast &#39; (M-M_0) Y_\\ast }{ r(M-M_0)}} {\\dfrac{ Y_\\ast &#39; (I-M) Y_\\ast }{r(I-M)}} &amp;\\sim F \\Big( r(M-M_0), r(I-M), \\delta^2 \\Big) \\\\ \\\\ \\delta^2 &amp;=\\dfrac{1}{2 \\sigma^2} \\Big( {\\beta^\\ast} &#39; X &#39; (M-M_0) X \\beta^\\ast \\Big) \\tag{non-centrality parameter} \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} 0 &amp;= \\beta_\\ast &#39; X&#39; &amp;&amp;(M-M_0) X \\beta_\\ast \\\\ &amp;\\Updownarrow \\\\ 0 &amp;= &amp;&amp;(M-M_0)X \\beta_\\ast \\\\ &amp;\\Updownarrow \\\\ X\\beta &amp; = M_0 (X &amp;&amp;\\beta - X b) + Xb \\tag{3} \\end{alignat}\\] $ will hold if $ \\[\\begin{align} \\gamma &amp;= (X_0 &#39; X_0)^- X_0(X \\beta - Xb) \\\\ &amp;= (X_0 &#39; X_0)^- X_0 X \\beta_\\ast \\end{align}\\] $ Furthermore, $ \\[\\begin{alignat}{2} Y_\\ast &#39; (M-M_0)Y_\\ast &amp;= Y_\\ast &#39; (I-M_0)Y_\\ast &amp;&amp;- &amp;&amp;Y_\\ast &#39; (I-M)Y_\\ast \\; \\; \\; \\; \\;\\text{ , and } \\\\ Y &#39; (I-M)Y &amp;= &amp;&amp; &amp;&amp; Y_\\ast &#39; (I-M)Y_\\ast \\end{alignat}\\] $ 6.5.4 Testing Linear Parametric Functions \\(H_0: Y= X \\beta + \\epsilon, \\; \\; \\; \\; \\; \\Lambda&#39; \\beta=0 \\tag{1}\\) $ \\[\\begin{alignat}{2} \\Lambda &#39; \\beta = 0 \\; \\; \\; &amp;\\iff \\beta &amp;&amp;\\in \\mathcal{N}(\\Lambda &#39;) = \\mathcal{C}(X)^\\perp \\\\ &amp;\\iff \\beta \\perp \\mathcal{C}(\\Lambda) \\\\ &amp;\\iff \\beta \\perp \\mathcal{C}(\\Gamma) \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; &amp;&amp;\\text{ if } \\exists\\Gamma \\; \\; s.t. \\; \\mathcal{C}(\\Gamma) = \\mathcal{C}(\\Lambda) \\\\ &amp;\\iff \\beta \\perp \\mathcal{C}(U) &amp;&amp;\\text{ if } \\exists U \\; \\; s.t. \\; \\mathcal{C}(U) = \\mathcal{C}(\\Lambda)^\\perp \\\\ &amp;\\iff \\beta = U_\\gamma &amp;&amp; \\exists \\gamma \\tag{2} \\end{alignat}\\] $ Thus, letting \\(X_0 = XU\\), (in general, \\(\\mathcal{C}(X_0) \\subset \\mathcal{C}(X)\\)), then $ \\[\\begin{alignat}{2} Y &amp;= X \\beta &amp;&amp;+ \\epsilon \\\\ &amp;= X U \\gamma &amp;&amp;+ \\epsilon \\\\ &amp;= X_0 \\gamma &amp;&amp;+ \\epsilon \\tag{3} \\end{alignat}\\] $ Suppose \\(\\mathcal{C}(X_0) = \\mathcal{C}(X)\\). Then there is nothing to test and \\(\\Lambda&#39; \\beta = 0\\) involves only arbitrary side conditions that do not affect the model. (EXAMPLE 3.3.1. pp. 62–64) $ ’ ; ; ; ; ; ; P:= X’ P $ $ \\[\\begin{align} \\mathcal{C}(MP) &amp;\\equiv \\mathcal{C}(M-M_0) \\\\ &amp;= \\mathcal{C}(X-X_0) \\\\ &amp;= \\mathcal{C}(X) \\; \\cap \\; \\mathcal{C}(X_0)^\\perp\\\\ &amp;= \\mathcal{C}(X_0)_{\\mathcal{C}(X)}^\\perp \\end{align}\\] $ thus, its distribution for testing \\(H_0: \\Lambda &#39; \\beta = 0\\) is given by $ \\[\\begin{alignat}{2} \\dfrac {\\dfrac{Y&#39;(M_{MP})Y}{r(M_{MP})}} {\\dfrac{Y&#39;(I-M)Y}{r(I-M)}} &amp;\\sim F \\Big( r(M_{MP}), r(I-M), \\delta^2 \\Big) \\tag{5} \\\\ \\\\\\ \\delta^2 &amp;= \\beta &#39; X&#39; M_{MP}X \\beta \\tag{non-centrality parameter} \\end{alignat}\\] $ Proposition 3.3.2 $ \\[\\begin{alignat}{2} \\mathcal{C}(M-M_0) &amp;= \\mathcal{C}(X_0)_{\\mathcal{C}(X)}^\\perp \\\\ &amp;= \\mathcal{C}(XU)_{\\mathcal{C}(X)}^\\perp = \\mathcal{C}(MP) \\end{alignat}\\] $ $ \\[\\begin{alignat}{2} H_0: Y=X\\beta + \\epsilon, \\; \\; \\; \\; \\; \\Lambda &#39; \\beta = 0 \\\\ \\Updownarrow \\\\ H_0: Y=X\\beta + \\epsilon, \\; \\; \\; \\; \\; P&#39;X \\beta = 0 \\\\ \\Updownarrow \\\\ H_0: Y=X\\beta + \\epsilon, \\; \\; \\; \\; \\; P&#39;MX \\beta = 0 (\\because MX = X) \\\\ \\Updownarrow \\\\ E(Y) \\in \\mathcal{C}(X), \\; \\; \\; \\; E(Y) \\perp \\mathcal{C}(MP) \\\\ \\Updownarrow \\\\ E(Y) \\in \\mathcal{C}(X) \\; \\cap \\; \\mathcal{C}(MP)^\\perp, \\; \\; \\; \\; \\mathcal{C}(X_0)=\\mathcal{C}(X) \\; \\cap \\; \\mathcal{C}(MP)^\\perp = \\mathcal{C}(MP)^\\perp_{\\mathcal{C}(X)} \\Longrightarrow \\mathcal{C}(X_0)^\\perp_{\\mathcal{C}(X)} = \\mathcal{C}(MP) \\\\ \\Updownarrow \\\\ X_0 = (I-M_{MP})X \\end{alignat}\\] $ $ \\[\\begin{align} \\mathcal{C} \\Big[ (I-M_{MP})X \\ \\Big] &amp;= \\mathcal{C} (X) \\; \\cap \\; \\mathcal{C} (MP)^\\perp \\\\ &amp;= \\mathcal{C} (X) \\; \\cap \\; \\mathcal{C} (P)^\\perp \\tag{EXAMPLE 3.3.4.: pp.66–67} \\end{align}\\] $ let \\(\\Lambda &#39; \\beta\\) is estimable, i.e., \\(\\Lambda = X&#39;P\\). then \\(\\mathcal{C}(\\Lambda) = \\mathcal{C}(X&#39;P) =\\mathcal{C}(MP)\\), and \\(X \\hat \\beta = MY\\), and \\(\\Lambda &#39; \\hat \\beta = P&#39; X \\hat \\beta = P&#39; M Y\\). then $ \\[\\begin{align} Y&#39; M_{MP}Y &amp;= Y&#39; M &amp;&amp; (P&#39; M P)^- &amp;&amp; MPY \\\\ &amp;= \\hat \\beta &#39; \\Lambda &amp;&amp; [P&#39; X(X&#39;X)^-X&#39; P]^- &amp;&amp; \\Lambda &#39; \\hat \\beta \\\\ &amp;= \\hat \\beta &#39; \\Lambda &amp;&amp; [\\Lambda&#39; (X&#39;X)^- \\Lambda]^- &amp;&amp; \\Lambda &#39; \\hat \\beta \\end{align}\\] $ 이윗부분 전혀모르겠음 thus, $ \\[\\begin{align} (5) = \\dfrac{\\dfrac{\\hat \\beta &#39; \\Lambda [\\Lambda &#39; (X&#39;X)^- \\Lambda]^- \\Lambda&#39; \\hat \\beta}{r(\\Lambda)}}{MSE} &amp;\\sim F \\Big( r(MP), r(I-M), \\delta^2 \\Big)\\\\ \\\\\\ \\\\\\ \\delta^2 &amp;= \\dfrac{\\hat \\beta &#39; \\Lambda [\\Lambda &#39; (X&#39;X)^- \\Lambda]^- \\Lambda&#39; \\hat \\beta}{2 \\sigma^2} \\\\ Cov\\Big(\\Lambda &#39; \\hat \\beta \\Big) &amp;= \\sigma^2 \\Lambda &#39; (X&#39; X)^{-} \\Lambda \\end{align}\\] $ For \\(H_0: \\lambda &#39; \\beta =0, \\; \\; \\; \\lambda \\in \\mathbb{R}^p\\), $ \\[\\begin{align} Y&#39;M_{MP}Y &amp;= \\hat \\beta &#39; \\lambda \\big [\\lambda &#39; (X&#39;X)^- \\lambda \\big]^- \\lambda&#39; \\hat \\beta \\\\ &amp;=\\dfrac{\\big( \\lambda&#39; \\hat \\beta \\big)^2}{\\lambda&#39;(X&#39;X)^-\\lambda} \\end{align}\\] $ and, under \\(H_0: \\lambda &#39; \\beta =0\\), $ F = (5) = F ( 1, ; r(I-M) ) $ Definition 3.3.5. The condition \\(E(Y) \\perp \\mathcal{C}(MP)\\) is called the constraint by \\(\\Lambda &#39; \\beta = 0\\) where \\(\\Lambda = X&#39; P\\). in other words, \\(\\mathcal{C}(MP)\\) is the constraint by \\(\\Lambda &#39; \\beta = 0\\). Do Exercise 3.5: Show that a necessary and sufficient condition for \\(\\rho_1 &#39; X \\beta = 0\\) and \\(\\rho_2 &#39; X \\beta = 0\\) to determine the orthogonal constraints on the model is that \\(\\rho_1 &#39; X \\rho_2 = 0\\) 6.5.5 Theoretical Complements Consider testing \\(\\Lambda &#39; \\beta = 0\\) when \\(\\Lambda &#39; \\beta\\) is NOT estimable. let \\(\\Lambda_0 &#39; \\beta\\) be estimable part of \\(\\Lambda &#39; \\beta\\). \\(\\Lambda_0\\) is chosen, so that \\(\\mathcal{C}(\\Lambda_0) = \\mathcal{C}(\\Lambda) \\; \\cap \\; \\mathcal{C}(X&#39;)\\), which means that \\(\\Lambda &#39; \\beta = 0\\) implies that \\(\\Lambda_0 &#39; \\beta = 0\\) but \\(\\Lambda_0 &#39; \\beta\\) is estimable, because \\(\\mathcal{C}(\\Lambda_0) \\subset \\mathcal{C}(X&#39;)\\). Theorem 3.3.6. let \\(\\mathcal{C}(\\Lambda_0) = \\mathcal{C}(\\Lambda) \\; \\cap \\; \\mathcal{C}(X&#39;)\\) and \\(\\mathcal{C}(U_0) = \\mathcal{C}(\\Lambda_0)^\\perp\\). Then \\(\\mathcal{C}(XU) = \\mathcal{C}(XU_0)\\). Thus \\(\\Lambda &#39; \\beta = 0\\) and \\(\\Lambda_0 &#39; \\beta = 0\\) induce the same RM. Proposition 3.3.7. let \\(\\Lambda_0 &#39; \\beta\\) be estimable and \\(\\Lambda \\not = 0\\). then \\(\\Lambda &#39; \\beta = 0 \\; \\; \\Longrightarrow \\; \\; \\mathcal{C}(XU) \\not = \\mathcal{C}(X)\\). Corollary 3.3.8. $ (_0) = () ; ; (X’) = {0 } \\ \\ (XU) ; ; (X) $ 6.5.6 A Generalized Test Procedure Consider as below, whose column space is solvable. \\(H_0: \\Lambda&#39; \\beta = d, \\; \\; \\; \\; \\; d \\in \\mathcal{C}(X&#39;), \\; \\; \\; \\; \\Lambda&#39; b =d\\) $ \\[\\begin{alignat}{2} \\Lambda &#39; \\beta = \\Lambda &#39; b = d \\; \\; \\; &amp;\\iff \\Lambda &#39; (\\beta - b) &amp;&amp;= 0 \\\\ &amp;\\iff (\\beta - b) &amp;&amp;\\perp \\mathcal{C}(\\Lambda) \\\\ &amp;\\iff (\\beta - b) &amp;&amp;\\in \\mathcal{C}(U) \\; \\; \\; \\; \\; \\; &amp;&amp;\\text{where } \\; \\mathcal{C}(U) = \\mathcal{C}(\\Lambda)^\\perp \\\\ &amp;\\iff (\\beta - b) &amp;&amp;= U_\\gamma &amp;&amp;\\exists \\gamma \\\\ &amp;\\iff X\\beta - Xb &amp;&amp;= XU_\\gamma \\\\ &amp; \\; \\; \\; \\Updownarrow \\\\ X\\beta &amp;= XU_\\gamma + Xb, \\\\ Y &amp;= X \\beta + \\epsilon \\\\ &amp;= X U_\\gamma + Xb + \\epsilon \\\\ &amp;= X_0 \\gamma + Xb + \\epsilon, &amp;&amp; &amp;&amp; \\text{where } \\; X_0 = XU \\end{alignat}\\] $ if \\(\\Lambda = X&#39;P\\), then \\(\\mathcal{C}(X_0)_{\\mathcal{C}(X)}^\\perp = \\mathcal{C}(MP)\\) and its test statistics is $ \\[\\begin{align} F = \\dfrac {\\dfrac{(Y-Xb)&#39;M_{MP}(Y-Xb)}{r \\Big(M_{MP} \\Big)}} {\\dfrac{(Y-Xb)&#39;(I-M)(Y-Xb)}{r \\Big(I-M \\Big)}} = \\dfrac {\\dfrac{(\\Lambda &#39; \\hat \\beta - d)&#39; \\Big[ \\Lambda&#39;(X&#39;X)^{-}\\Lambda \\Big]^- (\\Lambda &#39; \\hat \\beta - d)}{r(\\Lambda)}} {MSE} \\sim F(?, ?, ?) \\end{align}\\] $ Remark: (EXAMPLE 3.3.9.: pp.71–72, EXAMPLE 3.4.1.: pp.75) If \\(\\Lambda &#39; \\beta = d\\), the same reduced model results if we take \\(\\Lambda &#39; \\beta = d_0\\), where \\(d_0 = d + \\Lambda &#39; \\nu\\) and \\(\\nu \\perp \\mathcal{C}(X&#39;)\\). Note that, in this construction, if \\(\\Lambda &#39; \\beta = d\\) is estimable, \\(d_0 = d\\) for any \\(\\nu\\). 6.5.7 Testing Single Degrees of Freedom in a Given Subspace $ RM: Y=X_ 0 + ; ; ; ; ; vs. ; ; ; ; ; FM: Y=X + , ; ; ; ; ; with; ; (X_0) (X) $ let \\(M_\\ast = M - M_0\\), consider \\(H_0 : \\Lambda &#39; \\beta = 0\\). if \\(\\Lambda = X&#39;P\\), i.e. \\(\\Lambda \\in \\mathcal{C}(X&#39;)\\), then \\(M_\\ast = M_{MP}\\). Proposition 3.3.2 Since \\(M M_\\ast = M_\\ast\\), $ \\[\\begin{align} &amp;\\mathcal{C}(M - M_0) = \\mathcal{C}(X_0)_{\\mathcal{C}(X)}^\\perp \\equiv \\mathcal{C}(XU)_{\\mathcal{C}(X)}^\\perp = \\mathcal{C}(MP) \\\\ \\Longrightarrow \\; \\; \\; &amp;M \\rho \\in \\mathcal{C}(M_\\ast) \\\\ \\Longrightarrow \\; \\; \\; &amp;M \\rho = M_\\ast M \\rho = M_\\ast \\rho \\\\ \\Longrightarrow \\; \\; \\; &amp;\\rho &#39; \\hat \\beta = \\rho &#39; M_\\ast Y = \\rho &#39; M Y \\end{align}\\] $ thus the test statistic for \\(H_0 : \\Lambda &#39; \\beta = 0\\) is $ = $ 6.5.8 Breaking SS into Independent Components Consider \\(X = \\begin{pmatrix} X_0, &amp; X_1 \\end{pmatrix}\\). set $ \\[\\begin{alignat}{2} &amp;SSR(X_1 \\vert X_0) &amp;&amp;\\equiv Y &#39; (M-M_0)Y &amp;&amp; \\tag{Sum of Squares for regression X1 after X0}\\\\ &amp;SSR(X) &amp;&amp;\\equiv Y &#39; MY \\\\ &amp;SSR(X_0) &amp;&amp;\\equiv Y &#39; M_0 Y \\\\ &amp;SSR(X) &amp;&amp;= SSR(X_0) &amp;&amp;+ SSR (X_1 \\vert X_0) \\end{alignat}\\] $ Note: if \\(\\epsilon \\sim N(0, \\; \\sigma I)\\), then \\(SSR(X_0) \\perp SsR(X_1 \\vert X_0)\\). 6.5.9 General Theory Let \\(M\\) and \\(M_\\ast\\) be the orthogonal projection operator into \\(\\mathcal{C}(X)\\) and \\(\\mathcal{C}(X_\\ast)\\) respectively. Then, with \\(\\mathcal{C}(X_\\ast) \\subset \\mathcal{C}(X)\\), \\(M_\\ast\\) defines a test statistic as below. $ {} {} ; ; ; :Y = X_+ $ $ \\[\\begin{align} &amp;I-(M-M_\\ast ) &amp;&amp;= (I-M) + M_\\ast \\\\ &amp;\\mathcal{C}(M-M_\\ast) &amp;&amp;:\\tag{Estimation Space, under H0} \\\\ &amp;\\mathcal{C}(M_\\ast) &amp;&amp;:\\tag{Test Space, under H0} \\\\ &amp;\\mathcal{C} \\Big(I - (M-M_\\ast)\\Big) &amp;&amp;:\\tag{Error Space, under H0} \\end{align}\\] $ Using Gram-Schmidt procedure, let’s construct \\(M_\\ast\\) so that $ M_= RR’ = {i=1}^r R_iR_i ’ = {i=1}^r M_i, ; ; ; ; ; R=(R_1 , , R_r) $ and \\(M_i M_j=0\\) for \\(i \\not = j\\). By Theorem 1.3.7, $ Y’M_i Y Y’M_j Y ; ; ; ; ; ; M_i M_j =0 $ Next, $ Y’M Y = _{i=1}^r Y’M_i Y $, therefore when \\(r(M_i)=1\\), $ {} {} F ( 1, r(I-M), ’ X’ M_i X ) $ $ \\[\\begin{alignat}{2} &amp; &amp;&amp; &amp;&amp; &amp;&amp;\\beta &#39; X&#39; M_\\ast X \\beta \\; \\; &amp;&amp;= \\; \\; \\sum_{i=1}^r \\beta &#39; X&#39; M_i X \\beta &amp;&amp; =0 \\; \\; \\; \\\\ &amp;\\iff &amp;&amp; &amp;&amp; \\forall i \\; \\; : \\; \\; &amp;&amp; \\beta &#39; X&#39; M_i X \\beta &amp;&amp; &amp;&amp;=0 \\\\ &amp;\\iff &amp;&amp; &amp;&amp;\\forall i \\; \\; : \\; \\; &amp;&amp;R_i &#39; X \\beta &amp;&amp; &amp;&amp;= 0 \\\\ &amp;\\iff &amp;&amp; &amp;&amp; &amp;&amp;H_0 \\text{ is true.} \\end{alignat}\\] $ EXAMPLE 3.6.1.: Balanced design; pp.79–80 EXAMPLE 3.6.2.: Unbalanced design;pp.80–81 6.5.10 Two-Way ANOVA $ \\[\\begin{alignat}{2} y_{ijk} &amp;= \\mu + \\alpha_i + \\eta_j &amp;&amp;+ \\epsilon_{ijk} \\tag{FM} \\\\ y_{ijk} &amp;= \\mu + \\alpha_i &amp;&amp;+ \\epsilon_{ijk} \\tag{RM} \\end{alignat}\\] $ $ \\[\\begin{align} M &amp;= M_\\mu + M_\\alpha + M_\\eta \\\\ Y&#39;(M-M_0)Y &amp;= R(\\eta \\; \\Big \\vert \\; \\alpha, \\; \\mu) \\tag{1} \\end{align}\\] $ Reduction in SSE, due to fitting \\(\\eta_j\\)’s after \\(\\mu\\) and \\(\\alpha_i\\)’s. Next, $ \\[\\begin{alignat}{2} y_{ijk} &amp;= \\mu + \\alpha_i &amp;&amp;+ \\epsilon_{ijk} \\tag{FM} \\\\ y_{ijk} &amp;= \\mu &amp;&amp;+ \\epsilon_{ijk} \\tag{RM} \\\\ \\\\\\ \\\\\\ Y&#39;(M_0-M_J)Y &amp;= R(\\alpha \\; \\Big \\vert \\; \\mu) \\\\ Y&#39;(M-M_J)Y &amp;= R(\\alpha, \\; \\eta \\; \\Big \\vert \\; \\mu) \\\\ &amp;= R(\\eta \\; \\Big \\vert \\; \\mu, \\; \\alpha) &amp;&amp;+ R(\\alpha \\; \\Big \\vert \\; \\mu) \\end{alignat}\\] $ In general, $ \\[\\begin{alignat}{2} R(\\eta \\; \\Big \\vert \\; \\alpha, \\; \\mu) &amp;\\not = R(\\eta \\; \\Big \\vert \\; \\mu) \\\\ R(\\alpha \\; \\Big \\vert \\; \\eta, \\; \\mu) &amp; \\not = R(\\alpha \\; \\Big \\vert \\; \\mu) \\end{alignat}\\] $ In paricular, for balanced design, if \\(\\mathcal{C}(X_\\alpha) \\perp \\mathcal{C}(X_\\eta)\\), $ \\[\\begin{alignat}{2} R(\\eta \\; \\Big \\vert \\; \\alpha, \\; \\mu) &amp; = R(\\eta \\; \\Big \\vert \\; \\mu) \\\\ R(\\alpha \\; \\Big \\vert \\; \\eta, \\; \\mu) &amp; = R(\\alpha \\; \\Big \\vert \\; \\mu) \\end{alignat}\\] $ Proposition 3.6.3. $ \\[\\begin{alignat}{2} R(\\eta \\; \\Big \\vert \\; \\alpha, \\; \\mu) &amp; = R(\\eta \\; \\Big \\vert \\; \\mu) \\; \\; \\; \\; \\; &amp;&amp;\\iff \\; \\; \\; \\; \\; \\mathcal{C}(X_1 - M_j) \\perp \\mathcal{C}(X_0 - M_j) \\\\ \\text{that is}\\; \\; \\; \\; \\; \\; \\; M_1 - M_J&amp; = M-M_0 \\; \\; \\; \\; \\; &amp;&amp;\\iff \\; \\; \\; \\; \\; (M_1 - M_J)(M_0 - M_J) = 0, \\; \\; \\; \\; \\; \\text{where} \\; &amp;&amp;R(\\eta \\; \\Big \\vert \\; \\alpha, \\; \\mu) &amp;&amp;= Y&#39;(M-M_0)Y \\\\ &amp; &amp;&amp; &amp;&amp; R(\\eta \\; \\Big \\vert \\; \\mu) &amp;&amp;= Y&#39;(M_1 -M_0)Y \\end{alignat}\\] $ 6.5.11 Confidence Regions \\(100(1-\\alpha)\\%\\) Confidence Region(CR) for \\(\\Lambda &#39; \\beta\\) consists of all the vectors \\(d\\) satisfying the inequality $ {} {MSE} ( 1- , ; r(), ; r(I-M) ) $ These vectors form an ellipsoid in \\(r(\\Lambda)\\)-dimensional space. For regression problems, if we take \\(P&#39; = (X&#39;X)^{-1}X&#39;\\), then \\(\\Lambda&#39;\\beta = P&#39; X \\beta = \\beta = d\\). The \\(100(1-\\alpha)\\%\\) CR is $ \\[\\begin{alignat}{2} &amp; \\dfrac {\\dfrac{\\Big[\\Lambda &#39; \\hat \\beta - d\\Big]&#39; \\Big[\\Lambda &#39; (X&#39;X)^- \\Lambda\\Big]^- \\Big[\\Lambda &#39; \\hat \\beta - d\\Big]}{r(\\Lambda)}} {MSE} \\; \\; \\; &amp;&amp; = \\; \\; \\; &amp; \\dfrac {\\dfrac{\\Big(\\hat \\beta - \\beta \\Big)&#39; \\Big( X&#39;X \\Big)\\Big(\\hat \\beta - \\beta \\Big)} {p}} {MSE} \\; \\; \\; &amp;&amp;\\le \\; \\; \\; \\Big( 1- \\alpha, \\; p, \\; n-p \\Big) \\end{alignat}\\] $ 6.5.12 Tests for Generalized Least Squares Models $ \\[\\begin{alignat}{4} &amp;Y &amp;&amp;= &amp;&amp;X \\beta &amp;&amp;+ &amp;&amp;\\epsilon \\; \\; \\; \\; \\; &amp;&amp;vs. \\; \\; \\; \\; \\; &amp;&amp;Y = &amp;&amp;X_0 \\beta_0 &amp;&amp;+ &amp;&amp;\\epsilon , \\; \\; \\; \\; \\; &amp;&amp; \\epsilon \\sim N(0, \\; \\sigma^2 V) \\tag{1} \\\\ &amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; \\Updownarrow \\\\ Q^{-1}&amp;Y &amp;&amp;= Q^{-1} &amp;&amp;X \\beta &amp;&amp;+ Q^{-1} &amp;&amp;\\epsilon \\; \\; \\; \\; \\; \\; \\; \\; \\; &amp;&amp;vs. \\; \\; \\; \\; \\; Q^{-1} &amp;&amp;Y = Q^{-1} &amp;&amp;X_0 \\beta_0 &amp;&amp;+ Q^{-1} &amp;&amp;\\epsilon , \\; \\; \\; \\; \\; Q^{-1} &amp;&amp; \\epsilon \\sim N(0, \\; \\sigma^2 I) \\tag{2} \\end{alignat}\\] $ test (1) and (2) is equal. Note: \\(\\mathcal{C}(Q^{-1}X_0) \\subset \\mathcal{C}(Q^{-1}X)\\). From Section 2.7, $ \\[\\begin{align} A &amp;= X(X&#39;V^{-1}X)^- X&#39; \\ast V^{-1} \\\\ \\\\ MSE &amp;= \\dfrac{Y&#39; (I-A)&#39; V^{-1} (I-A)Y}{n-r(X)} \\\\ \\\\ A_0 &amp;= X_0(X_0&#39;V^{-1}X_0)^- X_0&#39; \\ast V^{-1} \\end{align}\\] $ Theorem 3.8.1 $ \\[\\begin{align} \\dfrac{\\dfrac{Y&#39; (A-A_0) V^{-1} (A-A_0)Y}{r(X) - r(X_0 )}}{MSE} &amp;\\sim F \\Big( r(X)-r(X_0), \\; n-r(X) , \\; \\delta^2 \\Big) \\\\ \\\\ \\delta^2 &amp;= \\dfrac{\\beta &#39; X&#39; (A-A_0) V^{-1} (A-A_0)X \\beta}{2\\sigma^2} \\tag{1} \\\\ \\\\ \\\\\\ {\\beta &#39; X&#39; (A-A0) V^{-1} (A-A_0)X \\beta} \\; \\; \\; \\; \\; &amp;\\iff \\; \\; \\; \\; \\; E(Y) \\in \\mathcal{C}(X_0) \\tag{2} \\end{align}\\] $ Theorem 3.8.2 let \\(\\Lambda &#39; \\beta\\) be estimable. then the test statistic for \\(H_0 : \\Lambda &#39; \\beta = 0\\) is $ \\[\\begin{align} \\dfrac{\\dfrac{\\hat \\beta &#39; \\Lambda \\Big[ \\Lambda &#39; (X&#39;V^{-1}X)^- \\Lambda \\Big]^- \\Lambda &#39; \\hat \\beta}{r(\\Lambda)}}{MSE} &amp;\\sim F \\Big( r(\\lambda), \\; n-r(X) , \\; \\delta^2 \\Big) \\\\ \\\\ \\delta^2 &amp;= \\dfrac{\\beta &#39; \\Lambda \\Big[ \\Lambda &#39; (X&#39;V^{-1}X)^- \\Lambda \\Big]^- \\Lambda &#39; \\beta}{2\\sigma^2} \\tag{1} \\\\ \\\\ \\\\\\ {\\beta &#39; \\Lambda \\Big[ \\Lambda &#39; (X&#39;V^{-1}X)^- \\Lambda \\Big]^- \\Lambda &#39; \\beta} \\; \\; \\; \\; \\; &amp;\\iff \\; \\; \\; \\; \\; \\Lambda &#39; \\beta = 0\\tag{2} \\end{align}\\] $ Theorem 3.8.3 $ \\[\\begin{align} \\dfrac{Y&#39; (A-A_0) V^{-1} (A-A_0)Y}{\\sigma^2} &amp;\\sim \\chi^2\\Big(r(x) - r(X_0), \\; \\delta^2 \\Big) \\\\ \\\\ \\delta^2 &amp;= \\dfrac{\\beta &#39; X&#39; (A-A_0) V^{-1} (A-A_0)X \\beta}{2\\sigma^2}, \\\\ \\\\ \\sigma^2 = 0 \\; \\; \\; \\; \\; &amp;\\iff E(Y) \\in \\mathcal{C}(X_0) \\tag{1} \\\\ \\\\ \\\\\\ \\dfrac{\\hat \\beta &#39; \\Lambda \\Big[ \\Lambda &#39; (X&#39;V^{-1}X)^- \\Lambda \\Big]^- \\Lambda &#39; \\hat \\beta}{2\\sigma^2} &amp;\\sim \\chi^2 \\Big( r(\\Lambda) , \\; \\delta^2 \\Big) \\\\ \\\\ \\delta^2 &amp;= {\\hat \\beta &#39; \\Lambda \\Big[ \\Lambda &#39; (X&#39;V^{-1}X)^- \\Lambda \\Big]^- \\Lambda &#39; \\hat \\beta}, \\\\ \\\\ \\sigma^2 = 0 \\; \\; \\; \\; \\; &amp;\\iff \\Lambda &#39; \\beta = 0 \\tag{2} \\end{align}\\] $ "],["generalized-least-squares.html", "6.6 Generalized Least Squares", " 6.6 Generalized Least Squares Consider a full rank parameterization $ Y = X + ; ; ; ; ; ; ; ; ; ; E()=0, ; ; ; Cov() = ^2 &gt;0 $ by SVD of \\(\\Sigma\\), $ \\[\\begin{alignat}{2} \\Sigma &amp;= \\Gamma &#39; \\Lambda \\Gamma = \\Gamma &#39; \\Lambda^{\\tfrac{1}{2}} \\Lambda^{\\tfrac{1}{2}}\\Gamma = \\Gamma &#39; \\Lambda^{\\tfrac{1}{2}} \\Gamma&#39; \\Gamma \\Lambda^{\\tfrac{1}{2}}\\Gamma = \\Lambda^{\\tfrac{1}{2}} \\\\ \\\\ Z &amp;\\equiv \\Lambda^{-\\tfrac{1}{2}} Y = \\Lambda^{-\\tfrac{1}{2}}(X \\beta + \\epsilon) = \\Lambda^{-\\tfrac{1}{2}}X \\beta + \\Lambda^{-\\tfrac{1}{2}} \\epsilon = W \\beta + \\epsilon^\\ast \\end{alignat}\\] $ $ \\[\\begin{align} \\hat \\beta &amp;= (W&#39;W)^{-1} W&#39; Z = (X&#39; \\Sigma^{-1}X)^{-1}X&#39;\\Sigma^{-1}Y \\\\ E(\\hat \\beta) &amp;= (X&#39; \\Sigma^{-1}X)^{-1} X&#39;\\Sigma^{-1} X \\beta = \\beta \\\\ Cov(\\hat \\beta) &amp;= \\sigma^2 (X&#39; \\Sigma^{-1}X)^{-1} \\\\ \\hat \\sigma^2 &amp;= \\dfrac{\\Vert Z - \\mu_Z \\Vert^2}{n-p} = \\dfrac{(Y-\\hat \\mu)&#39; \\Sigma^{-1} (Y-\\hat \\mu)}{n-p} \\end{align}\\] $ the projection Matrix is $ ^{-} X (X’ {-1}X){-1}X’ ^{-}$, which is symmetric, and hence is an orthogonal projection. Now all computations have been done in the \\(z\\) coordinates, so in particular \\(x&#39; \\beta\\) estimates \\(\\mu_Z = \\Sigma^{-\\tfrac{1}{2}} \\mu\\). Since linear combinations of Gauss-Markov estimates are Gauss-Markov, it follows immediately that \\(\\hat \\mu_Z = \\Sigma^{-\\tfrac{1}{2}} \\hat \\mu\\). 6.6.1 A direct solution via inner products We can approach the problem of determining the Generalized Least Squares estimators in a different way by viewing \\(\\Sigma\\) as determining an intter product. We do this by returning to first principles, carefully defining means and covariances in a general inner product space. let \\(x, \\; y \\in \\mathbb{R}^n\\) and \\((x,y) = x&#39;y\\) be the usual innter product. choose a basis \\(\\{e_1 , \\cdots, e_n \\}\\), the usual coordinate vectors. then a rvec \\(x\\) has coordinates \\((e_i, x) = x_i\\). Definition 1. \\(E(x)=\\mu= \\begin{pmatrix} \\mu_i \\end{pmatrix}\\) where \\(\\mu_i = E(e_i , \\; x)\\). For any \\(a \\in \\mathbb{R}^n\\), $ E( (a, x) ) = E( (_{i=1}^n a_i e_i, ; x ) ) = E( _{i=1}^n a_i (e_i, ; x) ) = _{i=1}^n a_i _i = (a, ; ) $ thus, another characterization of \\(\\mu\\) is: \\(\\mu\\) is the unique vector that satisfies \\(E\\Big( (a, x) \\Big) = (a, \\; \\mu)\\) for all \\(a \\in \\mathbb{R}^n\\). Now, turn to Cov. use the same set-up as above. if \\(E(x_i^2)&lt;\\infty\\), then \\(Cov(x_i , x_j) = (x_i = \\mu_i) (x_j - \\mu_j) = \\sigma_{ij} = \\sigma_{ji}\\) exists for all \\(i,j\\), and defines \\(\\Sigma = (\\sigma_{ij})\\). For any \\(a, b \\in \\mathbb{R}^n\\), $ Cov( (a, x), (b, x) ) = E( ({i=1}^n a_i x_i, ; {j=1}^n b_j x_j ) ) = {i=1}^n {j=1}^n a_i b_j Cov(x_i, ; x_j) = {i=1}^n {j=1}^n a_i b_j _{ij} =(a, b) $ Definition 2 Assume \\(E\\Bigg( (a,x)^2 \\Bigg) &lt; \\infty\\). The unique non-negative definite linear transformation \\(\\Sigma: V \\rightarrow V\\) that satisfies \\(Cov\\Bigg( (a,x), (b,x) \\Bigg) = (a, \\Sigma b)\\) for all \\(a, b \\in V\\) is called the covariance of \\(X\\) and is denoted \\(Cov(x)\\). Theorem 1 let \\(Y \\in V\\) with innerproduct \\((\\cdot, \\; \\cdot)\\), \\(Cov(Y)=\\Sigma\\). Define another inner product \\((\\cdot, \\; \\cdot )\\) on \\(V\\) by \\([x,y] - (x, \\; Ay)\\) for some positive definite \\(A\\). Then the covariance of \\(X\\) in the inner product sapce \\(V, \\; [\\cdot, \\; \\cdot])\\) is \\(\\Sigma A\\). Note 1: This shows that if \\(Cov(X)\\) exists in one inner product, it exists in all inner products. If \\(Cov(X)=\\Sigma\\) in \\(\\begin{pmatrix} V &amp; (\\cdot, \\; \\cdot) \\end{pmatrix}\\), then if \\(\\Sigma &gt; 0\\) in the inner product \\([x,y] = (x, \\; \\Sigma^{-1}y)\\), the covariance is \\(\\Sigma^{-1} \\Sigma = I\\). Theorem 2 Suppose \\(Cov(X) = \\Sigma\\) in \\(\\begin{pmatrix} V &amp; (\\cdot, \\; \\cdot) \\end{pmatrix}\\). If \\(\\Sigma_1\\) is symmetric on \\(\\begin{pmatrix} V &amp; (\\cdot, \\; \\cdot) \\end{pmatrix}\\), and \\(Cov \\Big( (a,x) \\Big) = (a, \\; \\Sigma_1 a)\\) for all \\(a \\in V\\), then \\(\\Sigma_1 = \\Sigma\\). This implies that the covariance is unique. Consider the inner product sapce given by \\(\\begin{pmatrix} \\mathbb{R}^n &amp; (\\cdot, \\; \\cdot) \\end{pmatrix}\\), where \\([x,y] = (x, \\; \\Sigma^{-1}y)\\), \\(E(Y)=\\mu \\in \\mathcal{E}\\) and \\(Cov(Y) = \\sigma^2 \\Sigma\\). Let \\(P_\\Sigma\\) be the projection on \\(\\mathcal{E}\\) in this inner product space, and let \\(Q_\\Sigma = I - P_\\Sigma\\), so \\(y = P_{\\Sigma} y + Q_{\\Sigma} y\\). Theorem 3 with \\([x,y] = (x, \\; \\Sigma^{-1}y)\\), \\(P_\\Sigma = X(X&#39;\\Sigma^{-1} X )^{-1} X&#39; \\Sigma^{-1}\\) is an orthogonal projection. Theorem 4 let the OLS estimate \\(\\hat \\beta = (X&#39;X)^{-1}X&#39;Y\\) and the GLS estimate \\(\\tilde \\beta = (X&#39;\\Sigma^{-1}X)^{-1} X&#39; \\Sigma^{-1}Y\\). then $ = ; ; ; ; ; ; ; ; ; ; (^{-1}X) = (X) $ Corollary 1 \\(\\mathcal{C}(\\Sigma^{-1}X) = \\mathcal{C}(X)= \\mathcal{C}(\\Sigma X)\\) So \\(\\Sigma\\) need not be inverted to apply the theory. To use this equivalence theorem (due to W. Kruskal), we usually characterize the \\(\\Sigma\\)’s for a given \\(X\\) for which \\(\\hat \\beta = \\tilde \\beta\\). if \\(X\\) is completely arbitrary, then only \\(\\Sigma = \\sigma^2 I\\) works. Intra-class correlation model: let \\(J_n \\in \\mathcal{C}(X)\\). then any \\(\\Sigma\\) of the form $ = ^2 (1-)I + ^2 J_n J_n ’ $ with \\(-\\dfrac{1}{n-1} &lt; \\rho &lt; 1\\) will work. to apply the theorem, we write, $ X = ^2 (1-)X + ^2 J_n J_n ’ X $ so for \\(i&gt;1\\), the i-th coluimn of \\(\\Sigma X\\) is $ ( X )_i = ^2 (1-)X_i + ^2 J_n a_i $ with \\(a_i = J_n &#39; X\\). Thus, the i-th column of \\(\\Sigma X\\) is a linear combination of the i-th column of \\(X\\) and the column of \\(1\\)’s. For the first column of \\(\\Sigma X\\), we compute \\(a_1 = J_n\\) and \\(\\Big ( \\Sigma X \\Big)_1 = \\sigma^2 (1- \\rho) J_n + n \\sigma^2 \\rho J_n = \\sigma^2 \\Big ( 1 + \\rho(n-1) \\Big )J_n\\), So \\(\\mathcal{C}(\\Sigma X) = \\mathcal{C}(X)\\) as required, provided that \\(1+\\rho(n-1) \\not = 0\\) or \\(\\rho &gt; -\\dfrac{1}{n-1}\\). "],["flat.html", "6.7 Flat", " 6.7 Flat 6.7.1 1.Flat Sometimes in statistical applications it is useful to consider a linear subspace that is shifted or translated from the origin. This will happen, for example, in models that include an intercept. It is therefore helpful to have the following definition of a space that is displaced from the origin. Definition 1 (Flat) suppose \\(M \\subset V\\) is a linear subspace, and \\(y_0 \\in V\\). Then a flat consists of \\(\\{x + y_0 \\; \\Big \\vert \\; x \\in M\\}\\). We will write \\(y_0 +M\\) where \\(M\\) is a subspace to indicate a flat. By considering translations, flats are equivalent to vector spaces. If \\(Y\\) is a rv whose domain is the flat \\(y_0 +M\\), then, if \\(y_0\\) is fixed, \\(Y-y_0\\) has domain \\(M\\). example set \\(S_4 = \\{(1,1,1)&#39; + z, \\; z \\in S_2\\}\\) is a flat, because \\(0 \\not \\in S_4\\). example In \\(C e^2\\), consider \\(M= \\left \\{ \\alpha \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\Bigg \\vert \\; \\alpha \\in C e \\right\\}\\), and \\(y_0 = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\\). Then the flat \\(y_0 + M\\) is given by the set \\(y_0 + M= \\left \\{ \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} + \\alpha \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\Bigg \\vert \\; \\alpha \\in C e \\right\\}\\). which is just a straight line that does not pass through the origin, but rather through the point \\((2,2)\\). The choice of \\(y_0\\) is not unique and it can be any point \\(y=y_0 + y_\\alpha\\), where \\(y_\\alpha = \\alpha(1,2)&#39;\\). For example, if \\(\\alpha = -2\\), then \\(y=(0,-2)&#39;\\) and if \\(\\alpha=+1\\), then \\(y=(3,4)&#39;\\), and so on. For any \\(y_0\\) not of this form, we simply get a different flat. This is summarized in the next remark. Theorem 1 The two spans $ \\[\\begin{align} F_1 &amp;= \\left\\{ z \\; \\Big \\vert \\; z=y_0 + x, \\; \\; \\; y_0 \\in V, \\; \\; \\; x \\in M \\subset V \\right\\} \\\\ F_2 &amp;= \\left\\{ z \\; \\Big \\vert \\; z=y_1 + x, \\; \\; \\; y_1 \\in F_1, \\; \\; \\; x \\in M \\subset V \\right\\} \\end{align}\\] $ are the same subspace, so the representation of the flat is not unique. Definition 2 (Sum and intersection of subspaces) let \\(H,K\\) be two linear subspaces. Then $ \\[\\begin{alignat}{2} H + K &amp;= \\Big\\{ x+y \\; &amp;&amp;\\Big \\vert \\; x \\in H, \\; \\; \\; y \\in K \\Big\\} \\tag{sum of H and K} \\\\ H \\cap K &amp;= \\Big\\{ x \\; &amp;&amp;\\Big \\vert \\; x \\in H, \\; \\; \\; x \\in K \\Big\\} \\tag{intersection of H and K} \\end{alignat}\\] $ Theorem 2 Both \\(H + K\\) and \\(H \\cap K\\) are linear subspaces. Definition 3 (Disjoint subspaces) Two subspaces are disjoint if \\(H \\cap K = \\big \\{ 0 \\big \\}\\), the null vector. Theorem 3 If \\(H \\cap K = \\big \\{ 0 \\big \\}\\), and \\(z \\in H +K\\), then the decomposition \\(z = x+y\\) with \\(x \\in H\\) and \\(y \\in K\\) is unique. prf) suppose \\(z=x+y\\) and \\(z=x&#39; + y&#39;\\). Then, \\(x-x&#39; \\in H\\) and \\(y-y&#39; \\in K\\). We must have \\(x+y = x&#39; + y&#39;\\) or \\(x-x&#39;=y-y&#39;\\), which in turn requires that \\(x-x&#39; = y-y&#39; = 0\\), since \\(0\\) is the only vector common to \\(H\\) and \\(K\\). Thus, \\(x=x&#39;\\) and \\(y=y&#39;\\). Theorem 4 if \\(H \\cap K = \\big \\{ 0 \\big \\}\\), then \\(\\dim(H+K) = \\dim(H) + \\dim(K)\\). In general, $(H+K) = (H) + (K) -(H K) $ Proof: Exercise. Definition 4 (Complement of a space) If \\(M\\) and \\(M^c\\) are disjoint subspaces of \\(V\\) and \\(V = M +M^c\\), then \\(M^c\\) is called a complement of \\(M\\). Remark 1: The complement is not unique. In \\(\\mathbb{R}^2\\), a subspace \\(M\\) of dimension 1 consists of a line through the origin. A complement of \\(M\\) is given by any other line \\(M^c \\not = \\alpha M\\) through the origin, because linear combinations of any two such lines span \\(Ce^2\\). In the linear model \\(Y = X \\beta + \\epsilon\\), we have that $= E(Y ) = X $, so that \\(\\mu \\in \\mathcal{C}(X)\\). To estimate \\(\\mu\\) with \\(\\hat \\mu\\), we might want to require that \\(\\hat \\mu \\in \\mathcal{C}(X)\\) (note: if \\(X\\) includes a constant, then \\(\\mathcal{C}(X)\\) is a flat; otherwise, it is a subspace). The estimate would then depend upon \\(Y\\) in a sensible way by moving \\(Y\\) to the subspace. The method of moving is via projections. The optimality of moves depends on the way we measure distance - on an inner product defined on the vector space. 6.7.2 2. Solutions to systems of linear equations Consider the Matrix equation \\(X_{n \\times p} \\beta_{p \\times 1} = y_{n \\times 1}\\). For a given \\(X\\) and \\(Y\\) does there exist \\(\\beta\\) to these equations? Is it unique? If not unique, can we characterize all possible solutions? If \\(n=p\\) and \\(X\\) is nonsingular, the unique solution is \\(\\beta = X^{-1} y\\). If \\(y \\in \\mathcal{C}(X)\\), \\(y\\) can be expressed as a linear combination of the columns of \\(X\\). If \\(X\\) is of full column rank, then the columns of \\(X\\) form a basis for \\(\\mathcal{C}(X)\\), and the solution \\(\\beta\\) is just the coordinates of \\(y\\) relative to this basis. For any g-inverse \\(X^-\\), we have \\(XX^- y = y\\) for all \\(y \\in \\mathcal{C}(X)\\), and so a solution is given by \\(\\beta=X^- y\\). If \\(\\rho (X) = rank \\Big( \\mathcal{C}(X) \\Big) &lt; p\\), then the solution is not unique. If \\(\\beta_0\\) as any solution, for example the solution is given by \\(\\beta=X^- y\\), then so is \\(\\beta_0 + z, \\;\\;\\;\\;\\; z\\in N(X)\\), which is null-space of \\(X\\). The set of solutions is given by \\(\\beta_0 + N(X)\\), which is a flat. If \\(y \\not \\in \\mathcal{C}(X)\\), then there is no exact solution. This is the usual situation in linear models, and leads to the estimation problem discussed in the next chapter. What we might do is get the closest solution by replacing \\(Y\\) by another vector \\(\\hat Y\\) that is as close to \\(Y\\) as possible; if we define close as \\(\\Vert Y - \\hat Y \\Vert^2\\) making small, we need to solve \\(X \\beta = P_{\\mathcal{C}(X)}Y\\) insetead of the original equation. If \\(X\\) has full column rank, this leads to the familiar solution: $ \\[\\begin{align} \\beta_0 &amp;= X^+ P y \\\\ &amp;= (X&#39;X)^{-1} X&#39; X (X&#39;X)^{-1}X&#39; Y \\\\ &amp; = (X&#39;X)^{-1}X&#39;Y \\tag{2} \\end{align}\\] $ which is unique. If \\(X\\) does not have not full column rank, then the set of solutions again forms a flat of the form \\(\\beta_0 + N(X)\\) with \\(\\beta_0\\) given by (2). "],["unified-approach-to-balanced-anova-models.html", "6.8 Unified Approach to Balanced ANOVA Models", " 6.8 Unified Approach to Balanced ANOVA Models We can develop a unified approach to obtaining orthogonal projection operatores in arbitrary balanced \\(k\\)-way ANOVA models by exploting the structure of design matrix. The structure of the design matrix can be easily examined using Kronecker products. Therefore, before we proceed further, we need to establish some more properties of Kronecker products. Kronecker Product \\(:= A \\otimes B = (a_{ij}B)\\). Consider the balanced two-way ANOVA model with interaction. This model is given by $ Y_{ijk} = + _ i + j + {ij} + _{ijk} $ where \\(i=1, \\cdots, a\\), \\(j=1, \\cdots, b\\), \\(k=1, \\cdots, N\\), and \\(n=abN\\). We want to write $ (M) = (M_) + (M_) + (M_) + (M_) $ and be able to compute the orthogonal projection operators in an easy and unified way. We can represent each subspace making up \\(\\mathcal{C}(M)\\) in terms of Kronecker produdcts. Once we do this, we can easily obtain the orthogonal projection operator for that space. ※ Notation: let \\(s\\) be an arbitrary index. Define \\(J_s\\) as the \\(s \\times 1\\) vector of ones, $P_s = J_s J_s ’ $ and \\(Q_s = I_s - P_s\\), where \\(I_s\\) is the \\(s \\times s\\) identity matrix. Thus, \\(P_s\\) is the orthogonal projection operator onto \\(\\mathcal{C}(J_s)\\) and \\(Q_s\\) is the orthogonal projection operator onto \\(\\mathcal{C}(J_s)^\\perp\\) ※ Facts: recall that the OPO onto \\(\\mathcal{C}(A)\\) is always given by by \\(A(A&#39;A)^{-}A&#39;\\). if \\(M\\) is an OPO, then \\(M^{-} = M\\). $ Kronecker Product forms for the OPO Computing \\(M_\\mu\\). We can write \\(J_n = J_\\a \\otimes J_b \\otimes J_N\\), so that \\(M_\\mu\\) is the OPO onto \\(\\mathcal{C} \\Big( J_\\a \\otimes J_b \\otimes J_N \\Big)\\). Thus by Fact 1 above, we have $ &amp; &amp;&amp;M_&amp;&amp; &amp;&amp; \\ &amp;= &amp;&amp;( J_J_b J_N ) &amp;&amp;( ( J_a ’ J_b ’ J_N ’ ) ( J_a J_b J_N ) )^{-} &amp;&amp;( J_a ’ J_b ’ J_N ’ ) \\ &amp;= &amp;&amp;( J_a J_b J_N ) &amp;&amp;( J_a ’ J_a J_b ’ J_b J_N ’ J_N)^{-} &amp;&amp;( J_a ’ J_b ’ J_N ’ ) \\ &amp;= &amp;&amp;( J_a J_b J_N ) &amp;&amp;( ab N)^{-} &amp;&amp;( J_a ’ J_b ’ J_N ’ ) &amp;= &amp;&amp; J_a J_a ’ + J_b J_b ’ + J_N J_N’ \\ &amp;= &amp;&amp;P_a P_b P_N $ Using the properties of Kronecker products, it can be easily shown that \\(M = I_a \\otimes I_b \\otimes P_N\\). the error space is \\(\\mathcal{C}(I-M)\\) and $ I-M &amp;= I_{abN} - M \\ &amp;= ( I_a I_b I_N ) - ( I_a I_b P_N ) \\ &amp;= ( I_a ) ( I_N - P_N ) \\ &amp;= I_a I_b Q_N $ observe that $ \\[\\begin{align} M + I - M &amp;= ( I_a \\otimes I_b \\otimes P_N ) + (I_a \\otimes I_b \\otimes Q_N) \\\\ &amp;= ( I_a \\otimes I_b) \\otimes(P_N + Q_N) \\\\ &amp;= ( I_a \\otimes I_b) \\otimes (I_N) \\\\ &amp;= I_a \\otimes I_b \\otimes I_N \\\\ &amp;= I_n \\end{align}\\] $ We can summarize the subspace and the OPO for the two-way ANOVA model as follows. Excercise Consider the three-way ANOVA model write out the subspaces and all OPO corresponding to each term in the ANOVA model completlely in terms of Kronecker. Find the simplest expression for \\(M_\\mu + M_\\alpha + M_\\eta\\). https://smartstore.naver.com/hidamari/products/5283571274 https://smartstore.naver.com/hidamari/products/3029413531 "],["network-stats.html", "Chapter 7 Network Stats ", " Chapter 7 Network Stats "],["introduction-2.html", "7.1 Introduction", " 7.1 Introduction Network = Graph: for mathematical purposes, networks are most commonly represented in a formal manner using graphs of various kinds Vertices (Vertex), Edges, directed, undirected 7.1.1 Types of Network Analysis Visualization Numerical Summaries – Transitivity (Clustering Coefficient): A-B, A-C 조합의 변호사가 동업할 때, B-C끼리도 동업할 확률은 얼마일까? 이는 social network에서의 transitivity 개념과 대응함. 소위 clustering coefficient로 요약되는, 삼각형을 이루는 (즉, 모든 세개의 vertex pair가 edge로 연결) vertex 3개 묶음들의 비율을 나열하는 것으로 수치적으로 획득 가능. – Assortativity Coefficient: 2가지 종류의 변호사(corporate와 litigation)이 존재할 때, 동업과 더 일을 자주하는지 다른 분야와 더 일을 자주하는지, 그 비율은 어떻게 되는지 궁금할 수 있음. 이는 social network의 assortativity 개념과 대응하며, in which labels of connected pairs of vertices들이 compared되는, 소위 assortativity coefficient라고 불리는 correlation statistic으로 quantified될 수 있다. The focus is on an attribute associated with network vertices (i.e., lawyer practice) and the network structure plays a comparatively more implicit role 7.1.2 Network Modeling and Inference 관찰 대상 네트워크가 어떻게 생겼는지 묻고 구조를 특성화하는 것을 넘어, 보다 근본적인 수준에서 우리는 네트워크가 어떻게 발생했는지 이해하는 데 관심이 있을 수 있다. 즉, 우리는 네트워크가 복잡한 관심 시스템과 관련된 몇 가지 기본적인 프로세스에서 비롯되었다고 생각하고 이러한 프로세스의 본질적인 측면이 무엇인지 물어볼 수 있다. 네트워크가 어떤 과정을 거쳐 획득되었는지 - 사용된 measurement와 construction process - 또한 숙고될만한 부분이다. Network Modeling: Mathematical Models: 간단한 확률 규칙에 의거하여 네트워크를 생산. 규칙은 특성한 메커니즘 혹은 원칙을 파악하기 위한 시도의 일환으로 정의됨 (ex: ‘the rich get richer’) Statistical Models: 대부분, 아니면 일부분이나마, 관측된 데이터와 맥락을 같이 하기 위해 정의되는 모델 (자주 probabilistic하기도 함, 1번의 성질도 같이 갖는다는 소리) 이며 이의 fit함은 통계적 추론의 일반적인 원칙들을 사용하여 영향을 받고, 또 평가도 받음 이러한 2개의 모델의 종류 사이에는 교집합이 존재하지만, 이 둘을 다루는 paper들 사이에는 그럼에도 불구하고 큰 차이들이 존재함 Erdos-Renyi Model: 각 vertex 쌍마다 iid 동전던지기를 통해 해당 쌍 사이에 edge를 둘지 안둘지를 랜덤하게 결정. 랜덤 그래프의 유명한 Erdos-Renyi 공식의 변형에 해당. 이는 성질이 정말 좋음. cohesive structure가 edge 1개에서의 확률의 함수로서 나타남. 또한 다른 더 복잡한 모델들과 비교되어 이해를 돕기 위한 교과서로서도. Mathematical Network Model: 수학모델은 현실 네트워크 데이터에 비하면 보통 너무 간단하지만, edge 구성의 특정 메커니즘이 어떻게 네트워크의 구조에 영향을 미칠 수 있는가 하는 것과, 관측된 네트워크에서 획득할 수 있는 구조적 성질이 얼마나 “significance” 한지를 판정하기 위한 네트워크의 null classes로 작동할 수 있다는 것에서 여전히 공부할 가치가 있음. Statistical Network Models: Exponential Random Graph Models 는 Generalized Linear Models (GLM)과 유사하며, 이는 둘다 지수족 형태(exponential family form)에 기반을 두고 있다. edge들이 unmeasured, 혹은 알려지지 않은 변수에 뿌리를 두고 있다는 것이 핵심인 Latent network models은 hierarchical modeling에서의 latent 변수 사용법과 정확하게 평행하다 - 즉, 대비된다???. Stochastic block models는 mixture 모델의 형태로 볼 수도 있다. 여기서 중요한건 이렇게 나열해놨지만서도 고차원 데이터가 의존성 높은 데이터를 쓰면 이런 애들은 이렇게 표준화된 모델과 맞아떨어지는 정도가 낮아진다는 것이다. 7.1.3 Network Processes 복잡계의 요소들간의 상호작용을 모사하기 위해, 네트워크 그래프 자체는 보통 네트워크 분석의 주된 목표가 됨. 물론 네트워크 구성 요소 중 시스템 내의 다른 모든 요소들과 상호작용하는 변량 혹은 속성이 있다면 이녀석이 최고관심의 대상이 될 것. 그러나 그럼에도 불구하고 요소들간의 상호작용이 앞에서 언급한 최고관심 대상에게 영향을 줄 것이라고 생각하는 것이 비합리적이지 않으므로 네트워크 그래프 자체는 여전히 모델링과 분석의 대상이기에 합당함. 우리는 확률과정을 네트워크에서의 “삶”이라고 해석해볼 수 있으며 네트워크 안의 vertices에 의해 첨수(indexed)됨. 이러한 과정에 관한 다양한 질문들은 정적 network process에 관한 것이든 동적 network process에 관한 것이든 이들을 예측하고자 하는 문제로 해석될 수 있음. 7.1.3.1 Dynamic Processes network-based 관점에서 연구되는 많은 system들은 본질적으로 동적임. 동적이 얘들 특성과 더 잘 부합함. 수학적 모델링이 여전히 이러한 과정을 모델링하는데 있어 1번째로 사용되는 툴이지만, network-based 통계적 모델들이 점차적으로 그 사용이 늘어나고 있음. 왜냐고? contact network에 대한 더욱 대량의 데이터가 사용 가능해지고 있으니까. – Statistical methods for analyzing network flows. Referring to the movement of something — materials, people, or commodities, for example — from origin to destination, flows are a special type of dynamic process fundamental to transportation networks (e.g., airlines moving people) and communication networks (e.g., the Internet moving packets of information), among others. – Dynamic network analysis, wherein the network, the process(es) on the network, or indeed both, are expected to be evolving in time. "],["descriptive-statistics-of-networks.html", "7.2 Descriptive Statistics of Networks", " 7.2 Descriptive Statistics of Networks "],["data-collection-and-sampling.html", "7.3 Data Collection and Sampling", " 7.3 Data Collection and Sampling Difficulties in Network Data Collection. 뭔 분야든 통계의 근간은 데이터 수집. 데이터가 IID라면 이 데이터는 sample이나 실험에서 확보한 데이터. 하지만 이는 네트워크 실험에서는 사실상 불가능. 따라서 우리는 샘플을 deal with 하기가 어려우며, 이전에 해왔던 것 대비 일이 무척 어려워짐. 이러한 복잡성은 empirical networks를 다룰 때는 너무나도 자주 무시되고 있어서 안타까운 실정임. 7.3.1 Sampling Procedures Ideal Data: Network Census The ideal data would be a census or enumeration of the network. This would record every node, and every edge between nodes, with no spurious additional nodes or edges. If you are in the fortunate situation of having a complete network census, you can pretty much ignore the sampling process, and proceed to model network formation. 4 / 30 Sampling Procedures Sampling Designs Coping Strategies Big Data Solves Nothing Imperfections in Network Censuses Unfortunately, even studies which try to get a complete census may fall short of perfection. The exact failure modes depend on the nature of the network and indeed on the details of the measurement process; for concreteness, I focus here on survey-based measurements of social networks. These surveys often work by approaching people and asking them questions like “Who are your friends?” or “From whom do you seek advice?” or “From whom have you borrowed money?” 5 / 30 Sampling Procedures Sampling Designs Coping Strategies Big Data Solves Nothing Imperfections in Network Censuses There can be different results depending on whether are given suggestions, or a checklist of possibilities, or are asked to spontaneously recall names. Answers may be influenced by shame, boastfulness, or other emotions related to the “presentation of self in everyday life.” In older studies, it was common to frame the question as something like “name up to three colleagues you commonly go to for advice”; such censoring by degree necessarily prevented any recorded out-degree from being higher than three. 7.3.2 Sampling Designs 우리가 true(참정보, 참값)를 확보하는 것이 불가능하다면, 우리는 IID 통계량에 의해 예시되었던 “population” graph \\(G = (V, E)\\) 확보를 포기하고 “sample” graph \\(G^\\ast = (V^\\ast, E^\\ast)\\)를 얻는 쪽으로 선회한다. 이때 \\(V^\\ast \\subset V\\), \\(E^\\ast \\subset E\\). 이러한 sampled subgraphs를 얻기 위한 다양한 방법들에 대응되는 서로 다른 sampling designs들이 존재한다. 우선 population으로부터의 units들에 대한 simple random sample (SRS)를 이해하는 것이 샘플링을 이해하기 위한 1단계가 된다. 네트워크에서는 단순 랜덤 샘플마저도 복잡한 이해를 거쳐야 한다. 7.3.2.1 Induced and Incident Subgraph node \\(V\\)의 Simpl Random Sample (SRS)인 \\(V^\\ast\\)로부터 시작하자. 이로부터 발생시킨 (induced) subgraph \\((i, j) \\in E^\\ast\\). 이때 \\((i, j) \\in E^\\ast \\Leftrightarrow (i,j) \\in E\\), \\(i \\in V^\\ast\\) and \\(j \\in V^\\ast\\) 여야만 함. This natural procedure, induced subgraph sampling, turns out be very biased for even very simple network statistics, though the biases can sometimes be calculated and compensated for. 반면에 우리는 edge의 SRS에서 시작해볼 수도 있다. 이 경우 \\(E^\\ast\\)는 \\(E\\)의 SRS. 이후 이 edge 양끝에 해당하는 발생을 node로서 잡는다. 이인즉슨 \\(\\exists j\\inV:(i,j) \\in E^\\ast \\Rightarrow i \\in V^\\ast\\). Experience with conventional surveys may make incident-subgraph sampling seem odd, but there are many situations where it’s actually quite natural. 7.3.2.1.1 Example of a Bias The canonical example of how sampling can induce a bias, even when we’re just doing a simple random sample of nodes, is the mean degree. Intuitively, we don’t see any edges outside the induced subgraph, so the degree we record for each node is at most its real degree, and the mean degree in the sampled graph should be ≤ the true mean degree let \\(k_i = \\sum_{j=1}^n A_{ij}\\), 즉 \\(k_i\\)는 node \\(i\\)의 degree. 이 경우 모든 네트워크에 걸친 mean degree는 $k = {i=1}^n k{i} $. 여기서 \\(m\\)개의 노드를 SRS 한다면, node \\(i\\)에게 부여된 확률은 모든 각각의 node에게 부여된 확률과 같으므로, 따라서 \\(\\pi = \\frac{m}{n}\\). 여기서 \\(Z_i\\)를 \\(i \\in V^\\ast\\) 여부에 대한 indicator로 정의하자. 그렇다면 node \\(i\\)가 샘플 안에 있을 경우 \\(Z_i = 1\\). 또한 관측된 graph \\(G^\\ast\\)는 관측된 adjacency matrix \\(A^\\ast\\)를 보유하며, \\(A_{ij}^\\ast =1\\) iff \\(A_{ij}=1\\)이며 \\(i,j\\) 양쪽 모두가 샘플에 있을 경우에만. 그렇다면 plug-in estimate \\(\\bar k\\) from \\(G^\\ast\\)의 기댓값 \\(\\bar k^\\ast\\)는 어떻게 되는가? $$ \\[\\begin{alignat}{2} E \\left( \\bar k^\\ast \\right) &amp;= E \\left( \\frac{1}{m} \\sum_{i \\in V^\\ast} k_i^\\ast \\right) &amp;&amp;= E \\left( \\frac{1}{m} \\sum_{i \\in V^\\ast} \\sum_{j \\in V^\\ast} A_{ij}^\\ast \\right) \\\\ &amp;= E \\left( \\frac{1}{m} \\sum_{i=1}^n \\sum_{j =1}^n A_{ij}Z_i Z_j \\right) &amp;&amp;= \\frac{1}{m} \\sum_{i=1}^n \\sum_{j =1}^n A_{ij} E \\left(Z_i Z_j \\right) \\\\ &amp;= \\frac{1}{m} \\sum_{i=1}^n \\sum_{j =1}^n A_{ij} \\pi^2 &amp;&amp;=\\frac{1}{n \\pi} \\pi^2 \\sum_{i=1}^n \\sum_{j =1}^n A_{ij} \\\\ &amp;= \\frac{\\pi}{n } \\sum_{i=1}^n \\sum_{j =1}^n A_{ij} &amp;&amp;= \\pi \\bar k \\end{alignat}\\] $$ 7.3.2.2 Exploratory Sampling Design For both induced- and incident-subgraph sampling, the sampling frame is in some sense separate from the actual, realized graph. The population from which we draw our SRS has to include all nodes, or all edges, but doesn’t use the graph beyond that. In egocentric designs, we sample nodes and record information about their local neighborhoods, or ego networks. “ego”: Other times we record edges and non-edges among the neighbors of the initial node; This is sometimes called a star design. When we deal with star designs, we collect multiple local graph neighborhoods, and an important question is whether those overlap; depending on the recording process, this information might be available 7.3.2.3 Snowball Sampling Start with a seed node, and record its immediate neighborhood. We then repeat the process for each of the neighbors, and then their neighbors, etc., until either no new nodes are found or we get tired, i.e., a pre-selected size is reached. There can be multiple seeds; there may then be an issue of determining when two snowballs which have formed around different seeds have over-lapped. Snowball sampling leads to a different distribution over graphs than does either induced- or incident-subgraph sampling. Even if the seed is chosen by a simple random sample, the other nodes picked up by the snowball are not a random sample. Since they are nodes which can be reached by following paths from the seed, they must have degree at least 1, must be at least weakly connected to the seed, and in general tend to have higher-than-average degree. 7.3.2.3.1 Respondent-driven Sampling An important variant on snowball sampling, for social networks, is respondent-driven sampling. This originated as a way of studying members of hard-to-find (“hidden”) sub-populations - often ones which were hidden because membership in them is stigmatized or illegal. The technique is to find some initial members of the group in question, and then persuade them to recruit other members whom they know as research subjects. Often, the respondents are given unique physical tokens to pass on those whom they recruit, so that links can be traced, and there may be some incentive for participation. Censoring by degree can result if, for instance, there is only a limited number of physical tokens per respondent. 7.3.2.3.2 Trace-route Sampling Trace-route sampling probes a network by tracing routes through it. The typical procedure goes as follows: 1. Pick a set of source nodes. 2. Pick a set of target nodes. 3. For each source-target combination, find a path from the source to the target, and record all nodes and edges traversed along the path. Clearly, a lot will depend on how, precisely, paths are found, but this is an application-specific issue Depending on exactly how route-tracing gets done, one may or may not get information from “failed” routes, i.e., ones which didn’t succeed in getting from source to target. Trace-route sampling systematically distorts the degree distribution, making all kinds of graphs look like they have heavy-tailed distributions whether they do or not 7.3.3 Coping Strategies 7.3.3.1 Head in Sand That is, ignore distortions or biases due to sampling, and pretend that the graph we see is the whole graph. This is generally not a good idea. For induced-subgraph sampling, the mean degree is biased from the real degree by a calculable factor. Indeed, the sample values of motif counts for all motifs are also biased (again, in calculable ways). These would be pretty easy to compensate for. But degree distribution, for example, gets distorted in very complicated, hard-to-fix ways, even with induced-subgraph sampling. 7.3.3.2 Learn Sampling Theory Classical sampling theory is a theory of statistical inference in which probability assumptions are only made about the sampling process. The true population is regarded as unknown but fixed, and no stochastic assumptions are made about how it is generated. (One can always regard this as conditioning on the unknown population.) Because all the probability assumptions refer to the sampling design, and the validity of the inference depends only on whether the design has been accurately modeled, this is sometimes called design-based inference. Try to estimate the mean \\(\\mu\\) of some quantity \\(X_i\\) over a finite population of size \\(n\\), using a sample of units \\(S\\). A simple, classic solution is the Horvitz-Thompson estimator: \\[ \\hat \\mu_{HT} \\equiv \\frac{1}{n} \\sum_{i \\in S}\\frac{X_i}{\\pi_i} \\] 이때 \\(\\pi_i\\)는 unit \\(i\\)의 (assumed-known) 포함확률, 즉 unit \\(i\\)가 샘플에 포함될 확률. 포함 확률은 \\(\\pi = \\frac{|S|}{n}\\)로 모두 동일하다는 것을 notice. 즉 우리는 다시 sample mean \\(X\\)로 되돌아감. 이에 대한 직관은 곧 우리가 1개의 unit을 보았고 그 unit의 포함확률이 \\(\\pi_i\\)라면, 우리가 보지 못한 \\(\\frac{1}{\\pi_i}\\)개의 다른 것들이 있다는 것이 골자이다. 더 이론적으로 들어가자면 우리는 이것이 UE임을 보일 수 있다. indicator 변수 \\(Z_i = I(i \\in S), i \\in 1:n\\)을 도입하자. 이를 사용하여 \\(\\hat \\mu_{HT}\\)의 기댓값을 구하면 $$ \\[\\begin{alignat}{2} E \\left( \\hat \\mu_{HT} \\right) &amp;= E \\left(\\frac{1}{n} \\sum_{i \\in S} \\frac{X_i}{\\pi_i} \\right) &amp;&amp;= E \\left(\\frac{1}{n} \\sum_{i \\in 1:n} \\frac{X_i}{\\pi_i} Z_i \\right) \\\\ &amp;= \\frac{1}{n} \\sum_{i \\in 1:n} \\frac{X_i}{\\pi_i} E \\left( Z_i \\right) &amp;&amp;= \\frac{1}{n} \\sum_{i \\in 1:n} \\frac{X_i}{\\pi_i} P \\left( Z_i =1 \\right) \\\\ &amp;= \\frac{1}{n} \\sum_{i \\in 1:n} \\frac{X_i}{\\pi_i} \\pi_i &amp;&amp;= \\frac{1}{n} \\sum_{i \\in 1:n} {X_i} \\\\ &amp;= \\mu \\end{alignat}\\] $$ 또한 \\[ Var \\left ( \\hat \\mu_{HT} \\right )= \\frac{1}{n^2} \\sum_{i \\in 1:n} \\sum_{j \\in 1:n} X_i X_j \\left( \\frac{\\pi_{ij}}{\\pi_i \\pi_j} -1 \\right) \\] 이때 \\(\\pi_{ij}\\)는 joint 포함확률. 즉슨 \\(i,j\\)가 한번에 샘플에 들어있을 확률. (\\(\\pi_{ii} = \\pi_i\\)로 취급) 모든 \\(\\pi_i \\rightarrow 1\\)로 가게 된다면, \\(Var \\rightarrow 0\\). 이 Var 참값을 정확히 계산하는 건 불가능. 우리는 population 안의 모든 unknown units의 합을 구하는건 불가능하기 때문. 그러가 empirical 대체값은 주어져 있다. 이는 \\[ \\hat {Var} \\left ( \\hat \\mu_{HT} \\right) = \\frac{1}{n^2} \\sum_{i \\in 1:n} \\sum_{j \\in 1:n} X_i X_j \\left( \\frac{\\pi_{ij}}{\\pi_i \\pi_j} -1 \\right) \\] Strengths and Weaknesses The sampling-theory approach works well for stuff you can express as averages (or totals) of population quantities, and where you can work out inclusion probabilities from knowledge of the sampling design. Many network statistics can be expressed as averages (sometimes by defining the “unit” as, e.g., a dyad of nodes), but exact calculation of inclusion probabilities is harder. 7.3.3.3 Missing Data Tools Another approach is to treat the unobserved part of the network as missing data, and try to infer it. This can range from simple imputation strategies, to complex model-based strategies for inference, such as the EM algorithm. Successful imputation or EM is not design-based but model-based, and requires a model both of the network, and of the sampling process. It is very, very rare for anything to be “missing at random,” let alone “missing completely at random.” 7.3.3.4 Model the Effective Network A final strategy is to model the observed network. This means modeling both the observation/sampling process and the actual network, but combining them so that we get a family of probability distributions over the observed graph. That observed network is (or can be) still informative about the parameters of the underlying generative model. If that is all that’s of interest, it may be possible to short-circuit the use of EM or imputation, which are more about recovering the full graph 7.3.4 Big Data Solves Nothing Even when, as the promoters say, “n = all,” and the data are automatically recorded (voluntarily or involuntarily), almost all the network sampling issues we’ve gone over remain. After all, as the promoters do not say, you’re getting all of a biased convenience sample, not all of the truth. Three issues are particularly prominent for network 1. Entity Resolution 2. Diffusion 3. Performativity 7.3.4.1 Entity resolution Entity resolution, or record linkage, is a pervasive problem for data analysis. Generally speaking, it’s the problem of determining when multiple data points all record information about the same thing (or records which are apparently co-referent really are about different things). In networks, this is usually about determining when two (or more) apparent nodes really refer to the same underlying entity. 7.3.4.2 Diffusion Diffusion refers to the way that many of the automatically-recorded networks which provide us with our big data have themselves spread over other, older social networks. What we see when we look at the network of (say) Facebook ties is a combination of the pre-Facebook social network and the results of the diffusion process. Comparatively little has been done to understand the results. Even if the diffusion process treats all nodes homogeneously, the network-as-diffused can differ radically in its properties from the underlying network. 7.3.4.3 Performativity Performativity, the way theories can become (partially) self-fulfilling prophecies. The companies which run online social networks are all very invested in getting very big, very dense networks of users. This is why they all offer link suggestion or link recommendation services. The algorithms behind these recommendations implement theories about how social networks form, and what sort of link patterns they should have. To the extent that people follow these recommendations, then, the recorded network will seem to conform to the theory. "],["mathematical-models-for-network-graphs.html", "7.4 Mathematical Models for Network Graphs", " 7.4 Mathematical Models for Network Graphs By a model for a network graph we mean effectively a collection \\[ \\Big \\{ P_\\theta (G), \\; G \\in \\mathcal G \\; \\; : \\; \\; \\theta \\in \\Theta \\Big \\} \\] 이때 where \\(G\\) 는 가능한 그래프들의 collection (혹은 ‘ensemble’), \\(P_\\theta\\)는 \\(G\\)의 확률분포 (간단하게 쓰면 \\(\\cdot_\\theta\\) 생략하고 \\(P\\)만 씀), \\(\\theta\\)는 \\(\\Theta\\) 내부에서 가능한 값들 안에서 펼쳐져있는 (ranging over) 패러미터들(패러미터값들)의 벡터. Variety of Purposes • The testing for ‘significance’ of a pre-defined characteristic(s) in a given network graph • The study of proposed mechanisms for generating certain commonly observed properties in real-world networks (such as broad degree distributions or small-world effects), • The assessment of potential predictive factors of relational ties. The richness of network graph modeling derives largely from how we choose to specify P(·), with methods in the literature ranging from the simple to the complex. It is useful for our purposes to distinguish, broadly speaking, between models defined more from (i) a mathematical perspective, versus (ii) a statistical perspective. • Those of the former class tend to be simpler in nature and more amendable to mathematical analysis yet, at the same time, do not always necessarily lend themselves well to formal statistical techniques of model fitting and assessment. • On the other hand, those of the latter class typically are designed to be fit to data, but their mathematical analysis can be challenging in some cases. • Nonetheless, both classes of network graph models have their uses for analyzing network graph data. 7.4.1 Classical Random Graph Models "],["introduction-to-ergm.html", "7.5 Introduction to ERGM", " 7.5 Introduction to ERGM 7.5.1 Exponential Random Graph Models 7.5.1.1 What Is a Network? A representation of “relational data” in the form of a mathematical graph: A set of nodes along with a set of edges connecting some pairs of nodes. Adjacencey Matrix \\(X_{ij} = 1\\), if node \\(i,j\\) are connected. \\(0\\) o.w. 7.5.1.2 Exponential Random Graph Model (ERGMs) \\[ P_\\theta (X=x) \\frac{1}{\\kappa(\\theta)} \\exp \\Big( \\theta&#39; g(x) \\Big) \\] \\[X\\]: A random network written as an adjacency Matrix, \\(X_{ij}\\) is an indicator of an edge from node i to node j. \\(g(x)\\): A vector of network statistics of interest. \\(\\theta\\): The vector of parameters measuring the strengths of the effects of the corresponding entries in the vector \\(g(x)\\). \\(\\theta &gt;0\\): There exists a tendency to form \\(g(x)\\) when changing \\(X_{ij}\\) value from 0 to 1. \\(\\theta &gt;0\\): There exists a tendency not to form \\(g(x)\\) when changing \\(X_{ij}\\) value from 0 to 1. $(θ)%: A normalizing constan Explain parsimoniously the local selection forces that shapes the global structure of a network. A network dataset may be considered like the response in a regression model, where the predictors are things such as “propensity for Indiv. to form triangles of partnerships.” ⇒ ERGM help us quantify the strength of local transitivity. The information from the use of an ERGM can be used to understand a particular phenomenon or to simulate new random realizations to networks that retain the essential properties of the original 7.5.1.3 Network Statistics Basic Markov Network Statistics 7.5.1.3.1 Degree and Shared Partnership Distribution Degree: The number of edges the node has to other nodes. \\(D_k (x)\\): The number of nodes with degree \\(k\\). \\(\\sum D_k(x) n\\). Shared Partnership Distribution: - The number of unordered pairs \\((i, j)\\) for which \\(i\\) and \\(j\\) have exactly share \\(k\\) common neighbors and - \\(EP_k (x)\\): \\(X_{ij} = 1\\) - \\(NP_k (x)\\): \\(X_{ij} = 0\\) - \\(DP_k (x)\\): regardless of value \\(X_{ij}\\) - \\(\\sum EP_k(x) = S_1(x)\\) (edge counts) and \\(\\sum DP_k (x) = {n \\choose x}\\) (dyad counts). The geometrically weighted statistics for degree and shared partnership distribution are defined by $$ \\[\\begin{alignat}{2} u(x | \\tau) &amp;= e^\\tau \\sum_{i=1}^{n-2} \\left \\{ 1- \\left ( 1-\\frac{1}{e^\\tau} \\right)^i \\right \\} &amp;&amp;\\cdot D_i(x) \\\\ v(x | \\tau) &amp;= &quot; &amp;&amp;\\cdot EP_i(x) \\\\ w(x | \\tau) &amp;= &quot; &amp;&amp;\\cdot DP_i(x) \\end{alignat}\\] $$ where the additional parameter \\(\\tau\\) specifies the decreasing rate of the weights put on the higher order terms. 7.5.2 Difficulty in Parameter Estimation 7.5.2.1 Intractable Normalizing Constants The normalizing constant of ERGMs is \\(\\kappa (\\theta) \\sum_{\\text{all possible }x} \\exp \\Big \\{ \\theta&#39; g(\\mathbf x) \\Big \\}\\). Since there exist \\(2^{n \\choose x}\\) networks even in the undirected case, \\(\\kappa(\\theta)\\) is not directly computable. Due to the intractable normalizing constant, MCMC is key to both simulation and statistical inference. However, for the general MH algorithm, the acceptance probability involve an unknown normalizing constant ratio \\(\\frac{\\kappa(\\theta)}{\\kappa(\\theta&#39;)}\\), where \\(\\theta &#39;\\) denotes the proposed value, and it renders its failure. 7.5.2.2 Model Degeneracy For some configurations of \\(\\theta\\), the ERGMs produces networks that are either full (every tie exists) or empty (no ties exist) with probability close to one. Example: Basic Markovian Statistics When one edge is added to or removed from the network, the values of the basic Markovian statistics can change a lot while the values of other statistics do not change proportionally, so the dyadic dependence effects amplify quickly and the model tend to be degenerated. Current methods, MCMLE and stochastic approximation, sometimes produce degenerate estimates of θ if the starting value is in or close to a degeneracy region. ⇒ Local convergence property. "],["parameter-estimation-of-ergm.html", "7.6 Parameter Estimation of ERGM", " 7.6 Parameter Estimation of ERGM Current Methods for ERGM Approximation-based Algorithm: Maximize the likelihood function with MCMC samples. Maximum Pseudo-likelihood Estimation (MPLE). Markov Chain Monte Carlo Maximum Likelihood Estimation (MCMCMLE). Markov Chain Monte Carlo Stochastic Approximation (MCMCSA). Varying Truncation Stochastic Approximation MCMC Method with Trajectory Averaging (VTSAMCMC). Auxiliary Variable Markov Chain Monte Carlo (MCMC) Algorithm: Introduce auxiliary variables to cancel the normalizing constant ratio \\(\\frac{\\kappa(\\theta)} {\\kappa(\\theta&#39;)}\\) or to approximate the normalizing constant. Used for the Bayesian Inference. The Exchange Algorithm. Auxiliary Variable Metropolis-Hasting Algorithm (AVMH). Adaptive Exchange Monte Carlo Algorithm (AEXMC). 7.6.1 Approximation-based Algorithm 7.6.1.1 Maximum Pseudo Likelihood Estimation Approximate the likelihood function by a product of series of conditional likelihood functions by ignoring dependence within components of \\(X\\). The conditional and pseudo likelihood of the ERGMs is $$ \\[\\begin{align} \\logit \\left \\{ P_\\theta \\Big (X_{ij} = 1 \\Big | X_{ij}^c = x_{ij}^c \\right \\} &amp;= \\theta &#39; g(x_{ij}^c) \\\\ \\log PL(\\theta, x) &amp;= \\sum_{ij} \\theta &#39; g(x_{ij}^c) \\cdot x_{ij} - \\sum_{ij}\\log \\left \\{ 1+ \\theta &#39; g(x_{ij}^c) \\right \\} \\end{align}\\] $$ This method is the simplest one. Since this method totally ignores certain dependent structures within data, the performance is not generally satisfactory. 7.6.1.2 MCMC Stochastic Approximation The theory of exponential family implies that maximizing the ERGMs is equivalent to solving the system of equations Eθˆ{g(x)} = g(xobs) that is satisfied if and only if θˆ is the maximum likelihood estimator of θ and it requires 1 Independent network generation 2 Parameter estimation update with stochastic approximation This method is inefficient in generating independent network samples. The number of iteration steps for generating each sample xk+1 is in the order of 100n 2 where n is the number of nodes. 7.6.1.3 MCMC Stochastic Approximation The theory of exponential family implies that maximizing the ERGMs is equivalent to solving the system of equations Eθˆ{g(x)} = g(xobs) that is satisfied if and only if θˆ is the maximum likelihood estimator of θ and it requires 1 Independent network generation 2 Parameter estimation update with stochastic approximation This method is inefficient in generating independent network samples. The number of iteration steps for generating each sample xk+1 is in the order of 100n 2 where n is the number of nodes. 7.6.2 Auxiliary Variable MCMC-based Approaches 7.6.2.1 Exchange Algorithm Augment the distribution f(x|θ) by an auxiliary variable such that the normalizing constant ratio κ(θ)/κ(θ 0 ) can be canceled in simulations. 1 Propose a candidate point θ 0 from a proposal distribution denoted by q(θ 0 |θ, x). 2 Generate an auxiliary variable y ∼ f(y|θ 0 ) using a perfect sampler. 3 Accept θ 0 with probability min{1, r(θ, θ0 |x)}, where r(θ, θ0 |x) = π(θ 0 ) π(θ) · f(x|θ 0 ) f(x|θ) · f(y|θ) f(y|θ 0) · q(θ|θ 0 , x) q(θ 0 |θ, x) Although the exchange algorithms work well for some discrete models, such as the Ising and autologistic models, they cannot be applied to many other models for which perfect sampling is not available. We can generate auxiliary variable y via MCMC samples, but there exists theoretical flaws on convergence issues. If the mixing of MCMC sample is very slow, which is a general feature of ERGMs, θ 0 tends to accept with a high probability. 7.6.2.2 Monte Carlo MH Algorithm At each iteration, the MCMH algorithms replaces the unknown normalizing constant ratio κ(θ)/κ(θ 0 ) by a Monte Carlo estimates and importance sampling approach. A Monte Carlo version of the Metropolis-Hastings algorithm. Unlike the exchange algorithms, the MCMH algorithm avoids the requirement for perfect sampling, and thus can be applied to many statistical models for which perfect sampling is not possible. This algorithm also suffers from a theoretical flaw on convergence, i.e. the importance sampling estimator might fail to converge to the true ratio κ(θ)/κ(θ 0 ) with a finite number of samples. 7.6.3 Goodness-of-fit Plots Goodness-of-fit Plots for ERGMs 0 1 2 3 4 5 6 7 8 9 10 12 14 16 0.0 0.1 0.2 0.3 0.4 degree proportion of nodes 012345678 0.0 0.1 0.2 0.3 0.4 0.5 0.6 edge−wise shared partners proportion of edges 1 2 3 4 5 6 7 8 9 11 13 15 17 19 0.0 0.2 0.4 0.6 0.8 1.0 minimum geodesic distance proportion of dyads Goodness−of−fit diagnostics Figure: GOF plots for the high school student friendship network 7.6.4 Varying Trunction Stochastic Approximation MCMC The likelihood function of the ERGM is \\[ f(y | \\theta ) = \\frac{1}{\\kappa(\\theta )} \\exp \\Big \\{ \\theta&#39; S(y)\\Big \\} \\] where \\(\\theta = (\\theta_1 , \\cdots, \\theta_d)&#39;\\), \\(S(y) = \\Big( S_1 (y), \\cdots, S_d(y) \\Big)&#39;\\). Due to 2 issues, intractability of \\(\\kappa(θ)\\) and model degeneracy, it is difficult to estimate \\(\\theta\\) well. These problem can be solved by using the varying truncation stochastic approximation MCMC 7.6.4.1 Two Difficulties in Parameter Estimation Intractability of Normalizing constant \\(\\kappa(\\theta) = \\sum_{\\text{all possible }y} \\exp \\Big \\{ \\theta &#39; S(y)\\Big\\}\\). MPLE - Assume dyadic independence - Highly dependent on the observed network MCMLE Depend on the choice of \\(\\theta^{(0)}\\) Converge to a local optimal solution or fail to converge due to model degeneracy. 7.6.4.1.1 Stochastic Approximation Solve a system of equation of the form \\(h(\\theta) = 0\\). The classical SA algorithm is of the form $$ \\[\\begin{align} \\theta_{k+1} &amp;= \\theta_k + a_k Y_k \\\\ &amp;=\\theta_k + a_k \\Big \\{ h(\\theta_k) + \\omega_k \\Big \\}, &amp;&amp; k \\ge 0 \\end{align}\\] $$ \\(Y = h(\\theta) + \\omega\\) is noisy estimate. \\(\\omega\\) is mean-zero noise. Under appropriate conditions (on \\(a_k\\) , \\(h\\), \\(\\omgea_k\\) ), the algorithm indeed can be shown to converge to a solution 7.6.4.2 MCMC Stochastic Approximation Finding MLE of \\(\\theta\\) is equivalent to solving \\(E_\\theta \\Big \\{ S(Y) \\Big \\} = S(y_{obs})\\) in exponential families. Steps: 1. Independence network generation: Sample \\(y^{(k+1)}\\) from the \\(f(y | \\theta^{(k)}\\). - Start with a random graph in which each arc variable \\(Y_{ij}\\) is determined independently, with a probability 0.5 for the values 0 and 1 - Update the random graph using the Gibbs sampler or the MH algorithm Parameter estimate update with SA, \\[ \\theta^{(k+1)} = \\theta^{(k)} - a_k D^{-1} \\Big \\{ U(y_{k+1}, \\bar y_{k+1}) - S(y_{obs}) \\Big \\} \\] where $$ \\[\\begin{align} U(y_{k+1}, \\bar y_{k+1} ) &amp;= P(\\bar y_{k+1} | y_{k+1}) \\cdot S(\\bar y_{k+1}) + \\Big (1-P(\\bar y_{k+1} | y_{k+1}) \\Big ) \\cdot S( y_{k+1}) \\\\ \\bar y_{k+1} = 1-y_{k+1} \\end{align}\\] $$ Inefficiency in generating independent network samples: Order of \\(100n^2\\). 7.6.4.3 Model Degeneracy For some configurations of θ, the model lumps all or most of its probability mass on just one or a few possible graphs. Complete(fully connected) or empty(entirely unconnected) networks A solution to avoid this problem is to specify a model whose parameter space contains no or less degeneracy regions But, this is often more difficult than usual. 7.6.4.4 Varying Truncation SAMCMC for ERGMs 7.6.4.4.1 Setup (\\(C_1\\)) Set $$ \\[\\begin{align} a_k &amp;= C_a \\left( \\frac{k_0}{k_0 \\vee k)}\\right)^\\eta \\\\ b_k &amp;= C_b \\left( \\frac{k_0}{k_0 \\vee k)}\\right)^\\ksi \\end{align}\\] $$ for some constants \\(k_0&gt;1\\), \\(\\eta \\in (\\frac{1}{2},1)\\), \\(\\ksi \\in (\\frac{1}{2},\\eta)\\), \\(C_a &gt; 0\\), \\(C_b &gt;0\\). (\\(C_2\\)) \\(\\bigcup_{s \\ge 0} \\mathcal K_s = \\Theta\\), where \\(\\mathcal K_s \\subset \\text{int}(\\mathcal K_{s+1})\\) And also, \\(\\mathcal X\\): a space of social network \\(\\mathcal T\\): \\(\\mathcal X \\times \\Theta \\rightarrow \\mathcal X_0 \\times \\mathcal K_0\\) (reinitialization mechanism) \\(\\sigma_k\\): the number of reinitialization performed until iteration \\(k\\). (\\(\\sigma_0 = 0\\)) 7.6.4.4.2 Varying truncation SAMCMC algorithm for ERGMs Draw an auxiliary network \\(y_{k+1}\\) from the distribution \\(f(y | \\theta^{(k)}\\) using the Gibbs sampler iterating for \\(m\\) sweeps. Set \\(\\theta^{(k + \\frac{1}{2})} = \\theta^{(k)} + a_k \\Big \\{ S(y_{k+1}) - S(y_{obs}) \\Big \\}\\) Let $$ \\begin{cases} {k+1} = k, ; ; ( y{k+1}, ^{(k + {1})} ) = ( y{k+1}, ^{(k + )} ) &amp; | ^{(k + )} - ^{(k)} | b_k, ; ; ^{(k + )} K_{k} \\ {k+1} = k+1, ; ; ( y{k+1}, ^{(k + {1})} ) = ( y_{k}, ^{(k)} ) &amp; o.w. \\end{cases} $$ 7.6.4.4.3 Trajectory averaging estimator \\(\\theta\\) can be estimated by the trajectory averaging estimator \\(\\bar \\theta_n = \\frac{1}{n}\\sum_{k=1}^n \\theta^{(k)}\\) In practice, to reduce the variation of the estimate, we often use \\(\\bar \\theta (n_0 , n) = \\frac{1}{n-n_0}\\sum_{k=n_0+1}^n \\theta^{(k)}\\) to estimate \\(\\theta\\), where \\(n_0\\) denotes the number of burn-in iterations. Free parameters: \\(\\{a_k\\}\\), \\(\\{b_k\\}\\), \\(\\{\\mathcal K_s, \\; s \\le 0\\}\\), \\(m\\) \\(k_0 = 100\\), \\(\\eta = 0.65\\), \\(\\ksi = \\frac{0.5 + \\eta}{2}\\). \\(C_a\\), \\(C_b\\): adjusted for different examples choose \\(\\mathcal K_0\\) to be around MPLE. In this artical, we set \\(\\mathcal K_{s, 1} = \\Big [ -4(s+1), 4(s+1) \\Big]\\), \\(\\mathcal K_{s, 2} = \\cdots = \\mathcal K_{s, d} = \\Big [ -2(s+1), 2(s+1) \\Big]\\). \\(m=1\\). 7.6.4.4.4 Numerical Examples Methods: MCMLE, SAA (Stochastic Approximation Algorithm), Varying truncation SAMCMC SAMCMC: independent 5 runs(each of 200,000 iterations) (m=1, Ca = 0.01, Cb = 1000, η, ξ, κs are defalut) "],["ergm-for-dynamic-networks.html", "7.7 ERGM for Dynamic Networks", " 7.7 ERGM for Dynamic Networks However, a need for statistical models representing the evolving phenomena ⇒ ”Dynamic Models” with a temporal structure 7.7.1 Temporal ERGM ERGM → TERGM → STERGM One-step transition probability \\((t-1) → (t)\\) (Markov Assumption) \\[ P_{\\eta, g} \\Big ( Y^t = y^t \\Big | Y^{t-1} \\; \\; ; \\; \\; \\theta \\Big ) = \\frac{\\exp \\Big \\{ \\eta(\\theta) \\cdot g(y^t, y^{t-1})\\Big \\}}{c_{\\eta, h}(\\theta, y^{t-1})} \\] TERGM: Temporal ERGM ⇒ The network at time \\(t\\) is a single draw from an ERGM conditional on the network at time \\(t − 1\\) (and possibly time \\(t − 2\\)) Simplify a statistical model for evolving social networks is to make a Markov assumption on the network from one time step to the next. If \\(A^t\\) is the weight matrix representation of a single-relation social network at time \\(t\\), then we might make the assumption that \\(A^t\\) is independent of \\(A^1, \\cdots, A^{t-2}\\) if we given \\(A^{t-1}\\). \\[ P\\Big(A^2, A^3, \\cdots, A^t \\Big | A^1 \\Big ) = P\\Big(A^t \\Big | A^{t-1} \\Big ) P\\Big(A^{t-1} \\Big | A^{t-2} \\Big ) \\cdots P\\Big(A^2 \\Big | A^1 \\Big ) \\tag{Temporal ERGM} \\] Given our Markov assumption, one natural way to generalize ERGMs for evolving networks is to assume \\(A^t \\vert A^{t-1}\\) admits an ERGM representation. Specify a function \\(\\Psi : \\mathbb R_{n \\times n} \\times \\mathbb R_{n \\times n} \\rightarrow \\mathbb R^k\\), which can be understood as a temporal potential over cliques across two time-adjacent networks, and parameter vector \\(\\theta \\in \\mathbb R^k\\), such that the conditional pdf has the following form: \\[ P \\bigg( A^t \\Big | A^{t-1}, \\theta \\bigg) = \\frac{1}{\\kappa(\\theta, A^{t-1})} \\exp \\left\\{ \\theta&#39; \\Psi \\left ( A^t, A^{t-1} \\right ) \\right\\} \\] In particular, we will be especially interested in the special case of these models in which \\[ \\Psi \\left ( A^t, A^{t-1} \\right ) = \\sum_{ij}\\Psi_{ij} \\left ( A^t_{ij}, A^{t-1} \\right ) \\] This form of the temporal potential function represents situations where the conditional distribution of \\(A^t | A^{t-1}\\) factors over the entries \\(A^t_{ij}\\) of \\(A^t\\). 7.7.1.0.1 Network Statistics for Temporal ERGM Density: The number of ties in the network as a whole. Stability: The tendency of a link that does exist at time \\(t − 1\\) to continue existing at time \\(t\\). Reciprocity: The tendency of a link from \\(i\\) to \\(j\\) to result in a link from \\(j\\) to \\(i\\) at the next time step. Transitivity: The tendency of a tie from \\(i\\) to \\(j\\) and from \\(j\\) to \\(k\\) to result in a tie from \\(i\\) to \\(k\\) at the next time step. 7.7.1.1 Estimation Use the sequence of observed networks, \\(N^1 , N^2 , \\cdots, N^T\\), to find an estimator \\(\\hat \\theta\\) that is close to the actual parameter value \\(\\theta\\). The normalizing constant is computationally intractable, often making explicit solutions of MLE difficult. Use MCMC stochastic approximation to estimate parameters. Let where expectations are taken over the random variable \\(N^t\\), the network at time \\(t\\). Note that The expectations can be approximated by Gibbs sampling from the conditional distributions. Perform an unconstrained optimization procedure akin to Newton’s method: Approximate the expectations, update parameter values in the direction that increases the likelihood, repeat until convergence. 7.7.1.2 Degeneracy of Temporal ERGMs In the simple case where the transition distribution factors over the edges, it turns out these models avoid such problems entirely. The intuitive reason for this is that, since the edges of \\(A^t\\) are conditionally independent given \\(A^{t−1}\\), as long as the individual conditional distributions for the \\(A^t_{ij}\\) given \\(A^{t−1}\\) are not too extreme, the conditional entropy of \\(A^t\\) given \\(A^{t−1}\\) should be large, and thus the entropy of \\(A^t\\) itself must be large. Of course, this argument only works if the dependence of \\(A^t\\) on \\(A^{t−1}\\) is not too strong, and the strength of this dependence can be controlled by the magnitudes of the parameters. Calculate it for equivalence classes of graphs which can be analytically shown to have identical probability values, and weight each class according to its size in the entropy calculation. For the first plot, since the conditional probability of \\(A^2\\) given \\(A^1\\) is only a function of how many edges are present in \\(A^2\\) and how many \\(ij\\) values have \\(A^2_{ij} = A^1_{ij}\\), and since the edges of \\(A^1\\) are exchangeable, we can write the marginal distribution of \\(A^2\\) purely in terms of the number of edges. Thus we need only calculate \\(n(n − 1)\\) probability values, and the entropy is a weighted sum, where the weights are combinatorial quantities reflecting the number of graphs with that many edges. 7.7.1.3 Assessing Statistic Importance and Quality of Fit Three Parameter Model Description of Network Statistics Reverse-Transitivity: Co-Supported: Co-Supporting: Popularity Generosity 7.7.2 Separable Temporal ERGM STERGM = A Separable Model for Dynamic Network Dynamic: social networks that evolve over time Time(discrete): \\(\\cdots (t-2) → (t-1) → (t) → \\cdots\\) Shows longitudinal properties based on the ERGM Separable formation : new ties duration : lasting ties Temporal ERGM Interpretation However, caution must be used in interpreting their parameters. Property1: incidence of ties (the rate at which new ties are formed) Property2: duration of ties (how long they tend to last once they do) Network statstic (ex) edge count \\(g(y^t , y^{t-1}) = | y^t |\\) coefficient on \\(g\\) \\(prop\\) possibility of a network with many ties But, this term simultaneously increases the weight of preservation of extant ties (fewer dissolved) ⇒ Both incidence and duration ↑ The two-sided nature of these effects tends to muddle parameter interpretation. ⇒ STERGM which separates the incidence and duration of ties and allows for the separate interpretation. : incidence/tie formation \\(y^+ = y^{t-1} \\cup y^t\\) – : duration/tie dissolution \\(y^- = y^{t-1} \\cap y^t \\Rightarrow y^t = y^- \\cup (y^+ \\setminus y^{t-1})\\) 7.7.2.1 Application Study 7.7.2.2 Conclusion "],["survival-analysis.html", "Chapter 8 Survival Analysis ", " Chapter 8 Survival Analysis "],["introduction-3.html", "8.1 Introduction", " 8.1 Introduction SA의 결과물은 보통 time-to-event, 즉슨 대부분의 경우에 nonnegative이며, 이는 곧 time domain을 한정함. time-to-event의 distribution은 보통 skewed. Survival data은 자주 right censored. 조사 대상자들은 조사 기간중에만 생존했음을 알며, 조사 기간 넘어서 죽으면 해당 시간이 정확히 기록되지 않음. tail probability. 충분한 후속연구 후에는, tail of survival curve에 해당하는 subject들이 보통 되게 적음. estimation of the tail of the survival curve can be quite difficult. tail에서 survival density는 엄청 적어짐. 따라서 총 표본 수가 많이 확보되어 있지 않으면 tail에 해당하는 분석결과는 확보하기가 어렵다. 모든 연구의 시간은 finite이므로 모든 subjects들에게서 발생한 event of interest 중 일부는 육안으로 관찰 못 할수도 있다. 장기적으로 발생은 했는데, 그게 우리 손닿는 곳에서 터지지 않았음. 일반적으로 관측안된 failure time 들이 포함되어 있으면 기존 통계 테크닉은 사용할 수 없음. failure time 이 관측되지 않은 subject들은 censored 되었다고 표현. censored observations를 포함한 자료에서 정보를 뽑아내는 것이 SA의 estimation methods의 목적. 8.1.0.1 Censoring Sources Adminisitrative censoring event 발생 전에 연구 종료 often independent of failure time Loss to follow-up subject들이 더이상 트랙 불과, 관찰 하에 있지 않음 (후속연구 개시했는데 예전에 살던 사람이 동네 떠났음) censoring may be related (indirectly) to the failure time withdrawl from study 너무 아프거나 증상이 낫던가 해서 연구에서 이탈 dependent censoring (informative drop-out), censoring이 failure time에 연관되어 있다는 점이 고민해야할 거리가 된다. 8.1.0.1.0.0.0.0.1 임시방편 censor된 시간을 failure time으로 인식. \\(\\bar X \\le E(X)\\) (underestimate). censor 관측치를 전부 삭제. loss of infomration. 8.1.0.1.0.1 notation \\(T_i\\): potential failure time for the i-th subject \\(C_i\\): potential censoring time for the i-th subject \\(X_i = \\min(T_i , C_i )\\) observed time \\(\\delta_i = \\begin{cases} 1, &amp; T_i \\le C_i &amp; \\text{(uncensored)} \\\\ 0, &amp; T_i &gt; C_i &amp; \\text{(censored)} \\end{cases}\\) 8.1.0.2 Right Censoring (most of the course) Fail이 확실하게 터진 경우에만 fail, 이외의 경우에는 censor. 조사기간 종료까지 발병하지 않았거나, 이외의 이유로 종료 이전에 연구 이탈하면 양쪽 모두 censored. 8.1.0.2.0.1 Type of Data to be analyzed in survival analysis Type Ⅰ Censoring: 특정 시점이 왔을 때 연구 종료. ex) 쥐한테 특정 영양소 먹이고 언제까지 생존하는지 Progressive Type Ⅰ Censoring: 대상들이 다른, 고정된 sacrifice time 보유 ex) 도즈 레벨 4개로 나누고 각 그룹에 다른 sacrifice 기간 적용, 비용 효율화 Generalized Type Ⅰ Censoring: subject들이 각각 다른 시기에 연구에 참여개시하고 정해진 시간에 연구 종료됨. subject가 참여할 때 censoring time 다 알려짐. Type Ⅱ Censoring: reliabilty 분석에서 흔함. 특정 횟수 failure 발생시 연구 종료. ※ Right Censoring: 개인의 정확한 survival time은 follow-up period의 우측에서는 incomplete해짐. Random Censoring: Censoring times are random. ※ let’s focus on right censoring. Suppose \\(T_1 , \\cdots, T_n \\sim f(t)\\) and \\(C_1 , \\cdots, C_n \\sim g(c)\\). Then, we observe \\(X_i = \\min(T_i , C_i )\\) for \\(i = 1, \\cdots, n\\). In type Ⅰ censoring, \\(C_i\\) is fixed (at \\(C_r\\) or \\(C_{r_i}\\)). In random censoring, \\(C_i\\) is random. 8.1.0.3 Left Censoring less common in practice $$ \\[\\begin{align} \\lambda(t) S(t)&amp;= f(t) \\\\ \\lambda(t) &amp;= \\dfrac{f(t)}{S(t)} \\\\ \\lambda(t) &amp;= \\dfrac{f(t)}{} \\dfrac{d}{dS(t)}\\log S(t) \\\\ \\end{align}\\] $$ $$ \\[\\begin{align} \\lambda(t) &amp;= - \\dfrac{d}{dt} \\log S(t) \\\\ \\lambda(t) &amp;= - \\dfrac {dS(t)}{dt} \\dfrac{d}{dS(t)} \\log S(t) \\\\ \\lambda(t) &amp;= - \\dfrac {d[1-F(t)]}{dt} \\dfrac{1}{S(t)} \\\\ \\lambda(t) &amp;= - (-f(t)) \\dfrac{1}{S(t)} \\\\ S(t)\\lambda(t) &amp;= f(t) \\end{align}\\] $$ \\[ A = A&#39;\\; \\; \\; \\Longrightarrow \\; \\; \\; \\exists \\text{basis for } C(A):\\text{constisting of evec of nonzero ev&#39;s.} \\] linear transformation, span, trace, nonsingular, null space \\[ tr(ABC) = tr(BCA)=tr(CAB) \\] \\[ r(A_{n \\times n})=r, \\; \\; \\; r[\\mathcal{N}(A)] = n-r \\] \\(\\lambda\\) is ev of \\(A\\), \\(v\\) is evec of \\(A\\). $$ \\[\\begin{alignat}{3} &amp;\\forall \\lambda_i \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; \\forall v_i : &amp;&amp; span(v_i) \\subset \\mathcal{C}(A) \\\\ &amp;A = A&#39;, \\; \\lambda_i \\not = \\lambda_j &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; v_i \\perp v_j, &amp;&amp; &amp;&amp;span(v_i, v_j) \\subset \\mathcal{C}(A) \\\\ &amp;\\exists A^{-1} &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; \\prod \\lambda\\not = 0 &amp;&amp; &amp;&amp; \\\\ &amp;A = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;\\exists \\text{basis for } \\mathcal{C}(A) \\text{ consists of } v_i \\text{ of } \\lambda_i \\not = 0 \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\prod \\lambda \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; \\mathcal C (A)=\\mathbb R^n, &amp;&amp; &amp;&amp;span( v) = \\mathbb{R}^n \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\forall \\lambda_i \\not = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;span(\\forall v_i) = \\mathcal{C}(A) \\subset \\mathbb{R}^n \\\\ &amp;A_{n \\times n} = A&#39;, \\; \\forall \\lambda_i = 0 &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;span(\\forall v_i) = \\mathcal{N}(A) \\\\ &amp;A = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp;\\mathcal{N}(A) = \\mathcal C (A)^\\perp \\\\ &amp;A_{n \\times n} = A&#39; &amp;&amp;\\; \\; \\; \\Longrightarrow \\; \\; \\; &amp;&amp; &amp;&amp; &amp;&amp; \\exists v_i : span(v_i) = \\mathcal C (A), \\; v_i \\perp v_j \\; \\; \\tiny {\\bigoplus} \\; \\; \\normalsize \\exists A^{-1} : \\mathcal C(A) = \\mathbb{R}^n \\; \\; \\tiny {\\bigoplus} \\; \\; \\normalsize \\text{if normalized, orthonormal} \\end{alignat}\\] $$ "],["section.html", "8.2 ", " 8.2 "],["section-1.html", "8.3 ", " 8.3 "],["section-2.html", "8.4 ", " 8.4 "],["cox-regression.html", "8.5 Cox Regression", " 8.5 Cox Regression 8.5.0.1 Proportional Hazards Model Proposed by Cox (1972, JRSS-B), primarily to model the relationship between hazard function and covariates. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science. Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc. ※ Data Structure Observed data: \\(\\Big \\{ X_i = T_i \\wedge C_i, \\; \\; \\; \\Delta_i = I(T_i &lt; C_i), \\; \\;\\; \\mathbf Z_i (\\cdot) \\Big \\} \\overset {iid} \\sim\\) 추가로 \\(N_i = I(X_i \\le t , \\; \\Delta_i = 1)\\), \\(Z_i(t)\\) = covariate vector (possibly time-dependent). 8.5.0.2 Cox PH Model \\[ \\lambda_i (t) = \\lambda (t \\vert Z_i ) = \\lambda_0 (t) \\exp (\\beta&#39; Z_i) \\tag{Cox Model} \\] semiparametric model: \\(\\exp(\\beta &#39; Z_i)\\), parametric assumption on covariate effects multiplicative model \\(\\beta\\) : \\(p \\times 1\\) vector, \\(p &lt; \\infty\\) \\(\\lambda_0(t)\\), nonparametric; is \\(\\infty\\) dimensional shape of hazard function is unspecified Due to nonparametric component, standard maximum likelihood theory does not apply Let \\(Z_{ij}\\) be the \\(j\\)-th element of \\(Z_i\\) - \\(\\beta_j\\) = difference in log hazards - \\(\\exp(\\beta_j)\\) = ratio of hazards; assumed constant for all \\(t\\) \\(\\lambda_0(t)\\): baseline hazard; common to all subjects, \\(\\lambda_0(t) = \\lambda_i(t \\big | Z_i = \\mathbf 0)\\) The hazard ratio, \\(\\exp(\\beta_j)\\), is sometimes referred to as a relative risk - risk = probability, not a rate - hazard is a rate, not a probability - in ratio of hazards, time dimension cancels out Direction of effect: $$ \\[\\begin{align} \\beta_j &gt; 0: &amp;&amp;\\uparrow\\lambda_i &amp;&amp;\\downarrow S_i(t) \\\\ \\beta_j &lt; 0: &amp;&amp;\\downarrow\\lambda_i &amp;&amp;\\uparrow S_i(t) \\end{align}\\] $$ Magnitude of effect is easy to interpret w.r.t. \\(\\lambda_i(t)\\) Cumulative hazard function: $$ \\[\\begin{align} \\lambda_i (t) &amp;= \\lambda_0(t) \\exp(\\beta Z_i) \\\\ \\Lambda_i (t) &amp;= \\int_0^t \\lambda_0(s) \\exp(\\beta Z_i) ds \\\\ &amp;= \\Lambda_0(t) \\exp(\\beta Z_i) \\end{align}\\] $$ Survival function: $$ \\[\\begin{align} S_i (t) &amp;= \\exp \\Big \\{ -\\Lambda_i (t) \\Big\\} \\\\ &amp;= \\exp \\Big \\{ -\\Lambda_0 (t) \\exp(\\beta &#39; Z_i)\\Big\\} \\\\ &amp;= S_0(t)^{\\exp \\Big \\{ \\beta&#39;Z_i \\Big\\}} \\end{align}\\] $$ By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard: - ex) randomized trial: treatment (\\(Z_i=1\\)) versus placebo (\\(Z_i=0\\)); \\(\\hat \\beta = 0.405\\) (\\(\\exp(\\hat \\beta)=1.5\\)) - \\(\\lambda_i(t)\\) for treated patients is 50% more of that of the controls. - irrespective of \\(\\lambda_0(t)\\) Nevertheless, \\(\\Lambda_0(t)\\) is required in order to determine \\(Z_i\\)’s effect on \\(S_i(t)\\), e.g., $$ \\[\\begin{align} S(t \\Big | Z_i = 0) = 0.95 &amp;&amp; vs. &amp;&amp; S(t \\Big | Z_i = 1) = 0.93 \\\\ S(t \\Big | Z_i = 0) = 0.70 &amp;&amp; vs. &amp;&amp; S(t \\Big | Z_i = 1) = 0.59 \\end{align}\\] $$ 8.5.0.2.0.1 Cox Model: Independent Censoring Independent censoring assumption is less stringent than in nonparametric estimation. Assumption is often written as \\(T_i \\perp C_i \\Big \\vert Z_i\\): $$ \\[\\begin{alignat}{2} &amp;\\lim_{\\delta \\rightarrow 0} \\frac{1}{\\delta} P(t \\le T_i &lt; t+ \\delta \\Big | T_i \\ge t , \\; C_i \\ge t , &amp;&amp;\\; Z_i) \\\\ = &amp;\\lim_{\\delta \\rightarrow 0} \\frac{1}{\\delta} P(t \\le T_i &lt; t+ \\delta \\Big | T_i \\ge t , &amp;&amp;\\; Z_i) \\end{alignat}\\] $$ ※ Note: \\(C_i\\) is allowed to depend on \\(Z_i\\) 8.5.0.3 Semiparametric PH Model: General General expression for multiplicative proportional hazards model: \\[ \\lambda_i (t) = \\lambda_0 (t) g(\\beta &#39; Z_i ) \\] \\(g(x)\\) is link function, specified. \\(\\forall x: g(x) \\ge 0\\), \\(\\exists g&#39;&#39;(x)\\), and in special case, \\(g(x) = \\exp(x)\\). Other choices for link function (e.g., Self &amp; Prentice, 1983): \\(g(x) = 1+x = (1+x)^{-1} = \\log(1+x)\\) ※ Notes: - not all choices of \\(g(x)\\) lead to clear interpretation of \\(\\beta_j\\) - certain choices of \\(g(x)\\) lead to numerical issues; e.g., likelihood is flat; local maxima, etc. - \\(g(x) \\not = exp(x)\\) has received little attention in the literature 8.5.0.4 Multiplicative Model Cox model is a multiplicative model, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard. Additive models also been proposed \\[ \\] 8.5.0.5 Proportional Hazards Regression and Multiplicative Intensity Model Recall Counting process: martingale representation $$ \\[\\begin{align} N(t) &amp;= I(X\\le t , \\; \\Delta = 1) \\\\ Y(t) &amp;= I(X \\ge t) \\\\ M(t) &amp;= N(t) - \\int_0^t Y(u)\\lambda_0(u) e^{\\beta &#39; Z } du \\tag{1} \\\\ \\mathcal F_t &amp;= \\sigma \\Big \\{ N(u) , Y(u+) , Z: \\; \\; 0 \\le u \\le t \\Big \\} \\end{align}\\] $$ intensity \\(l(u) = Y(u)\\lambda_0(u) e^{\\beta &#39; Z }\\), therefore integrated form is cumulative intensity \\(A(t)\\). Multiplicative Intensity Model: \\[ l(t) = Y(t)\\lambda_0(t) e^{\\beta &#39; Z(t) } \\] Counting process: \\(N(t)\\) = Number of events of a specified type that have occurred by time \\(t\\) \\(N(t)\\) may take more than one jump multiple infections, repeated breakdowns, hospital admissions \\(EN(t) &lt; \\infty\\) At-risk process: \\(Y(t)\\), left-continuous process, \\(1\\) if failure can be observed at time \\(t\\), otherwise \\(0\\). \\(Y(t)\\) can be used to represent situation in which a subject enter and exit risk sets several times \\(Y(t)\\) may be \\(1\\) even after an observed failure Covariate process: \\(Z(t)\\) = (bounded) predictable process time-dependent treatment, risk factors model checking and relaxing PH assumption Baseline hazard function: \\(\\lambda_0(\\cdot)\\) = an arbitrary deterministic function Filtration: \\(\\mathcal F_t = \\sigma \\Big \\{ N(u) , Y(u+) , Z(u): \\; \\; 0 \\le u \\le t \\Big \\}\\) Martingale: \\(M(t) = N(t) - \\int_0^t l(u) du\\) Intensity function: $ E { dN(t) | F_{t-} } = l(t) dt$ Data: \\(n\\) independent observations on $ { N(), ; Y(), ; Z() }$ 8.5.0.6 Likelihood; conditional, marginal and partial likelihoods \\(X =\\) vector of observations; \\(f_X(x, \\theta) =\\) density of \\(X\\) \\(\\theta =\\) vector parameter; \\(\\theta = (\\beta &#39; , \\phi&#39;)&#39;\\) \\(\\beta =\\) parameter of interest; \\(\\phi =\\) nuisance parameter likelihood: \\(f_X(x, \\theta) = f_{W|V} (w \\Big | v, \\theta )f_V (v, \\theta)\\) \\(X = (V&#39;, W&#39;)&#39;\\) infinite-dimensional \\(\\phi\\) \\(f_{W|V} (w \\Big | v, \\theta )\\) does not involve \\(\\phi\\) \\(\\Rightarrow\\) use \\(f_{W|V} (w \\Big | v, \\beta )\\) (conditional likelihood) \\(f_V (v, \\theta)\\) does not involve \\(\\phi\\) \\(\\Rightarrow\\) use \\(f_V (v, \\beta)\\) (marginal likelihood) \\[ X = (V_1 , W_1 , \\cdots, V_K , W_K) \\] $$ \\[\\begin{align} f_X(x, \\theta) &amp;= f_{V_1 , W_1 , \\cdots, V_K , W_K} (v_1 , w_1 , \\cdots, v_K , w_K\\; ;\\; \\theta) \\\\ &amp;= f_{V_1}(v_1 \\; ; \\; \\theta) f_{W_1 | V_1}(w_1 | v_1\\; ; \\; \\theta) f_{V_2 | V_1, W_1}(v_2 | v_1, w_1\\; ; \\; \\theta) \\times \\cdots \\\\ &amp;= \\left \\{ \\prod_{i=1}^K f_{W_i | Q_i } (w_i \\Big | q_i \\; ; \\theta) \\right \\} \\left \\{ \\prod_{i=1}^K f_{V_i | P_i } (v_i \\Big | p_i \\; ; \\theta) \\right \\} \\end{align}\\] $$ $$ \\[\\begin{align} P_1 = \\phi,&amp; &amp;&amp; P_i =(V_1 , W_1 , \\cdots, V_{i-1} , W_{i-1}) \\\\ Q_1 = V1,&amp; &amp;&amp; Q_i =(V_1 , W_1 , \\cdots , W_{i-1}, V_i) \\end{align}\\] $$ ${i=1}^K f{W_i | Q_i } (w_i | q_i ; ; ) $ is free of \\(\\phi\\) \\(\\Rightarrow\\) use $ {i=1}^K f{W_i | Q_i } (w_i | q_i ; ; ) $ (partial likelihood) 8.5.0.6.0.1 Partial &amp; Marginal Likelihoods Focus on Proportional Hazards Model: i.e., \\((X_i, \\; \\delta_i, \\; Z_i), \\; i = 1, \\cdots, n\\) (\\(n\\) independent triplets) $$ \\[\\begin{align} &amp;\\lambda(t \\Big | Z ) = \\lambda_0 (t) e^{\\beta &#39; Z} &amp;&amp;S(t \\Big | Z) = \\Big \\{ S_0(t) \\Big \\}^{e^{\\beta &#39; Z}} \\tag{1} \\end{align}\\] $$ 위에서 $ _0 (t)$는 unspecified. Partial Likelihood: assume no ties, absolutely continuous failure distribution Suppose there are L observed failures at \\(\\tau_1 &lt; \\cdots &lt; \\tau_L\\) (set \\(\\tau_0 \\equiv 0\\) &amp; \\(\\tau_{L+1} \\equiv \\infty\\)) 16.png Let (i) be the label for individual failing at \\(\\tau_i\\) (set \\((L + 1) \\equiv n + 1\\)). Note \\(t_{(i)} = \\tau_i\\) Covariates for \\(L\\) failures: \\((Z_{(1)}, \\cdots, Z_{(L)})\\). (Hereafter, condition on $ { Z_i : i = 1, , n }$) Censorship times in \\([\\tau_i; \\tau_{i+1})\\): \\((\\tau_{i1}, \\cdots, \\tau_{i, m_i})\\) with covariates \\((Z_{(i,1)}, \\cdots, Z_{(i,m_i)})\\), i.e., \\((i, j)\\) is label for item censored at \\(\\tau_{ij}\\) 17.png The data can be divided into sets \\[ (V_1 , W_1, \\cdots, V_{L+1} , W_{L+1}) \\] where, for \\(i = 1, \\cdots, L, L+1\\), $$ \\[\\begin{align} V_i &amp;= \\Big \\{ \\tau_i , \\tau_{i-1, j} \\; \\; ; \\; \\; (i-1, j):j = 1, \\cdots, m_{i-1} \\Big \\} \\\\ and \\; \\; \\; \\;W_i &amp;= \\Big \\{ (i) \\Big \\} \\end{align}\\] $$ 18.png 19.png GOAL: Build a likelihood on a subset of the full data set - carrying most of the information about \\(\\beta\\) - carrying no information on nuisance parameters \\(\\Big \\{ \\lambda_0 (t) : t \\ge 0 \\Big \\}\\) PROPOSAL: Generate likelihood of \\(\\Big \\{ W_1, \\cdots, W_L \\Big \\}\\) JUSTIFICATION, WHY?: - Timing of events \\(\\Big \\{ \\tau_1 , \\cdots, \\tau_L \\Big \\}\\) can be explained by \\(\\lambda_0(\\cdot)\\). - Censoring times and labels can be ignored if we assume non-informative censorship (independent censoring). So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data. If \\(Q_i \\equiv (V_1, W_1 , \\cdots, V_{i-1}, W_{i-1}, V_i)\\) and \\(\\mathcal F_{\\tau_i} \\equiv (Q_i, Z)\\), the partial likelihood is \\(\\prod_{i=1}^L P \\Big ( W_i = (i) \\Big | \\mathcal F_{\\tau_i} \\Big)\\), i.e., given the risk set at \\(\\tau_i\\), and given event occurs at \\(\\tau_i\\). Denote \\(R_i \\equiv \\Big \\{ j : X_j \\ge \\tau_i \\Big \\}\\) as risk set at \\(\\tau_i\\). Then, by the assumption of independent censoring, $$ \\[\\begin{align} P \\Big ( W_i = (i) \\Big | \\mathcal F_{\\tau_i} \\Big) &amp;= \\frac{ P \\Bigg \\{ t_{(i)} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\cdot \\prod\\limits_{j \\in R_i - (i)} P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} }{ \\sum\\limits_{l \\in R_i} \\left[ P \\Bigg \\{ t_{l} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\cdot \\prod\\limits_{j \\in R_i - l} P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} \\right] } \\tag{a} \\\\ \\\\ \\\\ &amp;= \\frac{ d\\Lambda \\Big( \\tau_i \\Big | Z_{(i)} \\Big) \\prod\\limits_{j \\in R_i - (i)} \\bigg \\{ 1 - d\\Lambda \\Big( \\tau_i \\Big | Z_{j} \\Big) \\bigg \\} }{ \\sum\\limits_{l \\in R_i} \\left [ d\\Lambda \\Big( \\tau_i \\Big | Z_{l} \\Big) \\prod\\limits_{j \\in R_i - l} \\bigg \\{ 1 - d\\Lambda \\Big( \\tau_i \\Big | Z_{j} \\Big) \\bigg \\} \\right ] } \\; \\; \\; \\div \\; \\; \\; \\frac{d\\tau_i}{d\\tau_i} \\tag{2} \\\\ \\\\ \\\\ &amp;= \\frac{\\lambda\\Big(\\tau_i \\Big | Z_{(i)} \\Big)}{ \\frac{P \\Big\\{T\\in [t, t+dt) \\Big | T \\ge t , Z \\Big\\}}{dt}= \\sum\\limits_{l\\in R_i} \\left[ \\lambda\\Big(\\tau_i \\Big | Z_{l} \\Big) \\right]} \\; \\; \\; \\overset {(1)}{=} \\; \\; \\; \\frac{\\exp(\\beta &#39; Z_{(i)})}{\\sum\\limits_{l\\in R_i} \\exp(\\beta &#39; Z_{l})} \\end{align}\\] $$ - at (a), \\(P \\Bigg \\{ t_{j} \\not \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\} = 1 - P \\Bigg \\{ t_{j} \\in \\big[\\tau_i , \\tau_i + d\\tau \\big) \\Bigg |\\mathcal F_{\\tau_i} \\Bigg \\}\\) - at (2), $ d( i | Z{j} ) = 0$ Thus, the Partial Likelihood is \\[ \\prod^L_{i=1}\\frac{\\exp(\\beta &#39; Z_{(i)})}{\\sum\\limits_{l\\in R_i} \\exp(\\beta &#39; Z_{l})} = L(\\beta)\\tag{3} \\] Note: unspecified \\(\\lambda_0(\\cdot)\\) + noninformative censoring \\(\\Rightarrow\\) \\(\\prod\\limits_{i=1}^L f_{V_i \\big | P_i} (v_i \\Big | p_i ; \\theta)\\) contains little or no information about \\(\\beta\\). Counting process notation: $$ \\[\\begin{align} L(\\beta) = \\prod^n_{i=1}\\prod_{t\\ge0} \\left \\{ \\frac{\\exp(\\beta &#39; Z_{i})}{\\sum\\limits_{j=1}^n Y_j(t) \\exp(\\beta &#39; Z_{j})} \\right\\}^{dN_i(t)} , &amp;&amp; dN_i(t) = \\begin{cases} 1 &amp; N_i(t) - N_i {(t-)} =1\\\\0 &amp; o.w.\\end{cases} \\end{align}\\] $$ Maximum partial likelihood estimator (MPLE): \\(L( \\hat \\beta) = \\max_\\beta L(\\beta)\\) (using Newton-Raphson (NR) algorithm) Specifically, the log partial likelihood is then \\[ l(\\beta) = \\sum_{i=1}^n \\int_0^\\infty \\left[ Y_i (t) Z_i \\beta - \\log\\left( \\sum_{j=1}^n Y_j(t) \\exp(\\beta &#39; Z_j ) \\right) \\right]dN_i(t) \\] The score vector, \\(U(\\beta)\\), can be obtained by differentiating \\(l(\\beta)\\) w.r.t. \\(\\beta\\): $$ \\[\\begin{alignat}{2} U(\\beta) &amp;= \\sum_{i=1}^n \\int_0^\\infty \\Big \\{ Z_i - \\bar Z(\\beta, t) \\Big \\}&amp;&amp;dN_i (t) \\\\ &amp;= \\sum_{i=1}^n \\int_0^\\infty \\left \\{ Z_i - \\frac{\\sum_{i=1}^n Y_i (t) Z_i \\exp(\\beta &#39; Z_i)}{\\sum_{i=1}^n Y_i (t) \\exp(\\beta &#39; Z_i)} \\right \\}&amp;&amp;dN_i (t) \\end{alignat}\\] $$ where \\(\\bar Z(\\beta, t)\\) is a weighted mean of \\(Z\\) over those observations still at risk at time \\(t\\). The information matrix, \\(\\mathcal I(\\beta)\\), is the negative second derivative where $$ \\[\\begin{align} \\mathcal I(\\beta) &amp;= \\sum\\limits_{i=1}^n \\int_0^\\infty V(\\beta, t) dN_i(s) \\\\ \\\\ V(\\beta, t) &amp;= \\frac{\\sum\\limits_{i=1}^n Y_i(t) \\exp(\\beta &#39; Z_i ) \\Big \\{ Z_i - \\hat Z (\\beta, t)\\Big\\}&#39;\\Big \\{ Z_i - \\hat Z (\\beta, t)\\Big\\}}{\\sum\\limits_{i=1}^n Y_i(t) \\exp(\\beta &#39; Z_i )} \\end{align}\\] $$ and \\(V(\\beta, t)\\) is the weighted variance of \\(Z\\) at time \\(t\\). Then, the MPLE, \\(\\hat \\beta\\), is found by solving the partial likelihood equation: \\(U(\\hat \\beta) = 0\\). Under some regularity conditions, \\(\\hat \\beta\\) is consistent and asymptotically normally distributed with mean \\(\\beta\\) and variance \\(E \\Big \\{ \\mathcal I(\\beta) \\Big\\}^{-1}\\) (will be shown later.) The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value \\(\\hat \\beta^{(0)}\\)). \\[ \\hat\\beta^{(n+1)} = \\hat\\beta^{(n)} + \\mathcal I ^{-1} \\Big( \\hat \\beta^{(n)}\\Big) \\cdot U \\Big( \\hat \\beta^{(n)}\\Big) \\] ※ Note: 1. (incredibly) Robust algorithm! 2. \\(\\hat \\beta^{(0)} = 0\\) usually works. 8.5.0.7 Cox Proportional Hazards Model Cox model: $$ \\[\\begin{align} \\lambda_i(t) = \\lambda(t \\Big | Z_i ) &amp;= \\lambda_0 (t) \\exp(\\beta &#39; Z_i) \\\\ &amp;= \\lambda_0(t) \\exp(\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik}) \\\\ &amp;\\Updownarrow \\\\ \\log \\lambda(t \\Big | Z_i ) &amp;= \\log \\Big[ \\lambda_0(t) \\Big] +\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik} \\\\ S(t \\Big | Z_i ) &amp;= \\Big[ S_0(t) \\Big]^{\\exp(\\beta_1 Z_{i1} + \\cdots + \\beta_k Z_{ik})} \\end{align}\\] $$ ※ Note: $$ \\[\\begin{align} \\lambda_0 (t) &amp;= \\lambda(t \\Big | Z_1 = \\cdots = Z_k = 0) \\\\ \\\\ \\exp(\\beta_1 Z_{1} + \\cdots + \\beta_k Z_{k}) &amp;= RR \\\\ &amp;= \\frac{\\lambda(t \\Big | Z_1 , \\cdots, Z_k)}{\\lambda(t \\Big | Z_1 = \\cdots = Z_k = 0)} \\tag{1} \\end{align}\\] $$ - (1) is relative risk of hazard of death comparing covariates values \\(Z_1,\\cdots, Z_k\\) to \\(Z_1 = \\cdots = Z_k = 0\\) Interpreting Cox Model Coeffcients: \\(\\beta_k\\) is the log RR (hazard ratio) for a unit change in \\(Z_k\\), given all other covariates remain constant, i.e., $$ \\[\\begin{align} \\frac {\\lambda\\Big[t \\Big | Z_1 , \\cdots, (Z_{k&#39;}+1), \\cdots, Z_k \\Big]} {\\lambda\\Big[t \\Big | Z_1 , \\cdots, Z_{k&#39;}, \\cdots, Z_k \\Big]} &amp;= \\exp \\Big (\\beta_1 \\cdot 0 + \\cdots + \\beta_{k&#39;} \\cdot (Z_{k&#39;} +1 - Z_{k&#39;}) + \\cdots + \\beta_k \\cdot 0 \\Big) \\\\ &amp;= \\exp(\\beta_{k&#39;}) \\end{align}\\] $$ The RR comparing 2 sets of values for the covariates \\((Z_1 , \\cdots, Z_k)\\) vs. \\((Z_1&#39; , \\cdots, Z_k&#39;)\\): \\[ RR = \\frac{\\lambda(t \\Big | Z_1 , \\cdots, Z_k)}{\\lambda(t \\Big | Z_1 &#39;, \\cdots, Z_k&#39;)} =\\exp \\Big \\{ \\beta_1(Z_1 - Z_1&#39;) + \\cdots + \\beta_k(Z_k - Z_k&#39;) \\Big \\} \\] 20.png 8.5.0.8 Comparison of Nested Models Nested Models: $$ \\[\\begin{align} \\lambda(t) &amp;= \\lambda_0(t) \\exp \\Big ( \\beta_1 Z_1 + \\cdots \\beta_p Z_p + \\beta_{p+1} Z_{p+1} +\\cdots + \\beta_{k} Z_{k}\\Big) \\tag{Full Model} \\\\ &amp;= \\lambda_0(t) \\exp \\Big ( \\beta_1 Z_1 + \\cdots \\beta_p Z_p \\Big) \\tag{Reduced Model} \\end{align}\\] $$ To test: Nested Models: $$ \\[\\begin{align} &amp;H_0: &amp;&amp;RM &amp;&amp; \\Leftrightarrow &amp;&amp; H_0: \\beta_{p+1} = \\cdots = \\beta_k = 0 \\\\ &amp;H_A: &amp;&amp;RM &amp;&amp; \\Leftrightarrow &amp;&amp; H_A: \\not = \\text{ somewhere} \\end{align}\\] $$ Use the partial likelihood ratio statistic, \\(X^2_{Cox} = -2 \\Big[ \\log PL(RM) - \\log PL(FM)\\Big]\\). Under \\(H_0\\): Reduced model, and when \\(n\\) is large: \\[ \\begin{align} X^2_{Cox} \\sim \\chi^2_{k-p} &amp;&amp; k-p \\text{ is the ## of parameters set to 0 by }H_0 \\end{align} \\] 20.png, 21.png 8.5.0.9 Stratification Two Ways to Stratify. Suppose a confounder \\(C\\) has 3 levels on which we would like to stratify when comparin g \\(\\lambda(t \\Big | E )\\) and \\(\\lambda ( t \\Big | \\bar E )\\). How? \\(X_E = \\begin{cases}1&amp;E&amp;\\text{(exposed)}\\\\0&amp;\\bar E&amp;\\text{(not exposed)}\\end{cases}\\) 22.png Which Way to Stratify? Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder \\(C\\) may be inadequately controlled. Proportionality assumption can be checked using time-dependent covariates. True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If \\(C\\) can be measured continuously and the strata were formed by grouping values of it, better control for \\(C\\) might be achieved with continuous (could be time-dependent) covariate adjustment. If \\(C\\) is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of \\(C\\). However, we can estimate \\(\\lambda_{0i}(t)\\) for each stratum then we can estimate a RR function. True stratification generally requires more data to obtain the same precision in coefficient estimates. 23.png 24.png 8.5.0.10 Test statistics The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood. 25.png Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least. 26.png When \\(p = 1\\) and the single covariate is categorical, the score test is identical to the log-rank test. 27.png 8.5.0.11 Handling ties Real data sets often contain tied event times. When do we have ties? Continuous event times are grouped into intervals. Event time scale is discrete. Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood. When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the \\(i\\)-th event at time \\(t_i\\) is \\(\\frac{\\exp(\\beta &#39; Z_i)}{ \\sum\\limits_{j \\in R_i} Y_j(t_i) \\exp(\\beta &#39; Z_j)}\\) Two commonly used methods are 1. Breslow approximation 2. Efron approximation Example: Assume 5 subjects are at risk of dying at time \\(t\\) and two die at the same time \\(t\\) (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either 28.png 29.png 30.png "],["concepts.html", "8.6 Concepts", " 8.6 Concepts \\(S(t)\\): survival function. 시점 \\(t\\)까지는 살아있을 확률. \\(h(t) = \\lambda(t) = \\frac{f(t)}{S(t)}\\): hazard function. 시점 \\(t\\)에서 사망할 확률. "],["r-bookdown.html", "A R Bookdown ", " A R Bookdown "],["tutorial.html", "A.1 Tutorial", " A.1 Tutorial A.1.1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). A.1.1.0.0.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: ### A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ###### A short section or ######### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. A.1.1.0.0.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. A.1.1.0.0.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book,” or from the R console: bookdown::serve_book() A.1.2 Hello bookdown All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (###) per .Rmd file. A.1.2.0.0.1 A section All chapter sections start with a second-level (######) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. A.1.3 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. A.1.3.0.0.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: ### Hello world {###nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, ### Hello world = ### Hello world {###hello-world}. To label an un-numbered heading, use: ### Hello world {-###nice-label} or {### Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter \\@ref(cross). If you prefer text as the link instead of a numbered reference use: any text you want can go here. A.1.3.0.0.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure A.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) FIGURE A.1: Here is a nice figure! Don’t miss Table A.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) TABLE A.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 A.1.4 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: ### (PART) Act one {-} (followed by ### A chapter) Add an unnumbered part: ### (PART\\*) Act one {-} (followed by ### A chapter) Add an appendix as a special kind of un-numbered part: ### (APPENDIX) Other stuff {-} (followed by ### A chapter). Chapters in an appendix are prepended with letters instead of numbers. A.1.5 Footnotes and citations A.1.5.0.0.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one.1 A.1.5.0.0.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2021) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/###/citations A.1.6 Blocks A.1.6.0.0.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation \\@ref(eq:binom). A.1.6.0.0.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem . ::: {.theorem ###tri} For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] ::: Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. A.1.6.0.0.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html A.1.7 Sharing your book A.1.7.0.0.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html A.1.7.0.0.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. A.1.7.0.0.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook References References "],["noname.html", "B NoName", " B NoName 모먼트, MLE (2차까지 확인) MLE 불변성 MSE를 통해 통계량 성능 비교 가능함 bias MSE = precision + accuracy UMVUE 7.5 크래머-라오 부등식 : 최저 분산 뽑아내는 수단 피셔 정보 2차원 피셔 정보 라오-블랙웰 : uniform better UE 뽑아내는 수단 unique best UE best UE는 오직 하나뿐 (레만쉐페) CSS에 기반한 UE는 오직 유일함 W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7 consistent (점근성) 충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일 test으 unbaised 8.8 네이만 피어슨 카를린 루빈 8.3 빅 샘플 추정자들과 8.5 스코어 스탯 8.12 왈드 테스트 8.13 1-a confidence iterval = acceptance region of level 알파 test 뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨 pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT. MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량. cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2. 감마와 포아송간 변환 유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5. dog-tired Bubble Plot 3D Scatter Plot Star Plot Chernoff Faces Parallel Coordinate Plot 1.Q-Q Plot Shapiro-Wilks Test Kolmogorov-Smirnov Test Skewness Test ( ) Kurtosis Test: ( ) Lin and Mudholkar Scatter Plot Squared Generalized Distances Chi-Square Plot (Gamma Plot) nqplot contour plot cqplot (Python – assumption check) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
