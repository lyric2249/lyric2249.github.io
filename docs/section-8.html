<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>F 01 | Self-Study</title>
  <meta name="description" content="F 01 | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="F 01 | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="F 01 | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cnn-3.html"/>

<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li><a href="index.html#intro" id="toc-intro">Intro<span></span></a></li>
<li><a href="#part-20-02" id="toc-part-20-02">(PART) 20-02<span></span></a></li>
<li><a href="categorical.html#categorical" id="toc-categorical"><span class="toc-section-number">1</span> Categorical<span></span></a>
<ul>
<li><a href="overview.html#overview" id="toc-overview"><span class="toc-section-number">1.1</span> Overview<span></span></a>
<ul>
<li><a href="overview.html#data-type-and-statistical-analysis" id="toc-data-type-and-statistical-analysis"><span class="toc-section-number">1.1.1</span> Data Type and Statistical Analysis<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="bayesian.html#bayesian" id="toc-bayesian"><span class="toc-section-number">2</span> Bayesian<span></span></a>
<ul>
<li><a href="abstract.html#abstract" id="toc-abstract"><span class="toc-section-number">2.1</span> Abstract<span></span></a>
<ul>
<li><a href="abstract.html#변수의-독립성" id="toc-변수의-독립성"><span class="toc-section-number">2.1.1</span> 변수의 독립성<span></span></a></li>
<li><a href="abstract.html#교환가능성" id="toc-교환가능성"><span class="toc-section-number">2.1.2</span> 교환가능성<span></span></a></li>
</ul></li>
<li><a href="continual-aeassessment-method.html#continual-aeassessment-method" id="toc-continual-aeassessment-method"><span class="toc-section-number">2.2</span> Continual Aeassessment Method<span></span></a></li>
<li><a href="horseshoe-prior.html#horseshoe-prior" id="toc-horseshoe-prior"><span class="toc-section-number">2.3</span> Horseshoe Prior<span></span></a></li>
</ul></li>
<li><a href="#part-21-01" id="toc-part-21-01">(PART) 21-01<span></span></a></li>
<li><a href="mathematical-stats.html#mathematical-stats" id="toc-mathematical-stats"><span class="toc-section-number">3</span> Mathematical Stats<span></span></a>
<ul>
<li><a href="inference.html#inference" id="toc-inference"><span class="toc-section-number">3.1</span> Inference<span></span></a>
<ul>
<li><a href="inference.html#rao-blackwell-thm." id="toc-rao-blackwell-thm."><span class="toc-section-number">3.1.1</span> Rao-Blackwell thm.<span></span></a></li>
<li><a href="inference.html#completeness" id="toc-completeness"><span class="toc-section-number">3.1.2</span> Completeness<span></span></a></li>
<li><a href="inference.html#레만-쉐페-thm." id="toc-레만-쉐페-thm."><span class="toc-section-number">3.1.3</span> 레만-쉐페 thm.<span></span></a></li>
<li><a href="inference.html#raoblack" id="toc-raoblack"><span class="toc-section-number">3.1.4</span> Rao-Blackwell thm.<span></span></a></li>
</ul></li>
<li><a href="hypothesis-test.html#hypothesis-test" id="toc-hypothesis-test"><span class="toc-section-number">3.2</span> Hypothesis Test<span></span></a></li>
<li><a href="power-fucntion.html#power-fucntion" id="toc-power-fucntion"><span class="toc-section-number">3.3</span> Power Fucntion<span></span></a>
<ul>
<li><a href="power-fucntion.html#significance-probability-p-value" id="toc-significance-probability-p-value"><span class="toc-section-number">3.3.1</span> Significance Probability (p-value)<span></span></a></li>
</ul></li>
<li><a href="optimal-testing-method.html#optimal-testing-method" id="toc-optimal-testing-method"><span class="toc-section-number">3.4</span> Optimal Testing Method<span></span></a></li>
<li><a href="data-reduction.html#data-reduction" id="toc-data-reduction"><span class="toc-section-number">3.5</span> Data Reduction<span></span></a>
<ul>
<li><a href="data-reduction.html#sufficiency-principle" id="toc-sufficiency-principle"><span class="toc-section-number">3.5.1</span> Sufficiency Principle<span></span></a></li>
</ul></li>
<li><a href="borel-paradox.html#borel-paradox" id="toc-borel-paradox"><span class="toc-section-number">3.6</span> Borel Paradox<span></span></a></li>
<li><a href="neymanpearson-lemma.html#neymanpearson-lemma" id="toc-neymanpearson-lemma"><span class="toc-section-number">3.7</span> Neyman–Pearson lemma<span></span></a>
<ul>
<li><a href="neymanpearson-lemma.html#overview-1" id="toc-overview-1"><span class="toc-section-number">3.7.1</span> Overview<span></span></a></li>
<li><a href="neymanpearson-lemma.html#generalized-lrt" id="toc-generalized-lrt"><span class="toc-section-number">3.7.2</span> Generalized LRT<span></span></a></li>
</ul></li>
<li><a href="개념.html#개념" id="toc-개념"><span class="toc-section-number">3.8</span> 개념<span></span></a></li>
</ul></li>
<li><a href="mcmc.html#mcmc" id="toc-mcmc"><span class="toc-section-number">4</span> MCMC<span></span></a>
<ul>
<li><a href="importance-sampling.html#importance-sampling" id="toc-importance-sampling"><span class="toc-section-number">4.1</span> Importance Sampling<span></span></a>
<ul>
<li><a href="importance-sampling.html#independent-monte-carlo" id="toc-independent-monte-carlo"><span class="toc-section-number">4.1.1</span> Independent Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo"><span class="toc-section-number">4.2</span> Markov Chain Monte Carlo<span></span></a>
<ul>
<li><a href="markov-chain-monte-carlo.html#mh-algorithm" id="toc-mh-algorithm"><span class="toc-section-number">4.2.1</span> MH Algorithm<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used" id="toc-random-walk-chains-most-widely-used"><span class="toc-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler" id="toc-basic-gibbs-sampler"><span class="toc-section-number">4.2.3</span> Basic Gibbs Sampler<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#implementation" id="toc-implementation"><span class="toc-section-number">4.2.4</span> Implementation<span></span></a></li>
</ul></li>
<li><a href="advanced-mcmc-wk08.html#advanced-mcmc-wk08" id="toc-advanced-mcmc-wk08"><span class="toc-section-number">4.3</span> Advanced MCMC (wk08)<span></span></a>
<ul>
<li><a href="advanced-mcmc-wk08.html#data-augmentation" id="toc-data-augmentation"><span class="toc-section-number">4.3.1</span> Data Augmentation<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm" id="toc-hit-and-run-algorithm"><span class="toc-section-number">4.3.2</span> Hit-and-Run Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm" id="toc-metropolis-adjusted-langevin-algorithm"><span class="toc-section-number">4.3.3</span> Metropolis-Adjusted Langevin Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm" id="toc-multiple-try-metropolis-algorithm"><span class="toc-section-number">4.3.4</span> Multiple-Try Metropolis Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm" id="toc-reversible-jump-mcmc-algorithm"><span class="toc-section-number">4.3.5</span> Reversible Jump MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc" id="toc-auxiliary-variable-mcmc"><span class="toc-section-number">4.4</span> Auxiliary Variable MCMC<span></span></a>
<ul>
<li><a href="auxiliary-variable-mcmc.html#introduction" id="toc-introduction"><span class="toc-section-number">4.4.1</span> Introduction<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution" id="toc-multimodal-target-distribution"><span class="toc-section-number">4.4.2</span> Multimodal Target Distribution<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants" id="toc-doubly-intractable-normalizing-constants"><span class="toc-section-number">4.4.3</span> Doubly-intractable Normalizing Constants<span></span></a></li>
</ul></li>
<li><a href="approximate-bayesian-computation.html#approximate-bayesian-computation" id="toc-approximate-bayesian-computation"><span class="toc-section-number">4.5</span> Approximate Bayesian Computation<span></span></a>
<ul>
<li><a href="approximate-bayesian-computation.html#simulator-based-models" id="toc-simulator-based-models"><span class="toc-section-number">4.5.1</span> Simulator-Based Models<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods" id="toc-abcifying-monte-carlo-methods"><span class="toc-section-number">4.5.2</span> ABCifying Monte Carlo Methods<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm" id="toc-abc-mcmc-algorithm"><span class="toc-section-number">4.5.3</span> ABC-MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="hamiltonian-monte-carlo.html#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo"><span class="toc-section-number">4.6</span> Hamiltonian Monte Carlo<span></span></a>
<ul>
<li><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo" id="toc-introduction-to-hamiltonian-monte-carlo"><span class="toc-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="population-monte-carlo.html#population-monte-carlo" id="toc-population-monte-carlo"><span class="toc-section-number">4.7</span> Population Monte Carlo<span></span></a>
<ul>
<li><a href="population-monte-carlo.html#adaptive-direction-sampling" id="toc-adaptive-direction-sampling"><span class="toc-section-number">4.7.1</span> Adaptive Direction Sampling<span></span></a></li>
<li><a href="population-monte-carlo.html#conjugate-gradient-mc" id="toc-conjugate-gradient-mc"><span class="toc-section-number">4.7.2</span> Conjugate Gradient MC<span></span></a></li>
<li><a href="population-monte-carlo.html#parallel-tempering" id="toc-parallel-tempering"><span class="toc-section-number">4.7.3</span> Parallel Tempering<span></span></a></li>
<li><a href="population-monte-carlo.html#evolutionary-mc" id="toc-evolutionary-mc"><span class="toc-section-number">4.7.4</span> Evolutionary MC<span></span></a></li>
<li><a href="population-monte-carlo.html#sequential-parallel-tempering" id="toc-sequential-parallel-tempering"><span class="toc-section-number">4.7.5</span> Sequential Parallel Tempering<span></span></a></li>
</ul></li>
<li><a href="stochastic-approximation-monte-carlo.html#stochastic-approximation-monte-carlo" id="toc-stochastic-approximation-monte-carlo"><span class="toc-section-number">4.8</span> Stochastic Approximation Monte Carlo<span></span></a></li>
<li><a href="review.html#review" id="toc-review"><span class="toc-section-number">4.9</span> Review<span></span></a>
<ul>
<li><a href="review.html#wk01" id="toc-wk01"><span class="toc-section-number">4.9.1</span> Wk01<span></span></a></li>
<li><a href="review.html#wk03" id="toc-wk03"><span class="toc-section-number">4.9.2</span> wk03<span></span></a></li>
<li><a href="review.html#wk04-05" id="toc-wk04-05"><span class="toc-section-number">4.9.3</span> wk04, 05<span></span></a></li>
</ul></li>
<li><a href="else.html#else" id="toc-else"><span class="toc-section-number">4.10</span> Else<span></span></a>
<ul>
<li><a href="else.html#hw4.-rasch-model" id="toc-hw4.-rasch-model"><span class="toc-section-number">4.10.1</span> Hw4. Rasch Model<span></span></a></li>
<li><a href="else.html#da-example-mvn" id="toc-da-example-mvn"><span class="toc-section-number">4.10.2</span> DA) Example: MVN<span></span></a></li>
<li><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes" id="toc-bayesian-adaptive-clinical-trial-with-delayed-outcomes"><span class="toc-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes<span></span></a></li>
<li><a href="else.html#nmar의-종류" id="toc-nmar의-종류"><span class="toc-section-number">4.10.4</span> NMAR의 종류<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-selection" id="toc-wk10-bayesian-model-selection"><span class="toc-section-number">4.10.5</span> wk10) Bayesian Model Selection<span></span></a></li>
<li><a href="else.html#autologistic-model" id="toc-autologistic-model"><span class="toc-section-number">4.10.6</span> Autologistic model<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-averaging" id="toc-wk10-bayesian-model-averaging"><span class="toc-section-number">4.10.7</span> wk10) Bayesian Model Averaging<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="mva.html#mva" id="toc-mva"><span class="toc-section-number">5</span> MVA<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#overview-of-mva-not-ended" id="toc-overview-of-mva-not-ended"><span class="toc-section-number">5.1</span> Overview of mva (not ended)<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#notation" id="toc-notation"><span class="toc-section-number">5.1.1</span> Notation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">5.1.2</span> Summary Statistics<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation" id="toc-statistical-inference-on-correlation"><span class="toc-section-number">5.1.3</span> Statistical Inference on Correlation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#standardization" id="toc-standardization"><span class="toc-section-number">5.1.4</span> Standardization<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#missing-value-treatment" id="toc-missing-value-treatment"><span class="toc-section-number">5.1.5</span> Missing Value Treatment<span></span></a></li>
</ul></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-nomral-wk2" id="toc-multivariate-nomral-wk2"><span class="toc-section-number">5.2</span> Multivariate Nomral (wk2)<span></span></a>
<ul>
<li><a href="multivariate-nomral-wk2.html#overview-2" id="toc-overview-2"><span class="toc-section-number">5.2.1</span> Overview<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#spectral-decomposition" id="toc-spectral-decomposition"><span class="toc-section-number">5.2.2</span> Spectral Decomposition<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">5.2.3</span> Properties of MVN<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#chi2-distribution" id="toc-chi2-distribution"><span class="toc-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors" id="toc-linear-combination-of-random-vectors"><span class="toc-section-number">5.2.5</span> Linear Combination of Random Vectors<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood" id="toc-multivariate-normal-likelihood"><span class="toc-section-number">5.2.6</span> Multivariate Normal Likelihood<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s" id="toc-sampling-distribtion-of-bar-pmb-y-s"><span class="toc-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span><span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#assessing-normality" id="toc-assessing-normality"><span class="toc-section-number">5.2.8</span> Assessing Normality<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#power-transformation" id="toc-power-transformation"><span class="toc-section-number">5.2.9</span> Power Transformation<span></span></a></li>
</ul></li>
<li><a href="inference-about-mean-vector-wk3.html#inference-about-mean-vector-wk3" id="toc-inference-about-mean-vector-wk3"><span class="toc-section-number">5.3</span> Inference about Mean Vector (wk3)<span></span></a>
<ul>
<li><a href="inference-about-mean-vector-wk3.html#overview-3" id="toc-overview-3"><span class="toc-section-number">5.3.1</span> Overview<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#confidence-region" id="toc-confidence-region"><span class="toc-section-number">5.3.2</span> 1. Confidence Region<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#simultaneous-ci" id="toc-simultaneous-ci"><span class="toc-section-number">5.3.3</span> 2. Simultaneous CI<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison" id="toc-note-bonferroni-multiple-comparison"><span class="toc-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector" id="toc-large-sample-inferences-about-a-mean-vector"><span class="toc-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5" id="toc-profile-analysis-wk4-5"><span class="toc-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend" id="toc-test-for-linear-trend"><span class="toc-section-number">5.3.7</span> 2. Test for Linear Trend<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix" id="toc-inferences-about-a-covariance-matrix"><span class="toc-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix<span></span></a></li>
</ul></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparison-of-several-mv-means-wk5" id="toc-comparison-of-several-mv-means-wk5"><span class="toc-section-number">5.4</span> Comparison of Several MV Means (wk5)<span></span></a>
<ul>
<li><a href="comparison-of-several-mv-means-wk5.html#paired-comparison" id="toc-paired-comparison"><span class="toc-section-number">5.4.1</span> Paired Comparison<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations" id="toc-comparing-mean-vectors-from-two-populations"><span class="toc-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2" id="toc-profile-analysis-for-g2"><span class="toc-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means" id="toc-comparing-several-multivariate-population-means"><span class="toc-section-number">5.4.4</span> Comparing Several Multivariate Population Means<span></span></a></li>
</ul></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression-wk6" id="toc-multivariate-multiple-regression-wk6"><span class="toc-section-number">5.5</span> Multivariate Multiple Regression (wk6)<span></span></a>
<ul>
<li><a href="multivariate-multiple-regression-wk6.html#overview-4" id="toc-overview-4"><span class="toc-section-number">5.5.1</span> Overview<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression" id="toc-multivariate-multiple-regression"><span class="toc-section-number">5.5.2</span> Multivariate Multiple Regression<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#example" id="toc-example"><span class="toc-section-number">5.5.3</span> Example)<span></span></a></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">5.6</span> PCA<span></span></a></li>
<li><a href="factor.html#factor" id="toc-factor"><span class="toc-section-number">5.7</span> Factor<span></span></a>
<ul>
<li><a href="factor.html#method-of-estimation" id="toc-method-of-estimation"><span class="toc-section-number">5.7.1</span> Method of Estimation<span></span></a></li>
<li><a href="factor.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">5.7.2</span> Factor Rotation<span></span></a></li>
<li><a href="factor.html#varimax-criterion" id="toc-varimax-criterion"><span class="toc-section-number">5.7.3</span> Varimax Criterion<span></span></a></li>
<li><a href="factor.html#factor-scores" id="toc-factor-scores"><span class="toc-section-number">5.7.4</span> Factor Scores<span></span></a></li>
</ul></li>
<li><a href="discrimination-and-classification.html#discrimination-and-classification" id="toc-discrimination-and-classification"><span class="toc-section-number">5.8</span> Discrimination and Classification<span></span></a>
<ul>
<li><a href="discrimination-and-classification.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">5.8.1</span> Bayes Rule<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations" id="toc-classification-with-two-mv-n-populations"><span class="toc-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations<span></span></a></li>
<li><a href="discrimination-and-classification.html#evaluating-classification-functions" id="toc-evaluating-classification-functions"><span class="toc-section-number">5.8.3</span> Evaluating Classification Functions<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-several-populations-wk13" id="toc-classification-with-several-populations-wk13"><span class="toc-section-number">5.8.4</span> Classification with several Populations (wk13)<span></span></a></li>
<li><a href="discrimination-and-classification.html#other-discriminant-analysis-methods" id="toc-other-discriminant-analysis-methods"><span class="toc-section-number">5.8.5</span> Other Discriminant Analysis Methods<span></span></a></li>
</ul></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-distance-methods-and-ordination" id="toc-clustering-distance-methods-and-ordination"><span class="toc-section-number">5.9</span> Clustering, Distance Methods, and Ordination<span></span></a>
<ul>
<li><a href="clustering-distance-methods-and-ordination.html#overview-5" id="toc-overview-5"><span class="toc-section-number">5.9.1</span> Overview<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">5.9.2</span> Hierarchical Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">5.9.3</span> K-means Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법" id="toc-군집의-평가방법"><span class="toc-section-number">5.9.4</span> 군집의 평가방법<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14" id="toc-clustering-using-density-estimation-wk14"><span class="toc-section-number">5.9.5</span> Clustering using Density Estimation (wk14)<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds" id="toc-multidimensional-scaling-mds"><span class="toc-section-number">5.9.6</span> Multidimensional Scaling (MDS)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="linear.html#linear" id="toc-linear"><span class="toc-section-number">6</span> Linear<span></span></a>
<ul>
<li><a href="overview-svd.html#overview-svd" id="toc-overview-svd"><span class="toc-section-number">6.1</span> Overview &amp; SVD<span></span></a>
<ul>
<li><a href="overview-svd.html#spectral-decomposition-1" id="toc-spectral-decomposition-1"><span class="toc-section-number">6.1.1</span> Spectral Decomposition<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-general-version" id="toc-singular-value-decomposition-general-version"><span class="toc-section-number">6.1.2</span> Singular value Decomposition: General-version<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-another-version" id="toc-singular-value-decomposition-another-version"><span class="toc-section-number">6.1.3</span> Singular value Decomposition: Another-version<span></span></a></li>
<li><a href="overview-svd.html#quadratic-forms" id="toc-quadratic-forms"><span class="toc-section-number">6.1.4</span> Quadratic Forms<span></span></a></li>
<li><a href="overview-svd.html#partitioned-matrices" id="toc-partitioned-matrices"><span class="toc-section-number">6.1.5</span> Partitioned Matrices<span></span></a></li>
<li><a href="overview-svd.html#geometrical-aspects" id="toc-geometrical-aspects"><span class="toc-section-number">6.1.6</span> Geometrical Aspects<span></span></a></li>
<li><a href="overview-svd.html#column-row-and-null-space" id="toc-column-row-and-null-space"><span class="toc-section-number">6.1.7</span> Column, Row and Null Space<span></span></a></li>
</ul></li>
<li><a href="introduction-1.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.2</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-1.html#what" id="toc-what"><span class="toc-section-number">6.2.1</span> What<span></span></a></li>
<li><a href="introduction-1.html#random-vectors-and-matrices" id="toc-random-vectors-and-matrices"><span class="toc-section-number">6.2.2</span> Random Vectors and Matrices<span></span></a></li>
<li><a href="introduction-1.html#multivariate-normal-distributions" id="toc-multivariate-normal-distributions"><span class="toc-section-number">6.2.3</span> Multivariate Normal Distributions<span></span></a></li>
<li><a href="introduction-1.html#distributions-of-quadratic-forms" id="toc-distributions-of-quadratic-forms"><span class="toc-section-number">6.2.4</span> Distributions of Quadratic Forms<span></span></a></li>
</ul></li>
<li><a href="estimation.html#estimation" id="toc-estimation"><span class="toc-section-number">6.3</span> Estimation<span></span></a>
<ul>
<li><a href="estimation.html#identifiability-and-estimability" id="toc-identifiability-and-estimability"><span class="toc-section-number">6.3.1</span> Identifiability and Estimability<span></span></a></li>
<li><a href="estimation.html#estimation-least-squares" id="toc-estimation-least-squares"><span class="toc-section-number">6.3.2</span> Estimation: Least Squares<span></span></a></li>
<li><a href="estimation.html#estimation-best-linear-unbiased" id="toc-estimation-best-linear-unbiased"><span class="toc-section-number">6.3.3</span> Estimation: Best Linear Unbiased<span></span></a></li>
<li><a href="estimation.html#estimation-maximum-likelihood" id="toc-estimation-maximum-likelihood"><span class="toc-section-number">6.3.4</span> Estimation: Maximum Likelihood<span></span></a></li>
<li><a href="estimation.html#estimation-minimum-variance-unbiased" id="toc-estimation-minimum-variance-unbiased"><span class="toc-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased<span></span></a></li>
<li><a href="estimation.html#sampling-distributions-of-estimates" id="toc-sampling-distributions-of-estimates"><span class="toc-section-number">6.3.6</span> Sampling Distributions of Estimates<span></span></a></li>
<li><a href="estimation.html#generalized-least-squaresgls" id="toc-generalized-least-squaresgls"><span class="toc-section-number">6.3.7</span> Generalized Least Squares(GLS)<span></span></a></li>
</ul></li>
<li><a href="one-way-anova.html#one-way-anova" id="toc-one-way-anova"><span class="toc-section-number">6.4</span> One-Way ANOVA<span></span></a>
<ul>
<li><a href="one-way-anova.html#one-way-anova-1" id="toc-one-way-anova-1"><span class="toc-section-number">6.4.1</span> One-Way ANOVA<span></span></a></li>
<li><a href="one-way-anova.html#more-about-models" id="toc-more-about-models"><span class="toc-section-number">6.4.2</span> More About Models<span></span></a></li>
<li><a href="one-way-anova.html#estimating-and-testing-contrasts" id="toc-estimating-and-testing-contrasts"><span class="toc-section-number">6.4.3</span> Estimating and Testing Contrasts<span></span></a></li>
<li><a href="one-way-anova.html#cochrans-theorem" id="toc-cochrans-theorem"><span class="toc-section-number">6.4.4</span> Cochran’s Theorem<span></span></a></li>
</ul></li>
<li><a href="testing.html#testing" id="toc-testing"><span class="toc-section-number">6.5</span> Testing<span></span></a>
<ul>
<li><a href="testing.html#more-about-models-two-approaches-for-linear-model" id="toc-more-about-models-two-approaches-for-linear-model"><span class="toc-section-number">6.5.1</span> More About Models: Two approaches for linear model<span></span></a></li>
<li><a href="testing.html#testing-models" id="toc-testing-models"><span class="toc-section-number">6.5.2</span> Testing Models<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure" id="toc-a-generalized-test-procedure"><span class="toc-section-number">6.5.3</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-linear-parametric-functions" id="toc-testing-linear-parametric-functions"><span class="toc-section-number">6.5.4</span> Testing Linear Parametric Functions<span></span></a></li>
<li><a href="testing.html#theoretical-complements" id="toc-theoretical-complements"><span class="toc-section-number">6.5.5</span> Theoretical Complements<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure-1" id="toc-a-generalized-test-procedure-1"><span class="toc-section-number">6.5.6</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace" id="toc-testing-single-degrees-of-freedom-in-a-given-subspace"><span class="toc-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace<span></span></a></li>
<li><a href="testing.html#breaking-ss-into-independent-components" id="toc-breaking-ss-into-independent-components"><span class="toc-section-number">6.5.8</span> Breaking SS into Independent Components<span></span></a></li>
<li><a href="testing.html#general-theory" id="toc-general-theory"><span class="toc-section-number">6.5.9</span> General Theory<span></span></a></li>
<li><a href="testing.html#two-way-anova" id="toc-two-way-anova"><span class="toc-section-number">6.5.10</span> Two-Way ANOVA<span></span></a></li>
<li><a href="testing.html#confidence-regions" id="toc-confidence-regions"><span class="toc-section-number">6.5.11</span> Confidence Regions<span></span></a></li>
<li><a href="testing.html#tests-for-generalized-least-squares-models" id="toc-tests-for-generalized-least-squares-models"><span class="toc-section-number">6.5.12</span> Tests for Generalized Least Squares Models<span></span></a></li>
</ul></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">6.6</span> Generalized Least Squares<span></span></a>
<ul>
<li><a href="generalized-least-squares.html#a-direct-solution-via-inner-products" id="toc-a-direct-solution-via-inner-products"><span class="toc-section-number">6.6.1</span> A direct solution via inner products<span></span></a></li>
</ul></li>
<li><a href="flat.html#flat" id="toc-flat"><span class="toc-section-number">6.7</span> Flat<span></span></a>
<ul>
<li><a href="flat.html#flat-1" id="toc-flat-1"><span class="toc-section-number">6.7.1</span> 1.Flat<span></span></a></li>
<li><a href="flat.html#solutions-to-systems-of-linear-equations" id="toc-solutions-to-systems-of-linear-equations"><span class="toc-section-number">6.7.2</span> 2. Solutions to systems of linear equations<span></span></a></li>
</ul></li>
<li><a href="unified-approach-to-balanced-anova-models.html#unified-approach-to-balanced-anova-models" id="toc-unified-approach-to-balanced-anova-models"><span class="toc-section-number">6.8</span> Unified Approach to Balanced ANOVA Models<span></span></a></li>
</ul></li>
<li><a href="#part-21-02" id="toc-part-21-02">(PART) 21-02<span></span></a></li>
<li><a href="network-stats.html#network-stats" id="toc-network-stats"><span class="toc-section-number">7</span> Network Stats<span></span></a>
<ul>
<li><a href="introduction-2.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">7.1</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-2.html#types-of-network-analysis" id="toc-types-of-network-analysis"><span class="toc-section-number">7.1.1</span> Types of Network Analysis<span></span></a></li>
<li><a href="introduction-2.html#network-modeling-and-inference" id="toc-network-modeling-and-inference"><span class="toc-section-number">7.1.2</span> Network Modeling and Inference<span></span></a></li>
<li><a href="introduction-2.html#network-processes" id="toc-network-processes"><span class="toc-section-number">7.1.3</span> Network Processes<span></span></a></li>
</ul></li>
<li><a href="descriptive-statistics-of-networks.html#descriptive-statistics-of-networks" id="toc-descriptive-statistics-of-networks"><span class="toc-section-number">7.2</span> Descriptive Statistics of Networks<span></span></a>
<ul>
<li><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics" id="toc-vertex-and-edge-characteristics"><span class="toc-section-number">7.2.1</span> Vertex and Edge Characteristics<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion" id="toc-characterizing-network-cohesion"><span class="toc-section-number">7.2.2</span> Characterizing Network Cohesion<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#graph-partitioning" id="toc-graph-partitioning"><span class="toc-section-number">7.2.3</span> Graph Partitioning<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing" id="toc-assortativity-and-mixing"><span class="toc-section-number">7.2.4</span> Assortativity and Mixing<span></span></a></li>
</ul></li>
<li><a href="data-collection-and-sampling.html#data-collection-and-sampling" id="toc-data-collection-and-sampling"><span class="toc-section-number">7.3</span> Data Collection and Sampling<span></span></a>
<ul>
<li><a href="data-collection-and-sampling.html#sampling-designs" id="toc-sampling-designs"><span class="toc-section-number">7.3.1</span> Sampling Designs<span></span></a></li>
<li><a href="data-collection-and-sampling.html#coping-strategies" id="toc-coping-strategies"><span class="toc-section-number">7.3.2</span> Coping Strategies<span></span></a></li>
<li><a href="data-collection-and-sampling.html#big-data-solves-nothing" id="toc-big-data-solves-nothing"><span class="toc-section-number">7.3.3</span> Big Data Solves Nothing<span></span></a></li>
</ul></li>
<li><a href="mathematical-models-for-network-graphs.html#mathematical-models-for-network-graphs" id="toc-mathematical-models-for-network-graphs"><span class="toc-section-number">7.4</span> Mathematical Models for Network Graphs<span></span></a>
<ul>
<li><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models" id="toc-classical-random-graph-models"><span class="toc-section-number">7.4.1</span> Classical Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models" id="toc-generalized-random-graph-models"><span class="toc-section-number">7.4.2</span> Generalized Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms" id="toc-network-graph-models-based-on-mechanisms"><span class="toc-section-number">7.4.3</span> Network Graph Models Based on Mechanisms<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics" id="toc-assessing-significance-of-network-graph-characteristics"><span class="toc-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics<span></span></a></li>
</ul></li>
<li><a href="introduction-to-ergm.html#introduction-to-ergm" id="toc-introduction-to-ergm"><span class="toc-section-number">7.5</span> Introduction to ERGM<span></span></a>
<ul>
<li><a href="introduction-to-ergm.html#exponential-random-graph-models" id="toc-exponential-random-graph-models"><span class="toc-section-number">7.5.1</span> Exponential Random Graph Models<span></span></a></li>
<li><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation" id="toc-difficulty-in-parameter-estimation"><span class="toc-section-number">7.5.2</span> Difficulty in Parameter Estimation<span></span></a></li>
</ul></li>
<li><a href="parameter-estimation-of-ergm.html#parameter-estimation-of-ergm" id="toc-parameter-estimation-of-ergm"><span class="toc-section-number">7.6</span> Parameter Estimation of ERGM<span></span></a>
<ul>
<li><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm" id="toc-current-methods-for-ergm"><span class="toc-section-number">7.6.1</span> Current Methods for ERGM<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm" id="toc-approximation-based-algorithm"><span class="toc-section-number">7.6.2</span> Approximation-based Algorithm<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches" id="toc-auxiliary-variable-mcmc-based-approaches"><span class="toc-section-number">7.6.3</span> Auxiliary Variable MCMC-based Approaches<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc" id="toc-varying-trunction-stochastic-approximation-mcmc"><span class="toc-section-number">7.6.4</span> Varying Trunction Stochastic Approximation MCMC<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#conclusion" id="toc-conclusion"><span class="toc-section-number">7.6.5</span> Conclusion<span></span></a></li>
</ul></li>
<li><a href="ergm-for-dynamic-networks.html#ergm-for-dynamic-networks" id="toc-ergm-for-dynamic-networks"><span class="toc-section-number">7.7</span> ERGM for Dynamic Networks<span></span></a>
<ul>
<li><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm" id="toc-temporal-ergm-tergm-t-ergm"><span class="toc-section-number">7.7.1</span> Temporal ERGM (TERGM, T ERGM)<span></span></a></li>
<li><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm" id="toc-separable-temporal-ergm-stergm-st-ergm"><span class="toc-section-number">7.7.2</span> Separable Temporal ERGM (STERGM, ST ERGM)<span></span></a></li>
</ul></li>
<li><a href="latent-network-models.html#latent-network-models" id="toc-latent-network-models"><span class="toc-section-number">7.8</span> Latent Network Models<span></span></a>
<ul>
<li><a href="latent-network-models.html#latent-position-model" id="toc-latent-position-model"><span class="toc-section-number">7.8.1</span> Latent Position Model<span></span></a></li>
<li><a href="latent-network-models.html#latent-position-cluster-model" id="toc-latent-position-cluster-model"><span class="toc-section-number">7.8.2</span> Latent Position Cluster Model<span></span></a></li>
</ul></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#additive-and-multiplicative-effects-network-models" id="toc-additive-and-multiplicative-effects-network-models"><span class="toc-section-number">7.9</span> Additive and Multiplicative Effects Network Models<span></span></a>
<ul>
<li><a href="additive-and-multiplicative-effects-network-models.html#introduction-3" id="toc-introduction-3"><span class="toc-section-number">7.9.1</span> Introduction<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression" id="toc-social-relations-regression"><span class="toc-section-number">7.9.2</span> Social Relations Regression<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models" id="toc-multiplicative-effects-models"><span class="toc-section-number">7.9.3</span> Multiplicative Effects Models<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation" id="toc-inference-via-posterior-approximation"><span class="toc-section-number">7.9.4</span> Inference via Posterior Approximation<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r" id="toc-discussion-and-example-with-r"><span class="toc-section-number">7.9.5</span> Discussion and Example with R<span></span></a></li>
</ul></li>
<li><a href="stochastic-block-models.html#stochastic-block-models" id="toc-stochastic-block-models"><span class="toc-section-number">7.10</span> Stochastic Block Models<span></span></a>
<ul>
<li><a href="stochastic-block-models.html#stochastic-block-model" id="toc-stochastic-block-model"><span class="toc-section-number">7.10.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm" id="toc-mixed-membership-block-model-mmbm"><span class="toc-section-number">7.10.2</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="high-dimension.html#high-dimension" id="toc-high-dimension"><span class="toc-section-number">8</span> High Dimension<span></span></a>
<ul>
<li><a href="introduction-4.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">8.1</span> Introduction<span></span></a></li>
<li><a href="concentration-inequalities.html#concentration-inequalities" id="toc-concentration-inequalities"><span class="toc-section-number">8.2</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities.html#motivation" id="toc-motivation"><span class="toc-section-number">8.2.1</span> Motivation<span></span></a></li>
<li><a href="concentration-inequalities.html#from-markov-to-chernoff" id="toc-from-markov-to-chernoff"><span class="toc-section-number">8.2.2</span> From Markov to Chernoff<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-variables" id="toc-sub-gaussian-random-variables"><span class="toc-section-number">8.2.3</span> sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables" id="toc-properties-of-sub-gaussian-random-variables"><span class="toc-section-number">8.2.4</span> Properties of sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#equivalent-definitions" id="toc-equivalent-definitions"><span class="toc-section-number">8.2.5</span> Equivalent definitions<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-vectors" id="toc-sub-gaussian-random-vectors"><span class="toc-section-number">8.2.6</span> Sub-Gaussian random vectors<span></span></a></li>
<li><a href="concentration-inequalities.html#hoeffdings-inequality" id="toc-hoeffdings-inequality"><span class="toc-section-number">8.2.7</span> Hoeffding’s inequality<span></span></a></li>
<li><a href="concentration-inequalities.html#maximal-inequalities" id="toc-maximal-inequalities"><span class="toc-section-number">8.2.8</span> Maximal inequalities<span></span></a></li>
<li><a href="concentration-inequalities.html#section" id="toc-section"><span class="toc-section-number">8.2.9</span> </a></li>
</ul></li>
<li><a href="concentration-inequalities-1.html#concentration-inequalities-1" id="toc-concentration-inequalities-1"><span class="toc-section-number">8.3</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities-1.html#sub-exponential-random-variables" id="toc-sub-exponential-random-variables"><span class="toc-section-number">8.3.1</span> Sub-exponential random variables<span></span></a></li>
<li><a href="concentration-inequalities-1.html#bernsteins-condition" id="toc-bernsteins-condition"><span class="toc-section-number">8.3.2</span> Bernstein’s condition<span></span></a></li>
<li><a href="concentration-inequalities-1.html#mcdiarmids-inequality" id="toc-mcdiarmids-inequality"><span class="toc-section-number">8.3.3</span> McDiarmid’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#levys-inequality" id="toc-levys-inequality"><span class="toc-section-number">8.3.4</span> Levy’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#quadratic-form" id="toc-quadratic-form"><span class="toc-section-number">8.3.5</span> Quadratic form<span></span></a></li>
<li><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma" id="toc-the-johnsonlindenstrauss-lemma"><span class="toc-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma<span></span></a></li>
</ul></li>
<li><a href="metric-entropy-and-its-uses.html#metric-entropy-and-its-uses" id="toc-metric-entropy-and-its-uses"><span class="toc-section-number">8.4</span> Metric entropy and its uses<span></span></a>
<ul>
<li><a href="metric-entropy-and-its-uses.html#metric-space" id="toc-metric-space"><span class="toc-section-number">8.4.1</span> Metric space<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy" id="toc-covering-numbers-and-metric-entropy"><span class="toc-section-number">8.4.2</span> Covering numbers and metric entropy<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#packing-numbers" id="toc-packing-numbers"><span class="toc-section-number">8.4.3</span> Packing numbers<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#section-1" id="toc-section-1"><span class="toc-section-number">8.4.4</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-2" id="toc-section-2"><span class="toc-section-number">8.4.5</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-3" id="toc-section-3"><span class="toc-section-number">8.4.6</span> </a></li>
</ul></li>
<li><a href="covariance-estimation.html#covariance-estimation" id="toc-covariance-estimation"><span class="toc-section-number">8.5</span> Covariance estimation<span></span></a>
<ul>
<li><a href="covariance-estimation.html#matrix-algebra-review" id="toc-matrix-algebra-review"><span class="toc-section-number">8.5.1</span> Matrix algebra review<span></span></a></li>
<li><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm" id="toc-covariance-matrix-estimation-in-the-operator-norm"><span class="toc-section-number">8.5.2</span> Covariance matrix estimation in the operator norm<span></span></a></li>
<li><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices" id="toc-bounds-for-structured-covariance-matrices"><span class="toc-section-number">8.5.3</span> Bounds for structured covariance matrices<span></span></a></li>
</ul></li>
<li><a href="matrix-concentration-inequalities.html#matrix-concentration-inequalities" id="toc-matrix-concentration-inequalities"><span class="toc-section-number">8.6</span> Matrix concentration inequalities<span></span></a>
<ul>
<li><a href="matrix-concentration-inequalities.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">8.6.1</span> Matrix calculus<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#matrix-chernoff" id="toc-matrix-chernoff"><span class="toc-section-number">8.6.2</span> Matrix Chernoff<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices" id="toc-sub-gaussian-and-sub-exponential-matrices"><span class="toc-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds" id="toc-랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><span class="toc-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds<span></span></a></li>
</ul></li>
<li><a href="principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.7</span> Principal Component Analysis<span></span></a>
<ul>
<li><a href="principal-component-analysis.html#pca-1" id="toc-pca-1"><span class="toc-section-number">8.7.1</span> PCA<span></span></a></li>
<li><a href="principal-component-analysis.html#matrix-perturbation" id="toc-matrix-perturbation"><span class="toc-section-number">8.7.2</span> Matrix Perturbation<span></span></a></li>
<li><a href="principal-component-analysis.html#spiked-cov-model" id="toc-spiked-cov-model"><span class="toc-section-number">8.7.3</span> Spiked Cov Model<span></span></a></li>
<li><a href="principal-component-analysis.html#sparse-pca" id="toc-sparse-pca"><span class="toc-section-number">8.7.4</span> sparse PCA<span></span></a></li>
</ul></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">8.8</span> Linear Regression<span></span></a>
<ul>
<li><a href="linear-regression.html#problem-formulation" id="toc-problem-formulation"><span class="toc-section-number">8.8.1</span> Problem formulation<span></span></a></li>
<li><a href="linear-regression.html#least-squares-estimator-in-high-dimensions" id="toc-least-squares-estimator-in-high-dimensions"><span class="toc-section-number">8.8.2</span> Least Squares Estimator in high dimensions<span></span></a></li>
<li><a href="linear-regression.html#sparse-linear-regression" id="toc-sparse-linear-regression"><span class="toc-section-number">8.8.3</span> Sparse linear regression<span></span></a></li>
</ul></li>
<li><a href="uniform-laws-of-large-numbers.html#uniform-laws-of-large-numbers" id="toc-uniform-laws-of-large-numbers"><span class="toc-section-number">8.9</span> Uniform laws of large numbers<span></span></a>
<ul>
<li><a href="uniform-laws-of-large-numbers.html#motivation-1" id="toc-motivation-1"><span class="toc-section-number">8.9.1</span> Motivation<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity" id="toc-a-uniform-law-via-rademacher-complexity"><span class="toc-section-number">8.9.2</span> A uniform law via Rademacher complexity<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity" id="toc-upper-bounds-on-the-rademacher-complexity"><span class="toc-section-number">8.9.3</span> Upper bounds on the Rademacher complexity<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">9</span> Survival Analysis<span></span></a>
<ul>
<li><a href="introduction-5.html#introduction-5" id="toc-introduction-5"><span class="toc-section-number">9.1</span> Introduction<span></span></a></li>
<li><a href="section-4.html#section-4" id="toc-section-4"><span class="toc-section-number">9.2</span> </a></li>
<li><a href="counting-processes-and-martingales.html#counting-processes-and-martingales" id="toc-counting-processes-and-martingales"><span class="toc-section-number">9.3</span> Counting Processes and Martingales<span></span></a>
<ul>
<li><a href="counting-processes-and-martingales.html#conditional-expectation" id="toc-conditional-expectation"><span class="toc-section-number">9.3.1</span> Conditional Expectation<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#martingale" id="toc-martingale"><span class="toc-section-number">9.3.2</span> Martingale<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#key-martingales-properties" id="toc-key-martingales-properties"><span class="toc-section-number">9.3.3</span> Key Martingales Properties<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#section-5" id="toc-section-5"><span class="toc-section-number">9.3.4</span> </a></li>
<li><a href="counting-processes-and-martingales.html#section-6" id="toc-section-6"><span class="toc-section-number">9.3.5</span> </a></li>
</ul></li>
<li><a href="section-7.html#section-7" id="toc-section-7"><span class="toc-section-number">9.4</span> </a></li>
<li><a href="cox-regression.html#cox-regression" id="toc-cox-regression"><span class="toc-section-number">9.5</span> Cox Regression<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#filtration의-개념을-정복하자" id="toc-filtration의-개념을-정복하자"><span class="toc-section-number">9.6</span> Filtration의 개념을 정복하자!<span></span></a>
<ul>
<li><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약" id="toc-random-process를-이야기-하기까지의-긴-여정의-요약"><span class="toc-section-number">9.6.1</span> Random Process를 이야기 하기까지의 긴 여정의 요약<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#ft-measurable" id="toc-ft-measurable"><span class="toc-section-number">9.6.2</span> Ft-measurable<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#epilogue" id="toc-epilogue"><span class="toc-section-number">9.6.3</span> EPILOGUE<span></span></a></li>
</ul></li>
<li><a href="concepts.html#concepts" id="toc-concepts"><span class="toc-section-number">9.7</span> Concepts<span></span></a></li>
</ul></li>
<li><a href="#part-22-01" id="toc-part-22-01">(PART) 22-01<span></span></a></li>
<li><a href="scikit.html#scikit" id="toc-scikit"><span class="toc-section-number">10</span> scikit<span></span></a>
<ul>
<li><a href="linear-models.html#linear-models" id="toc-linear-models"><span class="toc-section-number">10.1</span> Linear Models<span></span></a>
<ul>
<li><a href="linear-models.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">10.1.1</span> Ordinary Least Squares<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="#appendix-00-00" id="toc-appendix-00-00">(APPENDIX) 00-00<span></span></a></li>
<li><a href="concepts-1.html#concepts-1" id="toc-concepts-1"><span class="toc-section-number">11</span> Concepts<span></span></a>
<ul>
<li><a href="autologistic.html#autologistic" id="toc-autologistic"><span class="toc-section-number">11.1</span> Autologistics<span></span></a></li>
<li><a href="orderlogit.html#orderlogit" id="toc-orderlogit"><span class="toc-section-number">11.2</span> Ordered Logit<span></span></a></li>
<li><a href="concepts-questions.html#concepts-questions" id="toc-concepts-questions"><span class="toc-section-number">11.3</span> Concepts Questions<span></span></a>
<ul>
<li><a href="concepts-questions.html#통계-및-수학" id="toc-통계-및-수학"><span class="toc-section-number">11.3.1</span> 통계 및 수학<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="about-cluster-gcn.html#about-cluster-gcn" id="toc-about-cluster-gcn"><span class="toc-section-number">12</span> About Cluster-GCN<span></span></a>
<ul>
<li><a href="about-cluster-gcn.html#ann" id="toc-ann"><span class="toc-section-number">12.0.1</span> ANN<span></span></a></li>
<li><a href="about-cluster-gcn.html#cnn" id="toc-cnn"><span class="toc-section-number">12.0.2</span> CNN<span></span></a></li>
<li><a href="about-cluster-gcn.html#graph-convolution-network" id="toc-graph-convolution-network"><span class="toc-section-number">12.0.3</span> Graph Convolution Network<span></span></a></li>
<li><a href="about-cluster-gcn.html#cluster-gcn" id="toc-cluster-gcn"><span class="toc-section-number">12.0.4</span> Cluster-GCN<span></span></a></li>
</ul></li>
<li><a href="cnn-1.html#cnn-1" id="toc-cnn-1"><span class="toc-section-number">13</span> CNN<span></span></a></li>
<li><a href="cnn-2.html#cnn-2" id="toc-cnn-2"><span class="toc-section-number">14</span> CNN<span></span></a></li>
<li><a href="cnn-3.html#cnn-3" id="toc-cnn-3"><span class="toc-section-number">15</span> CNN<span></span></a></li>
<li><a href="section-8.html#section-8" id="toc-section-8"><span class="toc-section-number">16</span> 01<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-8" class="section level1 hasAnchor" number="16">
<h1><span class="header-section-number">F</span> 01<a href="section-8.html#section-8" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>여기서 thm 5.1. 과 복합하는 것으로 이하를 얻을 수 있음.</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_{max} (\hat \Sigma) &amp;= \max_{v \in \mathbb^{d-1}} v&#39;(\Sigma + E)v

\\

&amp;\le \lambda_{max}(\Sigma) + ||E||_{op}

\end{align}\]</span>
$$
<span class="math inline">\(\lambda_{max} (\Sigma) &amp;\le \lambda_{max}(\hat \Sigma) + ||E||_{op}\)</span></p>
<p>v</p>

<p>02</p>
<p>최종적으로 획득한 시각화 결과값을 통해 최신 논문 트렌드를 서술하는 것으로</p>
<p>본 논문에서는 불특정 다수의 latent space model 알고리즘을 구현하였고</p>
<p>word2vec을 통해 전처리하여</p>
<p>해당 과정의 도중 데이터가 부족할 상황을 상정하여 Biterm model 의 방법론을 활용하여 총 corpus 개수를 늘리는 작업을 병행하였다.</p>
<p>위의 알고리즘을 python 기반으로 구현하였으며 속도 퍼포먼스의 향상을 위해 c++을 접합하여 대량의 계산을 필요로 하는 부분을 c++로 처리하였다. 본 논문에서는 해당 구현의 결과값이 유효하다는 것을 증명하고자</p>
<p>동일 주제를 갖는 Web of Science에서 논문 abstract 들을 크롤링하여 이를 대상으로</p>
<p>한 후</p>
<p>이의 iteration을 반복하여 해당 통계량들의 변화 추이를 서술하는 것으로</p>
<p>작동성을 증명하고자 하였다.</p>
<p>현대에 들어서는 분야별로 전문성이 심화되고 있으며 해당 분야에 대한 전문적인 지식 없이는 해당 분야를 얕게나마 이해하는 것도 벅차지고 있습니다. 그럼에도 통섭이라는 단어로 대표되는 분야 간의 협업 및 심화된 전문영역간의 상호교류의 수요는 계속해서 높아지고 있는 상황입니다. 이런 상황에서 각 분야에 대한 지식 없이는 협업의 생산성이 담보되지 않으면서도, 생산성을 갖추기 위해 해당 분야의 공부에 시간을 투자하기에는 자신의 분야에 집중하는 것만 해도 시간이 부족하다는 진퇴양난의 상황이 발생합니다.</p>
<p>Graph-based Trajectory Visualization for Text Mining of COVID-19 Biomedical Literature 논문은 이러한 상황을 타파하기 위해 해당 분야와 관련된 documents 들을 이용하는 것을 제안합니다. 해당 분야와 관련된 대량의 documents 들을 획득한 후 이에 해당 알고리즘을 적용하여 시각화 하는 것으로 해당 분야에 대한 documents 들의 주제들을 개략적으로 하나의 단어로 표시한 후, 이를 2차원 그래프에 배치하는 것으로 해당 주제들 간의 관계성을 드러내는 것이 가능합니다. 이를 통해 분야에 대한 지식 없이도 분야에 관한 documents 들의 흐름을 통해 피상적으로나마 해당 분야를 개괄적으로 파악하여 해당 분야에 엮인 외부인에게 요구되는 노력을 줄일 수 있다고 기대합니다. 이러한 목적을 달성하기 위해 해당 알고리즘을 독립적인 패키지로 배포하고자 하는 것이 해당 프로젝트의 목표였습니다.</p>
<p>연구 목적</p>
<p>이렇듯 해당 논문은 분야를 이해하는데 있어 유효한 도구가 될 수 있는 알고리즘을 제공하고 있습니다. 그러나 구현과정에서 각종 통계학 이론 및 분포, 그리고 딥러닝 처리방법을 사용하기 있기 때문에 통계학 지식이 부족한 연구자들이 해당 알고리즘을 사용해내는 것은 그다지 쉬운 일이 아닙니다. 이는 곧 연구자로 하여금 해당 알고리즘을 구현하여 실사용하기 위해서는 추가적인 통계적 지식 및 기초적인 프로그래밍 지식을 요한다는 것과 같은 의미이며, 이는 곧 통계적 역량이 부족한 연구자들에게 목적으로 하는 분야 이외에 통계학적인 지식 또한 요구하는 상황이 되고 맙니다. 해당 알고리즘 수요자에게 이렇듯 추가적인 부담을 지우는 것은 트렌드 분석을 용이하게 하고자 했던 당초의 목적과는 상반된다고 말할 수 있습니다. 따라서 이러한 불편함을 덜어주기 위해 해당 알고리즘을 분석한 후 일련의 과정을 코드로 작성한 후 하나의 패키지화 하여 배포하는 것은 충분한 실익이 있다고 말할 수 있습니다.</p>
<p>이러한 목적 아래서 본 논문의 내용은 다음과 같습니다. 우선 해당 알고리즘의 바탕으로 하고 있는 이론들과 기초적인 흐름을 서술합니다. 그 후 다양한 프로그래밍 언어들 중 해당 언어를 채택한 이유와, 해당 언어를 통해 구현하는 과정에서 고려되었던 사항들과 실구현 과정을 서술하겠습니다. 이때 실구현 과정에서 마주친 문제점들과 해당 문제점들에 대한 해결책을 제시합니다. 마지막으로 해결책을 적용한 구현 방법론을 통해 해당 알고리즘을 구현한 패키지의 사용법을 서술하고, 실제 데이터를 사용하여 해당 패키지의 퍼포먼스를 보일 것입니다.</p>
<p>Method</p>
<p>해당 알고리즘이 목표로 하는 바는 명확합니다.</p>
<p>다수의</p>
<p>이때 문단의 길이가 길면 길수록 하나의 글줄에서 주제를 파악하기 위해 사용되는 corpus 의 숫자는 늘어나며, 그 숫자가 늘어남에 따라 글줄의 주제를 한두단어로 갈무리하고자 하는 시도는 더욱 어려워질수밖에 없습니다. 따라서 이러한 목적에 맞는 성질이 도드라지는 결과값을 얻기 위해서는 문단의 길이가 짧으면서도 문단 자체가 강력한 힘을 가지는 부류의 글줄을 사용하는 것이 최선입니다. 이런 성질을 가지는 글줄의 종류로는 기사의 서문, 정부발표 요약문, 그리고 논문의 abstract 등을 생각해볼 수 있을 것입니다.</p>
<p>Biterm</p>
<p>2.1.1</p>
<p>자연어 처리가 필요. 개별 글줄에서 corpus를 추출한 후</p>
<p>풍부하게 하기 위하여 단어 벡터들 간의 유사도를 계산해낼 필요가 있다.</p>
<p>이를 위해 ‘비슷한 의미를 가지는 단어들은 비슷한 문맥에서 등장한다’ 는 가정 하에서 각 단어가 보유하는 스테이터스를 부여하고</p>
<p>Word-To-Vector, 속칭 word2vec 알고리즘을 활용하여</p>
<p><strong>Why word2vec?</strong></p>
<p>다른 알고리즘 많잖아.</p>
<p>자연어 전처리는 큰 틀에서 둘. Frequency based Embedding(주파수 기반 임베딩) 과 Prediction based Vector(예측 기반 임베딩).
후자를 word2vec 이라고 부르며, 이는 단일 알고리즘이 아닌 Continuous Bag Of Words (CBOW) 와 Skip-Gram Model 둘의 조합. 전자의 경우에는 BOW, CountVectorizor, TF-IDF 등 여러가지 방법론이 있지만 전부 공통적으로 Frequency, 즉 단어의 횟수로 확률을 판정하여 부여함. 반면 Prediction 은</p>
<p>3줄 요약</p>
<p>3줄 요약에 주되게 사용되는 서비스는</p>
<p>tokenize 기법</p>
<p>추출적 방식</p>
<p>추상적 방식</p>
<p>2.1.2</p>
<p>이때 1차적으로 그러나 input 하는 글줄의 양도 적을 뿐더러 같은 분야의 글줄들을 다루기 때문에 개별 글줄마다의 특성을 통계적으로 파악하기에 충분하지 않을 정도로 개별 글줄들이 고유하게 가지는 단어의 갯수가 적을 수 있음</p>
<p>이를 보완하기 위해서 Biterm Model을 도입.<a href="section-8.html#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p>Biterm Model 은 본질적으로 통계적 확률을 가리기 위한 재료의 가짓수가 적을 경우 이를 판단하기 위한 재료를 늘리기 위한 과정</p>
<p>Biterm Model 은 다음과 같은 가정에 존재.</p>
<ul>
<li>두 단어는 겉보기로 인식할 수 없는 단어의 클러스터에 함께 속한다</li>
<li>각 글줄에는 인식할 수 없는 주제가 존재하며, 각각의 주제 내부에는 유사한 의미를 보유하는 단어들이 모여있다</li>
<li>인식할 수 없는 단어의 클러스터가 함께 속해있는 그것을, 인식할 수 없는 주제라고 인식할 수 있다</li>
</ul>
<p>이러한 Biterm Model 은 본질적으로 사용 가능한 corpus 의 양을 늘리고자 하는 것입니다. 원본 문서에서 corpus의 갯수가 <span class="math inline">\(n\)</span> 개였다면 Biterm 과정을 거치는 것으로 <span class="math inline">\(n^2\)</span>으로 확률 추정에 사용되는 샘플들의 갯수를 늘리는 것이 가능하다는 것입니다. 이렇게 샘플을 늘린 것으로 개별 단어의 확률을</p>
<p>이렇게 늘려서 획득한 각 corpus pair 들의 확률에서 개별 단어들의 확률 획득 가능.</p>
<p><strong>원본 corpus 만으로 진행하는 거랑 무슨 차이가 있는지를 서술해야 함</strong></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta \sim Dirichlet(\alpha)\)</span> 로부터 모든 주제들의 분포를 샘플링.</li>
<li>Biterm set B 의 각 biterm b 에 대해, 해당 biterm을 구성하는 2개의 단어의 합이 전체 주제들 중 어느 주제 z에 속하는지를 샘플링. 이때 <span class="math inline">\(z \sim Mult(\theta)\)</span>.</li>
<li>주제가 주어졌을 경우의 단어의 분포, 즉 주제 z의 topic-word 분포를 샘플링. 이때 <span class="math inline">\(\phi_z \sim Dirichlet(\beta)\)</span>.</li>
<li>topic-word 분포로부터 골라진 topic z 에 대응하는 각 두 단어들의 출현 확률을 샘플링. 이때 <span class="math inline">\(w_i, w_j \sim Mult(\phi_z)\)</span>.</li>
</ol>
<p>이의 단계를 모두 거치는 것으로, 모든 biterm set <span class="math inline">\(B\)</span> 의 joint likelihood 는 이하와 같이 표현될 수 있다.</p>
<p><span class="math display">\[
p(B) = \prod_{i,j} \sum_z \theta_z \phi_{i|z} \phi_{j|z}
\]</span></p>
<p>이에 의해 latent topic z 의 조건부 posterior 는 이하와 같은 비례식을 따른다.</p>
<p><span class="math display">\[
p(z | z_{-b} , B, \alpha, \beta) \propto (n_z + \alpha) \frac{(n_{w_i}+\beta)(n_{w_{j|z}}+\beta)}{(\sum_w n_{w|z}+M \beta)^2}
\]</span></p>
<ul>
<li><span class="math inline">\(n_z\)</span>: biterm 가 주제 z에 할당된 횟수</li>
<li><span class="math inline">\(n_{-b}\)</span>: biterm b 가 포함되지 않았던 주제들</li>
<li><span class="math inline">\(n_{w|z}\)</span>: 주제 z에 할당된 단어 w 의 횟수</li>
</ul>
<p>이때 <span class="math inline">\(p(z | z_{-b} , B, \alpha, \beta)\)</span> 에의 깁스 샘플링의 직접적인 적용은 변수들 간의 dependency 때문에 convergence 로 이르지 못할 우려를 배제할 수 없음. 따라서 우리는 collapsed 깁스 샘플링을 사용하여 불필요한 패러미터들을 integrate out 하여 이의 영향을 억제한다. 이때 prior 을 <span class="math inline">\(dirichlet\)</span> 으로 사용한 것의 이득을 볼 수 있다. <span class="math inline">\(dirichlet\)</span> 을 사용한 것으로 <span class="math inline">\(\phi_z\)</span> 와 <span class="math inline">\(\theta\)</span> 가 integrate out 당하므로. 몇번의 iteration 이후 우리는 획득한 statistics (통계량) <span class="math inline">\(\n_{w|z}\)</span> 와 <span class="math inline">\(\theta_z\)</span> 를 활용하여 <span class="math inline">\(\phi_{w|z}\)</span> 와 <span class="math inline">\(\theta_z\)</span> 의 distribution 을 이하와 같이 구성할 수 있게 된다.</p>
<p><span class="math display">\[
\phi_{w|z} = \frac{n_{w|z}}{\sum_w n_{w|z} + M \beta}, \; \; \; \; \; \theta_z = \frac{n+\alpha}{|B| + K \alpha}
\]</span></p>
<ul>
<li><span class="math inline">\(M\)</span>: 획득해두었던 corpus 의 총 갯수</li>
<li><span class="math inline">\(B\)</span>: 넘버링된 각 biterm</li>
<li><span class="math inline">\(K\)</span>: 설정한 총 topic 의 갯수</li>
</ul>
<p>이제 해당 biterm을 쓰는 것으로 우리는</p>
<p>이제 우리는 주제군 하에서의 corpus 분포 <span class="math inline">\(\phi_{w|z}\)</span> 와 주제 자체의 출현 분포 <span class="math inline">\(\theta_z\)</span> 을 획득했음.</p>
<p>우리가 목표로 하는 것은 글줄 모음에서 얻을 수 있는 각 주제별의 상관관계
지금까지 진행한 작업으로
주제별로 coefficient 를 얻어서 배치하는 건 가능하나 각 주제를 이름붙일 수 없으면 이는 무의미</p>
<p>따라서 이렇게 획득한 각 주제 하에서의 단어 출현 확률에서 각 주제를 어떻게 이름붙일것인가에 대한 재료를 확보해야함</p>
<p>이에 가장 직접적으로 활용할 수 있는 재료는 앞서 획득한 단어별 발생 확률</p>
<p>타 문서에서의 발생 확률이 낮고, 해당 주제군에 속하는 문서들에서만 여러번 발생하는 단어들이라면 해당 단어는 해당 주제군에만 묶여 있다는 것으로 해석할 수 있으며, 이는 곧 해당 주제를 어떻게 이름붙일것인가 하는 고민에서 유의미하게 활용될 수 있을 것</p>
<p>따라서 해당 고민을 해결하고자 하는 과정에는 모든 단어를 참고해서는 안되고 다른 주제군에서는 출현빈도가 낮고, 이 주제군에서는 높다는 조건을 만족해야함</p>
<p>이 조건을 해결하기 위한 기준으로서</p>
<p>우리는 앞서 <span class="math inline">\(M \times K\)</span> 크기의 matrix 를 획득하였음. 이때 각 row 는 개별 단어의 각 주제군에서의 출현도, 각 column 은 각 주제군에서의 개별 단어의 출현율이 됨.</p>
<p>여기서 우리는 각 row 에서의 coefficient variation 과 maximum probability 를 활용할 것. 전자는 주제군별 단어 출현 확률의 변동 정도를, 후자는 특정 주제에 단어가 얼마나 강하게 묶여 있는지에 대한 척도가 됨.</p>
<p>BTM 은 topic-word distribution 을 생산하며, 이는 각 주제들 내부에서 각 단어의 확률을 측정하므로, 우리는 이들의 variation 을 조정해주어야 한다. 단순히 variance 를 측정하는 것만으로는 불충분. 따라서 우리는 standard deviation 을 각 주제군에서 획득한 각 단어의 확률의 평균으로 나눔하며, 이것이 곧 <code>coefficient variation</code>이다.</p>
<p>행렬 <span class="math inline">\(X_i\)</span>의 각 행에서 단어를 선택하는 기준으로 계수 변동과 최대 확률을 선택하는 두 가지 이유가 있습니다.</p>
<p>첫째, 중요한 단어는 주제 간에 변동성이 낮으면 그 단어가 구체적으로 어떤 주제를 나타내지 않을 가능성이 높다. 따라서 확률의 variation 이 높은 단어야말로 주제를 판정함에 있어 유의미한 선택지로 판단될 수 있다. 따라서 의미 있는 단어를 판정함에 있어 variation을 사용하는 것은 타당하며, 여기서 coefficient variation 을 사용하는 것으로 더더욱 주제군간 topic 의 dispersion 을 증폭시키는 것이 가능하다.</p>
<p>두 번째, 의미 있는 단어가 되기 위해서는 적어도 하나의 주제에서 가능성이 높아야 합니다. 예를 들어, 단어의 variation 이 높다고 한들 그 어느 주제군에서도 높은 확률을 보이고 있지 못한다면 이는 결국 해당 주제군을 표현한다고 하기 어려우며 주제군을 표현함에 있어 기능을 다하기 어렵다. 그렇기 때문에 적어도 하나의 주제에서 확률이 높은 단어와, 앞문단에서 언급하였듯 변화가 큰 단어를 선택한다는 두가지 기준을 통해 효과적으로 주제를 특징지을 수 있습니다.</p>
<pre><code>

BTM 을 적용하기 위해 우리는 topic 갯수를 20으로 지정. hyper 패러미터로서는 $\alpha=3, \beta=0.01$ 을 부여. 궁극적인 목표는 topic 간의 관계를 시각화하는 것이기에 이에 필요한 hyper 패러미터는 empirically 결정하였다. topic-word 의 posterior 분포, 즉 BTM 과정 자체는 Gibbs Sampler 를 통해 결정되었으며, 이는 20000번의 burn-in, 55000 회의 iteration, 그리고 100 iteration 마다 thining 진행.


BTM 으로부터 획득한 각 topic-word 분포에서, 각 주제군들 하에서 높은 출현확률을 보이는 단어야말로 해당 주제를 특징짓기 적합함.

이에 대해서는 각 주제군들 별로 부여된 각 단어들의 확률의 로그 히스토그램을 구하면

bimodal 한 형태

좌측의 mode 는 낮은 확률, 즉 주제를 특징짓기 부적합한 라인업들이며, 우측의 mode 는 높은 확률로 출현하는 단어들.

따라서 noise 를 줄이기 위해 topic relationship 을 우측의 mode 에 등장하는 단어들만을 참고하여 판정하는 것은 실로 합리적일 것. 

이 히스토그램에 기반하여 최하 cutoff value, normal distribution의 최한도를 결정하는, 은 

우리는 

topic 을 유의미하게 표현하기 위해선 최소한 1000개의 단어가 필요함을 empirically

이 rationale 을 기반으로 하여 우리는 적어도 1000개의 단어는 사용하기로 결정

topic 의 특징을 추출하기 위한 단어의 기준선으로 우리는 

1. topic과 topic 간에 variance 가 큼 - coefficient variation
2. max probability 가 상대적으로 높음 - max probability

의 2가지 기준을 만족하는 단어들을 골라냈음. 해당 논문에서는 정해진 갯수의 단어를 사용하기 보다는 다른 갯수의 단어들을 사용하는 것으로 발생하는 변화를 관측하고자 하였음. **가령 포함하는 단어의 수가 변동함에 따라 topic 의 latent coordinate 가 격렬하게 변동한다면 이는 주제군으로 성립하기는 조금 어렵거나 주제군이 다루고 있는 바운더리가 넓어 그때그때 변동함을 의미할 것.** 특히, 우리는 다양한 매트릭스를 획득했다. 40%~60% 사이를 이용. 









이의 실적용에서는 상대적 편의를 위하여 

topic 들의 latent position 들 $\mathbf V = \{\mathbf v_i\}$ 를 획득ㄱ하기 위해 MCMC 가 적용되었다. MCMC 는 iteration 55000회, burn-in 5000회, thining 5. 해당 MCMC에 사용된 패러미터는 이하와 같다. 주제군들 간의 관계를 시각화하기 위해 우리는 2차원 Euclidean space 를 사용. 사용된 패러미터는 이하와 같다.

jumping 룰에 관해서는:</code></pre>
<p><span class="math display">\[
\alpha = ?
\\
\beta = 0.28
\\
\theta = 1
\\
w_k = z_i = 0.06
\]</span></p>
<p><span class="math display">\[
prior \beta = fixed
\\
\theta \sim N(0,1)
\\
a_\sigma = b_\sigma = 0.001
\]</span></p>
<pre><code>LSIRM 은 앞단계에서 이루어진 X_i 를 받아 결과값으로 $A_i$ 를 내놓는다. 이에 proc2와 oblim 을 적용하는 것으로 최종적 시각화에 사용될 matrix 를 내놓을 예정. 



topicnaming 에는 $A_max$ 를 활용하여 주제군별로 높게 랭킹된 단어를 활용하여 topic naming 진행. 왜? baseline matrix 야말로 topic 들을 characterize 함에 있어 가장 연고한 dependency 구조를 보유하고 있으니까. 


</code></pre>
<p>2.1.3 Latent Space Item Response Model</p>
<p>해당 단계에서는 위에서 획득한 단어들의 출현빈도를 사용하여 각 주제군들 간의 관계성을 확인하고 이 관계성을 interaction map 에 표시하여 각 글줄들 간의 관계를 구성한다.</p>
<p>원본: Latent Space Model, 네트워크에서의 각 actor (node) 들의 unobserved space 에서의 관계를 표현
후속: Latent Space Item Response Model (LSIRM). item response 를 biparite nwtwrok 로 인식하고, respondent 와 item 간의 관계를 latent space 를 사용하여 획득하는 가ㅓㅅ]</p>
<p>LSIRM 은 이하의 2가지로 모델링된다.</p>
<ul>
<li>Attribute: 특정 item 에 몇 명의 응답자가 응답했는지와, 특정 응답자들에 의해 몇 개의 item 이 응답되었는가</li>
<li>Interaction: 각 item과 응답자의 latent position, 그리고 item 과 응답자 사이의 interaction을 측정</li>
</ul>
<p>이를 응용하는 것으로 목표하는 바 달성 가능</p>
<p>해당 알고리즘의 목적은 주제 간의 관계를 추정하는 것과, 각 주제들에 연관된 단어를 근거로 하여 interaction map에서 주제의 latent position을 추정하는 것.</p>
<p>즉 topic 간의 관계를 획득하고 이 관계를 나타내는 coefficient 들을 연관된 단어를 기반으로 하여 interaction map 에 표방하고자 하는 일련의 과정을</p>
<p>앞서 획득한 <span class="math inline">\(\phi_{w|z}\)</span> 의 matrix <span class="math inline">\(X_i\)</span> 를 biparite network 로 인식하자. 이때 topic 은 item, respondent 은 word 가 된다.</p>
<p>|topic|item|
|word|respondent|</p>
<p>이는 위에서 서술한 LSIRM에서</p>
<p>단 본디 원본 LSIRM 은 binary 데이터를 서술하기 위해 작성. 따라서 해당 문제에 직접 적용은 불가하다. 해당 문제의 경우 word2vec을 거쳐 각 단어의 출현 확률에 0에서 1 사이의 실수값을 부여하였기에 binary 모델이 아닌 Gaussian 버전. 이를 보정하기 위하여 해당 문제의 기본 아이디어만을 살리고 사용하는 확률을 Gaussian 확률로 변경하는 것으로 해당 문제를 보완 가능.</p>
<p>해당 문제를 보정하기 위하여</p>
<p>모델을 Gaussian 버전으로 변경.</p>
<p>binary 가 아닌 Gaussian 용도로 변형된 LSIRM 은 이하와 같이 서술될 수 있다.</p>
<p><span class="math display">\[
x_{i,j}|\Theta = \theta_j + \beta+ \| \pmb u_i - \pmb v_j \| + \epsilon_{j,i}
\]</span></p>
<ul>
<li><span class="math inline">\(\epsilon_{j,i} \sim N(0, \sigma^2)\)</span></li>
<li><span class="math inline">\(i= 1\sim P\)</span>, <span class="math inline">\(j=1\sim N\)</span></li>
<li><span class="math inline">\(x_{j,i}\)</span>: 단어 <span class="math inline">\(x\)</span>가 주제 <span class="math inline">\(i\)</span>에 속할 확률 (횟수?)</li>
<li><span class="math inline">\(\Theta = \bigg\{ \pmb \theta= \{\theta_j\}, \pmb \beta= \{\beta_j\}, \pmb U = \{u_j\}, \pmb V = \{v_j\} \bigg\}\)</span></li>
<li><span class="math inline">\(\| u_i - v_j \|\)</span>: 단어 i 와 주제 j 각각의 latent position 사이의 Euclidean Distance.</li>
</ul>
<p>원본 LSIRM 의 경우 binary 자료를 연속형으로 변환하기 위해 logit link 함수를 사용했음.</p>
<p>따라서 여기서 우리는 interaction 부분, attribute 부분과 <span class="math inline">\(x_{j,i}\)</span> 사이의 선형성 가정을 이용. normality equation을 만족시키기 위해 error term <span class="math inline">\(\epsilon_{i,j}\)</span> 를 추가.</p>
<p>이때 <span class="math inline">\(\| u_i - v_j \|\)</span> 가 짧을 경우, 이는 곧 word 의 latent position <span class="math inline">\(u_i\)</span> 와 topic 의 latent position <span class="math inline">\(v_j\)</span> 의 연관성이 존재할 가능성이 높다는 것을 의미하며, 이는 곧 word <span class="math inline">\(i\)</span> 가 topic <span class="math inline">\(j\)</span> 에 link 되어 있을 확률이 높음을 암시. 따라서, topic 의 latent position 은 word 들과의 거리에 기반하여 측정되는 것이 가능하다.</p>
<p>위에 주어진 모델을 given 했을 때, 우리는 LSIRM 의 gaussian 버전에서의 패러미터를 측정하기 위해 베이지안 추론을 활용하였다. 우리는 패러미터에 대한 prior 분포를 이하와 같이 특정한다:</p>
<p><span class="math display">\[
\begin{alignedat}{2}
\beta_{i} \mid \tau_{\beta}^{2} &amp; \sim \mathrm{N}\left(0, \tau_{\beta}^{2}\right), &amp;&amp;\quad \tau_{\beta}^{2}&amp;&amp;&gt;0 \\
\theta_{j} \mid \sigma^{2} &amp; \sim \mathrm{N}\left(0, \sigma_{\theta}^{2}\right), &amp;&amp;\quad \sigma^{2}&amp;&amp;&gt;0 \\
\sigma^{2} &amp; \sim \operatorname{Inv-Gamma}(a, b), &amp;&amp;\quad a &amp;&amp;&gt; 0, \quad b&gt;0 \\
\sigma_{\theta}^{2} &amp; \sim \operatorname{Inv-Gamma}\left(a_{\sigma}, b_{\sigma}\right), &amp;&amp;\quad a_{\sigma}&amp;&amp;&gt;0, \quad b_{\sigma}&gt;0 \\
\mathbf{u}_{\mathbf{j}} &amp; \sim \mathrm{MVN}_{d}\left(\mathbf{0}, \mathbf{I}_{d}\right) \\
\mathbf{v}_{\mathbf{i}} &amp; \sim \mathrm{M V N}_{d}\left(\mathbf{0}, \mathbf{I}_{d}\right) .
\end{alignedat}
\]</span>
- <span class="math inline">\(\mathbf 0\)</span>: <span class="math inline">\(d\)</span> 크기의 0 vector
- <span class="math inline">\(\mathbf I_d\)</span>: <span class="math inline">\(d \times d\)</span> 크기의 identity matrix</p>
<p>여기서 <span class="math inline">\(\tau_\beta^2\)</span> 은 constant value 로 고정한다.</p>
<p>이제 LSIRM 의 posterior 분포를 살펴보자. 이는 이하와 같다.</p>
<p><span class="math display">\[
\begin{alignedat}{2}
\pi\left(\boldsymbol{\Theta}, \sigma^{2} \mid \mathbf{X}\right)  \propto &amp;\prod_{j} \prod_{i} \mathbb{P}\left(x_{j i} \mid \boldsymbol{\Theta}\right) \\
*
&amp;\prod_{j} \pi\left(\theta_{j} \mid \sigma_{\theta}^{2}\right) \pi\left(\sigma_{\theta}^{2}\right)
&amp;&amp;\prod_{i} \pi\left(\beta_{i}\right) \\
*
&amp;\prod_{j} \pi\left(\mathbf{u}_{\mathbf{j}}\right)
&amp;&amp;\prod_{\mathbf{i}} \pi\left(\mathbf{v}_{\mathbf{i}}\right) \pi\left(\sigma^{2}\right)
\end{alignedat}
\]</span></p>
<p>여기서 우리는 Markov Chain Monte Carlo (이하 MCMC) 를 사용하여 LSIRM 의 패러미터를 추정해 나간다. 이 방법으로 우리는 interaction map 에서 <span class="math inline">\(u_j\)</span> 와 <span class="math inline">\(v_i\)</span> 의 latent position 을 획득하는 것이 가능해진다. 우리는 topic network 를 획득하는 것에 관심이 있으므로, 우리는 <span class="math inline">\(u_j\)</span> 를 활용하여 이를 <span class="math inline">\(A_i\)</span> 의 매트릭스로 만들 것이다. <strong>이거 <span class="math inline">\(v_i\)</span> 아니냐???</strong></p>
<p>Procrustes Matching and Oblique Roation</p>
<p>다양한 matrix <span class="math inline">\(X_i\)</span> 각각에 대해 LSIRM 을 진행한 것을 통해 우리는 각 주제군들이 보유한 coordinate 로 구성된 matrix <span class="math inline">\(A_i\)</span> 들을 보유하고 있다.</p>
<p>주제군들 간의 관계의 해석을 더욱 진전시키기 위해 우리는 word set 의 함수의 결과값으로서의 latent position 이 어떻게 변화하는지를 체크하고자 한다. 특히, 우리는 각 matrix <span class="math inline">\(X_i\)</span> 로부터 생산한 각 주제군의 latent position <span class="math inline">\(A_i\)</span> 간을 이하의 과정을 거쳐 비교하고자 함.</p>
<p>이는 이하의 과정을 거쳐 진행.</p>
<ol style="list-style-type: decimal">
<li>LSIRM 에서 생산한 MCMC 샘플들 각각에 대해 procrustes matching 진행. 이는 invariance property 를 제어하기 위함. (소위 within-matrix matching)</li>
<li>1에서 procrustes matching 을 통해 조정된 각각의 MCMC matrix 샘플들을 평균내는 것으로 최종적으로 사용할 estimated matrix 획득. 이렇게 획득한 esimated matrix 들에 대해 topic 들을 동일한 quadrant 에 위치시키기 위해 다시 한 번 procrustes matching.
3 각 주제들의 latent postion 으로부터 원점까지의 거리를 구한다. 이는 곧 dependency structure 의 강도를 구하기 위함. 특히, latent position 의 거리가 길다면 이것은 곧 네트워크의 더 강한 dependency 를 의미함.</li>
</ol>
<p><span class="math inline">\(X_i\)</span> 를 동일한 quadrant 에 위치시키기 위해 우리는 baseline matrix 를 구해야 한다. 이는 dependency structure amnong topic 을 최대화 시키는 녀석이어야 함.</p>
<p>이는 곧 topic 의 latent position 의 변화를 보여줌에 있어서 도움을 크게 줌. 왜냐? 각 matrix <span class="math inline">\(X_i\)</span> 로부터의 rotated positions <span class="math inline">\(A_i\)</span> 는 원점으로부터 가장 뻗어있는 (stretched, 멀리 떨어져 있는) 네트워크를 기준으로 하였기 때문. 이 가장 뻗어있는 ㅔㄴ트워크에 대한 notation 은 <span class="math inline">\(A_{max}\)</span>.</p>
<ol start="4" style="list-style-type: decimal">
<li>마지막으로, 우리는 축을 회전시켜 topic 들 간의 관계의 해석성을 높이고자 함. 이 회전에는 <code>oblique factor roation</code> 을 사용. 이 과정들을 적용한 후 우리는 각 topic 의 coordinate 의 변화를 추적하여 topic 들 간의 관계를 추정하고자 함.</li>
</ol>
<p>Latent Space Item Response Model 구현</p>
<p>3.1. python 네이티브로 모델 설계</p>
<p>해당 알고리즘의 구현은 1차적으로 python 으로 진행되었다. 해당 패키지를 제작하는 1차적인 목표는 다름이 아닌 통계적 백그라운드가 부족한 유저도 해당 알고리즘을 활용하기 용이한 형태로 배포하는 것에 있다. 이러한 목적을 감안할 때 해당 알고리즘을 구현하기 위한 언어를 선정함에 있어 점유율이 높은 언어를 우선하는 것은 지극히 타당하다. 다양한 설문조사 및 통계를 기반으로 살펴보았을 때, 웹 환경과 모바일 환경을 제외하였을 때 파이썬의 점유율은 다양한 분야에 걸쳐 상위권을 놓치지 않고 있으며 1등을 차지하는 경우도 드물지 않다.[^주석] 따라서 타 언어에서의 구현보다 파이썬에서의 구현을 우선하는 것은 충분한 타당성을 지닌다.</p>
<p>이렇게 파이썬에서 구현하고자 할 경우 몇가지 고려되어야 할 부분들이 존재한다. 우선 해당 알고리즘은 BTM 알고리즘 적용 과정에서 각 주제 하에서의, 각 단어의 출현 확률을 따지며, 또한 latent coordinate 를 각 주제마다 2개 추정하므로 결국 2차원 행렬을 다루는 것이 필수불가결하다. 그러나 여기서 python 은 R 과 달리 자체적으로는 2차원 행렬 연산를 지원하지 않으므로 2차원 행렬을 구현하기 위해 외부 라이브러리를 도입해야 한다. 이러한 선형연산 자체만 본다면 가장 강력하면서도 널리 사용되는 라이브러리는 <code>numpy</code> 이나, 해당 라이브러니는 자료형이 숫자일 때의 행렬을 담아두는 것에 특화되어 있다. 그러나 해당 알고리즘의 경우 자연어처리값을 담아두는 과정에서 숫자 이외의 자료값을 행렬에 담아두어야 하는 상황이 존재한다. 따라서 해당 상황을 고려하여 <code>numpy</code> 와 <code>pandas</code> 양쪽 라이브러리 모두를 사용한다.</p>
<p>또한 알고리즘 상에서 자연어처리</p>
<p>3.1.1. python 네이티브에서의 속도 퍼포먼스</p>
<p>속도 퍼포먼스 예시로서 이하의 샘플을 사용한다.</p>
<table>
<thead>
<tr class="header">
<th align="center">문서갯수</th>
<th align="center">corpus</th>
<th align="center">주제갯수</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">15281</td>
<td align="center">3079</td>
<td align="center">10</td>
</tr>
</tbody>
</table>
<p>이를 통해 현재의 속도 퍼포먼스를 측정하고자 한다. corpus 갯수에 따른 속도를 측정하기 위하여, 총 corpus 의 1퍼센트부터 100퍼센트까지 1퍼센트p 간격으로, 즉 corpus 30개부터 3079개 전부를 사용하는 각 상황에서의 소요 시간을 측정한다. 이를 그래프로 나타내면 이하와 같다.</p>
<div class="figure">
<img src="" alt="" />
<p class="caption">plot_for_each_corpus_usages</p>
</div>
<p>주제의 갯수를 가리키는 패러미터를 <span class="math inline">\(K\)</span>로 지정하자. 이때 50퍼센트, 즉 corpus 1500개 가량에서 iteration 1회에 약 10회가 소모된다. 이는 곧 단순 산술계산하였을 때 해당 알고리즘을 제안한 논문에서 사용한 iteration 횟수인 55000을 적용하였을 경우 총 소모시간은 <span class="math inline">\(10 * 55000\)</span>초, 즉 약 6일이 소모된다는 것을 말한다.</p>
<p>단순 iteration 에서 시간이 이만큼이나 걸린다는 것은 정상적으로 사용 가능한 종류의 패키지라고 보기 어렵다. 따라서 해당 패키지를 배포하기 위해서는 속도 퍼포먼스 관련하여 최적화할 필요가 요구된다.</p>
<p>3.2. python에 c++ 접합한 모델 설계</p>
<p>시간 최적화에 고려해볼 수 있는 요소는 다양하다. 대표적으로는 이하와 같은 요소들을 고려해볼 수 있다.</p>
<ul>
<li>알고리즘 최적화</li>
<li>자료구조 최적화</li>
<li>반복문 최소화</li>
</ul>
<p>/<em>또한 n번 반복하는 iteration이 <span class="math inline">\(a\)</span>개라고 쳤을 때, 이의 반복을 <code>for</code> 문에만 의존하였을 때 이의 시간복잡도는 <span class="math inline">\(O(n^a)\)</span></em>/</p>
<p>그러나 현재 해당 패키지는 내부연산 중에 많은 부분을 외부 라이브러리에 의존하고 있어 이러한 부분에서 건드릴 수 있는 포인트는 다소 한정적이다. 따라서 기존의 패키지 구성을 크게 터치하지 않는 방향에서 이를 해결할 방법을 모색하자.</p>
<p>이때 가장 간단하면서도 직접적인 방법은 파이썬이 아닌 속도가 빠른 단어로 해당 알고리즘을 구현하는 것이다. 파이썬은 인터프리터 언어로 작성 및 활용도 측면에서는 타 언어들에 비해 부동의 강점을 지니지만, 언어의 태생적인 속도의 경우 컴파일 언어에 비해 다소 희생한 부분이 존재한다. 이에 대해서는 이하를 참조.</p>
<div class="figure">
<img src="" alt="" />
<p class="caption">comparison between other programming languages by graph</p>
</div>
<p>실제로 통계상 c++과 파이썬 사이의 속도차이는 극단적인 상황에서는 약 10배 가량 나고 있다. 따라서 c++ 로 해당 알고리즘을 작성한다면 현재 직면하고 있는 문제의 대다수는 해결할 수 있을 것.</p>
<p>그러나 이러한 목적 하에 해당 알고리즘을 컴파일 언어만으로 패키지를 작성한다면 앞서 언급하였던 “사용률이 높은 단어로 패키지를 작성하고자 하는 목적”에 부합하지 않게 될 것이다. 따라서 이러한 방향성을 가감없이 수용하는 것은 불가능하다.</p>
<p>그러나 해당 방안을 가감하여 수용한다면 해당 방안은 직면하고 있는 문제에 대한 강력한 해결책이 될 수 있으며, 실제로 이를 양립할 수 있는 방법이 있다.</p>
<p>파이썬의 내부 구조를 살펴보면, 파이썬 자체는 파이썬 자체적인 문법을 따르는 인터프리터 언어이되 실제로 스스로를 실행하는 타이밍에는 스스로를 c++로 컴파일해서 실행하는 구조로 구성되어 있다. 따라서 적절한 전처리가 이루어진 컴파일된 c++ 코드는 파이썬의 인터프리터 단을 거치지 않고 바로 컴파일 단에 포함시켜서 실행시키는 것으로, 파이썬에 포함하여 파이썬 실행시에 해당 알고리즘을 c++의 성능으로 활용하는 것이 가능하다.</p>
<p>/<em>주로 시간을 잡아먹는 부분은 역시 iteration 파트와 gibbs sampling (각 부위별 소모시간 표로) / dynamic programming을 응용하여</em>/</p>
<p>이때, c++ 에서 다루는 자료형과 python 에서 다루는 자료형은 직접적으로 호환되지 않는다. 따라서 c++ 에서 출력한 값을 python 에서 받아서 활용하기 위해선, c++ 에서 생산한 값을 받아 파이썬이 인식할 수 있는 값으로 바꿔주는, 앞에서 언급한 소위 ‘적절한 전처리’ 에 해당하는 일명 <em>‘래핑함수’</em> 의 존재가 필수불가결하다.</p>
<p>래핑함수를 위한 선택지는 크게 이하의 3가지가 존재한다:</p>
<ol style="list-style-type: decimal">
<li><code>Cython</code> 라이브러리</li>
<li><code>pybind11</code> 라이브러리</li>
<li>필요에 맞게 래핑 함수를 직접 작성</li>
</ol>
<p>인풋 아웃풋 효율 문제와 신뢰성 문제로 코드를 직접 짜기보다는 외부 라이브러리 사용. 여기선 범용적으로 사용되는 래핑용 라이브러리인 <code>pybind11</code>을 사용하겠다.</p>
<p>Wrapping Timing</p>
<p>위에서 확인하였듯 c++ 에서의 처리속도는 python보다 빠름. 그러나 c++에서 생산한 값을 python 단에서 받을 때, 속도가 급격하게 느려지는 현상 발생함.</p>
<p>이러한 문제점들을 고려할 때 iteration 부분 작업을 최대한 c++ 파트에 몰아넣은 후 모든 iteration을 처리하였을 때 값을 수령해야함.</p>
<p>그러나 이렇게 몰아넣는다고 한다면 파이썬 파트에서 현재 <code>numpy</code> 형식으로 데이터를 처리하고 있으므로 c++ 쪽에서도 <code>numpy</code> 형태에 맞추어 값을 전달해야 하나 c++ 쪽에서 직접적으로 <code>numpy</code> 자료형을 지원하는 것은 불가능.</p>
<p>이를 해결하기 위해 c++ 쪽에서 획득한 결과값을 모두 container에 포함시킨 후 파이썬 쪽에서 수령한 후 해당 컨테이너에서 값을 꺼내어 numpy 자료형에 맞도록 재배치. 다소 시간의 손실은 있을지언정 각 iteration마다 값을 수령하는 것보다는 훨씬 빠름.</p>
<p>Library needed in <code>c++</code></p>
<p>위에서 iteration 파트를 c++에서 모두 돌리기로 결정하였다. 여기서 iteration 은 크게 2개, BTM 부분과 lsirm 파트. 이 둘은 모두 2차원 행렬에 대해 적용되므로 c++ 에서 활용할 수 있는 선형연산 수단이 필요함. c++ 자체로 선형연산을 지원하고 있지는 않으므로 c++ 라이브러리를 적용해야 함.</p>
<p>c++에서 사용할 수 있는 메이저한 선형연산 라이브러리에는 크게 <code>armadillo</code> 와 <code>eigen</code> 의 2가지가 존재. 둘사이의 차별점을 정리하면 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="center">Package</th>
<th align="center"><code>armadillo</code></th>
<th align="center"><code>eigen</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Matrix Multiplication</td>
<td align="center">available</td>
<td align="center">available</td>
</tr>
<tr class="even">
<td align="center">More than 2d Matrix</td>
<td align="center">cube (3d)</td>
<td align="center">-</td>
</tr>
<tr class="odd">
<td align="center">generating function for probability</td>
<td align="center">None</td>
<td align="center"><span class="math inline">\(Dirichlet\)</span></td>
</tr>
</tbody>
</table>
<p><code>eigen</code> 또란 확률생산 기능이 <code>armadillo</code> 보다 강력하다는 점에서 충분한 차별점을 지니고 있음. 그러나 해당 패키지에서는 이터레이션 내부에서 2차원 행렬을 샘플로서 여러번 생산해 이를 묶어서 파이썬으로 보내야 함. 이인즉 이를 3차원 행렬로 인식할 수 있다는 것이며, 이는 곧 3차원 행렬을 지원하는 쪽이 데이터를 다룸에 있어서 유리하다는 것을 의미함. 따라서 3차원 행렬을 지원하는 <code>armadillo</code> 를 <code>eigen</code> 보다 우선하여 채택한다.</p>
<p>3.2.1. 접합 모델 검증 및 성능 비교</p>
<p>위에서 사용했던 예시와 동일하게 속도 퍼포먼스 예시로서 이하의 샘플을 사용한다.</p>
<table>
<thead>
<tr class="header">
<th align="center">문서갯수</th>
<th align="center">corpus</th>
<th align="center">주제갯수</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">15281</td>
<td align="center">3079</td>
<td align="center">10</td>
</tr>
</tbody>
</table>
<p>위와 동일한 방법으로 corpus 갯수 별 소모시간을 그래프로 표기하면 다음과 같다.</p>
<div class="figure">
<img src="" alt="" />
<p class="caption">plot_for_each_corpus_usages</p>
</div>
<p>보면 알 수 있듯이 python 에서 이터레이션을 진행했을 때에 반해 평균 약 3배의 속도 향상을 보임. 실사용 가능한 수준으로 유의미하게 개선되었다고 볼 수 있다.</p>
<p>Implementation</p>
<p>이 section은 앞에서 제시한 알고리즘을 string input 에 실적용할 수 있는 <code>topic_cluster_visualizer</code> 패키지의 function에 대해 논한다. 해당 package 는 <a href="https://pypi.org/project/topic-cluster-visualizer/" class="uri">https://pypi.org/project/topic-cluster-visualizer/</a> 에서 설치할 수 있으며, python 환경에서는 이하의 command 를 실행하는 것으로 설치할 수 있다.</p>
<p>The latest version of <code>topic_cluster_visualizer</code> can be installed directly from PyPI repository of <code>Python</code> pacakges using:</p>
<pre><code>pip install topic-cluster-visualizer</code></pre>
<p>The package requires:</p>
<ul>
<li><code>Python</code> programming language</li>
<li><code>numpy</code>, a package for efficient manipulation manipulation of multidimensional arrays,</li>
<li><code>pandas</code>, a package for efficient manipulation manipulation of non-numeric 2-dimensional arrays,</li>
<li><code>plotly</code>, a plotting package,</li>
<li><code>factor_analyzer</code>, a package for</li>
<li><code>nltk</code>, a package for Natural Language Processing (NLP)</li>
<li><code>gensim</code>, a package for Natural Language Processing (NLP)</li>
<li><code>pybind11</code>, a <code>python</code> library for wrapping <code>c++</code> function module for multiple iteration part</li>
</ul>
<p>And also system must support <code>c++</code>, which means c++ tools have to be installed.</p>
<p><code>topic_cluster_visualizer</code> 는 크게 4가지로 나뉜다.</p>
<ul>
<li><code>preprocess()</code>: <code>word2vec</code> 을 통해 corpus 획득</li>
<li><code>btmize()</code>: corpus list 를 넣으면 Biterm Model 을 통해 각 corpus 들에 확률을 부여</li>
<li><code>lsirmize()</code>: 부여된 확률 기반으로 Gibbs Sampling 을 돌려서 각 corpus 들의 latent topic 을 추정하고 추정한 topic 들의 latent coefficient 추정</li>
<li><code>fit()</code>: 획득한 latent space coefficient 들에 procrustes matching 2번과 oblique rotation 을 적용하여 동일 quadrant 에 coefficient 들을 배치시켜 해당 주제들간의 interaction 시각화</li>
</ul>
<p>The functions feature a consistent syntax. The following are the arguments of the fisher()
function as an illustration.</p>
<pre><code>python&gt; args(fisher)
function (p, adjust = &quot;none&quot;, R, m, size = 10000, threshold,
side = 2, batchsize, nearpd = TRUE, ...)
NULL</code></pre>
<p>We will explain the purpose of the various arguments in the following sections.</p>
<pre><code>class TopicClusterVisualizer:
    def __init__(self, target_data):</code></pre>
<p>need to be initialized with <code>target_data</code>, which is wanted to be analyzed.</p>
<p><code>preprocess()</code></p>
<pre><code>preprocess(self, train_data = None, keywords = None, train = False):</code></pre>
<p>상기하였듯이 해당 함수에서는 자연어처리하여 corpus 를 획득. 이는 이하와 같은 절차로 이루어진다. 이의 기본적인 corpus 처리는 <code>nltk</code> 패키지를 통해 이루어지며, 해당 word2vec 기반 자연어처리를 활성화시켰을 경우 이는 <code>gensim</code> 패키지의 <code>word2vec()</code> 함수를 이용한다.</p>
<p>절차는 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>python 내부에서 자연어처리. 입력값으로 받은 다수의 documents 들을 1차적으로 자연어처리하여 corpus 로 분해. word_tokenize
이때 tagging 해서 건지는 언어는 명사와 형용사로 한정한다 - 명사는 주제어, 형용사는 주제어를 수식할 수 있으나 동사는 상대적으로 주제를 드러냄에 있어서 그 역할이 약함</li>
</ol>
<p><br></p>
<ol start="2" style="list-style-type: decimal">
<li>모드 따라서 변경. <br><code>train</code> 사용을 끌 경우 단순 NLP 후 corpus 생산에서만 끝냄. 이는 corpus 빈도에 따른 필터링 없이 생산된 모든 corpus 들을 다 사용하므로 퀄리티 크게 낮아짐. 입력된 train용 값들과 keyword용 값들을 총합하여 model 생성. using internally-used-only function <code>_train_corpus</code>.<br><br><code>train</code> 사용을 켤 경우 word2Vec 을 적용. 적용의 구체적인 프로세스는 이하와 같다.
<ol style="list-style-type: decimal">
<li>우선 <code>train_data</code> 통하여 word2Vec 을 통하여 모델 생산.</li>
</ol>
<ul>
<li>min_freq 라는 변수 임의로 지정. keyword 와 corpus 출현 단어들 중 최소한도 이상으로 출현하는 단어들 추려내기 위한 바로미터.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>키워드에서 상위출현 단어 골라내고, 키워드에서 골라낸 상위출현 단어 중에서, (일례로 a) a가 model 에서 판정한 단어에 포함되어 있다면, a와 유사도가 높은 단어들을 포함시킨다. 패러미터 <code>near_term_topn_val</code> 사용. 디폴트값은 10.
term 이 인풋되었을 때, 그것이 우리가 제작한 모델에 속해있는 term이라면, - model.wv.key_to_index.keys() 라는 값을 사용한다. 해당 term 과 유사도가 높은 단어를 뽑아둔다 - model.wv.most_similar(term, topn=near_term_topn)]</li>
<li>corpus에서 상위출현 단어 골라내고. 앞에서 모델과 keyword 간의 교집합 단어들과의 높은 유사도 단어랑, corpus 단어와의 교집합만 뽑아서 저장한다.</li>
</ol></li>
</ol>
<p>※ run with <code>train</code> parameter as 1 is STRONGLY RECOMMENDED. performance of the algorithm is drastically weakened without <code>word2vec</code> sequence.</p>
<p><code>btmize()</code></p>
<p>위에서 획득한 corpus 들을 BTM 알고리즘을 통하여 샘플 갯수를 늘린 후 각 주제 하에서의 등장 확률을 추정. BTM 을 거치는 이유는 최대한 샘플 갯수를 늘려 추정의 정확성을 높이기 위함. 각 document 로부터 추려낸 단어들 각각에 대해 BTM 적용해서, 얘들을 각각 쌍으로 묶어서 sample 의 절대개수를 늘림. 이렇게 절대개수를 늘린 샘플들에서 바탕에 두고 있는 샘플의 개수를 empirical 하게 세팅하고, MCMC 방법론을 통해 이터레이션을 다횟수 돌리는 것으로 매 이터레이션에서 각 단어의 출현 확률을 보정해나감.</p>
<p>이 이터레이션의 속도를 높이기 위해 pybind11 으로 래핑한 <code>btm_cpp</code> 함수 도입. 해당 함수의 argument 는 이하와 같다.</p>
<p><code>lsirmize()</code></p>
<pre><code>lsirmize(
    percentage_range = [50],
    
    data,

    ndim = 2, 
    niter = 55000, 
    nburn = 5000, 
    nthin = 5, 
    nprint = 5000,
            
    jump_beta = 0.28,
    jump_theta = 1.0,
    jump_gamma = 0.01,
    jump_z = 0.06,
    jump_w = 0.06,
    
    pr_mean_beta = 0,
    pr_sd_beta = 1,
    pr_a_th_sigma = 0.001,
    pr_b_th_sigma = 0.001,
    pr_mean_theta = 0,
    pr_a_sigma = 0.001,
    pr_b_sigma = 0.001,
    pr_mean_gamma = 0.0,
    pr_sd_gamma = 1.0,
    
    missing = 99
)</code></pre>
<p>해당 함수에서는 위의 BTM 과정을 거쳐 각 주제가 조건으로 주어졌을 때, 각 단어에 부여된 확률 기반으로 Gibbs Sampling 을 돌려서 각 corpus 들의 latent topic 을 추정하고 추정한 topic 들의 latent coefficient 추정한다. 이때 부여해둔 값은 원본 논문에서 이터레이션용 하이퍼패러미터로 사용했던 값들에 해당한다. 변경이 필요하다면 입력한 후 사용.</p>
<p>상술하였듯이 해당 알고리즘을 돌림에 있어서 다양한 corpus 확률 범위에 걸쳐 알고리즘을 돌려본 후, corpus 범위별로 판정된 주제의 coordinate 를 2차원 그래프에 매핑한다. 따라서 확률 범위를 정해주는 것이 필요하다. 해당 확률 범위는 % 단위로 디폴트값은 50 하나로 설정되어 있다. 만약 여러가지 구간에 걸쳐 corpus 비율을 설정하고 싶다면 상응하는 확률구간의 % 값을 list 혹은 tuple 자료형으로 입력하면 된다. 가령 50퍼센트부터 55퍼센트 구간까지 1퍼센트p 차이로 coordinate 변화를 체크하고 싶다면 <code>[50,51,52,53,54,55]</code>를 패러미터로 주면 된다.</p>
<p>이때 언급하였듯이 해당 파트에서의 깁스 샘플링에서의 이터레이션의 속도를 높이기 위해 <code>pybind11</code> 으로 래핑한 <code>c++</code> 함수를 도입해주어야 한다. 해당 패키지에서는 이를 위하여 using internally-used-only function <code>onepl_lsrm_cont_missing</code> 함수를 도입하였다. 해당 함수의 parameter 는 이하와 같다.</p>
<pre><code>std::vector&lt;py::array_t&lt;double&gt;&gt; onepl_lsrm_cont_missing
(
    arma::Mat&lt;double&gt; data,

    const int ndim,
    const int niter,
    const int nburn,
    const int nthin,
    const int nprint,

    const double jump_beta,
    const double jump_theta,
    const double jump_gamma,
    const double jump_z,
    const double jump_w,

    const double pr_mean_beta,
    const double pr_sd_beta,
    const double pr_a_th_sigma,
    const double pr_b_th_sigma,
    const double pr_mean_theta,
    const double pr_a_sigma,
    const double pr_b_sigma,
    const double pr_mean_gamma,
    const double pr_sd_gamma,

    const double missing
)</code></pre>
<p><code>c++</code> 로 작성했기에 데이터형이 <code>c++</code> 기반으로 쓰여있긴 하나 이 자체는 <code>python</code> 함수로서 작동한다. 해당 함수는 각 확률구간마다 lsirm 파트를 실행한 후, lsirm 을 통해 각 이터레이션 별로 획득된 패러미터의 값들을 총합하여 해당 확률구간에서의 패러미터를 추정한다. 이를 통해 결과값은 <code>dict</code> 포맷으로 반환되며, 해당 <code>dict</code> 에는 <code>z</code>, <code>map</code>, <code>phiwz</code>, <code>words</code> 의 4가지 key 가 존재한다. 각각의 담고있는 내용은 이하와 같다.</p>
<ul>
<li><code>z</code>: 각 이터레이션에서 추정된 각 주제별 2차원 latent coordiante. ofiteration × oftopics × 2 크기의 행렬.</li>
<li><code>map</code>: 각 이터레이션 별로 얻어진 원점과의 총 거리.</li>
<li><code>phiwz</code>: topic <span class="math inline">\(z\)</span> 가 주어졌을 경우의 corpus <span class="math inline">\(w\)</span> 의 출현확률</li>
<li><code>words</code>: 해당 corpus 에서 어떤 corpus 들이 사용되었는가</li>
</ul>
<p>구현 모델 실적용 예시
4.1 데이터 서술</p>
<p>상술하였듯이 해당 알고리즘의 결과값을 도드라지게 만들기 위해서는 문단이 짧으면서도, 해당 문단의 의미하는 바가 명확한 글줄들을 입력값으로 넣었을 때 결과값이 도드라진다. 따라서 만족스러운 결과를 위해 해당 조건에 맞는 데이터를 사용하자.</p>
<p>앞서 언급하였듯이 해당 논문의 목적은 특정 연구분야를 빠르게 개괄하고 이를 유저에게 제공하는 것에 있다. 따라서 이의 실사용례를 제공하기 위해선 특정 연구분야를 정해야 할 필요가 있다. 가령 아래와 같은 주제는 어떨까. 2016년 알파고의 등장 이래 분야를 가리지 않고 딥러닝을 위시한 컴퓨터 과학에 대한 관심이 증가하였다. 특히 경영학에서는 MIS 라는 이름으로 타 분야에 비해 학문 자체에서 컴퓨터를 다루는 비중를 다루는 비중이 다소 높았던 편이다. 이러한 측면을 감안할 때 알파고의 도래 이후 모든 학문영역에 미쳤던 충격은 경영학에게 있어서는 크면 컸지 작다고 보기 어려울 것이며, 이는 곧 알파고 등장 이후 학계 논문의 주제 트렌드에 있어서 변화가 있지 않았을까 하는 의심을 품는 것에 대한 합리성을 부여해준다. 이러한 생각을 가정하였을 때 우리는 MIS 에서 딥러닝 등장에 따른 학계 논문의 주제 변화를 살펴보는 것으로 학계의 딥러닝에 대한 반응을 확인할 수 있다.</p>
<p>우리는 해당 알고리즘에서 상위 몇퍼센트의 corpus 를 주제 추정에 사용할 것인가에 대한 확률구간을 임의로 설정하고 각 확률구간에서의 latent coordinate 를 살펴볼 수 있다. 이때 해당 주제에 속한 논문들의 논지가 해당 주제에 확고하게 묶여있다면 이런 확률구간의 변화에 따른 coordinate 의 변화는 크지 않을 것이며 이에 따라 latent coordinate 들은 각각 어떤 형태의 cluster 를 이루게 될 것이다. 반면 해당 주제의 coordinate 들이 cluster 를 이루지 못하고 확률구간의 변화에 따라 2차원 상에서 계속 움직이는 꼴이 된다면 이는 곧 해당 주제 속한 문헌들의 주제가 해당 주제에 확고하게 묶여있지 못하다는 것으로, 해당 문헌들의 주제가 명확하게 드러나는 것이 아닌 다소 두루뭉술하다는 것을 나타낸다고 인식될 수 있다. 이는 바꾸어 말하면 해당 주제가 부차적인 영역에 그쳤다는 것일 것이므로 학계 내에서의 해당 주제의 입지가 그리 높지 않다는 것으로 해석될 수 있을 것이다. 따라서 곧 논문 주제의 cluster 정도를 살피는 것은 우리가 목표로 하는 경영학에서의 MIS 분야가 딥러닝 도래에 어떤 반응을 보였는지에 대한 인식을 확인할 수 있는 수단이 된다.</p>
<p>이를 분석하기 위해 알파고의 등장인 16년을 기준으로 하여 17년부터 21년까지의 경영학 학계에서의 MIS 관련 논문들의 5년치 데이터를 모아 위의 알고리즘을 통하여 분석을 진행하자. 해당 조건에 맞는 데이터로는 논문 아카이브 사이트인 Web of Science 에서 Management, Business 분야의 논문들 중 MIS 를 다루는 논문들로부터의 abstract 를 확보하여 진행하였다. 이렇게 획득한 데이터와 empirical 하게 지정한 주제의 개수를 서술하면 이하와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="center">문서갯수</th>
<th align="center">corpus</th>
<th align="center">주제갯수</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">15281</td>
<td align="center">3079</td>
<td align="center">10</td>
</tr>
</tbody>
</table>
<p>4.2 알고리즘 결과</p>
<p>이렇게 획득한 데이터에 위의 패키지를 적용하여 시각화한 결과를 획득하였다. 이때 타 확률구간에 대한 procrustes matching 에 있어 기준선으로 작동한, 가장 거리가 멀었던 확률구간 기준으로 표기한 coordinate 는 이하와 같다.</p>
<div class="figure">
<img src="" alt="" />
<p class="caption">plot_for_max_matrix_coordinate</p>
</div>
<ul>
<li><strong>TOPIC NEED TO BE NAMED</strong></li>
</ul>
<p>상술하였듯이 일련의 과정을 통해 얻어지는 주제는 단순히 다를 뿐 이 각각 다른 주제가 무엇에 대한 것인지에 대해서는 오롯이 연구자의 몫으로 남아있습니다. 이 이름을 어떻게 지정할 것인가에 대해서는 분석을 진행하는 연구자의 주관에 따라 결정되어야 할 것입니다. 이를 위해 해당 패키지에서는 설정한 확률 구간에 따라 사용된 corpus들이 무엇인지를 반환하는 attribute 로 <code>lsirmize()</code> 함수에 의해 배정되는 <code>words</code> attribute 가 배정되어 있습니다. 해당 attribute 를 사용해서 주관적으로 이름을 지정해주십시오. 본 논문에서 주제를 명명함에 있어서는 이하와 같은 룰로 이름을 지정하겠습니다.</p>
<ol style="list-style-type: decimal">
<li>타 논문에서 출현하지 않은 corpus를 최우선으로 참고하여 이름 지정</li>
<li>위에서 이름을 지정한 주제군을 제외하고 나머지 주제군으로 corpus 사용 여부를 참고하여 이때 출현하지 않은 corpus 를 기준으로 이름 지정</li>
<li>최종적으로 이름이 지정되지 않은 주제군들이 있을 경우, 타 주제들을 통하여 각 coefficient 들의 대소가 갖는 의미를 추측한 후 이를 참고하여 주제들의 coefficient 들과 겹치는 corpus 들을 통해 주제의 이름 추정</li>
</ol>
<p>이를 위하여 각 documents 들에서 유일하게 등장한 corpus 들과, 그렇지 않은 corpus들 중 고확률로 등장하였던 corpus 들을 나타내면 다음과 같습니다.</p>
<table>
<colgroup>
<col width="23%" />
<col width="38%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Unique Corpus</th>
<th align="center">High-probability Corpus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">‘load-depend’, ‘lithium-ion’, ‘n-vehicl’, ‘europcar’, …</td>
<td align="center">‘econometr’, ‘guidelin’, ‘socio-techn’, ‘reproduct’, …</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">‘human-machine-environ’, ‘datasheet’</td>
<td align="center">‘guideline, ‘budget-constraint’, ‘fintech’, ‘classification-base’, …</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">‘eql’ (equity loan)</td>
<td align="center">‘naval’, ‘sea-land’, ‘risk-rel’, ‘blockchain’, ‘obsolesce’, …</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">-</td>
<td align="center">‘state-of-the-art’, ‘ubiquitous’, ‘seaport’, ‘warehous’, ‘techniq’, …</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">‘incentive-bas’, ‘s-crm’, ‘nation-dyad’, ‘ai-aug’, ‘accultur’, …</td>
<td align="center">‘discret’, ‘transact’, ‘state’, ‘civil’, ‘telemat’, ‘transform’, …</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">-</td>
<td align="center">‘techniq’, ‘cross-sect’, ‘transmiss’, ‘worldwide’, ‘sement’, ‘agricult’, …</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">‘margin-trad’, ‘future-focus’, ‘protection-motiv’</td>
<td align="center">‘mathematic’, ‘econometr’, assess’, ‘itil’, …</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">‘reuse-bas’, ‘geo-ecolog’, ‘molybdenum-contain’, …</td>
<td align="center">‘textile’, ‘robust’, ‘retrain’, ‘quantity-pay’, ‘geograph’, …</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">‘assemble-to-ord’, ‘evm’, ‘chat-bot’, ‘feature-process-machin’, …</td>
<td align="center">‘transboundary’, ‘quantity-pay’, ‘translat’, ‘multi-type’, …</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">‘hardware-softwar’, ‘regime-switch’, ‘competition-bas’, …</td>
<td align="center">‘benchmark’, ‘simulat’, ‘ontology-bas’, ‘human-computer’, …</td>
</tr>
</tbody>
</table>
<p>이에 기반하여 위에서 서술하였던 룰에 따라 주제를 명명하면 다음과 같습니다.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Name of Topics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">전기차</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">Excel 등 DB 관리</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">회계 분야에서의 신기술 사용 관련</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">최신기술, DB 관리</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">이문화 조직구성원 간 소통</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">글로벌, 분야간 통섭</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">금융시장 분야</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">지속 가능한 환경경영</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">비트코인 위시한 블록체인 및 딥러닝 관련</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">경영 최전선에서의 디지털 기술 활용</td>
</tr>
</tbody>
</table>
<p>이제 주제를 명명한 바 이상으로 해당 데이터들에 대한 인사이트를 획득하기 위해 각 확률구간에 따른 coordinate 의 변화를 확인하겠습니다. 이는 다음과 같습니다.</p>
<div class="figure">
<img src="C:/Users/Song1/Documents/GitHub/202201_phd_paper/newplot%20(9).png" alt="" />
<p class="caption">plot_for_each_matrix_coordinate</p>
</div>
<p>여기서 타 사분면들 대비 1, 4분면 근방의 점이 많다는 점을 통해 근 5년간 딥러닝을 위주로 한 컴퓨터 과학 기술이 발전하였음에도 여전히 mis 논문들은 고전적인 경영학 이론을 다루는 경우가 많다는 것을, 그리고 네이처나 서스테이너블한 요소보다는 지오그래피컬한 실제적이고 구체적인 주제에 집중하고 있다는 사실을 파악할 수 있습니다.</p>
<p>이때 여기에, 결과의 시인성을 높이기 위해 확률구간의 변화에 따른 coordinate 이동을 화살표로 명시해주는 것으로 주목해볼 만한 유의미한 인사이트를 얻을 수 있습니다.</p>
<div class="figure">
<img src="C:/Users/Song1/Documents/GitHub/202201_phd_paper/Rplot03.bmp" alt="" />
<p class="caption">trajectory_for_each_matrix_coordinate</p>
</div>
<p>아까 말씀드렸듯이 동일 컬러링 상에서의 서로 다른 점들은 해당 topic 에서 확률구간에 따라 서로 다르게 나타난 coordinate 로, topic에서의 각 확률구간마다 corpus 등장 확률에 기반하여 추정에 사용된 corpus 데이터가 다릅니다. 확률 구간을 좁게 잡으면 가령 상위 40%의 확률로 등장하는 corpus들만이 주제 추정에 사용되지만 확률 구간을 넓혀감에 따라 최종적으로 상위 60%까지의 corpus들이 주제 추정에 사용되게 됩니다. 이는 곧 토픽 추정에 사용되는 corpus의 총량이 변화한다는 의미이며 이에 따라 추정된 주제의 형태가 변하는 경우가 발생하는 것은 당연하다고 말씀드렸습니다.</p>
<p>그러나 trajectory 를 보시면 확인하실 수 있듯이 디지털 경향이 강한 topic이 아날로그 쪽이나 organization 쪽으로 주제가 변하는 경우는 없으며 반대 또한 마찬가지입니다. 즉 확률 구간에 따른 topic의 coordiante 의 이동이 각 axis의 양 극단을 쌍으로 하여 그 사이에서만 이루어지고 있으며 이는 mis 연구에서의 방법론 현황에 대한 주목해볼 만한 단서를 던져줍니다.</p>
<p>즉 topic 들 중 소속된 문헌이 하나의 강력한 주제에 묶여있는 것이 아니어서 corpus 사용량에 따라 추정된 topic 이 변화하는 케이스에서조차도, nature 나 서스테이너빌리티의 관점을 다룬 topic이 클래시컬한 기존 경영학에서의 관리 일원들이나 아날로그한 측면의 토픽들과는 어울리지 못하고 디지털 및 테크놀로지 관점과만 상호 작용하고 있는 것입니다. 또한 역으로 logistic 이나 geography 측면의 터팩들은 analogue와 technology 사이에서 균형을 잡은 이론이 한계일 뿐 디지털 디지털 측면에 치우친 topic은 찾기 어렵습니다.</p>
<p>이는 곧 필드를 불문하고 학계 전체에 충격을 주었던 딥러닝 혁명이 아직 디지털 분야에서만 한정되어 논해지고 있다고 볼 수 있으며 딥러닝 혁명이 가지는 강력한 잠재력을 볼 때 이는 학계에 있어 커다란 손실이라고 할 수 있을 것입니다. 이러한 부분을 보완하여 서스테이너빌리티 측면과 클래식한 기존 경영학 이론을 좀 더 적극적으로 융합한 논문이 늘어나는 것을 통해 학계에서 진행되는 논의 토양이 조금 더 비옥해질 수 있지 않을까 조심스레 제안해 봅니다.</p>
<p>결론</p>
<hr />
<hr />
<p>Network (adjacency Matrix)
-&gt; Network Statistics <span class="math inline">\(S(y)\)</span>, which capture characteristics of network
-&gt; plug-in network statistics with their corresponding prameteres into the exponential term <span class="math inline">\(\underbrace{\exp \Big (\sum_{i=1}^p \theta_i S_i(y) \Big )}_{\text{unnormalized density}}\)</span>
-&gt; <span class="math inline">\(P_\theta (Y=y) = \frac{1}{\kappa(\theta)} \exp \Big( \sum^p_{i=1}\theta_i S_i(y) \Big)\)</span>, to make a valid prob.</p>
<ul>
<li><span class="math inline">\(\kappa\)</span>: normalizing constant</li>
<li><span class="math inline">\(\theta_i\)</span>: parameters measuring the strength of effects of <span class="math inline">\(S_i(y)\)</span></li>
<li><span class="math inline">\(S_i(y)\)</span>: network statistics</li>
</ul>
<p>-&gt; but extremely difficult to extimate. (1) doubly-interatable normalizing constant</p>
<p>-&gt; also, called as a <strong>Markov Network</strong>, 여기서 Markov 라는 단어는 status of edge depends on a status of other edge 하는 성질을 가리킴</p>
<p><span class="math display">\[
\theta_1 (\underbrace{\text{ of edge}}_{\substack {\text{homophily effect} \\ \text{dyadic *in*dependent stat.}}})
+
\theta_2 (\underbrace{\text{ of triangle}}_{\substack {\text{transitivity effect} \\ \text{dyadic dependent stat.}}})
\]</span></p>
<p><strong>dyadic independent statistics</strong>: a status of dyad does not depends on the status of other dyads.</p>
<p><mark><span class="math inline">\(S(y) = \sum_{i&lt;j} y_{ij}h(x_i , x_j)\)</span></mark></p>
<ul>
<li><span class="math inline">\(x\)</span>: covariate information of node</li>
<li><span class="math inline">\(x_i , x_j\)</span></li>
</ul>
<p>how we define <span class="math inline">\(h(x_i , x_j)\)</span> determines the network stats?</p>
<p><span class="math display">\[
\begin{align}
h(x_i , x_j) &amp; = \cases{1 &amp; \( x_i = x_j\) \\ 0 &amp; o.w.}
\tag{Uniform homophily effects}
\\
h(x_i , x_j, d) &amp; = \cases{1 &amp; \( x_i = x_j = d\) \\ 0 &amp; o.w.}
\tag{Differential homophily effects}
h(x_i , x_j, d) &amp; = \cases{2 &amp; \( x_i = x_j = d\) \\ 1 &amp; \( x_i = d or x_j = d and x_i \not = x_j \) (only one) \\ 0 &amp; o.w.}
\tag{Nodal Factor Effect}
\\
h(x_i , x_j) &amp; = \frac12 (x_i + x_j)
\tag{Main Effect (Continuous Case)}
\\
h(x_i , x_j , C ) &amp; = \cases{1 &amp; |x_i - x_j | = C \\ 0 &amp; o.w.}
\tag{Absolute Difference Effect}
\\
h(x_i ,x_j) &amp; = |x_i - x_j|
\end{align}
\]</span></p>
<p>상기의 1번과 2번은 <span class="math inline">\(x\)</span> 가 discrete 값일 때만 사용 가능. 이인즉 <span class="math inline">\(x\)</span> 가 factor 인 경우에만.</p>
<p>cause (2): Model-degeneracy</p>
<p>we also need to consider high-order interactions.</p>
<ol style="list-style-type: decimal">
<li>degree distribution: <span class="math inline">\(D_k(y)\)</span>, which means of node with degree <span class="math inline">\(k\)</span></li>
</ol>
<p><span class="math inline">\(\sum^{n-1}_{k=0} D_k(y) = n\)</span>: High-order interaction based on (nodes / edges / dyads) -&gt; shared partnership distribution</p>
<ul>
<li><strong>edgewise shared partnership distribution</strong>: <span class="math inline">\(EP_k(y)\)</span>, the number of unordered pairs <span class="math inline">\(9i,j)\)</span> for which i and j share k common neighbors and y_{ij}=1</li>
</ul>
<p><span class="math inline">\(\sum^{n-2}_k=0 EP_k (y) = S_1(y_1)\)</span>, <span class="math inline">\(S_1(y_1)\)</span> is high-order transitivites.
<span class="math inline">\(\sum^{n-2}_k=0 DP_k (y) = \choose n2\)</span>, <span class="math inline">\(DP_k (y)\)</span> is high-order relationships of two-stars
<span class="math inline">\(DP_k (y) - EP_k(y) = NP_k(y)\)</span></p>
<p><strong>dyadwise shared partnership distribution</strong></p>
<p><strong>non-edgewise shared partnership distribution</strong></p>
<p><span class="math inline">\(D_k(y), EP_k(y), DP_k(y)\)</span> are distribution -&gt; not plausible to plug-in -&gt; geometrically weighted statistics -&gt; summarise dist. into one statistics</p>
<p>by specifying decayed rate <span class="math inline">\(\tau\)</span>, we can construct GW statistics.</p>
<p><strong>homogeneous ERGM</strong></p>
<p><span class="math display">\[
P(Y=y) = \frac{1}{\kappa(\theta)} \exp \Big(\theta_1 S_1 (X) + \theta_2 \underbrace{T(X)}_{ of triangle} \Big)
\]</span></p>
<ul>
<li><span class="math inline">\(\theta_1\)</span>: behaves similar to density</li>
<li><span class="math inline">\(\theta_2&gt;0\)</span>: condition on edge, how likely it forms a triangle</li>
<li><span class="math inline">\(\theta_2&lt;0\)</span>: <mark>????????????????????????????</mark></li>
</ul>
<p><strong>inhomogeneous ERGM</strong> : homogenous’s all <span class="math inline">\(\theta_{1ij} = \theta_1\)</span>, $_{2ijk} = <span class="math inline">\(\theta_2\)</span></p>
<p><span class="math display">\[
P(Y=y) = \frac{1}{\kappa(\theta)} \exp \Big(\sum_{i&lt;j}\theta_{1ij} y_ij} + \sum_{i \not = j \no = k}\theta_{2jk} y_{ij}y_{ik}y_{jk} \Big)
\]</span></p>
<p>only applicable in <strong>multiplex network</strong>, which is all respondents are same but they have different networks.</p>
<p>Nomralizing constant of ERGM</p>
<p><span class="math display">\[
k(\theta) = \sum_{\text{all possible} y} \exp \Big( \sum^p_{i=1} \theta_i S_i (y) \Big)
\]</span></p>
<p>각 dyad 는 0 과 1 의 2가지 상태를 가짐. total possible <span class="math inline">\(y\)</span> 는 <span class="math inline">\(2^{\choose n2}\)</span>. 연산량 미침.</p>
<p>MCMC -&gt; frequentist
-&gt; Bayesian</p>
<ol style="list-style-type: decimal">
<li>Bayesian Inference: we assume parameters follow a distribution.
<ul>
<li>prior <span class="math inline">\(\pi(\theta)\)</span> -&gt; prior belief of parameters</li>
<li>likelihood <span class="math inline">\(f(y | \theta)\)</span></li>
<li>posterior <span class="math inline">\(\pi(\theta | y)\)</span> -&gt; posterior belief of parameters after including data</li>
</ul></li>
<li>Frequentist: parameters are fixed</li>
</ol>
<p><span class="math display">\[
\begin{align}
&amp; \propto f(y|\theta) \pi(\theta)
\\
pi(\theta|y) &amp;= \frac{f(y|\theta) \pi(\theta)}{\underbrace{\pi(y) = \int f(y|\theta)\pi(\theta)d \theta}_{\text{marginal density of }y\text{ (normalizing constant)}}}
\end{align}
\]</span></p>
<p>Generally, normalizing constant (denominator) does not depend on <span class="math inline">\(\theta\)</span></p>
<p>calculating normalizing contants involves integration, which is generally difficult</p>
<hr />
<p>Latent Space Model</p>
<p>we assume that there exists a latent space and we embedded each node into this latent space based on a connection (edge).</p>
<ul>
<li><span class="math inline">\(z_i\)</span>: latent position of node <span class="math inline">\(i\)</span></li>
</ul>
<p>Then, we try to explain a network based on a logistic regression framework.</p>
<p>Main assumption:</p>
<ul>
<li>given the latent position, each connection is conditionally independent each other.</li>
<li>latent positions can capture all dependence structures</li>
<li>the prob of having an edge is a function of latent positions.
<ul>
<li>main function what researchers use is a distance</li>
</ul></li>
<li></li>
</ul>
$
<span class="math display">\[\begin{bmatrix} \circ \end{bmatrix}\]</span>
<p>$$</p>
<hr />
<p>ANOVA -&gt; Additive Effect Model for network analysis</p>
<p><span class="math inline">\(y_{ij}\)</span>: weighted edges from node <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>.</p>
<p><span class="math inline">\(y_{ij} = \mu + a_i + b_j + \epsilon_{ij}\)</span></p>
<p>Social Relation Model</p>
<p>-&gt; Goal: Capture sender and receiver correlations (dyadic corrlations)</p>
<p>Assign Variance structures to <span class="math inline">\(a_i\)</span> and <span class="math inline">\(b_j\)</span>:</p>
<p><span class="math display">\[
Var \left[ \begin{pmatrix} a_i \\ b_j \end{pmatrix}\right] \equiv \Sigma
= \begin{pmatrix} \sigma_a^2 &amp; \sigma_{ab} \\ \sigma_{ab} &amp; \sigma^2_b \end{pmatrix}
\]</span></p>
<ul>
<li><span class="math inline">\(\sigma_{ab}\)</span>: Covariance term for both <span class="math inline">\(i \rightarrow j\)</span> and <span class="math inline">\(j \rightarrow i\)</span>, there should be a correlation b/w sender and receiver.</li>
</ul>
<p>In a social relation model, we caputre this correlation.</p>
<p><span class="math display">\[
Var \left[ \begin{pmatrix} \epsilon_{ij} \\ \epsilon_{ji}\end{pmatrix}\right]
= \sigma^2 \begin{pmatrix} 1 &amp; \rho \\ \rho &amp; 1 \end{pmatrix}
\]</span></p>
<p>Social Relation Covariance Model</p>
<p>You decompese the variance of <span class="math inline">\(y_{ij}\)</span> into three parts:</p>
<p><span class="math display">\[
Var(y_{ij}) =
\underbrace{\sigma^2_a }_{\text{variance of sender}}
+
\underbrace{\sigma^2_b }_{\text{variance of receiver}}
+
\underbrace{\sigma^2 }_{\text{common variance}}
\]</span></p>
<ul>
<li><span class="math inline">\(Cov(y_{ij}, y_{ik}) = \sigma_a^2\)</span>: within-row covariance</li>
<li><span class="math inline">\(Cov(y_{ij}, y_{kj}) = \sigma_b^2\)</span> : within-col covariance</li>
<li><span class="math inline">\(Cov(\underbrace{y_{ij}, y_{jk}}_{i\rightarrow j \rightarrow k}) = \sigma_{ab}\)</span>: row-col covariance</li>
<li><span class="math inline">\(Cov(\underbrace{y_{ij}, y_{ji}}_{ i\rightarrow j \\j \rightarrow i}) = 2 \sigma_{ab} + \rho \sigma^2\)</span>: row-col covariance + reciprocity</li>
</ul>
<p>Social Relation Regression Model</p>
<p><span class="math display">\[
y_{ij} = \beta &#39; x_{ij} + \mu + a_i + b_j + \epsilon_{ij} \tag{SRRM}
\]</span></p>
<p>Goal: measure the covariate effects on an adjacency Matrix as well as sender and receiver effects</p>
<p>Limitation of series of social relation model -&gt; we cannot capture high-order dependence within networks</p>
<p>Goal: measure high-order dependence in a network as well as sender and receivers effect</p>
<p>Additive and Multiplicative Model (AME)</p>
<p><span class="math display">\[
\begin{align}
&amp;y_{ij} = \beta&#39;x_{ij} + u_i &#39; v_j + a_i + b_j + \epsilon_{ij} \tag{AME}
&amp;&amp; \begin{pmatrix} \epsilon_{ij} \\ \epsilon_{ji} \end{pmatrix} \sim N \left(0, \; \;\sigma^2\begin{pmatrix} 1 &amp; \rho \\ \rho &amp; 1 \end{pmatrix} \right)
\end{align}
\]</span></p>
<p>we decompose <span class="math inline">\(\epsilon_{ij} = \underbrace{u_i &#39; v_j}_{\substack{\text{high-order}\\ \text{dependence}}} + \epsilon_{ij}\)</span></p>
<ul>
<li><span class="math inline">\(u_i\)</span>: latent vector that measure a high-order dependence for node <span class="math inline">\(i\)</span> in aspect of sender effect</li>
<li><span class="math inline">\(v_j\)</span>: latent vector that measure a high-order dependence for node <span class="math inline">\(j\)</span> in aspect of receiver effect</li>
</ul>
<p>AME: $y_{ij} = </p>
<hr />
<p>If we fit LSM seperatively, we cannot find the trajectory of each individuals.</p>
<p>-&gt; wee need a model taht combines each latent spaces.</p>
<p>Hidden Markov Model</p>
<ul>
<li><span class="math inline">\(Y_t = \{Y_{ijt}\}\)</span>: adjacency Matrix of observed network at time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(z_{it}\)</span>: <span class="math inline">\(p\)</span>-dimensional vectors of <span class="math inline">\(i\)</span>-th actor/s latent position at time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(z_t\)</span>: <span class="math inline">\(n \times p\)</span> Matrix whose its row is <span class="math inline">\(z_{it}\)</span>.</li>
</ul>
<p>When we assign the prior distribution of <span class="math inline">\(z_t\)</span>, we use the hidden Markov Model.</p>
<p><span class="math display">\[
\pi(z_1 \Big | \Psi_1) = \prod_{i=1}^n N(X_{i1} \Big | 0, \tau^2 I_P)\\
\pi(z_t \Big | z_{t-1}, \Psi_t) = \prod_{i=1}^n N(X_{it} \Big | X_{i(t-1)}, \sigma^2 I_P)
\]</span></p>
<p>Definition of Hidden Markov Model</p>
<p>two process</p>
<ul>
<li><span class="math inline">\(Y\)</span> (observable)</li>
<li><span class="math inline">\(Z\)</span> (unobsevable, assumed to be a Markov Process)</li>
</ul>
<p><span class="math inline">\(Y\)</span> depends on <span class="math inline">\(Z\)</span>.</p>
<p>Construct the likelihood (directed Network)</p>
<p>$$
P(Y_t | X_t , ) = <em>{i = j} ^{y</em>{ijt}}
^{1-y_{ijt}}</p>
<p>$$</p>
<p>Logistic Regression Framework</p>
<p><span class="math display">\[
\pi_{ijt} = \beta_{IN} \Bigg( 1-\frac{d_{ijt}}{r_j}\Bigg)
+
\beta_{OUT} \Bigg( 1-\frac{d_{ijt}}{r_j}\Bigg)
\]</span></p>
<ul>
<li><p><span class="math inline">\(\beta_{IN}\)</span>: how likely it tends to receive the connection (popularity)</p></li>
<li><p><span class="math inline">\(\beta_{OUT}\)</span>: how likely it tends to senc the connection (social activity)</p></li>
<li><p><span class="math inline">\(d_{ijt} = \| z_{it} - z_{jt}\|\)</span>: euclidian distance</p></li>
<li><p><span class="math inline">\(r_i\)</span>: positive actor specific parameters, that represent each actor’s social reach (tendency to form and receive edges)</p>
<ul>
<li>constraint <span class="math inline">\(\sum_{i=1}^n r_i = !\)</span></li>
<li>geometric interpretation <span class="math inline">\(r_i\)</span> forming a radius arount the <span class="math inline">\(i\)</span>-th actor.</li>
</ul></li>
</ul>
<p>If the distance b/w two actors are <strong>within</strong> each other’s radii, <span class="math inline">\(d_i &lt; \min(r_i , r_j)\)</span>, then the prob of forming an edge is <strong>greater</strong> than <span class="math inline">\(\frac12\)</span>.</p>
<p>If the distance b/w two actors are <strong>outside</strong> each other’s radii, <span class="math inline">\(d_i &lt; \max(r_i , r_j)\)</span>, then the prob of forming an edge is <strong>less</strong> than <span class="math inline">\(\frac12\)</span>.</p>
<p>If <span class="math inline">\(\d_{ijt}= r_i = r_j\)</span>, then the prob of forming an edge is <strong>equal</strong> to <span class="math inline">\(\frac12\)</span>.</p>
<p><br>
<br></p>
<p>If <span class="math inline">\(\beta_{IN} &gt; \beta_{OUT}\)</span>, the prob of an edge from <span class="math inline">\(i \rightarrow j\)</span> is determined more by the radius of <span class="math inline">\(j\)</span> than by the radius of <span class="math inline">\(i\)</span>, which means <strong>popularity &gt; social activity</strong>.</p>
<p>If <span class="math inline">\(\beta_{IN} &lt; \beta_{OUT}\)</span>, <strong>popularity &lt; social activity</strong>.</p>
<p>※ Prior Distribution</p>
<p><span class="math display">\[
\beta_{IN} \sim N
\\
\beta_{OUT} \sim N
\\
\sigma^2 \sim Inv-Gamma
\\
\tau^2 \sim Inv-Gamma
\\
(r_1, \cdots, r_n ) \sim Dirichlet (\alpha_1 , \cdots, \alpha_n)
\]</span></p>
<p>※ MCMC iteration</p>
<ol style="list-style-type: decimal">
<li>For <span class="math inline">\(t=1:T\)</span> and <span class="math inline">\(i=1:n\)</span>, draw <span class="math inline">\(z_{it}\)</span> using MH conditional posterior for <span class="math inline">\(z_{it}\)</span> is</li>
</ol>
$$
(z_{it} | Y_{i:T}, )
<span class="math display">\[\begin{cases}
\displaystyle
\prod_{i \not = j} \frac{\exp(\pi_{ijt} \cdot y_{ijt})}{1+\exp(\pi_{ijt})}
&amp; \cdot N(z_{it} \Big | 0, \tau^2 I_p )
&amp; \cdot N(z_{i2} \Big | z_{i1}, \sigma^2 I_p)
&amp; &amp;&amp; t=1
\\
\displaystyle
\prod_{i \not = j} \frac{\exp(\pi_{ijt} \cdot y_{ijt})}{1+\exp(\pi_{ijt})}
&amp; \cdot N(z_{i(t+1)} \Big | z_{it}, \sigma^2 I_p )
&amp; \cdot N(z_{it} \Big | z_{i(t-1)}, \sigma^2 I_p)
&amp; &amp;&amp; 2&lt;t&lt;T
\\
\displaystyle
&amp; \prod_{i \not = j} \frac{\exp(\pi_{ijt} \cdot y_{ijt})}{1+\exp(\pi_{ijt})}
&amp; \cdot N(z_{it} \Big | z_{i(t-1)}, \sigma^2 I_p)
&amp; &amp;&amp;

\end{cases}\]</span>
<p>$$</p>
<ol start="2" style="list-style-type: decimal">
<li>draw <span class="math inline">\(\tau^2\)</span> from its full conditional IG.</li>
<li>draw <span class="math inline">\(\sigma^2\)</span> from its full conditional IG.</li>
<li>draw <span class="math inline">\(\beta_{IN}\)</span> and <span class="math inline">\(\beta_{OUT}\)</span> using MH algorithm.</li>
<li>draw <span class="math inline">\(r_{1:N}\)</span> via MH using a Dirichlet proposal.</li>
</ol>
<p>let <span class="math inline">\(\mathcal D\)</span> denote the sampling</p>
<hr />
<ol style="list-style-type: decimal">
<li>simple approach</li>
<li>to find the <span class="math inline">\(z_{t+1}\)</span>, use <span class="math inline">\(\hat z_{t+1} = E(z_{t+1} \Big | Y_{1:T}) \approx \frac1L \sum^L_{l=1}z_t^{(l)}\)</span>, where
<span class="math inline">\(l\)</span> indicates the <span class="math inline">\(l\)</span>-th draw from the posterior.</li>
<li>By plugging-in <span class="math inline">\(\hat z_{t+1}\)</span> along with the posterior means of the parameter, into the <span class="math inline">\(\pi_{ijt}\)</span>, we can generate <span class="math inline">\(\hat Y_{t+1}\)</span>.</li>
</ol>
<p><span class="math display">\[
\begin{align}
&amp;z_{it} = z_{i(t-1)} + \epsilon_{it} &amp;&amp;\epsilon_{it} \sim N(\mu_t , \sigma^2 I_p)
\end{align}
\]</span></p>
<p><span class="math inline">\(\theta_t\)</span> equals the angle <span class="math inline">\(\arctan \Big \{2(X_{jt} - X_{i(t-1)} ) \Big \}\)</span>, which is two argument of arc tangent, the common variation of the arctangent function, which preserve the angle quadrant.</p>
$$
_t = R_t
<span class="math display">\[\begin{pmatrix} \mu \\ 0 \end{pmatrix}\]</span>
<p>=</p>
<span class="math display">\[\begin{pmatrix} \cos(\theta_t) &amp; -\sin(\theta_t) \\ \sin(\theta_t) &amp; \cos(\theta_t) \end{pmatrix} \begin{pmatrix} \mu \\ 0 \end{pmatrix}\]</span>
<p>$$</p>
<ul>
<li>where <span class="math inline">\(\mu_t\)</span> is edge attraction at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(\mu = \Bigg \|E(X_{it} - X_{i(t-1)}) \Bigg \|\)</span>.</li>
</ul>
<p><span class="math display">\[
\pi(\mu) = \begin{cases} p_0 &amp; &amp; \mu = 0 \\ (1-p_0) f(\mu) &amp; &amp; \mu&gt;0\end{cases}
\]</span></p>
<p>We assume <span class="math inline">\(f(\mu) \sim \exp (\lambda)\)</span>.</p>
<p>then the posterior density of <span class="math inline">\(\mu\)</span></p>
<p><span class="math display">\[
\pi (\mu \Big | Y_{1:T}) = \frac{\pi (Y_{1:T} \Big |  \mu) \pi (\mu)}{\pi (Y_{1:T})}
=
\frac{\pi (Y_{1:T} \Big |  \mu) }{\pi (Y_{1:T})} p_0 \cdot I\Big(\mu=0 \Big )
+\frac{\pi (Y_{1:T} \Big |  \mu) }{\pi (Y_{1:T})}
(1-p_0) f(\mu) \cdot I\Big(\mu&gt;0 \Big )
\]</span></p>
<p>let</p>
<p><span class="math display">\[
\pi_0 (\mu_0 = 0 \Big | Y_{1:T}) = \frac{f(Y_{1:T} | \mu)}{\pi(Y_{1:T})} p_0
\\
\pi_t (\mu \Big | Y_{1:T}) = \frac{f(Y_{1:T} | \mu)}{\pi(Y_{1:T})} (1-p_0) f(\mu)
\]</span></p>
<p>$$
<em>0 (<em>0 = 0 | Y</em>{1:T}) + <em>0^</em>+ (| Y</em>{1:p}) d= 1</p>
<p>\</p>
<p><em>0 (= 0 | Y</em>{1:p}) = , K(U) =
$$</p>
<hr />
<ol start="10" style="list-style-type: decimal">
<li></li>
</ol>
<p>Stochastic Block Model</p>
<ul>
<li>Latent Class Model</li>
<li>for each actor (node), we assign group memberships</li>
</ul>
<p>two components in the block model,</p>
<ol style="list-style-type: decimal">
<li>the vector of grop membership : <span class="math inline">\(z\)</span></li>
<li>conditional on the group membership, the <strong>block matrix</strong> represents the edge probability of two nodes</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}
&amp;
\begin{bmatrix}
0.8 &amp; 0.05 &amp; 0.02 \\
0.05 &amp; 0.9 &amp; 0.03 \\
0.02 &amp; 0.03 &amp; 0.7
\end{bmatrix}

&amp;&amp;
\begin{bmatrix}
b_{11} &amp; b_{12} &amp; b_{13} \\
b_{21} &amp; b_{22} &amp; b_{23}  \\
b_{31} &amp; b_{32} &amp; b_{32}
\end{bmatrix}

\end{align}\]</span>
$$</p>
<ul>
<li><span class="math inline">\(b_{11}\)</span> 에 부여된 확률 0.8: the connection prob within group 1</li>
<li><span class="math inline">\(b_{22}\)</span> 에 부여된 확률 0.9: the connection prob within group 1</li>
<li><span class="math inline">\(b_{11}\)</span> 에 부여된 확률 0.05: the connection prob b/w group 1 and group 2</li>
</ul>
<p>※ notations:</p>
<ul>
<li><span class="math inline">\(Y\)</span>: adjacency Matrix</li>
<li><span class="math inline">\(K\)</span>: the total membership groups (<span class="math inline">\(&lt;n\)</span>)</li>
<li><span class="math inline">\(Z_i\)</span>: <span class="math inline">\(k\)</span>-vector, all elements of which are <span class="math inline">\(0\)</span>, except exactly one that takes the value <span class="math inline">\(1\)</span> and represents the group node <span class="math inline">\(i\)</span> belongs to.</li>
<li><span class="math inline">\(Z := (z_1 , \cdots, z_n)&#39;\)</span></li>
<li><span class="math inline">\(C\)</span>: <span class="math inline">\(k \times k\)</span> block matrix
<ul>
<li>entry <span class="math inline">\(C_{ij} \in [0,1]\)</span>: prob of occurence of a edge from a node in <span class="math inline">\(g\)</span></li>
</ul></li>
</ul>
<p>the idea of block Matrix <span class="math inline">\(C\)</span> means the edges are are conditionally independent, given the block membership.</p>
<p><span class="math inline">\(\Rightarrow Y_{ij} \sim\)</span> Bernoulli distribution with success probability <span class="math inline">\(z_i &#39; C z_j\)</span>, and independent of <span class="math inline">\(Y_{kl}\)</span> for <span class="math inline">\((i,j) \no = (k,l)\)</span>, given <span class="math inline">\(z_i\)</span> and <span class="math inline">\(z_j\)</span>.</p>
<p>Likelihood function</p>
<p>$$
P (Y | Z, C) = <em>{i&lt;j} P (y</em>{ij} | Z, C)</p>
<p>= _{i&lt;j}</p>
<p>$$</p>
<p>In real data, <span class="math inline">\(z\)</span> and <span class="math inline">\(C\)</span> are unknown. <span class="math inline">\(\Rightarrow\)</span> we need additional assumptions.
<span class="math inline">\(\underbrace{1}_{2}\)</span>
1. <span class="math inline">\(z_i\)</span> is independent of <span class="math inline">\(z_j\)</span>.
2. <span class="math inline">\(P(z_{i \underbrace{k}_{\text group}} =1) = \theta_k\)</span>, <span class="math inline">\(\sum_{j=1}^k \theta_k = 1\)</span> <span class="math inline">\(\Rightarrow\)</span> the latent group <span class="math inline">\(z_p\)</span> follows multinomial distribution with <span class="math inline">\(\theta\)</span>, i.e.,</p>
<p><span class="math display">\[
\pi(z \Big | \theta) = \prod_{i=1}^n z_i &#39; \theta = \prod_{k=1}^K \theta_k^{n_k} \tag{2}
\]</span></p>
<p>, where <span class="math inline">\(n_k\)</span> is the total number of nodes that belongs to group <span class="math inline">\(K\)</span>.</p>
<p>In a Bayesian inference, we can assign <span class="math inline">\(Dirichlet\)</span> prior <span class="math inline">\(\alpha, \cdots, \alpha\)</span> <span class="math inline">\(\pi(\alpha) \sim Gamma (a,b)\)</span>.</p>
<p>Inference</p>
<p>By combining equation (1) and (2), we can make an inference by the frequentist way using EM algorithm.</p>
<p>Bayesian</p>
<p>we need to assign prior for <span class="math inline">\(C \Sim BETA\)</span>, <span class="math inline">\(C_{ij} \sim BETA(A_{ij}, B_{ij})\)</span>, where A, B are <span class="math inline">\(k \times k\)</span> Matrix.</p>
<p>Posterior Distribution</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}



\pi(Z , \theta, C , \alpha  \Big | Y)

&amp; \propto f(Y \Big | Z , \theta, C , \alpha)
&amp;&amp; \cdot \pi(Z , \theta, C , \alpha)

\\

&amp; = f(Y \Big | Z , \theta, C , \alpha)
&amp;&amp; \cdot \pi(Z \Big | \theta, C , \alpha)
&amp;&amp; \cdot \pi(\theta \Big | C , \alpha)
&amp;&amp; \cdot \pi(C, \alpha)


\\

&amp; = f(Y \Big | Z , C)
&amp;&amp; \cdot \pi(Z \Big | \theta)
&amp;&amp; \cdot \pi(\theta \Big | \alpha)
&amp;&amp; \cdot \pi(C)
\cdot \pi(\alpha)

\\
&amp; \propto \prod_{i&lt;j} \Big[ (z_i&#39; C z_j)^{y_{ij}}(1- z_i&#39; C z_j)^{1-y_{ij}} \Big]
&amp;&amp; \cdot \prod_{k=1}^K \theta_k^{n_k}
\Bigg[\Gamma(k \alpha) \Big \{ \sum^k_{i=} \theta_k = 1 \prod_{i=1}^k \frac{\theta_z^{\alpha-1}}{\Gamma(\alpha)}\Big \} \Bigg]
&amp;&amp; \cdot\prod^k_{i&lt;j} \Big[ C_{ij}^{A_{ij}-1} (1-C_{ij})^{B_{ij}-1} \Big]
&amp;&amp; \cdot \alpha^{a-1} e^{-b \alpha}

\end{alignat}\]</span>
$$</p>
<p><span class="math inline">\(\Rightarrow\)</span> Computation is veery straightforward via MCMC.</p>
<p>Mixed Membership Block Model (MMBM)</p>
<ul>
<li>SBM each actor only has one membership</li>
<li>to alleviate the assumption of SBM, MMBM has been proposed</li>
<li>This model allows each node can have multiple membership instead of assigning <span class="math inline">\(1\)</span> to a ceratin membership, we estimate the probability of all membership.</li>
</ul>
<p><span class="math display">\[
\begin{align}
z_i &amp;= (1, 0, 0) \tag{SBM}
\\
\theta_i &amp;= (0.7, 0.2, 0.1) \tag{MMSB}
\end{align}
\]</span></p>
<p>이때 MMSB 의 vector 의 각 항은 각각 group 1, group 2, group 3 일 prob.</p>
<ul>
<li><span class="math inline">\(\theta_i\)</span>: weights or probabilities in the grous that have to be non-negative and sum to 1.</li>
</ul>
<p>For each dyad <span class="math inline">\(y_{ij}\)</span>, a latent membership <span class="math inline">\(z_{ij}\)</span> is drawn from the multinomial distribution with <span class="math inline">\(\theta_p\)</span>.</p>
<p><span class="math inline">\(\pi(z \Big | \Theta) = \prod_{i \not = j} (z_{ij}&#39;\theta_i x z_{ji}&#39;\theta_j\)</span>, where <span class="math inline">\(\Theta := (\theta_1 , \cdots, \theta_k)\)</span> is <span class="math inline">\(n \times k\)</span> Matrix of membership probability.</p>
<p>The likeliood is <span class="math inline">\(f(Y \Big | Z, C) = \prod_{i&lt;j} \Big[ (z_{ij}&#39; C z_{ji})^{y_{ij}}(1- z_{ij}&#39; C z_{ji})^{1-y_{ij}} \Big]\)</span>.</p>
<p>The goal of inference estimating not <span class="math inline">\(z\)</span> but the mixed memberships <span class="math inline">\(\Theta\)</span>.</p>
<p>Degree-corrected SBM</p>
<p>use Poisson Model.</p>
<ul>
<li><span class="math inline">\(y_{ij}\)</span>: the number of edges from dyad (i,j) following a Poisson dist</li>
<li><span class="math inline">\(C_{ij}\)</span>: the expected number of edges from a node in group <span class="math inline">\(i\)</span> to a node in group <span class="math inline">\(j\)</span></li>
</ul>
<p>The likelihood is</p>
<p><span class="math display">\[
\pi(Y_{ij} \Big | Z, C) = (Y_{ij}!)^{-1} \exp \Big \{ (-z_i &#39; C z_j ) (z_i &#39; C z_j )^{y_{ij}}  \Big \} \tag{3}
\]</span></p>
<p>In a large sparse graph, where the edge probability equals the expected number of edges, DC-SBM is asymptotically equivalient to the Bernoulli counterpart in equation (3).</p>
<ul>
<li><span class="math inline">\(\phi_p\)</span>: the ratio of node <span class="math inline">\(i\)</span>’s degree to the sum of degrees in node <span class="math inline">\(i\)</span>’s group.</li>
</ul>
<p>Under constraint <span class="math inline">\(\sum_{i=1}^n \phi_i \cdot I \Big ( z_{ik} = 1 \Big) =1\)</span>, then equation (3) becomes</p>
<p><span class="math display">\[
f(y_{ij} \Big | Z, C, \phi) = (y_{ij}!)^{-1} \exp \Big \{ (- \phi_i \phi_j z_i &#39; C z_j ) (\phi_i \phi_j z_i &#39; C z_j )^{y_{ij}}  \Big \}
\]</span></p>
<p>which is <strong>DC-SBM</strong>.</p>
<p><span class="math inline">\(\Rightarrow\)</span> SBM ignores the variation of node degrees in a real network.</p>
<p>With DC-SBM, we can make correction better.</p>

</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>random increment<a href="markov-chain-monte-carlo.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The ordering of updates made to the components of X in the basic Gibbs sampler can change from one cycle to the next. Random ordering each cycle can be effective when parameters are highly correlated. In practice without specialized knowledge for a particular model, we recommend trying both deterministic and random scan Gibbs sampling when parameters are highly correlated from one iterations to the next.<a href="markov-chain-monte-carlo.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>1st class<a href="descriptive-statistics-of-networks.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Bayes risk = Expecation of loss function. 이때 loss function 으로는 Kullback-Leibler loss 를 사용한다.<a href="latent-network-models.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Combines a linear regression model with the covariance structure of the SRM as follows, where <span class="math inline">\(\mathbf x_{i,j}\)</span> is <span class="math inline">\(p\)</span>−dimensional vector of regressors and <span class="math inline">\(\beta\)</span> is a vector of regression coefficient to be estimated.<a href="additive-and-multiplicative-effects-network-models.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Tropp, Joel A. ”User-friendly tail bounds for sums of random matrices.” Foundations of computational mathematics 12.4 (2012): 389-434<a href="matrix-concentration-inequalities.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p><span class="math inline">\(V_{d \times d} V&#39; s= V&#39;V = I\)</span><a href="principal-component-analysis.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>diagonal Matrix <span class="math inline">\(\lambda_{d \times d}\)</span>, entries with ev <span class="math inline">\(\lambda_1 \ge \cdots \ge \lambda_d \ge 0\)</span><a href="principal-component-analysis.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>vector 안에 들어있는 non-zero elements 의 갯수가 <span class="math inline">\(k\)</span><a href="principal-component-analysis.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>이때 <span class="math inline">\(0^0 = 0\)</span>이라고 정의<a href="principal-component-analysis.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p><span class="math inline">\(\mathbb S^{r-1} =\{x\in\mathbb{R}^{r}: \|x\|_2 = 1\}\)</span><a href="linear-regression.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>almost surely.<a href="uniform-laws-of-large-numbers.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>흔히 <span class="math inline">\(\mathcal T = [0,\infty)\)</span>, 혹은 <span class="math inline">\(\mathcal T = (0,\tau_\ast)\)</span> where <span class="math inline">\(\forall n=1, \cdots, n:P(X_i &gt; \tau_\ast)&gt;0\)</span>.<a href="counting-processes-and-martingales.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>일반적인 counting process 에 대해, <span class="math inline">\(N(0)\)</span> 이며 <span class="math inline">\(\forall t \in \mathcal T:N(t)&lt;0\)</span>.<a href="counting-processes-and-martingales.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>증명에 <span class="math inline">\(E[X(t)|\mathcal{F}_{s}]=X(s)\mathrm{~for~}s\lt t\)</span> 가 사용되었다. 이는 위에서 보였다.<a href="counting-processes-and-martingales.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Xiaohui Yan, A Biterm Topic Model for Short Texts<a href="section-8.html#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cnn-3.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/99010292_GCN4.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
