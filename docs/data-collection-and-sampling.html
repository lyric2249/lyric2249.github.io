<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.3 Data Collection and Sampling | Self-Study</title>
  <meta name="description" content="7.3 Data Collection and Sampling | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.3 Data Collection and Sampling | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.3 Data Collection and Sampling | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="descriptive-statistics-of-networks.html"/>
<link rel="next" href="mathematical-models-for-network-graphs.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="part"><span><b>I 20-02</b></span></li>
<li class="chapter" data-level="1" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>1</b> Categorical</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="overview.html"><a href="overview.html#data-type-and-statistical-analysis"><i class="fa fa-check"></i><b>1.1.1</b> Data Type and Statistical Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian</a>
<ul>
<li class="chapter" data-level="2.1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>2.1</b> Abstract</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="abstract.html"><a href="abstract.html#변수의-독립성"><i class="fa fa-check"></i><b>2.1.1</b> 변수의 독립성</a></li>
<li class="chapter" data-level="2.1.2" data-path="abstract.html"><a href="abstract.html#교환가능성"><i class="fa fa-check"></i><b>2.1.2</b> 교환가능성</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continual-aeassessment-method.html"><a href="continual-aeassessment-method.html"><i class="fa fa-check"></i><b>2.2</b> Continual Aeassessment Method</a></li>
<li class="chapter" data-level="2.3" data-path="horseshoe-prior.html"><a href="horseshoe-prior.html"><i class="fa fa-check"></i><b>2.3</b> Horseshoe Prior</a></li>
</ul></li>
<li class="part"><span><b>II 21-01</b></span></li>
<li class="chapter" data-level="3" data-path="mathematical-stats.html"><a href="mathematical-stats.html"><i class="fa fa-check"></i><b>3</b> Mathematical Stats</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>3.1</b> Inference</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference.html"><a href="inference.html#rao-blackwell-thm."><i class="fa fa-check"></i><b>3.1.1</b> Rao-Blackwell thm.</a></li>
<li class="chapter" data-level="3.1.2" data-path="inference.html"><a href="inference.html#completeness"><i class="fa fa-check"></i><b>3.1.2</b> Completeness</a></li>
<li class="chapter" data-level="3.1.3" data-path="inference.html"><a href="inference.html#레만-쉐페-thm."><i class="fa fa-check"></i><b>3.1.3</b> 레만-쉐페 thm.</a></li>
<li class="chapter" data-level="3.1.4" data-path="inference.html"><a href="inference.html#raoblack"><i class="fa fa-check"></i><b>3.1.4</b> Rao-Blackwell thm.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>3.2</b> Hypothesis Test</a></li>
<li class="chapter" data-level="3.3" data-path="power-fucntion.html"><a href="power-fucntion.html"><i class="fa fa-check"></i><b>3.3</b> Power Fucntion</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="power-fucntion.html"><a href="power-fucntion.html#significance-probability-p-value"><i class="fa fa-check"></i><b>3.3.1</b> Significance Probability (p-value)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="optimal-testing-method.html"><a href="optimal-testing-method.html"><i class="fa fa-check"></i><b>3.4</b> Optimal Testing Method</a></li>
<li class="chapter" data-level="3.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>3.5</b> Data Reduction</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="data-reduction.html"><a href="data-reduction.html#sufficiency-principle"><i class="fa fa-check"></i><b>3.5.1</b> Sufficiency Principle</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="borel-paradox.html"><a href="borel-paradox.html"><i class="fa fa-check"></i><b>3.6</b> Borel Paradox</a></li>
<li class="chapter" data-level="3.7" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html"><i class="fa fa-check"></i><b>3.7</b> Neyman–Pearson lemma</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#overview-1"><i class="fa fa-check"></i><b>3.7.1</b> Overview</a></li>
<li class="chapter" data-level="3.7.2" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#generalized-lrt"><i class="fa fa-check"></i><b>3.7.2</b> Generalized LRT</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="개념.html"><a href="개념.html"><i class="fa fa-check"></i><b>3.8</b> 개념</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>4</b> MCMC</a>
<ul>
<li class="chapter" data-level="4.1" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>4.1</b> Importance Sampling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="importance-sampling.html"><a href="importance-sampling.html#independent-monte-carlo"><i class="fa fa-check"></i><b>4.1.1</b> Independent Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.2</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mh-algorithm"><i class="fa fa-check"></i><b>4.2.1</b> MH Algorithm</a></li>
<li class="chapter" data-level="4.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used"><i class="fa fa-check"></i><b>4.2.2</b> Random Walk Chains (Most Widely Used)</a></li>
<li class="chapter" data-level="4.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler"><i class="fa fa-check"></i><b>4.2.3</b> Basic Gibbs Sampler</a></li>
<li class="chapter" data-level="4.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#implementation"><i class="fa fa-check"></i><b>4.2.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html"><i class="fa fa-check"></i><b>4.3</b> Advanced MCMC (wk08)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#data-augmentation"><i class="fa fa-check"></i><b>4.3.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.3.2" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm"><i class="fa fa-check"></i><b>4.3.2</b> Hit-and-Run Algorithm</a></li>
<li class="chapter" data-level="4.3.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm"><i class="fa fa-check"></i><b>4.3.3</b> Metropolis-Adjusted Langevin Algorithm</a></li>
<li class="chapter" data-level="4.3.4" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm"><i class="fa fa-check"></i><b>4.3.4</b> Multiple-Try Metropolis Algorithm</a></li>
<li class="chapter" data-level="4.3.5" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm"><i class="fa fa-check"></i><b>4.3.5</b> Reversible Jump MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html"><i class="fa fa-check"></i><b>4.4</b> Auxiliary Variable MCMC</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#introduction"><i class="fa fa-check"></i><b>4.4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.4.2" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution"><i class="fa fa-check"></i><b>4.4.2</b> Multimodal Target Distribution</a></li>
<li class="chapter" data-level="4.4.3" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants"><i class="fa fa-check"></i><b>4.4.3</b> Doubly-intractable Normalizing Constants</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html"><i class="fa fa-check"></i><b>4.5</b> Approximate Bayesian Computation</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#simulator-based-models"><i class="fa fa-check"></i><b>4.5.1</b> Simulator-Based Models</a></li>
<li class="chapter" data-level="4.5.2" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods"><i class="fa fa-check"></i><b>4.5.2</b> ABCifying Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.5.3" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm"><i class="fa fa-check"></i><b>4.5.3</b> ABC-MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Hamiltonian Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>4.6.1</b> Introduction to Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html"><i class="fa fa-check"></i><b>4.7</b> Population Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#adaptive-direction-sampling"><i class="fa fa-check"></i><b>4.7.1</b> Adaptive Direction Sampling</a></li>
<li class="chapter" data-level="4.7.2" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#conjugate-gradient-mc"><i class="fa fa-check"></i><b>4.7.2</b> Conjugate Gradient MC</a></li>
<li class="chapter" data-level="4.7.3" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#parallel-tempering"><i class="fa fa-check"></i><b>4.7.3</b> Parallel Tempering</a></li>
<li class="chapter" data-level="4.7.4" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#evolutionary-mc"><i class="fa fa-check"></i><b>4.7.4</b> Evolutionary MC</a></li>
<li class="chapter" data-level="4.7.5" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#sequential-parallel-tempering"><i class="fa fa-check"></i><b>4.7.5</b> Sequential Parallel Tempering</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="stochastic-approximation-monte-carlo.html"><a href="stochastic-approximation-monte-carlo.html"><i class="fa fa-check"></i><b>4.8</b> Stochastic Approximation Monte Carlo</a></li>
<li class="chapter" data-level="4.9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>4.9</b> Review</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="review.html"><a href="review.html#wk01"><i class="fa fa-check"></i><b>4.9.1</b> Wk01</a></li>
<li class="chapter" data-level="4.9.2" data-path="review.html"><a href="review.html#wk03"><i class="fa fa-check"></i><b>4.9.2</b> wk03</a></li>
<li class="chapter" data-level="4.9.3" data-path="review.html"><a href="review.html#wk04-05"><i class="fa fa-check"></i><b>4.9.3</b> wk04, 05</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="else.html"><a href="else.html"><i class="fa fa-check"></i><b>4.10</b> Else</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="else.html"><a href="else.html#hw4.-rasch-model"><i class="fa fa-check"></i><b>4.10.1</b> Hw4. Rasch Model</a></li>
<li class="chapter" data-level="4.10.2" data-path="else.html"><a href="else.html#da-example-mvn"><i class="fa fa-check"></i><b>4.10.2</b> DA) Example: MVN</a></li>
<li class="chapter" data-level="4.10.3" data-path="else.html"><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><i class="fa fa-check"></i><b>4.10.3</b> Bayesian adaptive clinical trial with delayed outcomes</a></li>
<li class="chapter" data-level="4.10.4" data-path="else.html"><a href="else.html#nmar의-종류"><i class="fa fa-check"></i><b>4.10.4</b> NMAR의 종류</a></li>
<li class="chapter" data-level="4.10.5" data-path="else.html"><a href="else.html#wk10-bayesian-model-selection"><i class="fa fa-check"></i><b>4.10.5</b> wk10) Bayesian Model Selection</a></li>
<li class="chapter" data-level="4.10.6" data-path="else.html"><a href="else.html#autologistic-model"><i class="fa fa-check"></i><b>4.10.6</b> Autologistic model</a></li>
<li class="chapter" data-level="4.10.7" data-path="else.html"><a href="else.html#wk10-bayesian-model-averaging"><i class="fa fa-check"></i><b>4.10.7</b> wk10) Bayesian Model Averaging</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mva.html"><a href="mva.html"><i class="fa fa-check"></i><b>5</b> MVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html"><i class="fa fa-check"></i><b>5.1</b> Overview of mva (not ended)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#notation"><i class="fa fa-check"></i><b>5.1.1</b> Notation</a></li>
<li class="chapter" data-level="5.1.2" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#summary-statistics"><i class="fa fa-check"></i><b>5.1.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation"><i class="fa fa-check"></i><b>5.1.3</b> Statistical Inference on Correlation</a></li>
<li class="chapter" data-level="5.1.4" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#standardization"><i class="fa fa-check"></i><b>5.1.4</b> Standardization</a></li>
<li class="chapter" data-level="5.1.5" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#missing-value-treatment"><i class="fa fa-check"></i><b>5.1.5</b> Missing Value Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html"><i class="fa fa-check"></i><b>5.2</b> Multivariate Nomral (wk2)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#overview-2"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#spectral-decomposition"><i class="fa fa-check"></i><b>5.2.2</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="5.2.3" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#properties-of-mvn"><i class="fa fa-check"></i><b>5.2.3</b> Properties of MVN</a></li>
<li class="chapter" data-level="5.2.4" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#chi2-distribution"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\Chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="5.2.5" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors"><i class="fa fa-check"></i><b>5.2.5</b> Linear Combination of Random Vectors</a></li>
<li class="chapter" data-level="5.2.6" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood"><i class="fa fa-check"></i><b>5.2.6</b> Multivariate Normal Likelihood</a></li>
<li class="chapter" data-level="5.2.7" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s"><i class="fa fa-check"></i><b>5.2.7</b> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></a></li>
<li class="chapter" data-level="5.2.8" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#assessing-normality"><i class="fa fa-check"></i><b>5.2.8</b> Assessing Normality</a></li>
<li class="chapter" data-level="5.2.9" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#power-transformation"><i class="fa fa-check"></i><b>5.2.9</b> Power Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html"><i class="fa fa-check"></i><b>5.3</b> Inference about Mean Vector (wk3)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#overview-3"><i class="fa fa-check"></i><b>5.3.1</b> Overview</a></li>
<li class="chapter" data-level="5.3.2" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#confidence-region"><i class="fa fa-check"></i><b>5.3.2</b> 1. Confidence Region</a></li>
<li class="chapter" data-level="5.3.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#simultaneous-ci"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simultaneous CI</a></li>
<li class="chapter" data-level="5.3.4" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison"><i class="fa fa-check"></i><b>5.3.4</b> 3. Note: Bonferroni Multiple Comparison</a></li>
<li class="chapter" data-level="5.3.5" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector"><i class="fa fa-check"></i><b>5.3.5</b> 4. Large Sample Inferences about a Mean Vector</a></li>
<li class="chapter" data-level="5.3.6" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5"><i class="fa fa-check"></i><b>5.3.6</b> 1. Profile Analysis (wk4, 5)</a></li>
<li class="chapter" data-level="5.3.7" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend"><i class="fa fa-check"></i><b>5.3.7</b> 2. Test for Linear Trend</a></li>
<li class="chapter" data-level="5.3.8" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix"><i class="fa fa-check"></i><b>5.3.8</b> 3. Inferences about a Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of Several MV Means (wk5)</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#paired-comparison"><i class="fa fa-check"></i><b>5.4.1</b> Paired Comparison</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations"><i class="fa fa-check"></i><b>5.4.2</b> Comparing Mean Vectors from Two Populations</a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2"><i class="fa fa-check"></i><b>5.4.3</b> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means"><i class="fa fa-check"></i><b>5.4.4</b> Comparing Several Multivariate Population Means</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html"><i class="fa fa-check"></i><b>5.5</b> Multivariate Multiple Regression (wk6)</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#overview-4"><i class="fa fa-check"></i><b>5.5.1</b> Overview</a></li>
<li class="chapter" data-level="5.5.2" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression"><i class="fa fa-check"></i><b>5.5.2</b> Multivariate Multiple Regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.5.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.5.4" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#example"><i class="fa fa-check"></i><b>5.5.4</b> Example)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>5.6</b> PCA</a></li>
<li class="chapter" data-level="5.7" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>5.7</b> Factor</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="factor.html"><a href="factor.html#method-of-estimation"><i class="fa fa-check"></i><b>5.7.1</b> Method of Estimation</a></li>
<li class="chapter" data-level="5.7.2" data-path="factor.html"><a href="factor.html#factor-rotation"><i class="fa fa-check"></i><b>5.7.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="5.7.3" data-path="factor.html"><a href="factor.html#varimax-criterion"><i class="fa fa-check"></i><b>5.7.3</b> Varimax Criterion</a></li>
<li class="chapter" data-level="5.7.4" data-path="factor.html"><a href="factor.html#factor-scores"><i class="fa fa-check"></i><b>5.7.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html"><i class="fa fa-check"></i><b>5.8</b> Discrimination and Classification</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#bayes-rule"><i class="fa fa-check"></i><b>5.8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="5.8.2" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations"><i class="fa fa-check"></i><b>5.8.2</b> Classification with Two mv <span class="math inline">\(N\)</span> Populations</a></li>
<li class="chapter" data-level="5.8.3" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#evaluating-classification-functions"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating Classification Functions</a></li>
<li class="chapter" data-level="5.8.4" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-several-populations-wk13"><i class="fa fa-check"></i><b>5.8.4</b> Classification with several Populations (wk13)</a></li>
<li class="chapter" data-level="5.8.5" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#other-discriminant-analysis-methods"><i class="fa fa-check"></i><b>5.8.5</b> Other Discriminant Analysis Methods</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html"><i class="fa fa-check"></i><b>5.9</b> Clustering, Distance Methods, and Ordination</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#overview-5"><i class="fa fa-check"></i><b>5.9.1</b> Overview</a></li>
<li class="chapter" data-level="5.9.2" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering"><i class="fa fa-check"></i><b>5.9.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="5.9.3" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#k-means-clustering"><i class="fa fa-check"></i><b>5.9.3</b> K-means Clustering</a></li>
<li class="chapter" data-level="5.9.4" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법"><i class="fa fa-check"></i><b>5.9.4</b> 군집의 평가방법</a></li>
<li class="chapter" data-level="5.9.5" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14"><i class="fa fa-check"></i><b>5.9.5</b> Clustering using Density Estimation (wk14)</a></li>
<li class="chapter" data-level="5.9.6" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>5.9.6</b> Multidimensional Scaling (MDS)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>6</b> Linear</a>
<ul>
<li class="chapter" data-level="6.1" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>6.1</b> SVD</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="svd.html"><a href="svd.html#spectral-decomposition-1"><i class="fa fa-check"></i><b>6.1.1</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="6.1.2" data-path="svd.html"><a href="svd.html#singular-value-decomposition-general-version"><i class="fa fa-check"></i><b>6.1.2</b> Singular value Decomposition: General-version</a></li>
<li class="chapter" data-level="6.1.3" data-path="svd.html"><a href="svd.html#singular-value-decomposition-another-version"><i class="fa fa-check"></i><b>6.1.3</b> Singular value Decomposition: Another-version</a></li>
<li class="chapter" data-level="6.1.4" data-path="svd.html"><a href="svd.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1.4</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.1.5" data-path="svd.html"><a href="svd.html#partitioned-matrices"><i class="fa fa-check"></i><b>6.1.5</b> Partitioned Matrices</a></li>
<li class="chapter" data-level="6.1.6" data-path="svd.html"><a href="svd.html#geometrical-aspects"><i class="fa fa-check"></i><b>6.1.6</b> Geometrical Aspects</a></li>
<li class="chapter" data-level="6.1.7" data-path="svd.html"><a href="svd.html#column-row-and-null-space"><i class="fa fa-check"></i><b>6.1.7</b> Column, Row and Null Space</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>6.2</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-1.html"><a href="introduction-1.html#what"><i class="fa fa-check"></i><b>6.2.1</b> What</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-1.html"><a href="introduction-1.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.2.2</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-1.html"><a href="introduction-1.html#multivariate-normal-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Multivariate Normal Distributions</a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-1.html"><a href="introduction-1.html#distributions-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2.4</b> Distributions of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>6.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation.html"><a href="estimation.html#identifiability-and-estimability"><i class="fa fa-check"></i><b>6.3.1</b> Identifiability and Estimability</a></li>
<li class="chapter" data-level="6.3.2" data-path="estimation.html"><a href="estimation.html#estimation-least-squares"><i class="fa fa-check"></i><b>6.3.2</b> Estimation: Least Squares</a></li>
<li class="chapter" data-level="6.3.3" data-path="estimation.html"><a href="estimation.html#estimation-best-linear-unbiased"><i class="fa fa-check"></i><b>6.3.3</b> Estimation: Best Linear Unbiased</a></li>
<li class="chapter" data-level="6.3.4" data-path="estimation.html"><a href="estimation.html#estimation-maximum-likelihood"><i class="fa fa-check"></i><b>6.3.4</b> Estimation: Maximum Likelihood</a></li>
<li class="chapter" data-level="6.3.5" data-path="estimation.html"><a href="estimation.html#estimation-minimum-variance-unbiased"><i class="fa fa-check"></i><b>6.3.5</b> Estimation: Minimum Variance Unbiased</a></li>
<li class="chapter" data-level="6.3.6" data-path="estimation.html"><a href="estimation.html#sampling-distributions-of-estimates"><i class="fa fa-check"></i><b>6.3.6</b> Sampling Distributions of Estimates</a></li>
<li class="chapter" data-level="6.3.7" data-path="estimation.html"><a href="estimation.html#generalized-least-squaresgls"><i class="fa fa-check"></i><b>6.3.7</b> Generalized Least Squares(GLS)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>6.4</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way-anova.html"><a href="one-way-anova.html#one-way-anova-1"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way-anova.html"><a href="one-way-anova.html#more-about-models"><i class="fa fa-check"></i><b>6.4.2</b> More About Models</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way-anova.html"><a href="one-way-anova.html#estimating-and-testing-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating and Testing Contrasts</a></li>
<li class="chapter" data-level="6.4.4" data-path="one-way-anova.html"><a href="one-way-anova.html#cochrans-theorem"><i class="fa fa-check"></i><b>6.4.4</b> Cochran’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>6.5</b> Testing</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="testing.html"><a href="testing.html#more-about-models-two-approaches-for-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> More About Models: Two approaches for linear model</a></li>
<li class="chapter" data-level="6.5.2" data-path="testing.html"><a href="testing.html#testing-models"><i class="fa fa-check"></i><b>6.5.2</b> Testing Models</a></li>
<li class="chapter" data-level="6.5.3" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure"><i class="fa fa-check"></i><b>6.5.3</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.4" data-path="testing.html"><a href="testing.html#testing-linear-parametric-functions"><i class="fa fa-check"></i><b>6.5.4</b> Testing Linear Parametric Functions</a></li>
<li class="chapter" data-level="6.5.5" data-path="testing.html"><a href="testing.html#theoretical-complements"><i class="fa fa-check"></i><b>6.5.5</b> Theoretical Complements</a></li>
<li class="chapter" data-level="6.5.6" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure-1"><i class="fa fa-check"></i><b>6.5.6</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.7" data-path="testing.html"><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace"><i class="fa fa-check"></i><b>6.5.7</b> Testing Single Degrees of Freedom in a Given Subspace</a></li>
<li class="chapter" data-level="6.5.8" data-path="testing.html"><a href="testing.html#breaking-ss-into-independent-components"><i class="fa fa-check"></i><b>6.5.8</b> Breaking SS into Independent Components</a></li>
<li class="chapter" data-level="6.5.9" data-path="testing.html"><a href="testing.html#general-theory"><i class="fa fa-check"></i><b>6.5.9</b> General Theory</a></li>
<li class="chapter" data-level="6.5.10" data-path="testing.html"><a href="testing.html#two-way-anova"><i class="fa fa-check"></i><b>6.5.10</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.5.11" data-path="testing.html"><a href="testing.html#confidence-regions"><i class="fa fa-check"></i><b>6.5.11</b> Confidence Regions</a></li>
<li class="chapter" data-level="6.5.12" data-path="testing.html"><a href="testing.html#tests-for-generalized-least-squares-models"><i class="fa fa-check"></i><b>6.5.12</b> Tests for Generalized Least Squares Models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>6.6</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#a-direct-solution-via-inner-products"><i class="fa fa-check"></i><b>6.6.1</b> A direct solution via inner products</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="flat.html"><a href="flat.html"><i class="fa fa-check"></i><b>6.7</b> Flat</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="flat.html"><a href="flat.html#flat-1"><i class="fa fa-check"></i><b>6.7.1</b> 1.Flat</a></li>
<li class="chapter" data-level="6.7.2" data-path="flat.html"><a href="flat.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>6.7.2</b> 2. Solutions to systems of linear equations</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="unified-approach-to-balanced-anova-models.html"><a href="unified-approach-to-balanced-anova-models.html"><i class="fa fa-check"></i><b>6.8</b> Unified Approach to Balanced ANOVA Models</a></li>
</ul></li>
<li class="part"><span><b>III 21-02</b></span></li>
<li class="chapter" data-level="7" data-path="network-stats.html"><a href="network-stats.html"><i class="fa fa-check"></i><b>7</b> Network Stats</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-2.html"><a href="introduction-2.html#types-of-network-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Types of Network Analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-2.html"><a href="introduction-2.html#network-modeling-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Network Modeling and Inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-2.html"><a href="introduction-2.html#network-processes"><i class="fa fa-check"></i><b>7.1.3</b> Network Processes</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html"><i class="fa fa-check"></i><b>7.2</b> Descriptive Statistics of Networks</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics"><i class="fa fa-check"></i><b>7.2.1</b> Vertex and Edge Characteristics</a></li>
<li class="chapter" data-level="7.2.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion"><i class="fa fa-check"></i><b>7.2.2</b> Characterizing Network Cohesion</a></li>
<li class="chapter" data-level="7.2.3" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#graph-partitioning"><i class="fa fa-check"></i><b>7.2.3</b> Graph Partitioning</a></li>
<li class="chapter" data-level="7.2.4" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing"><i class="fa fa-check"></i><b>7.2.4</b> Assortativity and Mixing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html"><i class="fa fa-check"></i><b>7.3</b> Data Collection and Sampling</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#sampling-designs"><i class="fa fa-check"></i><b>7.3.1</b> Sampling Designs</a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#coping-strategies"><i class="fa fa-check"></i><b>7.3.2</b> Coping Strategies</a></li>
<li class="chapter" data-level="7.3.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#big-data-solves-nothing"><i class="fa fa-check"></i><b>7.3.3</b> Big Data Solves Nothing</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html"><i class="fa fa-check"></i><b>7.4</b> Mathematical Models for Network Graphs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models"><i class="fa fa-check"></i><b>7.4.1</b> Classical Random Graph Models</a></li>
<li class="chapter" data-level="7.4.2" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models"><i class="fa fa-check"></i><b>7.4.2</b> Generalized Random Graph Models</a></li>
<li class="chapter" data-level="7.4.3" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms"><i class="fa fa-check"></i><b>7.4.3</b> Network Graph Models Based on Mechanisms</a></li>
<li class="chapter" data-level="7.4.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics"><i class="fa fa-check"></i><b>7.4.4</b> Assessing Significance of Network Graph Characteristics</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html"><i class="fa fa-check"></i><b>7.5</b> Introduction to ERGM</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#exponential-random-graph-models"><i class="fa fa-check"></i><b>7.5.1</b> Exponential Random Graph Models</a></li>
<li class="chapter" data-level="7.5.2" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation"><i class="fa fa-check"></i><b>7.5.2</b> Difficulty in Parameter Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html"><i class="fa fa-check"></i><b>7.6</b> Parameter Estimation of ERGM</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm"><i class="fa fa-check"></i><b>7.6.1</b> Current Methods for ERGM</a></li>
<li class="chapter" data-level="7.6.2" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm"><i class="fa fa-check"></i><b>7.6.2</b> Approximation-based Algorithm</a></li>
<li class="chapter" data-level="7.6.3" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches"><i class="fa fa-check"></i><b>7.6.3</b> Auxiliary Variable MCMC-based Approaches</a></li>
<li class="chapter" data-level="7.6.4" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc"><i class="fa fa-check"></i><b>7.6.4</b> Varying Trunction Stochastic Approximation MCMC</a></li>
<li class="chapter" data-level="7.6.5" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#conclusion"><i class="fa fa-check"></i><b>7.6.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html"><i class="fa fa-check"></i><b>7.7</b> ERGM for Dynamic Networks</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm"><i class="fa fa-check"></i><b>7.7.1</b> Temporal ERGM (TERGM, T ERGM)</a></li>
<li class="chapter" data-level="7.7.2" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm"><i class="fa fa-check"></i><b>7.7.2</b> Separable Temporal ERGM (STERGM, ST ERGM)</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="latent-network-models.html"><a href="latent-network-models.html"><i class="fa fa-check"></i><b>7.8</b> Latent Network Models</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-model"><i class="fa fa-check"></i><b>7.8.1</b> Latent Position Model</a></li>
<li class="chapter" data-level="7.8.2" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-cluster-model"><i class="fa fa-check"></i><b>7.8.2</b> Latent Position Cluster Model</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html"><i class="fa fa-check"></i><b>7.9</b> Additive and Multiplicative Effects Network Models</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#introduction-3"><i class="fa fa-check"></i><b>7.9.1</b> Introduction</a></li>
<li class="chapter" data-level="7.9.2" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression"><i class="fa fa-check"></i><b>7.9.2</b> Social Relations Regression</a></li>
<li class="chapter" data-level="7.9.3" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models"><i class="fa fa-check"></i><b>7.9.3</b> Multiplicative Effects Models</a></li>
<li class="chapter" data-level="7.9.4" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation"><i class="fa fa-check"></i><b>7.9.4</b> Inference via Posterior Approximation</a></li>
<li class="chapter" data-level="7.9.5" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r"><i class="fa fa-check"></i><b>7.9.5</b> Discussion and Example with R</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html"><i class="fa fa-check"></i><b>7.10</b> Stochastic Block Models</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html#stochastic-block-model"><i class="fa fa-check"></i><b>7.10.1</b> Stochastic Block Model</a></li>
<li class="chapter" data-level="7.10.2" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm"><i class="fa fa-check"></i><b>7.10.2</b> Mixed Membership Block Model (MMBM)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="high-dimension.html"><a href="high-dimension.html"><i class="fa fa-check"></i><b>8</b> High Dimension</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html"><i class="fa fa-check"></i><b>8.2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation</a></li>
<li class="chapter" data-level="8.2.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#from-markov-to-chernoff"><i class="fa fa-check"></i><b>8.2.2</b> From Markov to Chernoff</a></li>
<li class="chapter" data-level="8.2.3" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.3</b> sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.4" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.4</b> Properties of sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.5" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#equivalent-definitions"><i class="fa fa-check"></i><b>8.2.5</b> Equivalent definitions</a></li>
<li class="chapter" data-level="8.2.6" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-vectors"><i class="fa fa-check"></i><b>8.2.6</b> Sub-Gaussian random vectors</a></li>
<li class="chapter" data-level="8.2.7" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#hoeffdings-inequality"><i class="fa fa-check"></i><b>8.2.7</b> Hoeffding’s inequality</a></li>
<li class="chapter" data-level="8.2.8" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#maximal-inequalities"><i class="fa fa-check"></i><b>8.2.8</b> Maximal inequalities</a></li>
<li class="chapter" data-level="8.2.9" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#section"><i class="fa fa-check"></i><b>8.2.9</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html"><i class="fa fa-check"></i><b>8.3</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#sub-exponential-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Sub-exponential random variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#bernsteins-condition"><i class="fa fa-check"></i><b>8.3.2</b> Bernstein’s condition</a></li>
<li class="chapter" data-level="8.3.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#mcdiarmids-inequality"><i class="fa fa-check"></i><b>8.3.3</b> McDiarmid’s inequality</a></li>
<li class="chapter" data-level="8.3.4" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#levys-inequality"><i class="fa fa-check"></i><b>8.3.4</b> Levy’s inequality</a></li>
<li class="chapter" data-level="8.3.5" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#quadratic-form"><i class="fa fa-check"></i><b>8.3.5</b> Quadratic form</a></li>
<li class="chapter" data-level="8.3.6" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma"><i class="fa fa-check"></i><b>8.3.6</b> The Johnson–Lindenstrauss Lemma</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html"><i class="fa fa-check"></i><b>8.4</b> Metric entropy and its uses</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#metric-space"><i class="fa fa-check"></i><b>8.4.1</b> Metric space</a></li>
<li class="chapter" data-level="8.4.2" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy"><i class="fa fa-check"></i><b>8.4.2</b> Covering numbers and metric entropy</a></li>
<li class="chapter" data-level="8.4.3" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#packing-numbers"><i class="fa fa-check"></i><b>8.4.3</b> Packing numbers</a></li>
<li class="chapter" data-level="8.4.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-1"><i class="fa fa-check"></i><b>8.4.4</b> </a></li>
<li class="chapter" data-level="8.4.5" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-2"><i class="fa fa-check"></i><b>8.4.5</b> </a></li>
<li class="chapter" data-level="8.4.6" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-3"><i class="fa fa-check"></i><b>8.4.6</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="covariance-estimation.html"><a href="covariance-estimation.html"><i class="fa fa-check"></i><b>8.5</b> Covariance estimation</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="covariance-estimation.html"><a href="covariance-estimation.html#matrix-algebra-review"><i class="fa fa-check"></i><b>8.5.1</b> Matrix algebra review</a></li>
<li class="chapter" data-level="8.5.2" data-path="covariance-estimation.html"><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm"><i class="fa fa-check"></i><b>8.5.2</b> Covariance matrix estimation in the operator norm</a></li>
<li class="chapter" data-level="8.5.3" data-path="covariance-estimation.html"><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices"><i class="fa fa-check"></i><b>8.5.3</b> Bounds for structured covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html"><i class="fa fa-check"></i><b>8.6</b> Matrix concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-calculus"><i class="fa fa-check"></i><b>8.6.1</b> Matrix calculus</a></li>
<li class="chapter" data-level="8.6.2" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-chernoff"><i class="fa fa-check"></i><b>8.6.2</b> Matrix Chernoff</a></li>
<li class="chapter" data-level="8.6.3" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices"><i class="fa fa-check"></i><b>8.6.3</b> Sub-Gaussian and sub-exponential matrices</a></li>
<li class="chapter" data-level="8.6.4" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><i class="fa fa-check"></i><b>8.6.4</b> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>8.7</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-1"><i class="fa fa-check"></i><b>8.7.1</b> PCA</a></li>
<li class="chapter" data-level="8.7.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#matrix-perturbation"><i class="fa fa-check"></i><b>8.7.2</b> Matrix Perturbation</a></li>
<li class="chapter" data-level="8.7.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#spiked-cov-model"><i class="fa fa-check"></i><b>8.7.3</b> Spiked Cov Model</a></li>
<li class="chapter" data-level="8.7.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#sparse-pca"><i class="fa fa-check"></i><b>8.7.4</b> sparse PCA</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>8.8</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="linear-regression.html"><a href="linear-regression.html#problem-formulation"><i class="fa fa-check"></i><b>8.8.1</b> Problem formulation</a></li>
<li class="chapter" data-level="8.8.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimator-in-high-dimensions"><i class="fa fa-check"></i><b>8.8.2</b> Least Squares Estimator in high dimensions</a></li>
<li class="chapter" data-level="8.8.3" data-path="linear-regression.html"><a href="linear-regression.html#sparse-linear-regression"><i class="fa fa-check"></i><b>8.8.3</b> Sparse linear regression</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html"><i class="fa fa-check"></i><b>8.9</b> Uniform laws of large numbers</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#motivation-1"><i class="fa fa-check"></i><b>8.9.1</b> Motivation</a></li>
<li class="chapter" data-level="8.9.2" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity"><i class="fa fa-check"></i><b>8.9.2</b> A uniform law via Rademacher complexity</a></li>
<li class="chapter" data-level="8.9.3" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity"><i class="fa fa-check"></i><b>8.9.3</b> Upper bounds on the Rademacher complexity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>9</b> Survival Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-5.html"><a href="introduction-5.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>9.2</b> </a></li>
<li class="chapter" data-level="9.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html"><i class="fa fa-check"></i><b>9.3</b> Counting Processes and Martingales</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#conditional-expectation"><i class="fa fa-check"></i><b>9.3.1</b> Conditional Expectation</a></li>
<li class="chapter" data-level="9.3.2" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#martingale"><i class="fa fa-check"></i><b>9.3.2</b> Martingale</a></li>
<li class="chapter" data-level="9.3.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#key-martingales-properties"><i class="fa fa-check"></i><b>9.3.3</b> Key Martingales Properties</a></li>
<li class="chapter" data-level="9.3.4" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-5"><i class="fa fa-check"></i><b>9.3.4</b> </a></li>
<li class="chapter" data-level="9.3.5" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-6"><i class="fa fa-check"></i><b>9.3.5</b> </a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>9.4</b> </a></li>
<li class="chapter" data-level="9.5" data-path="cox-regression.html"><a href="cox-regression.html"><i class="fa fa-check"></i><b>9.5</b> Cox Regression</a></li>
<li class="chapter" data-level="9.6" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html"><i class="fa fa-check"></i><b>9.6</b> Filtration의 개념을 정복하자!</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약"><i class="fa fa-check"></i><b>9.6.1</b> Random Process를 이야기 하기까지의 긴 여정의 요약</a></li>
<li class="chapter" data-level="9.6.2" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#ft-measurable"><i class="fa fa-check"></i><b>9.6.2</b> Ft-measurable</a></li>
<li class="chapter" data-level="9.6.3" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#epilogue"><i class="fa fa-check"></i><b>9.6.3</b> EPILOGUE</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>9.7</b> Concepts</a></li>
</ul></li>
<li class="appendix"><span><b>00-00</b></span></li>
<li class="chapter" data-level="A" data-path="concepts-1.html"><a href="concepts-1.html"><i class="fa fa-check"></i><b>A</b> Concepts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="autologistic.html"><a href="autologistic.html"><i class="fa fa-check"></i><b>A.1</b> Autologistics</a></li>
<li class="chapter" data-level="A.2" data-path="orderlogit.html"><a href="orderlogit.html"><i class="fa fa-check"></i><b>A.2</b> Ordered Logit</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="abstract-1.html"><a href="abstract-1.html"><i class="fa fa-check"></i><b>B</b> ABSTRACT</a></li>
<li class="chapter" data-level="C" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>C</b> CNN</a></li>
<li class="chapter" data-level="D" data-path="cnn-1.html"><a href="cnn-1.html"><i class="fa fa-check"></i><b>D</b> CNN</a></li>
<li class="chapter" data-level="E" data-path="cnn-2.html"><a href="cnn-2.html"><i class="fa fa-check"></i><b>E</b> CNN</a></li>
<li class="chapter" data-level="F" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>F</b> 01</a></li>
<li class="chapter" data-level="G" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>G</b> 02</a>
<ul>
<li class="chapter" data-level="G.1" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>G.1</b> 10.</a>
<ul>
<li class="chapter" data-level="G.1.1" data-path="section-10.html"><a href="section-10.html#stochastic-block-model-1"><i class="fa fa-check"></i><b>G.1.1</b> Stochastic Block Model</a></li>
<li class="chapter" data-level="G.1.2" data-path="section-10.html"><a href="section-10.html#likelihood-function-1"><i class="fa fa-check"></i><b>G.1.2</b> Likelihood function</a></li>
<li class="chapter" data-level="G.1.3" data-path="section-10.html"><a href="section-10.html#mixed-membership-block-model-mmbm-1"><i class="fa fa-check"></i><b>G.1.3</b> Mixed Membership Block Model (MMBM)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-collection-and-sampling" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Data Collection and Sampling</h2>
<p>Difficulties in Network Data Collection. 뭔 분야든 통계의 근간은 데이터 수집. 데이터가 <strong>IID</strong>라면 이 데이터는 sample이나 실험에서 확보한 데이터. 하지만 이는 네트워크 실험에서는 사실상 불가능. 따라서 우리는 샘플을 deal with 하기가 어려우며, 이전에 해왔던 것 대비 일이 무척 어려워짐. 이러한 복잡성은 empirical networks를 다룰 때는 너무나도 자주 무시되고 있어서 안타까운 실정임.</p>
<ul>
<li><strong>Sampling Procedures</strong></li>
</ul>
<p>이상적인 데이터에 해당하는 네트워크 census 를 생각해보자. 이는 모든 node 와 edge 를 기록하고 거기에 오류가 없음. 만약 완벽한 네트워크 census 데이터를 가지고 있는 케이스라면 샘플링 과정 스킵하고 바로 네트워크 formation 모델하는 단계로 넘어갈 수 있음.</p>
<p>하지만 그렇게 운좋을리가. 대다수의 경우에 보유한 네트워크 census 데이터는 불완전함. 보통 이런 실패는 네트워크의 성질과 mesurement process의 디테일 부족에서 옴. Survey 케이스를 생각해보자. survey 질문자, survey 답변자의 성격, survey 질문 구성 등으로 이런건 널뛰기함. 아니면 일부 질문 같은 경우에는 “가장 좋아하는 연예인 3명” 이런 식이라고 치자고. 이러면 4명 이하부터는 <strong>censoring</strong> 발생해서 이것도 완벽 데이터에서 왜곡됨.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="sampling-designs" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Sampling Designs</h3>
<p>우리가 <strong>true</strong>(참정보, 참값)를 확보하는 것이 불가능하다면, 우리는 IID 통계량에 의해 예시되었던 “population” graph <span class="math inline">\(G = (V, E)\)</span> 확보를 포기하고 “sample” graph <span class="math inline">\(G^\ast = (V^\ast, E^\ast)\)</span>를 얻는 쪽으로 선회한다. 이때 <span class="math inline">\(V^\ast \subset V\)</span>, <span class="math inline">\(E^\ast \subset E\)</span>.</p>
<p>이러한 sampled subgraphs를 얻기 위한 다양한 방법들에 대응되는 서로 다른 sampling designs들이 존재한다. 우선 population으로부터의 units들에 대한 simple random sample (SRS)를 이해하는 것이 샘플링을 이해하기 위한 1단계가 된다. 네트워크에서는 단순 랜덤 샘플마저도 복잡한 이해를 거쳐야 한다.</p>
<p><br>
<br>
<br></p>
<div id="induced-and-incident-subgraph" class="section level4" number="7.3.1.1">
<h4><span class="header-section-number">7.3.1.1</span> Induced and Incident Subgraph</h4>
<p>node <span class="math inline">\(V\)</span>의 Simpl Random Sample (SRS)인 <span class="math inline">\(V^\ast\)</span>로부터 시작하자. 이로부터 발생시킨 (induced) subgraph <span class="math inline">\((i, j) \in E^\ast\)</span>. 이때 <span class="math inline">\((i, j) \in E^\ast \Leftrightarrow (i,j) \in E\)</span>, <span class="math inline">\(i \in V^\ast\)</span> and <span class="math inline">\(j \in V^\ast\)</span> 여야만 함. 이 정제되지 않은 natural 한 과정인 <strong>induced subgraph sampling</strong> 은 정말 간단한 네트워크 stats 에 대해서도 엄청 biased. bias를 계산해낸 후에 bias 를 보정할 수 있는 경우도 있지만 여하튼 bias 가 크다는게 장점은 아니지.</p>
<p>반면에 우리는 edge의 SRS에서 시작해볼 수도 있다. 이 경우 <span class="math inline">\(E^\ast\)</span>는 <span class="math inline">\(E\)</span>의 SRS. 이후 이 edge 양끝에 해당하는 발생을 node로서 잡는다. 이인즉슨 <span class="math inline">\(\exists j \in V:(i,j) \in E^\ast \Rightarrow i \in V^\ast\)</span>. 고전적 survey 에 대해 쌓인 경험에 비추어볼 때 <strong>incident-subgraph sampling</strong> 는 꽤 괴상해보이지만, 그럼에도 이쪽이 natural 한 경우가 꽤 있기는 함.</p>
<div id="example-of-a-bias" class="section level5" number="7.3.1.1.1">
<h5><span class="header-section-number">7.3.1.1.1</span> Example of a Bias</h5>
<p>우리가 정말정말 간단하기 그지없는 작업인 node 의 랜덤 샘플링을 진행할 때조차도 샘플링이 왜 bias 를 유발해버리는 걸까? 이는 <strong>mean degree</strong> 를 생각해보면 쉽게 알 수 있다. 직관적으로 생각해보자. induced subgraph 를 하나 가지고 있다. 이때 우리는 induced subgraph 바깥인데 전체 그래프 안에 있는, 즉 induced subgraph 에 포함되지 못한 edge 는 관측할 수가 없다. 따라서 우리가 각 node 에 대해 기록할 수 있는 degree 는 많아봤자 그것들의 degree 참값에 불과할 것이다. 따라서 샘플된 그래프들의 mean degree 는 mean degree 의 참값보다 작아져버리겠지. bias 발생.</p>
<p>let <span class="math inline">\(k_i = \sum_{j=1}^n A_{ij}\)</span>, 즉 <span class="math inline">\(k_i\)</span>는 node <span class="math inline">\(i\)</span>의 degree. 이 경우 모든 네트워크에 걸친 mean degree는 $k =  <em>{i=1}^n k</em>{i} $. 여기서 <span class="math inline">\(m\)</span>개의 노드를 SRS 한다면, node <span class="math inline">\(i\)</span>에게 부여된 확률은 모든 각각의 node에게 부여된 확률과 같으므로, 따라서 <span class="math inline">\(\pi = \frac{m}{n}\)</span>.</p>
<p>여기서 <span class="math inline">\(Z_i\)</span>를 <span class="math inline">\(i \in V^\ast\)</span> 여부에 대한 indicator로 정의하자. 그렇다면 node <span class="math inline">\(i\)</span>가 샘플 안에 있을 경우 <span class="math inline">\(Z_i = 1\)</span>.</p>
<p>또한 관측된 graph <span class="math inline">\(G^\ast\)</span>는 관측된 adjacency matrix <span class="math inline">\(A^\ast\)</span>를 보유하며, <span class="math inline">\(A_{ij}^\ast =1\)</span> iff <span class="math inline">\(A_{ij}=1\)</span>이며 <span class="math inline">\(i,j\)</span> 양쪽 모두가 샘플에 있을 경우에만.</p>
<p>그렇다면 plug-in estimate <span class="math inline">\(\bar k\)</span> from <span class="math inline">\(G^\ast\)</span>의 기댓값 <span class="math inline">\(\bar k^\ast\)</span>는 어떻게 되는가?</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

E \left( \bar k^\ast \right)


&amp;= E \left( \frac{1}{m} \sum_{i \in V^\ast} k_i^\ast \right)

&amp;&amp;= E \left( \frac{1}{m} \sum_{i \in V^\ast} \sum_{j \in V^\ast} A_{ij}^\ast \right)

\\


&amp;= E \left( \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}Z_i Z_j \right)

&amp;&amp;= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  E \left(Z_i Z_j \right)

\\

&amp;= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  \pi^2

&amp;&amp;=\frac{1}{n \pi} \pi^2 \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

\\

&amp;= \frac{\pi}{n } \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

&amp;&amp;= \pi \bar k




\end{alignat}\]</span>
$$</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="exploratory-sampling-design" class="section level4" number="7.3.1.2">
<h4><span class="header-section-number">7.3.1.2</span> Exploratory Sampling Design</h4>
<p><strong>induced</strong> 와 <strong>incident</strong> 이외의 방법론을 쓰고 싶은 경우도 있지 않을까? <strong>induced</strong> 와 <strong>incident</strong> 서브그래프 샘플링 양쪽 모두에서 <strong>sampling frame</strong> 은 실제로 발생하는 그래프에 비하면 약간 좀 거리가 있고 이질적이다. 우리가 SRS 를 사용하는 대상인 population 은 모든 node를 포함하거나, 모든 edge를 포함해야 하지만, <mark>but doesn’t use the graph beyond that.</mark></p>
<p><strong>egocentric</strong> 디자인에서 우리는 nodes 들을 샘플링한 후에 이렇게 샘플링된 nodes 들의 local 이웃에 대해서만, 혹은 <strong>ego network</strong> 에 대해서만, 정보를 수집하고 기록한다. 혹은 <strong>“ego”</strong> 케이스에서 우리는 edge 들이나 initial node 의 이웃들의 edges 들이나 non-edges 들만 기록함; 이는 때때로 <strong>star design</strong> 이라고 불림. star design 케이스에서 우리는 local 그래프 이웃에 대한 정보를 수집한 후 이들이 중복되는 지점이 있는지를 확인함. 기록 과정을 뭘 쓰느냐에 달려있긴 한데 이 정보는 보통 수집 가능함.</p>
<p><br>
<br>
<br></p>
<div id="snowball-sampling" class="section level5" number="7.3.1.2.1">
<h5><span class="header-section-number">7.3.1.2.1</span> Snowball Sampling</h5>
<p>seed node 로 부터 시작. 이의 직접적인 이웃을 바로 기록. 이후 그 이웃들로 이동한 후 또 직접적인 이웃을 기록. 이 작업을 새로운 node 가 더이상 발견되지 않거나, 정해진 size 에 도달할 때까지 함. 이때 seeds 는 여럿이 있을 수 있음. 이 여럿인 경우에, 가령 seeds 가 2개라면, 진행하다가 서로 다른 seed 로부터 촉발된 2개의 snowball 이 overlap 되는 상황에 마주쳤을 때 어느 snowball을 고를지 결정하는 문제가 생김.</p>
<p><strong>snowball 샘플링</strong>은 그래프에 대해, incuded 나 incident 에 의해 얻어지는 것 그 어느것과도 다른 분포를 얻게 되는 결과를 초래함. seed 가 SRS에 의해 정해졌더라도 snowball 에 의해 골라지는 다른 node 들은 랜덤샘플이 아님. initial node 이외의 node 들은 seed 로부터 길을 따라서 도착할 수 있는 node 다 보니, 그들은 적어도 degree 가 1은 보장되어야 하고, 약하게나마 seed 에 연결은 되어 있어야 하마, 일반적으로 평균보다는 높은 degree 를 갖는 경향성을 보임.</p>
<p><br>
<br></p>
</div>
<div id="respondent-driven-sampling" class="section level5" number="7.3.1.2.2">
<h5><span class="header-section-number">7.3.1.2.2</span> Respondent-driven Sampling</h5>
<p><strong>Respondent-driven</strong> 샘플링은 소셜네트워크 상황에서 snowball 샘플링의 유의한 변주. 이는 낙인되었거나 혹은 불법적이라 그들의 존재를 관계적으로 잘 발견해내기 어려운 <strong>sub-populations</strong> 을 찾아내기 위한 방법으로서 태초의 목적은 이것이었음. 이건 연구중인 문제에 해당하는 그룹 안의 멤버를 한둘 골라내서 이들을 이니셜 멤버로 한 뒤 걔들한테 주위 사람들 좀 여기 참가시켜보라고 설득하는 거. 때때로는 이 이니셜 멤버들한테 물리적 토큰(표식)을 준 뒤 이 물리적 표식을 여기 참가하라고 꼬실 대상들한테 뿌리라고 하는 식으로 link 를 트랙하기도 함. 이 물리적 토큰 자체가 인센티브일 수도 있고. 이때 응답자 별로 줄 수 있는 (허락되는) 토큰의 총량이 정해져 있다면 이건 곧 degree 의 censoring 으로 기능함.</p>
<p><br>
<br></p>
</div>
<div id="trace-route-sampling" class="section level5" number="7.3.1.2.3">
<h5><span class="header-section-number">7.3.1.2.3</span> Trace-route Sampling</h5>
<p><strong>Trace-route</strong> 샘플링은 네트워크를 통과하는 각 route 들을 추적하여 네트워크를 검색함. 절차는 아래와 같다:</p>
<ol style="list-style-type: decimal">
<li>source node의 set 을 지정</li>
<li>target node의 set 을 지정</li>
<li>각각의 source-target의 조합에 대해서, source 에서 target으로 도착하는 path 하나를 찾고, 그후 이 path에서 거친 모든 edge와 node를 기록함.</li>
</ol>
<p>물론 이 프로세스는 어떤 path 가 탐색되었는가에 크게 의존하긴 하는데 이건 적용 층위의 문제지 메커니즘 자체가 문제가 있다고 할 건 아님. route 추적이 어떻게 이루어졌는지에 따라 연구자는 “실패” (source 에서 target 으로 도착 못했음) 한 route 에 대한 정보를 얻을수도 있고 못얻을수도 있음.</p>
<p><strong>Trace-route</strong> 샘플링은 체계적으로 degree 분포를 왜곡하며 모든 종류의 그래프들로 하여금 그들이 heavy-tail 인 것처럼 보이게 할 수 있다. 그들이 실제로 heavy-tail 이었든 아니든.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
</div>
<div id="coping-strategies" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Coping Strategies</h3>
<div id="head-in-sand" class="section level4" number="7.3.2.1">
<h4><span class="header-section-number">7.3.2.1</span> Head in Sand</h4>
<p>이인즉 샘플링으로 인한 왜곡이나 bias 를 싹 무시하고 우리가 현재 보고 있는 그래프가 그래프의 참값이라고 가정하는 것. <strong>당연히 좋은 생각은 아님.</strong> <strong>incuded</strong> 서브그래프 샘플링의 경우에 mean degree는 real degree 에서 bias 되어 있는데, 이 bias 는 계산 가능함. 실제로 모든 <mark>motif</mark>에 대해 motif count 의 샘플값도 또한 (얘도 계산 가능한 방법으로) 편향되어 있다. 얘들을 사후적으로 보정하는 건 꽤 쉬운 편. 하지만 다른 놈들은 복잡하게 꼬여있는데, 꼬여있는 놈들 중 일례로 degree 분포의 경우에는 매우 복잡하게 왜곡되어 있어서 사후적으로 보정하기가 드럽게 어렵다. 이건 induced 상황에서도 마찬가지로 복잡해서 사후적 보정이 난해함.</p>
<p><br>
<br>
<br></p>
</div>
<div id="learn-sampling-theory" class="section level4" number="7.3.2.2">
<h4><span class="header-section-number">7.3.2.2</span> Learn Sampling Theory</h4>
<p><strong>Classical sampling theory</strong>은 통계적 추론에 대한 이론으로, <mark>probability assumption은 오직 샘플링 프로세스에 대해서만 (성립)만들어진다는 것을 그 골자로 한다.</mark> population의 참값은 unknown 하나 fixed 되어 이 참값이 어떻게 생산되었는지에 대해서는 어떤 stochastic 가정도 만들어지지 않는다. (이를 unknown population 에 대해 조건부를 건다고 생각해도 틀리지 않다.) 모든 probability assumption 들이 샘플링 디자인에 대해서만 논하며, 추론의 타당성은 오직 디자인이 정확히 모델링되었는지 여부에만 의존하므로, 이는 때때로 <strong>design-based</strong> 추론이라고도 불린다.</p>
<p>크기가 n 인 어떤 finite population 에 대한 어떤 quantity <span class="math inline">\(X_i\)</span> 의 평균을 a sample of units <span class="math inline">\(S\)</span> 를 사용해구하고자 하는 상황이라고 해보자. 간단하고 고전적인 해는 <strong>Horvitz-Thompson estimator</strong>:</p>
<p><span class="math display">\[
\hat \mu_{HT} \equiv \frac{1}{n} \sum_{i \in S}\frac{X_i}{\pi_i}
\]</span></p>
<ul>
<li><span class="math inline">\(\pi_i\)</span>는 unit <span class="math inline">\(i\)</span>의 (assumed-known) 포함확률, 즉 unit <span class="math inline">\(i\)</span>가 샘플에 포함될 확률.</li>
</ul>
<p>포함 확률은 <span class="math inline">\(\pi = \frac{|S|}{n}\)</span>로 모두 동일하다는 것을 notice. 즉 우리는 다시 sample mean <span class="math inline">\(X\)</span>로 되돌아감. 이에 대한 직관은 곧 우리가 1개의 unit을 보았고 그 unit의 포함확률이 <span class="math inline">\(\pi_i\)</span>라면, 우리가 보지 못한 <span class="math inline">\(\frac{1}{\pi_i}\)</span>개의 다른 것들이 있다는 것이 골자이다. 더 이론적으로 들어가자면 우리는 이것이 <strong>UE</strong>임을 보일 수 있다.</p>
<p>indicator 변수 <span class="math inline">\(Z_i = I(i \in S), i \in 1:n\)</span>을 도입하자. 이를 사용하여 <span class="math inline">\(\hat \mu_{HT}\)</span>의 기댓값을 구하면</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

E \left( \hat \mu_{HT} \right)


&amp;= E \left(\frac{1}{n} \sum_{i \in S} \frac{X_i}{\pi_i} \right)

&amp;&amp;= E \left(\frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} Z_i \right)

\\

&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} E \left( Z_i \right)

&amp;&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} P \left( Z_i =1 \right)

\\

&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} \pi_i

&amp;&amp;= \frac{1}{n} \sum_{i \in 1:n} {X_i}

\\

&amp;= \mu

\end{alignat}\]</span>
$$</p>
<p>또한</p>
<p><span class="math display">\[
Var \left ( \hat \mu_{HT} \right )= \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]</span></p>
<p>이때 <span class="math inline">\(\pi_{ij}\)</span>는 joint 포함확률. 즉슨 <span class="math inline">\(i,j\)</span>가 한번에 샘플에 들어있을 확률. (<span class="math inline">\(\pi_{ii} = \pi_i\)</span>로 취급)</p>
<p>모든 <span class="math inline">\(\pi_i \rightarrow 1\)</span>로 가게 된다면, <span class="math inline">\(Var \rightarrow 0\)</span>.</p>
<p>이 Var 참값을 정확히 계산하는 건 불가능. 우리는 population 안의 모든 unknown units의 합을 구하는건 불가능하기 때문. 그러가 empirical 대체값은 주어져 있다. 이는</p>
<p><span class="math display">\[
\hat {Var} \left ( \hat \mu_{HT} \right) = \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]</span></p>
<p><strong>sampling-theory approach</strong>는 population quantity의 평균 (혹은 총량) 으로 나타낼 수 있는 대상에게 적합. 혹은 샘플링 디자인에 대한 지식으로부터 포함 (inclusion) 확률을 파악할 수 있는 상황에 대해서도 쓸만하다. 많은 네트워크 stats는 <strong>평균</strong>으로 표현될 수 있지만 (때때로 “unit”을 정의하여 해결하기도 함, node 의 dyad 같은 거), inclusion 확률을 정확히 계산해내는 건 평균 구하는 것보다는 더 빡셈.</p>
<p><br>
<br>
<br></p>
</div>
<div id="missing-data-tools" class="section level4" number="7.3.2.3">
<h4><span class="header-section-number">7.3.2.3</span> Missing Data Tools</h4>
<p>다른 방법은 네트워크에서 unobserved 된 부분을 missing data로 처리하고 이를 추론해버리는 것. 이건 simple imputation 전략부터 시작해서, EM 알고리즘과 같이 추론에 대한 복잡한 모델-based 전략에 이르기까지 다양한 것들이 속한다. EM 혹은 성공적인 imputation은 design-based 가 아니라 model-based 이며, 네트워크와 샘플링 프로세스 양쪽 모두에 대한 모델을 필요로 한다. 실전에서 “missing at random” 상황은 진짜 엄청나게 드물며, “missing completely at random” 상황조차도 흔하지 않다. <mark> let alone </mark></p>
<p><br>
<br>
<br></p>
</div>
<div id="model-the-effective-network" class="section level4" number="7.3.2.4">
<h4><span class="header-section-number">7.3.2.4</span> Model the Effective Network</h4>
<p>마지막 전략은 observed 네트워크를 모델링하는 것. 즉 observation / 샘플링 프로세스와 실제 네트워크 양쪽 모두를 모델링하지만, 그 후 이 둘을 합치는 것으로 observed 그래프에 대한 확률 분포의 family 를 얻는 것이 가능함. 그 observed 네트워크는 underlying generative 모델의 패러미터에 대해 여전히 informative. 이게 알고 싶은 전부라면, 여기까지만 진행한 후에 종료해버릴 수 있음. 전부가 아니라면 이것 이후에 EM이나 imputation 써서 full 그래프를 복원하고자 시도하게 될 것이고.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="big-data-solves-nothing" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Big Data Solves Nothing</h3>
<p>“<span class="math inline">\(n =\)</span> all” 로 설정되고 모든 데이터가 자동적으로 기록된 경우에도 우리가 겪어온 모든 네트워크 샘플링 문제는 여전히 남아있음. 이런 상황에서도 우리가 얻은 데이터는 결국 biased convenience 샘플을 갖고 있는 것이지 가지고 있는 모든 자료가 참값이라고 말할 수가 없기 때문임. 네트워크에서는 특히 아래와 같은 3가지 문제가 두드러짐.</p>
<p><mark>Even when, as the promoters say, “n = all,” and the data are automatically recorded (voluntarily or involuntarily), almost all the network sampling issues we’ve gone over remain. After all, as the promoters do not say, you’re getting all of a biased convenience sample, not all of the truth. Three issues are particularly prominent for network.</mark></p>
<ol style="list-style-type: decimal">
<li>Entity Resolution</li>
<li>Diffusion</li>
<li>Performativity</li>
</ol>
<p><br>
<br>
<br></p>
<div id="entity-resolution" class="section level4" number="7.3.3.1">
<h4><span class="header-section-number">7.3.3.1</span> Entity resolution</h4>
<p><strong>Entity resolution</strong>, 혹은 <strong>record linkage</strong> 라 불리는 것은 데이터 분석에서 메이저한 문제 중 하나. 이는 간단하게 말하면 동일 대상에 대해 서로 다른 시간대에 기록된 자료가 있다면 이 중 무엇을 쓸 것인가 하는 문제. 혹은 겉보기에 같은 대상에 대해 서술하는 것 같은 (co-referent) 기록들이 실제로는 다른 것들에 대해 이야기하고 있는 상황
. 네트워크에서 이는 보통 같은 underlying entity 로 직결되는 2개의 다른 node 들 중에 뭘 고를까 하는 문제가 됨.</p>
<p><br>
<br>
<br></p>
</div>
<div id="diffusion" class="section level4" number="7.3.3.2">
<h4><span class="header-section-number">7.3.3.2</span> Diffusion</h4>
<p><strong>diffusion</strong>은 우리에게 빅데이터를 제공하는 많은 자동적으로 기록된 네트워크들이 다른 오래된 소셜 네트워크로 퍼져나가는 것. <mark>provide A with B</mark> 예를 들어 페북의 tie는 pre-페북의 소셜 네트워크과 diffusion 프로세스의 결과물이다. 이 결과물을 이해하는데에는 비교적 약간의 노력만이 이루어졌다. diffusion 프로세스가 모든 node 를 균질하게 취겁하더라도, diffusion을 당한 네트워크는 기반 네트워크와 그 특성이 근본적으로 다를 수 있다.</p>
<p><br>
<br>
<br></p>
</div>
<div id="performativity" class="section level4" number="7.3.3.3">
<h4><span class="header-section-number">7.3.3.3</span> Performativity</h4>
<p>이론이 자기실현적 예전이 되어버리는 상황을 Performativity라고 함. 온라인 소셜 네트워크를 운영하는 회사들은 사용자들의 크고 조밀한 네트워크를 만들어낼 수 있도록 엄청나게 투자중. 이것이 그들이 link 제안 혹은 link 추천 서비스를 제공하는 이유임. 왜 당신이 아실지도 모르는 친구 이런거. 이러한 추천의 이면에 있는 알고리즘들은 소셜 네트워크가 어떻게 만들어지는지에 대한 이론과 그들이 어떤 link 패턴을 가져야하는지에 대한 이론 등이 반영되어 있다. 유저들이 이러한 추천 친구와 link 를 수락하는 순간 이 알고리즘 이면에 반영된 이론의 입맛에 맞는 케이스가 강화되는 거.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptive-statistics-of-networks.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mathematical-models-for-network-graphs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/212103_DataCollection.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
