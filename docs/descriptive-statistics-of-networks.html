<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.2 Descriptive Statistics of Networks | Self-Study</title>
  <meta name="description" content="7.2 Descriptive Statistics of Networks | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.2 Descriptive Statistics of Networks | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.2 Descriptive Statistics of Networks | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-2.html"/>
<link rel="next" href="data-collection-and-sampling.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="part"><span><b>I 20-02</b></span></li>
<li class="chapter" data-level="1" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>1</b> Categorical</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="overview.html"><a href="overview.html#data-type-and-statistical-analysis"><i class="fa fa-check"></i><b>1.1.1</b> Data Type and Statistical Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian</a>
<ul>
<li class="chapter" data-level="2.1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>2.1</b> Abstract</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="abstract.html"><a href="abstract.html#변수의-독립성"><i class="fa fa-check"></i><b>2.1.1</b> 변수의 독립성</a></li>
<li class="chapter" data-level="2.1.2" data-path="abstract.html"><a href="abstract.html#교환가능성"><i class="fa fa-check"></i><b>2.1.2</b> 교환가능성</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continual-aeassessment-method.html"><a href="continual-aeassessment-method.html"><i class="fa fa-check"></i><b>2.2</b> Continual Aeassessment Method</a></li>
<li class="chapter" data-level="2.3" data-path="horseshoe-prior.html"><a href="horseshoe-prior.html"><i class="fa fa-check"></i><b>2.3</b> Horseshoe Prior</a></li>
</ul></li>
<li class="part"><span><b>II 21-01</b></span></li>
<li class="chapter" data-level="3" data-path="mathematical-stats.html"><a href="mathematical-stats.html"><i class="fa fa-check"></i><b>3</b> Mathematical Stats</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>3.1</b> Inference</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference.html"><a href="inference.html#rao-blackwell-thm."><i class="fa fa-check"></i><b>3.1.1</b> Rao-Blackwell thm.</a></li>
<li class="chapter" data-level="3.1.2" data-path="inference.html"><a href="inference.html#completeness"><i class="fa fa-check"></i><b>3.1.2</b> Completeness</a></li>
<li class="chapter" data-level="3.1.3" data-path="inference.html"><a href="inference.html#레만-쉐페-thm."><i class="fa fa-check"></i><b>3.1.3</b> 레만-쉐페 thm.</a></li>
<li class="chapter" data-level="3.1.4" data-path="inference.html"><a href="inference.html#raoblack"><i class="fa fa-check"></i><b>3.1.4</b> Rao-Blackwell thm.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>3.2</b> Hypothesis Test</a></li>
<li class="chapter" data-level="3.3" data-path="power-fucntion.html"><a href="power-fucntion.html"><i class="fa fa-check"></i><b>3.3</b> Power Fucntion</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="power-fucntion.html"><a href="power-fucntion.html#significance-probability-p-value"><i class="fa fa-check"></i><b>3.3.1</b> Significance Probability (p-value)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="optimal-testing-method.html"><a href="optimal-testing-method.html"><i class="fa fa-check"></i><b>3.4</b> Optimal Testing Method</a></li>
<li class="chapter" data-level="3.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>3.5</b> Data Reduction</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="data-reduction.html"><a href="data-reduction.html#sufficiency-principle"><i class="fa fa-check"></i><b>3.5.1</b> Sufficiency Principle</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="borel-paradox.html"><a href="borel-paradox.html"><i class="fa fa-check"></i><b>3.6</b> Borel Paradox</a></li>
<li class="chapter" data-level="3.7" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html"><i class="fa fa-check"></i><b>3.7</b> Neyman–Pearson lemma</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#overview-1"><i class="fa fa-check"></i><b>3.7.1</b> Overview</a></li>
<li class="chapter" data-level="3.7.2" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#generalized-lrt"><i class="fa fa-check"></i><b>3.7.2</b> Generalized LRT</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="개념.html"><a href="개념.html"><i class="fa fa-check"></i><b>3.8</b> 개념</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>4</b> MCMC</a>
<ul>
<li class="chapter" data-level="4.1" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>4.1</b> Importance Sampling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="importance-sampling.html"><a href="importance-sampling.html#independent-monte-carlo"><i class="fa fa-check"></i><b>4.1.1</b> Independent Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.2</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mh-algorithm"><i class="fa fa-check"></i><b>4.2.1</b> MH Algorithm</a></li>
<li class="chapter" data-level="4.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used"><i class="fa fa-check"></i><b>4.2.2</b> Random Walk Chains (Most Widely Used)</a></li>
<li class="chapter" data-level="4.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler"><i class="fa fa-check"></i><b>4.2.3</b> Basic Gibbs Sampler</a></li>
<li class="chapter" data-level="4.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#implementation"><i class="fa fa-check"></i><b>4.2.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html"><i class="fa fa-check"></i><b>4.3</b> Advanced MCMC (wk08)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#data-augmentation"><i class="fa fa-check"></i><b>4.3.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.3.2" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm"><i class="fa fa-check"></i><b>4.3.2</b> Hit-and-Run Algorithm</a></li>
<li class="chapter" data-level="4.3.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm"><i class="fa fa-check"></i><b>4.3.3</b> Metropolis-Adjusted Langevin Algorithm</a></li>
<li class="chapter" data-level="4.3.4" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm"><i class="fa fa-check"></i><b>4.3.4</b> Multiple-Try Metropolis Algorithm</a></li>
<li class="chapter" data-level="4.3.5" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm"><i class="fa fa-check"></i><b>4.3.5</b> Reversible Jump MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html"><i class="fa fa-check"></i><b>4.4</b> Auxiliary Variable MCMC</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#introduction"><i class="fa fa-check"></i><b>4.4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.4.2" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution"><i class="fa fa-check"></i><b>4.4.2</b> Multimodal Target Distribution</a></li>
<li class="chapter" data-level="4.4.3" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants"><i class="fa fa-check"></i><b>4.4.3</b> Doubly-intractable Normalizing Constants</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html"><i class="fa fa-check"></i><b>4.5</b> Approximate Bayesian Computation</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#simulator-based-models"><i class="fa fa-check"></i><b>4.5.1</b> Simulator-Based Models</a></li>
<li class="chapter" data-level="4.5.2" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods"><i class="fa fa-check"></i><b>4.5.2</b> ABCifying Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.5.3" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm"><i class="fa fa-check"></i><b>4.5.3</b> ABC-MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Hamiltonian Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>4.6.1</b> Introduction to Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html"><i class="fa fa-check"></i><b>4.7</b> Population Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#adaptive-direction-sampling"><i class="fa fa-check"></i><b>4.7.1</b> Adaptive Direction Sampling</a></li>
<li class="chapter" data-level="4.7.2" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#conjugate-gradient-mc"><i class="fa fa-check"></i><b>4.7.2</b> Conjugate Gradient MC</a></li>
<li class="chapter" data-level="4.7.3" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#parallel-tempering"><i class="fa fa-check"></i><b>4.7.3</b> Parallel Tempering</a></li>
<li class="chapter" data-level="4.7.4" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#evolutionary-mc"><i class="fa fa-check"></i><b>4.7.4</b> Evolutionary MC</a></li>
<li class="chapter" data-level="4.7.5" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#sequential-parallel-tempering"><i class="fa fa-check"></i><b>4.7.5</b> Sequential Parallel Tempering</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="stochastic-approximation-monte-carlo.html"><a href="stochastic-approximation-monte-carlo.html"><i class="fa fa-check"></i><b>4.8</b> Stochastic Approximation Monte Carlo</a></li>
<li class="chapter" data-level="4.9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>4.9</b> Review</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="review.html"><a href="review.html#wk01"><i class="fa fa-check"></i><b>4.9.1</b> Wk01</a></li>
<li class="chapter" data-level="4.9.2" data-path="review.html"><a href="review.html#wk03"><i class="fa fa-check"></i><b>4.9.2</b> wk03</a></li>
<li class="chapter" data-level="4.9.3" data-path="review.html"><a href="review.html#wk04-05"><i class="fa fa-check"></i><b>4.9.3</b> wk04, 05</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="else.html"><a href="else.html"><i class="fa fa-check"></i><b>4.10</b> Else</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="else.html"><a href="else.html#hw4.-rasch-model"><i class="fa fa-check"></i><b>4.10.1</b> Hw4. Rasch Model</a></li>
<li class="chapter" data-level="4.10.2" data-path="else.html"><a href="else.html#da-example-mvn"><i class="fa fa-check"></i><b>4.10.2</b> DA) Example: MVN</a></li>
<li class="chapter" data-level="4.10.3" data-path="else.html"><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><i class="fa fa-check"></i><b>4.10.3</b> Bayesian adaptive clinical trial with delayed outcomes</a></li>
<li class="chapter" data-level="4.10.4" data-path="else.html"><a href="else.html#nmar의-종류"><i class="fa fa-check"></i><b>4.10.4</b> NMAR의 종류</a></li>
<li class="chapter" data-level="4.10.5" data-path="else.html"><a href="else.html#wk10-bayesian-model-selection"><i class="fa fa-check"></i><b>4.10.5</b> wk10) Bayesian Model Selection</a></li>
<li class="chapter" data-level="4.10.6" data-path="else.html"><a href="else.html#autologistic-model"><i class="fa fa-check"></i><b>4.10.6</b> Autologistic model</a></li>
<li class="chapter" data-level="4.10.7" data-path="else.html"><a href="else.html#wk10-bayesian-model-averaging"><i class="fa fa-check"></i><b>4.10.7</b> wk10) Bayesian Model Averaging</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mva.html"><a href="mva.html"><i class="fa fa-check"></i><b>5</b> MVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html"><i class="fa fa-check"></i><b>5.1</b> Overview of mva (not ended)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#notation"><i class="fa fa-check"></i><b>5.1.1</b> Notation</a></li>
<li class="chapter" data-level="5.1.2" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#summary-statistics"><i class="fa fa-check"></i><b>5.1.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation"><i class="fa fa-check"></i><b>5.1.3</b> Statistical Inference on Correlation</a></li>
<li class="chapter" data-level="5.1.4" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#standardization"><i class="fa fa-check"></i><b>5.1.4</b> Standardization</a></li>
<li class="chapter" data-level="5.1.5" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#missing-value-treatment"><i class="fa fa-check"></i><b>5.1.5</b> Missing Value Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html"><i class="fa fa-check"></i><b>5.2</b> Multivariate Nomral (wk2)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#overview-2"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#spectral-decomposition"><i class="fa fa-check"></i><b>5.2.2</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="5.2.3" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#properties-of-mvn"><i class="fa fa-check"></i><b>5.2.3</b> Properties of MVN</a></li>
<li class="chapter" data-level="5.2.4" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#chi2-distribution"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\Chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="5.2.5" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors"><i class="fa fa-check"></i><b>5.2.5</b> Linear Combination of Random Vectors</a></li>
<li class="chapter" data-level="5.2.6" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood"><i class="fa fa-check"></i><b>5.2.6</b> Multivariate Normal Likelihood</a></li>
<li class="chapter" data-level="5.2.7" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s"><i class="fa fa-check"></i><b>5.2.7</b> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></a></li>
<li class="chapter" data-level="5.2.8" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#assessing-normality"><i class="fa fa-check"></i><b>5.2.8</b> Assessing Normality</a></li>
<li class="chapter" data-level="5.2.9" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#power-transformation"><i class="fa fa-check"></i><b>5.2.9</b> Power Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html"><i class="fa fa-check"></i><b>5.3</b> Inference about Mean Vector (wk3)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#overview-3"><i class="fa fa-check"></i><b>5.3.1</b> Overview</a></li>
<li class="chapter" data-level="5.3.2" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#confidence-region"><i class="fa fa-check"></i><b>5.3.2</b> 1. Confidence Region</a></li>
<li class="chapter" data-level="5.3.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#simultaneous-ci"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simultaneous CI</a></li>
<li class="chapter" data-level="5.3.4" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison"><i class="fa fa-check"></i><b>5.3.4</b> 3. Note: Bonferroni Multiple Comparison</a></li>
<li class="chapter" data-level="5.3.5" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector"><i class="fa fa-check"></i><b>5.3.5</b> 4. Large Sample Inferences about a Mean Vector</a></li>
<li class="chapter" data-level="5.3.6" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5"><i class="fa fa-check"></i><b>5.3.6</b> 1. Profile Analysis (wk4, 5)</a></li>
<li class="chapter" data-level="5.3.7" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend"><i class="fa fa-check"></i><b>5.3.7</b> 2. Test for Linear Trend</a></li>
<li class="chapter" data-level="5.3.8" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix"><i class="fa fa-check"></i><b>5.3.8</b> 3. Inferences about a Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of Several MV Means (wk5)</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#paired-comparison"><i class="fa fa-check"></i><b>5.4.1</b> Paired Comparison</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations"><i class="fa fa-check"></i><b>5.4.2</b> Comparing Mean Vectors from Two Populations</a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2"><i class="fa fa-check"></i><b>5.4.3</b> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means"><i class="fa fa-check"></i><b>5.4.4</b> Comparing Several Multivariate Population Means</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html"><i class="fa fa-check"></i><b>5.5</b> Multivariate Multiple Regression (wk6)</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#overview-4"><i class="fa fa-check"></i><b>5.5.1</b> Overview</a></li>
<li class="chapter" data-level="5.5.2" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression"><i class="fa fa-check"></i><b>5.5.2</b> Multivariate Multiple Regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.5.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.5.4" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#example"><i class="fa fa-check"></i><b>5.5.4</b> Example)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>5.6</b> PCA</a></li>
<li class="chapter" data-level="5.7" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>5.7</b> Factor</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="factor.html"><a href="factor.html#method-of-estimation"><i class="fa fa-check"></i><b>5.7.1</b> Method of Estimation</a></li>
<li class="chapter" data-level="5.7.2" data-path="factor.html"><a href="factor.html#factor-rotation"><i class="fa fa-check"></i><b>5.7.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="5.7.3" data-path="factor.html"><a href="factor.html#varimax-criterion"><i class="fa fa-check"></i><b>5.7.3</b> Varimax Criterion</a></li>
<li class="chapter" data-level="5.7.4" data-path="factor.html"><a href="factor.html#factor-scores"><i class="fa fa-check"></i><b>5.7.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html"><i class="fa fa-check"></i><b>5.8</b> Discrimination and Classification</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#bayes-rule"><i class="fa fa-check"></i><b>5.8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="5.8.2" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations"><i class="fa fa-check"></i><b>5.8.2</b> Classification with Two mv <span class="math inline">\(N\)</span> Populations</a></li>
<li class="chapter" data-level="5.8.3" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#evaluating-classification-functions"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating Classification Functions</a></li>
<li class="chapter" data-level="5.8.4" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-several-populations-wk13"><i class="fa fa-check"></i><b>5.8.4</b> Classification with several Populations (wk13)</a></li>
<li class="chapter" data-level="5.8.5" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#other-discriminant-analysis-methods"><i class="fa fa-check"></i><b>5.8.5</b> Other Discriminant Analysis Methods</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html"><i class="fa fa-check"></i><b>5.9</b> Clustering, Distance Methods, and Ordination</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#overview-5"><i class="fa fa-check"></i><b>5.9.1</b> Overview</a></li>
<li class="chapter" data-level="5.9.2" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering"><i class="fa fa-check"></i><b>5.9.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="5.9.3" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#k-means-clustering"><i class="fa fa-check"></i><b>5.9.3</b> K-means Clustering</a></li>
<li class="chapter" data-level="5.9.4" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법"><i class="fa fa-check"></i><b>5.9.4</b> 군집의 평가방법</a></li>
<li class="chapter" data-level="5.9.5" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14"><i class="fa fa-check"></i><b>5.9.5</b> Clustering using Density Estimation (wk14)</a></li>
<li class="chapter" data-level="5.9.6" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>5.9.6</b> Multidimensional Scaling (MDS)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>6</b> Linear</a>
<ul>
<li class="chapter" data-level="6.1" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>6.1</b> SVD</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="svd.html"><a href="svd.html#spectral-decomposition-1"><i class="fa fa-check"></i><b>6.1.1</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="6.1.2" data-path="svd.html"><a href="svd.html#singular-value-decomposition-general-version"><i class="fa fa-check"></i><b>6.1.2</b> Singular value Decomposition: General-version</a></li>
<li class="chapter" data-level="6.1.3" data-path="svd.html"><a href="svd.html#singular-value-decomposition-another-version"><i class="fa fa-check"></i><b>6.1.3</b> Singular value Decomposition: Another-version</a></li>
<li class="chapter" data-level="6.1.4" data-path="svd.html"><a href="svd.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1.4</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.1.5" data-path="svd.html"><a href="svd.html#partitioned-matrices"><i class="fa fa-check"></i><b>6.1.5</b> Partitioned Matrices</a></li>
<li class="chapter" data-level="6.1.6" data-path="svd.html"><a href="svd.html#geometrical-aspects"><i class="fa fa-check"></i><b>6.1.6</b> Geometrical Aspects</a></li>
<li class="chapter" data-level="6.1.7" data-path="svd.html"><a href="svd.html#column-row-and-null-space"><i class="fa fa-check"></i><b>6.1.7</b> Column, Row and Null Space</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>6.2</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-1.html"><a href="introduction-1.html#what"><i class="fa fa-check"></i><b>6.2.1</b> What</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-1.html"><a href="introduction-1.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.2.2</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-1.html"><a href="introduction-1.html#multivariate-normal-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Multivariate Normal Distributions</a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-1.html"><a href="introduction-1.html#distributions-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2.4</b> Distributions of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>6.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation.html"><a href="estimation.html#identifiability-and-estimability"><i class="fa fa-check"></i><b>6.3.1</b> Identifiability and Estimability</a></li>
<li class="chapter" data-level="6.3.2" data-path="estimation.html"><a href="estimation.html#estimation-least-squares"><i class="fa fa-check"></i><b>6.3.2</b> Estimation: Least Squares</a></li>
<li class="chapter" data-level="6.3.3" data-path="estimation.html"><a href="estimation.html#estimation-best-linear-unbiased"><i class="fa fa-check"></i><b>6.3.3</b> Estimation: Best Linear Unbiased</a></li>
<li class="chapter" data-level="6.3.4" data-path="estimation.html"><a href="estimation.html#estimation-maximum-likelihood"><i class="fa fa-check"></i><b>6.3.4</b> Estimation: Maximum Likelihood</a></li>
<li class="chapter" data-level="6.3.5" data-path="estimation.html"><a href="estimation.html#estimation-minimum-variance-unbiased"><i class="fa fa-check"></i><b>6.3.5</b> Estimation: Minimum Variance Unbiased</a></li>
<li class="chapter" data-level="6.3.6" data-path="estimation.html"><a href="estimation.html#sampling-distributions-of-estimates"><i class="fa fa-check"></i><b>6.3.6</b> Sampling Distributions of Estimates</a></li>
<li class="chapter" data-level="6.3.7" data-path="estimation.html"><a href="estimation.html#generalized-least-squaresgls"><i class="fa fa-check"></i><b>6.3.7</b> Generalized Least Squares(GLS)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>6.4</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way-anova.html"><a href="one-way-anova.html#one-way-anova-1"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way-anova.html"><a href="one-way-anova.html#more-about-models"><i class="fa fa-check"></i><b>6.4.2</b> More About Models</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way-anova.html"><a href="one-way-anova.html#estimating-and-testing-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating and Testing Contrasts</a></li>
<li class="chapter" data-level="6.4.4" data-path="one-way-anova.html"><a href="one-way-anova.html#cochrans-theorem"><i class="fa fa-check"></i><b>6.4.4</b> Cochran’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>6.5</b> Testing</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="testing.html"><a href="testing.html#more-about-models-two-approaches-for-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> More About Models: Two approaches for linear model</a></li>
<li class="chapter" data-level="6.5.2" data-path="testing.html"><a href="testing.html#testing-models"><i class="fa fa-check"></i><b>6.5.2</b> Testing Models</a></li>
<li class="chapter" data-level="6.5.3" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure"><i class="fa fa-check"></i><b>6.5.3</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.4" data-path="testing.html"><a href="testing.html#testing-linear-parametric-functions"><i class="fa fa-check"></i><b>6.5.4</b> Testing Linear Parametric Functions</a></li>
<li class="chapter" data-level="6.5.5" data-path="testing.html"><a href="testing.html#theoretical-complements"><i class="fa fa-check"></i><b>6.5.5</b> Theoretical Complements</a></li>
<li class="chapter" data-level="6.5.6" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure-1"><i class="fa fa-check"></i><b>6.5.6</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.7" data-path="testing.html"><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace"><i class="fa fa-check"></i><b>6.5.7</b> Testing Single Degrees of Freedom in a Given Subspace</a></li>
<li class="chapter" data-level="6.5.8" data-path="testing.html"><a href="testing.html#breaking-ss-into-independent-components"><i class="fa fa-check"></i><b>6.5.8</b> Breaking SS into Independent Components</a></li>
<li class="chapter" data-level="6.5.9" data-path="testing.html"><a href="testing.html#general-theory"><i class="fa fa-check"></i><b>6.5.9</b> General Theory</a></li>
<li class="chapter" data-level="6.5.10" data-path="testing.html"><a href="testing.html#two-way-anova"><i class="fa fa-check"></i><b>6.5.10</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.5.11" data-path="testing.html"><a href="testing.html#confidence-regions"><i class="fa fa-check"></i><b>6.5.11</b> Confidence Regions</a></li>
<li class="chapter" data-level="6.5.12" data-path="testing.html"><a href="testing.html#tests-for-generalized-least-squares-models"><i class="fa fa-check"></i><b>6.5.12</b> Tests for Generalized Least Squares Models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>6.6</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#a-direct-solution-via-inner-products"><i class="fa fa-check"></i><b>6.6.1</b> A direct solution via inner products</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="flat.html"><a href="flat.html"><i class="fa fa-check"></i><b>6.7</b> Flat</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="flat.html"><a href="flat.html#flat-1"><i class="fa fa-check"></i><b>6.7.1</b> 1.Flat</a></li>
<li class="chapter" data-level="6.7.2" data-path="flat.html"><a href="flat.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>6.7.2</b> 2. Solutions to systems of linear equations</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="unified-approach-to-balanced-anova-models.html"><a href="unified-approach-to-balanced-anova-models.html"><i class="fa fa-check"></i><b>6.8</b> Unified Approach to Balanced ANOVA Models</a></li>
</ul></li>
<li class="part"><span><b>III 21-02</b></span></li>
<li class="chapter" data-level="7" data-path="network-stats.html"><a href="network-stats.html"><i class="fa fa-check"></i><b>7</b> Network Stats</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-2.html"><a href="introduction-2.html#types-of-network-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Types of Network Analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-2.html"><a href="introduction-2.html#network-modeling-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Network Modeling and Inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-2.html"><a href="introduction-2.html#network-processes"><i class="fa fa-check"></i><b>7.1.3</b> Network Processes</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html"><i class="fa fa-check"></i><b>7.2</b> Descriptive Statistics of Networks</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics"><i class="fa fa-check"></i><b>7.2.1</b> Vertex and Edge Characteristics</a></li>
<li class="chapter" data-level="7.2.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion"><i class="fa fa-check"></i><b>7.2.2</b> Characterizing Network Cohesion</a></li>
<li class="chapter" data-level="7.2.3" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#graph-partitioning"><i class="fa fa-check"></i><b>7.2.3</b> Graph Partitioning</a></li>
<li class="chapter" data-level="7.2.4" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing"><i class="fa fa-check"></i><b>7.2.4</b> Assortativity and Mixing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html"><i class="fa fa-check"></i><b>7.3</b> Data Collection and Sampling</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#sampling-designs"><i class="fa fa-check"></i><b>7.3.1</b> Sampling Designs</a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#coping-strategies"><i class="fa fa-check"></i><b>7.3.2</b> Coping Strategies</a></li>
<li class="chapter" data-level="7.3.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#big-data-solves-nothing"><i class="fa fa-check"></i><b>7.3.3</b> Big Data Solves Nothing</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html"><i class="fa fa-check"></i><b>7.4</b> Mathematical Models for Network Graphs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models"><i class="fa fa-check"></i><b>7.4.1</b> Classical Random Graph Models</a></li>
<li class="chapter" data-level="7.4.2" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models"><i class="fa fa-check"></i><b>7.4.2</b> Generalized Random Graph Models</a></li>
<li class="chapter" data-level="7.4.3" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms"><i class="fa fa-check"></i><b>7.4.3</b> Network Graph Models Based on Mechanisms</a></li>
<li class="chapter" data-level="7.4.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics"><i class="fa fa-check"></i><b>7.4.4</b> Assessing Significance of Network Graph Characteristics</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html"><i class="fa fa-check"></i><b>7.5</b> Introduction to ERGM</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#exponential-random-graph-models"><i class="fa fa-check"></i><b>7.5.1</b> Exponential Random Graph Models</a></li>
<li class="chapter" data-level="7.5.2" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation"><i class="fa fa-check"></i><b>7.5.2</b> Difficulty in Parameter Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html"><i class="fa fa-check"></i><b>7.6</b> Parameter Estimation of ERGM</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm"><i class="fa fa-check"></i><b>7.6.1</b> Current Methods for ERGM</a></li>
<li class="chapter" data-level="7.6.2" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm"><i class="fa fa-check"></i><b>7.6.2</b> Approximation-based Algorithm</a></li>
<li class="chapter" data-level="7.6.3" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches"><i class="fa fa-check"></i><b>7.6.3</b> Auxiliary Variable MCMC-based Approaches</a></li>
<li class="chapter" data-level="7.6.4" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc"><i class="fa fa-check"></i><b>7.6.4</b> Varying Trunction Stochastic Approximation MCMC</a></li>
<li class="chapter" data-level="7.6.5" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#conclusion"><i class="fa fa-check"></i><b>7.6.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html"><i class="fa fa-check"></i><b>7.7</b> ERGM for Dynamic Networks</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#temporal-ergm"><i class="fa fa-check"></i><b>7.7.1</b> Temporal ERGM</a></li>
<li class="chapter" data-level="7.7.2" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm"><i class="fa fa-check"></i><b>7.7.2</b> Separable Temporal ERGM</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="latent-network-models.html"><a href="latent-network-models.html"><i class="fa fa-check"></i><b>7.8</b> Latent Network Models</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-model"><i class="fa fa-check"></i><b>7.8.1</b> Latent Position Model</a></li>
<li class="chapter" data-level="7.8.2" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-cluster-model"><i class="fa fa-check"></i><b>7.8.2</b> Latent Position Cluster Model</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html"><i class="fa fa-check"></i><b>7.9</b> Additive and Multiplicative Effects Network Models</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#introduction-3"><i class="fa fa-check"></i><b>7.9.1</b> Introduction</a></li>
<li class="chapter" data-level="7.9.2" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression"><i class="fa fa-check"></i><b>7.9.2</b> Social Relations Regression</a></li>
<li class="chapter" data-level="7.9.3" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models"><i class="fa fa-check"></i><b>7.9.3</b> Multiplicative Effects Models</a></li>
<li class="chapter" data-level="7.9.4" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation"><i class="fa fa-check"></i><b>7.9.4</b> Inference via Posterior Approximation</a></li>
<li class="chapter" data-level="7.9.5" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r"><i class="fa fa-check"></i><b>7.9.5</b> Discussion and Example with R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="high-dimension.html"><a href="high-dimension.html"><i class="fa fa-check"></i><b>8</b> High Dimension</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html"><i class="fa fa-check"></i><b>8.2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation</a></li>
<li class="chapter" data-level="8.2.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#from-markov-to-chernoff"><i class="fa fa-check"></i><b>8.2.2</b> From Markov to Chernoff</a></li>
<li class="chapter" data-level="8.2.3" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.3</b> sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.4" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.4</b> Properties of sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.5" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#equivalent-definitions"><i class="fa fa-check"></i><b>8.2.5</b> Equivalent definitions</a></li>
<li class="chapter" data-level="8.2.6" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-vectors"><i class="fa fa-check"></i><b>8.2.6</b> Sub-Gaussian random vectors</a></li>
<li class="chapter" data-level="8.2.7" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#hoeffdings-inequality"><i class="fa fa-check"></i><b>8.2.7</b> Hoeffding’s inequality</a></li>
<li class="chapter" data-level="8.2.8" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#maximal-inequalities"><i class="fa fa-check"></i><b>8.2.8</b> Maximal inequalities</a></li>
<li class="chapter" data-level="8.2.9" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#section"><i class="fa fa-check"></i><b>8.2.9</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html"><i class="fa fa-check"></i><b>8.3</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#sub-exponential-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Sub-exponential random variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#bernsteins-condition"><i class="fa fa-check"></i><b>8.3.2</b> Bernstein’s condition</a></li>
<li class="chapter" data-level="8.3.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#mcdiarmids-inequality"><i class="fa fa-check"></i><b>8.3.3</b> McDiarmid’s inequality</a></li>
<li class="chapter" data-level="8.3.4" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#levys-inequality"><i class="fa fa-check"></i><b>8.3.4</b> Levy’s inequality</a></li>
<li class="chapter" data-level="8.3.5" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#quadratic-form"><i class="fa fa-check"></i><b>8.3.5</b> Quadratic form</a></li>
<li class="chapter" data-level="8.3.6" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma"><i class="fa fa-check"></i><b>8.3.6</b> The Johnson–Lindenstrauss Lemma</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html"><i class="fa fa-check"></i><b>8.4</b> Metric entropy and its uses</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#metric-space"><i class="fa fa-check"></i><b>8.4.1</b> Metric space</a></li>
<li class="chapter" data-level="8.4.2" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy"><i class="fa fa-check"></i><b>8.4.2</b> Covering numbers and metric entropy</a></li>
<li class="chapter" data-level="8.4.3" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#packing-numbers"><i class="fa fa-check"></i><b>8.4.3</b> Packing numbers</a></li>
<li class="chapter" data-level="8.4.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-1"><i class="fa fa-check"></i><b>8.4.4</b> </a></li>
<li class="chapter" data-level="8.4.5" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-2"><i class="fa fa-check"></i><b>8.4.5</b> </a></li>
<li class="chapter" data-level="8.4.6" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-3"><i class="fa fa-check"></i><b>8.4.6</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="covariance-estimation.html"><a href="covariance-estimation.html"><i class="fa fa-check"></i><b>8.5</b> Covariance estimation</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="covariance-estimation.html"><a href="covariance-estimation.html#matrix-algebra-review"><i class="fa fa-check"></i><b>8.5.1</b> Matrix algebra review</a></li>
<li class="chapter" data-level="8.5.2" data-path="covariance-estimation.html"><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm"><i class="fa fa-check"></i><b>8.5.2</b> Covariance matrix estimation in the operator norm</a></li>
<li class="chapter" data-level="8.5.3" data-path="covariance-estimation.html"><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices"><i class="fa fa-check"></i><b>8.5.3</b> Bounds for structured covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html"><i class="fa fa-check"></i><b>8.6</b> Matrix concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-calculus"><i class="fa fa-check"></i><b>8.6.1</b> Matrix calculus</a></li>
<li class="chapter" data-level="8.6.2" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-chernoff"><i class="fa fa-check"></i><b>8.6.2</b> Matrix Chernoff</a></li>
<li class="chapter" data-level="8.6.3" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices"><i class="fa fa-check"></i><b>8.6.3</b> Sub-Gaussian and sub-exponential matrices</a></li>
<li class="chapter" data-level="8.6.4" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><i class="fa fa-check"></i><b>8.6.4</b> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>8.7</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-1"><i class="fa fa-check"></i><b>8.7.1</b> PCA</a></li>
<li class="chapter" data-level="8.7.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#matrix-perturbation"><i class="fa fa-check"></i><b>8.7.2</b> Matrix Perturbation</a></li>
<li class="chapter" data-level="8.7.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#spiked-cov-model"><i class="fa fa-check"></i><b>8.7.3</b> Spiked Cov Model</a></li>
<li class="chapter" data-level="8.7.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#sparse-pca"><i class="fa fa-check"></i><b>8.7.4</b> sparse PCA</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>8.8</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="linear-regression.html"><a href="linear-regression.html#problem-formulation"><i class="fa fa-check"></i><b>8.8.1</b> Problem formulation</a></li>
<li class="chapter" data-level="8.8.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimator-in-high-dimensions"><i class="fa fa-check"></i><b>8.8.2</b> Least Squares Estimator in high dimensions</a></li>
<li class="chapter" data-level="8.8.3" data-path="linear-regression.html"><a href="linear-regression.html#sparse-linear-regression"><i class="fa fa-check"></i><b>8.8.3</b> Sparse linear regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>9</b> Survival Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-5.html"><a href="introduction-5.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>9.2</b> </a></li>
<li class="chapter" data-level="9.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html"><i class="fa fa-check"></i><b>9.3</b> Counting Processes and Martingales</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#conditional-expectation"><i class="fa fa-check"></i><b>9.3.1</b> Conditional Expectation</a></li>
<li class="chapter" data-level="9.3.2" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#martingale"><i class="fa fa-check"></i><b>9.3.2</b> Martingale</a></li>
<li class="chapter" data-level="9.3.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#key-martingales-properties"><i class="fa fa-check"></i><b>9.3.3</b> Key Martingales Properties</a></li>
<li class="chapter" data-level="9.3.4" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-5"><i class="fa fa-check"></i><b>9.3.4</b> </a></li>
<li class="chapter" data-level="9.3.5" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-6"><i class="fa fa-check"></i><b>9.3.5</b> </a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>9.4</b> </a></li>
<li class="chapter" data-level="9.5" data-path="cox-regression.html"><a href="cox-regression.html"><i class="fa fa-check"></i><b>9.5</b> Cox Regression</a></li>
<li class="chapter" data-level="9.6" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html"><i class="fa fa-check"></i><b>9.6</b> Filtration의 개념을 정복하자!</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약"><i class="fa fa-check"></i><b>9.6.1</b> Random Process를 이야기 하기까지의 긴 여정의 요약</a></li>
<li class="chapter" data-level="9.6.2" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#ft-measurable"><i class="fa fa-check"></i><b>9.6.2</b> Ft-measurable</a></li>
<li class="chapter" data-level="9.6.3" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#epilogue"><i class="fa fa-check"></i><b>9.6.3</b> EPILOGUE</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>9.7</b> Concepts</a></li>
</ul></li>
<li class="appendix"><span><b>00-00</b></span></li>
<li class="chapter" data-level="A" data-path="concepts-1.html"><a href="concepts-1.html"><i class="fa fa-check"></i><b>A</b> Concepts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="autologistic.html"><a href="autologistic.html"><i class="fa fa-check"></i><b>A.1</b> Autologistics</a></li>
<li class="chapter" data-level="A.2" data-path="orderlogit.html"><a href="orderlogit.html"><i class="fa fa-check"></i><b>A.2</b> Ordered Logit</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="abstract-1.html"><a href="abstract-1.html"><i class="fa fa-check"></i><b>B</b> ABSTRACT</a></li>
<li class="chapter" data-level="C" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>C</b> CNN</a></li>
<li class="chapter" data-level="D" data-path="cnn-1.html"><a href="cnn-1.html"><i class="fa fa-check"></i><b>D</b> CNN</a></li>
<li class="chapter" data-level="E" data-path="cnn-2.html"><a href="cnn-2.html"><i class="fa fa-check"></i><b>E</b> CNN</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="descriptive-statistics-of-networks" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Descriptive Statistics of Networks</h2>
<p>complex system 에 대한 연구에서 연구하는 문제는 대응하는 네트워크 그래프의 구조, 혹은 특성을 분석하는 문제로 동치될 수 있음. 3개의 vertex 들을 묶어 특정 형태의 triplet 을 만들어 triplet 의 특성을 분석. 상품이나 정보의 흐름 분석은 네트워크 분석에서의 path 발생 혹은 비발생 확인 문제와 동치. 각각의 시스템에서 해당 element 의 중요도를 체크하는건 vertex 의 centrality 확인과 동치. 동계통의 community 혹은 그룹을 찾는 문제는 그래프 partitioning 문제와 동치. 이런 네트워크 분석은 순혈 통계와는 살짝 차이가 있음. 보통 수학과 컴퓨터과학, 사회구조 분석사회학, 물리학 등에 의존함.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="vertex-and-edge-characteristics" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Vertex and Edge Characteristics</h3>
<p>네트워크의 기본 요소는 <strong>edge</strong> 와 <strong>vertex</strong>. 이들을 characterization 하고자 하는 작업은 <strong>vertex degree</strong> 에 기반하며, 이는 각 vertex 가 얼마나 중요한지를 판단하기 위한 측도를 획득하기 위함.</p>
<p><br>
<br>
<br></p>
<div id="vertex-degree" class="section level4" number="7.2.1.1">
<h4><span class="header-section-number">7.2.1.1</span> Vertex Degree</h4>
<p>네트워크 그래프 <span class="math inline">\(G=(V, E)\)</span> 에서 vertex <span class="math inline">\(v\)</span> 의 <strong>degree</strong> <span class="math inline">\(d_v\)</span> 는 <span class="math inline">\(v\)</span> 에 엮인 edge 의 갯수. <span class="math inline">\(\forall v \in V, d_v = d: f_d \coloneqq \frac{v}{d = d_v}\)</span>. collection <span class="math inline">\(\{f_d\}_{d \ge 0}\)</span> 는 <span class="math inline">\(G\)</span> 의 <strong>degree distribution</strong> 이라고 부른다. 이는 결국 원본 degree sequence 를 rescaling 한 것.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="descriptive-statistics-of-networks.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sand)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="descriptive-statistics-of-networks.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(karate)</span>
<span id="cb5-2"><a href="descriptive-statistics-of-networks.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb5-3"><a href="descriptive-statistics-of-networks.html#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">degree</span>(karate), <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="at">xlab =</span> <span class="st">&quot;Vertex Degree&quot;</span>,</span>
<span id="cb5-4"><a href="descriptive-statistics-of-networks.html#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Frequency&quot;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb5-5"><a href="descriptive-statistics-of-networks.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">graph.strength</span>(karate), <span class="at">col =</span> <span class="st">&quot;pink&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Vertex Strength&quot;</span>,</span>
<span id="cb5-6"><a href="descriptive-statistics-of-networks.html#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Frequency&quot;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:1"></span>
<img src="_main_files/figure-html/1-1.png" alt="Karate Network" width="672" />
<p class="caption">
FIGURE 7.1: Karate Network
</p>
</div>
<p>weighted network 케이스에서 유용하게 자주 쓰이는 degree 의 일반화는 <strong>vertex strength</strong>. 이는 해당 vertex 에 연결된 edge 의 weight 를 전부 합한 것. 이러한 strength 의 distribution 은 <strong>weighted degree distribution</strong> 이라고 불리며, 이는 일반적인 degree distribution 과 입지가 같음.</p>
<p><em>Figure 2: The vertex strength distribution for the Karate club network - A Network of Interactions among Protein Pairs in Yeast</em></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="descriptive-statistics-of-networks.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraphdata)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="descriptive-statistics-of-networks.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(yeast)</span>
<span id="cb7-2"><a href="descriptive-statistics-of-networks.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ecount</span>(yeast)</span>
<span id="cb7-3"><a href="descriptive-statistics-of-networks.html#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11855</span></span>
<span id="cb7-4"><a href="descriptive-statistics-of-networks.html#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">vcount</span>(yeast)</span>
<span id="cb7-5"><a href="descriptive-statistics-of-networks.html#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 2617</span></span></code></pre></div>
<p>히스토그램을 확인해보자. degree 가 낮은 substantial fraction of vertex 들이 존재한다. 이들의 magnitude 는 karate network 의 그것이랑 유사하지만, 이와 동시에 연속적으로 higher order of magnitude 를 가지는 vertex 들의 숫자가 non-trivial 하게 관측된다. 로그화 시킨 degree 의 경우, log frequency 에서 상당한 linear decay 관측 가능.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="descriptive-statistics-of-networks.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb8-2"><a href="descriptive-statistics-of-networks.html#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="descriptive-statistics-of-networks.html#cb8-3" aria-hidden="true" tabindex="-1"></a>d.yeast <span class="ot">=</span> <span class="fu">degree</span>(yeast)</span>
<span id="cb8-4"><a href="descriptive-statistics-of-networks.html#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(d.yeast, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Degree&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Frequency&quot;</span>,</span>
<span id="cb8-5"><a href="descriptive-statistics-of-networks.html#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> <span class="st">&quot;Degree Distribution&quot;</span>)</span>
<span id="cb8-6"><a href="descriptive-statistics-of-networks.html#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="descriptive-statistics-of-networks.html#cb8-7" aria-hidden="true" tabindex="-1"></a>dd.yeast <span class="ot">=</span> <span class="fu">degree.distribution</span>(yeast)</span>
<span id="cb8-8"><a href="descriptive-statistics-of-networks.html#cb8-8" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">max</span>(d.yeast) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb8-9"><a href="descriptive-statistics-of-networks.html#cb8-9" aria-hidden="true" tabindex="-1"></a>ind <span class="ot">=</span> (dd.yeast <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb8-10"><a href="descriptive-statistics-of-networks.html#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d[ind], dd.yeast[ind], <span class="at">log =</span> <span class="st">&quot;xy&quot;</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">xlab =</span> <span class="fu">c</span>(<span class="st">&quot;Log-Degree&quot;</span>),</span>
<span id="cb8-11"><a href="descriptive-statistics-of-networks.html#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="fu">c</span>(<span class="st">&quot;Log-Intensity&quot;</span>), <span class="at">main =</span> <span class="st">&quot;Log-Log Degree Distribution&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="_main_files/figure-html/unnamed-chunk-4-1.png" alt="The degree distribution for protein interactions in Yeast" width="672" />
<p class="caption">
FIGURE 7.2: The degree distribution for protein interactions in Yeast
</p>
</div>
<p>Figure 3: The degree distribution for protein interactions in Yeast</p>
<p>서로 다른 degree 의 vertex 들이 서로 연결되어 있다면 그 기저에 깔린 메커니즘은 무엇인가? 이 또한 흥미로운 부분. 이 문제의 해결에 주효하게 작용하는 개념은 주어진 vertex 의 <strong>average degree of the neighbors</strong>. 높은 degree 의 vertex 는 높은 degree 랑만 붙는 경향이 있는 반면 lower degree 들은 높든 낮든 들러붙는 경향.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="descriptive-statistics-of-networks.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># par(mfrow=c(1,1))</span></span>
<span id="cb9-2"><a href="descriptive-statistics-of-networks.html#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="descriptive-statistics-of-networks.html#cb9-3" aria-hidden="true" tabindex="-1"></a>a.nn.deg.yeast <span class="ot">=</span> <span class="fu">graph.knn</span>(yeast, <span class="fu">V</span>(yeast))<span class="sc">$</span>knn</span>
<span id="cb9-4"><a href="descriptive-statistics-of-networks.html#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d.yeast, a.nn.deg.yeast, <span class="at">log =</span> <span class="st">&quot;xy&quot;</span>, <span class="at">col =</span> <span class="st">&quot;goldenrod&quot;</span>,</span>
<span id="cb9-5"><a href="descriptive-statistics-of-networks.html#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="fu">c</span>(<span class="st">&quot;Log Vertex Degree&quot;</span>), <span class="at">ylab =</span> <span class="fu">c</span>(<span class="st">&quot;Log Average Neighbor Degree&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-5"></span>
<img src="_main_files/figure-html/unnamed-chunk-5-1.png" alt="The degree distribution for protein interactions in Yeast" width="672" />
<p class="caption">
FIGURE 7.3: The degree distribution for protein interactions in Yeast
</p>
</div>
<p><br>
<br>
<br></p>
</div>
<div id="vertex-centrality" class="section level4" number="7.2.1.2">
<h4><span class="header-section-number">7.2.1.2</span> Vertex Centrality</h4>
<p>vertex 에 대해 갖는 많은 의문은 결국 해당 vertex 가 주어진 네트워크에서 얼마나 <strong>중요한가</strong> 를 알기 위한 것.</p>
<p><strong>centrality</strong> 에 대한 많은 측도 (measure) 들은 이러한 중요성을 측정하기 위해 개발되었음. <strong>vertex centrality</strong> 를 확인하기 위해 가장 자주 쓰이는 measure 는 <strong>vertex degree</strong>. 이외에 vertex centrality measure 로서 사용되는 건 <strong>Closeness</strong>, <strong>Betweenness</strong>, and <strong>Eigenvector</strong> 등이 존재. 이 셋이 좀 메이저, 마이저.</p>
<p>vertex centrality 를 나타내는 가장 직관적인 방법은 radial layout 을 쓰는 것. 이는 곧 central vertex 를 중앙에 가깝게 배치하는 것. 물론 네트워크가 너무너무 커버리면 표시불가. 작거나 중간크기 네트워크에만 사용가능.</p>
<ul>
<li><strong>Closeness centrality</strong></li>
</ul>
<p>vertex 가 다른 다수의 vertex 와 가깝다면 이를 central 이라고 판정. 일반적으로 사용되는 기준값은 <span class="math inline">\(C_{CL} =\frac{1}{\sum\limits_{u \in V} dist(u,v)}\)</span>. 이때 denominator <span class="math inline">\(dist(v, u)\)</span> 는 <span class="math inline">\(u, v \ in V\)</span> 인 vertex <span class="math inline">\(u, v\)</span> 사이의 geodesic distance. 각각 다른 그래프에서 산출된 centrality measure 를 비교하기 위해 normalize 하는 상황 있음. 이때는 factor <span class="math inline">\(N_v - 1\)</span> 으로 곱해서 <span class="math inline">\([0,1]\)</span> 로 normalize.</p>
<ul>
<li><strong>Betweenness centrality</strong></li>
</ul>
<p>어떤 vertex 가 다른 vertex 쌍 사이에 위치하고 있는지를 확인. 이건 vertex 가 네트워크 그래프의 path 에 비추어서 어디에 위치하고 있는지가 중요하다는 관점에 기반. 현실세계에 비추어도 이러한 path 가 인간관계라고 생각한다면 path 가 다수 지나가는 vertex, 즉 인싸는 중요한 사람일 것. 일반적으로 사용되는 값은 <span class="math inline">\(C_B (v) = \sum\limits_{s \not = t \not = v \in V} \frac{\sigma(s,t | v)}{\sigma(s, t)}\)</span>. 이때 numerator 는 <span class="math inline">\(v\)</span> 를 통과하면서 <span class="math inline">\(s,t\)</span> 사이가 최단거리인 path 의 총 숫자, denominator 는 이런 조건 없이 <span class="math inline">\(s,t\)</span> 사이가 최단거리인 path 의 총 숫자. 이를 unit interval 로 scale 할 때는 <span class="math inline">\(\frac{(N_v - 1) (N_v - 2)}{2}\)</span> 로 나누면 됨.</p>
<ul>
<li><strong>eigenvector centrality</strong></li>
</ul>
<p>‘status,’ ‘prestige,’ ‘rank’ 등에 기반한 사고방식. vertex 의 이웃이 central 하다면, 본인 vertex 자체도 central 하리라는 관점. 이는 central 의 정의만 생각해보더라도 꽤 합리적인 추론임. 이는 적절하게 정의된 방정식의 linear system 의 ev solution 으로 표현가능함. 이러한 ev centrality 관점에 쓰이는 값은 꽤 많은데 가장 대표적인건 <span class="math inline">\(C_{E_i} (v) = \alpha \sum\limits_{\{u,v\}\in E} C_{E_i}(u)\)</span>. 이때 vector <span class="math inline">\(C_{E_i} = \left ( C_{E_i}(1), \cdots, C_{E_i}(N_v) \right)&#39;\)</span> 는 ev problem <span class="math inline">\(A_{C_{E_i}}\)</span> 의 solution. 이때 <span class="math inline">\(A\)</span> 는 네트워크 그래프 <span class="math inline">\(G\)</span> 의 adjacency 매트릭스.</p>
<p><span class="math inline">\(\alpha^{-1}\)</span> 의 optimal choice 는 <span class="math inline">\(A\)</span> 의 가장 큰 ev. 따라서 <span class="math inline">\(h_{E_i}\)</span> 는 상응하는 evec. <span class="math inline">\(G\)</span> 가 undirected 이며 connected 라면, <span class="math inline">\(A\)</span> 의 largest ev 는 간단하며 이의 evec는 모두 nonzero entry 이며 부호 같음. 관례 (convention) 적으로는 이 entry 들의 abs 를 보고함. 이러면 evec 의 orthonormality 에 의해 얘들은 자동적으로 <span class="math inline">\([0,1]\)</span> 사이로 scaled.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="descriptive-statistics-of-networks.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(network)</span>
<span id="cb10-2"><a href="descriptive-statistics-of-networks.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sna)</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="descriptive-statistics-of-networks.html#cb11-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">get.adjacency</span>(karate, <span class="at">sparse =</span> <span class="cn">FALSE</span>)</span>
<span id="cb11-2"><a href="descriptive-statistics-of-networks.html#cb11-2" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">as.network.matrix</span>(A)</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="descriptive-statistics-of-networks.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb12-2"><a href="descriptive-statistics-of-networks.html#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="descriptive-statistics-of-networks.html#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">degree</span>(g), <span class="at">main =</span> <span class="st">&quot;Degree&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-4"><a href="descriptive-statistics-of-networks.html#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,</span>
<span id="cb12-5"><a href="descriptive-statistics-of-networks.html#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>), <span class="at">edge.col =</span> <span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb12-6"><a href="descriptive-statistics-of-networks.html#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">closeness</span>(g), <span class="at">main =</span> <span class="st">&quot;Closeness&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-7"><a href="descriptive-statistics-of-networks.html#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,</span>
<span id="cb12-8"><a href="descriptive-statistics-of-networks.html#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>), <span class="at">edge.col =</span> <span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb12-9"><a href="descriptive-statistics-of-networks.html#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">betweenness</span>(g), <span class="at">main =</span> <span class="st">&quot;Betweenness&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-10"><a href="descriptive-statistics-of-networks.html#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,</span>
<span id="cb12-11"><a href="descriptive-statistics-of-networks.html#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>), <span class="at">edge.col =</span> <span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb12-12"><a href="descriptive-statistics-of-networks.html#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">evcent</span>(g), <span class="at">main =</span> <span class="st">&quot;Eigenvalue&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-13"><a href="descriptive-statistics-of-networks.html#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,</span>
<span id="cb12-14"><a href="descriptive-statistics-of-networks.html#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>), <span class="at">edge.col =</span> <span class="st">&quot;darkgray&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="_main_files/figure-html/unnamed-chunk-8-1.png" alt="Target plots showing various vertex centralities for the karate club network" width="672" />
<p class="caption">
FIGURE 7.4: Target plots showing various vertex centralities for the karate club network
</p>
</div>
<p>이러한 centrality measure 를 undirected 에만 적용해왔음. directed 에도 적용못할 이유는 없지.</p>
<p>소위 <strong>hub vertex</strong> 의 중요성을 정의해보자. 얼마나 많은 authority vertex 를 그들이 향하는지, 그리고 얼마나 많은 authority vertex 들이 해당 vertex 를 향하는지를 통해 판단. directed graph <span class="math inline">\(A\)</span> 가 주어졌을 때 <strong>hub</strong> 는 <span class="math inline">\(M_{hub} = AA&#39;\)</span> 의 evec centrality 에 의해 결정됨. authority 는 <span class="math inline">\(M_{auth} = A&#39;A\)</span> 에 의해 결정.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="descriptive-statistics-of-networks.html#cb13-1" aria-hidden="true" tabindex="-1"></a>l <span class="ot">=</span> <span class="fu">layout.kamada.kawai</span>(aidsblog)</span>
<span id="cb13-2"><a href="descriptive-statistics-of-networks.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb13-3"><a href="descriptive-statistics-of-networks.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aidsblog, <span class="at">layout =</span> l, <span class="at">main =</span> <span class="st">&quot;Hubs&quot;</span>, <span class="at">vertex.label =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb13-4"><a href="descriptive-statistics-of-networks.html#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">vertex.size =</span> <span class="dv">10</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">hub.score</span>(aidsblog)<span class="sc">$</span>vector))</span>
<span id="cb13-5"><a href="descriptive-statistics-of-networks.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aidsblog, <span class="at">layout =</span> l, <span class="at">main =</span> <span class="st">&quot;Authorities&quot;</span>, <span class="at">vertex.label =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb13-6"><a href="descriptive-statistics-of-networks.html#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">vertex.size =</span> <span class="dv">10</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">authority.score</span>(aidsblog)<span class="sc">$</span>vector))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-9"></span>
<img src="_main_files/figure-html/unnamed-chunk-9-1.png" alt="AIDS blog network with vertex area proportional to hubs and authority centrality measures" width="672" />
<p class="caption">
FIGURE 7.5: AIDS blog network with vertex area proportional to hubs and authority centrality measures
</p>
</div>
<p><br>
<br>
<br></p>
</div>
<div id="characterizing-edges" class="section level4" number="7.2.1.3">
<h4><span class="header-section-number">7.2.1.3</span> Characterizing Edges</h4>
<p>vertex betweenness centrality 에서 <strong>edge betweenness centrality </strong> 는 직관적. 각 edge 에 해당 edge 가 최단거리 path 로 삼아지는 횟수를 고르면 됨.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="descriptive-statistics-of-networks.html#cb14-1" aria-hidden="true" tabindex="-1"></a>eb <span class="ot">=</span> <span class="fu">edge.betweenness</span>(karate)</span>
<span id="cb14-2"><a href="descriptive-statistics-of-networks.html#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">E</span>(karate)[<span class="fu">order</span>(eb, <span class="at">decreasing =</span> T)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]]</span>
<span id="cb14-3"><a href="descriptive-statistics-of-networks.html#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="do">## + 3/78 edges from 4b458a1 (vertex names):</span></span>
<span id="cb14-4"><a href="descriptive-statistics-of-networks.html#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] Actor 20--John A   Mr Hi   --Actor 20 Mr Hi   --Actor 32</span></span></code></pre></div>
<p>하지만 이외의 vertex centrality measures 들은 edge 에 적용하려면 그렇게 쉽진 않음. 해결책 중 하나는 네트워크 그래프 <span class="math inline">\(G\)</span> 의 라인 그래프의 vertex 에 vertex centrality measures 를 적용하는 것. <span class="math inline">\(G\)</span> 의 라인그래프 <span class="math inline">\(G&#39;=(V&#39;, E&#39;)\)</span> 는 <span class="math inline">\(G\)</span> 의 vertex 를 edge 로, edge 를 vertex 로 바꾸는 것으로 획득됨. vertex <span class="math inline">\(v&#39; \in V&#39;\)</span> 는 원본 그래프의 edge <span class="math inline">\(e \in E&#39;\)</span> 를 의미하며, edge <span class="math inline">\(e&#39; \in E&#39;\)</span> 는 <span class="math inline">\(G\)</span> 에서의 대응하는 원본 vertex 1개의 세트를 의미함.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="characterizing-network-cohesion" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Characterizing Network Cohesion</h3>
<p>• 네트워크 그래프 상에서 edge 로서 정의된 관계에 비추었을 때, vertex 들의 어느 subset 이 어느 정도로 응집되는가, 혹은 같이 들러붙는가 하는 문제에 대해 생각해보는 것이 <strong>network cohesion</strong>. SNS 에서 친구의 친구끼리는 친구가 되기 쉬운가? 세포에서 어느 protein 들끼리 협업할 가능성이 높은가? 인터넷 토폴로지에서 어느 부분이 “backbone” 을 구성하는가? 다루는 문제가 무엇이냐에 따라 <strong>network cohesion</strong> 그 자체가 무엇인지 또한 달라짐. local 에서 global (ex. giant component), 어느 정도로 확실하게 정의되는가 (ex. clique) 혹은 두루뭉술한가 (ex. cluster, community) 등 스탯이 다양함.</p>
<p><br>
<br>
<br></p>
<div id="subgraphs-and-censuses" class="section level4" number="7.2.2.1">
<h4><span class="header-section-number">7.2.2.1</span> Subgraphs and Censuses</h4>
<ul>
<li><strong>Cliques</strong></li>
</ul>
<p>complete 서브그래프, 즉 fully cohesive 한 vertex 들의 subset 을 <strong>Cliques</strong> 라고 통칭. 이인즉 소속된 모든 vertex 들이 edge 로 연결되어 있다는 것. 모든 사이즈의 clique 들에 대한 census 는 그래프가 어떻게 structure 되어 있는지에 대한 ‘snapshot’ 을 제공함.</p>
<p>더 큰 사이즈의 clique 는 필연적으로 작은 사이즈의 cluque 들을 포함함. <strong>maximal clique</strong> 는 더 큰 clique 의 subset 이 아닌 clique 를 일컫음. 큰 clique 는 본질적으로 드뭄. 큰 clique 의 존재는 결국 원본 그래프 <span class="math inline">\(G\)</span> 가 일정 이상으로 dense 할 것을 요구하니까. 하지만 현실세계 네트워크는 보통 sparse 하거든.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="descriptive-statistics-of-networks.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(<span class="fu">cliques</span>(karate), length))</span>
<span id="cb15-2"><a href="descriptive-statistics-of-networks.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb15-3"><a href="descriptive-statistics-of-networks.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  1  2  3  4  5 </span></span>
<span id="cb15-4"><a href="descriptive-statistics-of-networks.html#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 34 78 45 11  2</span></span>
<span id="cb15-5"><a href="descriptive-statistics-of-networks.html#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cliques</span>(karate)[<span class="fu">sapply</span>(<span class="fu">cliques</span>(karate), length) <span class="sc">==</span> <span class="dv">5</span>]</span>
<span id="cb15-6"><a href="descriptive-statistics-of-networks.html#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [[1]]</span></span>
<span id="cb15-7"><a href="descriptive-statistics-of-networks.html#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="do">## + 5/34 vertices, named, from 4b458a1:</span></span>
<span id="cb15-8"><a href="descriptive-statistics-of-networks.html#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] Mr Hi    Actor 2  Actor 3  Actor 4  Actor 14</span></span>
<span id="cb15-9"><a href="descriptive-statistics-of-networks.html#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb15-10"><a href="descriptive-statistics-of-networks.html#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [[2]]</span></span>
<span id="cb15-11"><a href="descriptive-statistics-of-networks.html#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="do">## + 5/34 vertices, named, from 4b458a1:</span></span>
<span id="cb15-12"><a href="descriptive-statistics-of-networks.html#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] Mr Hi   Actor 2 Actor 3 Actor 4 Actor 8</span></span>
<span id="cb15-13"><a href="descriptive-statistics-of-networks.html#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(<span class="fu">maximal.cliques</span>(karate), length))</span>
<span id="cb15-14"><a href="descriptive-statistics-of-networks.html#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb15-15"><a href="descriptive-statistics-of-networks.html#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  2  3  4  5 </span></span>
<span id="cb15-16"><a href="descriptive-statistics-of-networks.html#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 11 21  2  2</span></span>
<span id="cb15-17"><a href="descriptive-statistics-of-networks.html#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="fu">clique.number</span>(yeast)</span>
<span id="cb15-18"><a href="descriptive-statistics-of-networks.html#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 23</span></span></code></pre></div>
<ul>
<li><strong><span class="math inline">\(k\)</span>-core</strong></li>
</ul>
<p>clique 를 약화시킨 개념. 그래프 <span class="math inline">\(G\)</span> 의 <span class="math inline">\(k\)</span>-core 는 <span class="math inline">\(G\)</span> 의 서브그래프 중 모든 vertex degree 가 최소한 <span class="math inline">\(k\)</span> 는 되는 것 서브그래프들 중에서도, 다른 서브그래프들이 <span class="math inline">\(k\)</span>-core 와 동일한 condition 을 따르지 않는 것을 <strong><span class="math inline">\(k\)</span>-core</strong> 라고 말함. 즉, 해당 성질을 보유한 서브그래프들 중 maximal 한 놈. core 라는 개념은 특히 visualization 쪽에서 핫함. 네트워크를 ‘layer’ 로 decomposition 할 방법론을 제공하기 때문.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="descriptive-statistics-of-networks.html#cb16-1" aria-hidden="true" tabindex="-1"></a>cores <span class="ot">=</span> <span class="fu">graph.coreness</span>(karate)</span>
<span id="cb16-2"><a href="descriptive-statistics-of-networks.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, cores, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb16-3"><a href="descriptive-statistics-of-networks.html#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col =</span> cores, <span class="at">edge.col =</span> <span class="st">&quot;darkgray&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-12"></span>
<img src="_main_files/figure-html/unnamed-chunk-12-1.png" alt="Visual representation of the k-core decomposition of the karate network" width="672" />
<p class="caption">
FIGURE 7.6: Visual representation of the k-core decomposition of the karate network
</p>
</div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="descriptive-statistics-of-networks.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(<span class="st">&quot;package:sna&quot;</span>)</span>
<span id="cb17-2"><a href="descriptive-statistics-of-networks.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(<span class="st">&quot;package:network&quot;</span>)</span></code></pre></div>
<p>core 에 포함된 vertex 들은 center 에서 크게 떨어지지 않았으며, 각 core 에서 일정한 거리를 유지하고 있음이 시각적으로 확인 가능.</p>
<ul>
<li>Network Cohesion 을 정의함에 있어서 쓰이는 다른 서브그래프들의 class</li>
</ul>
<p>vertex 2개를 뽑아 만든 쌍 (pair) 를 <strong>dyad</strong> 라고 부름. directed 그래프에서 dyad 는 3개의 상태를 가질 수 있다. null (no directed edges), asymmetric (one directed edge), mutual (two directed edges). 대부분의 dyad 는 보통 null 이며, non-null 중에서도 대부분은 aymmetric 이다. 후자의 경우는 블로그에서 서로이웃이 아니라 한쪽만 팔로잉하는 경우겠지.</p>
<p>vertex 3개를 뽑아 만든 모음은 <strong>Triad</strong>. 이는 16개의 상태를 가질 수 있음. null 서브그래프부터, triad 에 속한 모든 vertex 들이 mutual directed edge 를 보유하는 서브그래프 까지.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="descriptive-statistics-of-networks.html#cb18-1" aria-hidden="true" tabindex="-1"></a>aidsblog <span class="ot">=</span> <span class="fu">simplify</span>(aidsblog)</span>
<span id="cb18-2"><a href="descriptive-statistics-of-networks.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dyad.census</span>(aidsblog)</span>
<span id="cb18-3"><a href="descriptive-statistics-of-networks.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="do">## $mut</span></span>
<span id="cb18-4"><a href="descriptive-statistics-of-networks.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3</span></span>
<span id="cb18-5"><a href="descriptive-statistics-of-networks.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-6"><a href="descriptive-statistics-of-networks.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="do">## $asym</span></span>
<span id="cb18-7"><a href="descriptive-statistics-of-networks.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 177</span></span>
<span id="cb18-8"><a href="descriptive-statistics-of-networks.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb18-9"><a href="descriptive-statistics-of-networks.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="do">## $null</span></span>
<span id="cb18-10"><a href="descriptive-statistics-of-networks.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 10405</span></span></code></pre></div>
<p>해당 데이터를 살펴보면 hub 와 authority 에 대한 기존 지식과 궤를 같이함을 확인 가능. <mark>Small connected subgraphs of interest are commonly termed motifs.</mark> <strong>motif</strong> 라는 개념은 생물 네트워크에서 두드러지게 유명한 개념, 생태계 substructure 를 biological function 과 연결지을때 자주 쓰임.</p>
<p><br>
<br>
<br></p>
</div>
<div id="density-and-related-notions-of-relative-frequency" class="section level4" number="7.2.2.2">
<h4><span class="header-section-number">7.2.2.2</span> Density and Related Notions of Relative Frequency</h4>
<ul>
<li><strong>Density</strong></li>
</ul>
<p>그래프의 <strong>Density</strong> 는 potential, 즉 잠재적으로 발생할 edge 대비 실제로 발생한 edge 들의 빈도. 예를 들어 (undirected) 그래프 <span class="math inline">\(G\)</span> 가 self-loop 가 없고 multiple edge 도 없다고 할 때, 서브그래프 <span class="math inline">\(H=(V_H, E_H)\)</span> 의 density 는 <span class="math inline">\(den(H) = \frac{|E_H|}{\frac{|V_H|(|V_H|-1)}{2}}\)</span>. 해당 값은 <span class="math inline">\([0,1]\)</span> 에 존재하며 <span class="math inline">\(H\)</span> 가 clique 가 되기까지의 역치에 얼마나 가까운지에 대한 측도 (measure) 를 제공함. directed 그래프 라면 denominator 는 <span class="math inline">\(|V_H|(|V_H|-1)\)</span> 로 대체.</p>
<p><span class="math inline">\(H=G\)</span> 인 상황이라면 전체 그래프 <span class="math inline">\(G\)</span> 에 대한 density 를 생산. 반대로 vertex <span class="math inline">\(v \in V\)</span> 의 neighbor 의 set <span class="math inline">\(H_v=H\)</span> 가 되게 한다면, 이들 사이의 edge 는 <span class="math inline">\(v\)</span> 의 immediate 이웃의 density 의 측도 (measure) 을 생산함. immediate 이웃의 합집합으로만 생산한 ego-centric 네트워크는 원본의 overall 네트워크보다 명백히 dense 함.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="descriptive-statistics-of-networks.html#cb19-1" aria-hidden="true" tabindex="-1"></a>ego.instr <span class="ot">=</span> <span class="fu">induced.subgraph</span>(karate, <span class="fu">neighborhood</span>(karate, <span class="dv">1</span>,</span>
<span id="cb19-2"><a href="descriptive-statistics-of-networks.html#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>)[[<span class="dv">1</span>]])</span>
<span id="cb19-3"><a href="descriptive-statistics-of-networks.html#cb19-3" aria-hidden="true" tabindex="-1"></a>ego.admin <span class="ot">=</span> <span class="fu">induced.subgraph</span>(karate, <span class="fu">neighborhood</span>(karate, <span class="dv">1</span>,</span>
<span id="cb19-4"><a href="descriptive-statistics-of-networks.html#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">34</span>)[[<span class="dv">1</span>]])</span>
<span id="cb19-5"><a href="descriptive-statistics-of-networks.html#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(karate)</span>
<span id="cb19-6"><a href="descriptive-statistics-of-networks.html#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.1390374</span></span>
<span id="cb19-7"><a href="descriptive-statistics-of-networks.html#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(ego.instr)</span>
<span id="cb19-8"><a href="descriptive-statistics-of-networks.html#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.25</span></span>
<span id="cb19-9"><a href="descriptive-statistics-of-networks.html#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(ego.admin)</span>
<span id="cb19-10"><a href="descriptive-statistics-of-networks.html#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.2091503</span></span></code></pre></div>
<ul>
<li><strong>Clustering Coefficients</strong></li>
</ul>
<p>일반적으로 <span class="math inline">\(cl_T (G) = \frac{3\tau_\Delta (G)}{\tau_3 (G)}\)</span> 를 일컫음. 이때 <span class="math inline">\(\tau_\Delta (G)\)</span> 는 그래프 <span class="math inline">\(G\)</span> 안에 있는 모든 triangle 의 숫자이며, <span class="math inline">\(\tau_3 (G)\)</span> 는 connected triple, 즉 3개의 vertex 에 2개의 edge 가 놓여있는 (i.e., 2-star) vertex 들로 만든 서브그래프의 숫자. 이 <strong>Clustering Coefficients</strong> 인 <span class="math inline">\(cl_T(g)\)</span> 는 그래프의 <strong>transitivity</strong> 라고 불리기도 함. 이는 소셜 네트워크 문헌에서 일반적으로 관심을 갖는 변량 중 하나임. 다른 말로 <strong>fraction of transitive triples</strong> 라고도 불림. <span class="math inline">\(cl_T(g)\)</span> 는 global clsutring 의 measure 이며, connected triple 이 triangle 을 형성하기까지에 얼마나 가까운지에 대한 상대적 빈도를 서술함.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="descriptive-statistics-of-networks.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(karate)</span>
<span id="cb20-2"><a href="descriptive-statistics-of-networks.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.2556818</span></span>
<span id="cb20-3"><a href="descriptive-statistics-of-networks.html#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(karate, <span class="st">&quot;local&quot;</span>, <span class="at">vids =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">34</span>))</span>
<span id="cb20-4"><a href="descriptive-statistics-of-networks.html#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.1500000 0.1102941</span></span></code></pre></div>
<ul>
<li><strong>Reciprocity</strong></li>
</ul>
<p><strong>directed graph 에 한정된 개념</strong>. reciprocated (mutual) 한 edge 의 숫자를 총 edge 의 숫자로 나눈 것. 이는 single, unreciprocated 한 dyad 대비 reciprocated dyad 의 비중을 나타냄.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="descriptive-statistics-of-networks.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reciprocity</span>(aidsblog, <span class="at">mode =</span> <span class="st">&quot;default&quot;</span>)</span>
<span id="cb21-2"><a href="descriptive-statistics-of-networks.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.03278689</span></span>
<span id="cb21-3"><a href="descriptive-statistics-of-networks.html#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">reciprocity</span>(aidsblog, <span class="at">mode =</span> <span class="st">&quot;ratio&quot;</span>)</span>
<span id="cb21-4"><a href="descriptive-statistics-of-networks.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.01666667</span></span></code></pre></div>
<p><br>
<br>
<br></p>
</div>
<div id="connectivity-cuts-and-flows" class="section level4" number="7.2.2.3">
<h4><span class="header-section-number">7.2.2.3</span> Connectivity, Cuts, and Flows</h4>
<p>기본적으로 궁금한 건 주어진 그래프가 서로 다른 서브그래프로 쪼개질 수 있나 하는 것. 불가능하다면 해당 그래프가 이 쪼개질 수 있는 성질의 역치에 얼마나 가까운지를 체크하는 것이 목적이 된다.</p>
<p>만약 모든 vertex가 다른 모든 vertex에서 접근 가능하다면, 즉 adjacency Matrix가 diag 제외하고 모두 1이면, 그래프 <span class="math inline">\(G\)</span>는 <strong>connected</strong>라고 칭해진다. 그리고 그래프의 <strong>connected component</strong>는 maximally connected 서브그래프이다.</p>
<p>그래프 <span class="math inline">\(G\)</span>의 connected component 중 하나가 다른 모두를 위력에서 압도한다면, 이는 곧 해당 connected component가 <span class="math inline">\(G\)</span>의 대부분의 vertex를 포함하고 있다는 이야기. 이러한 component는 <strong>giant component</strong>라고 불리며 이는 random graph theory 출신 용어.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="descriptive-statistics-of-networks.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.connected</span>(yeast)</span>
<span id="cb22-2"><a href="descriptive-statistics-of-networks.html#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] FALSE</span></span>
<span id="cb22-3"><a href="descriptive-statistics-of-networks.html#cb22-3" aria-hidden="true" tabindex="-1"></a>comps <span class="ot">=</span> <span class="fu">decompose.graph</span>(yeast)</span>
<span id="cb22-4"><a href="descriptive-statistics-of-networks.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(comps, vcount))</span>
<span id="cb22-5"><a href="descriptive-statistics-of-networks.html#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb22-6"><a href="descriptive-statistics-of-networks.html#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="do">##    2    3    4    5    6    7 2375 </span></span>
<span id="cb22-7"><a href="descriptive-statistics-of-networks.html#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   63   13    5    6    1    3    1</span></span></code></pre></div>
<p>결과는 false로 나오지만 이에 대해 census 돌리면 giant component의 존재 확인 가능. 아래 예시의 경우 component 1개가 2375/2617로 90퍼 vertex랑 연결중임. 이는 현실 네트워크에서의 <strong>small world property</strong>와 연결. vertex 쌍들 collection에서의 minimum path는 보통 되게 작음. 대비되게 clustring은 상대적으로 높음. (ex) protein?</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="descriptive-statistics-of-networks.html#cb23-1" aria-hidden="true" tabindex="-1"></a>yeast.gc <span class="ot">=</span> <span class="fu">decompose.graph</span>(yeast)[[<span class="dv">1</span>]]</span>
<span id="cb23-2"><a href="descriptive-statistics-of-networks.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">average.path.length</span>(yeast.gc)</span>
<span id="cb23-3"><a href="descriptive-statistics-of-networks.html#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 5.09597</span></span>
<span id="cb23-4"><a href="descriptive-statistics-of-networks.html#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">diameter</span>(yeast.gc)</span>
<span id="cb23-5"><a href="descriptive-statistics-of-networks.html#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 15</span></span>
<span id="cb23-6"><a href="descriptive-statistics-of-networks.html#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(yeast.gc)</span>
<span id="cb23-7"><a href="descriptive-statistics-of-networks.html#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.4686663</span></span></code></pre></div>
<p>해당 네트워크에서의 shortest path는 <span class="math inline">\(N_v\)</span>보다 <span class="math inline">\(\log N_v\)</span>로 표현되는게 정확할 정도로 짧음. scales more like, thus considered small. 동시에 해당 네트워크에서의 clustering은 상대적으로 large, 이는 transitivity로 확인 가능.</p>
<ul>
<li><strong>Connectivity</strong></li>
</ul>
<p>그래프 <span class="math inline">\(G\)</span> 가
1. <strong><span class="math inline">\(k\)</span>-vertex-connected</strong>
- the number of vertices <span class="math inline">\(N_v &gt; k\)</span>
- cardinality <span class="math inline">\(|X|&lt;k\)</span>이며 <span class="math inline">\(X \subseteq V\)</span>인 vertex의 subset <span class="math inline">\(X\)</span>을 지우면 connected subgraph가 아니게 됨.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong><span class="math inline">\(k\)</span>-edge-connected</strong>
<ul>
<li><span class="math inline">\(N_v ≥ 2\)</span></li>
<li>cardinality <span class="math inline">\(|Y|&lt;k\)</span>이며 <span class="math inline">\(Y \subseteq E\)</span>인 edge의 subset <span class="math inline">\(Y\)</span>을 지우면 connected subgraph가 아니게 됨.</li>
</ul></li>
</ol>
<p>즉 <span class="math inline">\(G\)</span>의 vertex (edge) connectivity는 <span class="math inline">\(G\)</span>의 k-vertex(k-edge-) connected가 유지되는 가장 큰 integer. <mark> 이때 vertex connectivity <span class="math inline">\(\le\)</span> edge connectivity <span class="math inline">\(\le\)</span> minimum degree among vertex in <span class="math inline">\(G\)</span> (dmin).</mark> 따라서 이 서브그래프를 추가적인 component로 분해하기 위해서는 단 1개의 엄선된 vertex나 edge를 제거하는 것으로 충분하다.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="descriptive-statistics-of-networks.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vertex.connectivity</span>(yeast.gc)</span>
<span id="cb24-2"><a href="descriptive-statistics-of-networks.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1</span></span>
<span id="cb24-3"><a href="descriptive-statistics-of-networks.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">edge.connectivity</span>(yeast.gc)</span>
<span id="cb24-4"><a href="descriptive-statistics-of-networks.html#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1</span></span></code></pre></div>
<ul>
<li><strong>Cut</strong></li>
</ul>
<p>vertex (edge)의 subset <span class="math inline">\(S\)</span>를 제거하는 것으로 해당 그래프가 서브그래프로 조각난다면, <span class="math inline">\(S\)</span>는 vertex-cut (edge-cut). 여기서 vertex <span class="math inline">\(S\)</span>의 원소가 1개라면, 즉 vertex 1개만을 제거한 것으로 그래프가 조각났다면, 이는 cut vertex, 혹은 <strong>articulation point</strong>. 이러한 vertex의 여부를 식별하는 건 해당 네트워크가 외부 공격에 취약하는지를 파악하는데 도움이 됨. 해당 포인트 끊기면 네트워크 정상작동이 안되니까.</p>
<p>• Identification of such vertices can provide a sense of where a network is vulnerable (e.g., in the sense of an attack, where disconnecting produces undesired consequences, such as a power outage in an energy network).
• In the giant component of the yeast network, almost 15% of the vertices are cut vertices.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="descriptive-statistics-of-networks.html#cb25-1" aria-hidden="true" tabindex="-1"></a>yeast.cut.vertices <span class="ot">=</span> <span class="fu">articulation.points</span>(yeast.gc)</span>
<span id="cb25-2"><a href="descriptive-statistics-of-networks.html#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(yeast.cut.vertices)</span>
<span id="cb25-3"><a href="descriptive-statistics-of-networks.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 350</span></span></code></pre></div>
<p>nontrivial 그래프 <span class="math inline">\(G\)</span>는 k-vertex (k-edge) connected <span class="math inline">\(\iff\)</span> 서로다른 vertex의 쌍 <span class="math inline">\(u, v \in V\)</span>가 k vertex-disjoint (edge-disjoint) paths에 의해 connected 가능.</p>
<p>이 결과는 그래프에서 특정 vertex (edge)가 제거된 상황에서도 그래프 내부에서 만들어지는 서로 다른 path 들이 얼마나 많은지를 통해 평가되는 그래프의 robust함과 연결되어 있다. 낮은 vertex (edge) connectivity 를 가지는 그래프는 따라서 path들을 가질 수 있으며, 이에 의해 그 path들을 통과했던 “information”들은 작은 숫자의 vertex (edge)를 없애는 것만으로 쉽게 방해되고 만다.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="descriptive-statistics-of-networks.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shortest.paths</span>()</span>
<span id="cb26-2"><a href="descriptive-statistics-of-networks.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.maxfow</span>()</span>
<span id="cb26-3"><a href="descriptive-statistics-of-networks.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.mincu</span>()</span></code></pre></div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="graph-partitioning" class="section level3" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Graph Partitioning</h3>
<p><strong>Partitioning</strong>은 elements의 집합을 “발생이 자연스러운” 부분집합으로 분할하는 과정. 더 이론적으로 말하자면, finite set <span class="math inline">\(S\)</span>의 partition <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>는 <span class="math inline">\(S\)</span>를 <span class="math inline">\(K\)</span> 개의 disjoint로 decomposition 한 물건으로, 이인즉 <span class="math inline">\(\forall C_k \not = \emptyset: \cup_{k=1}^K C_k = S\)</span>.</p>
<p>네트워크 그래프 분석에서, partitioning은 겉으로 드러나지 않는 관계성 측면에서 vertex의 묶음이 “cohesiveness”를 가지고 있는지를 확인하기에 유용한 방법이다. vertex의 “cohesive”한 subset은 일반적으로 이하와 같은 걸 일컬음:
1. subset 내부에서, “동시에,” 잘 connected 되어 있어야 한다
2. subset 외부, 즉 남아있는 vertex들과 잘 seperated - 연결성이 없음</p>
<p>Graph partitioning algorithms 은 보통 그래프 <span class="math inline">\(G(V, E)\)</span>의 vertex set <span class="math inline">\(V\)</span> 의 partition <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>를 찾는 것을 그 목표로 함. 이를 위한 방법으로 <span class="math inline">\(C_k\)</span> 안의 vertex에서 <span class="math inline">\(C_k&#39;\)</span>로의 vertex로 잇는 edge의 sets <span class="math inline">\(E(C_k, C_k &#39;)\)</span>는 <span class="math inline">\(C_k\)</span> 내에서 vertex 를 잇는 edge들의 set <span class="math inline">\(E(C_k) = E(C_k , C_k)\)</span>보다 작다는 점을 활용함.</p>
<p>그래프 partitioning의 이 문제는 complex networks 문헌에서의 community detection에서도 동일하게 발생함. 이에 대한 해결책으로 큰 틀에서 2가지 접근법이 존재.</p>
<p><br>
<br>
<br></p>
<div id="hierarchical-clustering-1" class="section level4" number="7.2.3.1">
<h4><span class="header-section-number">7.2.3.1</span> Hierarchical Clustering</h4>
<p>그래프 파티셔닝에 사용되는 대부분의 방법은 본질적으로 Hierarchical Clustering의 변용에 불과함. 여러가지 방법론이 제시되었지만, 그 차이는 결국 이하가 다를 뿐임.</p>
<ol style="list-style-type: decimal">
<li>proposed clusterings의 quality를 어떻게 측정하는가</li>
<li>연구자가 찾고 있는 해당 quality를 어떻게 최적화하는가. 보통 그리디 알고리즘으로 모든 가능한 partition <span class="math inline">\(C\)</span>의 space를 탐색하는 식으로 한다. 이 과정에서 계속해서 후보 partition을 갱신하고.</li>
</ol>
<p>Hierarchical methods 는 다음 둘로 분류됨.
1. agglomerative, 파티션을 합쳐나가는 것을 계속해나가는 것으로 크기를 키워가는 것에 기반 (coarsen)
2. divisive, 파티션을 쪼개나가는 것을 계속해나가는 것으로 연속으로 다듬어나가는 것</p>
<p>각 단계에서 현재의 후보 partition은 지정된 비용 측정값을 최소화한다는 목적으로 계속해서 정제되어 갑니다.
1. agglomerative 방법에서는, 2개의 이전의 partition elements 중 가장 저렴한 merge 방법이 실행된다
2. divisive 방법에서는, 1개의 이전의 partition 중 가장 저렴하게 2개로 split 할 수 있는 방법이 실행된다</p>
<p>비용측정의 기준은 vertex의 “cohesive” subset을 뭘 기준으로 판정할지 하는 연구자의 주관이 개입됨. 메이저한 기준은 <strong>modularity</strong>. <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>를 주어진 후보 partition으로 하고, <mark><span class="math inline">\(f_{ij} = f_{ij}(\mathcal C)\)</span>는 <span class="math inline">\(C_i\)</span>의 vertex를 to be the fraction of edges in the original network that connect vertices in Ci with vertices in Cj.</mark> 이때 <span class="math inline">\(\mathcal C\)</span>의 <strong>modularity</strong>는</p>
<p><span class="math display">\[
\mod(\mathcal C) = \sum_{k=1}^K \left[ f_{kk}(\mathcal C) - f_{kk}^\ast \right]
\]</span></p>
<p><mark>
where <span class="math inline">\(f_{kk}^\ast\)</span>는 random edge assignment의 몇몇 모델을 두고 만들어진 <span class="math inline">\(f_{kk}\)</span>의 기댓값. <span class="math inline">\(f_{kk}^\ast\)</span>는 <span class="math inline">\(f_{k+} \cdot f_{+k}\)</span>이며 각각 <span class="math inline">\(f\)</span>의 k번째 rowsum과 colsum. 즉 <span class="math inline">\(f_{ij}\)</span>를 entry로 하는 <span class="math inline">\(K \times K\)</span> 매트릭스가 만들어짐. This choice corresponds to a model in which a graph is constructed to have the same degree distribution as <span class="math inline">\(G\)</span>, but with edges otherwise placed at random, without respect to the underlying partition elements dictated by <span class="math inline">\(C\)</span>.
</mark></p>
<p>In principle the optimization of the modularity requires a search over all possible partitions C, which is prohibitively expensive in networks of moderate size and larger.
• A fast, greedy approach to optimization has been proposed, in the form of an agglomerative hierarchical clustering algorithm, and implemented in igraph as fastgreedy.community.
• The result of this and related community detection methods in igraph is to produce an object of the class communities, which can then serve as input to various other functions.</p>
<p>Applying this method to the karate network,</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="descriptive-statistics-of-networks.html#cb27-1" aria-hidden="true" tabindex="-1"></a>kc <span class="ot">=</span> <span class="fu">fastgreedy.community</span>(karate)</span>
<span id="cb27-2"><a href="descriptive-statistics-of-networks.html#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(kc)</span>
<span id="cb27-3"><a href="descriptive-statistics-of-networks.html#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3</span></span>
<span id="cb27-4"><a href="descriptive-statistics-of-networks.html#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sizes</span>(kc)</span>
<span id="cb27-5"><a href="descriptive-statistics-of-networks.html#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Community sizes</span></span>
<span id="cb27-6"><a href="descriptive-statistics-of-networks.html#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="do">##  1  2  3 </span></span>
<span id="cb27-7"><a href="descriptive-statistics-of-networks.html#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 18 11  5</span></span>
<span id="cb27-8"><a href="descriptive-statistics-of-networks.html#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">membership</span>(kc))</span>
<span id="cb27-9"><a href="descriptive-statistics-of-networks.html#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   Mr Hi Actor 2 Actor 3 Actor 4 Actor 5 Actor 6 </span></span>
<span id="cb27-10"><a href="descriptive-statistics-of-networks.html#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="do">##       2       2       2       2       3       3</span></span></code></pre></div>
<p>The largest community of 18 members is centered around the administrator (i.e., John A, vertex ID 34).
• The second largest community of 11 members is centered around the head instructor (i.e., Mr Hi, vertex ID 1).</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="descriptive-statistics-of-networks.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(kc, karate)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-24"></span>
<img src="_main_files/figure-html/unnamed-chunk-24-1.png" alt="Partitioning of the Karate network obtained from hierarchical clustering" width="672" />
<p class="caption">
FIGURE 7.7: Partitioning of the Karate network obtained from hierarchical clustering
</p>
</div>
<p>Figure 9: Partitioning of the Karate network obtained from hierarchical clustering</p>
<p>• Whether agglomerative or divisive, when used for network graph partitioning, hierarchical clustering methods actually produce, as the name indicates, an entire hierarchy of nested partitions of the graph, not just a single partition.
• The resulting hierarchy typically is represented in the form of a tree, called a dendrogram.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="descriptive-statistics-of-networks.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ape)</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="descriptive-statistics-of-networks.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dendPlot</span>(kc, <span class="at">mode =</span> <span class="st">&quot;phylo&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-26"></span>
<img src="_main_files/figure-html/unnamed-chunk-26-1.png" alt="The corresponding dendrogram for this partitioning" width="672" />
<p class="caption">
FIGURE 7.8: The corresponding dendrogram for this partitioning
</p>
</div>
<p><br>
<br>
<br></p>
</div>
<div id="spectral-partitioning" class="section level4" number="7.2.3.2">
<h4><span class="header-section-number">7.2.3.2</span> Spectral Partitioning</h4>
<p>spectral graph theory의 연구결과를 응용하여 그래프 <span class="math inline">\(G\)</span>의 connectivity를 특정 매트릭스의 eigen-analysis와 연관짓는 것.</p>
<p>adjacency matrix <span class="math inline">\(A\)</span>에 대한 그래프 <span class="math inline">\(G\)</span>의 그래프 Laplacian 은 <span class="math inline">\(L = D − A\)</span>이며, 이때 <span class="math inline">\(D = diag[(D_{vv} = d_v)]\)</span>, <span class="math inline">\(d_v\)</span>는 <span class="math inline">\(G\)</span>의 entries of the degree sequences.</p>
<p>spectral graph theory의 결과를 통해 우리는 다음을 파악 가능.</p>
<p>그래프 <span class="math inline">\(G\)</span>는 <span class="math inline">\(K\)</span> 개의 connected components로 구성 <span class="math inline">\(\iff\)</span> <span class="math inline">\(\lambda_1 (L) = \cdots = \lambda_K(L) = 0\)</span> 이며 <span class="math inline">\(\lambda_{K+1}(L)&gt;0\)</span>, where <span class="math inline">\(\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_{N_v}\)</span>들은 L의 (not necessarily distinct) ev이며, <mark>ordered from small to large</mark>.</p>
<p>그래프 안의 component의 숫자는 그래프 Laplacian의 non-zero ev의 숫자과 직접적으로 연관되어 있음. <span class="math inline">\(L\)</span>의 최소 ev는 0임을 바로 보일 수 있다. evec <span class="math inline">\(x_1 = (1,\cdots,1)&#39;\)</span>에 대응하므로. 따라서 우리가 그래프 <span class="math inline">\(G\)</span>가 “거의” <span class="math inline">\(K=2\)</span> 개의 component들로 구성되어 있다고 추론한다면, 즉슨 2개로 쪼개기에 적합하다고 생각한다면, 이는 곧 우리는 해당 대상에 대해 <span class="math inline">\(\lambda_2(L)\)</span>가 0에 가까울 것이라고 추론할 것이라는 것과 동치이다. 이러한 추론은 <span class="math inline">\(\lambda_2\)</span>가 그래프 connectivity와 structure의 측정치의 값과 깊은 연관이 있기에 합리적이다. 특히 이러한 관계성은 <span class="math inline">\(\lambda_2\)</span>가 0에 가까울 수록 서브그래프 A과 서브그래프 B 사이를 통과하는 edge가 적을 것이기에 이렇게 둘로 쪼개는 것이 합리적일 것임을 보여준다. <span class="math inline">\(\lambda_2\)</span>를 그래프의 connectivity와 연관지은 제언자는 대응하는 evec <span class="math inline">\(x_2\)</span> 안의 entries들의 부호에 따라 vertex들을 쪼개는 것을 주장했다. 결과는 다음과 같다:</p>
<p><span class="math display">\[
S = \{v \in V: x_2 (v) \ge 0 \}
\\
\bar S = \{v \in V: x_2 (v) &lt; 0 \}
\]</span></p>
<p>즉, 2개의 vertex의 subset이 생산되며 (이를 보통 <strong>cut</strong>이라고 부름), 이 벡터 <span class="math inline">\(x_2\)</span>는 보통 <strong>Fiedler Vector</strong>라고 불리며 이에 대응하는 ev <span class="math inline">\(\lambda_2\)</span>는 <strong>Fiedler Value</strong>라고 부른다.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="descriptive-statistics-of-networks.html#cb31-1" aria-hidden="true" tabindex="-1"></a>k.lap <span class="ot">=</span> <span class="fu">graph.laplacian</span>(karate)</span>
<span id="cb31-2"><a href="descriptive-statistics-of-networks.html#cb31-2" aria-hidden="true" tabindex="-1"></a>eig.anal <span class="ot">=</span> <span class="fu">eigen</span>(k.lap)</span>
<span id="cb31-3"><a href="descriptive-statistics-of-networks.html#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eig.anal<span class="sc">$</span>values, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Eigenvalues of Graph Laplacian&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-27"></span>
<img src="_main_files/figure-html/unnamed-chunk-27-1.png" alt="Eigenvalues of Graph Laplacian" width="672" />
<p class="caption">
FIGURE 7.9: Eigenvalues of Graph Laplacian
</p>
</div>
<p>We plot the eigenvalues of the graph Laplacian.</p>
<ol style="list-style-type: decimal">
<li>0인 ev는 딱 하나. (해당 네트워크는 connected이므로 예상한 결과)</li>
<li>2번째로 작은 ev인 <span class="math inline">\(\lambda_2\)</span>는 0에 매우 가까움.</li>
</ol>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="descriptive-statistics-of-networks.html#cb32-1" aria-hidden="true" tabindex="-1"></a>f.vec <span class="ot">=</span> eig.anal<span class="sc">$</span>vectors[, <span class="dv">33</span>]  <span class="co">#Extracting the Fiedler vector</span></span>
<span id="cb32-2"><a href="descriptive-statistics-of-networks.html#cb32-2" aria-hidden="true" tabindex="-1"></a>faction <span class="ot">=</span> <span class="fu">get.vertex.attribute</span>(karate, <span class="st">&quot;Faction&quot;</span>)</span>
<span id="cb32-3"><a href="descriptive-statistics-of-networks.html#cb32-3" aria-hidden="true" tabindex="-1"></a>f.colors <span class="ot">=</span> <span class="fu">as.character</span>(<span class="fu">length</span>(faction))</span>
<span id="cb32-4"><a href="descriptive-statistics-of-networks.html#cb32-4" aria-hidden="true" tabindex="-1"></a>f.colors[faction <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">=</span> <span class="st">&quot;red&quot;</span></span>
<span id="cb32-5"><a href="descriptive-statistics-of-networks.html#cb32-5" aria-hidden="true" tabindex="-1"></a>f.colors[faction <span class="sc">==</span> <span class="dv">2</span>] <span class="ot">=</span> <span class="st">&quot;cyan&quot;</span></span>
<span id="cb32-6"><a href="descriptive-statistics-of-networks.html#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(f.vec, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">xlab =</span> <span class="st">&quot;Actor Number&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Fiedler Vector Entry&quot;</span>,</span>
<span id="cb32-7"><a href="descriptive-statistics-of-networks.html#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> f.colors)</span>
<span id="cb32-8"><a href="descriptive-statistics-of-networks.html#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;lightgray&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-28"></span>
<img src="_main_files/figure-html/unnamed-chunk-28-1.png" alt="Fiedler vector and its corresponding partition" width="672" />
<p class="caption">
FIGURE 7.10: Fiedler vector and its corresponding partition
</p>
</div>
<p>Fiedler vector를 생산하고 해당 vector의 요소들을 실제 actor number에 따라 배정한 그래프를 보면 이 spectral 방법이 faction label에 의해 네트워크 partitioning 을 획득할 수 있다는 것을 확인된다.</p>
<p>보통 우리는 네트워크가 서브그래프 2개보다는 더 잘게 쪼개질 수 있으리라고 예상 가능. spectral 방법을 iterative하게 적용하는 것으로 2개 이상으로 쪼갤 수 있음. 하지만 이러한 반복이 특정 목적 함수를 최적화할 수 있도록 목표하는 것이 바람직함. Newman은 spectral bisection method와 논리적 흐름이 유사하나 Laplacian <span class="math inline">\(L\)</span>이 아니라 이를 대체해서 modularity와 연관된 매트릭스를 사용하는 방법을 제안했다.(leading.eigenvector.community)</p>
<p><br>
<br>
<br></p>
</div>
<div id="validation-of-graph-partitioning" class="section level4" number="7.2.3.3">
<h4><span class="header-section-number">7.2.3.3</span> Validation of Graph Partitioning</h4>
<p>validation 문제는 그래프 partitioning에 항상 중요하지만, 대부분의 경우 nontrivial 문제이다. 네트워크 그래프에 vertex의 cohesive subset 이 존재한다면, 이러한 subset의 기저에는 vertex에게 있어 vertex 간에 특정한 연관적인 특성 (또는 속성)에 일부 공통성이 있을 것으로 일반적으로 예상한다. 그래프 partitioning은 이러한 성질에 대한 지식이 없을때 그러한 subset을 발견하기 위한 도구로 인식될 수도 있다. 우리가 그래프 외부에서 정의된 클래스 멤버쉽에 대한 subset 정의를 알고 있다면, 그래프 내부에서의 partitioning으로 얻은 분절들과 비교하는 것도 흥미로움.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="descriptive-statistics-of-networks.html#cb33-1" aria-hidden="true" tabindex="-1"></a>func.class <span class="ot">=</span> <span class="fu">get.vertex.attribute</span>(yeast.gc, <span class="st">&quot;Class&quot;</span>)</span>
<span id="cb33-2"><a href="descriptive-statistics-of-networks.html#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(func.class)</span>
<span id="cb33-3"><a href="descriptive-statistics-of-networks.html#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="do">## func.class</span></span>
<span id="cb33-4"><a href="descriptive-statistics-of-networks.html#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="do">##   A   B   C   D   E   F   G   M   O   P   R   T   U </span></span>
<span id="cb33-5"><a href="descriptive-statistics-of-networks.html#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="do">##  51  98 122 238  95 171  96 278 171 248  45 240 483</span></span></code></pre></div>
<p>해당 예시는 cell 구축에 있어 protein이 역할하는 바로 분절했음. 단백질들이 서로 다른 단백질들과 얼마나 유사한지는 특정 세포 역할에 해당 단백질이 무슨 일을 하는지와 연관되어 있다고 알려져 있음. 그래프 외부에서 이러한 단백질들을 분류하려는 시도는 분류된 결과가 그래프 내부에서 합리적은 partitioning 과정을 걸쳐 나온 결과물과 어느정도는 연관이 있는게 맞다. 아니면 partitioning이 잘못됐던가 그래프 외부 분절이 잘못됐던가.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="descriptive-statistics-of-networks.html#cb34-1" aria-hidden="true" tabindex="-1"></a>yc <span class="ot">=</span> <span class="fu">fastgreedy.community</span>(yeast.gc)</span>
<span id="cb34-2"><a href="descriptive-statistics-of-networks.html#cb34-2" aria-hidden="true" tabindex="-1"></a>c.m <span class="ot">=</span> <span class="fu">membership</span>(yc)</span>
<span id="cb34-3"><a href="descriptive-statistics-of-networks.html#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">table</span>(c.m, func.class, <span class="at">useNA =</span> <span class="fu">c</span>(<span class="st">&quot;no&quot;</span>)))</span>
<span id="cb34-4"><a href="descriptive-statistics-of-networks.html#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="do">##    func.class</span></span>
<span id="cb34-5"><a href="descriptive-statistics-of-networks.html#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="do">## c.m   A   B   C   D   E   F   G   M   O   P   R   T   U</span></span>
<span id="cb34-6"><a href="descriptive-statistics-of-networks.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="do">##   1   0   0   0   1   3   7   0   6   3 110   2  35  14</span></span>
<span id="cb34-7"><a href="descriptive-statistics-of-networks.html#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   2   0   2   2   7   1   1   1   4  39   5   0   4  27</span></span>
<span id="cb34-8"><a href="descriptive-statistics-of-networks.html#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   3   1   9   7  18   4   8   4  20  10  23   8  74  64</span></span>
<span id="cb34-9"><a href="descriptive-statistics-of-networks.html#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   4  25  11  10  22  72  84  81 168  14  75  16  27 121</span></span>
<span id="cb34-10"><a href="descriptive-statistics-of-networks.html#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   5   1   7   5  14   0   4   0   2   3   6   1  34  68</span></span>
<span id="cb34-11"><a href="descriptive-statistics-of-networks.html#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="do">##   6   1  24   1   4   1   4   0   7   0   1   0  19  16</span></span></code></pre></div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="assortativity-and-mixing" class="section level3" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> Assortativity and Mixing</h3>
<ul>
<li><strong>Assortative mixing</strong></li>
</ul>
<p>특정 성질에 따라서 vertex 중에 선별적으로 연결.</p>
<ul>
<li>Assortativity coefficients</li>
</ul>
<p>assortative mixing의 정도를 량화하는 측도. 이는 correlation coefficients의 변용. vertex 특성은 categorical, ordinal, or continuous 다 가능. categorical 케이스를 가정하고, 그래프 <span class="math inline">\(G\)</span>의 각 vertex가 <span class="math inline">\(M\)</span>개의 카테고리 중에 label 될 수 있다고 생각하자. 이 세팅에서의 Assortativity coefficients <span class="math inline">\(r_a\)</span>는 아래와 같다.</p>
<p><span class="math display">\[
r_a = \frac{\sum_{i}f_{ii} - \sum_i f_{x+}f_{+y}}{1 - \sum_if_{x+}f_{+y}}
\]</span></p>
<p><mark>where fij is the fraction of edges in G that join a vertex in the i-th category with a vertex in the jth category, and fi+ and f+i denote the ith marginal row and column sums, respectively, of the resulting matrix f.</mark></p>
<p>이때 <span class="math inline">\(-1 \le r_a \le 1\)</span></p>
<p>– It is equal to zero when the mixing in the graph is no different from that obtained through a random assignment of edges that preserves the marginal degree distribution.
– It is equal to one when there is perfect assortative mixing (i.e., when edges only connect vertices of the same category).
– However, in the event that the mixing is perfectly disassortative, in the sense that every edge in the graph connects vertices of two different categories, the coefficient need not take the value −1.
• The fact that physical binding of proteins is known to be directly relevant to functional classes suggests that there will frequently be strong assortative mixing in protein-protein interaction networks with respective to these classes as attributes.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="descriptive-statistics-of-networks.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">assortativity.nominal</span>(yeast, (<span class="fu">replace</span>(<span class="fu">V</span>(yeast)<span class="sc">$</span>Class, <span class="fu">is.na</span>(<span class="fu">V</span>(yeast)<span class="sc">$</span>Class),</span>
<span id="cb35-2"><a href="descriptive-statistics-of-networks.html#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>) <span class="sc">==</span> <span class="st">&quot;P&quot;</span>) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">directed =</span> <span class="cn">FALSE</span>)</span>
<span id="cb35-3"><a href="descriptive-statistics-of-networks.html#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.5232879</span></span>
<span id="cb35-4"><a href="descriptive-statistics-of-networks.html#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">assortativity.degree</span>(yeast)</span>
<span id="cb35-5"><a href="descriptive-statistics-of-networks.html#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.4610798</span></span></code></pre></div>
<p>• When the vertex characteristic of interest is continuous, rather than discrete, denote by (xe, ye) the
values of that characteristic for the vertices joined by an edge e ∈ E.
• A natural candidate for quantifying the assortativity in this characteristic is just th e Pearson correlation coefficient of the pairs (xe, ye),</p>
<p><span class="math display">\[
r = \frac{\sum_{x,y}xy(f_{xy} - f_{x+}f_{+y})}{\sigma_x \sigma_y}
\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-collection-and-sampling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/212102_DescriptiveStats.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
