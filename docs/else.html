<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.10 Else | Self-Study</title>
  <meta name="description" content="4.10 Else | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.10 Else | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.10 Else | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="review.html"/>
<link rel="next" href="mva.html"/>
<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li><a href="index.html#intro" id="toc-intro">Intro<span></span></a></li>
<li><a href="#part-20-02" id="toc-part-20-02">(PART) 20-02<span></span></a></li>
<li><a href="categorical.html#categorical" id="toc-categorical"><span class="toc-section-number">1</span> Categorical<span></span></a>
<ul>
<li><a href="overview.html#overview" id="toc-overview"><span class="toc-section-number">1.1</span> Overview<span></span></a>
<ul>
<li><a href="overview.html#data-type-and-statistical-analysis" id="toc-data-type-and-statistical-analysis"><span class="toc-section-number">1.1.1</span> Data Type and Statistical Analysis<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="bayesian.html#bayesian" id="toc-bayesian"><span class="toc-section-number">2</span> Bayesian<span></span></a>
<ul>
<li><a href="abstract.html#abstract" id="toc-abstract"><span class="toc-section-number">2.1</span> Abstract<span></span></a>
<ul>
<li><a href="abstract.html#변수의-독립성" id="toc-변수의-독립성"><span class="toc-section-number">2.1.1</span> 변수의 독립성<span></span></a></li>
<li><a href="abstract.html#교환가능성" id="toc-교환가능성"><span class="toc-section-number">2.1.2</span> 교환가능성<span></span></a></li>
</ul></li>
<li><a href="continual-aeassessment-method.html#continual-aeassessment-method" id="toc-continual-aeassessment-method"><span class="toc-section-number">2.2</span> Continual Aeassessment Method<span></span></a></li>
<li><a href="horseshoe-prior.html#horseshoe-prior" id="toc-horseshoe-prior"><span class="toc-section-number">2.3</span> Horseshoe Prior<span></span></a></li>
</ul></li>
<li><a href="#part-21-01" id="toc-part-21-01">(PART) 21-01<span></span></a></li>
<li><a href="mathematical-stats.html#mathematical-stats" id="toc-mathematical-stats"><span class="toc-section-number">3</span> Mathematical Stats<span></span></a>
<ul>
<li><a href="inference.html#inference" id="toc-inference"><span class="toc-section-number">3.1</span> Inference<span></span></a>
<ul>
<li><a href="inference.html#rao-blackwell-thm." id="toc-rao-blackwell-thm."><span class="toc-section-number">3.1.1</span> Rao-Blackwell thm.<span></span></a></li>
<li><a href="inference.html#completeness" id="toc-completeness"><span class="toc-section-number">3.1.2</span> Completeness<span></span></a></li>
<li><a href="inference.html#레만-쉐페-thm." id="toc-레만-쉐페-thm."><span class="toc-section-number">3.1.3</span> 레만-쉐페 thm.<span></span></a></li>
<li><a href="inference.html#raoblack" id="toc-raoblack"><span class="toc-section-number">3.1.4</span> Rao-Blackwell thm.<span></span></a></li>
</ul></li>
<li><a href="hypothesis-test.html#hypothesis-test" id="toc-hypothesis-test"><span class="toc-section-number">3.2</span> Hypothesis Test<span></span></a></li>
<li><a href="power-fucntion.html#power-fucntion" id="toc-power-fucntion"><span class="toc-section-number">3.3</span> Power Fucntion<span></span></a>
<ul>
<li><a href="power-fucntion.html#significance-probability-p-value" id="toc-significance-probability-p-value"><span class="toc-section-number">3.3.1</span> Significance Probability (p-value)<span></span></a></li>
</ul></li>
<li><a href="optimal-testing-method.html#optimal-testing-method" id="toc-optimal-testing-method"><span class="toc-section-number">3.4</span> Optimal Testing Method<span></span></a></li>
<li><a href="data-reduction.html#data-reduction" id="toc-data-reduction"><span class="toc-section-number">3.5</span> Data Reduction<span></span></a>
<ul>
<li><a href="data-reduction.html#sufficiency-principle" id="toc-sufficiency-principle"><span class="toc-section-number">3.5.1</span> Sufficiency Principle<span></span></a></li>
</ul></li>
<li><a href="borel-paradox.html#borel-paradox" id="toc-borel-paradox"><span class="toc-section-number">3.6</span> Borel Paradox<span></span></a></li>
<li><a href="neymanpearson-lemma.html#neymanpearson-lemma" id="toc-neymanpearson-lemma"><span class="toc-section-number">3.7</span> Neyman–Pearson lemma<span></span></a>
<ul>
<li><a href="neymanpearson-lemma.html#overview-1" id="toc-overview-1"><span class="toc-section-number">3.7.1</span> Overview<span></span></a></li>
<li><a href="neymanpearson-lemma.html#generalized-lrt" id="toc-generalized-lrt"><span class="toc-section-number">3.7.2</span> Generalized LRT<span></span></a></li>
</ul></li>
<li><a href="개념.html#개념" id="toc-개념"><span class="toc-section-number">3.8</span> 개념<span></span></a></li>
</ul></li>
<li><a href="mcmc.html#mcmc" id="toc-mcmc"><span class="toc-section-number">4</span> MCMC<span></span></a>
<ul>
<li><a href="importance-sampling.html#importance-sampling" id="toc-importance-sampling"><span class="toc-section-number">4.1</span> Importance Sampling<span></span></a>
<ul>
<li><a href="importance-sampling.html#independent-monte-carlo" id="toc-independent-monte-carlo"><span class="toc-section-number">4.1.1</span> Independent Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo"><span class="toc-section-number">4.2</span> Markov Chain Monte Carlo<span></span></a>
<ul>
<li><a href="markov-chain-monte-carlo.html#mh-algorithm" id="toc-mh-algorithm"><span class="toc-section-number">4.2.1</span> MH Algorithm<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used" id="toc-random-walk-chains-most-widely-used"><span class="toc-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler" id="toc-basic-gibbs-sampler"><span class="toc-section-number">4.2.3</span> Basic Gibbs Sampler<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#implementation" id="toc-implementation"><span class="toc-section-number">4.2.4</span> Implementation<span></span></a></li>
</ul></li>
<li><a href="advanced-mcmc-wk08.html#advanced-mcmc-wk08" id="toc-advanced-mcmc-wk08"><span class="toc-section-number">4.3</span> Advanced MCMC (wk08)<span></span></a>
<ul>
<li><a href="advanced-mcmc-wk08.html#data-augmentation" id="toc-data-augmentation"><span class="toc-section-number">4.3.1</span> Data Augmentation<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm" id="toc-hit-and-run-algorithm"><span class="toc-section-number">4.3.2</span> Hit-and-Run Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm" id="toc-metropolis-adjusted-langevin-algorithm"><span class="toc-section-number">4.3.3</span> Metropolis-Adjusted Langevin Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm" id="toc-multiple-try-metropolis-algorithm"><span class="toc-section-number">4.3.4</span> Multiple-Try Metropolis Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm" id="toc-reversible-jump-mcmc-algorithm"><span class="toc-section-number">4.3.5</span> Reversible Jump MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc" id="toc-auxiliary-variable-mcmc"><span class="toc-section-number">4.4</span> Auxiliary Variable MCMC<span></span></a>
<ul>
<li><a href="auxiliary-variable-mcmc.html#introduction" id="toc-introduction"><span class="toc-section-number">4.4.1</span> Introduction<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution" id="toc-multimodal-target-distribution"><span class="toc-section-number">4.4.2</span> Multimodal Target Distribution<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants" id="toc-doubly-intractable-normalizing-constants"><span class="toc-section-number">4.4.3</span> Doubly-intractable Normalizing Constants<span></span></a></li>
</ul></li>
<li><a href="approximate-bayesian-computation.html#approximate-bayesian-computation" id="toc-approximate-bayesian-computation"><span class="toc-section-number">4.5</span> Approximate Bayesian Computation<span></span></a>
<ul>
<li><a href="approximate-bayesian-computation.html#simulator-based-models" id="toc-simulator-based-models"><span class="toc-section-number">4.5.1</span> Simulator-Based Models<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods" id="toc-abcifying-monte-carlo-methods"><span class="toc-section-number">4.5.2</span> ABCifying Monte Carlo Methods<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm" id="toc-abc-mcmc-algorithm"><span class="toc-section-number">4.5.3</span> ABC-MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="hamiltonian-monte-carlo.html#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo"><span class="toc-section-number">4.6</span> Hamiltonian Monte Carlo<span></span></a>
<ul>
<li><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo" id="toc-introduction-to-hamiltonian-monte-carlo"><span class="toc-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="population-monte-carlo.html#population-monte-carlo" id="toc-population-monte-carlo"><span class="toc-section-number">4.7</span> Population Monte Carlo<span></span></a>
<ul>
<li><a href="population-monte-carlo.html#adaptive-direction-sampling" id="toc-adaptive-direction-sampling"><span class="toc-section-number">4.7.1</span> Adaptive Direction Sampling<span></span></a></li>
<li><a href="population-monte-carlo.html#conjugate-gradient-mc" id="toc-conjugate-gradient-mc"><span class="toc-section-number">4.7.2</span> Conjugate Gradient MC<span></span></a></li>
<li><a href="population-monte-carlo.html#parallel-tempering" id="toc-parallel-tempering"><span class="toc-section-number">4.7.3</span> Parallel Tempering<span></span></a></li>
<li><a href="population-monte-carlo.html#evolutionary-mc" id="toc-evolutionary-mc"><span class="toc-section-number">4.7.4</span> Evolutionary MC<span></span></a></li>
<li><a href="population-monte-carlo.html#sequential-parallel-tempering" id="toc-sequential-parallel-tempering"><span class="toc-section-number">4.7.5</span> Sequential Parallel Tempering<span></span></a></li>
</ul></li>
<li><a href="stochastic-approximation-monte-carlo.html#stochastic-approximation-monte-carlo" id="toc-stochastic-approximation-monte-carlo"><span class="toc-section-number">4.8</span> Stochastic Approximation Monte Carlo<span></span></a></li>
<li><a href="review.html#review" id="toc-review"><span class="toc-section-number">4.9</span> Review<span></span></a>
<ul>
<li><a href="review.html#wk01" id="toc-wk01"><span class="toc-section-number">4.9.1</span> Wk01<span></span></a></li>
<li><a href="review.html#wk03" id="toc-wk03"><span class="toc-section-number">4.9.2</span> wk03<span></span></a></li>
<li><a href="review.html#wk04-05" id="toc-wk04-05"><span class="toc-section-number">4.9.3</span> wk04, 05<span></span></a></li>
</ul></li>
<li><a href="else.html#else" id="toc-else"><span class="toc-section-number">4.10</span> Else<span></span></a>
<ul>
<li><a href="else.html#hw4.-rasch-model" id="toc-hw4.-rasch-model"><span class="toc-section-number">4.10.1</span> Hw4. Rasch Model<span></span></a></li>
<li><a href="else.html#da-example-mvn" id="toc-da-example-mvn"><span class="toc-section-number">4.10.2</span> DA) Example: MVN<span></span></a></li>
<li><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes" id="toc-bayesian-adaptive-clinical-trial-with-delayed-outcomes"><span class="toc-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes<span></span></a></li>
<li><a href="else.html#nmar의-종류" id="toc-nmar의-종류"><span class="toc-section-number">4.10.4</span> NMAR의 종류<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-selection" id="toc-wk10-bayesian-model-selection"><span class="toc-section-number">4.10.5</span> wk10) Bayesian Model Selection<span></span></a></li>
<li><a href="else.html#autologistic-model" id="toc-autologistic-model"><span class="toc-section-number">4.10.6</span> Autologistic model<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-averaging" id="toc-wk10-bayesian-model-averaging"><span class="toc-section-number">4.10.7</span> wk10) Bayesian Model Averaging<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="mva.html#mva" id="toc-mva"><span class="toc-section-number">5</span> MVA<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#overview-of-mva-not-ended" id="toc-overview-of-mva-not-ended"><span class="toc-section-number">5.1</span> Overview of mva (not ended)<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#notation" id="toc-notation"><span class="toc-section-number">5.1.1</span> Notation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">5.1.2</span> Summary Statistics<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation" id="toc-statistical-inference-on-correlation"><span class="toc-section-number">5.1.3</span> Statistical Inference on Correlation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#standardization" id="toc-standardization"><span class="toc-section-number">5.1.4</span> Standardization<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#missing-value-treatment" id="toc-missing-value-treatment"><span class="toc-section-number">5.1.5</span> Missing Value Treatment<span></span></a></li>
</ul></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-nomral-wk2" id="toc-multivariate-nomral-wk2"><span class="toc-section-number">5.2</span> Multivariate Nomral (wk2)<span></span></a>
<ul>
<li><a href="multivariate-nomral-wk2.html#overview-2" id="toc-overview-2"><span class="toc-section-number">5.2.1</span> Overview<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#spectral-decomposition" id="toc-spectral-decomposition"><span class="toc-section-number">5.2.2</span> Spectral Decomposition<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">5.2.3</span> Properties of MVN<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#chi2-distribution" id="toc-chi2-distribution"><span class="toc-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors" id="toc-linear-combination-of-random-vectors"><span class="toc-section-number">5.2.5</span> Linear Combination of Random Vectors<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood" id="toc-multivariate-normal-likelihood"><span class="toc-section-number">5.2.6</span> Multivariate Normal Likelihood<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s" id="toc-sampling-distribtion-of-bar-pmb-y-s"><span class="toc-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span><span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#assessing-normality" id="toc-assessing-normality"><span class="toc-section-number">5.2.8</span> Assessing Normality<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#power-transformation" id="toc-power-transformation"><span class="toc-section-number">5.2.9</span> Power Transformation<span></span></a></li>
</ul></li>
<li><a href="inference-about-mean-vector-wk3.html#inference-about-mean-vector-wk3" id="toc-inference-about-mean-vector-wk3"><span class="toc-section-number">5.3</span> Inference about Mean Vector (wk3)<span></span></a>
<ul>
<li><a href="inference-about-mean-vector-wk3.html#overview-3" id="toc-overview-3"><span class="toc-section-number">5.3.1</span> Overview<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#confidence-region" id="toc-confidence-region"><span class="toc-section-number">5.3.2</span> 1. Confidence Region<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#simultaneous-ci" id="toc-simultaneous-ci"><span class="toc-section-number">5.3.3</span> 2. Simultaneous CI<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison" id="toc-note-bonferroni-multiple-comparison"><span class="toc-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector" id="toc-large-sample-inferences-about-a-mean-vector"><span class="toc-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5" id="toc-profile-analysis-wk4-5"><span class="toc-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend" id="toc-test-for-linear-trend"><span class="toc-section-number">5.3.7</span> 2. Test for Linear Trend<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix" id="toc-inferences-about-a-covariance-matrix"><span class="toc-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix<span></span></a></li>
</ul></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparison-of-several-mv-means-wk5" id="toc-comparison-of-several-mv-means-wk5"><span class="toc-section-number">5.4</span> Comparison of Several MV Means (wk5)<span></span></a>
<ul>
<li><a href="comparison-of-several-mv-means-wk5.html#paired-comparison" id="toc-paired-comparison"><span class="toc-section-number">5.4.1</span> Paired Comparison<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations" id="toc-comparing-mean-vectors-from-two-populations"><span class="toc-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2" id="toc-profile-analysis-for-g2"><span class="toc-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means" id="toc-comparing-several-multivariate-population-means"><span class="toc-section-number">5.4.4</span> Comparing Several Multivariate Population Means<span></span></a></li>
</ul></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression-wk6" id="toc-multivariate-multiple-regression-wk6"><span class="toc-section-number">5.5</span> Multivariate Multiple Regression (wk6)<span></span></a>
<ul>
<li><a href="multivariate-multiple-regression-wk6.html#overview-4" id="toc-overview-4"><span class="toc-section-number">5.5.1</span> Overview<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression" id="toc-multivariate-multiple-regression"><span class="toc-section-number">5.5.2</span> Multivariate Multiple Regression<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#example" id="toc-example"><span class="toc-section-number">5.5.3</span> Example)<span></span></a></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">5.6</span> PCA<span></span></a></li>
<li><a href="factor.html#factor" id="toc-factor"><span class="toc-section-number">5.7</span> Factor<span></span></a>
<ul>
<li><a href="factor.html#method-of-estimation" id="toc-method-of-estimation"><span class="toc-section-number">5.7.1</span> Method of Estimation<span></span></a></li>
<li><a href="factor.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">5.7.2</span> Factor Rotation<span></span></a></li>
<li><a href="factor.html#varimax-criterion" id="toc-varimax-criterion"><span class="toc-section-number">5.7.3</span> Varimax Criterion<span></span></a></li>
<li><a href="factor.html#factor-scores" id="toc-factor-scores"><span class="toc-section-number">5.7.4</span> Factor Scores<span></span></a></li>
</ul></li>
<li><a href="discrimination-and-classification.html#discrimination-and-classification" id="toc-discrimination-and-classification"><span class="toc-section-number">5.8</span> Discrimination and Classification<span></span></a>
<ul>
<li><a href="discrimination-and-classification.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">5.8.1</span> Bayes Rule<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations" id="toc-classification-with-two-mv-n-populations"><span class="toc-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations<span></span></a></li>
<li><a href="discrimination-and-classification.html#evaluating-classification-functions" id="toc-evaluating-classification-functions"><span class="toc-section-number">5.8.3</span> Evaluating Classification Functions<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-several-populations-wk13" id="toc-classification-with-several-populations-wk13"><span class="toc-section-number">5.8.4</span> Classification with several Populations (wk13)<span></span></a></li>
<li><a href="discrimination-and-classification.html#other-discriminant-analysis-methods" id="toc-other-discriminant-analysis-methods"><span class="toc-section-number">5.8.5</span> Other Discriminant Analysis Methods<span></span></a></li>
</ul></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-distance-methods-and-ordination" id="toc-clustering-distance-methods-and-ordination"><span class="toc-section-number">5.9</span> Clustering, Distance Methods, and Ordination<span></span></a>
<ul>
<li><a href="clustering-distance-methods-and-ordination.html#overview-5" id="toc-overview-5"><span class="toc-section-number">5.9.1</span> Overview<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">5.9.2</span> Hierarchical Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">5.9.3</span> K-means Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법" id="toc-군집의-평가방법"><span class="toc-section-number">5.9.4</span> 군집의 평가방법<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14" id="toc-clustering-using-density-estimation-wk14"><span class="toc-section-number">5.9.5</span> Clustering using Density Estimation (wk14)<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds" id="toc-multidimensional-scaling-mds"><span class="toc-section-number">5.9.6</span> Multidimensional Scaling (MDS)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="linear.html#linear" id="toc-linear"><span class="toc-section-number">6</span> Linear<span></span></a>
<ul>
<li><a href="overview-svd.html#overview-svd" id="toc-overview-svd"><span class="toc-section-number">6.1</span> Overview &amp; SVD<span></span></a>
<ul>
<li><a href="overview-svd.html#spectral-decomposition-1" id="toc-spectral-decomposition-1"><span class="toc-section-number">6.1.1</span> Spectral Decomposition<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-general-version" id="toc-singular-value-decomposition-general-version"><span class="toc-section-number">6.1.2</span> Singular value Decomposition: General-version<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-another-version" id="toc-singular-value-decomposition-another-version"><span class="toc-section-number">6.1.3</span> Singular value Decomposition: Another-version<span></span></a></li>
<li><a href="overview-svd.html#quadratic-forms" id="toc-quadratic-forms"><span class="toc-section-number">6.1.4</span> Quadratic Forms<span></span></a></li>
<li><a href="overview-svd.html#partitioned-matrices" id="toc-partitioned-matrices"><span class="toc-section-number">6.1.5</span> Partitioned Matrices<span></span></a></li>
<li><a href="overview-svd.html#geometrical-aspects" id="toc-geometrical-aspects"><span class="toc-section-number">6.1.6</span> Geometrical Aspects<span></span></a></li>
<li><a href="overview-svd.html#column-row-and-null-space" id="toc-column-row-and-null-space"><span class="toc-section-number">6.1.7</span> Column, Row and Null Space<span></span></a></li>
</ul></li>
<li><a href="introduction-1.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.2</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-1.html#what" id="toc-what"><span class="toc-section-number">6.2.1</span> What<span></span></a></li>
<li><a href="introduction-1.html#random-vectors-and-matrices" id="toc-random-vectors-and-matrices"><span class="toc-section-number">6.2.2</span> Random Vectors and Matrices<span></span></a></li>
<li><a href="introduction-1.html#multivariate-normal-distributions" id="toc-multivariate-normal-distributions"><span class="toc-section-number">6.2.3</span> Multivariate Normal Distributions<span></span></a></li>
<li><a href="introduction-1.html#distributions-of-quadratic-forms" id="toc-distributions-of-quadratic-forms"><span class="toc-section-number">6.2.4</span> Distributions of Quadratic Forms<span></span></a></li>
</ul></li>
<li><a href="estimation.html#estimation" id="toc-estimation"><span class="toc-section-number">6.3</span> Estimation<span></span></a>
<ul>
<li><a href="estimation.html#identifiability-and-estimability" id="toc-identifiability-and-estimability"><span class="toc-section-number">6.3.1</span> Identifiability and Estimability<span></span></a></li>
<li><a href="estimation.html#estimation-least-squares" id="toc-estimation-least-squares"><span class="toc-section-number">6.3.2</span> Estimation: Least Squares<span></span></a></li>
<li><a href="estimation.html#estimation-best-linear-unbiased" id="toc-estimation-best-linear-unbiased"><span class="toc-section-number">6.3.3</span> Estimation: Best Linear Unbiased<span></span></a></li>
<li><a href="estimation.html#estimation-maximum-likelihood" id="toc-estimation-maximum-likelihood"><span class="toc-section-number">6.3.4</span> Estimation: Maximum Likelihood<span></span></a></li>
<li><a href="estimation.html#estimation-minimum-variance-unbiased" id="toc-estimation-minimum-variance-unbiased"><span class="toc-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased<span></span></a></li>
<li><a href="estimation.html#sampling-distributions-of-estimates" id="toc-sampling-distributions-of-estimates"><span class="toc-section-number">6.3.6</span> Sampling Distributions of Estimates<span></span></a></li>
<li><a href="estimation.html#generalized-least-squaresgls" id="toc-generalized-least-squaresgls"><span class="toc-section-number">6.3.7</span> Generalized Least Squares(GLS)<span></span></a></li>
</ul></li>
<li><a href="one-way-anova.html#one-way-anova" id="toc-one-way-anova"><span class="toc-section-number">6.4</span> One-Way ANOVA<span></span></a>
<ul>
<li><a href="one-way-anova.html#one-way-anova-1" id="toc-one-way-anova-1"><span class="toc-section-number">6.4.1</span> One-Way ANOVA<span></span></a></li>
<li><a href="one-way-anova.html#more-about-models" id="toc-more-about-models"><span class="toc-section-number">6.4.2</span> More About Models<span></span></a></li>
<li><a href="one-way-anova.html#estimating-and-testing-contrasts" id="toc-estimating-and-testing-contrasts"><span class="toc-section-number">6.4.3</span> Estimating and Testing Contrasts<span></span></a></li>
<li><a href="one-way-anova.html#cochrans-theorem" id="toc-cochrans-theorem"><span class="toc-section-number">6.4.4</span> Cochran’s Theorem<span></span></a></li>
</ul></li>
<li><a href="testing.html#testing" id="toc-testing"><span class="toc-section-number">6.5</span> Testing<span></span></a>
<ul>
<li><a href="testing.html#more-about-models-two-approaches-for-linear-model" id="toc-more-about-models-two-approaches-for-linear-model"><span class="toc-section-number">6.5.1</span> More About Models: Two approaches for linear model<span></span></a></li>
<li><a href="testing.html#testing-models" id="toc-testing-models"><span class="toc-section-number">6.5.2</span> Testing Models<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure" id="toc-a-generalized-test-procedure"><span class="toc-section-number">6.5.3</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-linear-parametric-functions" id="toc-testing-linear-parametric-functions"><span class="toc-section-number">6.5.4</span> Testing Linear Parametric Functions<span></span></a></li>
<li><a href="testing.html#theoretical-complements" id="toc-theoretical-complements"><span class="toc-section-number">6.5.5</span> Theoretical Complements<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure-1" id="toc-a-generalized-test-procedure-1"><span class="toc-section-number">6.5.6</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace" id="toc-testing-single-degrees-of-freedom-in-a-given-subspace"><span class="toc-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace<span></span></a></li>
<li><a href="testing.html#breaking-ss-into-independent-components" id="toc-breaking-ss-into-independent-components"><span class="toc-section-number">6.5.8</span> Breaking SS into Independent Components<span></span></a></li>
<li><a href="testing.html#general-theory" id="toc-general-theory"><span class="toc-section-number">6.5.9</span> General Theory<span></span></a></li>
<li><a href="testing.html#two-way-anova" id="toc-two-way-anova"><span class="toc-section-number">6.5.10</span> Two-Way ANOVA<span></span></a></li>
<li><a href="testing.html#confidence-regions" id="toc-confidence-regions"><span class="toc-section-number">6.5.11</span> Confidence Regions<span></span></a></li>
<li><a href="testing.html#tests-for-generalized-least-squares-models" id="toc-tests-for-generalized-least-squares-models"><span class="toc-section-number">6.5.12</span> Tests for Generalized Least Squares Models<span></span></a></li>
</ul></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">6.6</span> Generalized Least Squares<span></span></a>
<ul>
<li><a href="generalized-least-squares.html#a-direct-solution-via-inner-products" id="toc-a-direct-solution-via-inner-products"><span class="toc-section-number">6.6.1</span> A direct solution via inner products<span></span></a></li>
</ul></li>
<li><a href="flat.html#flat" id="toc-flat"><span class="toc-section-number">6.7</span> Flat<span></span></a>
<ul>
<li><a href="flat.html#flat-1" id="toc-flat-1"><span class="toc-section-number">6.7.1</span> 1.Flat<span></span></a></li>
<li><a href="flat.html#solutions-to-systems-of-linear-equations" id="toc-solutions-to-systems-of-linear-equations"><span class="toc-section-number">6.7.2</span> 2. Solutions to systems of linear equations<span></span></a></li>
</ul></li>
<li><a href="unified-approach-to-balanced-anova-models.html#unified-approach-to-balanced-anova-models" id="toc-unified-approach-to-balanced-anova-models"><span class="toc-section-number">6.8</span> Unified Approach to Balanced ANOVA Models<span></span></a></li>
</ul></li>
<li><a href="#part-21-02" id="toc-part-21-02">(PART) 21-02<span></span></a></li>
<li><a href="network-stats.html#network-stats" id="toc-network-stats"><span class="toc-section-number">7</span> Network Stats<span></span></a>
<ul>
<li><a href="introduction-2.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">7.1</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-2.html#types-of-network-analysis" id="toc-types-of-network-analysis"><span class="toc-section-number">7.1.1</span> Types of Network Analysis<span></span></a></li>
<li><a href="introduction-2.html#network-modeling-and-inference" id="toc-network-modeling-and-inference"><span class="toc-section-number">7.1.2</span> Network Modeling and Inference<span></span></a></li>
<li><a href="introduction-2.html#network-processes" id="toc-network-processes"><span class="toc-section-number">7.1.3</span> Network Processes<span></span></a></li>
</ul></li>
<li><a href="descriptive-statistics-of-networks.html#descriptive-statistics-of-networks" id="toc-descriptive-statistics-of-networks"><span class="toc-section-number">7.2</span> Descriptive Statistics of Networks<span></span></a>
<ul>
<li><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics" id="toc-vertex-and-edge-characteristics"><span class="toc-section-number">7.2.1</span> Vertex and Edge Characteristics<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion" id="toc-characterizing-network-cohesion"><span class="toc-section-number">7.2.2</span> Characterizing Network Cohesion<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#graph-partitioning" id="toc-graph-partitioning"><span class="toc-section-number">7.2.3</span> Graph Partitioning<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing" id="toc-assortativity-and-mixing"><span class="toc-section-number">7.2.4</span> Assortativity and Mixing<span></span></a></li>
</ul></li>
<li><a href="data-collection-and-sampling.html#data-collection-and-sampling" id="toc-data-collection-and-sampling"><span class="toc-section-number">7.3</span> Data Collection and Sampling<span></span></a>
<ul>
<li><a href="data-collection-and-sampling.html#sampling-designs" id="toc-sampling-designs"><span class="toc-section-number">7.3.1</span> Sampling Designs<span></span></a></li>
<li><a href="data-collection-and-sampling.html#coping-strategies" id="toc-coping-strategies"><span class="toc-section-number">7.3.2</span> Coping Strategies<span></span></a></li>
<li><a href="data-collection-and-sampling.html#big-data-solves-nothing" id="toc-big-data-solves-nothing"><span class="toc-section-number">7.3.3</span> Big Data Solves Nothing<span></span></a></li>
</ul></li>
<li><a href="mathematical-models-for-network-graphs.html#mathematical-models-for-network-graphs" id="toc-mathematical-models-for-network-graphs"><span class="toc-section-number">7.4</span> Mathematical Models for Network Graphs<span></span></a>
<ul>
<li><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models" id="toc-classical-random-graph-models"><span class="toc-section-number">7.4.1</span> Classical Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models" id="toc-generalized-random-graph-models"><span class="toc-section-number">7.4.2</span> Generalized Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms" id="toc-network-graph-models-based-on-mechanisms"><span class="toc-section-number">7.4.3</span> Network Graph Models Based on Mechanisms<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics" id="toc-assessing-significance-of-network-graph-characteristics"><span class="toc-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics<span></span></a></li>
</ul></li>
<li><a href="introduction-to-ergm.html#introduction-to-ergm" id="toc-introduction-to-ergm"><span class="toc-section-number">7.5</span> Introduction to ERGM<span></span></a>
<ul>
<li><a href="introduction-to-ergm.html#exponential-random-graph-models" id="toc-exponential-random-graph-models"><span class="toc-section-number">7.5.1</span> Exponential Random Graph Models<span></span></a></li>
<li><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation" id="toc-difficulty-in-parameter-estimation"><span class="toc-section-number">7.5.2</span> Difficulty in Parameter Estimation<span></span></a></li>
</ul></li>
<li><a href="parameter-estimation-of-ergm.html#parameter-estimation-of-ergm" id="toc-parameter-estimation-of-ergm"><span class="toc-section-number">7.6</span> Parameter Estimation of ERGM<span></span></a>
<ul>
<li><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm" id="toc-current-methods-for-ergm"><span class="toc-section-number">7.6.1</span> Current Methods for ERGM<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm" id="toc-approximation-based-algorithm"><span class="toc-section-number">7.6.2</span> Approximation-based Algorithm<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches" id="toc-auxiliary-variable-mcmc-based-approaches"><span class="toc-section-number">7.6.3</span> Auxiliary Variable MCMC-based Approaches<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc" id="toc-varying-trunction-stochastic-approximation-mcmc"><span class="toc-section-number">7.6.4</span> Varying Trunction Stochastic Approximation MCMC<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#conclusion" id="toc-conclusion"><span class="toc-section-number">7.6.5</span> Conclusion<span></span></a></li>
</ul></li>
<li><a href="ergm-for-dynamic-networks.html#ergm-for-dynamic-networks" id="toc-ergm-for-dynamic-networks"><span class="toc-section-number">7.7</span> ERGM for Dynamic Networks<span></span></a>
<ul>
<li><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm" id="toc-temporal-ergm-tergm-t-ergm"><span class="toc-section-number">7.7.1</span> Temporal ERGM (TERGM, T ERGM)<span></span></a></li>
<li><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm" id="toc-separable-temporal-ergm-stergm-st-ergm"><span class="toc-section-number">7.7.2</span> Separable Temporal ERGM (STERGM, ST ERGM)<span></span></a></li>
</ul></li>
<li><a href="latent-network-models.html#latent-network-models" id="toc-latent-network-models"><span class="toc-section-number">7.8</span> Latent Network Models<span></span></a>
<ul>
<li><a href="latent-network-models.html#latent-position-model" id="toc-latent-position-model"><span class="toc-section-number">7.8.1</span> Latent Position Model<span></span></a></li>
<li><a href="latent-network-models.html#latent-position-cluster-model" id="toc-latent-position-cluster-model"><span class="toc-section-number">7.8.2</span> Latent Position Cluster Model<span></span></a></li>
</ul></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#additive-and-multiplicative-effects-network-models" id="toc-additive-and-multiplicative-effects-network-models"><span class="toc-section-number">7.9</span> Additive and Multiplicative Effects Network Models<span></span></a>
<ul>
<li><a href="additive-and-multiplicative-effects-network-models.html#introduction-3" id="toc-introduction-3"><span class="toc-section-number">7.9.1</span> Introduction<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression" id="toc-social-relations-regression"><span class="toc-section-number">7.9.2</span> Social Relations Regression<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models" id="toc-multiplicative-effects-models"><span class="toc-section-number">7.9.3</span> Multiplicative Effects Models<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation" id="toc-inference-via-posterior-approximation"><span class="toc-section-number">7.9.4</span> Inference via Posterior Approximation<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r" id="toc-discussion-and-example-with-r"><span class="toc-section-number">7.9.5</span> Discussion and Example with R<span></span></a></li>
</ul></li>
<li><a href="stochastic-block-models.html#stochastic-block-models" id="toc-stochastic-block-models"><span class="toc-section-number">7.10</span> Stochastic Block Models<span></span></a>
<ul>
<li><a href="stochastic-block-models.html#stochastic-block-model" id="toc-stochastic-block-model"><span class="toc-section-number">7.10.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm" id="toc-mixed-membership-block-model-mmbm"><span class="toc-section-number">7.10.2</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="high-dimension.html#high-dimension" id="toc-high-dimension"><span class="toc-section-number">8</span> High Dimension<span></span></a>
<ul>
<li><a href="introduction-4.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">8.1</span> Introduction<span></span></a></li>
<li><a href="concentration-inequalities.html#concentration-inequalities" id="toc-concentration-inequalities"><span class="toc-section-number">8.2</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities.html#motivation" id="toc-motivation"><span class="toc-section-number">8.2.1</span> Motivation<span></span></a></li>
<li><a href="concentration-inequalities.html#from-markov-to-chernoff" id="toc-from-markov-to-chernoff"><span class="toc-section-number">8.2.2</span> From Markov to Chernoff<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-variables" id="toc-sub-gaussian-random-variables"><span class="toc-section-number">8.2.3</span> sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables" id="toc-properties-of-sub-gaussian-random-variables"><span class="toc-section-number">8.2.4</span> Properties of sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#equivalent-definitions" id="toc-equivalent-definitions"><span class="toc-section-number">8.2.5</span> Equivalent definitions<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-vectors" id="toc-sub-gaussian-random-vectors"><span class="toc-section-number">8.2.6</span> Sub-Gaussian random vectors<span></span></a></li>
<li><a href="concentration-inequalities.html#hoeffdings-inequality" id="toc-hoeffdings-inequality"><span class="toc-section-number">8.2.7</span> Hoeffding’s inequality<span></span></a></li>
<li><a href="concentration-inequalities.html#maximal-inequalities" id="toc-maximal-inequalities"><span class="toc-section-number">8.2.8</span> Maximal inequalities<span></span></a></li>
<li><a href="concentration-inequalities.html#section" id="toc-section"><span class="toc-section-number">8.2.9</span> </a></li>
</ul></li>
<li><a href="concentration-inequalities-1.html#concentration-inequalities-1" id="toc-concentration-inequalities-1"><span class="toc-section-number">8.3</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities-1.html#sub-exponential-random-variables" id="toc-sub-exponential-random-variables"><span class="toc-section-number">8.3.1</span> Sub-exponential random variables<span></span></a></li>
<li><a href="concentration-inequalities-1.html#bernsteins-condition" id="toc-bernsteins-condition"><span class="toc-section-number">8.3.2</span> Bernstein’s condition<span></span></a></li>
<li><a href="concentration-inequalities-1.html#mcdiarmids-inequality" id="toc-mcdiarmids-inequality"><span class="toc-section-number">8.3.3</span> McDiarmid’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#levys-inequality" id="toc-levys-inequality"><span class="toc-section-number">8.3.4</span> Levy’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#quadratic-form" id="toc-quadratic-form"><span class="toc-section-number">8.3.5</span> Quadratic form<span></span></a></li>
<li><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma" id="toc-the-johnsonlindenstrauss-lemma"><span class="toc-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma<span></span></a></li>
</ul></li>
<li><a href="metric-entropy-and-its-uses.html#metric-entropy-and-its-uses" id="toc-metric-entropy-and-its-uses"><span class="toc-section-number">8.4</span> Metric entropy and its uses<span></span></a>
<ul>
<li><a href="metric-entropy-and-its-uses.html#metric-space" id="toc-metric-space"><span class="toc-section-number">8.4.1</span> Metric space<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy" id="toc-covering-numbers-and-metric-entropy"><span class="toc-section-number">8.4.2</span> Covering numbers and metric entropy<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#packing-numbers" id="toc-packing-numbers"><span class="toc-section-number">8.4.3</span> Packing numbers<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#section-1" id="toc-section-1"><span class="toc-section-number">8.4.4</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-2" id="toc-section-2"><span class="toc-section-number">8.4.5</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-3" id="toc-section-3"><span class="toc-section-number">8.4.6</span> </a></li>
</ul></li>
<li><a href="covariance-estimation.html#covariance-estimation" id="toc-covariance-estimation"><span class="toc-section-number">8.5</span> Covariance estimation<span></span></a>
<ul>
<li><a href="covariance-estimation.html#matrix-algebra-review" id="toc-matrix-algebra-review"><span class="toc-section-number">8.5.1</span> Matrix algebra review<span></span></a></li>
<li><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm" id="toc-covariance-matrix-estimation-in-the-operator-norm"><span class="toc-section-number">8.5.2</span> Covariance matrix estimation in the operator norm<span></span></a></li>
<li><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices" id="toc-bounds-for-structured-covariance-matrices"><span class="toc-section-number">8.5.3</span> Bounds for structured covariance matrices<span></span></a></li>
</ul></li>
<li><a href="matrix-concentration-inequalities.html#matrix-concentration-inequalities" id="toc-matrix-concentration-inequalities"><span class="toc-section-number">8.6</span> Matrix concentration inequalities<span></span></a>
<ul>
<li><a href="matrix-concentration-inequalities.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">8.6.1</span> Matrix calculus<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#matrix-chernoff" id="toc-matrix-chernoff"><span class="toc-section-number">8.6.2</span> Matrix Chernoff<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices" id="toc-sub-gaussian-and-sub-exponential-matrices"><span class="toc-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds" id="toc-랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><span class="toc-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds<span></span></a></li>
</ul></li>
<li><a href="principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.7</span> Principal Component Analysis<span></span></a>
<ul>
<li><a href="principal-component-analysis.html#pca-1" id="toc-pca-1"><span class="toc-section-number">8.7.1</span> PCA<span></span></a></li>
<li><a href="principal-component-analysis.html#matrix-perturbation" id="toc-matrix-perturbation"><span class="toc-section-number">8.7.2</span> Matrix Perturbation<span></span></a></li>
<li><a href="principal-component-analysis.html#spiked-cov-model" id="toc-spiked-cov-model"><span class="toc-section-number">8.7.3</span> Spiked Cov Model<span></span></a></li>
<li><a href="principal-component-analysis.html#sparse-pca" id="toc-sparse-pca"><span class="toc-section-number">8.7.4</span> sparse PCA<span></span></a></li>
</ul></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">8.8</span> Linear Regression<span></span></a>
<ul>
<li><a href="linear-regression.html#problem-formulation" id="toc-problem-formulation"><span class="toc-section-number">8.8.1</span> Problem formulation<span></span></a></li>
<li><a href="linear-regression.html#least-squares-estimator-in-high-dimensions" id="toc-least-squares-estimator-in-high-dimensions"><span class="toc-section-number">8.8.2</span> Least Squares Estimator in high dimensions<span></span></a></li>
<li><a href="linear-regression.html#sparse-linear-regression" id="toc-sparse-linear-regression"><span class="toc-section-number">8.8.3</span> Sparse linear regression<span></span></a></li>
</ul></li>
<li><a href="uniform-laws-of-large-numbers.html#uniform-laws-of-large-numbers" id="toc-uniform-laws-of-large-numbers"><span class="toc-section-number">8.9</span> Uniform laws of large numbers<span></span></a>
<ul>
<li><a href="uniform-laws-of-large-numbers.html#motivation-1" id="toc-motivation-1"><span class="toc-section-number">8.9.1</span> Motivation<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity" id="toc-a-uniform-law-via-rademacher-complexity"><span class="toc-section-number">8.9.2</span> A uniform law via Rademacher complexity<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity" id="toc-upper-bounds-on-the-rademacher-complexity"><span class="toc-section-number">8.9.3</span> Upper bounds on the Rademacher complexity<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">9</span> Survival Analysis<span></span></a>
<ul>
<li><a href="introduction-5.html#introduction-5" id="toc-introduction-5"><span class="toc-section-number">9.1</span> Introduction<span></span></a></li>
<li><a href="section-4.html#section-4" id="toc-section-4"><span class="toc-section-number">9.2</span> </a></li>
<li><a href="counting-processes-and-martingales.html#counting-processes-and-martingales" id="toc-counting-processes-and-martingales"><span class="toc-section-number">9.3</span> Counting Processes and Martingales<span></span></a>
<ul>
<li><a href="counting-processes-and-martingales.html#conditional-expectation" id="toc-conditional-expectation"><span class="toc-section-number">9.3.1</span> Conditional Expectation<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#martingale" id="toc-martingale"><span class="toc-section-number">9.3.2</span> Martingale<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#key-martingales-properties" id="toc-key-martingales-properties"><span class="toc-section-number">9.3.3</span> Key Martingales Properties<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#section-5" id="toc-section-5"><span class="toc-section-number">9.3.4</span> </a></li>
<li><a href="counting-processes-and-martingales.html#section-6" id="toc-section-6"><span class="toc-section-number">9.3.5</span> </a></li>
</ul></li>
<li><a href="section-7.html#section-7" id="toc-section-7"><span class="toc-section-number">9.4</span> </a></li>
<li><a href="cox-regression.html#cox-regression" id="toc-cox-regression"><span class="toc-section-number">9.5</span> Cox Regression<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#filtration의-개념을-정복하자" id="toc-filtration의-개념을-정복하자"><span class="toc-section-number">9.6</span> Filtration의 개념을 정복하자!<span></span></a>
<ul>
<li><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약" id="toc-random-process를-이야기-하기까지의-긴-여정의-요약"><span class="toc-section-number">9.6.1</span> Random Process를 이야기 하기까지의 긴 여정의 요약<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#ft-measurable" id="toc-ft-measurable"><span class="toc-section-number">9.6.2</span> Ft-measurable<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#epilogue" id="toc-epilogue"><span class="toc-section-number">9.6.3</span> EPILOGUE<span></span></a></li>
</ul></li>
<li><a href="concepts.html#concepts" id="toc-concepts"><span class="toc-section-number">9.7</span> Concepts<span></span></a></li>
</ul></li>
<li><a href="#part-22-01" id="toc-part-22-01">(PART) 22-01<span></span></a></li>
<li><a href="scikit.html#scikit" id="toc-scikit"><span class="toc-section-number">10</span> scikit<span></span></a>
<ul>
<li><a href="linear-models.html#linear-models" id="toc-linear-models"><span class="toc-section-number">10.1</span> Linear Models<span></span></a>
<ul>
<li><a href="linear-models.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">10.1.1</span> Ordinary Least Squares<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="#appendix-00-00" id="toc-appendix-00-00">(APPENDIX) 00-00<span></span></a></li>
<li><a href="concepts-1.html#concepts-1" id="toc-concepts-1"><span class="toc-section-number">11</span> Concepts<span></span></a>
<ul>
<li><a href="autologistic.html#autologistic" id="toc-autologistic"><span class="toc-section-number">11.1</span> Autologistics<span></span></a></li>
<li><a href="orderlogit.html#orderlogit" id="toc-orderlogit"><span class="toc-section-number">11.2</span> Ordered Logit<span></span></a></li>
<li><a href="concepts-questions.html#concepts-questions" id="toc-concepts-questions"><span class="toc-section-number">11.3</span> Concepts Questions<span></span></a>
<ul>
<li><a href="concepts-questions.html#통계-및-수학" id="toc-통계-및-수학"><span class="toc-section-number">11.3.1</span> 통계 및 수학<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="about-cluster-gcn.html#about-cluster-gcn" id="toc-about-cluster-gcn"><span class="toc-section-number">12</span> About Cluster-GCN<span></span></a>
<ul>
<li><a href="about-cluster-gcn.html#ann" id="toc-ann"><span class="toc-section-number">12.0.1</span> ANN<span></span></a></li>
<li><a href="about-cluster-gcn.html#cnn" id="toc-cnn"><span class="toc-section-number">12.0.2</span> CNN<span></span></a></li>
<li><a href="about-cluster-gcn.html#graph-convolution-network" id="toc-graph-convolution-network"><span class="toc-section-number">12.0.3</span> Graph Convolution Network<span></span></a></li>
<li><a href="about-cluster-gcn.html#cluster-gcn" id="toc-cluster-gcn"><span class="toc-section-number">12.0.4</span> Cluster-GCN<span></span></a></li>
</ul></li>
<li><a href="cnn-1.html#cnn-1" id="toc-cnn-1"><span class="toc-section-number">13</span> CNN<span></span></a></li>
<li><a href="cnn-2.html#cnn-2" id="toc-cnn-2"><span class="toc-section-number">14</span> CNN<span></span></a></li>
<li><a href="cnn-3.html#cnn-3" id="toc-cnn-3"><span class="toc-section-number">15</span> CNN<span></span></a></li>
<li><a href="section-8.html#section-8" id="toc-section-8"><span class="toc-section-number">16</span> 01<span></span></a></li>
<li><a href="section-9.html#section-9" id="toc-section-9"><span class="toc-section-number">17</span> 02<span></span></a></li>
<li><a href="서-론.html#서-론" id="toc-서-론"><span class="toc-section-number">18</span> 서 론<span></span></a>
<ul>
<li><a href="연구-배경.html#연구-배경" id="toc-연구-배경"><span class="toc-section-number">18.1</span> 연구 배경<span></span></a></li>
<li><a href="연구-목적.html#연구-목적" id="toc-연구-목적"><span class="toc-section-number">18.2</span> 연구 목적<span></span></a></li>
</ul></li>
<li><a href="method.html#method" id="toc-method"><span class="toc-section-number">19</span> Method<span></span></a>
<ul>
<li><a href="biterm.html#biterm" id="toc-biterm"><span class="toc-section-number">19.1</span> Biterm<span></span></a>
<ul>
<li><a href="biterm.html#section-10" id="toc-section-10"><span class="toc-section-number">19.1.1</span> 2.1.1<span></span></a></li>
<li><a href="biterm.html#줄-요약" id="toc-줄-요약"><span class="toc-section-number">19.1.2</span> 3줄 요약<span></span></a></li>
<li><a href="biterm.html#section-11" id="toc-section-11"><span class="toc-section-number">19.1.3</span> 2.1.2<span></span></a></li>
<li><a href="biterm.html#latent-space-item-response-model" id="toc-latent-space-item-response-model"><span class="toc-section-number">19.1.4</span> 2.1.3 Latent Space Item Response Model<span></span></a></li>
<li><a href="biterm.html#procrustes-matching-and-oblique-roation" id="toc-procrustes-matching-and-oblique-roation"><span class="toc-section-number">19.1.5</span> Procrustes Matching and Oblique Roation<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="latent-space-item-response-model-구현.html#latent-space-item-response-model-구현" id="toc-latent-space-item-response-model-구현"><span class="toc-section-number">20</span> Latent Space Item Response Model 구현<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브로-모델-설계" id="toc-python-네이티브로-모델-설계"><span class="toc-section-number">20.1</span> 3.1. python 네이티브로 모델 설계<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브에서의-속도-퍼포먼스" id="toc-python-네이티브에서의-속도-퍼포먼스"><span class="toc-section-number">20.1.1</span> 3.1.1. python 네이티브에서의 속도 퍼포먼스<span></span></a></li>
</ul></li>
<li><a href="python에-c-접합한-모델-설계.html#python에-c-접합한-모델-설계" id="toc-python에-c-접합한-모델-설계"><span class="toc-section-number">20.2</span> 3.2. python에 c++ 접합한 모델 설계<span></span></a>
<ul>
<li><a href="python에-c-접합한-모델-설계.html#wrapping-timing" id="toc-wrapping-timing"><span class="toc-section-number">20.2.1</span> Wrapping Timing<span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#library-needed-in-c" id="toc-library-needed-in-c"><span class="toc-section-number">20.2.2</span> Library needed in <code>c++</code><span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#접합-모델-검증-및-성능-비교" id="toc-접합-모델-검증-및-성능-비교"><span class="toc-section-number">20.2.3</span> 3.2.1. 접합 모델 검증 및 성능 비교<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="implementation-1.html#implementation-1" id="toc-implementation-1"><span class="toc-section-number">21</span> Implementation<span></span></a>
<ul>
<li><a href="preprocess.html#preprocess" id="toc-preprocess"><span class="toc-section-number">21.1</span> <code>preprocess()</code><span></span></a></li>
<li><a href="btmize.html#btmize" id="toc-btmize"><span class="toc-section-number">21.2</span> <code>btmize()</code><span></span></a></li>
<li><a href="lsirmize.html#lsirmize" id="toc-lsirmize"><span class="toc-section-number">21.3</span> <code>lsirmize()</code><span></span></a></li>
</ul></li>
<li><a href="구현-모델-실적용-예시.html#구현-모델-실적용-예시" id="toc-구현-모델-실적용-예시"><span class="toc-section-number">22</span> 구현 모델 실적용 예시<span></span></a>
<ul>
<li><a href="데이터-서술.html#데이터-서술" id="toc-데이터-서술"><span class="toc-section-number">22.1</span> 4.1 데이터 서술<span></span></a></li>
<li><a href="알고리즘-결과.html#알고리즘-결과" id="toc-알고리즘-결과"><span class="toc-section-number">22.2</span> 4.2 알고리즘 결과<span></span></a></li>
</ul></li>
<li><a href="결론.html#결론" id="toc-결론"><span class="toc-section-number">23</span> 결론<span></span></a>
<ul>
<li><a href="section-12.html#section-12" id="toc-section-12"><span class="toc-section-number">23.1</span> 10.<span></span></a>
<ul>
<li><a href="section-12.html#stochastic-block-model-1" id="toc-stochastic-block-model-1"><span class="toc-section-number">23.1.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="section-12.html#likelihood-function-1" id="toc-likelihood-function-1"><span class="toc-section-number">23.1.2</span> Likelihood function<span></span></a></li>
<li><a href="section-12.html#mixed-membership-block-model-mmbm-1" id="toc-mixed-membership-block-model-mmbm-1"><span class="toc-section-number">23.1.3</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="else" class="section level2 hasAnchor" number="4.10">
<h2><span class="header-section-number">4.10</span> Else<a href="else.html#else" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="hw4.-rasch-model" class="section level3 hasAnchor" number="4.10.1">
<h3><span class="header-section-number">4.10.1</span> Hw4. Rasch Model<a href="else.html#hw4.-rasch-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>$$
<span class="math display">\[\begin{align}

L(\theta, \beta) &amp;= \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}} \\



\pi (\theta, \beta \vert y) &amp;= \pi(\theta) \pi(\beta) \ast \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}}


\end{align}\]</span>
$$</p>
<p><span class="math display">\[
0&lt;\left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} &lt;1, \; \; \; \; \; 0&lt;\left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}}&lt;1
\]</span></p>
<p><strong>underflow problem</strong>. log 취하면 해결.</p>
<p><span class="math display">\[
\pi(\theta_k) \sim N(0, \sigma^2), \; \; \; \; \; \pi(\sigma^2 ) \sim IG(0.001, 0.001)
\]</span></p>
<p>update <span class="math inline">\(\theta_k , k=1, \cdots, n\)</span>”</p>
<p><span class="math display">\[
\log (r) = \log \pi (\theta_k &#39; \vert y, \beta^{(t)}. \theta_{-k}^{(t)} - \log \pi (\theta^{(t)} \vert y, \beta^{(t)}. \theta_{-k}^{(t)}
\]</span></p>
<p>if <span class="math inline">\(\log U &lt; min(\log(r), 0))\)</span>, accept. else, reject.</p>
<hr />
</div>
<div id="da-example-mvn" class="section level3 hasAnchor" number="4.10.2">
<h3><span class="header-section-number">4.10.2</span> DA) Example: MVN<a href="else.html#da-example-mvn" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>for DA 알고리즘, I-step과 P-step이 존재.</p>
<div id="i-step" class="section level4 hasAnchor" number="4.10.2.1">
<h4><span class="header-section-number">4.10.2.1</span> 1. I-Step<a href="else.html#i-step" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>$$
<span class="math display">\[\begin{alignat}{4}

Y_2 \vert Y_1 &amp;\sim N &amp;&amp; \Big( \mu_2 + \Sigma_{21} \Sigma_{11}^{-1} (Y_1 - \mu_1) , &amp;&amp; \Sigma_{22}  - \Sigma_{21}\Sigma_{11}^{-1} \Sigma_{12} \Big) \\

Y_{i, mis} \vert Y_{i, obs}, \mu, \Sigma &amp;\sim N_{dim(Y_{mis}^{(i)})} &amp;&amp; \Big( \mu_{mis}^{(i)} + \Sigma_{mis, obs}^{(i)} \Sigma_{obs, obs}^{-1} (Y_{i, obs} - \mu_{i, mis}^{(i)}) , &amp;&amp; \Sigma_{mis,mis}^{(i)}  - \Sigma_{mis,obs}^{(i)}[\Sigma_{obs,obs}^{(i)}]^{-1} \Sigma_{obs,mis}^{(i)} \Big)

\end{alignat}\]</span>
$$</p>
<p>상기의 conditional pdf로 우리는 <span class="math inline">\(Y_{i, mis}\)</span>를 impute 가능.</p>
<p><strong>for <span class="math inline">\(i=1, \cdots, n\)</span>, <span class="math inline">\(Y_{i, mis} \vert Y_{i, obs}\)</span> 에서 <span class="math inline">\(Y_{i, mis}\)</span>를 draw.</strong></p>
</div>
<div id="p-step" class="section level4 hasAnchor" number="4.10.2.2">
<h4><span class="header-section-number">4.10.2.2</span> 2. P-Step<a href="else.html#p-step" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>베이지안 분석을 위해선 prior가 필요. 여기서 prior는 이하로 설정하자. <span class="math inline">\(q\)</span>는 known integer이며, <span class="math inline">\(q=p\)</span>인 상황에 이는 <span class="math inline">\(\Sigma\)</span>에 대한 Jefferey’s prior.</p>
<p><span class="math display">\[
\pi (\mu, \Sigma) \propto \vert \Sigma \vert^{-\tfrac{q+1}{2}}
\]</span></p>
<p>위와 같이 식들을 구성하였을 때, com 데이터에 대한 posterior distribution <span class="math inline">\(\pi(\mu, \Sigma \vert Y_1 , \cdots, Y_n)\)</span>는 이하와 같이 characterized 가능. 이는 inverse-Wishart 분포.</p>
<p><span class="math display">\[
\Sigma \vert Y_1 , \cdots, Y_n \sim \dfrac{1}{\vert \Sigma \vert^{-\tfrac{q+n}{2}}} \exp \left\{ -\dfrac{1}{2} tr\left( \Sigma^{-1} S \right) \right\}
\]</span></p>
<p>이렇게 획득해온 패러미터들을 사용해 <span class="math inline">\(\mu\)</span>의 post를 구하면 이하와 같다.</p>
<p><span class="math display">\[
\mu \vert \Sigma, Y_1 , \cdots, Y_n \sim N_p \left( \bar Y \dfrac {1}{n} \Sigma \right)
\]</span></p>
<p><strong><span class="math inline">\(\Sigma \vert Y_1 , \cdots, Y_n\)</span>에서 <span class="math inline">\(\Sigma\)</span> 를 생산</strong></p>
<p><strong>이후 <span class="math inline">\(\mu \vert \Sigma, Y_1 , \cdots, Y_n\)</span>에서 <span class="math inline">\(\mu\)</span> 를 생산</strong></p>
<hr />
</div>
</div>
<div id="bayesian-adaptive-clinical-trial-with-delayed-outcomes" class="section level3 hasAnchor" number="4.10.3">
<h3><span class="header-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes<a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="continual-reassessment-method" class="section level4 hasAnchor" number="4.10.3.1">
<h4><span class="header-section-number">4.10.3.1</span> Continual Reassessment Method<a href="else.html#continual-reassessment-method" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Clinical Trial: Toxicity -&gt; Efficacy -&gt; Confirmation</p>
<p>희귀병 케이스에서는 도즈 레벨을 1~n까지 정해둔 후, 샘플을 slice 하여 1번 subsample에 도즈1 투입. 유효하면 (1차시에 3명 투입했다고 하고 그중에 1명이 독성 나왔으면 독성 확률은 1/3. 해당 여부로 도즈2로 넘어갈 것인지를 판단) 2투입. 2에서 문제 생기면 1로 복귀하고 2번 subsample에 도즈1 투입해봐서 유효한지 검증. 이렇게 모든 서브샘플에 도즈레벨 오가면서 투입해보고 최적 도즈레벨 결정.</p>
<p><img src="99-0.png"></p>
<p>이때 CRM을 시작하기 전 대략적으로 이정도의 도즈레벨이 최적 도즈레벨일 것이라는 예측 (Skeleton)을 정하고 CRM을 시작함.</p>
<hr />
<ul>
<li>delay outcome</li>
</ul>
<p>이전 환자들의 evaluation이 끝나기 전에 (evaluation period가 경과하기 전이나, 결과가 나오기 전에) 환자 풀이 증가하는 상황</p>
<p>이 상황에서는 관측이 더 된 환자보다 덜 된 환자에서 outcome이 발생할 확률이 높음. 9개월 누워있던 놈보다 2개월 누워있던 놈이 12개월 경과 전에 뭔가 변화를 보이기 쉽다는 소리.</p>
<p>이때 아직 결과를 관찰하지 못한 환자들을 mis로 지정. 이 상황은 누워있던 기간이 결과 발생 여부라는 variant와 직결되어 있으므로 NMAR. 그러니까, 여기서 결과값은 outcome이 발생했는지 안했는지, 그리고 variable은 환자나 누워있던 기간.</p>
<p>위에서 언급했듯 누워있던 기간이 짧으면 변이확률 높음. 따라서 각각에 대해 다른 survival function을 적용하여 각각의 다른 확률 뽑아낸 후 이거 기반으로 DA 진행하면 해결.</p>
<hr />
</div>
</div>
<div id="nmar의-종류" class="section level3 hasAnchor" number="4.10.4">
<h3><span class="header-section-number">4.10.4</span> NMAR의 종류<a href="else.html#nmar의-종류" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(m_i\)</span>는 missing indicator. <span class="math inline">\(Y_i\)</span>가 mis면 1.</p>
<p><span class="math display">\[
f(M, Y \vert X, \theta, \psi) = \prod_{i=1}^n f(m_i , y_i \vert x_i , \theta, psi)
\]</span></p>
<p>interested in <strong>direct</strong> relationship b/w <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, rather than in subpopulation defined by missing-data pattern.</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Selection Model</th>
<th align="center">characterize <span class="math inline">\(y\)</span></th>
<th align="center">missing mechanism</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(f(m_i, y_i \vert x_i, \theta, \psi) =\)</span></td>
<td align="center"><span class="math inline">\(f_y(y_i \vert x_i, \theta)\)</span></td>
<td align="center"><span class="math inline">\(\ast f_{m \vert y}(m_i \vert x_i, y_i, \psi)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(f(m_i, y_i \vert x_i, \xi, \psi) =\)</span></td>
<td align="center"><span class="math inline">\(f(y_i \vert x_i, \xi)\)</span></td>
<td align="center"><span class="math inline">\(\ast f(m_i \vert x_i, \xi)\)</span></td>
</tr>
<tr class="odd">
<td align="center">Pattern Mixture model</td>
<td align="center">mis 데이터의 다른 패턴들에 의해 <br>정의되는 각각 다른 strata에서의 <span class="math inline">\(y_i \vert x_i\)</span>의 분포</td>
<td align="center">probability of different patterns in missingness</td>
</tr>
</tbody>
</table>
<p>missing의 다른 패턴에 따라 <span class="math inline">\(x_i\)</span>가 결정이 되고, 그 <span class="math inline">\(x_i\)</span>를 기준으로 놓았을 때의 <span class="math inline">\(y_i\)</span>의 분포가 궁금.</p>
<hr />
</div>
<div id="wk10-bayesian-model-selection" class="section level3 hasAnchor" number="4.10.5">
<h3><span class="header-section-number">4.10.5</span> wk10) Bayesian Model Selection<a href="else.html#wk10-bayesian-model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>해당 문제는 prior을 어떻게 고르느냐에 따라서 해결될 수 있음. 이하는 해당 문제에 대한 다양한 해결책들.</p>
<div id="spike-and-slab-prior" class="section level4 hasAnchor" number="4.10.5.1">
<h4><span class="header-section-number">4.10.5.1</span> 1. Spike-and-Slab prior<a href="else.html#spike-and-slab-prior" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>let <span class="math inline">\(X_{n \times p} , Y_{n \times 1}\)</span>, then <span class="math inline">\(Y = X \beta\)</span>, where <span class="math inline">\(\beta_{p \times 1}\)</span>.</p>
<p>p가 많다, 즉 배리어블이 많다는 이야기는 실제 각각의 x의 정보량이 중첩될 가능성이 큼. 그러면 수학적으로는 x’x가 full rank matrix가 아닐 것이며, 이는 곧 몇몇 변수들 간에 서로간의 의존관계가 강하여 의미없는 정보를 포함하는 변수들이 많아질 것. 이러한 의미없는 변수를 삭제하고 실제로 필요한 변수들만 골라내어 y에 대한 inference를 하고 싶음. 이것이 모델 셀렉션 문제이며 이걸 베이지안적으로 풀어내는 것이 곧 Bayesian Model Selection.</p>
<p>무지성 prior로는 <span class="math inline">\(\pi(\beta) \sim N(0, \sigma^2)\)</span>가 쓰이지만, 이로는 variable selection이 불가. <span class="math inline">\(\beta\)</span> 중 하나의 component가 0에 가깝게 나왔다고 한들 이것을 0으로 판정할 indicator가 없기 때문. (HPD interval을 구성해서 이것이 0을 포함하면 내치는 식의 방법도 있지만 일단은.)</p>
<p>따라서 다른 prior를 필요로 함. 바로 여기서 사용되는 것이 <strong>Spike-and-Slab prior</strong>. 이름에서 알 수 있듯이 mixture distribution을 prior로 사용함. <span class="math inline">\(\beta\)</span>의 component가 spike 부분에 포함되면 이를 0으로 판정함, 즉 not significant로 판정. 이의 역은 slab part.</p>
<p>이는 곧 prior로 variable selection을 한다는 이야기이다. 즉 이 상황에서는 prior가 패널티로 들어간 것이 된다. 정의적으로 엄밀하게 패널티는 아니지만 사실상의 패널티로 작동. 패널티 term (error penalty)으로 골라내는 것은 full context에서 많이 사용? 이때는 라플라스 프라이어를 쓰고, 노멀을 프라이어 주면? 패널티 텀을 베이지안 인퍼런스로 연결지어서 생각할 수 있지만, 이 배리어블 셀렉션은 디멘션 셀렉션과 연관이 있기 때문에 위와는 정확하게는 다른 개념?</p>
<p>variable selection에는 3가지 방법:
1. 패널티 텀
2. mixture prior
3. 컴퓨테이셔널 (reversible jump, dimension selection) (gradient descent는 아님!)</p>
<p><img src = "99-1.png"></p>
<p>spike 파트 (아래에서는 <span class="math inline">\((1-\lambda)N(0, \sigma^2)\)</span>) 에는 double exponential을 쓰거나, normal 을 변형해서 사용함. 혹은 극단적으로는 dirac 분포 (point mass) 를 쓸 수도 있음.</p>
<p>이하에서 예시로 제시된 수식은 SS prior이며, 이는 spike와 slab 모두 Normal을 사용하였음.</p>
<p><span class="math display">\[
\pi(\beta) \sim (1-\lambda)N(0, \sigma^2) + \lambda N(0, \omega \sigma^2), \; \; \; \; \; w \gg 1
\]</span></p>
<p>위에서 <span class="math inline">\(\sigma^2\)</span>는 spike variance, <span class="math inline">\(w \sigma^2\)</span>는 slab variance.</p>
<p>여기서 <span class="math inline">\(\lambda\)</span>가 취할 수 있는 값은 0 아니면 1. 확인할 수 있듯이 1이면 slab part, 즉 significant하고, 0이면 역으로 not significant. 우리는 이에 MCMC 알고리즘을 적용하게 되며, 따라서 MCMC 샘플로 계산을 하면 해당 샘플에서 0인 propotion과 1인 비율이 나오게 될 것. 이때 1인 비율이 0.5 이상이면? 해당 component (변수) 는 significant 하다고 결론짓는 것이 가능하다.</p>
<p>$$
<span class="math display">\[\begin{alignat}{3}

\pi(\beta, \lambda, \sigma^2, \omega \vert y, x) &amp;\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) &amp;&amp; f(y \vert x, \beta, \lambda, \sigma^2, \omega) \\
&amp;\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) &amp;&amp;L( x, \beta, \lambda, \sigma^2, \omega \vert y) \\

\\

\pi(\lambda) &amp;\sim BETA(1,1), \; \; \; \pi(\sigma^2) \sim \cdot \tag{1}, \; \; \; \omega \sim 1 + GAM(\alpha, \beta)

\end{alignat}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li>이때 <span class="math inline">\(\sigma^2\)</span>는 우리가 임의로 fixed 해서 given으로 잡거나, 위처럼 prior로 해서 시뮬레이션 중에 생산되도록 할수도 있다. 여기선 <span class="math inline">\(\dfrac{1}{U(4,100)}\)</span>을 사용.</li>
</ol>
<p>accept를 하기 위해선 위를 돌리면 됨. 이는 <strong>Stochastic Search Variable Selection (SSVS)</strong>라고 불림. 이는 GS를 통하여 패러미터를 sequentially update. 이의 결과값은 다음과 같으며, 프로세스는 그 다음과 같다.</p>
<p><span class="math display">\[
(\beta_1 , \cdots, \beta_p, \lambda_1, \cdots, \lambda_p, \sigma^2, \omega)
\]</span></p>
<ul>
<li>Proceeds:
<ol style="list-style-type: decimal">
<li>update model parameter <span class="math inline">\(\beta_i^{(t+1)} \sim \pi( \beta_{i} \vert y, x, \beta_{-i}^{(t)}, \lambda_{i}^{(t)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>
<ul>
<li>where <span class="math inline">\(\beta_{-i}^{(t)} = \left( \beta_{1}^{(t+1)}, \cdots, \beta_{i-1}^{(t+1)}, \beta_{i+1}^{(t)}, \cdots, \beta_{p}^{(t)} \right)\)</span></li>
<li><strong>Simple GS로도 가능하고, MH-within-Gibbs로도 가능함</strong></li>
</ul></li>
<li>update <span class="math inline">\(\lambda_I^{(t+1)} \sim \pi(\lambda_i \vert y, x, \lambda_{-i}^{(t)}, \beta_{i}^{(t+1)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>
<ul>
<li>where <br> $P( <em>{i}^{(t+1)} = 1 y, x, </em>{-i}^{(t)}, _{i}^{(t+1)}, {<sup>2}</sup>{(t)}, ^{(t)} )= {a+b} BER( {a+b} ) $.
<ul>
<li><span class="math inline">\(a = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=1, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>.</li>
<li><span class="math inline">\(b = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=0, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>,</li>
</ul></li>
</ul></li>
<li>update <span class="math inline">\(\sigma^2\)</span></li>
<li>update <span class="math inline">\(\omega\)</span></li>
</ol></li>
</ul>
<hr />
</div>
<div id="horseshoe-prior-scale-mixture-prior" class="section level4 hasAnchor" number="4.10.5.2">
<h4><span class="header-section-number">4.10.5.2</span> 2. Horseshoe prior (Scale-mixture prior)<a href="else.html#horseshoe-prior-scale-mixture-prior" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>distribution에서 scale이란 Variance</strong>.</p>
<p>위와 동일 케이스 가정. 그 경우</p>
<p>$$
<span class="math display">\[\begin{alignat}{4}

\pi(\beta \vert y, x) \propto f(y \vert x, \beta) \pi(\beta), \; \; \; \; \; &amp;\pi(\beta) &amp;&amp; \sim N(0, \sigma^2) \\
\Longrightarrow &amp;\pi(\beta_i \vert \tau, \lambda_i) &amp;&amp; \sim N(0, \tau^2 \lambda_i^2)

\end{alignat}\]</span>
$$</p>
<ul>
<li>where <span class="math inline">\(pi(\tau^2), \pi(\lambda_i^2) \sim Cauchy^{+}(0,1)\)</span></li>
</ul>
<p>이때 common variance component <span class="math inline">\(\tau\)</span>는 각 component마다 공유하는 1개의 variance component, 그리고 각 component마다 indiviually 고유한 individual parameter variance component <span class="math inline">\(\lambda_i\)</span>를 설정한 것.</p>
<hr />
</div>
</div>
<div id="autologistic-model" class="section level3 hasAnchor" number="4.10.6">
<h3><span class="header-section-number">4.10.6</span> Autologistic model<a href="else.html#autologistic-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="99-2.png">
<img src="99-3.png">
<img src="99-4.png"></p>
<hr />
</div>
<div id="wk10-bayesian-model-averaging" class="section level3 hasAnchor" number="4.10.7">
<h3><span class="header-section-number">4.10.7</span> wk10) Bayesian Model Averaging<a href="else.html#wk10-bayesian-model-averaging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>해당 상황에서 연구자는 다양한 모델 예측 후보를 생각해볼 수 있음. 보통은 프로세스를 거쳐 이 모델들 중의 하나를 선택하게 됨. 하지만 완벽한 모델이라는 건 (보통) 존재할 수 없음, 어떤 모델 후보를 선택하든 해당 후보가 내포하고 있는 uncertainty가 존재하며 이를 수용하게 됨. 따라서 모델을 선택한다는 것은 동시에 over-confidence inference 문제를 발생시킨다. 따라서 모델 후보군을 하나만 골라야 한다는 고정관념을 벗어나 다양한 모델 후보군들 각각을 동시에 반영하자. 이 동시 반영할 때 각 모델이 내포하고 있는 확률 (uncertainty)에 의해 각 모델의 반영 정도를 가감하게 된다.</p>
<p>BMA는 패러미터 estimate를 획득할 때, 이러한 model uncertainty를 설명하기 위한 일관된 메커니즘을 제공한다.</p>
<p>given 데이터 <span class="math inline">\(D\)</span>, posterior prob of <span class="math inline">\(\mathcal{M}_k\)</span> <span class="math inline">\(= P(\mathcal{M}_k \vert D) = \dfrac{L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}{\sum_{k=1}^k L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}\)</span>.</p>
<p>이때 marginal likelihood under <span class="math inline">\(\mathcal{M}_k)\)</span> <span class="math inline">\(L(D \vert \mathcal{M}_k) = \int L(D \vert \theta \mathcal{M}_k) \pi(\theta \vert \mathcal{M}_k) d \theta\)</span>이며, integral 안의 수식은 posterior of model의 상수배</p>
<p>In brief, BMA는 model uncertainty를 설명할 수 있는 posterior density를 획득하기 위해 integral을 취한다 (model에 대해 마지널化). (각각의 모델에 대한 model uncertainty를 구한다)</p>
<p>이를 통해 최종적으로 posterior sample 같은 경우에는 각 모델 별로 model probability에 posterior sample의 probability를 다 더해준 값이 실제로 우리의 <span class="math inline">\(\theta\)</span>에 대한 post가 된다.</p>
<p>즉슨 BMA란 다양한 모델 후보군들이 존재할 때, 그 어떤 상황에서도 robust inference를 가능케 하는 tool이 바로 BMA.</p>
<hr />
<div id="ex-bma-crm" class="section level4 hasAnchor" number="4.10.7.1">
<h4><span class="header-section-number">4.10.7.1</span> Ex: BMA-CRM<a href="else.html#ex-bma-crm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>CRM 시작 전에 skeleton 정하고 시작하는 건 자명. 근데 이 skeleton이 잘못 선정되었다면 제대로된 도즈 selection이 불가능해지므로 skeleton의 선정이 잘못되어 있다면 이는 치명적임. 상식적으로, 하나의 skeleton으로만 도즈 셀렉션을 진행한다면 문제가 생길 확률은 당연히 높음. 이런 리스크를 희석하기 위해 skeleton을 다수를 정하고 CRM을 시작하면 이런 문제를 다소 회피할 수 있지 않을까? 이때 이 각각의 스켈레톤 하나하나를 모델로 인식한다. 이 각각의 모델에 따라서 CRM을, 즉 도즈레벨을 업데이트할 확률을, 즉 업데이트 할 때 패러미터 evaluation을 하는데, 그때 나오는 패러미터 값과 그 각각의 모델 probability를 비교하여 그 모델 averaging을 해주면 그 어떤 상황이 와도 굉장히 robust 한 값을 획득할 수 있을 것.</p>
<hr />
<ol style="list-style-type: decimal">
<li><p>Main research question</p></li>
<li><p>Justification for your research question (why is it important to answer the question?)</p></li>
<li><p>Data source</p></li>
<li><p>Data analysis</p></li>
<li><p>Summary of the data analysis results and conclusion</p></li>
<li><p>Appendix (if needed)
– R scripts (scripts or codes for any other software)</p></li>
</ol>
<p>1
– Technical details regarding the statistical tools used in the analysis</p>
<p>비교적 오랜 기간 데이터가 잘 정립된 MLB 기록 활용을 위해
수업 시 활용하였던 Lahman package(R) 사용</p>
<p>야구는 공격과 수비로 이루어지며, 따라서 분석을 진행함에 있어</p>
<p>야구는</p>
<p>야구 스탯들 간에 상당한 수준의 선형성이 보장되어 이</p>
<p>타자의 가치 = α∗Batting+β∗Fielding, α,β는 임의의 패러미터</p>
<p>선수의 타격능력은 이른바 클래식 스탯으로 불리는 다양한 구형 통계량으로도 표기하는데 문제가 없지만, 수비능력은 선수별로 할당된 수비범위가 천차만별이며 선수가 수비시도를 하지 않으면 선수의 실책으로 이어지지 않는다는 점 때문에 선수 개별의 수비능력이 객관적으로 평가되기 시작한 것은 구장의 정보를 훨씬 자세하게 담을 수 있게 된 2000년대 중반부 이후부터의 이야기.</p>
<p>최신야구에서 선수 수비능력의 평가는 주로 Ultimate Zone Rating (UZR) 로 이루어지며, 해당 스탯은 ARM (달린거리), DPR (병살), RngR (수비커버리지), ErrR (에러빈도) 등 수비에 관련된 스탯을 총집합하여 망라하는 고밀도 스탯이다. 그러나 해당 스탯의 계산은 2002년 BIS (Baseball Info Solutions)라는 회사에서 제공하는 유료 데이터셋과 15년 도입된 스탯캐스트 데이터에 거의 전적으로 의존하고 있다. 스탯캐스트 데이터는 민간에 어느정도는 공개되어 있어 접근이 불가능하지 않지만 (<a href="https://baseballsavant.mlb.com/statcast_leaderboard" class="uri">https://baseballsavant.mlb.com/statcast_leaderboard</a>), BIS 데이터는 접근이 어렵다.</p>
<p>이와 같은 이유로 선수별 수비 스탯을 구하기를 시도하기보단 팀별 수비력에 대한 척도인 Defensive Efficiency Ratio (DER)를 사용하고자 한다. 최대 12개의 팀인만큼 팀 간의 차이를 포착하기 쉬우며, 12개의 팀으로 표준화되니만큼 아웃라이어들이 평준화되어 전반적인 경향성으로 기능하는 것을 기대해볼 수 있다. DER의 수식은 다음과 같다.</p>
<p>DER의 계산법은 이하와 같다.</p>
<p>DER=1−(Hits+Reached.On.Error−HomeRunsPlate.Appearance−BB(Walks)−Strike.Out−Hit.By.Pitch−HomeRuns)</p>
<p>Teams %&gt;%
mutate(., DER = 1-((H + E - HR)/((AB + SF) - SO - HR))) %&gt;%
##select(., yearID, teamID, Rank, SO, SOA)
select(.,yearID, teamID, franchID, Rank, G,DER) -&gt; Teams_DER</p>
<p>물론 같은 팀에 속했다는 이유만으로 모든 선수들에게 동급의 수비스탯을 배정하는 건 합리적이라고 말하기 어렵다. 팀의 수비에 기여하는 정도가 높은 선수가 있다면 낮은 선수도 있을 것이 자명하기 때문이다. 따라서 팀별로 획득한 DER을 수비에 대한 클래식 스탯인 각 선수의 Fielding Percentage(FPCT) 나 Range Factor(RF)의 비율로 스케일링해서 부여하자. 두 스탯은 각각 수비능력과 개인의 수비범위 평가를 위해 시도되었던 스탯들이지만, 전자는 개인의 수비범위가 좁으면 더 좋은 값이 나온다는 한계, 후자는 공이 본인 위치로 떨어졌을 때 스탯계산에서 이득을 본다는 한계를 넘지 못해 좋은 스탯으로는 평가받지 못했던 값들이다. 그러나 팀 단위로 한번 수비력을 표준화한 후 팀 내에서 상대적인 기여도를 보는 식으로 보정이 한 번 들어갔으므로 어느정도 기준선으로서는 기능할 것이라고 기대된다.</p>
<p>이를 위해 선수생활 중의 메인 수비포지션 지정하고 해당 포지션에서의 통계량만 사용.</p>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="review.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mva.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/211299_Else.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
