<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.8 Latent Network Models | Self-Study</title>
  <meta name="description" content="7.8 Latent Network Models | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.8 Latent Network Models | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.8 Latent Network Models | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ergm-for-dynamic-networks.html"/>
<link rel="next" href="additive-and-multiplicative-effects-network-models.html"/>
<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li><a href="index.html#intro">Intro<span></span></a></li>
<li class="part"><span><b>I 20-02<span></span></b></span></li>
<li class="chapter" data-level="1" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>1</b> Categorical<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview<span></span></a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="overview.html"><a href="overview.html#data-type-and-statistical-analysis"><i class="fa fa-check"></i><b>1.1.1</b> Data Type and Statistical Analysis<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>2.1</b> Abstract<span></span></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="abstract.html"><a href="abstract.html#변수의-독립성"><i class="fa fa-check"></i><b>2.1.1</b> 변수의 독립성<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="abstract.html"><a href="abstract.html#교환가능성"><i class="fa fa-check"></i><b>2.1.2</b> 교환가능성<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continual-aeassessment-method.html"><a href="continual-aeassessment-method.html"><i class="fa fa-check"></i><b>2.2</b> Continual Aeassessment Method<span></span></a></li>
<li class="chapter" data-level="2.3" data-path="horseshoe-prior.html"><a href="horseshoe-prior.html"><i class="fa fa-check"></i><b>2.3</b> Horseshoe Prior<span></span></a></li>
</ul></li>
<li class="part"><span><b>II 21-01<span></span></b></span></li>
<li class="chapter" data-level="3" data-path="mathematical-stats.html"><a href="mathematical-stats.html"><i class="fa fa-check"></i><b>3</b> Mathematical Stats<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>3.1</b> Inference<span></span></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference.html"><a href="inference.html#rao-blackwell-thm."><i class="fa fa-check"></i><b>3.1.1</b> Rao-Blackwell thm.<span></span></a></li>
<li class="chapter" data-level="3.1.2" data-path="inference.html"><a href="inference.html#completeness"><i class="fa fa-check"></i><b>3.1.2</b> Completeness<span></span></a></li>
<li class="chapter" data-level="3.1.3" data-path="inference.html"><a href="inference.html#레만-쉐페-thm."><i class="fa fa-check"></i><b>3.1.3</b> 레만-쉐페 thm.<span></span></a></li>
<li class="chapter" data-level="3.1.4" data-path="inference.html"><a href="inference.html#raoblack"><i class="fa fa-check"></i><b>3.1.4</b> Rao-Blackwell thm.<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>3.2</b> Hypothesis Test<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="power-fucntion.html"><a href="power-fucntion.html"><i class="fa fa-check"></i><b>3.3</b> Power Fucntion<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="power-fucntion.html"><a href="power-fucntion.html#significance-probability-p-value"><i class="fa fa-check"></i><b>3.3.1</b> Significance Probability (p-value)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="optimal-testing-method.html"><a href="optimal-testing-method.html"><i class="fa fa-check"></i><b>3.4</b> Optimal Testing Method<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>3.5</b> Data Reduction<span></span></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="data-reduction.html"><a href="data-reduction.html#sufficiency-principle"><i class="fa fa-check"></i><b>3.5.1</b> Sufficiency Principle<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="borel-paradox.html"><a href="borel-paradox.html"><i class="fa fa-check"></i><b>3.6</b> Borel Paradox<span></span></a></li>
<li class="chapter" data-level="3.7" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html"><i class="fa fa-check"></i><b>3.7</b> Neyman–Pearson lemma<span></span></a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#overview-1"><i class="fa fa-check"></i><b>3.7.1</b> Overview<span></span></a></li>
<li class="chapter" data-level="3.7.2" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#generalized-lrt"><i class="fa fa-check"></i><b>3.7.2</b> Generalized LRT<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="개념.html"><a href="개념.html"><i class="fa fa-check"></i><b>3.8</b> 개념<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>4</b> MCMC<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>4.1</b> Importance Sampling<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="importance-sampling.html"><a href="importance-sampling.html#independent-monte-carlo"><i class="fa fa-check"></i><b>4.1.1</b> Independent Monte Carlo<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.2</b> Markov Chain Monte Carlo<span></span></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mh-algorithm"><i class="fa fa-check"></i><b>4.2.1</b> MH Algorithm<span></span></a></li>
<li class="chapter" data-level="4.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used"><i class="fa fa-check"></i><b>4.2.2</b> Random Walk Chains (Most Widely Used)<span></span></a></li>
<li class="chapter" data-level="4.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler"><i class="fa fa-check"></i><b>4.2.3</b> Basic Gibbs Sampler<span></span></a></li>
<li class="chapter" data-level="4.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#implementation"><i class="fa fa-check"></i><b>4.2.4</b> Implementation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html"><i class="fa fa-check"></i><b>4.3</b> Advanced MCMC (wk08)<span></span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#data-augmentation"><i class="fa fa-check"></i><b>4.3.1</b> Data Augmentation<span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm"><i class="fa fa-check"></i><b>4.3.2</b> Hit-and-Run Algorithm<span></span></a></li>
<li class="chapter" data-level="4.3.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm"><i class="fa fa-check"></i><b>4.3.3</b> Metropolis-Adjusted Langevin Algorithm<span></span></a></li>
<li class="chapter" data-level="4.3.4" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm"><i class="fa fa-check"></i><b>4.3.4</b> Multiple-Try Metropolis Algorithm<span></span></a></li>
<li class="chapter" data-level="4.3.5" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm"><i class="fa fa-check"></i><b>4.3.5</b> Reversible Jump MCMC Algorithm<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html"><i class="fa fa-check"></i><b>4.4</b> Auxiliary Variable MCMC<span></span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#introduction"><i class="fa fa-check"></i><b>4.4.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="4.4.2" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution"><i class="fa fa-check"></i><b>4.4.2</b> Multimodal Target Distribution<span></span></a></li>
<li class="chapter" data-level="4.4.3" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants"><i class="fa fa-check"></i><b>4.4.3</b> Doubly-intractable Normalizing Constants<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html"><i class="fa fa-check"></i><b>4.5</b> Approximate Bayesian Computation<span></span></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#simulator-based-models"><i class="fa fa-check"></i><b>4.5.1</b> Simulator-Based Models<span></span></a></li>
<li class="chapter" data-level="4.5.2" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods"><i class="fa fa-check"></i><b>4.5.2</b> ABCifying Monte Carlo Methods<span></span></a></li>
<li class="chapter" data-level="4.5.3" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm"><i class="fa fa-check"></i><b>4.5.3</b> ABC-MCMC Algorithm<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Hamiltonian Monte Carlo<span></span></a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>4.6.1</b> Introduction to Hamiltonian Monte Carlo<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html"><i class="fa fa-check"></i><b>4.7</b> Population Monte Carlo<span></span></a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#adaptive-direction-sampling"><i class="fa fa-check"></i><b>4.7.1</b> Adaptive Direction Sampling<span></span></a></li>
<li class="chapter" data-level="4.7.2" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#conjugate-gradient-mc"><i class="fa fa-check"></i><b>4.7.2</b> Conjugate Gradient MC<span></span></a></li>
<li class="chapter" data-level="4.7.3" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#parallel-tempering"><i class="fa fa-check"></i><b>4.7.3</b> Parallel Tempering<span></span></a></li>
<li class="chapter" data-level="4.7.4" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#evolutionary-mc"><i class="fa fa-check"></i><b>4.7.4</b> Evolutionary MC<span></span></a></li>
<li class="chapter" data-level="4.7.5" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#sequential-parallel-tempering"><i class="fa fa-check"></i><b>4.7.5</b> Sequential Parallel Tempering<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="stochastic-approximation-monte-carlo.html"><a href="stochastic-approximation-monte-carlo.html"><i class="fa fa-check"></i><b>4.8</b> Stochastic Approximation Monte Carlo<span></span></a></li>
<li class="chapter" data-level="4.9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>4.9</b> Review<span></span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="review.html"><a href="review.html#wk01"><i class="fa fa-check"></i><b>4.9.1</b> Wk01<span></span></a></li>
<li class="chapter" data-level="4.9.2" data-path="review.html"><a href="review.html#wk03"><i class="fa fa-check"></i><b>4.9.2</b> wk03<span></span></a></li>
<li class="chapter" data-level="4.9.3" data-path="review.html"><a href="review.html#wk04-05"><i class="fa fa-check"></i><b>4.9.3</b> wk04, 05<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="else.html"><a href="else.html"><i class="fa fa-check"></i><b>4.10</b> Else<span></span></a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="else.html"><a href="else.html#hw4.-rasch-model"><i class="fa fa-check"></i><b>4.10.1</b> Hw4. Rasch Model<span></span></a></li>
<li class="chapter" data-level="4.10.2" data-path="else.html"><a href="else.html#da-example-mvn"><i class="fa fa-check"></i><b>4.10.2</b> DA) Example: MVN<span></span></a></li>
<li class="chapter" data-level="4.10.3" data-path="else.html"><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><i class="fa fa-check"></i><b>4.10.3</b> Bayesian adaptive clinical trial with delayed outcomes<span></span></a></li>
<li class="chapter" data-level="4.10.4" data-path="else.html"><a href="else.html#nmar의-종류"><i class="fa fa-check"></i><b>4.10.4</b> NMAR의 종류<span></span></a></li>
<li class="chapter" data-level="4.10.5" data-path="else.html"><a href="else.html#wk10-bayesian-model-selection"><i class="fa fa-check"></i><b>4.10.5</b> wk10) Bayesian Model Selection<span></span></a></li>
<li class="chapter" data-level="4.10.6" data-path="else.html"><a href="else.html#autologistic-model"><i class="fa fa-check"></i><b>4.10.6</b> Autologistic model<span></span></a></li>
<li class="chapter" data-level="4.10.7" data-path="else.html"><a href="else.html#wk10-bayesian-model-averaging"><i class="fa fa-check"></i><b>4.10.7</b> wk10) Bayesian Model Averaging<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mva.html"><a href="mva.html"><i class="fa fa-check"></i><b>5</b> MVA<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html"><i class="fa fa-check"></i><b>5.1</b> Overview of mva (not ended)<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#notation"><i class="fa fa-check"></i><b>5.1.1</b> Notation<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#summary-statistics"><i class="fa fa-check"></i><b>5.1.2</b> Summary Statistics<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation"><i class="fa fa-check"></i><b>5.1.3</b> Statistical Inference on Correlation<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#standardization"><i class="fa fa-check"></i><b>5.1.4</b> Standardization<span></span></a></li>
<li class="chapter" data-level="5.1.5" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#missing-value-treatment"><i class="fa fa-check"></i><b>5.1.5</b> Missing Value Treatment<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html"><i class="fa fa-check"></i><b>5.2</b> Multivariate Nomral (wk2)<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#overview-2"><i class="fa fa-check"></i><b>5.2.1</b> Overview<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#spectral-decomposition"><i class="fa fa-check"></i><b>5.2.2</b> Spectral Decomposition<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#properties-of-mvn"><i class="fa fa-check"></i><b>5.2.3</b> Properties of MVN<span></span></a></li>
<li class="chapter" data-level="5.2.4" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#chi2-distribution"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\Chi^2\)</span> distribution<span></span></a></li>
<li class="chapter" data-level="5.2.5" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors"><i class="fa fa-check"></i><b>5.2.5</b> Linear Combination of Random Vectors<span></span></a></li>
<li class="chapter" data-level="5.2.6" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood"><i class="fa fa-check"></i><b>5.2.6</b> Multivariate Normal Likelihood<span></span></a></li>
<li class="chapter" data-level="5.2.7" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s"><i class="fa fa-check"></i><b>5.2.7</b> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span><span></span></a></li>
<li class="chapter" data-level="5.2.8" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#assessing-normality"><i class="fa fa-check"></i><b>5.2.8</b> Assessing Normality<span></span></a></li>
<li class="chapter" data-level="5.2.9" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#power-transformation"><i class="fa fa-check"></i><b>5.2.9</b> Power Transformation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html"><i class="fa fa-check"></i><b>5.3</b> Inference about Mean Vector (wk3)<span></span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#overview-3"><i class="fa fa-check"></i><b>5.3.1</b> Overview<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#confidence-region"><i class="fa fa-check"></i><b>5.3.2</b> 1. Confidence Region<span></span></a></li>
<li class="chapter" data-level="5.3.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#simultaneous-ci"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simultaneous CI<span></span></a></li>
<li class="chapter" data-level="5.3.4" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison"><i class="fa fa-check"></i><b>5.3.4</b> 3. Note: Bonferroni Multiple Comparison<span></span></a></li>
<li class="chapter" data-level="5.3.5" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector"><i class="fa fa-check"></i><b>5.3.5</b> 4. Large Sample Inferences about a Mean Vector<span></span></a></li>
<li class="chapter" data-level="5.3.6" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5"><i class="fa fa-check"></i><b>5.3.6</b> 1. Profile Analysis (wk4, 5)<span></span></a></li>
<li class="chapter" data-level="5.3.7" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend"><i class="fa fa-check"></i><b>5.3.7</b> 2. Test for Linear Trend<span></span></a></li>
<li class="chapter" data-level="5.3.8" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix"><i class="fa fa-check"></i><b>5.3.8</b> 3. Inferences about a Covariance Matrix<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of Several MV Means (wk5)<span></span></a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#paired-comparison"><i class="fa fa-check"></i><b>5.4.1</b> Paired Comparison<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations"><i class="fa fa-check"></i><b>5.4.2</b> Comparing Mean Vectors from Two Populations<span></span></a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2"><i class="fa fa-check"></i><b>5.4.3</b> Profile Analysis (for <span class="math inline">\(g=2\)</span>)<span></span></a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means"><i class="fa fa-check"></i><b>5.4.4</b> Comparing Several Multivariate Population Means<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html"><i class="fa fa-check"></i><b>5.5</b> Multivariate Multiple Regression (wk6)<span></span></a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#overview-4"><i class="fa fa-check"></i><b>5.5.1</b> Overview<span></span></a></li>
<li class="chapter" data-level="5.5.2" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression"><i class="fa fa-check"></i><b>5.5.2</b> Multivariate Multiple Regression<span></span></a></li>
<li class="chapter" data-level="5.5.3" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#example"><i class="fa fa-check"></i><b>5.5.3</b> Example)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>5.6</b> PCA<span></span></a></li>
<li class="chapter" data-level="5.7" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>5.7</b> Factor<span></span></a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="factor.html"><a href="factor.html#method-of-estimation"><i class="fa fa-check"></i><b>5.7.1</b> Method of Estimation<span></span></a></li>
<li class="chapter" data-level="5.7.2" data-path="factor.html"><a href="factor.html#factor-rotation"><i class="fa fa-check"></i><b>5.7.2</b> Factor Rotation<span></span></a></li>
<li class="chapter" data-level="5.7.3" data-path="factor.html"><a href="factor.html#varimax-criterion"><i class="fa fa-check"></i><b>5.7.3</b> Varimax Criterion<span></span></a></li>
<li class="chapter" data-level="5.7.4" data-path="factor.html"><a href="factor.html#factor-scores"><i class="fa fa-check"></i><b>5.7.4</b> Factor Scores<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html"><i class="fa fa-check"></i><b>5.8</b> Discrimination and Classification<span></span></a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#bayes-rule"><i class="fa fa-check"></i><b>5.8.1</b> Bayes Rule<span></span></a></li>
<li class="chapter" data-level="5.8.2" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations"><i class="fa fa-check"></i><b>5.8.2</b> Classification with Two mv <span class="math inline">\(N\)</span> Populations<span></span></a></li>
<li class="chapter" data-level="5.8.3" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#evaluating-classification-functions"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating Classification Functions<span></span></a></li>
<li class="chapter" data-level="5.8.4" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-several-populations-wk13"><i class="fa fa-check"></i><b>5.8.4</b> Classification with several Populations (wk13)<span></span></a></li>
<li class="chapter" data-level="5.8.5" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#other-discriminant-analysis-methods"><i class="fa fa-check"></i><b>5.8.5</b> Other Discriminant Analysis Methods<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html"><i class="fa fa-check"></i><b>5.9</b> Clustering, Distance Methods, and Ordination<span></span></a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#overview-5"><i class="fa fa-check"></i><b>5.9.1</b> Overview<span></span></a></li>
<li class="chapter" data-level="5.9.2" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering"><i class="fa fa-check"></i><b>5.9.2</b> Hierarchical Clustering<span></span></a></li>
<li class="chapter" data-level="5.9.3" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#k-means-clustering"><i class="fa fa-check"></i><b>5.9.3</b> K-means Clustering<span></span></a></li>
<li class="chapter" data-level="5.9.4" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법"><i class="fa fa-check"></i><b>5.9.4</b> 군집의 평가방법<span></span></a></li>
<li class="chapter" data-level="5.9.5" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14"><i class="fa fa-check"></i><b>5.9.5</b> Clustering using Density Estimation (wk14)<span></span></a></li>
<li class="chapter" data-level="5.9.6" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>5.9.6</b> Multidimensional Scaling (MDS)<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>6</b> Linear<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>6.1</b> SVD<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="svd.html"><a href="svd.html#spectral-decomposition-1"><i class="fa fa-check"></i><b>6.1.1</b> Spectral Decomposition<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="svd.html"><a href="svd.html#singular-value-decomposition-general-version"><i class="fa fa-check"></i><b>6.1.2</b> Singular value Decomposition: General-version<span></span></a></li>
<li class="chapter" data-level="6.1.3" data-path="svd.html"><a href="svd.html#singular-value-decomposition-another-version"><i class="fa fa-check"></i><b>6.1.3</b> Singular value Decomposition: Another-version<span></span></a></li>
<li class="chapter" data-level="6.1.4" data-path="svd.html"><a href="svd.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1.4</b> Quadratic Forms<span></span></a></li>
<li class="chapter" data-level="6.1.5" data-path="svd.html"><a href="svd.html#partitioned-matrices"><i class="fa fa-check"></i><b>6.1.5</b> Partitioned Matrices<span></span></a></li>
<li class="chapter" data-level="6.1.6" data-path="svd.html"><a href="svd.html#geometrical-aspects"><i class="fa fa-check"></i><b>6.1.6</b> Geometrical Aspects<span></span></a></li>
<li class="chapter" data-level="6.1.7" data-path="svd.html"><a href="svd.html#column-row-and-null-space"><i class="fa fa-check"></i><b>6.1.7</b> Column, Row and Null Space<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>6.2</b> Introduction<span></span></a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-1.html"><a href="introduction-1.html#what"><i class="fa fa-check"></i><b>6.2.1</b> What<span></span></a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-1.html"><a href="introduction-1.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.2.2</b> Random Vectors and Matrices<span></span></a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-1.html"><a href="introduction-1.html#multivariate-normal-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Multivariate Normal Distributions<span></span></a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-1.html"><a href="introduction-1.html#distributions-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2.4</b> Distributions of Quadratic Forms<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>6.3</b> Estimation<span></span></a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation.html"><a href="estimation.html#identifiability-and-estimability"><i class="fa fa-check"></i><b>6.3.1</b> Identifiability and Estimability<span></span></a></li>
<li class="chapter" data-level="6.3.2" data-path="estimation.html"><a href="estimation.html#estimation-least-squares"><i class="fa fa-check"></i><b>6.3.2</b> Estimation: Least Squares<span></span></a></li>
<li class="chapter" data-level="6.3.3" data-path="estimation.html"><a href="estimation.html#estimation-best-linear-unbiased"><i class="fa fa-check"></i><b>6.3.3</b> Estimation: Best Linear Unbiased<span></span></a></li>
<li class="chapter" data-level="6.3.4" data-path="estimation.html"><a href="estimation.html#estimation-maximum-likelihood"><i class="fa fa-check"></i><b>6.3.4</b> Estimation: Maximum Likelihood<span></span></a></li>
<li class="chapter" data-level="6.3.5" data-path="estimation.html"><a href="estimation.html#estimation-minimum-variance-unbiased"><i class="fa fa-check"></i><b>6.3.5</b> Estimation: Minimum Variance Unbiased<span></span></a></li>
<li class="chapter" data-level="6.3.6" data-path="estimation.html"><a href="estimation.html#sampling-distributions-of-estimates"><i class="fa fa-check"></i><b>6.3.6</b> Sampling Distributions of Estimates<span></span></a></li>
<li class="chapter" data-level="6.3.7" data-path="estimation.html"><a href="estimation.html#generalized-least-squaresgls"><i class="fa fa-check"></i><b>6.3.7</b> Generalized Least Squares(GLS)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>6.4</b> One-Way ANOVA<span></span></a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way-anova.html"><a href="one-way-anova.html#one-way-anova-1"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA<span></span></a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way-anova.html"><a href="one-way-anova.html#more-about-models"><i class="fa fa-check"></i><b>6.4.2</b> More About Models<span></span></a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way-anova.html"><a href="one-way-anova.html#estimating-and-testing-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating and Testing Contrasts<span></span></a></li>
<li class="chapter" data-level="6.4.4" data-path="one-way-anova.html"><a href="one-way-anova.html#cochrans-theorem"><i class="fa fa-check"></i><b>6.4.4</b> Cochran’s Theorem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>6.5</b> Testing<span></span></a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="testing.html"><a href="testing.html#more-about-models-two-approaches-for-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> More About Models: Two approaches for linear model<span></span></a></li>
<li class="chapter" data-level="6.5.2" data-path="testing.html"><a href="testing.html#testing-models"><i class="fa fa-check"></i><b>6.5.2</b> Testing Models<span></span></a></li>
<li class="chapter" data-level="6.5.3" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure"><i class="fa fa-check"></i><b>6.5.3</b> A Generalized Test Procedure<span></span></a></li>
<li class="chapter" data-level="6.5.4" data-path="testing.html"><a href="testing.html#testing-linear-parametric-functions"><i class="fa fa-check"></i><b>6.5.4</b> Testing Linear Parametric Functions<span></span></a></li>
<li class="chapter" data-level="6.5.5" data-path="testing.html"><a href="testing.html#theoretical-complements"><i class="fa fa-check"></i><b>6.5.5</b> Theoretical Complements<span></span></a></li>
<li class="chapter" data-level="6.5.6" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure-1"><i class="fa fa-check"></i><b>6.5.6</b> A Generalized Test Procedure<span></span></a></li>
<li class="chapter" data-level="6.5.7" data-path="testing.html"><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace"><i class="fa fa-check"></i><b>6.5.7</b> Testing Single Degrees of Freedom in a Given Subspace<span></span></a></li>
<li class="chapter" data-level="6.5.8" data-path="testing.html"><a href="testing.html#breaking-ss-into-independent-components"><i class="fa fa-check"></i><b>6.5.8</b> Breaking SS into Independent Components<span></span></a></li>
<li class="chapter" data-level="6.5.9" data-path="testing.html"><a href="testing.html#general-theory"><i class="fa fa-check"></i><b>6.5.9</b> General Theory<span></span></a></li>
<li class="chapter" data-level="6.5.10" data-path="testing.html"><a href="testing.html#two-way-anova"><i class="fa fa-check"></i><b>6.5.10</b> Two-Way ANOVA<span></span></a></li>
<li class="chapter" data-level="6.5.11" data-path="testing.html"><a href="testing.html#confidence-regions"><i class="fa fa-check"></i><b>6.5.11</b> Confidence Regions<span></span></a></li>
<li class="chapter" data-level="6.5.12" data-path="testing.html"><a href="testing.html#tests-for-generalized-least-squares-models"><i class="fa fa-check"></i><b>6.5.12</b> Tests for Generalized Least Squares Models<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>6.6</b> Generalized Least Squares<span></span></a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#a-direct-solution-via-inner-products"><i class="fa fa-check"></i><b>6.6.1</b> A direct solution via inner products<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="flat.html"><a href="flat.html"><i class="fa fa-check"></i><b>6.7</b> Flat<span></span></a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="flat.html"><a href="flat.html#flat-1"><i class="fa fa-check"></i><b>6.7.1</b> 1.Flat<span></span></a></li>
<li class="chapter" data-level="6.7.2" data-path="flat.html"><a href="flat.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>6.7.2</b> 2. Solutions to systems of linear equations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="unified-approach-to-balanced-anova-models.html"><a href="unified-approach-to-balanced-anova-models.html"><i class="fa fa-check"></i><b>6.8</b> Unified Approach to Balanced ANOVA Models<span></span></a></li>
</ul></li>
<li class="part"><span><b>III 21-02<span></span></b></span></li>
<li class="chapter" data-level="7" data-path="network-stats.html"><a href="network-stats.html"><i class="fa fa-check"></i><b>7</b> Network Stats<span></span></a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>7.1</b> Introduction<span></span></a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-2.html"><a href="introduction-2.html#types-of-network-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Types of Network Analysis<span></span></a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-2.html"><a href="introduction-2.html#network-modeling-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Network Modeling and Inference<span></span></a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-2.html"><a href="introduction-2.html#network-processes"><i class="fa fa-check"></i><b>7.1.3</b> Network Processes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html"><i class="fa fa-check"></i><b>7.2</b> Descriptive Statistics of Networks<span></span></a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics"><i class="fa fa-check"></i><b>7.2.1</b> Vertex and Edge Characteristics<span></span></a></li>
<li class="chapter" data-level="7.2.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion"><i class="fa fa-check"></i><b>7.2.2</b> Characterizing Network Cohesion<span></span></a></li>
<li class="chapter" data-level="7.2.3" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#graph-partitioning"><i class="fa fa-check"></i><b>7.2.3</b> Graph Partitioning<span></span></a></li>
<li class="chapter" data-level="7.2.4" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing"><i class="fa fa-check"></i><b>7.2.4</b> Assortativity and Mixing<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html"><i class="fa fa-check"></i><b>7.3</b> Data Collection and Sampling<span></span></a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#sampling-designs"><i class="fa fa-check"></i><b>7.3.1</b> Sampling Designs<span></span></a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#coping-strategies"><i class="fa fa-check"></i><b>7.3.2</b> Coping Strategies<span></span></a></li>
<li class="chapter" data-level="7.3.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#big-data-solves-nothing"><i class="fa fa-check"></i><b>7.3.3</b> Big Data Solves Nothing<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html"><i class="fa fa-check"></i><b>7.4</b> Mathematical Models for Network Graphs<span></span></a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models"><i class="fa fa-check"></i><b>7.4.1</b> Classical Random Graph Models<span></span></a></li>
<li class="chapter" data-level="7.4.2" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models"><i class="fa fa-check"></i><b>7.4.2</b> Generalized Random Graph Models<span></span></a></li>
<li class="chapter" data-level="7.4.3" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms"><i class="fa fa-check"></i><b>7.4.3</b> Network Graph Models Based on Mechanisms<span></span></a></li>
<li class="chapter" data-level="7.4.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics"><i class="fa fa-check"></i><b>7.4.4</b> Assessing Significance of Network Graph Characteristics<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html"><i class="fa fa-check"></i><b>7.5</b> Introduction to ERGM<span></span></a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#exponential-random-graph-models"><i class="fa fa-check"></i><b>7.5.1</b> Exponential Random Graph Models<span></span></a></li>
<li class="chapter" data-level="7.5.2" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation"><i class="fa fa-check"></i><b>7.5.2</b> Difficulty in Parameter Estimation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html"><i class="fa fa-check"></i><b>7.6</b> Parameter Estimation of ERGM<span></span></a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm"><i class="fa fa-check"></i><b>7.6.1</b> Current Methods for ERGM<span></span></a></li>
<li class="chapter" data-level="7.6.2" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm"><i class="fa fa-check"></i><b>7.6.2</b> Approximation-based Algorithm<span></span></a></li>
<li class="chapter" data-level="7.6.3" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches"><i class="fa fa-check"></i><b>7.6.3</b> Auxiliary Variable MCMC-based Approaches<span></span></a></li>
<li class="chapter" data-level="7.6.4" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc"><i class="fa fa-check"></i><b>7.6.4</b> Varying Trunction Stochastic Approximation MCMC<span></span></a></li>
<li class="chapter" data-level="7.6.5" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#conclusion"><i class="fa fa-check"></i><b>7.6.5</b> Conclusion<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html"><i class="fa fa-check"></i><b>7.7</b> ERGM for Dynamic Networks<span></span></a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm"><i class="fa fa-check"></i><b>7.7.1</b> Temporal ERGM (TERGM, T ERGM)<span></span></a></li>
<li class="chapter" data-level="7.7.2" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm"><i class="fa fa-check"></i><b>7.7.2</b> Separable Temporal ERGM (STERGM, ST ERGM)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="latent-network-models.html"><a href="latent-network-models.html"><i class="fa fa-check"></i><b>7.8</b> Latent Network Models<span></span></a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-model"><i class="fa fa-check"></i><b>7.8.1</b> Latent Position Model<span></span></a></li>
<li class="chapter" data-level="7.8.2" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-cluster-model"><i class="fa fa-check"></i><b>7.8.2</b> Latent Position Cluster Model<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html"><i class="fa fa-check"></i><b>7.9</b> Additive and Multiplicative Effects Network Models<span></span></a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#introduction-3"><i class="fa fa-check"></i><b>7.9.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="7.9.2" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression"><i class="fa fa-check"></i><b>7.9.2</b> Social Relations Regression<span></span></a></li>
<li class="chapter" data-level="7.9.3" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models"><i class="fa fa-check"></i><b>7.9.3</b> Multiplicative Effects Models<span></span></a></li>
<li class="chapter" data-level="7.9.4" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation"><i class="fa fa-check"></i><b>7.9.4</b> Inference via Posterior Approximation<span></span></a></li>
<li class="chapter" data-level="7.9.5" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r"><i class="fa fa-check"></i><b>7.9.5</b> Discussion and Example with R<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html"><i class="fa fa-check"></i><b>7.10</b> Stochastic Block Models<span></span></a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html#stochastic-block-model"><i class="fa fa-check"></i><b>7.10.1</b> Stochastic Block Model<span></span></a></li>
<li class="chapter" data-level="7.10.2" data-path="stochastic-block-models.html"><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm"><i class="fa fa-check"></i><b>7.10.2</b> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="high-dimension.html"><a href="high-dimension.html"><i class="fa fa-check"></i><b>8</b> High Dimension<span></span></a>
<ul>
<li class="chapter" data-level="8.1" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>8.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html"><i class="fa fa-check"></i><b>8.2</b> Concentration inequalities<span></span></a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation<span></span></a></li>
<li class="chapter" data-level="8.2.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#from-markov-to-chernoff"><i class="fa fa-check"></i><b>8.2.2</b> From Markov to Chernoff<span></span></a></li>
<li class="chapter" data-level="8.2.3" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.3</b> sub-Gaussian random variables<span></span></a></li>
<li class="chapter" data-level="8.2.4" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.4</b> Properties of sub-Gaussian random variables<span></span></a></li>
<li class="chapter" data-level="8.2.5" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#equivalent-definitions"><i class="fa fa-check"></i><b>8.2.5</b> Equivalent definitions<span></span></a></li>
<li class="chapter" data-level="8.2.6" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-vectors"><i class="fa fa-check"></i><b>8.2.6</b> Sub-Gaussian random vectors<span></span></a></li>
<li class="chapter" data-level="8.2.7" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#hoeffdings-inequality"><i class="fa fa-check"></i><b>8.2.7</b> Hoeffding’s inequality<span></span></a></li>
<li class="chapter" data-level="8.2.8" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#maximal-inequalities"><i class="fa fa-check"></i><b>8.2.8</b> Maximal inequalities<span></span></a></li>
<li class="chapter" data-level="8.2.9" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#section"><i class="fa fa-check"></i><b>8.2.9</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html"><i class="fa fa-check"></i><b>8.3</b> Concentration inequalities<span></span></a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#sub-exponential-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Sub-exponential random variables<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#bernsteins-condition"><i class="fa fa-check"></i><b>8.3.2</b> Bernstein’s condition<span></span></a></li>
<li class="chapter" data-level="8.3.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#mcdiarmids-inequality"><i class="fa fa-check"></i><b>8.3.3</b> McDiarmid’s inequality<span></span></a></li>
<li class="chapter" data-level="8.3.4" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#levys-inequality"><i class="fa fa-check"></i><b>8.3.4</b> Levy’s inequality<span></span></a></li>
<li class="chapter" data-level="8.3.5" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#quadratic-form"><i class="fa fa-check"></i><b>8.3.5</b> Quadratic form<span></span></a></li>
<li class="chapter" data-level="8.3.6" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma"><i class="fa fa-check"></i><b>8.3.6</b> The Johnson–Lindenstrauss Lemma<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html"><i class="fa fa-check"></i><b>8.4</b> Metric entropy and its uses<span></span></a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#metric-space"><i class="fa fa-check"></i><b>8.4.1</b> Metric space<span></span></a></li>
<li class="chapter" data-level="8.4.2" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy"><i class="fa fa-check"></i><b>8.4.2</b> Covering numbers and metric entropy<span></span></a></li>
<li class="chapter" data-level="8.4.3" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#packing-numbers"><i class="fa fa-check"></i><b>8.4.3</b> Packing numbers<span></span></a></li>
<li class="chapter" data-level="8.4.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-1"><i class="fa fa-check"></i><b>8.4.4</b> </a></li>
<li class="chapter" data-level="8.4.5" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-2"><i class="fa fa-check"></i><b>8.4.5</b> </a></li>
<li class="chapter" data-level="8.4.6" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-3"><i class="fa fa-check"></i><b>8.4.6</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="covariance-estimation.html"><a href="covariance-estimation.html"><i class="fa fa-check"></i><b>8.5</b> Covariance estimation<span></span></a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="covariance-estimation.html"><a href="covariance-estimation.html#matrix-algebra-review"><i class="fa fa-check"></i><b>8.5.1</b> Matrix algebra review<span></span></a></li>
<li class="chapter" data-level="8.5.2" data-path="covariance-estimation.html"><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm"><i class="fa fa-check"></i><b>8.5.2</b> Covariance matrix estimation in the operator norm<span></span></a></li>
<li class="chapter" data-level="8.5.3" data-path="covariance-estimation.html"><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices"><i class="fa fa-check"></i><b>8.5.3</b> Bounds for structured covariance matrices<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html"><i class="fa fa-check"></i><b>8.6</b> Matrix concentration inequalities<span></span></a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-calculus"><i class="fa fa-check"></i><b>8.6.1</b> Matrix calculus<span></span></a></li>
<li class="chapter" data-level="8.6.2" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-chernoff"><i class="fa fa-check"></i><b>8.6.2</b> Matrix Chernoff<span></span></a></li>
<li class="chapter" data-level="8.6.3" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices"><i class="fa fa-check"></i><b>8.6.3</b> Sub-Gaussian and sub-exponential matrices<span></span></a></li>
<li class="chapter" data-level="8.6.4" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><i class="fa fa-check"></i><b>8.6.4</b> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>8.7</b> Principal Component Analysis<span></span></a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-1"><i class="fa fa-check"></i><b>8.7.1</b> PCA<span></span></a></li>
<li class="chapter" data-level="8.7.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#matrix-perturbation"><i class="fa fa-check"></i><b>8.7.2</b> Matrix Perturbation<span></span></a></li>
<li class="chapter" data-level="8.7.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#spiked-cov-model"><i class="fa fa-check"></i><b>8.7.3</b> Spiked Cov Model<span></span></a></li>
<li class="chapter" data-level="8.7.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#sparse-pca"><i class="fa fa-check"></i><b>8.7.4</b> sparse PCA<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>8.8</b> Linear Regression<span></span></a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="linear-regression.html"><a href="linear-regression.html#problem-formulation"><i class="fa fa-check"></i><b>8.8.1</b> Problem formulation<span></span></a></li>
<li class="chapter" data-level="8.8.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimator-in-high-dimensions"><i class="fa fa-check"></i><b>8.8.2</b> Least Squares Estimator in high dimensions<span></span></a></li>
<li class="chapter" data-level="8.8.3" data-path="linear-regression.html"><a href="linear-regression.html#sparse-linear-regression"><i class="fa fa-check"></i><b>8.8.3</b> Sparse linear regression<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html"><i class="fa fa-check"></i><b>8.9</b> Uniform laws of large numbers<span></span></a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#motivation-1"><i class="fa fa-check"></i><b>8.9.1</b> Motivation<span></span></a></li>
<li class="chapter" data-level="8.9.2" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity"><i class="fa fa-check"></i><b>8.9.2</b> A uniform law via Rademacher complexity<span></span></a></li>
<li class="chapter" data-level="8.9.3" data-path="uniform-laws-of-large-numbers.html"><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity"><i class="fa fa-check"></i><b>8.9.3</b> Upper bounds on the Rademacher complexity<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>9</b> Survival Analysis<span></span></a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-5.html"><a href="introduction-5.html"><i class="fa fa-check"></i><b>9.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>9.2</b> </a></li>
<li class="chapter" data-level="9.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html"><i class="fa fa-check"></i><b>9.3</b> Counting Processes and Martingales<span></span></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#conditional-expectation"><i class="fa fa-check"></i><b>9.3.1</b> Conditional Expectation<span></span></a></li>
<li class="chapter" data-level="9.3.2" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#martingale"><i class="fa fa-check"></i><b>9.3.2</b> Martingale<span></span></a></li>
<li class="chapter" data-level="9.3.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#key-martingales-properties"><i class="fa fa-check"></i><b>9.3.3</b> Key Martingales Properties<span></span></a></li>
<li class="chapter" data-level="9.3.4" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-5"><i class="fa fa-check"></i><b>9.3.4</b> </a></li>
<li class="chapter" data-level="9.3.5" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-6"><i class="fa fa-check"></i><b>9.3.5</b> </a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>9.4</b> </a></li>
<li class="chapter" data-level="9.5" data-path="cox-regression.html"><a href="cox-regression.html"><i class="fa fa-check"></i><b>9.5</b> Cox Regression<span></span></a></li>
<li class="chapter" data-level="9.6" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html"><i class="fa fa-check"></i><b>9.6</b> Filtration의 개념을 정복하자!<span></span></a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약"><i class="fa fa-check"></i><b>9.6.1</b> Random Process를 이야기 하기까지의 긴 여정의 요약<span></span></a></li>
<li class="chapter" data-level="9.6.2" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#ft-measurable"><i class="fa fa-check"></i><b>9.6.2</b> Ft-measurable<span></span></a></li>
<li class="chapter" data-level="9.6.3" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#epilogue"><i class="fa fa-check"></i><b>9.6.3</b> EPILOGUE<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>9.7</b> Concepts<span></span></a></li>
</ul></li>
<li class="appendix"><span><b>00-00<span></span></b></span></li>
<li class="chapter" data-level="A" data-path="concepts-1.html"><a href="concepts-1.html"><i class="fa fa-check"></i><b>A</b> Concepts<span></span></a>
<ul>
<li class="chapter" data-level="A.1" data-path="autologistic.html"><a href="autologistic.html"><i class="fa fa-check"></i><b>A.1</b> Autologistics<span></span></a></li>
<li class="chapter" data-level="A.2" data-path="orderlogit.html"><a href="orderlogit.html"><i class="fa fa-check"></i><b>A.2</b> Ordered Logit<span></span></a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="abstract-1.html"><a href="abstract-1.html"><i class="fa fa-check"></i><b>B</b> ABSTRACT<span></span></a></li>
<li class="chapter" data-level="C" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>C</b> CNN<span></span></a></li>
<li class="chapter" data-level="D" data-path="cnn-1.html"><a href="cnn-1.html"><i class="fa fa-check"></i><b>D</b> CNN<span></span></a></li>
<li class="chapter" data-level="E" data-path="cnn-2.html"><a href="cnn-2.html"><i class="fa fa-check"></i><b>E</b> CNN<span></span></a></li>
<li class="chapter" data-level="F" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>F</b> 01<span></span></a></li>
<li class="chapter" data-level="G" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>G</b> 02<span></span></a>
<ul>
<li class="chapter" data-level="G.1" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>G.1</b> 10.<span></span></a>
<ul>
<li class="chapter" data-level="G.1.1" data-path="section-10.html"><a href="section-10.html#stochastic-block-model-1"><i class="fa fa-check"></i><b>G.1.1</b> Stochastic Block Model<span></span></a></li>
<li class="chapter" data-level="G.1.2" data-path="section-10.html"><a href="section-10.html#likelihood-function-1"><i class="fa fa-check"></i><b>G.1.2</b> Likelihood function<span></span></a></li>
<li class="chapter" data-level="G.1.3" data-path="section-10.html"><a href="section-10.html#mixed-membership-block-model-mmbm-1"><i class="fa fa-check"></i><b>G.1.3</b> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="latent-network-models" class="section level2 hasAnchor" number="7.8">
<h2><span class="header-section-number">7.8</span> Latent Network Models<a href="latent-network-models.html#latent-network-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="latent-position-model" class="section level3 hasAnchor" number="7.8.1">
<h3><span class="header-section-number">7.8.1</span> Latent Position Model<a href="latent-network-models.html#latent-position-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>ERGMs 와 다르게, 이 모델은 소셜 스페이스의 개념을 도입함. 이 소셜 스페이스에서는, 네트워크 관계에 있어 unobserved latent 특성이 potential transitive 경향을 represent, 즉 위력? 을 나타낼 수 있음. 이때 이 소셜 스페이스에서 각 actor (혹은 node) <span class="math inline">\(i\)</span>는 알려지지 않은 포지션 <span class="math inline">\(z_i\)</span>를 각각 차지하게 됨. 우리는 이를 <strong>latent position</strong> 이라고 부름.</p>
<p>여기서 우리는 주된 가정으로 ties 간의 <strong>조건부 독립</strong>을 가정한다. latent position이 주어진다면, 네트워크 안의 ties들은 조건부 독립임이 가정된다. 두 개인들 간의 특정한 tie의 확률은 그들의 positions 들의 함수로 모델링된다. 가령 소셜 스페이스 안에서의 두 actor 사이의 거리라던가.</p>
<ul>
<li>main assumption
<ul>
<li>given the latent position, each connection is conditionally independent each others</li>
<li>latent positions can capture all dependence structures</li>
<li>the prob of having an edge is a function of latent positions
<ul>
<li>이때 주로 사용되는 function 은 distance.</li>
</ul></li>
</ul></li>
</ul>
<p>이때 이를 노테이션으로 표기하자면 다음과 같다. 아래는 joint likelihood function.</p>
<p><span class="math display">\[
P(Y | Z, X, \theta) = \prod_{i \not = j, i&lt;j} P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)
\]</span></p>
<ul>
<li><span class="math inline">\(i&lt;j\)</span> 는 undirected network 상황에서</li>
<li>sociomatrix (binary network) <span class="math inline">\(Y_{n \times n}\)</span>, 이때 요소 <span class="math inline">\(y_{i,j}\)</span>는 actor <span class="math inline">\(i\)</span>로부터 <span class="math inline">\(j\)</span>로의 관계를 의미하는 값.</li>
<li>additional covariate information <span class="math inline">\(X\)</span> (nodal covaraites)</li>
<li>이때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(x_{i,j}\)</span>는 unobserved 성질이며, <span class="math inline">\(\theta\)</span>는 estimate되어야 하는 패러미터, <span class="math inline">\(Z\)</span>는 estimate 되어야 하는 포지션.
<ul>
<li><span class="math inline">\(z_i\)</span>: node <span class="math inline">\(i\)</span> 의 latent position.</li>
</ul></li>
</ul>
<p><br>
<br>
<br></p>
<div id="methods" class="section level4 hasAnchor" number="7.8.1.1">
<h4><span class="header-section-number">7.8.1.1</span> Methods<a href="latent-network-models.html#methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="distance-models" class="section level5 hasAnchor" number="7.8.1.1.1">
<h5><span class="header-section-number">7.8.1.1.1</span> Distance Models<a href="latent-network-models.html#distance-models" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math inline">\(P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)\)</span>는 logistic regression framework 를 활용하는 것으로 편하게 패러미터化 (설명) 할 수 있다. 이렇게 패러미터化 할 때 tie의 확률은 <span class="math inline">\(z_i , z_j \in \mathbb R\)</span> 인 <span class="math inline">\(z_i , z_j\)</span> 사이의 euclidean distance 에 의존한다. 수식은 아래와 같다.</p>
<p><span class="math display">\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = 
\underbrace{\alpha}_{\text{intercept}} + 
\underbrace{\beta &#39; }_{\substack{\text{effect of}\\\text{nodal covariates}}} x_{i,j}- 
\underbrace{|z_i - z_j |}_{\text{euclidean}}
\]</span></p>
<p><span class="math display">\[
\begin{alignat}{2}
P(Y|Z,X,\theta) 
&amp;= \prod_{i&lt;j} &amp;&amp;\pi_{ij}^{y_{ij}}&amp;&amp;(1-\pi_{ij})^{1-y_{ij}}
&amp;= \prod_{i&lt;j} 
&amp;&amp;\left(\frac{\exp(\alpha + \beta x_{ij} - \|z_i - z_j \|)}
{1+\exp(\alpha + \beta x_{ij} - \|z_i - z_j \|)} \right)^{y_{ij}}
&amp;&amp;\left(\frac{1}{1+\exp(\alpha + \beta x_{ij} - \|z_i - z_j \|)} \right)^{1-y_{ij}}
\end{alignat}
\]</span></p>
<ul>
<li>이때 distance <span class="math inline">\(|z_i - z_j |=d_{ij}\)</span> 는 그 어떤 metric으로도 대체될 수 있다는 것을 notice. 삼각부등식 <span class="math inline">\(d_{i,j} \le d_{i,k} + d_{k,j}\)</span>만 만족하면 됨.
<ul>
<li><span class="math inline">\(d_{ij}\)</span> 이 증가하면 edge 를 가질 prob은 감소. 역도 성립. out of sight, out of mind.</li>
</ul></li>
</ul>
<p>latent 포지션 모델은 본질적으로 reciprocal 하고 transitive 함. <mark>왜? 만약 <span class="math inline">\(i \rightarrow j\)</span> 이고 <span class="math inline">\(j \rightarrow k\)</span> 이라면, <span class="math inline">\(d_{i,j}\)</span> 와 <span class="math inline">\(d_{j,k}\)</span> 는 어쩌면 지나치게 크지는 않을 수도 있는 것이고, 이 경우에는 이하로 이어짐: </mark></p>
<ol style="list-style-type: decimal">
<li>events <span class="math inline">\(j \rightarrow i\)</span> (reciprocity)</li>
<li>그리고 <span class="math inline">\(i \rightarrow k\)</span> (transitivity)</li>
</ol>
<p><mark>when a node <span class="math inline">\(i,j,k\)</span> are connected, the latent position of <span class="math inline">\(z_i\)</span> and <span class="math inline">\(z_j\)</span> are close.</mark></p>
<ul>
<li>benefits: visualize the relationship / very easy to capture the cluster - structures
disadvantages: even though a latent space model can capture the transitivities with triangle inequalities, it still has a limitatino in capturing a high-order dependence</li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="projection-models" class="section level5 hasAnchor" number="7.8.1.1.2">
<h5><span class="header-section-number">7.8.1.1.2</span> Projection Models<a href="latent-network-models.html#projection-models" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><strong>Invariance of distance</strong>. distance 모델은 본질적으로 symmetric 임. 즉 <span class="math inline">\(p(i → j) = p(j → i)\)</span>. 하지만 많은 (<strong>directed</strong>) 모델에서 이런 symmetry 는 성립을 안함. 예를 들어 actor <span class="math inline">\(i\)</span> 가 대량의 ties 들을 보내는 반면 <span class="math inline">\(j\)</span> 가 <span class="math inline">\(i\)</span> 에게서 ties 들을 받은 actors 전체 중 작은 subset 에게만 보낸다면? <mark>따라서 행위의 변수 레벨은 관계에서 확률의 transitivity 를 allow하는 latent 포지션 모델의 맥락 속에서 모델링될 필요가 있다.</mark> 개개인의 소셜 활동의 특정한 수준도 고려되어야 함은 물론이다.<mark></p>
<p>그러나 likelihood 는 only include a distance function -&gt; distance 는 2개의 latent position 사이의 infinite realization 을 보유.</p>
<p>latent position 들 자체도 무한한 realization 이 존재.</p>
<p>-&gt; Bayesian Inference</p>
<p>-&gt; post-process for posterior sample (<strong>Procrustes Matching</strong>: based on a reference point, all posterior samples are moved / rotated tward a reference point. commonly used in statistical shape analysis)</p>
<ol style="list-style-type: decimal">
<li><p>set up a reference point generally a posterior sample that yiedls MAP (Maximum A Posterior)</p></li>
<li><p>all other posterior samples are transformed by procrustes matching -&gt; <span class="math inline">\(procrustes(X_{ref}, X_{ref})\)</span> in <code>MCMCpack</code> pacakage of <code>R</code>.</p></li>
</ol>
<p>distance -&gt; undirected network
projection method -&gt; directed network</p>
<p>actor <span class="math inline">\(i\)</span>의 특성의 벡터 <span class="math inline">\(v_i\)</span>를 <strong>unit</strong> <span class="math inline">\(k\)</span>-dim 이라고 가정. <span class="math inline">\(i,j\)</span> 사이의 angle 에 따라 둘 사이에 tie 가 존재할 가능성이 이하와 같이 영향받는다.</p>
<ul>
<li>예각: high</li>
<li>직각: neutral</li>
<li>둔각: low</li>
</ul>
<p>actor <span class="math inline">\(i\)</span> 의 활동 레벨 <span class="math inline">\(a_i &gt;0\)</span> 를 설정한 후, <span class="math inline">\(i→j\)</span>의 tie의 존재 확률을 <span class="math inline">\(a_i v_i &#39; v_i = \frac{z_i&#39; z_j}{| z_j |}\)</span> (이때 <span class="math inline">\(z_i = \underbrace{a_i}_{\text{strength (length)}} \underbrace{v_i}_{\text{unit vector}}\)</span>) 라고 설정한다면 이하의 등식이 성립.</p>
<p><span class="math display">\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = \alpha + \beta &#39; x_{i,j} + \frac{z_i&#39; z_j}{| z_j |}
\]</span></p>
<p>from note:</p>
<p><span class="math display">\[
\pi_{ij} = logodds(y_{ij} | z_i , z_j , \alpha) = \alpha + \frac{z_i &#39; z_j}{\|z_i \|}
\\
\pi_{ji} = \phantom{logodds}(y_{ji} | \phantom{z_i , z_j , \alpha) = \alpha} + \frac{z_j &#39; z_i}{\|z_j \|}
\]</span></p>
<p>Latent Space Model (LSM)</p>
<p>-&gt; map each node into unobserved latent space
-&gt; easy to visualized
-&gt; easy to observe cluster structures</p>
<ol style="list-style-type: decimal">
<li>LSM <span class="math inline">\(z_i \sim (0, \sigma^2)\)</span>, <span class="math inline">\(\pi(z_i) \sim N(0, \sigma^2)\)</span></li>
</ol>
<p>-&gt; need a model that capture clusture structures using a model</p>
<p>여기서 <span class="math inline">\(z_i\)</span> 는 mixture normal prior (one of the typical way to implement clustering)</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="estimation-2" class="section level4 hasAnchor" number="7.8.1.2">
<h4><span class="header-section-number">7.8.1.2</span> Estimation<a href="latent-network-models.html#estimation-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Distance</strong> 모델 상황을 생각해보자. 유클리드 공간에서 set points 간의 거리는 회전, 반사, 이동에 불변 (invariant). 따라서 모든 각각의 latent postion의 행렬 <span class="math inline">\(Z_{k \times n}\)</span> 에 대해 같은 log-likelihood 를 갖는 다른 positions 을 표상하는 행렬이 존재한다.</p>
<p><span class="math inline">\(\mathcal Z\)</span> 를 회전, 반사, 이동에 불변한 <span class="math inline">\(Z\)</span>와 equivalent 한 postions들의 class 라고 하자. 각각의 <span class="math inline">\(\mathcal Z\)</span>에 대해 node 들 간의 거리를 모아 set 1개가 나옴. 이러한 positions 들의 class를 <strong>configuration</strong> 이라고 부름.</p>
<p>마찬가지로 Projection 모델에서의 <span class="math inline">\(Z\)</span> 에 대해서도 Projection 모델들은 positions 들의 회전과 반사에는 불변하지만, <mark>이동에 대해서는 불변이 아님.</mark></p>
<p>조건부 독립 모델의 log-likelihood 모델은 다음과 같다:</p>
<p><span class="math display">\[
\log P(Y | \eta ) = \sum_{i \not = j} \Big \{  \eta_{i,j}y_{i,j} - \log (1+\exp(\eta_{i,j})
\Big \}
\]</span></p>
<p>※ Steps:</p>
<ol style="list-style-type: decimal">
<li>각 j 에서 <span class="math inline">\(z_j &#39;\)</span> 샘플링하기 위해 MH 스텝 거침. proposal 분포 <span class="math inline">\(\varphi(\cdot)\)</span> 으로부터 <span class="math inline">\(z_j&#39;\)</span> 생산하고 이를 이하의 확률 <span class="math inline">\(r_z \left ( z_j &#39; , z_j^{(t)} \right)\)</span> 로 채택. 비슷환 과정을 따라서 <span class="math inline">\(\alpha, \beta\)</span> 도 MH 이용해서 생산.</li>
</ol>
<p><span class="math display">\[
r_z \left ( z_j &#39; , .z_j^{(t)} \right)
= \frac{\pi \Big (z_j &#39;  \Big \vert Y, \alpha , \beta \Big )}{\pi \Big (z_j^{(t)}  \Big \vert Y, \alpha , \beta \Big )}
\cdot
\frac{\varphi \Big (z_j &#39; \rightarrow z_j^{(t)} \Big )}{\varphi \Big ( z_j^{(t)}\rightarrow z_j &#39; \Big )}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Procrustes</strong> 매칭 사용해서 MCMC 샘플 후처리.</p>
<ol style="list-style-type: lower-alpha">
<li>latent positions 들의 reference set 을 찾기 위해, MCMC 샘플로부터 latent positions들 중 full log posterior density가 가장 높은 latent positions들 <span class="math inline">\(Z_0\)</span>를 하나 뽑아서 쟁여둠</li>
<li><span class="math inline">\(Z_0\)</span>를 사용해서 각각의 MCMC 샘플에 Procrustes 매칭 적용</li>
</ol></li>
</ol>
<p><span class="math display">\[
Z^\ast  = \arg \min_{TZ} tr \Big \{ (Z_0 - TZ) &#39; (Z_0 - TZ) \Big \}
\]</span></p>
<p><br>
<br>
<br></p>
</div>
<div id="advantages" class="section level4 hasAnchor" number="7.8.1.3">
<h4><span class="header-section-number">7.8.1.3</span> Advantages<a href="latent-network-models.html#advantages" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>네트워크 관계에 대한 시각적이고 모델에 기반한 공간적인 표현을 제공. 해석 용이함.</p>
<p>It is flexible and can be easily generalized to allow for multiple relationships, ties with varying strengths, and time-varying relations</p>
<p>deal easily with missing data, at least if information on ties is missing at random</p>
<p>the model is inherently transitive, and so we can expect an improved fit over models lacking such structure when the relations are transitive in nature</p>
<p><br>
<br>
<br></p>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="latent-position-cluster-model" class="section level3 hasAnchor" number="7.8.2">
<h3><span class="header-section-number">7.8.2</span> Latent Position Cluster Model<a href="latent-network-models.html#latent-position-cluster-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>$$
<span class="math display">\[\begin{align}


\log \frac{P(y_{i, j} = 1\Big | z_i , z_j , x_{i,j}, \beta)}{1 - P(y_{i, j} = 1 \Big | z_i , z_j , x_{i,j}, \beta)} &amp;= \beta_0 &#39; x_{i,j} - \beta_1 |z_i - z_j |

\\

P(Y | Z, X, \beta) &amp;= \prod_{i \not = j} P(y_{i, j} \Big | z_i , z_j , x_{i,j}, \beta) \tag{Likelihood}


\end{align}\]</span>
$$</p>
<ul>
<li><span class="math inline">\(z_i \sim \sum\limits_{g=1}^G \lambda_g \cdot MVN_d )\mu_g , \sigma^2_g I_d )\)</span>, where <span class="math inline">\(\sqrt{\frac{1}{n} \sum_i |z_i|^2} = 1\)</span>.</li>
<li><span class="math inline">\(\lambda_g\)</span>는 individual distribution의 비율</li>
</ul>
<p><br>
<br>
<br></p>
<ol start="2" style="list-style-type: decimal">
<li>Latent position cluster model</li>
</ol>
<p><span class="math display">\[
z_i \sim \sum^G_{g=1} \lambda_g \cdot MVN(\mu_g , \sigma^2_g I)
\]</span></p>
<ul>
<li><span class="math inline">\(\lambda_g\)</span>: proportion of an individual distribution (probability of belonging to cluster <span class="math inline">\(g\)</span> from node <span class="math inline">\(i\)</span>)</li>
<li><span class="math inline">\(\mu_g\)</span>: center of cluster position</li>
<li><span class="math inline">\(\sigma_g^2\)</span>: size of cluster</li>
</ul>
<p><mark>이때 <span class="math inline">\(\sqrt{\frac{1}{n} \sum\limits^n_{i=1}\|z_i\|^2} = 1\)</span></mark></p>
<p><span class="math display">\[
logodd \pi_{ij} = \beta_0 &#39; x_{ij} - \beta_1 |z_i - z_j| = \alpha - \beta \|z_i - z_j\|
\]</span></p>
<div id="bayesian-estimation" class="section level4 hasAnchor" number="7.8.2.1">
<h4><span class="header-section-number">7.8.2.1</span> Bayesian Estimation<a href="latent-network-models.html#bayesian-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>※ Fully Bayesian Estimation Procedure</p>
<ol style="list-style-type: decimal">
<li>모델 패러미터 <span class="math inline">\(\beta, \lambda_g, \mu_g, \sigma_g^2\)</span> 들의 prior 분포 특정</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}

\beta &amp;\sim MVN_p \left( \xi , \Psi \right)

\\

\lambda &amp;\sim Dirichlet(\nu)

\\

\sigma^2_g &amp;\sim \sigma_0^2 Inv- \chi_\alpha^2 &amp;&amp; g = 1, \cdots, G

\\

\mu_g &amp;\sim MVN_d \left( 0, \omega^2 \cdot I_d \right) &amp;&amp; g = 1, \cdots, G


\end{align}\]</span>
$$</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\mathbf z_i , \beta, \lambda, \mu_g ,\sigma^2_g, K_i\)</span>의 full 조건부 posterior 분포 특정</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}

{\bf z}_{i}\mid K_{i}=g,\mathrm{others}
&amp;\sim
\phi_{d}\bigl({\bf z}_{i};\mu_{g},\sigma_{g}^{2}I_{d}\bigr)
\cdot
P\bigl(Y\mid Z,X,\beta\bigr),\quad 
&amp;&amp;i=1:n,
\\
&amp;=
MVN(\bf z_i ; \mu_g , \sigma_g^2 I_d)
\cdot
P\bigl(Y\mid Z,X,\beta\bigr),\quad 



\tag{1}
\\

\beta\mid \bf{Z},\mathrm{others}
&amp;\sim
\phi_{p}\Bigl(\beta;\xi,\Psi\Bigr)
\cdot
P\Bigl({Y}\mid\bf {Z},\bf {X},\beta\Bigr),
\\
&amp;=

MVN(\beta ; \xi, \Psi)
\cdot
P\Bigl({Y}\mid\bf {Z},\bf {X},\beta\Bigr),
\tag{2}
\\

\lambda\mid{\mathrm{others}}
&amp;\sim
{Dirichlet\Big (m + \nu \Big)}

\\

\mu_{g}\mid\mathrm{others}
&amp;\sim
MVN_{d}\left(\frac{m_{g}\bar z_{g}}{m_{g}+\sigma_{g}^{2}/\omega^{2}},\,\frac{\sigma_{g}^{2}}{m_{g}+\sigma_{g}^{2}/\omega^{2}}  \cdot I\right),\quad 

&amp;&amp;g=1:G,


\\

\sigma_{g}^{2}\mid\mathrm{others}
&amp;\sim
\left(\sigma_{0}^{2}+d s_{g}^{2}\right) \cdot \mathrm{Inv-}\chi^2_{\alpha + m_s d},

&amp;&amp;g=1:G,


\\

P\Bigl(K_{i}=g \bigg | \mathrm{others}\Bigr)
&amp;=
\frac{\lambda_{g}\phi_{d}\Bigl(z_{i};\mu_{g},\;\sigma_{g}^{2} \cdot I_{d}\Bigr)}
{\sum_{r=1}^{G}\lambda_{r}\phi_{d}\Bigl(z_{i};\mu_{r}, \; \sigma_{r}^{2} \cdot I_{d}\Bigr)},\quad 

&amp;&amp;g=1:G.

\end{align}\]</span>
$$</p>
<ul>
<li><span class="math inline">\(K_i = g\)</span>: the membership of node <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(MVN(\bf z_i ; \mu_g , \sigma_g^2 I_d)\)</span>: normal for membership <span class="math inline">\(g\)</span></li>
<li><span class="math inline">\(P\bigl(Y\mid Z,X,\beta\bigr)\)</span>: we cannot calculate the conditional posterior distribution analytically.
<ul>
<li>for same reason, for (1) and (2), use MH algorithm</li>
</ul></li>
<li><span class="math inline">\(m_g = \sum\limits^n_{i=1}I(K_i = g)\)</span></li>
<li><span class="math inline">\(\bar z_g\)</span>: mean of latent positions that belongs to cluster <span class="math inline">\(g\)</span></li>
<li><span class="math inline">\(d\)</span>: dimension</li>
<li><span class="math inline">\(s_g^2 = \frac{1}{d}\sum\limits_{i=1}^n (z_i - \mu_g) &#39; (z_i - \mu_g) I(K_i = g)\)</span></li>
</ul>
<p>※ Steps.</p>
<ol style="list-style-type: decimal">
<li><p>MH 스텝 이용해서 <span class="math inline">\(Z_{t+1}\)</span> 업데이트
1. proposal <span class="math inline">\(2_{i}^{\ast}\sim\left|l\right|/|\bigvee_{i}(\Sigma_{i},(\hat{L}_{i}^{\ast}|_{i})\)</span>, <span class="math inline">\(g=1, \cdots, G\)</span>
2. accept <span class="math inline">\(Z_i^\ast\)</span> as the i-th element of <span class="math inline">\(z_{t+1}\)</span> with probability <span class="math inline">\(\frac{P\big(\mathbf{V}|\mathbf{Z}^{*},\mathbf{X},\beta_{t}\big)\phi_{d}\big(\mathbf{Z}_{i}^{*},\mu K_{i},\sigma_{K}^{2}|_{d}\big)}{P\big(\mathbf{V}|\mathbf{Z}_{t},\mathbf{X},\beta_{t}\big)\phi_{d}\big(\mathbf{Z}_{i i};\mu K_{i},\sigma_{K}^{2}|_{d}\big)}\)</span></p></li>
<li><p>MH 스텝 이용해서 <span class="math inline">\(\beta_{t+1}\)</span> 업데이트
1. <span class="math inline">\(2_{i}^{\ast}\sim\left|l\right|/|\bigvee_{i}(\Sigma_{i},(\hat{L}_{i}^{\ast}|_{i})\)</span>, <span class="math inline">\(g=1, \cdots, G\)</span>
2. accept <span class="math inline">\(Z_i^\ast\)</span> as the i-th element of <span class="math inline">\(z_{t+1}\)</span> with probability <span class="math inline">\(\frac{{\cal P}\big(\mit{W}\lbrack\mathbf{Z}_{t+1},\mit{X},\beta^{*}\big)\phi_{\rho}\big(\beta^{*};\xi,\mit{\mit\Psi}\big)}{{\cal P}\Big(\mit{\bf V}\lbrack\Z_{t+1},\mit{\bf X},\beta_{t}\big)\phi_{\rho}\big(\beta_{t};\xi,\mit{\mit\Psi}\Big)}.\)</span></p></li>
<li><p>Update λ, µg, σ, g, Ki using full conditional posterior distributions</p></li>
</ol>
<p>Pros and Cons</p>
<ul>
<li>장점: 성능이 더 나음</li>
<li>단점: 더 복잡함</li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="identifiability-of-positions-and-cluster-labels" class="section level4 hasAnchor" number="7.8.2.2">
<h4><span class="header-section-number">7.8.2.2</span> Identifiability of Positions and Cluster Labels<a href="latent-network-models.html#identifiability-of-positions-and-cluster-labels" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>2개의 <strong>identifiability</strong> issues</p>
<ol style="list-style-type: decimal">
<li>invariant property of distance</li>
<li><dl>
<dt>label-switching problem</dt>
<dd>common problem in a Bayesian Mixture Model
</dd>
</dl></li>
</ol>
<p>Cluster label does not change the likelihood
-&gt; changing the cluster label will make problems for making inferences of individuals in a cluster.</p>
<p>Solution: Minimize, expectation of loss function, which is <strong>Bayes risk</strong></p>
<p>Likelihood 에만 의존해서 cluster化 성능 평가하면 문제생김. positions 과 cluster labels 들의 Non-identifiabilities 문제. Likelihood 는 이하에 불변.</p>
<ol style="list-style-type: decimal">
<li>latent positions 들의 반사, 회전, translation</li>
<li>cluster 들의 relabeling. 이는 <strong>Label switching problem</strong>[^cluster 의 label 을 permute 하는 것은 Likelihood 에 변화를 가져오지 않지만, obs 들을 그룹에 넣는 과정에서 우리가 문제를 겪게 됨. Likelihood 는 같지만 label 이 다른 순간 이건 cluster 의 구성이 다른 것과 동일하니까.] 으로 이어짐.</li>
</ol>
<p>이를 해결하기 위한 방법으로 Minimizing <strong>Bayes risk</strong> 가 제시.</p>
<ol style="list-style-type: decimal">
<li>estimate 되는 Bayes risk<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> 를 최소화하는 actor 들의 position (i.e., reference point) 탐색</li>
<li>latent position 의 posterior 추출값 (draw), (i.e. 모든 다른 MCMC 샘플들) 를 Procrustes Transform 하고 동일한 Transformation Matrix 를 사용하여, cluster mean 와 Cov 를 transform</li>
<li>Estimate 된 Bayes risk 를 최소화하는 cluster membership probability 을 탐색</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>에 대한 계산은 이하와 같다. 이를 통하여 cluster 의 갯수를 정한다. Bayesian estimation - 이하의 equation, 즉 higehest posterior probability 를 가지는 model 을 선택.</li>
</ol>
$$
<span class="math display">\[\begin{array}


&amp;P(Y,{\hat{Z}}|G)

&amp;=
&amp;&amp;\underbrace
{\int P(Y|{\hat{Z}},X,\beta)p(\beta)d\beta}
_{\substack{\text{integrated likelihood for the logistic regression} 
\\ \approx BIC_{lr}(\text{logistic regression})}}

&amp;&amp;\cdot 

&amp;&amp;\underbrace
{\int P({\hat{Z}}|\theta)p(\theta)d\theta}
_{\substack{\text{integrated likelihood for the mixture model} 
\\ \approx BIC_{mbc}(\text{mixture model})}}

\\

BIC &amp;= &amp;&amp;BIC_{lr} &amp;&amp;+ &amp;&amp;BIC_{mbc}

\\

&amp;= &amp;&amp; \left \{ 2 \log \Big [ P \Big \{ Y \Big | \hat Z , X, \hat \beta ( \hat Z ) \Big \} \Big ] - d_{logit} \log (n_{logit}) \right \}

&amp;&amp; +

&amp;&amp; 

\left\{ 2 \log \Big [ P \Big \{ \hat Z \Big | \hat \theta ( \hat Z ) \Big \} \Big ] - d_{mbc} \log (n) \right \}

\end{array}\]</span>
<p>$$</p>
<ul>
<li><span class="math inline">\(d_{logit} =\)</span> # of parameters in the logistic regression</li>
<li><span class="math inline">\(n_{logit} =\)</span> # of ties in data (# of edges)</li>
<li><span class="math inline">\(d_{mbc} =\)</span> # of parameters in the clustering model</li>
</ul>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Bayes risk = Expecation of loss function. 이때 loss function 으로는 Kullback-Leibler loss 를 사용한다.<a href="latent-network-models.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ergm-for-dynamic-networks.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="additive-and-multiplicative-effects-network-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/212108_Latent.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
