<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.4 Auxiliary Variable MCMC | Self-Study</title>
  <meta name="description" content="4.4 Auxiliary Variable MCMC | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.4 Auxiliary Variable MCMC | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.4 Auxiliary Variable MCMC | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="advanced-mcmc-wk08.html"/>
<link rel="next" href="approximate-bayesian-computation.html"/>
<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li><a href="index.html#intro" id="toc-intro">Intro<span></span></a></li>
<li><a href="#part-20-02" id="toc-part-20-02">(PART) 20-02<span></span></a></li>
<li><a href="categorical.html#categorical" id="toc-categorical"><span class="toc-section-number">1</span> Categorical<span></span></a>
<ul>
<li><a href="overview.html#overview" id="toc-overview"><span class="toc-section-number">1.1</span> Overview<span></span></a>
<ul>
<li><a href="overview.html#data-type-and-statistical-analysis" id="toc-data-type-and-statistical-analysis"><span class="toc-section-number">1.1.1</span> Data Type and Statistical Analysis<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="bayesian.html#bayesian" id="toc-bayesian"><span class="toc-section-number">2</span> Bayesian<span></span></a>
<ul>
<li><a href="abstract.html#abstract" id="toc-abstract"><span class="toc-section-number">2.1</span> Abstract<span></span></a>
<ul>
<li><a href="abstract.html#변수의-독립성" id="toc-변수의-독립성"><span class="toc-section-number">2.1.1</span> 변수의 독립성<span></span></a></li>
<li><a href="abstract.html#교환가능성" id="toc-교환가능성"><span class="toc-section-number">2.1.2</span> 교환가능성<span></span></a></li>
</ul></li>
<li><a href="continual-aeassessment-method.html#continual-aeassessment-method" id="toc-continual-aeassessment-method"><span class="toc-section-number">2.2</span> Continual Aeassessment Method<span></span></a></li>
<li><a href="horseshoe-prior.html#horseshoe-prior" id="toc-horseshoe-prior"><span class="toc-section-number">2.3</span> Horseshoe Prior<span></span></a></li>
</ul></li>
<li><a href="#part-21-01" id="toc-part-21-01">(PART) 21-01<span></span></a></li>
<li><a href="mathematical-stats.html#mathematical-stats" id="toc-mathematical-stats"><span class="toc-section-number">3</span> Mathematical Stats<span></span></a>
<ul>
<li><a href="inference.html#inference" id="toc-inference"><span class="toc-section-number">3.1</span> Inference<span></span></a>
<ul>
<li><a href="inference.html#rao-blackwell-thm." id="toc-rao-blackwell-thm."><span class="toc-section-number">3.1.1</span> Rao-Blackwell thm.<span></span></a></li>
<li><a href="inference.html#completeness" id="toc-completeness"><span class="toc-section-number">3.1.2</span> Completeness<span></span></a></li>
<li><a href="inference.html#레만-쉐페-thm." id="toc-레만-쉐페-thm."><span class="toc-section-number">3.1.3</span> 레만-쉐페 thm.<span></span></a></li>
<li><a href="inference.html#raoblack" id="toc-raoblack"><span class="toc-section-number">3.1.4</span> Rao-Blackwell thm.<span></span></a></li>
</ul></li>
<li><a href="hypothesis-test.html#hypothesis-test" id="toc-hypothesis-test"><span class="toc-section-number">3.2</span> Hypothesis Test<span></span></a></li>
<li><a href="power-fucntion.html#power-fucntion" id="toc-power-fucntion"><span class="toc-section-number">3.3</span> Power Fucntion<span></span></a>
<ul>
<li><a href="power-fucntion.html#significance-probability-p-value" id="toc-significance-probability-p-value"><span class="toc-section-number">3.3.1</span> Significance Probability (p-value)<span></span></a></li>
</ul></li>
<li><a href="optimal-testing-method.html#optimal-testing-method" id="toc-optimal-testing-method"><span class="toc-section-number">3.4</span> Optimal Testing Method<span></span></a></li>
<li><a href="data-reduction.html#data-reduction" id="toc-data-reduction"><span class="toc-section-number">3.5</span> Data Reduction<span></span></a>
<ul>
<li><a href="data-reduction.html#sufficiency-principle" id="toc-sufficiency-principle"><span class="toc-section-number">3.5.1</span> Sufficiency Principle<span></span></a></li>
</ul></li>
<li><a href="borel-paradox.html#borel-paradox" id="toc-borel-paradox"><span class="toc-section-number">3.6</span> Borel Paradox<span></span></a></li>
<li><a href="neymanpearson-lemma.html#neymanpearson-lemma" id="toc-neymanpearson-lemma"><span class="toc-section-number">3.7</span> Neyman–Pearson lemma<span></span></a>
<ul>
<li><a href="neymanpearson-lemma.html#overview-1" id="toc-overview-1"><span class="toc-section-number">3.7.1</span> Overview<span></span></a></li>
<li><a href="neymanpearson-lemma.html#generalized-lrt" id="toc-generalized-lrt"><span class="toc-section-number">3.7.2</span> Generalized LRT<span></span></a></li>
</ul></li>
<li><a href="개념.html#개념" id="toc-개념"><span class="toc-section-number">3.8</span> 개념<span></span></a></li>
</ul></li>
<li><a href="mcmc.html#mcmc" id="toc-mcmc"><span class="toc-section-number">4</span> MCMC<span></span></a>
<ul>
<li><a href="importance-sampling.html#importance-sampling" id="toc-importance-sampling"><span class="toc-section-number">4.1</span> Importance Sampling<span></span></a>
<ul>
<li><a href="importance-sampling.html#independent-monte-carlo" id="toc-independent-monte-carlo"><span class="toc-section-number">4.1.1</span> Independent Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo"><span class="toc-section-number">4.2</span> Markov Chain Monte Carlo<span></span></a>
<ul>
<li><a href="markov-chain-monte-carlo.html#mh-algorithm" id="toc-mh-algorithm"><span class="toc-section-number">4.2.1</span> MH Algorithm<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used" id="toc-random-walk-chains-most-widely-used"><span class="toc-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler" id="toc-basic-gibbs-sampler"><span class="toc-section-number">4.2.3</span> Basic Gibbs Sampler<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#implementation" id="toc-implementation"><span class="toc-section-number">4.2.4</span> Implementation<span></span></a></li>
</ul></li>
<li><a href="advanced-mcmc-wk08.html#advanced-mcmc-wk08" id="toc-advanced-mcmc-wk08"><span class="toc-section-number">4.3</span> Advanced MCMC (wk08)<span></span></a>
<ul>
<li><a href="advanced-mcmc-wk08.html#data-augmentation" id="toc-data-augmentation"><span class="toc-section-number">4.3.1</span> Data Augmentation<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm" id="toc-hit-and-run-algorithm"><span class="toc-section-number">4.3.2</span> Hit-and-Run Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm" id="toc-metropolis-adjusted-langevin-algorithm"><span class="toc-section-number">4.3.3</span> Metropolis-Adjusted Langevin Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm" id="toc-multiple-try-metropolis-algorithm"><span class="toc-section-number">4.3.4</span> Multiple-Try Metropolis Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm" id="toc-reversible-jump-mcmc-algorithm"><span class="toc-section-number">4.3.5</span> Reversible Jump MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc" id="toc-auxiliary-variable-mcmc"><span class="toc-section-number">4.4</span> Auxiliary Variable MCMC<span></span></a>
<ul>
<li><a href="auxiliary-variable-mcmc.html#introduction" id="toc-introduction"><span class="toc-section-number">4.4.1</span> Introduction<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution" id="toc-multimodal-target-distribution"><span class="toc-section-number">4.4.2</span> Multimodal Target Distribution<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants" id="toc-doubly-intractable-normalizing-constants"><span class="toc-section-number">4.4.3</span> Doubly-intractable Normalizing Constants<span></span></a></li>
</ul></li>
<li><a href="approximate-bayesian-computation.html#approximate-bayesian-computation" id="toc-approximate-bayesian-computation"><span class="toc-section-number">4.5</span> Approximate Bayesian Computation<span></span></a>
<ul>
<li><a href="approximate-bayesian-computation.html#simulator-based-models" id="toc-simulator-based-models"><span class="toc-section-number">4.5.1</span> Simulator-Based Models<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods" id="toc-abcifying-monte-carlo-methods"><span class="toc-section-number">4.5.2</span> ABCifying Monte Carlo Methods<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm" id="toc-abc-mcmc-algorithm"><span class="toc-section-number">4.5.3</span> ABC-MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="hamiltonian-monte-carlo.html#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo"><span class="toc-section-number">4.6</span> Hamiltonian Monte Carlo<span></span></a>
<ul>
<li><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo" id="toc-introduction-to-hamiltonian-monte-carlo"><span class="toc-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="population-monte-carlo.html#population-monte-carlo" id="toc-population-monte-carlo"><span class="toc-section-number">4.7</span> Population Monte Carlo<span></span></a>
<ul>
<li><a href="population-monte-carlo.html#adaptive-direction-sampling" id="toc-adaptive-direction-sampling"><span class="toc-section-number">4.7.1</span> Adaptive Direction Sampling<span></span></a></li>
<li><a href="population-monte-carlo.html#conjugate-gradient-mc" id="toc-conjugate-gradient-mc"><span class="toc-section-number">4.7.2</span> Conjugate Gradient MC<span></span></a></li>
<li><a href="population-monte-carlo.html#parallel-tempering" id="toc-parallel-tempering"><span class="toc-section-number">4.7.3</span> Parallel Tempering<span></span></a></li>
<li><a href="population-monte-carlo.html#evolutionary-mc" id="toc-evolutionary-mc"><span class="toc-section-number">4.7.4</span> Evolutionary MC<span></span></a></li>
<li><a href="population-monte-carlo.html#sequential-parallel-tempering" id="toc-sequential-parallel-tempering"><span class="toc-section-number">4.7.5</span> Sequential Parallel Tempering<span></span></a></li>
</ul></li>
<li><a href="stochastic-approximation-monte-carlo.html#stochastic-approximation-monte-carlo" id="toc-stochastic-approximation-monte-carlo"><span class="toc-section-number">4.8</span> Stochastic Approximation Monte Carlo<span></span></a></li>
<li><a href="review.html#review" id="toc-review"><span class="toc-section-number">4.9</span> Review<span></span></a>
<ul>
<li><a href="review.html#wk01" id="toc-wk01"><span class="toc-section-number">4.9.1</span> Wk01<span></span></a></li>
<li><a href="review.html#wk03" id="toc-wk03"><span class="toc-section-number">4.9.2</span> wk03<span></span></a></li>
<li><a href="review.html#wk04-05" id="toc-wk04-05"><span class="toc-section-number">4.9.3</span> wk04, 05<span></span></a></li>
</ul></li>
<li><a href="else.html#else" id="toc-else"><span class="toc-section-number">4.10</span> Else<span></span></a>
<ul>
<li><a href="else.html#hw4.-rasch-model" id="toc-hw4.-rasch-model"><span class="toc-section-number">4.10.1</span> Hw4. Rasch Model<span></span></a></li>
<li><a href="else.html#da-example-mvn" id="toc-da-example-mvn"><span class="toc-section-number">4.10.2</span> DA) Example: MVN<span></span></a></li>
<li><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes" id="toc-bayesian-adaptive-clinical-trial-with-delayed-outcomes"><span class="toc-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes<span></span></a></li>
<li><a href="else.html#nmar의-종류" id="toc-nmar의-종류"><span class="toc-section-number">4.10.4</span> NMAR의 종류<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-selection" id="toc-wk10-bayesian-model-selection"><span class="toc-section-number">4.10.5</span> wk10) Bayesian Model Selection<span></span></a></li>
<li><a href="else.html#autologistic-model" id="toc-autologistic-model"><span class="toc-section-number">4.10.6</span> Autologistic model<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-averaging" id="toc-wk10-bayesian-model-averaging"><span class="toc-section-number">4.10.7</span> wk10) Bayesian Model Averaging<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="mva.html#mva" id="toc-mva"><span class="toc-section-number">5</span> MVA<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#overview-of-mva-not-ended" id="toc-overview-of-mva-not-ended"><span class="toc-section-number">5.1</span> Overview of mva (not ended)<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#notation" id="toc-notation"><span class="toc-section-number">5.1.1</span> Notation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">5.1.2</span> Summary Statistics<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation" id="toc-statistical-inference-on-correlation"><span class="toc-section-number">5.1.3</span> Statistical Inference on Correlation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#standardization" id="toc-standardization"><span class="toc-section-number">5.1.4</span> Standardization<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#missing-value-treatment" id="toc-missing-value-treatment"><span class="toc-section-number">5.1.5</span> Missing Value Treatment<span></span></a></li>
</ul></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-nomral-wk2" id="toc-multivariate-nomral-wk2"><span class="toc-section-number">5.2</span> Multivariate Nomral (wk2)<span></span></a>
<ul>
<li><a href="multivariate-nomral-wk2.html#overview-2" id="toc-overview-2"><span class="toc-section-number">5.2.1</span> Overview<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#spectral-decomposition" id="toc-spectral-decomposition"><span class="toc-section-number">5.2.2</span> Spectral Decomposition<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">5.2.3</span> Properties of MVN<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#chi2-distribution" id="toc-chi2-distribution"><span class="toc-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors" id="toc-linear-combination-of-random-vectors"><span class="toc-section-number">5.2.5</span> Linear Combination of Random Vectors<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood" id="toc-multivariate-normal-likelihood"><span class="toc-section-number">5.2.6</span> Multivariate Normal Likelihood<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s" id="toc-sampling-distribtion-of-bar-pmb-y-s"><span class="toc-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span><span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#assessing-normality" id="toc-assessing-normality"><span class="toc-section-number">5.2.8</span> Assessing Normality<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#power-transformation" id="toc-power-transformation"><span class="toc-section-number">5.2.9</span> Power Transformation<span></span></a></li>
</ul></li>
<li><a href="inference-about-mean-vector-wk3.html#inference-about-mean-vector-wk3" id="toc-inference-about-mean-vector-wk3"><span class="toc-section-number">5.3</span> Inference about Mean Vector (wk3)<span></span></a>
<ul>
<li><a href="inference-about-mean-vector-wk3.html#overview-3" id="toc-overview-3"><span class="toc-section-number">5.3.1</span> Overview<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#confidence-region" id="toc-confidence-region"><span class="toc-section-number">5.3.2</span> 1. Confidence Region<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#simultaneous-ci" id="toc-simultaneous-ci"><span class="toc-section-number">5.3.3</span> 2. Simultaneous CI<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison" id="toc-note-bonferroni-multiple-comparison"><span class="toc-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector" id="toc-large-sample-inferences-about-a-mean-vector"><span class="toc-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5" id="toc-profile-analysis-wk4-5"><span class="toc-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend" id="toc-test-for-linear-trend"><span class="toc-section-number">5.3.7</span> 2. Test for Linear Trend<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix" id="toc-inferences-about-a-covariance-matrix"><span class="toc-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix<span></span></a></li>
</ul></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparison-of-several-mv-means-wk5" id="toc-comparison-of-several-mv-means-wk5"><span class="toc-section-number">5.4</span> Comparison of Several MV Means (wk5)<span></span></a>
<ul>
<li><a href="comparison-of-several-mv-means-wk5.html#paired-comparison" id="toc-paired-comparison"><span class="toc-section-number">5.4.1</span> Paired Comparison<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations" id="toc-comparing-mean-vectors-from-two-populations"><span class="toc-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2" id="toc-profile-analysis-for-g2"><span class="toc-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means" id="toc-comparing-several-multivariate-population-means"><span class="toc-section-number">5.4.4</span> Comparing Several Multivariate Population Means<span></span></a></li>
</ul></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression-wk6" id="toc-multivariate-multiple-regression-wk6"><span class="toc-section-number">5.5</span> Multivariate Multiple Regression (wk6)<span></span></a>
<ul>
<li><a href="multivariate-multiple-regression-wk6.html#overview-4" id="toc-overview-4"><span class="toc-section-number">5.5.1</span> Overview<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression" id="toc-multivariate-multiple-regression"><span class="toc-section-number">5.5.2</span> Multivariate Multiple Regression<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#example" id="toc-example"><span class="toc-section-number">5.5.3</span> Example)<span></span></a></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">5.6</span> PCA<span></span></a></li>
<li><a href="factor.html#factor" id="toc-factor"><span class="toc-section-number">5.7</span> Factor<span></span></a>
<ul>
<li><a href="factor.html#method-of-estimation" id="toc-method-of-estimation"><span class="toc-section-number">5.7.1</span> Method of Estimation<span></span></a></li>
<li><a href="factor.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">5.7.2</span> Factor Rotation<span></span></a></li>
<li><a href="factor.html#varimax-criterion" id="toc-varimax-criterion"><span class="toc-section-number">5.7.3</span> Varimax Criterion<span></span></a></li>
<li><a href="factor.html#factor-scores" id="toc-factor-scores"><span class="toc-section-number">5.7.4</span> Factor Scores<span></span></a></li>
</ul></li>
<li><a href="discrimination-and-classification.html#discrimination-and-classification" id="toc-discrimination-and-classification"><span class="toc-section-number">5.8</span> Discrimination and Classification<span></span></a>
<ul>
<li><a href="discrimination-and-classification.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">5.8.1</span> Bayes Rule<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations" id="toc-classification-with-two-mv-n-populations"><span class="toc-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations<span></span></a></li>
<li><a href="discrimination-and-classification.html#evaluating-classification-functions" id="toc-evaluating-classification-functions"><span class="toc-section-number">5.8.3</span> Evaluating Classification Functions<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-several-populations-wk13" id="toc-classification-with-several-populations-wk13"><span class="toc-section-number">5.8.4</span> Classification with several Populations (wk13)<span></span></a></li>
<li><a href="discrimination-and-classification.html#other-discriminant-analysis-methods" id="toc-other-discriminant-analysis-methods"><span class="toc-section-number">5.8.5</span> Other Discriminant Analysis Methods<span></span></a></li>
</ul></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-distance-methods-and-ordination" id="toc-clustering-distance-methods-and-ordination"><span class="toc-section-number">5.9</span> Clustering, Distance Methods, and Ordination<span></span></a>
<ul>
<li><a href="clustering-distance-methods-and-ordination.html#overview-5" id="toc-overview-5"><span class="toc-section-number">5.9.1</span> Overview<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">5.9.2</span> Hierarchical Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">5.9.3</span> K-means Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법" id="toc-군집의-평가방법"><span class="toc-section-number">5.9.4</span> 군집의 평가방법<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14" id="toc-clustering-using-density-estimation-wk14"><span class="toc-section-number">5.9.5</span> Clustering using Density Estimation (wk14)<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds" id="toc-multidimensional-scaling-mds"><span class="toc-section-number">5.9.6</span> Multidimensional Scaling (MDS)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="linear.html#linear" id="toc-linear"><span class="toc-section-number">6</span> Linear<span></span></a>
<ul>
<li><a href="overview-svd.html#overview-svd" id="toc-overview-svd"><span class="toc-section-number">6.1</span> Overview &amp; SVD<span></span></a>
<ul>
<li><a href="overview-svd.html#spectral-decomposition-1" id="toc-spectral-decomposition-1"><span class="toc-section-number">6.1.1</span> Spectral Decomposition<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-general-version" id="toc-singular-value-decomposition-general-version"><span class="toc-section-number">6.1.2</span> Singular value Decomposition: General-version<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-another-version" id="toc-singular-value-decomposition-another-version"><span class="toc-section-number">6.1.3</span> Singular value Decomposition: Another-version<span></span></a></li>
<li><a href="overview-svd.html#quadratic-forms" id="toc-quadratic-forms"><span class="toc-section-number">6.1.4</span> Quadratic Forms<span></span></a></li>
<li><a href="overview-svd.html#partitioned-matrices" id="toc-partitioned-matrices"><span class="toc-section-number">6.1.5</span> Partitioned Matrices<span></span></a></li>
<li><a href="overview-svd.html#geometrical-aspects" id="toc-geometrical-aspects"><span class="toc-section-number">6.1.6</span> Geometrical Aspects<span></span></a></li>
<li><a href="overview-svd.html#column-row-and-null-space" id="toc-column-row-and-null-space"><span class="toc-section-number">6.1.7</span> Column, Row and Null Space<span></span></a></li>
</ul></li>
<li><a href="introduction-1.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.2</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-1.html#what" id="toc-what"><span class="toc-section-number">6.2.1</span> What<span></span></a></li>
<li><a href="introduction-1.html#random-vectors-and-matrices" id="toc-random-vectors-and-matrices"><span class="toc-section-number">6.2.2</span> Random Vectors and Matrices<span></span></a></li>
<li><a href="introduction-1.html#multivariate-normal-distributions" id="toc-multivariate-normal-distributions"><span class="toc-section-number">6.2.3</span> Multivariate Normal Distributions<span></span></a></li>
<li><a href="introduction-1.html#distributions-of-quadratic-forms" id="toc-distributions-of-quadratic-forms"><span class="toc-section-number">6.2.4</span> Distributions of Quadratic Forms<span></span></a></li>
</ul></li>
<li><a href="estimation.html#estimation" id="toc-estimation"><span class="toc-section-number">6.3</span> Estimation<span></span></a>
<ul>
<li><a href="estimation.html#identifiability-and-estimability" id="toc-identifiability-and-estimability"><span class="toc-section-number">6.3.1</span> Identifiability and Estimability<span></span></a></li>
<li><a href="estimation.html#estimation-least-squares" id="toc-estimation-least-squares"><span class="toc-section-number">6.3.2</span> Estimation: Least Squares<span></span></a></li>
<li><a href="estimation.html#estimation-best-linear-unbiased" id="toc-estimation-best-linear-unbiased"><span class="toc-section-number">6.3.3</span> Estimation: Best Linear Unbiased<span></span></a></li>
<li><a href="estimation.html#estimation-maximum-likelihood" id="toc-estimation-maximum-likelihood"><span class="toc-section-number">6.3.4</span> Estimation: Maximum Likelihood<span></span></a></li>
<li><a href="estimation.html#estimation-minimum-variance-unbiased" id="toc-estimation-minimum-variance-unbiased"><span class="toc-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased<span></span></a></li>
<li><a href="estimation.html#sampling-distributions-of-estimates" id="toc-sampling-distributions-of-estimates"><span class="toc-section-number">6.3.6</span> Sampling Distributions of Estimates<span></span></a></li>
<li><a href="estimation.html#generalized-least-squaresgls" id="toc-generalized-least-squaresgls"><span class="toc-section-number">6.3.7</span> Generalized Least Squares(GLS)<span></span></a></li>
</ul></li>
<li><a href="one-way-anova.html#one-way-anova" id="toc-one-way-anova"><span class="toc-section-number">6.4</span> One-Way ANOVA<span></span></a>
<ul>
<li><a href="one-way-anova.html#one-way-anova-1" id="toc-one-way-anova-1"><span class="toc-section-number">6.4.1</span> One-Way ANOVA<span></span></a></li>
<li><a href="one-way-anova.html#more-about-models" id="toc-more-about-models"><span class="toc-section-number">6.4.2</span> More About Models<span></span></a></li>
<li><a href="one-way-anova.html#estimating-and-testing-contrasts" id="toc-estimating-and-testing-contrasts"><span class="toc-section-number">6.4.3</span> Estimating and Testing Contrasts<span></span></a></li>
<li><a href="one-way-anova.html#cochrans-theorem" id="toc-cochrans-theorem"><span class="toc-section-number">6.4.4</span> Cochran’s Theorem<span></span></a></li>
</ul></li>
<li><a href="testing.html#testing" id="toc-testing"><span class="toc-section-number">6.5</span> Testing<span></span></a>
<ul>
<li><a href="testing.html#more-about-models-two-approaches-for-linear-model" id="toc-more-about-models-two-approaches-for-linear-model"><span class="toc-section-number">6.5.1</span> More About Models: Two approaches for linear model<span></span></a></li>
<li><a href="testing.html#testing-models" id="toc-testing-models"><span class="toc-section-number">6.5.2</span> Testing Models<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure" id="toc-a-generalized-test-procedure"><span class="toc-section-number">6.5.3</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-linear-parametric-functions" id="toc-testing-linear-parametric-functions"><span class="toc-section-number">6.5.4</span> Testing Linear Parametric Functions<span></span></a></li>
<li><a href="testing.html#theoretical-complements" id="toc-theoretical-complements"><span class="toc-section-number">6.5.5</span> Theoretical Complements<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure-1" id="toc-a-generalized-test-procedure-1"><span class="toc-section-number">6.5.6</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace" id="toc-testing-single-degrees-of-freedom-in-a-given-subspace"><span class="toc-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace<span></span></a></li>
<li><a href="testing.html#breaking-ss-into-independent-components" id="toc-breaking-ss-into-independent-components"><span class="toc-section-number">6.5.8</span> Breaking SS into Independent Components<span></span></a></li>
<li><a href="testing.html#general-theory" id="toc-general-theory"><span class="toc-section-number">6.5.9</span> General Theory<span></span></a></li>
<li><a href="testing.html#two-way-anova" id="toc-two-way-anova"><span class="toc-section-number">6.5.10</span> Two-Way ANOVA<span></span></a></li>
<li><a href="testing.html#confidence-regions" id="toc-confidence-regions"><span class="toc-section-number">6.5.11</span> Confidence Regions<span></span></a></li>
<li><a href="testing.html#tests-for-generalized-least-squares-models" id="toc-tests-for-generalized-least-squares-models"><span class="toc-section-number">6.5.12</span> Tests for Generalized Least Squares Models<span></span></a></li>
</ul></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">6.6</span> Generalized Least Squares<span></span></a>
<ul>
<li><a href="generalized-least-squares.html#a-direct-solution-via-inner-products" id="toc-a-direct-solution-via-inner-products"><span class="toc-section-number">6.6.1</span> A direct solution via inner products<span></span></a></li>
</ul></li>
<li><a href="flat.html#flat" id="toc-flat"><span class="toc-section-number">6.7</span> Flat<span></span></a>
<ul>
<li><a href="flat.html#flat-1" id="toc-flat-1"><span class="toc-section-number">6.7.1</span> 1.Flat<span></span></a></li>
<li><a href="flat.html#solutions-to-systems-of-linear-equations" id="toc-solutions-to-systems-of-linear-equations"><span class="toc-section-number">6.7.2</span> 2. Solutions to systems of linear equations<span></span></a></li>
</ul></li>
<li><a href="unified-approach-to-balanced-anova-models.html#unified-approach-to-balanced-anova-models" id="toc-unified-approach-to-balanced-anova-models"><span class="toc-section-number">6.8</span> Unified Approach to Balanced ANOVA Models<span></span></a></li>
</ul></li>
<li><a href="#part-21-02" id="toc-part-21-02">(PART) 21-02<span></span></a></li>
<li><a href="network-stats.html#network-stats" id="toc-network-stats"><span class="toc-section-number">7</span> Network Stats<span></span></a>
<ul>
<li><a href="introduction-2.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">7.1</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-2.html#types-of-network-analysis" id="toc-types-of-network-analysis"><span class="toc-section-number">7.1.1</span> Types of Network Analysis<span></span></a></li>
<li><a href="introduction-2.html#network-modeling-and-inference" id="toc-network-modeling-and-inference"><span class="toc-section-number">7.1.2</span> Network Modeling and Inference<span></span></a></li>
<li><a href="introduction-2.html#network-processes" id="toc-network-processes"><span class="toc-section-number">7.1.3</span> Network Processes<span></span></a></li>
</ul></li>
<li><a href="descriptive-statistics-of-networks.html#descriptive-statistics-of-networks" id="toc-descriptive-statistics-of-networks"><span class="toc-section-number">7.2</span> Descriptive Statistics of Networks<span></span></a>
<ul>
<li><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics" id="toc-vertex-and-edge-characteristics"><span class="toc-section-number">7.2.1</span> Vertex and Edge Characteristics<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion" id="toc-characterizing-network-cohesion"><span class="toc-section-number">7.2.2</span> Characterizing Network Cohesion<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#graph-partitioning" id="toc-graph-partitioning"><span class="toc-section-number">7.2.3</span> Graph Partitioning<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing" id="toc-assortativity-and-mixing"><span class="toc-section-number">7.2.4</span> Assortativity and Mixing<span></span></a></li>
</ul></li>
<li><a href="data-collection-and-sampling.html#data-collection-and-sampling" id="toc-data-collection-and-sampling"><span class="toc-section-number">7.3</span> Data Collection and Sampling<span></span></a>
<ul>
<li><a href="data-collection-and-sampling.html#sampling-designs" id="toc-sampling-designs"><span class="toc-section-number">7.3.1</span> Sampling Designs<span></span></a></li>
<li><a href="data-collection-and-sampling.html#coping-strategies" id="toc-coping-strategies"><span class="toc-section-number">7.3.2</span> Coping Strategies<span></span></a></li>
<li><a href="data-collection-and-sampling.html#big-data-solves-nothing" id="toc-big-data-solves-nothing"><span class="toc-section-number">7.3.3</span> Big Data Solves Nothing<span></span></a></li>
</ul></li>
<li><a href="mathematical-models-for-network-graphs.html#mathematical-models-for-network-graphs" id="toc-mathematical-models-for-network-graphs"><span class="toc-section-number">7.4</span> Mathematical Models for Network Graphs<span></span></a>
<ul>
<li><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models" id="toc-classical-random-graph-models"><span class="toc-section-number">7.4.1</span> Classical Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models" id="toc-generalized-random-graph-models"><span class="toc-section-number">7.4.2</span> Generalized Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms" id="toc-network-graph-models-based-on-mechanisms"><span class="toc-section-number">7.4.3</span> Network Graph Models Based on Mechanisms<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics" id="toc-assessing-significance-of-network-graph-characteristics"><span class="toc-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics<span></span></a></li>
</ul></li>
<li><a href="introduction-to-ergm.html#introduction-to-ergm" id="toc-introduction-to-ergm"><span class="toc-section-number">7.5</span> Introduction to ERGM<span></span></a>
<ul>
<li><a href="introduction-to-ergm.html#exponential-random-graph-models" id="toc-exponential-random-graph-models"><span class="toc-section-number">7.5.1</span> Exponential Random Graph Models<span></span></a></li>
<li><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation" id="toc-difficulty-in-parameter-estimation"><span class="toc-section-number">7.5.2</span> Difficulty in Parameter Estimation<span></span></a></li>
</ul></li>
<li><a href="parameter-estimation-of-ergm.html#parameter-estimation-of-ergm" id="toc-parameter-estimation-of-ergm"><span class="toc-section-number">7.6</span> Parameter Estimation of ERGM<span></span></a>
<ul>
<li><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm" id="toc-current-methods-for-ergm"><span class="toc-section-number">7.6.1</span> Current Methods for ERGM<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm" id="toc-approximation-based-algorithm"><span class="toc-section-number">7.6.2</span> Approximation-based Algorithm<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches" id="toc-auxiliary-variable-mcmc-based-approaches"><span class="toc-section-number">7.6.3</span> Auxiliary Variable MCMC-based Approaches<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc" id="toc-varying-trunction-stochastic-approximation-mcmc"><span class="toc-section-number">7.6.4</span> Varying Trunction Stochastic Approximation MCMC<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#conclusion" id="toc-conclusion"><span class="toc-section-number">7.6.5</span> Conclusion<span></span></a></li>
</ul></li>
<li><a href="ergm-for-dynamic-networks.html#ergm-for-dynamic-networks" id="toc-ergm-for-dynamic-networks"><span class="toc-section-number">7.7</span> ERGM for Dynamic Networks<span></span></a>
<ul>
<li><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm" id="toc-temporal-ergm-tergm-t-ergm"><span class="toc-section-number">7.7.1</span> Temporal ERGM (TERGM, T ERGM)<span></span></a></li>
<li><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm" id="toc-separable-temporal-ergm-stergm-st-ergm"><span class="toc-section-number">7.7.2</span> Separable Temporal ERGM (STERGM, ST ERGM)<span></span></a></li>
</ul></li>
<li><a href="latent-network-models.html#latent-network-models" id="toc-latent-network-models"><span class="toc-section-number">7.8</span> Latent Network Models<span></span></a>
<ul>
<li><a href="latent-network-models.html#latent-position-model" id="toc-latent-position-model"><span class="toc-section-number">7.8.1</span> Latent Position Model<span></span></a></li>
<li><a href="latent-network-models.html#latent-position-cluster-model" id="toc-latent-position-cluster-model"><span class="toc-section-number">7.8.2</span> Latent Position Cluster Model<span></span></a></li>
</ul></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#additive-and-multiplicative-effects-network-models" id="toc-additive-and-multiplicative-effects-network-models"><span class="toc-section-number">7.9</span> Additive and Multiplicative Effects Network Models<span></span></a>
<ul>
<li><a href="additive-and-multiplicative-effects-network-models.html#introduction-3" id="toc-introduction-3"><span class="toc-section-number">7.9.1</span> Introduction<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression" id="toc-social-relations-regression"><span class="toc-section-number">7.9.2</span> Social Relations Regression<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models" id="toc-multiplicative-effects-models"><span class="toc-section-number">7.9.3</span> Multiplicative Effects Models<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation" id="toc-inference-via-posterior-approximation"><span class="toc-section-number">7.9.4</span> Inference via Posterior Approximation<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r" id="toc-discussion-and-example-with-r"><span class="toc-section-number">7.9.5</span> Discussion and Example with R<span></span></a></li>
</ul></li>
<li><a href="stochastic-block-models.html#stochastic-block-models" id="toc-stochastic-block-models"><span class="toc-section-number">7.10</span> Stochastic Block Models<span></span></a>
<ul>
<li><a href="stochastic-block-models.html#stochastic-block-model" id="toc-stochastic-block-model"><span class="toc-section-number">7.10.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm" id="toc-mixed-membership-block-model-mmbm"><span class="toc-section-number">7.10.2</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="high-dimension.html#high-dimension" id="toc-high-dimension"><span class="toc-section-number">8</span> High Dimension<span></span></a>
<ul>
<li><a href="introduction-4.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">8.1</span> Introduction<span></span></a></li>
<li><a href="concentration-inequalities.html#concentration-inequalities" id="toc-concentration-inequalities"><span class="toc-section-number">8.2</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities.html#motivation" id="toc-motivation"><span class="toc-section-number">8.2.1</span> Motivation<span></span></a></li>
<li><a href="concentration-inequalities.html#from-markov-to-chernoff" id="toc-from-markov-to-chernoff"><span class="toc-section-number">8.2.2</span> From Markov to Chernoff<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-variables" id="toc-sub-gaussian-random-variables"><span class="toc-section-number">8.2.3</span> sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables" id="toc-properties-of-sub-gaussian-random-variables"><span class="toc-section-number">8.2.4</span> Properties of sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#equivalent-definitions" id="toc-equivalent-definitions"><span class="toc-section-number">8.2.5</span> Equivalent definitions<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-vectors" id="toc-sub-gaussian-random-vectors"><span class="toc-section-number">8.2.6</span> Sub-Gaussian random vectors<span></span></a></li>
<li><a href="concentration-inequalities.html#hoeffdings-inequality" id="toc-hoeffdings-inequality"><span class="toc-section-number">8.2.7</span> Hoeffding’s inequality<span></span></a></li>
<li><a href="concentration-inequalities.html#maximal-inequalities" id="toc-maximal-inequalities"><span class="toc-section-number">8.2.8</span> Maximal inequalities<span></span></a></li>
<li><a href="concentration-inequalities.html#section" id="toc-section"><span class="toc-section-number">8.2.9</span> </a></li>
</ul></li>
<li><a href="concentration-inequalities-1.html#concentration-inequalities-1" id="toc-concentration-inequalities-1"><span class="toc-section-number">8.3</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities-1.html#sub-exponential-random-variables" id="toc-sub-exponential-random-variables"><span class="toc-section-number">8.3.1</span> Sub-exponential random variables<span></span></a></li>
<li><a href="concentration-inequalities-1.html#bernsteins-condition" id="toc-bernsteins-condition"><span class="toc-section-number">8.3.2</span> Bernstein’s condition<span></span></a></li>
<li><a href="concentration-inequalities-1.html#mcdiarmids-inequality" id="toc-mcdiarmids-inequality"><span class="toc-section-number">8.3.3</span> McDiarmid’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#levys-inequality" id="toc-levys-inequality"><span class="toc-section-number">8.3.4</span> Levy’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#quadratic-form" id="toc-quadratic-form"><span class="toc-section-number">8.3.5</span> Quadratic form<span></span></a></li>
<li><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma" id="toc-the-johnsonlindenstrauss-lemma"><span class="toc-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma<span></span></a></li>
</ul></li>
<li><a href="metric-entropy-and-its-uses.html#metric-entropy-and-its-uses" id="toc-metric-entropy-and-its-uses"><span class="toc-section-number">8.4</span> Metric entropy and its uses<span></span></a>
<ul>
<li><a href="metric-entropy-and-its-uses.html#metric-space" id="toc-metric-space"><span class="toc-section-number">8.4.1</span> Metric space<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy" id="toc-covering-numbers-and-metric-entropy"><span class="toc-section-number">8.4.2</span> Covering numbers and metric entropy<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#packing-numbers" id="toc-packing-numbers"><span class="toc-section-number">8.4.3</span> Packing numbers<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#section-1" id="toc-section-1"><span class="toc-section-number">8.4.4</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-2" id="toc-section-2"><span class="toc-section-number">8.4.5</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-3" id="toc-section-3"><span class="toc-section-number">8.4.6</span> </a></li>
</ul></li>
<li><a href="covariance-estimation.html#covariance-estimation" id="toc-covariance-estimation"><span class="toc-section-number">8.5</span> Covariance estimation<span></span></a>
<ul>
<li><a href="covariance-estimation.html#matrix-algebra-review" id="toc-matrix-algebra-review"><span class="toc-section-number">8.5.1</span> Matrix algebra review<span></span></a></li>
<li><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm" id="toc-covariance-matrix-estimation-in-the-operator-norm"><span class="toc-section-number">8.5.2</span> Covariance matrix estimation in the operator norm<span></span></a></li>
<li><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices" id="toc-bounds-for-structured-covariance-matrices"><span class="toc-section-number">8.5.3</span> Bounds for structured covariance matrices<span></span></a></li>
</ul></li>
<li><a href="matrix-concentration-inequalities.html#matrix-concentration-inequalities" id="toc-matrix-concentration-inequalities"><span class="toc-section-number">8.6</span> Matrix concentration inequalities<span></span></a>
<ul>
<li><a href="matrix-concentration-inequalities.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">8.6.1</span> Matrix calculus<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#matrix-chernoff" id="toc-matrix-chernoff"><span class="toc-section-number">8.6.2</span> Matrix Chernoff<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices" id="toc-sub-gaussian-and-sub-exponential-matrices"><span class="toc-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds" id="toc-랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><span class="toc-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds<span></span></a></li>
</ul></li>
<li><a href="principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.7</span> Principal Component Analysis<span></span></a>
<ul>
<li><a href="principal-component-analysis.html#pca-1" id="toc-pca-1"><span class="toc-section-number">8.7.1</span> PCA<span></span></a></li>
<li><a href="principal-component-analysis.html#matrix-perturbation" id="toc-matrix-perturbation"><span class="toc-section-number">8.7.2</span> Matrix Perturbation<span></span></a></li>
<li><a href="principal-component-analysis.html#spiked-cov-model" id="toc-spiked-cov-model"><span class="toc-section-number">8.7.3</span> Spiked Cov Model<span></span></a></li>
<li><a href="principal-component-analysis.html#sparse-pca" id="toc-sparse-pca"><span class="toc-section-number">8.7.4</span> sparse PCA<span></span></a></li>
</ul></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">8.8</span> Linear Regression<span></span></a>
<ul>
<li><a href="linear-regression.html#problem-formulation" id="toc-problem-formulation"><span class="toc-section-number">8.8.1</span> Problem formulation<span></span></a></li>
<li><a href="linear-regression.html#least-squares-estimator-in-high-dimensions" id="toc-least-squares-estimator-in-high-dimensions"><span class="toc-section-number">8.8.2</span> Least Squares Estimator in high dimensions<span></span></a></li>
<li><a href="linear-regression.html#sparse-linear-regression" id="toc-sparse-linear-regression"><span class="toc-section-number">8.8.3</span> Sparse linear regression<span></span></a></li>
</ul></li>
<li><a href="uniform-laws-of-large-numbers.html#uniform-laws-of-large-numbers" id="toc-uniform-laws-of-large-numbers"><span class="toc-section-number">8.9</span> Uniform laws of large numbers<span></span></a>
<ul>
<li><a href="uniform-laws-of-large-numbers.html#motivation-1" id="toc-motivation-1"><span class="toc-section-number">8.9.1</span> Motivation<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity" id="toc-a-uniform-law-via-rademacher-complexity"><span class="toc-section-number">8.9.2</span> A uniform law via Rademacher complexity<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity" id="toc-upper-bounds-on-the-rademacher-complexity"><span class="toc-section-number">8.9.3</span> Upper bounds on the Rademacher complexity<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">9</span> Survival Analysis<span></span></a>
<ul>
<li><a href="introduction-5.html#introduction-5" id="toc-introduction-5"><span class="toc-section-number">9.1</span> Introduction<span></span></a></li>
<li><a href="section-4.html#section-4" id="toc-section-4"><span class="toc-section-number">9.2</span> </a></li>
<li><a href="counting-processes-and-martingales.html#counting-processes-and-martingales" id="toc-counting-processes-and-martingales"><span class="toc-section-number">9.3</span> Counting Processes and Martingales<span></span></a>
<ul>
<li><a href="counting-processes-and-martingales.html#conditional-expectation" id="toc-conditional-expectation"><span class="toc-section-number">9.3.1</span> Conditional Expectation<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#martingale" id="toc-martingale"><span class="toc-section-number">9.3.2</span> Martingale<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#key-martingales-properties" id="toc-key-martingales-properties"><span class="toc-section-number">9.3.3</span> Key Martingales Properties<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#section-5" id="toc-section-5"><span class="toc-section-number">9.3.4</span> </a></li>
<li><a href="counting-processes-and-martingales.html#section-6" id="toc-section-6"><span class="toc-section-number">9.3.5</span> </a></li>
</ul></li>
<li><a href="section-7.html#section-7" id="toc-section-7"><span class="toc-section-number">9.4</span> </a></li>
<li><a href="cox-regression.html#cox-regression" id="toc-cox-regression"><span class="toc-section-number">9.5</span> Cox Regression<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#filtration의-개념을-정복하자" id="toc-filtration의-개념을-정복하자"><span class="toc-section-number">9.6</span> Filtration의 개념을 정복하자!<span></span></a>
<ul>
<li><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약" id="toc-random-process를-이야기-하기까지의-긴-여정의-요약"><span class="toc-section-number">9.6.1</span> Random Process를 이야기 하기까지의 긴 여정의 요약<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#ft-measurable" id="toc-ft-measurable"><span class="toc-section-number">9.6.2</span> Ft-measurable<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#epilogue" id="toc-epilogue"><span class="toc-section-number">9.6.3</span> EPILOGUE<span></span></a></li>
</ul></li>
<li><a href="concepts.html#concepts" id="toc-concepts"><span class="toc-section-number">9.7</span> Concepts<span></span></a></li>
</ul></li>
<li><a href="#part-22-01" id="toc-part-22-01">(PART) 22-01<span></span></a></li>
<li><a href="scikit.html#scikit" id="toc-scikit"><span class="toc-section-number">10</span> scikit<span></span></a>
<ul>
<li><a href="linear-models.html#linear-models" id="toc-linear-models"><span class="toc-section-number">10.1</span> Linear Models<span></span></a>
<ul>
<li><a href="linear-models.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">10.1.1</span> Ordinary Least Squares<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="#appendix-00-00" id="toc-appendix-00-00">(APPENDIX) 00-00<span></span></a></li>
<li><a href="concepts-1.html#concepts-1" id="toc-concepts-1"><span class="toc-section-number">11</span> Concepts<span></span></a>
<ul>
<li><a href="autologistic.html#autologistic" id="toc-autologistic"><span class="toc-section-number">11.1</span> Autologistics<span></span></a></li>
<li><a href="orderlogit.html#orderlogit" id="toc-orderlogit"><span class="toc-section-number">11.2</span> Ordered Logit<span></span></a></li>
<li><a href="concepts-questions.html#concepts-questions" id="toc-concepts-questions"><span class="toc-section-number">11.3</span> Concepts Questions<span></span></a>
<ul>
<li><a href="concepts-questions.html#통계-및-수학" id="toc-통계-및-수학"><span class="toc-section-number">11.3.1</span> 통계 및 수학<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="about-cluster-gcn.html#about-cluster-gcn" id="toc-about-cluster-gcn"><span class="toc-section-number">12</span> About Cluster-GCN<span></span></a>
<ul>
<li><a href="about-cluster-gcn.html#ann" id="toc-ann"><span class="toc-section-number">12.0.1</span> ANN<span></span></a></li>
<li><a href="about-cluster-gcn.html#cnn" id="toc-cnn"><span class="toc-section-number">12.0.2</span> CNN<span></span></a></li>
<li><a href="about-cluster-gcn.html#graph-convolution-network" id="toc-graph-convolution-network"><span class="toc-section-number">12.0.3</span> Graph Convolution Network<span></span></a></li>
<li><a href="about-cluster-gcn.html#cluster-gcn" id="toc-cluster-gcn"><span class="toc-section-number">12.0.4</span> Cluster-GCN<span></span></a></li>
</ul></li>
<li><a href="cnn-1.html#cnn-1" id="toc-cnn-1"><span class="toc-section-number">13</span> CNN<span></span></a></li>
<li><a href="cnn-2.html#cnn-2" id="toc-cnn-2"><span class="toc-section-number">14</span> CNN<span></span></a></li>
<li><a href="cnn-3.html#cnn-3" id="toc-cnn-3"><span class="toc-section-number">15</span> CNN<span></span></a></li>
<li><a href="section-8.html#section-8" id="toc-section-8"><span class="toc-section-number">16</span> 01<span></span></a></li>
<li><a href="section-9.html#section-9" id="toc-section-9"><span class="toc-section-number">17</span> 02<span></span></a></li>
<li><a href="서-론.html#서-론" id="toc-서-론"><span class="toc-section-number">18</span> 서 론<span></span></a>
<ul>
<li><a href="연구-배경.html#연구-배경" id="toc-연구-배경"><span class="toc-section-number">18.1</span> 연구 배경<span></span></a></li>
<li><a href="연구-목적.html#연구-목적" id="toc-연구-목적"><span class="toc-section-number">18.2</span> 연구 목적<span></span></a></li>
</ul></li>
<li><a href="method.html#method" id="toc-method"><span class="toc-section-number">19</span> Method<span></span></a>
<ul>
<li><a href="biterm.html#biterm" id="toc-biterm"><span class="toc-section-number">19.1</span> Biterm<span></span></a>
<ul>
<li><a href="biterm.html#section-10" id="toc-section-10"><span class="toc-section-number">19.1.1</span> 2.1.1<span></span></a></li>
<li><a href="biterm.html#줄-요약" id="toc-줄-요약"><span class="toc-section-number">19.1.2</span> 3줄 요약<span></span></a></li>
<li><a href="biterm.html#section-11" id="toc-section-11"><span class="toc-section-number">19.1.3</span> 2.1.2<span></span></a></li>
<li><a href="biterm.html#latent-space-item-response-model" id="toc-latent-space-item-response-model"><span class="toc-section-number">19.1.4</span> 2.1.3 Latent Space Item Response Model<span></span></a></li>
<li><a href="biterm.html#procrustes-matching-and-oblique-roation" id="toc-procrustes-matching-and-oblique-roation"><span class="toc-section-number">19.1.5</span> Procrustes Matching and Oblique Roation<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="latent-space-item-response-model-구현.html#latent-space-item-response-model-구현" id="toc-latent-space-item-response-model-구현"><span class="toc-section-number">20</span> Latent Space Item Response Model 구현<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브로-모델-설계" id="toc-python-네이티브로-모델-설계"><span class="toc-section-number">20.1</span> 3.1. python 네이티브로 모델 설계<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브에서의-속도-퍼포먼스" id="toc-python-네이티브에서의-속도-퍼포먼스"><span class="toc-section-number">20.1.1</span> 3.1.1. python 네이티브에서의 속도 퍼포먼스<span></span></a></li>
</ul></li>
<li><a href="python에-c-접합한-모델-설계.html#python에-c-접합한-모델-설계" id="toc-python에-c-접합한-모델-설계"><span class="toc-section-number">20.2</span> 3.2. python에 c++ 접합한 모델 설계<span></span></a>
<ul>
<li><a href="python에-c-접합한-모델-설계.html#wrapping-timing" id="toc-wrapping-timing"><span class="toc-section-number">20.2.1</span> Wrapping Timing<span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#library-needed-in-c" id="toc-library-needed-in-c"><span class="toc-section-number">20.2.2</span> Library needed in <code>c++</code><span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#접합-모델-검증-및-성능-비교" id="toc-접합-모델-검증-및-성능-비교"><span class="toc-section-number">20.2.3</span> 3.2.1. 접합 모델 검증 및 성능 비교<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="implementation-1.html#implementation-1" id="toc-implementation-1"><span class="toc-section-number">21</span> Implementation<span></span></a>
<ul>
<li><a href="preprocess.html#preprocess" id="toc-preprocess"><span class="toc-section-number">21.1</span> <code>preprocess()</code><span></span></a></li>
<li><a href="btmize.html#btmize" id="toc-btmize"><span class="toc-section-number">21.2</span> <code>btmize()</code><span></span></a></li>
<li><a href="lsirmize.html#lsirmize" id="toc-lsirmize"><span class="toc-section-number">21.3</span> <code>lsirmize()</code><span></span></a></li>
</ul></li>
<li><a href="구현-모델-실적용-예시.html#구현-모델-실적용-예시" id="toc-구현-모델-실적용-예시"><span class="toc-section-number">22</span> 구현 모델 실적용 예시<span></span></a>
<ul>
<li><a href="데이터-서술.html#데이터-서술" id="toc-데이터-서술"><span class="toc-section-number">22.1</span> 4.1 데이터 서술<span></span></a></li>
<li><a href="알고리즘-결과.html#알고리즘-결과" id="toc-알고리즘-결과"><span class="toc-section-number">22.2</span> 4.2 알고리즘 결과<span></span></a></li>
</ul></li>
<li><a href="결론.html#결론" id="toc-결론"><span class="toc-section-number">23</span> 결론<span></span></a>
<ul>
<li><a href="section-12.html#section-12" id="toc-section-12"><span class="toc-section-number">23.1</span> 10.<span></span></a>
<ul>
<li><a href="section-12.html#stochastic-block-model-1" id="toc-stochastic-block-model-1"><span class="toc-section-number">23.1.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="section-12.html#likelihood-function-1" id="toc-likelihood-function-1"><span class="toc-section-number">23.1.2</span> Likelihood function<span></span></a></li>
<li><a href="section-12.html#mixed-membership-block-model-mmbm-1" id="toc-mixed-membership-block-model-mmbm-1"><span class="toc-section-number">23.1.3</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="auxiliary-variable-mcmc" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Auxiliary Variable MCMC<a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>실전에서 마주치는 대부분의 상황에서 ABC나 HMC 문제를 제외하고는 대부분의 경우 MCMC 문제를 완벽하게 풀어내는 건 불가능. 이때 주어진 variable 말고 보조변수 (Auxiliary Variable)을 추가함으로써 시뮬레이션 품질을 좀 더 높일 수 있지 않을까 하는 것이 논하고자 하는 바.</p>
<div id="introduction" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Introduction<a href="auxiliary-variable-mcmc.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Difficulties with MH Algorithm. 일반적인 MH 알고리즘으로 풀어낼 수 없는 2가지 상황이 존재:
<ol style="list-style-type: decimal">
<li>Local-trap problem: 에너지 계가 울퉁불퉁한 complex system에서 시뮬레이션을 진행했을 때 끝없이 로컬 최적값에서 빠져나오지 못함. 시뮬레이션을 비효율적으로 만듬.
<ul>
<li>density가 높다는 것은 해당 파트의 에너지가 낮다는 것이며, density가 낮은 에너지가 많은 파트에서 high density로 가는 것은 쉽고 자주 일어나도 역은 드뭄. 조밀하면 움직일 여력이 없으니까. 이것이 local trap의 원인</li>
<li>에너지는 이하로 표시 가능: energy function <span class="math inline">\(= -log \pi(\theta \vert x)\)</span>, 즉 negative log posterior, 혹은 negative log density.</li>
</ul></li>
<li>Doubly-intractable normalizing constants problem:
<ul>
<li>Inability to sample from distributions with intractable integrals
<ul>
<li>보통이라면, <span class="math inline">\(pi(\theta \vert x) \propto \kappa(x) f(x\vert\theta)\pi(\theta)\)</span>. <span class="math inline">\(r= \dfrac{pi(\theta &#39; \vert x)}{pi(\theta^{(t)} \vert x)} = \dfrac{\kappa(x) f(x\vert\theta &#39; )\pi(\theta &#39; )}{\kappa(x) f(x\vert\theta^{(t)})\pi(\theta^{(t)})}\)</span> 과정에서 normarlizing constant <span class="math inline">\(\kappa\)</span>가 알아서 캔슬되어 MH 돌리는데 문제가 없음.</li>
</ul></li>
<li>let <span class="math inline">\(f(x) \propto \kappa(x;\theta) \psi(x)\)</span> 는 알고자 하는 분포. 여기서 <span class="math inline">\(\kappa(x)\)</span>는 unnormalized density의 함수. 이때 <span class="math inline">\(\kappa(x)\)</span>는 패러미터의 함수이며 각 이터레이션의 다른 패러미터 추정값마다 변화해버려서 캔슬되지 않음. 그러면 계산하면 되는거 아님? 계산 불가능한 상황 존재 - nearly infinite summation or integration 포함하는 경우. (ex:) 이는 곧 intractable integral. acceptance <span class="math inline">\(Pr\)</span>이 알 수 없는 비 <span class="math inline">\(\frac{\kappa(x&#39;)}{\kappa(x)}\)</span>를 포함하므로 MH 알고리즘은 사용불가. <br> 이러한 문제는 bayesian 추론에서 spatial statistical models, random effects models, 그리고 exponential random graph models 등 다양한 통계적 모형에서 부딪히게 된다.
<ul>
<li>ex: Lattice system of areal model (Lattice의 승만큼 연산 필요)</li>
<li>e.g., <strong>Random Effect Model</strong>. 이때는 각 individual별로 Random Effect를 integration 해줘야 하므로 문제터짐</li>
<li>ex: Exponential Random Graph model: 네트워크에 사용되는 모델. 얘도 power임.</li>
<li>이러한 상황에서는 대부분의 optimization 알고리즘도 다 먹통됨</li>
</ul></li>
</ul></li>
</ol></li>
</ul>
<p><img src = "4-1.png"></p>
<ul>
<li>이러한 2개의 문제점을 극복하기 위해 다양한 진보된 MCMC 방법론이 제시되었음.
<ol style="list-style-type: decimal">
<li>Auxiliary variable-based methods</li>
<li>Population-based methods</li>
<li><del>Importance weight-based methods</del></li>
<li>Stochastic approximation-based methods</li>
</ol></li>
</ul>
<p><br>
<br>
<br></p>
<div id="auxiliary-variable-mcmc-methods" class="section level4 hasAnchor" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> Auxiliary Variable MCMC Methods<a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(f(x)\)</span>를 가지는 mv 분포에서의 샘플링을 생각해보자. <strong>Rao-Blackwellization</strong>(<a href="inference.html#raoblack">#</a>)이 MC 시뮬레이션에의 최우선원칙임은 알려져 있다. 시뮬레이션의 수렴을 좀 더 강화하기 위해 우리는 가능한한 많은 <span class="math inline">\(x\)</span>의 구성물을 integrate하는 것을 시도해보아야 한다. 하지만 이하의 두가지 경우(이외에도 존재)에 시뮬레이션을 양질로 만들기 위해 우리는 1개 이상의 변수를 추가하는 상황을 고려할 수 있다.</p>
<ol style="list-style-type: decimal">
<li>타겟분포 <span class="math inline">\(f(x)\)</span>가 multimodal. 온도 혹은 아직 관측되지 않은 측정값과 같은 auxiliary variable이 계가 <strong>로컬 트랩</strong>에서 빠져나올 수 있도록 도움을 줌. multimodal 상황.</li>
<li>타겟분포 <span class="math inline">\(f(x)\)</span>가 intractable normalizing constant 포함. <span class="math inline">\(X\)</span>의 auxiliary 실현값이 시뮬레이션에 포함됨으로써 시뮬레이션에서 normalizing constant 를 무력화시킴.</li>
</ol>
<p>MH 알고리즘 <span class="math inline">\(\dfrac{ f(\theta &#39; \vert x )}{f(\theta^{(t)} \vert x )} \dfrac{ g(\theta &#39; \rightarrow \theta^{(t)} )}{ g(\theta^{(t)} \rightarrow \theta &#39;)}\)</span>은 이하의 2가지 기본적인 부품을 가지고 있다.</p>
<ol style="list-style-type: decimal">
<li>타겟분포 (左)</li>
<li>proposal 분포 (右)</li>
</ol>
<p>이에 더해서 auxiliary variable 방법론은 이하의 2가지 방법으로 행해질 수 있다. 타겟과 제안 어느쪽에 변수를 추가하는지에 대한 이야기이다.</p>
<ol style="list-style-type: decimal">
<li>타겟분포 augmentation 방법론: Augmenting auxiliary variables to the <strong>target</strong> distribution
<ul>
<li>auxiliary variable <span class="math inline">\(u\)</span>와 조건부 분포 <span class="math inline">\(f(u \rvert x )\)</span>를 정의한다. joint 분포 <span class="math inline">\(f(x,u) = f(u \rvert x) f(x)\)</span>를 만들기 위해. 이후 MH 알고리즘이나 GS를 사용해 <span class="math inline">\((x,u)\)</span>를 업데이트. <span class="math inline">\(f(x)\)</span>의 샘플은 <span class="math inline">\((X, U)\)</span>의 실현값 <span class="math inline">\((x_1, u_1), \cdots, (x_N, u_N)\)</span>를 이용해 marginalization이나 프로젝션 등을 이용해 획득될 수 있다.</li>
</ul></li>
<li>Method of Proposal Distribution Augmentation: Augmenting auxiliary variables to the <strong>proposal</strong> distribution.
<ul>
<li>proposal 분포 <span class="math inline">\(T(x&#39;, u \rvert x)\)</span>를 특정하고, 이의 reversible version <span class="math inline">\(T(x, u \rvert x&#39;)\)</span>도 특정한다. 즉슨 <span class="math inline">\(\int T(x&#39;, u \vert x)du = T(x&#39; \vert x)\)</span>, <span class="math inline">\(\int T(x, u \vert x&#39;)du = T(x \vert x&#39;)\)</span>의 관계가 성립한다.<br> 이제 proposal <span class="math inline">\(T(x&#39;, u \vert x)\)</span> 로부터 후보 (candidate) 샘플 <span class="math inline">\(x&#39;\)</span>를 생산하고, 이를 with probability <span class="math inline">\(\min \left\{ 1, r(x, x&#39;, u) \right \}\)</span>. 이때 <span class="math inline">\(r(x, x&#39;, u) = \dfrac {f(x&#39;)} {f(x)} \dfrac {T(x,u \vert x&#39;)} {T(x&#39;,u \vert x)}\)</span>.</li>
</ul></li>
</ol>
<p>실현값 (realizations) <span class="math inline">\(x_1 , \cdots, x_N\)</span>을 생산할 때까지 이를 반복한다. 이제 <span class="math inline">\(N\)</span>이 충분히 크다면, 이 실현값들은 근사적으로 <span class="math inline">\(f(x)\)</span>에 의해 분포되어 있다.</p>
<p>이러한 방법론의 타당성은 이하를 통해 보일 수 있다.</p>
<p><span class="math display">\[
K(x&#39; \vert x) = \int_{\mathcal{u}} s(x, x&#39;, u) du + \mathbf{1}(x=x&#39;) \left[ 1-\int_{\mathcal{X}}\int_{\mathcal{u}} s(x, x&#39;, u) du dx&#39; \right]
\]</span></p>
<p>이는 <span class="math inline">\(x\)</span>로부터 <span class="math inline">\(x&#39;\)</span>로의 <strong>integrated transition kernel</strong> 을 의미하며, 이때 <span class="math inline">\(s(x, x&#39;, u) = T(x&#39;, u \rvert x) \ast r(x, x&#39;, u)\)</span>. Then,</p>
<p><span class="math display">\[
f(x) \int_{\mathcal{u}} s(x, x&#39;, u) du = \int_{\mathcal{u}} \min \left[ f(x&#39;) T(x, u \vert x&#39;), \; \; f(x)T(x&#39;, u \vert x) \right] du
\]</span></p>
<p>이는 <span class="math inline">\(x\)</span>와 <span class="math inline">\(x&#39;\)</span> 에 대해 symmetric. 이는 곧 <span class="math inline">\(f(x)K(x&#39; \vert x) = f(x&#39;)K(x \vert x&#39;)\)</span> 임을 의미한다.</p>
<p>original density?</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="multimodal-target-distribution" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Multimodal Target Distribution<a href="auxiliary-variable-mcmc.html#multimodal-target-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br>
<br>
<br></p>
<div id="simulated-tempering" class="section level4 hasAnchor" number="4.4.2.1">
<h4><span class="header-section-number">4.4.2.1</span> Simulated Tempering<a href="auxiliary-variable-mcmc.html#simulated-tempering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>분포 <span class="math inline">\(f(x) \propto \exp \left(-H(x) \right), x \in X\)</span> 에서 샘플링하는데에 관심이 있다고 하자. simulated annealing에서 그러했던 것처럼, simulated tempering <span class="math inline">\(f(x, T) \propto \exp \left( -\dfrac {H(x)} {T} \right)\)</span>로 타겟 분포를 확장시켰다. 이는 auxiliary variable인 temperture <span class="math inline">\(T\)</span>를 포함함으로서 이루어진다. <span class="math inline">\(T\)</span>는 <strong>사용자가 미리 지정한 값들의 finite set</strong>이 된다. <span class="math inline">\(H(x)\)</span>는 사실상 energy function.</p>
<p>Temperature Transition Matrix <span class="math inline">\(T = \begin{bmatrix} q_{11} &amp; q_{12} &amp; \cdots &amp; q_{1n} \\ q_{21} &amp; \ddots &amp; &amp; \\ \vdots &amp; &amp; \ddots &amp; \\ q_{n1} &amp; \cdots &amp; &amp; q_{nn} \end{bmatrix}\)</span>. 이때 row는 current 온도 <span class="math inline">\(T_1, \cdots, T_n\)</span>, column은 행선지 온도.</p>
<hr />
<p><strong>Parallel Tempering</strong>은 인접한 온도로만 이동 가능 (가장 높은 온도에서 가장 낮은 온도로 한단계 한단계씩). 온도 자체를 시뮬레이션한게 아니라 온도의 chain이 주어져 있어 각 온도 간의 움직임을 만드는 것에 그친다. 따라서 이는 multiple chain을 이용하는 population MC 방법론 쪽에 소속됨.</p>
<p>Simulated Tempering과는 이 점에서 차이를 보임. 후자는 어느 온도로든 다 이동. 온도 매트릭스 만들어놓고, <span class="math inline">\(U(0,1)\)</span> 분포에서 온도 하나 생산하고 이 온도로 이동할 것인지의 여부를 MH 알고리즘으로 결정.</p>
<hr />
<p><span class="math inline">\(U(0,1)\)</span>에서 랜덤하게 숫자를 뽑고, <span class="math inline">\(j\)</span>의 값을 proposal transition matrix <span class="math inline">\((q_{ij})\)</span>에 따라서 정한다. <span class="math inline">\(u&lt;q_{11}\)</span>이면 <span class="math inline">\(T_1 \rightarrow T_1\)</span>, <span class="math inline">\(q_{11}&lt;u&lt;q_{11} + q_{12}\)</span>이면 <span class="math inline">\(T_1 \rightarrow T_2\)</span>, ….
- if <span class="math inline">\(j=i_t\)</span>, let <span class="math inline">\(i_{t+1}=i_t\)</span>, and let <span class="math inline">\(x_{t+1}\)</span>을 MH kernal <span class="math inline">\(K_{i_t}(x,y)\)</span>에서 뽑는다. 이때 <span class="math inline">\(K_{i_t}(x,y)\)</span>는 <span class="math inline">\(f(x, T_{i_t})\)</span>을 invariant distribution로 허용하는 아이이다. 즉 새로운 <span class="math inline">\(x\)</span>를 생산하면 된다.
- if <span class="math inline">\(j \not= i_t\)</span>, let <span class="math inline">\(x_{t+1}=x_t\)</span>하고 proposal을 이하의 <span class="math inline">\(Pr\)</span>에 따라 채택한다. 이때 <span class="math inline">\(Z\)</span>는 <span class="math inline">\(Z_i\)</span>의 측정값이다. 채택된다면 <span class="math inline">\(i_{t+1} = j\)</span>이고, 그외의 경우에는 <span class="math inline">\(i_{t+1} = i_t\)</span>로 한다. 새로운 <span class="math inline">\(x\)</span>를 생산하는 것이 아니라 들고 있던 <span class="math inline">\(x\)</span>를 쓰되, 이걸 accept 할건지 안할건지를 체크한다.</p>
<p><span class="math display">\[
\min \left[
1, \; \;
\dfrac {\hat Z_j} {\hat Z_{i_t}} \ast \exp \right \{
-H(x) \left( \dfrac{1}{T_j}-\dfrac{1}{T_{i_t}} \right)
\left \}
\cdot
\dfrac {q_{j,i_t}} {q_{i_t , j}}
\right]
\]</span></p>
<p>이때 <span class="math inline">\(\dfrac {q_{j,i_t}} {q_{i_t , j}}\)</span> 는 proposal distribution이라고 생각할 수 있다. 나머지는 Likelihood part이며, 이때 <span class="math inline">\(\dfrac {\hat Z_j} {\hat Z_{i_t}}\)</span> 가 normalizing constant의 ratio이다. 온도가 변화하였으므로 두 식의 normalizing constant가 같지 않기 때문이다.</p>
<p><br>
<br></p>
<hr />
<p><del><strong>Issues on Simulated Tempering:</strong></del></p>
<ol style="list-style-type: decimal">
<li><strong>Temperature Ladder를 어떻게 고를 것인가.</strong> → 각 chain별로 이동이 원활하게 잡는 것이 핵심.
<ul>
<li>가장 높은 온도 <span class="math inline">\(T_1\)</span>은 대부분의 uphill move가 해당 레벨에서 accept 될 수 있도록 설정되어야 한다.</li>
<li>사이의(intermediate) 온도들은 sequential manner로 설정될 수 있다. <span class="math inline">\(T_1\)</span>에서 시작해서, 점차적으로 다음으로 낮은 온도를 <span class="math inline">\(Var_i \left\{ H(x) \right\} \ast \delta^2 = O(1)\)</span>을 만족하도록 설정하는 것이다. 이때 <span class="math inline">\(\delta = \dfrac {1}{T_{i+1}} - \dfrac{1}{T_i}\)</span>이며, <span class="math inline">\(Var_i(\cdot)\)</span>은 <span class="math inline">\(H(x)\)</span> (taken with respect to <span class="math inline">\(f(x, T_i)\)</span>) 의 분산을 의미한다.
<ul>
<li>이러한 조건들은 <span class="math inline">\(f(x,T_i), f(x,T_{i+1})\)</span> 사이에 상당히 겹치는 점이 많아야 한다는 것을 의미하기도 한다. 실전에선 <span class="math inline">\(Var_i \left( H(x) \right)\)</span>는 샘플러를 레벨 <span class="math inline">\(T_i\)</span>에서 예비적으로(preliminary) 돌려보았던 결과에서 러프하게나마 예측될 수 있다.<br />
</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(Z_i\)</span>를 어떻게 estimate 할 것인가.</strong> → accept 여부가 normalizing constant에도 의존해서 이거 이상하게 고르면 효율 떨어짐. 엄청난 단점이라서 요즘은 이 알고리즘 자체를 잘 안씀
<ul>
<li>이는 simulated tempering의 효율에 직결되는 부분이다. <span class="math inline">\(Z_i\)</span>들이 잘 estimate 되었다면, simulated tempering은 temperature ladder을 따라 <strong>symmetric RW</strong>처럼 동작한다. (<span class="math inline">\(x\)</span>-updating step을 제하고 볼 경우) 그렇지 않다면 이는 특정 temperature 레벨에서 멈춰버린다. 시뮬레이션이 실패함은 물론이다(rendering). <br> 실전에서 <span class="math inline">\(Z_i\)</span>들은 stochastic approximation MC 방법론을 사용해서 estimate 가능하다. 혹은 reverse logistic regression 방법론을 사용해서도 <span class="math inline">\(Z_i\)</span>를 estimate 할 수 있다.</li>
</ul></li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="slice-sampler" class="section level4 hasAnchor" number="4.4.2.2">
<h4><span class="header-section-number">4.4.2.2</span> Slice Sampler<a href="auxiliary-variable-mcmc.html#slice-sampler" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>density <span class="math inline">\(f(x), \; \; \; x \in \mathcal X\)</span>에서 샘플링하고자 한다. <span class="math inline">\(x \sim f(x)\)</span>에서 샘플링하는 것은, <span class="math inline">\(f(x)\)</span> 그래프 이하의 영역에서 uniform하게 샘플링하는 것과 동등하다. 해당 영역은 <span class="math inline">\(A = \{ (x,u): 0 \le u \le f(x) \}\)</span>이며, 이것이 acceptance-rejection 알고리즘의 기초(basis)였다. 이 목적을 달성하기 위해 우리는 타겟분포 <span class="math inline">\(f\)</span>를 auxiliary variable <span class="math inline">\(U\)</span>를 사용하여 확장해볼 수 있다. 이 <span class="math inline">\(U\)</span>는, <span class="math inline">\(x\)</span>에 대해서 조건부일 때, 구간 <span class="math inline">\([0, f(x)]\)</span>에서 uniform하게 분포되어 있다.</p>
<p><img src="4-2.png"></p>
<p>따라서, <span class="math inline">\((X, U)\)</span>의 joint density function은 <span class="math inline">\(f(x,u)=f(x)f(u \rvert x) \propto I_{(x,u)\in \textit A}\)</span>. 후자의 인디케이터는 언급되었던 영역 안에 속한다는 의미. 이는 GS에 의해 이하와 같이 샘플링 가능하다.</p>
<ol style="list-style-type: decimal">
<li>draw <span class="math inline">\(u_{t+1} \sim U[0, f(x_t)]\)</span>.</li>
<li>draw <span class="math inline">\(x_{t+1}\)</span> uniformly from the region <span class="math inline">\(\{ x: f(x) \ge u_{t+1} \}\)</span>.</li>
</ol>
<p>위의 샘플러는 <strong>slice sampler</strong>라고 불림. 이는 multimodal 분포들에 대해 단순 MH 알고리즘보다 더 나을 가능성이 있음. slice 때문에 b/w-mode-transition에 자유롭기 때문. 현재도 핫한 샘플러중 하나임. horseshoe prior 에서의 패러미터 estimate에 대표적으로 이녀석이 쓰인다.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="doubly-intractable-normalizing-constants" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Doubly-intractable Normalizing Constants<a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Spatial models, e.g., the autologistic model, the Potts model, and the autonormal model (Besag, 1974)는 많은 과학적 문제들을 위한 모델링에 쓰이고 있음. 이러한 모델들에 해당하는 주요한 문제는 normalizing constant가 doubly-intractable하다는데 있음.</p>
<p>for dataset <span class="math inline">\(X\)</span>, 패러미터 <span class="math inline">\(\theta\)</span>, normalizing constant <span class="math inline">\(\kappa (\theta)\)</span>. 이때 <span class="math inline">\(\kappa (\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 의존하나 closed form으로는 만들 수 없음. 이하는 dataset을 생산한 likelihood function.</p>
<p><span class="math display">\[
\begin{align*}
X \sim f(x \vert \theta) = \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \}, &amp;x \in \mathcal{X}, &amp;\theta \in \Theta
\end{align*}
\]</span></p>
<p><span class="math inline">\(\pi(\theta)\)</span>는 <span class="math inline">\(\theta\)</span>의 prior. 이 경우 post는 <span class="math inline">\(f(\theta \vert x) \propto \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \} \ast \pi(\theta)\)</span>.</p>
<p><br>
<br>
<br></p>
<div id="ising" class="section level4 hasAnchor" number="4.4.3.1">
<h4><span class="header-section-number">4.4.3.1</span> Boltzmann Density<a href="auxiliary-variable-mcmc.html#ising" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>known as <strong>Ising Model</strong>, 그리고 ~로 확장될 경우 <strong><a href="autologistic.html#autologistic">autologistic model</a></strong>.</p>
<p>Consider a 2-D Ising model with the Boltzmann density</p>
<p><span class="math display">\[
f(\pmb x) \propto \exp \left\{ K \sum_{i\sim j} x_i x_j \right\}
\]</span></p>
<ul>
<li>spins <span class="math inline">\(x_i = \pm 1\)</span> (S극이 -1)</li>
<li><span class="math inline">\(K\)</span>는 inverse temperature (measure for interaction : <span class="math inline">\(x_i\)</span>가 주변에 있는 값과 얼마나 많은 같은 값을 가지는지, 다른 값을 가지는지에 대해 측정해주는 패러미터) 온도가 낮을수록 interaction가 강해지며, 이에 의해 동일값 확률이 높아짐.</li>
<li><span class="math inline">\(i\sim j\)</span>는 lattice 상의 가장 가까운 neighbors.</li>
</ul>
<p>온도가 높다면, 이 모델은 GS를 사용해 쉽게 시뮬레이션 가능하다. 조건부 분포에 따라 각 spin의 값을 iteratively 초기화한다. 아래의 식에서 <span class="math inline">\(n(i)\)</span>는 spin <span class="math inline">\(i\)</span>의 neighbors의 집합 (set). 이하의 수식은 autologistic 과 그 과정이 유사하다.</p>
<p>$$
<span class="math display">\[\begin{align*}

P(x_i =1 \vert x_j, \; \; j \in n(i)) &amp;= \dfrac {1}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} \\
P(x_i =-1 \vert x_j, \; \; j \in n(i)) &amp;= \dfrac {\exp \left \{ -2K \sum_{j \in n(i)} \right\}}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} &amp;= 1- P(x_i =1 \vert x_j, \; \; j \in n(i))

\end{align*}\]</span>
$$</p>
<p>하지만, GS는 temperature가 critical temperature로 근접하거나 이하로 내려갈 경우 GS가 빠르게 느려진다. 온도가 낮으면 interaction이 강해져, 주변값과 비슷한 값을 generate 해야만 하기 때문이다. 이렇게 샘플링이 어려워지는 지점, 온도를 <strong>critical point</strong>라고 부른다. 이는 대략 <span class="math inline">\(\theta \approx 0.43\)</span>. 이것이 소위 <strong>critical slowing down</strong> 이라고 불리는 현상이다.</p>
<p><br></p>
<div id="perfect-sampler" class="section level5 hasAnchor" number="4.4.3.1.1">
<h5><span class="header-section-number">4.4.3.1.1</span> Perfect Sampler<a href="auxiliary-variable-mcmc.html#perfect-sampler" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>과거 샘플들의 굉장히 많은 조합을 커플링해서 샘플을 생산. previous realization 전체에 대해 (이는 그 이전의 샘플, 아니면 그 이전의 샘플, 혹은 original 데이터에 대해서조차도) independent한 샘플을 생산해내는 sampler. 즉 그 어떤 것에서도 independent한 sample을 생산해낸다. 문제는 이 샘플러는 <span class="math inline">\(\theta&gt;0.43\)</span>인 순간 바로 작동을 안함. <span class="math inline">\(\theta&gt;0.32, 0.35\)</span> 정도로 엔간 크기만 해도 드럽게 느림.</p>
<p><br></p>
</div>
<div id="swendsen-wang-algorithm" class="section level5 hasAnchor" number="4.4.3.1.2">
<h5><span class="header-section-number">4.4.3.1.2</span> Swendsen-Wang Algorithm<a href="auxiliary-variable-mcmc.html#swendsen-wang-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>slice sampling에서 Boltzmann 덴시티는 이하의 형으로 다시 쓰여진다. 이때 <span class="math inline">\(\beta = 2K\)</span>. indicator function으로 변형했을 때 저 둘이 어떻게 equation이 성립하는지 유의.</p>
<p><span class="math display">\[
f(\pmb x)
\; \propto
\; \prod_{i\sim j} \exp \left\{ K(1+x_i x_j) \right\}
\;  =
\; \prod_{i\sim j} \exp \left\{ \beta \ast
\mathbf{1}(x_i = x_j)
\right\}
\]</span></p>
<p>이때 우리가 auxiliary variable <span class="math inline">\(\pmb u = (u_{i \sim j})\)</span>, where each component <span class="math inline">\(u_{i \sim j}\)</span>, conditional on <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>, is uniformly distributed on <span class="math inline">\(\left[ 0, \; \exp \{\beta \ast \mathbf{1}(x_i = x_j)\} \right]\)</span>, then</p>
<p><span class="math display">\[
f(\pmb x, \pmb u)
\; \propto  \;
\prod_{i \sim j} \mathbf{1} \left( 0 \le u_{i \sim j } \le \exp\left\{ \beta \ast \mathbf{1} (x_i = x_j) \right\} \right)
\]</span></p>
<p>이때 <span class="math inline">\(u_{i \sim j}\)</span> 자체는 <strong>bond variable</strong>이라고 명명된다. 이는 spin <span class="math inline">\(i\)</span>와 spin <span class="math inline">\(j\)</span> 사이의 가장자리에 물리적으로 앉아 있는 변수로서 생각될 수 있다. (i와 j가 묶여져 있는지, 같은 group 안에 존재하는 것인지 아닌지에 대한 indicator가 되는 variable)</p>
<ul>
<li>if <span class="math inline">\(u_{i \sim j}&gt;1\)</span>, then <span class="math inline">\(\exp \left\{ \beta \ast \mathbf{1}(x_i = x_j) \right \}&gt;1\)</span>, 따라서 반드시 <span class="math inline">\(x_i = x_j\)</span>.</li>
<li>if <span class="math inline">\(u_{i \sim j}&lt;1\)</span>, 이 경우 <span class="math inline">\(x_i, x_j\)</span>에 제약 (constraint) 이 없다.</li>
</ul>
<p><span class="math inline">\(b_{i \sim j}\)</span>가 제약에 대한 indicator variable이라고 정의하자. 즉, <span class="math inline">\(x_i, x_j\)</span>가 같도록 제약되었다면, <span class="math inline">\(b_{i \sim j}=1\)</span>이며 이외엔 0이다. for any 2개의 “like-spin” (i.e. 2개의 spin이 같은 값을 가진다) neighbors에 대해서, 이 둘은 with probability <span class="math inline">\(1-\exp (-\beta)\)</span>를 따라 bonded 될 수 있는 가능성이 있음을 기억하라. <span class="math inline">\(\pmb u\)</span>의 설정 (configuration)에 따라, “mutual bond” (i.e., <span class="math inline">\(b_{i \sim j}=1\)</span>) 을 통하여 연결될 수 있는지 없는지 여부에 따라 spin들을 군집 (cluster) 할 수 있다. (위에서 i와 j가 같다고 indicator가 판별했을 경우에만 이런 cluster 로 묶는 것이 가능하다) Then 동일 클러스터 내의 모든 spin은 같은 값을 가질 것이다. 또한 군집 내부의 모든 spin을 동시에 뒤집는 (flip) 것은 <span class="math inline">\(f(\pmb x , \pmb u)\)</span>의 평형 (equilibrium)을 해치지 않을 것이다.</p>
<p><br></p>
<p>Proceeds:</p>
<ol style="list-style-type: decimal">
<li>Update the bond values: check all “like-spin” neighbors, and set <span class="math inline">\(b_{i \sim j}=1\)</span> with probability <span class="math inline">\(1-\exp (-\beta)\)</span>.</li>
<li>Update the spin values: Cluster spins by connecting neighboring sites with a mutual bond, and then flip each cluster with probability <span class="math inline">\(0.5\)</span>.</li>
</ol>
<p>For the Ising model, the introduction of the auxiliary variable <span class="math inline">\(\pmb u\)</span> has the dependence between neighboring spins partially decoupled, and the resulting sampler can thus converge substantially faster than the single site updating algorithm. As demonstrated by Swendsen and Wang (1987), this algorithm can eliminate much of the <strong>critical slowing down</strong>.</p>
<p><img src = "4-3.png"></p>
<p>같은 값들이 모여있는 cluster를 판별하여 각각을 grouping. grouping을 랜덤으로 하므로 인접해 있는 동일값임에도 그룹에 포함되지 못하는 경우가 존재함. Swendsen-Wang에서는 이렇게 그룹을 만든 후, 해당 그룹을 통채로 toggling. group을 통채로 토글링하기 때문에 dependency가 있는 것들이 통채로 toggling되어서 dependency가 있는 것들은 나머지 것들과 인제 이렇게 independent한 것도 있지만 dependent한 것을 통채로 묶어서 하는 것이므로 좀더 한꺼번에 뒤집으니까 실제로 우리가 업데이트하는 것은 group 내부 말고 group 외부 간들에는 independent하다고 가정될 수 있는 몇몇개의 group들만이 남음. 이 덩어리들을 한꺼번에 업데이트하므로 따라서 샘플러 generate가 상대적으로 쉬움. 하지만 이 만든 덩어리는 매 이터레이션마다 덩어리를 새로 만들어야 함. 매 이터레이션마다 클러스터를 새로 만들고 flip하여 이를 accept할지 말지를 결정하는 이런 형태의 구조를 가짐.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="møollers-algorithm" class="section level4 hasAnchor" number="4.4.3.2">
<h4><span class="header-section-number">4.4.3.2</span> <del>Møoller’s Algorithm</del><a href="auxiliary-variable-mcmc.html#møollers-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>auxiliary variable <span class="math inline">\(y\)</span>, 이는 <span class="math inline">\(x\)</span>와 같은 state space를 공유한다고 정의. 그 경우 이하의 joint pdf <span class="math inline">\(f\)</span> 를 생각해볼 수 있다. <span class="math inline">\(f(y \vert \theta , x)\)</span>는 <span class="math inline">\(y\)</span>의 분포.</p>
<p><span class="math display">\[
f(\theta, y \vert x) = f(x \vert \theta) \ast f(\theta) \ast f(y \vert \theta , x)
\]</span></p>
<p><span class="math inline">\(f(\theta, y \vert x)\)</span> 에서 MH 알고리즘을 통해 시뮬레이트하기 위해서는 이하와 같은 제안분포 <span class="math inline">\(q\)</span> 를 사용해볼 수 있다. 이는 패러미터 벡터 <span class="math inline">\(\theta \rightarrow \theta&#39;\)</span>의 usual change에 상응하며, 이 후에는 <span class="math inline">\(q(\cdot \vert \theta &#39; )\)</span>에서 <span class="math inline">\(y&#39;\)</span>를 추출하는 exact sampling step이 따른다.</p>
<p>$$
q(’ , y’ , y) = q(‘, y) q(y’ ’)
$ $</p>
<p><span class="math inline">\(q(y&#39; \vert \theta &#39; )\)</span>가 <span class="math inline">\(f(y&#39; \vert \theta)\)</span>로 설정되었다면, MH ratio <span class="math inline">\(r\)</span>은 이하와 같이 쓰일 수 있다. 이때 unknown normalizing constant <span class="math inline">\(\kappa(\theta)\)</span>가 상쇄 (cancel) 되었음에 주목하라.</p>
<p>$$
<span class="math display">\[\begin{align*}

r(\theta, y, \theta&#39;, y&#39; \vert x)

&amp;=


\dfrac
{f(x \vert \theta&#39;) f(\theta&#39;) f(y&#39; \vert \theta&#39; , x) \ast q(\theta\vert \theta&#39; , y&#39;) q(y \vert \theta)}
{f(x \vert \theta) f(\theta) f(y \vert \theta , x) \ast q(\theta&#39;\vert \theta , y) q(y&#39; \vert \theta&#39;)}

\\

&amp;=

\dfrac {f(\theta&#39;, y&#39; \vert x)}{f(\theta, y \vert x)} \ast
\dfrac {q(\theta , y \vert \theta&#39; , y&#39;))}{q(\theta&#39; , y&#39; \vert \theta , y)}


\\
&amp;=

\dfrac
{
\dfrac {f(\theta&#39;, y&#39; \vert x)}{q(\theta&#39; , y&#39; \vert \theta , y)}
}
{
\dfrac{f(\theta, y \vert x) }{q(\theta , y \vert \theta&#39; , y&#39;))}
}



\end{align*}\]</span>
$$</p>
<p>여기서 계산을 간단하게 하기 위해 제안분포 <span class="math inline">\(q\)</span>와 auxiliary distribution을 이하와 같이 정리하는 것을 생각해볼 수 있다. 이때 <span class="math inline">\(\hat \theta\)</span>는 <span class="math inline">\(\theta\)</span>의 estimate로써, 예를 들어 pseudo-likelihood function을 극대화하는 것으로 얻어진 값이다.</p>
<p>$$
<span class="math display">\[\begin{align*}

q(\theta&#39; \vert \theta , y) &amp;= q(\theta&#39; \vert \theta ) , q(\theta \vert \theta &#39;, y&#39;) &amp;= q(\theta \vert \theta &#39;) \\

f(y \vert \theta , x) &amp;= f(y \vert \hat \theta ), f(y&#39; \vert \theta&#39; , x) &amp;= f(y&#39; \vert \hat \theta )

\end{align*}\]</span>
$$</p>
<p>분포 <span class="math inline">\(f(x \vert \theta)\)</span>를 auxiliary variable, 가령 normalizing constant ratio <span class="math inline">\(\dfrac {\kappa(\theta)} {\kappa(\theta&#39;)}\)</span> 등으로 살찌워놓은 것은, 시뮬레이션 진행 과정에서 상쇄시키는 것이 가능하다.</p>
<ol style="list-style-type: decimal">
<li>generate <span class="math inline">\(\theta \sim q(\theta&#39; \vert \theta_t)\)</span></li>
<li>generate exact sample <span class="math inline">\(y&#39; \sim f(y \vert \theta&#39;)\)</span></li>
<li>accept <span class="math inline">\((\theta&#39;, y&#39;)\)</span> with probability <span class="math inline">\(\min (1, r)\)</span>, <span class="math inline">\(r=\dfrac {f(x \vert \theta&#39;) f(\theta&#39;) f(y&#39; \vert \hat \theta&#39;) \ast q(\theta_t \vert \theta&#39;) q(y \vert \theta_t)} {f(x \vert \theta_t) f(\theta_t) f(y \vert \hat \theta) \ast q(\theta&#39;\vert \theta_t) q(y&#39; \vert \theta&#39;)}\)</span>.
<ul>
<li>채택된다면, set <span class="math inline">\((\theta_{t+1}, y_{t+1}) = (\theta&#39;, y&#39; )\)</span>.</li>
<li>o.w., <span class="math inline">\((\theta_{t+1}, y_{t+1}) = (\theta_t, y&#39;_t)\)</span>.</li>
</ul></li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="exchange-algorithm" class="section level4 hasAnchor" number="4.4.3.3">
<h4><span class="header-section-number">4.4.3.3</span> Exchange Algorithm<a href="auxiliary-variable-mcmc.html#exchange-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Møller’s 알고리즘을 <strong>parallel tempering</strong> 개념을 도입하여 개선.</p>
<ol style="list-style-type: decimal">
<li>propose candidate point $’ $ proposal distribution <span class="math inline">\(q(\theta&#39; \vert \theta, x)\)</span>.</li>
<li>propose auxiliary variable <span class="math inline">\(y \sim\)</span> perfect sampler <span class="math inline">\(f(y \vert \theta &#39; )\)</span>.</li>
<li>accept $’ $ with probability <span class="math inline">\(\min \{ 1, r(\theta, \theta&#39; \vert x) \}\)</span>.
<ul>
<li><span class="math inline">\(r(\theta, \theta&#39; \vert x) = \dfrac{\pi(\theta&#39;) }{\pi(\theta) } \ast \dfrac{f(x \vert \theta &#39;) }{f(x \vert \theta)} \ast \dfrac{f(y \vert \theta) }{f(y \vert \theta&#39;)} \ast \dfrac{f(\theta \; \vert \theta&#39;, x) }{f(\theta&#39; \vert \theta, x)}\)</span></li>
</ul></li>
</ol>
<p>The exchange algorithm can be viewed as an auxiliary variable MCMC algorithm with the proposal distribution being augmented, for which the proposal distribution can be written as</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

T \left( \theta \rightarrow (\theta&#39; , y) \right) &amp;= q(\theta &#39; \vert \theta) f(y \vert \theta &#39;) \\
T \left( \theta&#39; \rightarrow (\theta , y) \right) &amp;= q(\theta \vert \theta &#39; ) f(y \vert \theta)


\end{align}\]</span>
$</p>
<p>This simply validates the algorithm, following the arguments for auxiliary variable Markov chains.</p>
<p>The exchange algorithm generally improves the performance of the Møller algorithm, as it avoids an initial estimation step (for <span class="math inline">\(\theta\)</span>) that required by the Møller.</p>
<p>Although the Møller’s and exchange algorithms work well for some discrete models, such as the Ising and autologistic models, they cannot be applied to many other models for which perfect sampling is not available.</p>
<p>Even for the Ising and autologistic models, perfect sampling may be very expensive when the temperature is near or below the critical point.</p>
<hr />
</div>
<div id="adaptive-exchange-algorithm" class="section level4 hasAnchor" number="4.4.3.4">
<h4><span class="header-section-number">4.4.3.4</span> Adaptive Exchange Algorithm<a href="auxiliary-variable-mcmc.html#adaptive-exchange-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Object: An adaptive exchange algorithm (AEX) is an adaptive Monte Carlo version of the exchange algorithm, where the auxiliary variables are generated via an importance sampling procedure from a Markov chain running in parallel.</p>
<ul>
<li>Advantage
<ul>
<li>Removes the requirement of perfect sampling</li>
<li>Overcomes its theoretical difficulty caused by inconvergence of finite MCMC runs</li>
</ul></li>
</ul>
<p>AEX consists of two chains running in parallel.</p>
<p>The first chain is <strong>auxiliary</strong>, which is run in the space <span class="math inline">\({\mathcal{x}}\)</span> with an aim to draw samples from a family of distributions <span class="math inline">\(f(X \vert \theta^{(1)}), \; \; \cdots, \; \; f(X \vert \theta^{(m)})\)</span> for a set of pre-specified parameter values <span class="math inline">\(\theta^{(1)}, \; \cdots, \; \theta^{(m)}\)</span>.</p>
<p>The second chain is the <strong>target</strong> chain, which is run in the space <span class="math inline">\(\theta\)</span> with an aim to draw samples from the target posterior <span class="math inline">\(\pi(\theta \vert y)\)</span>. For a candidate point <span class="math inline">\(\theta&#39;\)</span>, the auxiliary variable <span class="math inline">\(x\)</span> is resampled from the past samples of the auxiliary chain via an importance sampling procedure.</p>
<p>Assume that the neighboring distributions <span class="math inline">\(f(X \vert \theta^{(i)})\)</span>’s have a reasonable overlap and the set <span class="math inline">\(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\)</span> has covered the major part of the support of <span class="math inline">\(\pi (\theta \vert y)\)</span>.</p>
<ul>
<li>ALGORITHM: PART 1 - (Auxiliary Chain) Auxiliary Sample Collection via SAMC</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>(Sampling) Choose to update <span class="math inline">\(\vartheta\)</span> or <span class="math inline">\(\pmb z_t \vert \vartheta\)</span> with pre-specified probabilities, e.g., <span class="math inline">\(0.75\)</span> for updating <span class="math inline">\(\vartheta\)</span> and <span class="math inline">\(0.25\)</span> for updating <span class="math inline">\(z_t\)</span>.</p>
<p>1.-a Update <span class="math inline">\(\vartheta_{t}\)</span> : Draw <span class="math inline">\(\vartheta &#39;\)</span> from the set <span class="math inline">\(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\)</span> according to a proposal distribution <span class="math inline">\(T_1 ( \; \cdot \; \vert \vartheta_{t})\)</span>, set <span class="math inline">\((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta &#39; , \pmb z_{t+1} )\)</span> with probability <span class="math inline">\(\min \left\{ 1, \; \; \dfrac{\omega_t^{J(\vartheta_t)}}{\omega_t^{J(\vartheta &#39;)}} \ast \dfrac {\varphi (\pmb z_{t} \vert \vartheta &#39;)} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_1 (\vartheta_{t} \vert \vartheta &#39; )}{T_1 (\vartheta &#39; \vert \vartheta_{t} )} \right\}\)</span>, and set <span class="math inline">\((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta_{t}, \pmb z_t)\)</span> with remaining probability, where <span class="math inline">\(J(\vartheta_t)\)</span> denotes the index of <span class="math inline">\(\vartheta_t\)</span>, i.e., <span class="math inline">\(J(\vartheta_t) = j\)</span> if <span class="math inline">\(\vartheta_t = \theta_i^{(k)}\)</span> and <span class="math inline">\(\varphi(\pmb z \vert \vartheta)\)</span> is an unnormalized density of <span class="math inline">\(f(\pmb z \vert \vartheta)\)</span>.</p>
<p>1.-b. Update <span class="math inline">\(\pmb z_t\)</span> : Draw <span class="math inline">\(\pmb z &#39;\)</span> according to a proposal distribution <span class="math inline">\(T_2 ( \; \cdot \; \vert \pmb z_t)\)</span>, set <span class="math inline">\((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z &#39; , \vartheta_{t})\)</span> with probability <span class="math inline">\(\min \left\{ 1, \; \; \dfrac {\varphi (\pmb z &#39; \vert \vartheta_{t})} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_2 (\pmb z_{t} \vert \pmb z &#39; )}{T_2 (\pmb z &#39; \vert \pmb z_{t} )} \right\}\)</span>, and set <span class="math inline">\((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z_t , \vartheta_{t})\)</span></p></li>
<li><p>(Abundance Factor Updating) Set</p></li>
</ol>
<p><span class="math display">\[
\log (\omega_{t+0.5}^{(j)}) =\log (\omega_{t}^{(j)}) + a_{t+1} (e_{t+1, \; j} - p_j), \; \; \; \; \; j=1, \cdots, m
\]</span></p>
<p>where <span class="math inline">\(e_{t+1, \; j} = \begin{cases} 1 &amp; &amp;&amp; \vartheta^{t+1} = \theta^{(j)} \\ 0 &amp; &amp;&amp; o.w. \end{cases}\)</span>.</p>
<p>If <span class="math inline">\(\omega_{t+0.5}^{(j)} \in \mathcal{K}_{\varsigma_t}\)</span>, set <span class="math inline">\((\omega_{t+1}, \pmb z_{t+1}) = (\omega_{t+0.5}, \pmb z_{t+1})\)</span> and <span class="math inline">\(\varsigma_{t+1} = \varsigma_t\)</span>.</p>
<p>o.w., set <span class="math inline">\((\omega_{t+1}, \pmb z_{t+1}) = \mathbb{T}(\omega_{t}, \pmb z_{t})\)</span> and <span class="math inline">\(\varsigma_{t+1} = \varsigma_t + 1\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>(Auxiliary Sample Collection) Append the sample <span class="math inline">\(\left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right)\)</span> to the collection <span class="math inline">\(S_t\)</span>. Denote the new collection by <span class="math inline">\(S_{t+1}\)</span> which is set by <span class="math inline">\(S_{t+1} = S_t \cup \left\{ \left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right) \right\}\)</span>.</li>
</ol>
<ul>
<li>ALGORITHM: PART 2 - (Target Chain) Adaptive Exchange Sampler</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>(Proposal) Propose a candidate point <span class="math inline">\(\theta &#39;\)</span> from a proposal distribution <span class="math inline">\(q(\theta &#39; \vert \theta)\)</span></p></li>
<li><p>(Resampling for Auxiliary Variables) Resample an auxiliary variable <span class="math inline">\(\pmb x\)</span> from the collection <span class="math inline">\(S_{t+1}\)</span> via a dynamic importance sampling procedure;</p></li>
</ol>
<p>that is, setting <span class="math inline">\(\pmb x = \pmb z_k\)</span> with probability</p>
<p><span class="math display">\[
P(\pmb x = \pmb z_k)
\dfrac
{\sum_{j=1}^{\vert S_{t+1} \vert} \omega_t^{\left( J(\vartheta_j) \right)} \tfrac{\varphi(\pmb z_k \vert \theta &#39; )} {\varphi(\pmb z_k \vert \vartheta_j &#39; )} \ast I(\pmb z_j = \pmb z_k )}
{\sum_{j=1}^{\vert S_{t+1} \vert} \omega_t^{\left( J(\vartheta_j) \right)} \tfrac{\varphi(\pmb z_k \vert \theta &#39; )} {\varphi(\pmb z_k \vert \vartheta_j &#39; )}}
\]</span></p>
<ul>
<li><span class="math inline">\(\left(\pmb z_{j} , \vartheta_{j}, \omega_{t}^{J(\vartheta_{j}} \right)\)</span> denotes the <span class="math inline">\(j\)</span>-th element of the set <span class="math inline">\(S_{t+1}\)</span>.</li>
<li><span class="math inline">\(\vert S_{t+1} \vert\)</span>는 <span class="math inline">\(S_{t+1}\)</span>의 size.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>(Exchange Algorithm) Set <span class="math inline">\(\theta_{t+1} = \theta &#39;\)</span> with the probability <span class="math inline">\(\alpha(\theta_t , \pmb x, \theta&#39; )\)</span>, and <span class="math inline">\(\theta_{t+1} = \theta_{t}\)</span> with probability <span class="math inline">\(1-\alpha(\theta_t , \pmb x, \theta&#39; )\)</span>.</li>
</ol>
<p><span class="math display">\[
\alpha(\theta_t , \pmb x, \theta&#39; ) =
\dfrac {\pi(\theta &#39; )} {\pi(\theta_t )}
\dfrac {\varphi(\pmb y \vert \theta &#39; )} {\varphi(\pmb y \vert \theta_t )}
\dfrac {q(\theta_t \vert \theta &#39; )} {q(\theta&#39; \vert \theta_t )}
\dfrac {\varphi(\pmb x \vert \theta_t )} {\varphi(\pmb x \vert \theta &#39; )}
\]</span></p>
<ul>
<li>Why this algorithm is adaptive?</li>
</ul>
<p>Since the underlying true proposal distribution for generating auxiliary variables in part II is changing from iteration to iteration, the new algorithm falls into the class of adaptive MCMC algorithms (for which the proposal distribution is changing from iteration to iteration).</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="advanced-mcmc-wk08.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="approximate-bayesian-computation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/211204_AuxiliaryVariableMCMC.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
