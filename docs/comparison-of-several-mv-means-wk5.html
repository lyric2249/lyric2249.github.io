<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.4 Comparison of Several MV Means (wk5) | Self-Study</title>
  <meta name="description" content="5.4 Comparison of Several MV Means (wk5) | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="5.4 Comparison of Several MV Means (wk5) | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="https://github.com/lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.4 Comparison of Several MV Means (wk5) | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference-about-mean-vector-wk3.html"/>
<link rel="next" href="multivariate-multiple-regression-wk6.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="part"><span><b>I 20-02</b></span></li>
<li class="chapter" data-level="1" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>1</b> Categorical</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="overview.html"><a href="overview.html#data-type-and-statistical-analysis"><i class="fa fa-check"></i><b>1.1.1</b> Data Type and Statistical Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian</a>
<ul>
<li class="chapter" data-level="2.1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>2.1</b> Abstract</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="abstract.html"><a href="abstract.html#변수의-독립성"><i class="fa fa-check"></i><b>2.1.1</b> 변수의 독립성</a></li>
<li class="chapter" data-level="2.1.2" data-path="abstract.html"><a href="abstract.html#교환가능성"><i class="fa fa-check"></i><b>2.1.2</b> 교환가능성</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continual-aeassessment-method.html"><a href="continual-aeassessment-method.html"><i class="fa fa-check"></i><b>2.2</b> Continual Aeassessment Method</a></li>
<li class="chapter" data-level="2.3" data-path="horseshoe-prior.html"><a href="horseshoe-prior.html"><i class="fa fa-check"></i><b>2.3</b> Horseshoe Prior</a></li>
</ul></li>
<li class="part"><span><b>II 21-01</b></span></li>
<li class="chapter" data-level="3" data-path="mathematical-stats.html"><a href="mathematical-stats.html"><i class="fa fa-check"></i><b>3</b> Mathematical Stats</a>
<ul>
<li class="chapter" data-level="3.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>3.1</b> Inference</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="inference.html"><a href="inference.html#rao-blackwell-thm."><i class="fa fa-check"></i><b>3.1.1</b> Rao-Blackwell thm.</a></li>
<li class="chapter" data-level="3.1.2" data-path="inference.html"><a href="inference.html#completeness"><i class="fa fa-check"></i><b>3.1.2</b> Completeness</a></li>
<li class="chapter" data-level="3.1.3" data-path="inference.html"><a href="inference.html#레만-쉐페-thm."><i class="fa fa-check"></i><b>3.1.3</b> 레만-쉐페 thm.</a></li>
<li class="chapter" data-level="3.1.4" data-path="inference.html"><a href="inference.html#raoblack"><i class="fa fa-check"></i><b>3.1.4</b> Rao-Blackwell thm.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>3.2</b> Hypothesis Test</a></li>
<li class="chapter" data-level="3.3" data-path="power-fucntion.html"><a href="power-fucntion.html"><i class="fa fa-check"></i><b>3.3</b> Power Fucntion</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="power-fucntion.html"><a href="power-fucntion.html#significance-probability-p-value"><i class="fa fa-check"></i><b>3.3.1</b> Significance Probability (p-value)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="optimal-testing-method.html"><a href="optimal-testing-method.html"><i class="fa fa-check"></i><b>3.4</b> Optimal Testing Method</a></li>
<li class="chapter" data-level="3.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>3.5</b> Data Reduction</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="data-reduction.html"><a href="data-reduction.html#sufficiency-principle"><i class="fa fa-check"></i><b>3.5.1</b> Sufficiency Principle</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="borel-paradox.html"><a href="borel-paradox.html"><i class="fa fa-check"></i><b>3.6</b> Borel Paradox</a></li>
<li class="chapter" data-level="3.7" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html"><i class="fa fa-check"></i><b>3.7</b> Neyman–Pearson lemma</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#overview-1"><i class="fa fa-check"></i><b>3.7.1</b> Overview</a></li>
<li class="chapter" data-level="3.7.2" data-path="neymanpearson-lemma.html"><a href="neymanpearson-lemma.html#generalized-lrt"><i class="fa fa-check"></i><b>3.7.2</b> Generalized LRT</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="개념.html"><a href="개념.html"><i class="fa fa-check"></i><b>3.8</b> 개념</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>4</b> MCMC</a>
<ul>
<li class="chapter" data-level="4.1" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>4.1</b> Importance Sampling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="importance-sampling.html"><a href="importance-sampling.html#independent-monte-carlo"><i class="fa fa-check"></i><b>4.1.1</b> Independent Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>4.2</b> Markov Chain Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mh-algorithm"><i class="fa fa-check"></i><b>4.2.1</b> MH Algorithm</a></li>
<li class="chapter" data-level="4.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used"><i class="fa fa-check"></i><b>4.2.2</b> Random Walk Chains (Most Widely Used)</a></li>
<li class="chapter" data-level="4.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler"><i class="fa fa-check"></i><b>4.2.3</b> Basic Gibbs Sampler</a></li>
<li class="chapter" data-level="4.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#implementation"><i class="fa fa-check"></i><b>4.2.4</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html"><i class="fa fa-check"></i><b>4.3</b> Advanced MCMC (wk08)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#data-augmentation"><i class="fa fa-check"></i><b>4.3.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.3.2" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm"><i class="fa fa-check"></i><b>4.3.2</b> Hit-and-Run Algorithm</a></li>
<li class="chapter" data-level="4.3.3" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm"><i class="fa fa-check"></i><b>4.3.3</b> Metropolis-Adjusted Langevin Algorithm</a></li>
<li class="chapter" data-level="4.3.4" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm"><i class="fa fa-check"></i><b>4.3.4</b> Multiple-Try Metropolis Algorithm</a></li>
<li class="chapter" data-level="4.3.5" data-path="advanced-mcmc-wk08.html"><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm"><i class="fa fa-check"></i><b>4.3.5</b> Reversible Jump MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html"><i class="fa fa-check"></i><b>4.4</b> Auxiliary Variable MCMC</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#introduction"><i class="fa fa-check"></i><b>4.4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.4.2" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution"><i class="fa fa-check"></i><b>4.4.2</b> Multimodal Target Distribution</a></li>
<li class="chapter" data-level="4.4.3" data-path="auxiliary-variable-mcmc.html"><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants"><i class="fa fa-check"></i><b>4.4.3</b> Doubly-intractable Normalizing Constants</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html"><i class="fa fa-check"></i><b>4.5</b> Approximate Bayesian Computation</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#simulator-based-models"><i class="fa fa-check"></i><b>4.5.1</b> Simulator-Based Models</a></li>
<li class="chapter" data-level="4.5.2" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods"><i class="fa fa-check"></i><b>4.5.2</b> ABCifying Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.5.3" data-path="approximate-bayesian-computation.html"><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm"><i class="fa fa-check"></i><b>4.5.3</b> ABC-MCMC Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html"><i class="fa fa-check"></i><b>4.6</b> Hamiltonian Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hamiltonian-monte-carlo.html"><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>4.6.1</b> Introduction to Hamiltonian Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html"><i class="fa fa-check"></i><b>4.7</b> Population Monte Carlo</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#adaptive-direction-sampling"><i class="fa fa-check"></i><b>4.7.1</b> Adaptive Direction Sampling</a></li>
<li class="chapter" data-level="4.7.2" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#conjugate-gradient-mc"><i class="fa fa-check"></i><b>4.7.2</b> Conjugate Gradient MC</a></li>
<li class="chapter" data-level="4.7.3" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#parallel-tempering"><i class="fa fa-check"></i><b>4.7.3</b> Parallel Tempering</a></li>
<li class="chapter" data-level="4.7.4" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#evolutionary-mc"><i class="fa fa-check"></i><b>4.7.4</b> Evolutionary MC</a></li>
<li class="chapter" data-level="4.7.5" data-path="population-monte-carlo.html"><a href="population-monte-carlo.html#sequential-parallel-tempering"><i class="fa fa-check"></i><b>4.7.5</b> Sequential Parallel Tempering</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="stochastic-approximation-monte-carlo.html"><a href="stochastic-approximation-monte-carlo.html"><i class="fa fa-check"></i><b>4.8</b> Stochastic Approximation Monte Carlo</a></li>
<li class="chapter" data-level="4.9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>4.9</b> Review</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="review.html"><a href="review.html#wk01"><i class="fa fa-check"></i><b>4.9.1</b> Wk01</a></li>
<li class="chapter" data-level="4.9.2" data-path="review.html"><a href="review.html#wk03"><i class="fa fa-check"></i><b>4.9.2</b> wk03</a></li>
<li class="chapter" data-level="4.9.3" data-path="review.html"><a href="review.html#wk04-05"><i class="fa fa-check"></i><b>4.9.3</b> wk04, 05</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="else.html"><a href="else.html"><i class="fa fa-check"></i><b>4.10</b> Else</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="else.html"><a href="else.html#hw4.-rasch-model"><i class="fa fa-check"></i><b>4.10.1</b> Hw4. Rasch Model</a></li>
<li class="chapter" data-level="4.10.2" data-path="else.html"><a href="else.html#da-example-mvn"><i class="fa fa-check"></i><b>4.10.2</b> DA) Example: MVN</a></li>
<li class="chapter" data-level="4.10.3" data-path="else.html"><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><i class="fa fa-check"></i><b>4.10.3</b> Bayesian adaptive clinical trial with delayed outcomes</a></li>
<li class="chapter" data-level="4.10.4" data-path="else.html"><a href="else.html#nmar의-종류"><i class="fa fa-check"></i><b>4.10.4</b> NMAR의 종류</a></li>
<li class="chapter" data-level="4.10.5" data-path="else.html"><a href="else.html#wk10-bayesian-model-selection"><i class="fa fa-check"></i><b>4.10.5</b> wk10) Bayesian Model Selection</a></li>
<li class="chapter" data-level="4.10.6" data-path="else.html"><a href="else.html#autologistic-model"><i class="fa fa-check"></i><b>4.10.6</b> Autologistic model</a></li>
<li class="chapter" data-level="4.10.7" data-path="else.html"><a href="else.html#wk10-bayesian-model-averaging"><i class="fa fa-check"></i><b>4.10.7</b> wk10) Bayesian Model Averaging</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mva.html"><a href="mva.html"><i class="fa fa-check"></i><b>5</b> MVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html"><i class="fa fa-check"></i><b>5.1</b> Overview of mva (not ended)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#notation"><i class="fa fa-check"></i><b>5.1.1</b> Notation</a></li>
<li class="chapter" data-level="5.1.2" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#summary-statistics"><i class="fa fa-check"></i><b>5.1.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation"><i class="fa fa-check"></i><b>5.1.3</b> Statistical Inference on Correlation</a></li>
<li class="chapter" data-level="5.1.4" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#standardization"><i class="fa fa-check"></i><b>5.1.4</b> Standardization</a></li>
<li class="chapter" data-level="5.1.5" data-path="overview-of-mva-not-ended.html"><a href="overview-of-mva-not-ended.html#missing-value-treatment"><i class="fa fa-check"></i><b>5.1.5</b> Missing Value Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html"><i class="fa fa-check"></i><b>5.2</b> Multivariate Nomral (wk2)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#overview-2"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#spectral-decomposition"><i class="fa fa-check"></i><b>5.2.2</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="5.2.3" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#properties-of-mvn"><i class="fa fa-check"></i><b>5.2.3</b> Properties of MVN</a></li>
<li class="chapter" data-level="5.2.4" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#chi2-distribution"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\Chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="5.2.5" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors"><i class="fa fa-check"></i><b>5.2.5</b> Linear Combination of Random Vectors</a></li>
<li class="chapter" data-level="5.2.6" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood"><i class="fa fa-check"></i><b>5.2.6</b> Multivariate Normal Likelihood</a></li>
<li class="chapter" data-level="5.2.7" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s"><i class="fa fa-check"></i><b>5.2.7</b> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></a></li>
<li class="chapter" data-level="5.2.8" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#assessing-normality"><i class="fa fa-check"></i><b>5.2.8</b> Assessing Normality</a></li>
<li class="chapter" data-level="5.2.9" data-path="multivariate-nomral-wk2.html"><a href="multivariate-nomral-wk2.html#power-transformation"><i class="fa fa-check"></i><b>5.2.9</b> Power Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html"><i class="fa fa-check"></i><b>5.3</b> Inference about Mean Vector (wk3)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#overview-3"><i class="fa fa-check"></i><b>5.3.1</b> Overview</a></li>
<li class="chapter" data-level="5.3.2" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#confidence-region"><i class="fa fa-check"></i><b>5.3.2</b> 1. Confidence Region</a></li>
<li class="chapter" data-level="5.3.3" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#simultaneous-ci"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simultaneous CI</a></li>
<li class="chapter" data-level="5.3.4" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison"><i class="fa fa-check"></i><b>5.3.4</b> 3. Note: Bonferroni Multiple Comparison</a></li>
<li class="chapter" data-level="5.3.5" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector"><i class="fa fa-check"></i><b>5.3.5</b> 4. Large Sample Inferences about a Mean Vector</a></li>
<li class="chapter" data-level="5.3.6" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5"><i class="fa fa-check"></i><b>5.3.6</b> 1. Profile Analysis (wk4, 5)</a></li>
<li class="chapter" data-level="5.3.7" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend"><i class="fa fa-check"></i><b>5.3.7</b> 2. Test for Linear Trend</a></li>
<li class="chapter" data-level="5.3.8" data-path="inference-about-mean-vector-wk3.html"><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix"><i class="fa fa-check"></i><b>5.3.8</b> 3. Inferences about a Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html"><i class="fa fa-check"></i><b>5.4</b> Comparison of Several MV Means (wk5)</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#paired-comparison"><i class="fa fa-check"></i><b>5.4.1</b> Paired Comparison</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations"><i class="fa fa-check"></i><b>5.4.2</b> Comparing Mean Vectors from Two Populations</a></li>
<li class="chapter" data-level="5.4.3" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2"><i class="fa fa-check"></i><b>5.4.3</b> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</a></li>
<li class="chapter" data-level="5.4.4" data-path="comparison-of-several-mv-means-wk5.html"><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means"><i class="fa fa-check"></i><b>5.4.4</b> Comparing Several Multivariate Population Means</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html"><i class="fa fa-check"></i><b>5.5</b> Multivariate Multiple Regression (wk6)</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#overview-4"><i class="fa fa-check"></i><b>5.5.1</b> Overview</a></li>
<li class="chapter" data-level="5.5.2" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression"><i class="fa fa-check"></i><b>5.5.2</b> Multivariate Multiple Regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="multivariate-multiple-regression-wk6.html"><a href="multivariate-multiple-regression-wk6.html#example"><i class="fa fa-check"></i><b>5.5.3</b> Example)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>5.6</b> PCA</a></li>
<li class="chapter" data-level="5.7" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>5.7</b> Factor</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="factor.html"><a href="factor.html#method-of-estimation"><i class="fa fa-check"></i><b>5.7.1</b> Method of Estimation</a></li>
<li class="chapter" data-level="5.7.2" data-path="factor.html"><a href="factor.html#factor-rotation"><i class="fa fa-check"></i><b>5.7.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="5.7.3" data-path="factor.html"><a href="factor.html#varimax-criterion"><i class="fa fa-check"></i><b>5.7.3</b> Varimax Criterion</a></li>
<li class="chapter" data-level="5.7.4" data-path="factor.html"><a href="factor.html#factor-scores"><i class="fa fa-check"></i><b>5.7.4</b> Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html"><i class="fa fa-check"></i><b>5.8</b> Discrimination and Classification</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#bayes-rule"><i class="fa fa-check"></i><b>5.8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="5.8.2" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations"><i class="fa fa-check"></i><b>5.8.2</b> Classification with Two mv <span class="math inline">\(N\)</span> Populations</a></li>
<li class="chapter" data-level="5.8.3" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#evaluating-classification-functions"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating Classification Functions</a></li>
<li class="chapter" data-level="5.8.4" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#classification-with-several-populations-wk13"><i class="fa fa-check"></i><b>5.8.4</b> Classification with several Populations (wk13)</a></li>
<li class="chapter" data-level="5.8.5" data-path="discrimination-and-classification.html"><a href="discrimination-and-classification.html#other-discriminant-analysis-methods"><i class="fa fa-check"></i><b>5.8.5</b> Other Discriminant Analysis Methods</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html"><i class="fa fa-check"></i><b>5.9</b> Clustering, Distance Methods, and Ordination</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#overview-5"><i class="fa fa-check"></i><b>5.9.1</b> Overview</a></li>
<li class="chapter" data-level="5.9.2" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering"><i class="fa fa-check"></i><b>5.9.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="5.9.3" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#k-means-clustering"><i class="fa fa-check"></i><b>5.9.3</b> K-means Clustering</a></li>
<li class="chapter" data-level="5.9.4" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법"><i class="fa fa-check"></i><b>5.9.4</b> 군집의 평가방법</a></li>
<li class="chapter" data-level="5.9.5" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14"><i class="fa fa-check"></i><b>5.9.5</b> Clustering using Density Estimation (wk14)</a></li>
<li class="chapter" data-level="5.9.6" data-path="clustering-distance-methods-and-ordination.html"><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>5.9.6</b> Multidimensional Scaling (MDS)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>6</b> Linear</a>
<ul>
<li class="chapter" data-level="6.1" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>6.1</b> SVD</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="svd.html"><a href="svd.html#spectral-decomposition-1"><i class="fa fa-check"></i><b>6.1.1</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="6.1.2" data-path="svd.html"><a href="svd.html#singular-value-decomposition-general-version"><i class="fa fa-check"></i><b>6.1.2</b> Singular value Decomposition: General-version</a></li>
<li class="chapter" data-level="6.1.3" data-path="svd.html"><a href="svd.html#singular-value-decomposition-another-version"><i class="fa fa-check"></i><b>6.1.3</b> Singular value Decomposition: Another-version</a></li>
<li class="chapter" data-level="6.1.4" data-path="svd.html"><a href="svd.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1.4</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.1.5" data-path="svd.html"><a href="svd.html#partitioned-matrices"><i class="fa fa-check"></i><b>6.1.5</b> Partitioned Matrices</a></li>
<li class="chapter" data-level="6.1.6" data-path="svd.html"><a href="svd.html#geometrical-aspects"><i class="fa fa-check"></i><b>6.1.6</b> Geometrical Aspects</a></li>
<li class="chapter" data-level="6.1.7" data-path="svd.html"><a href="svd.html#column-row-and-null-space"><i class="fa fa-check"></i><b>6.1.7</b> Column, Row and Null Space</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>6.2</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-1.html"><a href="introduction-1.html#what"><i class="fa fa-check"></i><b>6.2.1</b> What</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-1.html"><a href="introduction-1.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.2.2</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-1.html"><a href="introduction-1.html#multivariate-normal-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Multivariate Normal Distributions</a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-1.html"><a href="introduction-1.html#distributions-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2.4</b> Distributions of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>6.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation.html"><a href="estimation.html#identifiability-and-estimability"><i class="fa fa-check"></i><b>6.3.1</b> Identifiability and Estimability</a></li>
<li class="chapter" data-level="6.3.2" data-path="estimation.html"><a href="estimation.html#estimation-least-squares"><i class="fa fa-check"></i><b>6.3.2</b> Estimation: Least Squares</a></li>
<li class="chapter" data-level="6.3.3" data-path="estimation.html"><a href="estimation.html#estimation-best-linear-unbiased"><i class="fa fa-check"></i><b>6.3.3</b> Estimation: Best Linear Unbiased</a></li>
<li class="chapter" data-level="6.3.4" data-path="estimation.html"><a href="estimation.html#estimation-maximum-likelihood"><i class="fa fa-check"></i><b>6.3.4</b> Estimation: Maximum Likelihood</a></li>
<li class="chapter" data-level="6.3.5" data-path="estimation.html"><a href="estimation.html#estimation-minimum-variance-unbiased"><i class="fa fa-check"></i><b>6.3.5</b> Estimation: Minimum Variance Unbiased</a></li>
<li class="chapter" data-level="6.3.6" data-path="estimation.html"><a href="estimation.html#sampling-distributions-of-estimates"><i class="fa fa-check"></i><b>6.3.6</b> Sampling Distributions of Estimates</a></li>
<li class="chapter" data-level="6.3.7" data-path="estimation.html"><a href="estimation.html#generalized-least-squaresgls"><i class="fa fa-check"></i><b>6.3.7</b> Generalized Least Squares(GLS)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>6.4</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="one-way-anova.html"><a href="one-way-anova.html#one-way-anova-1"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="6.4.2" data-path="one-way-anova.html"><a href="one-way-anova.html#more-about-models"><i class="fa fa-check"></i><b>6.4.2</b> More About Models</a></li>
<li class="chapter" data-level="6.4.3" data-path="one-way-anova.html"><a href="one-way-anova.html#estimating-and-testing-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating and Testing Contrasts</a></li>
<li class="chapter" data-level="6.4.4" data-path="one-way-anova.html"><a href="one-way-anova.html#cochrans-theorem"><i class="fa fa-check"></i><b>6.4.4</b> Cochran’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>6.5</b> Testing</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="testing.html"><a href="testing.html#more-about-models-two-approaches-for-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> More About Models: Two approaches for linear model</a></li>
<li class="chapter" data-level="6.5.2" data-path="testing.html"><a href="testing.html#testing-models"><i class="fa fa-check"></i><b>6.5.2</b> Testing Models</a></li>
<li class="chapter" data-level="6.5.3" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure"><i class="fa fa-check"></i><b>6.5.3</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.4" data-path="testing.html"><a href="testing.html#testing-linear-parametric-functions"><i class="fa fa-check"></i><b>6.5.4</b> Testing Linear Parametric Functions</a></li>
<li class="chapter" data-level="6.5.5" data-path="testing.html"><a href="testing.html#theoretical-complements"><i class="fa fa-check"></i><b>6.5.5</b> Theoretical Complements</a></li>
<li class="chapter" data-level="6.5.6" data-path="testing.html"><a href="testing.html#a-generalized-test-procedure-1"><i class="fa fa-check"></i><b>6.5.6</b> A Generalized Test Procedure</a></li>
<li class="chapter" data-level="6.5.7" data-path="testing.html"><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace"><i class="fa fa-check"></i><b>6.5.7</b> Testing Single Degrees of Freedom in a Given Subspace</a></li>
<li class="chapter" data-level="6.5.8" data-path="testing.html"><a href="testing.html#breaking-ss-into-independent-components"><i class="fa fa-check"></i><b>6.5.8</b> Breaking SS into Independent Components</a></li>
<li class="chapter" data-level="6.5.9" data-path="testing.html"><a href="testing.html#general-theory"><i class="fa fa-check"></i><b>6.5.9</b> General Theory</a></li>
<li class="chapter" data-level="6.5.10" data-path="testing.html"><a href="testing.html#two-way-anova"><i class="fa fa-check"></i><b>6.5.10</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.5.11" data-path="testing.html"><a href="testing.html#confidence-regions"><i class="fa fa-check"></i><b>6.5.11</b> Confidence Regions</a></li>
<li class="chapter" data-level="6.5.12" data-path="testing.html"><a href="testing.html#tests-for-generalized-least-squares-models"><i class="fa fa-check"></i><b>6.5.12</b> Tests for Generalized Least Squares Models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>6.6</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#a-direct-solution-via-inner-products"><i class="fa fa-check"></i><b>6.6.1</b> A direct solution via inner products</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="flat.html"><a href="flat.html"><i class="fa fa-check"></i><b>6.7</b> Flat</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="flat.html"><a href="flat.html#flat-1"><i class="fa fa-check"></i><b>6.7.1</b> 1.Flat</a></li>
<li class="chapter" data-level="6.7.2" data-path="flat.html"><a href="flat.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>6.7.2</b> 2. Solutions to systems of linear equations</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="unified-approach-to-balanced-anova-models.html"><a href="unified-approach-to-balanced-anova-models.html"><i class="fa fa-check"></i><b>6.8</b> Unified Approach to Balanced ANOVA Models</a></li>
</ul></li>
<li class="part"><span><b>III 21-02</b></span></li>
<li class="chapter" data-level="7" data-path="network-stats.html"><a href="network-stats.html"><i class="fa fa-check"></i><b>7</b> Network Stats</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-2.html"><a href="introduction-2.html#types-of-network-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Types of Network Analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-2.html"><a href="introduction-2.html#network-modeling-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Network Modeling and Inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-2.html"><a href="introduction-2.html#network-processes"><i class="fa fa-check"></i><b>7.1.3</b> Network Processes</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html"><i class="fa fa-check"></i><b>7.2</b> Descriptive Statistics of Networks</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics"><i class="fa fa-check"></i><b>7.2.1</b> Vertex and Edge Characteristics</a></li>
<li class="chapter" data-level="7.2.2" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion"><i class="fa fa-check"></i><b>7.2.2</b> Characterizing Network Cohesion</a></li>
<li class="chapter" data-level="7.2.3" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#graph-partitioning"><i class="fa fa-check"></i><b>7.2.3</b> Graph Partitioning</a></li>
<li class="chapter" data-level="7.2.4" data-path="descriptive-statistics-of-networks.html"><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing"><i class="fa fa-check"></i><b>7.2.4</b> Assortativity and Mixing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html"><i class="fa fa-check"></i><b>7.3</b> Data Collection and Sampling</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#sampling-designs"><i class="fa fa-check"></i><b>7.3.1</b> Sampling Designs</a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#coping-strategies"><i class="fa fa-check"></i><b>7.3.2</b> Coping Strategies</a></li>
<li class="chapter" data-level="7.3.3" data-path="data-collection-and-sampling.html"><a href="data-collection-and-sampling.html#big-data-solves-nothing"><i class="fa fa-check"></i><b>7.3.3</b> Big Data Solves Nothing</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html"><i class="fa fa-check"></i><b>7.4</b> Mathematical Models for Network Graphs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models"><i class="fa fa-check"></i><b>7.4.1</b> Classical Random Graph Models</a></li>
<li class="chapter" data-level="7.4.2" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models"><i class="fa fa-check"></i><b>7.4.2</b> Generalized Random Graph Models</a></li>
<li class="chapter" data-level="7.4.3" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms"><i class="fa fa-check"></i><b>7.4.3</b> Network Graph Models Based on Mechanisms</a></li>
<li class="chapter" data-level="7.4.4" data-path="mathematical-models-for-network-graphs.html"><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics"><i class="fa fa-check"></i><b>7.4.4</b> Assessing Significance of Network Graph Characteristics</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html"><i class="fa fa-check"></i><b>7.5</b> Introduction to ERGM</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#exponential-random-graph-models"><i class="fa fa-check"></i><b>7.5.1</b> Exponential Random Graph Models</a></li>
<li class="chapter" data-level="7.5.2" data-path="introduction-to-ergm.html"><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation"><i class="fa fa-check"></i><b>7.5.2</b> Difficulty in Parameter Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html"><i class="fa fa-check"></i><b>7.6</b> Parameter Estimation of ERGM</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm"><i class="fa fa-check"></i><b>7.6.1</b> Current Methods for ERGM</a></li>
<li class="chapter" data-level="7.6.2" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm"><i class="fa fa-check"></i><b>7.6.2</b> Approximation-based Algorithm</a></li>
<li class="chapter" data-level="7.6.3" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches"><i class="fa fa-check"></i><b>7.6.3</b> Auxiliary Variable MCMC-based Approaches</a></li>
<li class="chapter" data-level="7.6.4" data-path="parameter-estimation-of-ergm.html"><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc"><i class="fa fa-check"></i><b>7.6.4</b> Varying Trunction Stochastic Approximation MCMC</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>7.7</b> Conclusion</a></li>
<li class="chapter" data-level="7.8" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html"><i class="fa fa-check"></i><b>7.8</b> ERGM for Dynamic Networks</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#temporal-ergm"><i class="fa fa-check"></i><b>7.8.1</b> Temporal ERGM</a></li>
<li class="chapter" data-level="7.8.2" data-path="ergm-for-dynamic-networks.html"><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm"><i class="fa fa-check"></i><b>7.8.2</b> Separable Temporal ERGM</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="latent-network-models.html"><a href="latent-network-models.html"><i class="fa fa-check"></i><b>7.9</b> Latent Network Models</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-model"><i class="fa fa-check"></i><b>7.9.1</b> Latent Position Model</a></li>
<li class="chapter" data-level="7.9.2" data-path="latent-network-models.html"><a href="latent-network-models.html#latent-position-cluster-model"><i class="fa fa-check"></i><b>7.9.2</b> Latent Position Cluster Model</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html"><i class="fa fa-check"></i><b>7.10</b> Additive and Multiplicative Effects Network Models</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#introduction-3"><i class="fa fa-check"></i><b>7.10.1</b> Introduction</a></li>
<li class="chapter" data-level="7.10.2" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression"><i class="fa fa-check"></i><b>7.10.2</b> Social Relations Regression</a></li>
<li class="chapter" data-level="7.10.3" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models"><i class="fa fa-check"></i><b>7.10.3</b> Multiplicative Effects Models</a></li>
<li class="chapter" data-level="7.10.4" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation"><i class="fa fa-check"></i><b>7.10.4</b> Inference via Posterior Approximation</a></li>
<li class="chapter" data-level="7.10.5" data-path="additive-and-multiplicative-effects-network-models.html"><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r"><i class="fa fa-check"></i><b>7.10.5</b> Discussion and Example with R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="high-dimension.html"><a href="high-dimension.html"><i class="fa fa-check"></i><b>8</b> High Dimension</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html"><i class="fa fa-check"></i><b>8.2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation</a></li>
<li class="chapter" data-level="8.2.2" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#from-markov-to-chernoff"><i class="fa fa-check"></i><b>8.2.2</b> From Markov to Chernoff</a></li>
<li class="chapter" data-level="8.2.3" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.3</b> sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.4" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables"><i class="fa fa-check"></i><b>8.2.4</b> Properties of sub-Gaussian random variables</a></li>
<li class="chapter" data-level="8.2.5" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#equivalent-definitions"><i class="fa fa-check"></i><b>8.2.5</b> Equivalent definitions</a></li>
<li class="chapter" data-level="8.2.6" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#sub-gaussian-random-vectors"><i class="fa fa-check"></i><b>8.2.6</b> Sub-Gaussian random vectors</a></li>
<li class="chapter" data-level="8.2.7" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#hoeffdings-inequality"><i class="fa fa-check"></i><b>8.2.7</b> Hoeffding’s inequality</a></li>
<li class="chapter" data-level="8.2.8" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#maximal-inequalities"><i class="fa fa-check"></i><b>8.2.8</b> Maximal inequalities</a></li>
<li class="chapter" data-level="8.2.9" data-path="concentration-inequalities.html"><a href="concentration-inequalities.html#section"><i class="fa fa-check"></i><b>8.2.9</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html"><i class="fa fa-check"></i><b>8.3</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#sub-exponential-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Sub-exponential random variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#bernsteins-condition"><i class="fa fa-check"></i><b>8.3.2</b> Bernstein’s condition</a></li>
<li class="chapter" data-level="8.3.3" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#mcdiarmids-inequality"><i class="fa fa-check"></i><b>8.3.3</b> McDiarmid’s inequality</a></li>
<li class="chapter" data-level="8.3.4" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#levys-inequality"><i class="fa fa-check"></i><b>8.3.4</b> Levy’s inequality</a></li>
<li class="chapter" data-level="8.3.5" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#quadratic-form"><i class="fa fa-check"></i><b>8.3.5</b> Quadratic form</a></li>
<li class="chapter" data-level="8.3.6" data-path="concentration-inequalities-1.html"><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma"><i class="fa fa-check"></i><b>8.3.6</b> The Johnson–Lindenstrauss Lemma</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html"><i class="fa fa-check"></i><b>8.4</b> Metric entropy and its uses</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#metric-space"><i class="fa fa-check"></i><b>8.4.1</b> Metric space</a></li>
<li class="chapter" data-level="8.4.2" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy"><i class="fa fa-check"></i><b>8.4.2</b> Covering numbers and metric entropy</a></li>
<li class="chapter" data-level="8.4.3" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#packing-numbers"><i class="fa fa-check"></i><b>8.4.3</b> Packing numbers</a></li>
<li class="chapter" data-level="8.4.4" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-1"><i class="fa fa-check"></i><b>8.4.4</b> </a></li>
<li class="chapter" data-level="8.4.5" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-2"><i class="fa fa-check"></i><b>8.4.5</b> </a></li>
<li class="chapter" data-level="8.4.6" data-path="metric-entropy-and-its-uses.html"><a href="metric-entropy-and-its-uses.html#section-3"><i class="fa fa-check"></i><b>8.4.6</b> </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="covariance-estimation.html"><a href="covariance-estimation.html"><i class="fa fa-check"></i><b>8.5</b> Covariance estimation</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="covariance-estimation.html"><a href="covariance-estimation.html#matrix-algebra-review"><i class="fa fa-check"></i><b>8.5.1</b> Matrix algebra review</a></li>
<li class="chapter" data-level="8.5.2" data-path="covariance-estimation.html"><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm"><i class="fa fa-check"></i><b>8.5.2</b> Covariance matrix estimation in the operator norm</a></li>
<li class="chapter" data-level="8.5.3" data-path="covariance-estimation.html"><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices"><i class="fa fa-check"></i><b>8.5.3</b> Bounds for structured covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html"><i class="fa fa-check"></i><b>8.6</b> Matrix concentration inequalities</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-calculus"><i class="fa fa-check"></i><b>8.6.1</b> Matrix calculus</a></li>
<li class="chapter" data-level="8.6.2" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#matrix-chernoff"><i class="fa fa-check"></i><b>8.6.2</b> Matrix Chernoff</a></li>
<li class="chapter" data-level="8.6.3" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices"><i class="fa fa-check"></i><b>8.6.3</b> Sub-Gaussian and sub-exponential matrices</a></li>
<li class="chapter" data-level="8.6.4" data-path="matrix-concentration-inequalities.html"><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><i class="fa fa-check"></i><b>8.6.4</b> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>8.7</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-1"><i class="fa fa-check"></i><b>8.7.1</b> PCA</a></li>
<li class="chapter" data-level="8.7.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#matrix-perturbation"><i class="fa fa-check"></i><b>8.7.2</b> Matrix Perturbation</a></li>
<li class="chapter" data-level="8.7.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#spiked-cov-model"><i class="fa fa-check"></i><b>8.7.3</b> Spiked Cov Model</a></li>
<li class="chapter" data-level="8.7.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#sparse-pca"><i class="fa fa-check"></i><b>8.7.4</b> sparse PCA</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>8.8</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="linear-regression.html"><a href="linear-regression.html#problem-formulation"><i class="fa fa-check"></i><b>8.8.1</b> Problem formulation</a></li>
<li class="chapter" data-level="8.8.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimator-in-high-dimensions"><i class="fa fa-check"></i><b>8.8.2</b> Least Squares Estimator in high dimensions</a></li>
<li class="chapter" data-level="8.8.3" data-path="linear-regression.html"><a href="linear-regression.html#sparse-linear-regression"><i class="fa fa-check"></i><b>8.8.3</b> Sparse linear regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>9</b> Survival Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-5.html"><a href="introduction-5.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>9.2</b> </a></li>
<li class="chapter" data-level="9.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html"><i class="fa fa-check"></i><b>9.3</b> Counting Processes and Martingales</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#conditional-expectation"><i class="fa fa-check"></i><b>9.3.1</b> Conditional Expectation</a></li>
<li class="chapter" data-level="9.3.2" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#martingale"><i class="fa fa-check"></i><b>9.3.2</b> Martingale</a></li>
<li class="chapter" data-level="9.3.3" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#key-martingales-properties"><i class="fa fa-check"></i><b>9.3.3</b> Key Martingales Properties</a></li>
<li class="chapter" data-level="9.3.4" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-5"><i class="fa fa-check"></i><b>9.3.4</b> </a></li>
<li class="chapter" data-level="9.3.5" data-path="counting-processes-and-martingales.html"><a href="counting-processes-and-martingales.html#section-6"><i class="fa fa-check"></i><b>9.3.5</b> </a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>9.4</b> </a></li>
<li class="chapter" data-level="9.5" data-path="cox-regression.html"><a href="cox-regression.html"><i class="fa fa-check"></i><b>9.5</b> Cox Regression</a></li>
<li class="chapter" data-level="9.6" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html"><i class="fa fa-check"></i><b>9.6</b> Filtration의 개념을 정복하자!</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약"><i class="fa fa-check"></i><b>9.6.1</b> Random Process를 이야기 하기까지의 긴 여정의 요약</a></li>
<li class="chapter" data-level="9.6.2" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#ft-measurable"><i class="fa fa-check"></i><b>9.6.2</b> Ft-measurable</a></li>
<li class="chapter" data-level="9.6.3" data-path="filtration의-개념을-정복하자.html"><a href="filtration의-개념을-정복하자.html#epilogue"><i class="fa fa-check"></i><b>9.6.3</b> EPILOGUE</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>9.7</b> Concepts</a></li>
</ul></li>
<li class="appendix"><span><b>00-00</b></span></li>
<li class="chapter" data-level="A" data-path="concepts-1.html"><a href="concepts-1.html"><i class="fa fa-check"></i><b>A</b> Concepts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="autologistic.html"><a href="autologistic.html"><i class="fa fa-check"></i><b>A.1</b> Autologistics</a></li>
<li class="chapter" data-level="A.2" data-path="orderlogit.html"><a href="orderlogit.html"><i class="fa fa-check"></i><b>A.2</b> Ordered Logit</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="abstract-1.html"><a href="abstract-1.html"><i class="fa fa-check"></i><b>B</b> ABSTRACT</a></li>
<li class="chapter" data-level="C" data-path="cnn.html"><a href="cnn.html"><i class="fa fa-check"></i><b>C</b> CNN</a></li>
<li class="chapter" data-level="D" data-path="cnn-1.html"><a href="cnn-1.html"><i class="fa fa-check"></i><b>D</b> CNN</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="comparison-of-several-mv-means-wk5" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Comparison of Several MV Means (wk5)</h2>
<div id="paired-comparison" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Paired Comparison</h3>
<p><em>Recall:</em></p>
<p>for univariate, let <span class="math inline">\(X_i - Y_i = D_i \sim N(\delta, \sigma_d^2)\)</span>, <span class="math inline">\(i=1, \cdots, n\)</span></p>
<p>then for <span class="math inline">\(H_0 : \delta = 0\)</span>, test stat <span class="math inline">\(t = \tfrac{\bar D}{\tfrac{S_d}{\sqrt{n}}} \overset {H_0}{\sim} t_{n-1}\)</span>.</p>
<hr />
<p>Assume independent rvec <span class="math inline">\(\pmb D_1 , \cdots, \pmb D_n \sim N_p (\pmb \delta , \Sigma_{\pmb d})\)</span>.</p>
<p>then test stat <span class="math inline">\(T^2 = n(\bar {\pmb D} - \pmb \delta)&#39; S^{-1}_{\pmb d} (\bar {\pmb D} - \pmb \delta) \sim (n-1)\tfrac{p}{n-p} F_{p, n-p}\)</span>.</p>
<ul>
<li>Hypothesis Testing:</li>
</ul>
<p>$
H_0 : = 
$</p>
<p>$</p>
<p>T^2 = n({D} )’ S^{-1}<em>{d} ({D} )  F</em>{p, n-p}</p>
<p>$</p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T^2 &gt; \tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)\)</span>.</p>
<p><br>
<br></p>
<ol style="list-style-type: decimal">
<li>$100(1-) % $ CR for <span class="math inline">\(\pmb \delta\)</span>:</li>
</ol>
<p>$</p>
<p>({D} - )’ S^{-1}<em>{d} ({D} - )   F</em>{p, n-p} ()</p>
<p>$</p>
<ol start="2" style="list-style-type: decimal">
<li><p>$100(1-) % $ simultaneous CI for individual <span class="math inline">\(\delta_i\)</span>:</p></li>
<li><p>Bonferroni’s $100(1-) % $ simultaneous CI for individual <span class="math inline">\(\delta_i\)</span>:</p></li>
</ol>
<p>$
<span class="math display">\[\begin{alignat*}{3}

\bar d_i \pm 
&amp;\sqrt{\tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)} 
&amp;\sqrt{\tfrac{S^2_{d_i}}{n}} \tag{2} \\

\bar d_i \pm 
&amp;t_{n-1} \left( \tfrac {\alpha} {2p} \right)
&amp;\sqrt{\tfrac{S^2_{d_i}}{n}}\tag{3}


\end{alignat*}\]</span>
$</p>
<p><br>
<br></p>
<ul>
<li></li>
</ul>
<p>–</p>
<hr />
<hr />
<p>====</p>
<div id="different-approach" class="section level5" number="5.4.1.0.1">
<h5><span class="header-section-number">5.4.1.0.1</span> Different Approach</h5>
<p>let <span class="math inline">\(\pmb X = \left[ x_{11}, \cdots, x_{1p}, x_{21}, \cdots, x_{2p} \right]_{1 \times 2p}&#39; \sim N_{2p}(\pmb \mu, \Sigma)\)</span>.</p>
then <span class="math inline">\(\pmb D = C \pmb X\)</span>, where $C = (
<span class="math display">\[\begin{matrix} 1 &amp;  &amp; \pmb 0 &amp; \vdots &amp; -1 &amp;  &amp; \pmb 0 \\  &amp; \ddots &amp;  &amp; \vdots &amp;  &amp; \ddots &amp;  \\ \pmb 0 &amp;  &amp; 1 &amp; \vdots &amp; \pmb 0 &amp;  &amp; -1 \end{matrix}\]</span>
<p>)_{p 2p} $.</p>
<p>at here,</p>
<p>$
<span class="math display">\[\begin{align*}

E(\pmb D) 
&amp;= E(C \pmb X) = C \pmb \mu \\ 
&amp;= \pmb \delta\\
\\

Cov(\pmb D)  
&amp;= Cov(C \pmb X) = C \Sigma C&#39; \\ 
&amp;= \Sigma_d\\

\\

\pmb D &amp;= C \pmb X \sim N_p (C \pmb \mu, C \Sigma C&#39;)

\end{align*}\]</span>
$</p>
<p>therefore, given <span class="math inline">\(H_0 : C \pmb \mu = \pmb 0\)</span>,</p>
<p>test stat <span class="math inline">\(T^2 = n (C \bar {\pmb X})&#39; (CSC&#39;)^{-1} (C \bar {\pmb X}) \overset {H_0}{\sim} \tfrac{(n-1)p}{n-p} F_{p, n-p}\)</span></p>
<p><br></p>
<ul>
<li>graph, check normality:</li>
</ul>
<p><img src></p>
<hr />
</div>
</div>
<div id="comparing-mean-vectors-from-two-populations" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations</h3>
<p><em>Recall:</em>
univariate, $ t =  {sqrt{S_p^2 (  + )}}  t_{n_1 + n_2 - 2}$</p>
<hr />
<p>for MV, assume below, where <span class="math inline">\((\pmb X_{11}, \cdots, \pmb X_{1n_1})\)</span> and <span class="math inline">\((\pmb X_{21}, \cdots, \pmb X_{2n_2})\)</span> are independent.</p>
<p>$
X_{11}, , X_{1n_1} N_p (_1 , _1 )</p>
<p>$
$</p>
<p>X_{21}, , X_{2n_2} N_p (_2 , _2 )
$</p>
<p>at here,</p>
<p>$
H_0 : _1 - _2 = 
$</p>
<hr />
<div id="case-1-_1-_2" class="section level5" number="5.4.2.0.1">
<h5><span class="header-section-number">5.4.2.0.1</span> case 1: $ _1 = _2 = $</h5>
<p>이하 대부분은 벡터에 관한 이야기이다.</p>
<p><span class="math inline">\(\bar X_i\)</span> estimates <span class="math inline">\(\mu_i\)</span>, <span class="math inline">\(i=1,2\)</span>.</p>
<p><span class="math inline">\(S_p\)</span> estimates <span class="math inline">\(\Sigma\)</span>, where $S_p =  {(n_1-1) + (n_2-1)} $.</p>
<p><br></p>
<p>the test stats <strong>Hotelling’s </strong> $ T^2 =  ( {X_1 } - {X_2} ) ’ S_p^{-1} ( {X_1 } - {X_2} ) $</p>
<p>where $  {p [ (n_1 - 1) + (n_2 - 1) ]} ; T^2 =  {p [ (n_1 + n_2 - 2) ]} ; T^2  F_{p, n_1 + n_2 -p - 1}$. (p.285 for pf)</p>
<p><br></p>
<ul>
<li><strong>CR for <span class="math inline">\(\mu_1 - \mu_2\)</span></strong> will be</li>
</ul>
<p>$</p>
<p>Pr = 1-</p>
<p>$</p>
<p>where $ c^2=  {n_1 + n_2 - p - 1} ; T^2  F_{p, n_1 + n_2 -p - 1} ()$.
* 이때 constant가 역수가 되었음을 눈치.
* The equality will define the boundary of a region.
* The region is an ellipsoid centered at <span class="math inline">\((\bar X_1 - \bar X_2)\)</span>.</p>
<div id="example-testing-h_0-mu_1---mu_2-0-at-alpha0.05-is-equivalent-to-see-whether-falls-within-the-confidence-region" class="section level6" number="5.4.2.0.1.1">
<h6><span class="header-section-number">5.4.2.0.1.1</span> Example) Testing <span class="math inline">\(H_0 : \mu_1 - \mu_2 = 0\)</span> at <span class="math inline">\(\alpha=0.05\)</span> is equivalent to see whether falls within the confidence region</h6>
<ul>
<li>Axes of the confidence region
* let <span class="math inline">\(\lambda_1 , \cdots, \lambda_p\)</span> are ev of <span class="math inline">\(S_p\)</span>.
* let <span class="math inline">\(e_1 , \cdots, e_p\)</span> are evc of <span class="math inline">\(S_p\)</span>.
<ul>
<li>then <span class="math inline">\(e_i\)</span>’s are the direction of CI</li>
<li>$  $are the half-length of the CR <a href="">Link</a></li>
</ul></li>
</ul>
<p>let $ c^2=  {n_1 + n_2 - p - 1} ; T^2  F_{p, n_1 + n_2 -p - 1} ()$.</p>
<ul>
<li><span class="math inline">\(100(1-\alpha)%\)</span> <strong>simultaneous CI</strong> for <span class="math inline">\(a&#39;(\mu_1 - \mu_2)\)</span>, <span class="math inline">\(\forall a\)</span>:<br />
$</li>
</ul>
<p>a’ ( X_1 - X_2 ) c </p>
<p>$</p>
</div>
<div id="example-simultaneous-ci-for-mu_1i---mu_2i-i1-cdots-p." class="section level6" number="5.4.2.0.1.2">
<h6><span class="header-section-number">5.4.2.0.1.2</span> Example) simultaneous CI for <span class="math inline">\((\mu_{1i} - \mu_{2i}), i=1, \cdots, p\)</span>.</h6>
<p>let <span class="math inline">\(a&#39; = \left[0, \cdots, 0, 1, 0, \cdots, 0 \right]\)</span>. 이때 <span class="math inline">\(a&#39;\)</span>가 하나만 1이고 나머지 0이면, 어떤 특별한 한 axis로 proj하라는 의미. <a href="">link</a></p>
<p>let <span class="math inline">\(\mu_1 - \mu_2 = \left[ \mu_{1i} - \mu_{2i} \right]_{i=1,\cdots,p}\)</span>.</p>
<p>$ a’(X_1 - X_2) = X_{1i} - X_{2i}$, <span class="math inline">\(a&#39; \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_p a = \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_{p \; ii}\)</span>
* <span class="math inline">\(S_{p \; ii}\)</span> : p번째 변수의 표본 cov. 이는 단변량에서 나왔던 공통 cov, 즉 샘플 se와 표기법이 동일해지며 유사하다. (ch1) <a href="">link</a></p>
<p>the Bonferroni’s $100(1-)% $ simultaneous CI for <span class="math inline">\((\mu_{1i} - \mu_{2i})\)</span> is $ (X_1 - X_2) t_{n_2 + n_2 -2, ()} $.</p>
<hr />
</div>
</div>
<div id="case-2-_1-_2" class="section level5" number="5.4.2.0.2">
<h5><span class="header-section-number">5.4.2.0.2</span> case 2: $ _1 = _2 $</h5>
<p>assume <span class="math inline">\(n_1 - p , \; n_2 - p\)</span> are large.</p>
<p>for <span class="math inline">\(H_0 : \mu_1 - \mu_2 = 0\)</span>, test stat becomes <span class="math inline">\(T^2 = (\bar X_1 - \bar X_2 )&#39; \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2 \right]^{-1} (\bar X_1 - \bar X_2 ) \overset{H_0}{\sim} \chi_p^2\)</span>.</p>
<pre class="note"><code>
$
E(\bar X_1 - \bar X_2 ) = \mu_1 - \mu_2
$

$
Cov(\bar X_1 - \bar X_2 ) = Cov(\bar X_1) + Cov(\bar X_2 ) - 2 Cov(\bar X_1, \bar X_2 ) = \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2 - 0
$


$
\bar X_1 - \bar X_2 \overset{\cdot}{\sim} N_p \left( \mu_1 - \mu_2, \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2  \right)
\tag{∵ CLT}
$

$\\[3ex]
$

$
\text{under } H_0, 
$

$
S_1 \overset{p}{\to} \Sigma_1, S_2 \overset{p}{\to} \Sigma_2 \tag{∵ WLLN}
$

$
(\bar X_1 - \bar X_2 )&#39; \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2\right]^-1 (\bar X_1 - \bar X_2 ) \overset{app}{\sim} \chi_p^2 \tag{∵ Slutsky&#39;s thm}
$</code></pre>
<p><strong><em>why Cov become 0???</em></strong></p>
<p>i.e. reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T^2 &gt; \chi_p^2 (\alpha)\)</span>.</p>
<p>CI becomes</p>
<p>$</p>
<p>Pr = 1-</p>
<p>$</p>
<p>차이는~~</p>
<p>Remark: if <span class="math inline">\(n_1 = n_2 = 2\)</span>,</p>
<p>$
<span class="math display">\[\begin{align*}

\dfrac{1}{n_1} S_1 + \dfrac{1}{n_2} S_2 

&amp;=  \dfrac{1}{n} (S_1 + S_2) \\

&amp;= \dfrac{1}{n}

\left[

\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{1i} - \bar {\pmb X_1})(\pmb X_{1i} - \bar {\pmb X_1})&#39; + 
\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{2i} - \bar {\pmb X_2})(\pmb X_{2i} - \bar {\pmb X_2})&#39;

\right] \\

&amp;= \dfrac{1}{n} \dfrac{1}{n-1} S_p \ast 2(n-1) 

= \dfrac{2}{n}  S_p 


\end{align*}\]</span>
$</p>
<p>i.e. case 1 and case 2 are the same procedure when the sample sizes are the same for large sample sizes.</p>
<ul>
<li><span class="math inline">\(100(1-\alpha)%\)</span> <strong>simultaneous CI</strong> for <span class="math inline">\(\pmb a&#39;(\pmb \mu_1 - \pmb \mu_2)\)</span>, <span class="math inline">\(\forall \pmb a\)</span>:</li>
</ul>
<p>$</p>
<p>a’ ( {X_1} - {X_2} )  </p>
<p>$</p>
<hr />
</div>
<div id="other-statistics-for-testing-two-mean-vectors" class="section level5" number="5.4.2.0.3">
<h5><span class="header-section-number">5.4.2.0.3</span> Other Statistics for Testing two Mean Vectors</h5>
<ul>
<li><p>let <span class="math inline">\(W=(n_1-1)S_1 + (n_2-1)S_2\)</span>: within SS, <span class="math inline">\(B=n_1 (\bar {\pmb X_1} - \bar {\pmb X})(\bar {\pmb X_1} - \bar {\pmb X})&#39; + n_2 (\bar {\pmb X_2} - \bar {\pmb X})(\bar {\pmb X_2} - \bar {\pmb X})&#39;\)</span></p></li>
<li><p>Wilk’s Lambda:</p>
<ul>
<li>when two-sample procedure, Hotelling’s <span class="math inline">\(T^2\)</span></li>
</ul></li>
</ul>
<p>$
^= 
$</p>
<ul>
<li>Lawley-Hotelling’s Trace:</li>
</ul>
<p>$
tr(BW^{-1})
$</p>
<ul>
<li>Pillai Trace:</li>
</ul>
<p>$
tr $</p>
<ul>
<li>Roy’s Largest Root:
<ul>
<li>maximum ev of <span class="math inline">\(B(B+W)^{-1}\)</span>.</li>
</ul></li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="testing-equality-of-covariance-matrices" class="section level5" number="5.4.2.0.4">
<h5><span class="header-section-number">5.4.2.0.4</span> Testing Equality of Covariance Matrices</h5>
<p>$
H_0 : _1 = _2
$</p>
<p>let <span class="math inline">\(S_p = \dfrac{1}{n_1 + n_2 - 2} \left[ (n_1 - 1) S_1 + (n_2 - 1) S_2 \right]\)</span>.</p>
<p>$
<span class="math display">\[\begin{align*}

M &amp;= (n_1 + n_2 - 2) \ln \vert S_p \vert - (n_1 - 1) \ln \vert S_1 \vert - (n_2 - 1) \ln \vert S_2 \vert \tag{test stat} \\

C^{-1} &amp;= 1 - \dfrac{2p^2 + 3p -1}{6(p+1)} \left( \dfrac {n_1 + n_2 - 2}{(n_1-1)(n_2 - 1)} - \dfrac {1}{n_1 + n_2 - 2} \tag{Scale Factor} \\

MC^{-1} &amp;\sim \chi_v^2, \; \; \; \; \; v=\dfrac{p(p+1)}{2}
\end{align*}\]</span>
$</p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(MC^{-1} &gt; \chi_v^2(\alpha)\)</span></p>
<hr />
</div>
</div>
<div id="profile-analysis-for-g2" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</h3>
<p>Recall:</p>
<p><span class="math inline">\(H_0: \pmb \mu_1 = \pmb \mu_2\)</span>, when <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span></p>
<p>$
<span class="math display">\[\begin{align*}

T^2 &amp;= (\bar {\pmb X_1} - \bar {\pmb X_2})&#39; \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) S_p \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&amp;\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)p} {n_1 + n_2-p-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}\]</span>
$</p>
<hr />
<p>let’s <span class="math inline">\(H_0: C \pmb \mu_1 = C \pmb \mu_2\)</span>, when <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span>, where <span class="math inline">\(C_{q \times p}\)</span>, <span class="math inline">\(q \le p\)</span> and <span class="math inline">\(rank(C)=q\)</span>.</p>
<p>$
<span class="math display">\[\begin{align*}

T^2 &amp;= (\bar {\pmb X_1} - \bar {\pmb X_2})&#39; C&#39; \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) CS_p C&#39;\right]^{-1} C(\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&amp;\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)q} {n_1 + n_2-q-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}\]</span>
$</p>
<p>Profiles are constructed for each group.</p>
<p><img src></p>
<p>Consider two groups. Questions:</p>
<ol style="list-style-type: decimal">
<li>Are the profiles parallel?</li>
</ol>
<p>$
<span class="math display">\[\begin{alignat*}{3}

&amp;&amp;H_0 : \mu_{11}-\mu{12} = \mu_{21}-\mu{22}, \mu_{12}-\mu{13} = \mu_{22}-\mu{23}, \mu_{13}-\mu{14} = \mu_{23}-\mu{24}, \cdots, \mu_{1,p-1}-\mu{1,p} = \mu_{2,p-1}-\mu{2,p} \\
&amp;\iff &amp; H_0 : \mu_{11}-\mu{21} = \mu_{12}-\mu{22} = \cdots = \mu_{1p}-\mu{2p}} \\

&amp;\iff C_{(p-1) \times p} &amp;H_0: C \pmb \mu_1 = C \pmb \mu_2

\end{alignat*}\]</span>
$</p>
<p>This is equivalent to test the equal mean vector of the transformed data <span class="math inline">\(C \pmb X_1\)</span> and <span class="math inline">\(C \pmb X_2\)</span>.</p>
<p>Populations 1: <span class="math inline">\(C \pmb X_{11}, \cdots, C \pmb X_{1n_1} \sim N_{p-1} (C \pmb \mu_1 , C \Sigma C&#39;)\)</span>
Populations 2: <span class="math inline">\(C \pmb X_{21}, \cdots, C \pmb X_{2n_2} \sim N_{p-1} (C \pmb \mu_2 , C \Sigma C&#39;)\)</span></p>
<p>reject <span class="math inline">\(H_0: C \pmb \mu_1 = C \pmb \mu_2\)</span> (i.e. paralle profiles), if
$</p>
<p>T^2 = ({X_1} - {X_2})‘C’ ^{-1} C({X_1} - {X_2}) &gt; d^2 = (n_1 + n_2 - 2)  F_{p-1,n_1+n_2-p} ()</p>
<p>$</p>
<hr />
<div id="coincident-profiles" class="section level5" number="5.4.3.0.1">
<h5><span class="header-section-number">5.4.3.0.1</span> 2. Coincident Profiles</h5>
<ol start="2" style="list-style-type: decimal">
<li>Assuming that the profiles are parallel, are the profiles coincident?</li>
</ol>
<p>$
<span class="math display">\[\begin{align*}

&amp;H_0 : \mu_{1i} = \mu_{2i}, i=1, \cdots, p \\
\iff &amp; H_0 : \pmb 1 &#39; \pmb \mu_1 = \pmb 1 &#39; \pmb \mu_2

\end{align*}\]</span>
$</p>
<p>is the case where <span class="math inline">\(C\)</span> is replaced by <span class="math inline">\(\pmb 1 &#39;\)</span>.</p>
<p>reject <span class="math inline">\(H_0\)</span> if</p>
<p>$
<span class="math display">\[\begin{alignat*}{2}
T^2 &amp;= \pmb 1 &#39; (\bar {\pmb X_1} - \bar {\pmb X_2}) \left[ \left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 &#39; S_p \pmb 1 \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) &amp;&amp; \\





&amp;= 

\left( 

\dfrac{\pmb 1 &#39; (\bar {\pmb X_1} - \bar {\pmb X_2})}{\sqrt{\left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 &#39; S_p \pmb 1}}

\right)^2

&amp;&amp;&gt; F_{1, n_1 + n_2 -2} (\alpha)

(n_1 + n_2 - 2) \dfrac{p-1}{n_1 + n_2 - p } F_{p-1,n_1+n_2-p} (\alpha)



\end{alignat*}\]</span>
$</p>
<hr />
</div>
<div id="flat-profiles" class="section level5" number="5.4.3.0.2">
<h5><span class="header-section-number">5.4.3.0.2</span> 3. Flat Profiles</h5>
<p>3.Assuming that the profiles are coincident, are the profiles level?</p>
<p>$
H_0 : <em>{11} = </em>{12} = } = <em>{1p} = </em>{21} = <em>{22} = } = </em>{2p}
$</p>
<p>by 1 and 2, we can collapse two groups into one.</p>
<p>$
X_{11}, , X_{1n_1}, X_{21}, , X_{2n_2} N_p (, )
$</p>
<p>this is one population problem</p>
<p>$
C_{(p-1) p}, H_0: C = 0
$</p>
<p>reject <span class="math inline">\(H_0\)</span>, iff</p>
<p>$
T^2 = (n_1+n_2) {X}‘C’ [CSC’]^{-1} C {X} &gt; d^2 = (n_1 + n_2 - 1)  F_{p-1,n_1+n_2-p+1} ()
$</p>
<p>이는 1번에서의 그것과는 <span class="math inline">\(F\)</span>분포의 df가 변화했다는 점에 주목.
- <span class="math inline">\(\bar {\pmb X} = \tfrac{1}{n_1 + n_2} \left( \sum_{j=1}^{n_1} \pmb X_{1j}+ \sum_{j=1}^{n_2} \pmb X_{2j} right)\)</span>.
- <span class="math inline">\(S = n_1 + n_2\)</span> sample covariance matrix, using data.</p>
<hr />
</div>
</div>
<div id="comparing-several-multivariate-population-means" class="section level3" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> Comparing Several Multivariate Population Means</h3>
<p><em>Recall:</em></p>
<p>In univariate, two-sample t-test is extended to Analysis of Variance(ANOVA).</p>
<p>$
H_0:_1 = =_g
$</p>
<p>$
F^=  {SSE/df_2}  F_{df_1 , df_2}
$
- where
- SSR: sum of squared regression,
- SSE: sum of squared error,
- SST: sum of squared total
- <span class="math inline">\(df_1 = g-1, df_2 = N-g, N=\sum_{i=1}^g n_i\)</span>.</p>
<hr />
<p>Assume <span class="math inline">\(g\)</span> population or treatment groups, and <strong>each groups are independent</strong>. 각 population은 같은 Cov를 갖고 같은 숫자의 패러미터를 갖되 총 observation 숫자랑 각각의 population mean은 다름.</p>
<p>Population 1~g: <span class="math inline">\(\pmb X_{i1}, \cdots, \pmb X_{in_i} \sim N_p(\pmb \mu_i , \Sigma)\)</span>.</p>
<ul>
<li>Model</li>
</ul>
<p>$
X_{ij} = <em>{i} + </em>{ij}, ; ; ; ; ; i=1, , g, ; ; j = 1, , n_i</p>
<p>$</p>
<p>$
H_0: _1 = _g
$</p>
$
 X_{ij} =
<span class="math display">\[\begin{bmatrix} X_{ij1} \\ X_{ij2} \\ \vdots \\X_{ijp} \end{bmatrix}\]</span>
<em>{p } , </em>{ij} =
<span class="math display">\[\begin{bmatrix} \mu_{i1} \\ \mu_{i2} \\ \vdots \\ \mu_{ip} \end{bmatrix}\]</span>
<em>{p }, </em>{ij} =
<span class="math display">\[\begin{bmatrix} \epsilon_{ij1} \\ \epsilon_{ij2} \\ \vdots \\ \epsilon_{ijp} \end{bmatrix}\]</span>
<p>_{p }
$</p>
<ul>
<li>Assumptions
<ol style="list-style-type: decimal">
<li>The random samples from different populations are independent.</li>
<li>All populations have a common covariance matrix <span class="math inline">\(\Sigma\)</span>.</li>
<li>Each population is Multivariate Normal. This assumption can be relaxed by C.L.T., when the sample sizes <span class="math inline">\(n_1 , \cdots, n_g\)</span> are large.</li>
</ol></li>
</ul>
<div id="one-way-manova" class="section level5" number="5.4.4.0.1">
<h5><span class="header-section-number">5.4.4.0.1</span> One-Way MANOVA</h5>
<p>The quantities SSR, SSE and SST become matrices in MANOVA.</p>
<p>$
<span class="math display">\[\begin{align*}
B &amp;= \sum_{i=1}^g n_i (\pmb X_i - \pmb X) (\pmb X_i - \pmb X)&#39; \tag{SSR} \\

W &amp;= \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \pmb X_i) (\pmb X_{ij} - \pmb X_i)&#39; \\

&amp;= (n_1 -1)S_1 + \cdots + (n_g -1)S_g \tag{SSE}

\end{align*}\]</span>
$</p>
<ul>
<li>Note:</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{3}

(\pmb X_{ij} - \bar {\pmb X}) 

&amp;= 


(\bar {\pmb X_i} - \bar {\pmb X}) 


+ (\pmb X_{ij} - \bar {\pmb X_i})&amp;&amp;

\\

(\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) &#39;


&amp;= 


(\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39; + 

&amp;&amp;(\bar {\pmb X_i} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X_i})&#39;


+ (\pmb X_{ij} - \bar {\pmb X_i}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39;



+ (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})&#39;


\\

\sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) &#39;

&amp;= \sum_{i=1}^g n_i (\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39; 

&amp;&amp;+ \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})&#39;

\\

T &amp;= B &amp;&amp;+ W



\end{alignat*}\]</span>
$</p>
<ul>
<li>B: Between Sum of Squares</li>
<li>W: Within Sum of Squares</li>
</ul>
<hr />
<p>Any test statistic will be a function of B and W. Popular test statistics use eigenvalues of <span class="math inline">\(BW^{-1}\)</span>.</p>
<p>let <span class="math inline">\(\lambda_1, \cdots, \lambda_r\)</span> be ev of <span class="math inline">\(BW^{-1}\)</span>, where <span class="math inline">\(r=\)</span> ## of non-zero ev’s.</p>
<ol style="list-style-type: decimal">
<li>Wilk’s Lambda (LRT)</li>
</ol>
<p>$
=  =  = _{i=1}^r (1+_1)^{-1}
$</p>
<ol start="2" style="list-style-type: decimal">
<li>Pillai’s Trace</li>
</ol>
<p>$
<span class="math display">\[\begin{align*}
V &amp;= tr[B(B+W)^{-1}] =  tr[B(B(I+B^{-1}W))^{-1}] = tr[B(I+B^{-1}W)^{-1}B^{-1}] \\

&amp;=tr[B^{-1}B(I+B^{-1}W)^{-1}] = tr[(I+B^{-1}W)^{-1}] = tr[I+(B^{-1}W)^{-1}]\\

&amp;=\sum_{i=1}^r \left( \dfrac{\lambda_i}{1+\lambda_i}\right)

\end{align*}\]</span>
$</p>
<ol start="3" style="list-style-type: decimal">
<li>Lawley-Hotelling’s Trace</li>
</ol>
<p>$
T = tr(BW^{-1}) = _{i=1}^r _i
$</p>
<ol start="4" style="list-style-type: decimal">
<li>Roy’s Largest Root</li>
</ol>
<p>$
U = _{i=1,,r} { _i }
$</p>
<hr />
<ul>
<li>Sampling Distribution of Wilk’s Lambda</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{2}
p=1, g \ge 2:

&amp;\left(\dfrac{\sum_{i=1}^g n_i - g}{g-1}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&amp;&amp;\overset{H_0}{\sim} F_{g, \sum_{i=1}^g n_i - g}

\\






p=2, g \ge 2:

&amp;\left(\dfrac{\sum_{i=1}^g n_i - g-1}{g-1}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&amp;&amp;\overset{H_0}{\sim} F_{2(g-1), 2(\sum_{i=1}^g n_i - g-1)}

\\







p\ge1, g = 2:

&amp;\left(\dfrac{n_1 + n_2 - p -1}{p}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&amp;&amp;\overset{H_0}{\sim} F_{p, n_1 + n_2 - p -1}

\\







p \ge 1, g \ge 3:

&amp;\left(\dfrac{\sum_{i=1}^3 n_i - p-2}{p}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&amp;&amp;\overset{H_0}{\sim} F_{2p, 2(\sum_{i=1}^g n_i - p-2)} 

\\

\text{large sample sizes}:



&amp;- \left( \sum_{i=1}^g n_i -1 -\dfrac{p+q}{2}\right) \ln \Lambda^\ast

&amp;&amp;\overset{H_0}{\sim} \chi^2_{p(g-1)} \tag{Why?}

\end{alignat*}\]</span>
$</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-about-mean-vector-wk3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multivariate-multiple-regression-wk6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/211306_ComparisonofSeveralMVMeans.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
