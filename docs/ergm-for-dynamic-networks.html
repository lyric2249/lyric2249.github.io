<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.7 ERGM for Dynamic Networks | Self-Study</title>
  <meta name="description" content="7.7 ERGM for Dynamic Networks | Self-Study" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.7 ERGM for Dynamic Networks | Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="lyric2249/lyric2249.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.7 ERGM for Dynamic Networks | Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="parameter-estimation-of-ergm.html"/>
<link rel="next" href="latent-network-models.html"/>
<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Self</a></li>

<li class="divider"></li>
<li><a href="index.html#intro" id="toc-intro">Intro<span></span></a></li>
<li><a href="#part-20-02" id="toc-part-20-02">(PART) 20-02<span></span></a></li>
<li><a href="categorical.html#categorical" id="toc-categorical"><span class="toc-section-number">1</span> Categorical<span></span></a>
<ul>
<li><a href="overview.html#overview" id="toc-overview"><span class="toc-section-number">1.1</span> Overview<span></span></a>
<ul>
<li><a href="overview.html#data-type-and-statistical-analysis" id="toc-data-type-and-statistical-analysis"><span class="toc-section-number">1.1.1</span> Data Type and Statistical Analysis<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="bayesian.html#bayesian" id="toc-bayesian"><span class="toc-section-number">2</span> Bayesian<span></span></a>
<ul>
<li><a href="abstract.html#abstract" id="toc-abstract"><span class="toc-section-number">2.1</span> Abstract<span></span></a>
<ul>
<li><a href="abstract.html#변수의-독립성" id="toc-변수의-독립성"><span class="toc-section-number">2.1.1</span> 변수의 독립성<span></span></a></li>
<li><a href="abstract.html#교환가능성" id="toc-교환가능성"><span class="toc-section-number">2.1.2</span> 교환가능성<span></span></a></li>
</ul></li>
<li><a href="continual-aeassessment-method.html#continual-aeassessment-method" id="toc-continual-aeassessment-method"><span class="toc-section-number">2.2</span> Continual Aeassessment Method<span></span></a></li>
<li><a href="horseshoe-prior.html#horseshoe-prior" id="toc-horseshoe-prior"><span class="toc-section-number">2.3</span> Horseshoe Prior<span></span></a></li>
</ul></li>
<li><a href="#part-21-01" id="toc-part-21-01">(PART) 21-01<span></span></a></li>
<li><a href="mathematical-stats.html#mathematical-stats" id="toc-mathematical-stats"><span class="toc-section-number">3</span> Mathematical Stats<span></span></a>
<ul>
<li><a href="inference.html#inference" id="toc-inference"><span class="toc-section-number">3.1</span> Inference<span></span></a>
<ul>
<li><a href="inference.html#rao-blackwell-thm." id="toc-rao-blackwell-thm."><span class="toc-section-number">3.1.1</span> Rao-Blackwell thm.<span></span></a></li>
<li><a href="inference.html#completeness" id="toc-completeness"><span class="toc-section-number">3.1.2</span> Completeness<span></span></a></li>
<li><a href="inference.html#레만-쉐페-thm." id="toc-레만-쉐페-thm."><span class="toc-section-number">3.1.3</span> 레만-쉐페 thm.<span></span></a></li>
<li><a href="inference.html#raoblack" id="toc-raoblack"><span class="toc-section-number">3.1.4</span> Rao-Blackwell thm.<span></span></a></li>
</ul></li>
<li><a href="hypothesis-test.html#hypothesis-test" id="toc-hypothesis-test"><span class="toc-section-number">3.2</span> Hypothesis Test<span></span></a></li>
<li><a href="power-fucntion.html#power-fucntion" id="toc-power-fucntion"><span class="toc-section-number">3.3</span> Power Fucntion<span></span></a>
<ul>
<li><a href="power-fucntion.html#significance-probability-p-value" id="toc-significance-probability-p-value"><span class="toc-section-number">3.3.1</span> Significance Probability (p-value)<span></span></a></li>
</ul></li>
<li><a href="optimal-testing-method.html#optimal-testing-method" id="toc-optimal-testing-method"><span class="toc-section-number">3.4</span> Optimal Testing Method<span></span></a></li>
<li><a href="data-reduction.html#data-reduction" id="toc-data-reduction"><span class="toc-section-number">3.5</span> Data Reduction<span></span></a>
<ul>
<li><a href="data-reduction.html#sufficiency-principle" id="toc-sufficiency-principle"><span class="toc-section-number">3.5.1</span> Sufficiency Principle<span></span></a></li>
</ul></li>
<li><a href="borel-paradox.html#borel-paradox" id="toc-borel-paradox"><span class="toc-section-number">3.6</span> Borel Paradox<span></span></a></li>
<li><a href="neymanpearson-lemma.html#neymanpearson-lemma" id="toc-neymanpearson-lemma"><span class="toc-section-number">3.7</span> Neyman–Pearson lemma<span></span></a>
<ul>
<li><a href="neymanpearson-lemma.html#overview-1" id="toc-overview-1"><span class="toc-section-number">3.7.1</span> Overview<span></span></a></li>
<li><a href="neymanpearson-lemma.html#generalized-lrt" id="toc-generalized-lrt"><span class="toc-section-number">3.7.2</span> Generalized LRT<span></span></a></li>
</ul></li>
<li><a href="개념.html#개념" id="toc-개념"><span class="toc-section-number">3.8</span> 개념<span></span></a></li>
</ul></li>
<li><a href="mcmc.html#mcmc" id="toc-mcmc"><span class="toc-section-number">4</span> MCMC<span></span></a>
<ul>
<li><a href="importance-sampling.html#importance-sampling" id="toc-importance-sampling"><span class="toc-section-number">4.1</span> Importance Sampling<span></span></a>
<ul>
<li><a href="importance-sampling.html#independent-monte-carlo" id="toc-independent-monte-carlo"><span class="toc-section-number">4.1.1</span> Independent Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo"><span class="toc-section-number">4.2</span> Markov Chain Monte Carlo<span></span></a>
<ul>
<li><a href="markov-chain-monte-carlo.html#mh-algorithm" id="toc-mh-algorithm"><span class="toc-section-number">4.2.1</span> MH Algorithm<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#random-walk-chains-most-widely-used" id="toc-random-walk-chains-most-widely-used"><span class="toc-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#basic-gibbs-sampler" id="toc-basic-gibbs-sampler"><span class="toc-section-number">4.2.3</span> Basic Gibbs Sampler<span></span></a></li>
<li><a href="markov-chain-monte-carlo.html#implementation" id="toc-implementation"><span class="toc-section-number">4.2.4</span> Implementation<span></span></a></li>
</ul></li>
<li><a href="advanced-mcmc-wk08.html#advanced-mcmc-wk08" id="toc-advanced-mcmc-wk08"><span class="toc-section-number">4.3</span> Advanced MCMC (wk08)<span></span></a>
<ul>
<li><a href="advanced-mcmc-wk08.html#data-augmentation" id="toc-data-augmentation"><span class="toc-section-number">4.3.1</span> Data Augmentation<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#hit-and-run-algorithm" id="toc-hit-and-run-algorithm"><span class="toc-section-number">4.3.2</span> Hit-and-Run Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#metropolis-adjusted-langevin-algorithm" id="toc-metropolis-adjusted-langevin-algorithm"><span class="toc-section-number">4.3.3</span> Metropolis-Adjusted Langevin Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#multiple-try-metropolis-algorithm" id="toc-multiple-try-metropolis-algorithm"><span class="toc-section-number">4.3.4</span> Multiple-Try Metropolis Algorithm<span></span></a></li>
<li><a href="advanced-mcmc-wk08.html#reversible-jump-mcmc-algorithm" id="toc-reversible-jump-mcmc-algorithm"><span class="toc-section-number">4.3.5</span> Reversible Jump MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="auxiliary-variable-mcmc.html#auxiliary-variable-mcmc" id="toc-auxiliary-variable-mcmc"><span class="toc-section-number">4.4</span> Auxiliary Variable MCMC<span></span></a>
<ul>
<li><a href="auxiliary-variable-mcmc.html#introduction" id="toc-introduction"><span class="toc-section-number">4.4.1</span> Introduction<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#multimodal-target-distribution" id="toc-multimodal-target-distribution"><span class="toc-section-number">4.4.2</span> Multimodal Target Distribution<span></span></a></li>
<li><a href="auxiliary-variable-mcmc.html#doubly-intractable-normalizing-constants" id="toc-doubly-intractable-normalizing-constants"><span class="toc-section-number">4.4.3</span> Doubly-intractable Normalizing Constants<span></span></a></li>
</ul></li>
<li><a href="approximate-bayesian-computation.html#approximate-bayesian-computation" id="toc-approximate-bayesian-computation"><span class="toc-section-number">4.5</span> Approximate Bayesian Computation<span></span></a>
<ul>
<li><a href="approximate-bayesian-computation.html#simulator-based-models" id="toc-simulator-based-models"><span class="toc-section-number">4.5.1</span> Simulator-Based Models<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abcifying-monte-carlo-methods" id="toc-abcifying-monte-carlo-methods"><span class="toc-section-number">4.5.2</span> ABCifying Monte Carlo Methods<span></span></a></li>
<li><a href="approximate-bayesian-computation.html#abc-mcmc-algorithm" id="toc-abc-mcmc-algorithm"><span class="toc-section-number">4.5.3</span> ABC-MCMC Algorithm<span></span></a></li>
</ul></li>
<li><a href="hamiltonian-monte-carlo.html#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo"><span class="toc-section-number">4.6</span> Hamiltonian Monte Carlo<span></span></a>
<ul>
<li><a href="hamiltonian-monte-carlo.html#introduction-to-hamiltonian-monte-carlo" id="toc-introduction-to-hamiltonian-monte-carlo"><span class="toc-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo<span></span></a></li>
</ul></li>
<li><a href="population-monte-carlo.html#population-monte-carlo" id="toc-population-monte-carlo"><span class="toc-section-number">4.7</span> Population Monte Carlo<span></span></a>
<ul>
<li><a href="population-monte-carlo.html#adaptive-direction-sampling" id="toc-adaptive-direction-sampling"><span class="toc-section-number">4.7.1</span> Adaptive Direction Sampling<span></span></a></li>
<li><a href="population-monte-carlo.html#conjugate-gradient-mc" id="toc-conjugate-gradient-mc"><span class="toc-section-number">4.7.2</span> Conjugate Gradient MC<span></span></a></li>
<li><a href="population-monte-carlo.html#parallel-tempering" id="toc-parallel-tempering"><span class="toc-section-number">4.7.3</span> Parallel Tempering<span></span></a></li>
<li><a href="population-monte-carlo.html#evolutionary-mc" id="toc-evolutionary-mc"><span class="toc-section-number">4.7.4</span> Evolutionary MC<span></span></a></li>
<li><a href="population-monte-carlo.html#sequential-parallel-tempering" id="toc-sequential-parallel-tempering"><span class="toc-section-number">4.7.5</span> Sequential Parallel Tempering<span></span></a></li>
</ul></li>
<li><a href="stochastic-approximation-monte-carlo.html#stochastic-approximation-monte-carlo" id="toc-stochastic-approximation-monte-carlo"><span class="toc-section-number">4.8</span> Stochastic Approximation Monte Carlo<span></span></a></li>
<li><a href="review.html#review" id="toc-review"><span class="toc-section-number">4.9</span> Review<span></span></a>
<ul>
<li><a href="review.html#wk01" id="toc-wk01"><span class="toc-section-number">4.9.1</span> Wk01<span></span></a></li>
<li><a href="review.html#wk03" id="toc-wk03"><span class="toc-section-number">4.9.2</span> wk03<span></span></a></li>
<li><a href="review.html#wk04-05" id="toc-wk04-05"><span class="toc-section-number">4.9.3</span> wk04, 05<span></span></a></li>
</ul></li>
<li><a href="else.html#else" id="toc-else"><span class="toc-section-number">4.10</span> Else<span></span></a>
<ul>
<li><a href="else.html#hw4.-rasch-model" id="toc-hw4.-rasch-model"><span class="toc-section-number">4.10.1</span> Hw4. Rasch Model<span></span></a></li>
<li><a href="else.html#da-example-mvn" id="toc-da-example-mvn"><span class="toc-section-number">4.10.2</span> DA) Example: MVN<span></span></a></li>
<li><a href="else.html#bayesian-adaptive-clinical-trial-with-delayed-outcomes" id="toc-bayesian-adaptive-clinical-trial-with-delayed-outcomes"><span class="toc-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes<span></span></a></li>
<li><a href="else.html#nmar의-종류" id="toc-nmar의-종류"><span class="toc-section-number">4.10.4</span> NMAR의 종류<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-selection" id="toc-wk10-bayesian-model-selection"><span class="toc-section-number">4.10.5</span> wk10) Bayesian Model Selection<span></span></a></li>
<li><a href="else.html#autologistic-model" id="toc-autologistic-model"><span class="toc-section-number">4.10.6</span> Autologistic model<span></span></a></li>
<li><a href="else.html#wk10-bayesian-model-averaging" id="toc-wk10-bayesian-model-averaging"><span class="toc-section-number">4.10.7</span> wk10) Bayesian Model Averaging<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="mva.html#mva" id="toc-mva"><span class="toc-section-number">5</span> MVA<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#overview-of-mva-not-ended" id="toc-overview-of-mva-not-ended"><span class="toc-section-number">5.1</span> Overview of mva (not ended)<span></span></a>
<ul>
<li><a href="overview-of-mva-not-ended.html#notation" id="toc-notation"><span class="toc-section-number">5.1.1</span> Notation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">5.1.2</span> Summary Statistics<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#statistical-inference-on-correlation" id="toc-statistical-inference-on-correlation"><span class="toc-section-number">5.1.3</span> Statistical Inference on Correlation<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#standardization" id="toc-standardization"><span class="toc-section-number">5.1.4</span> Standardization<span></span></a></li>
<li><a href="overview-of-mva-not-ended.html#missing-value-treatment" id="toc-missing-value-treatment"><span class="toc-section-number">5.1.5</span> Missing Value Treatment<span></span></a></li>
</ul></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-nomral-wk2" id="toc-multivariate-nomral-wk2"><span class="toc-section-number">5.2</span> Multivariate Nomral (wk2)<span></span></a>
<ul>
<li><a href="multivariate-nomral-wk2.html#overview-2" id="toc-overview-2"><span class="toc-section-number">5.2.1</span> Overview<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#spectral-decomposition" id="toc-spectral-decomposition"><span class="toc-section-number">5.2.2</span> Spectral Decomposition<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">5.2.3</span> Properties of MVN<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#chi2-distribution" id="toc-chi2-distribution"><span class="toc-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#linear-combination-of-random-vectors" id="toc-linear-combination-of-random-vectors"><span class="toc-section-number">5.2.5</span> Linear Combination of Random Vectors<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#multivariate-normal-likelihood" id="toc-multivariate-normal-likelihood"><span class="toc-section-number">5.2.6</span> Multivariate Normal Likelihood<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#sampling-distribtion-of-bar-pmb-y-s" id="toc-sampling-distribtion-of-bar-pmb-y-s"><span class="toc-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span><span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#assessing-normality" id="toc-assessing-normality"><span class="toc-section-number">5.2.8</span> Assessing Normality<span></span></a></li>
<li><a href="multivariate-nomral-wk2.html#power-transformation" id="toc-power-transformation"><span class="toc-section-number">5.2.9</span> Power Transformation<span></span></a></li>
</ul></li>
<li><a href="inference-about-mean-vector-wk3.html#inference-about-mean-vector-wk3" id="toc-inference-about-mean-vector-wk3"><span class="toc-section-number">5.3</span> Inference about Mean Vector (wk3)<span></span></a>
<ul>
<li><a href="inference-about-mean-vector-wk3.html#overview-3" id="toc-overview-3"><span class="toc-section-number">5.3.1</span> Overview<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#confidence-region" id="toc-confidence-region"><span class="toc-section-number">5.3.2</span> 1. Confidence Region<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#simultaneous-ci" id="toc-simultaneous-ci"><span class="toc-section-number">5.3.3</span> 2. Simultaneous CI<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#note-bonferroni-multiple-comparison" id="toc-note-bonferroni-multiple-comparison"><span class="toc-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#large-sample-inferences-about-a-mean-vector" id="toc-large-sample-inferences-about-a-mean-vector"><span class="toc-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#profile-analysis-wk4-5" id="toc-profile-analysis-wk4-5"><span class="toc-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#test-for-linear-trend" id="toc-test-for-linear-trend"><span class="toc-section-number">5.3.7</span> 2. Test for Linear Trend<span></span></a></li>
<li><a href="inference-about-mean-vector-wk3.html#inferences-about-a-covariance-matrix" id="toc-inferences-about-a-covariance-matrix"><span class="toc-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix<span></span></a></li>
</ul></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparison-of-several-mv-means-wk5" id="toc-comparison-of-several-mv-means-wk5"><span class="toc-section-number">5.4</span> Comparison of Several MV Means (wk5)<span></span></a>
<ul>
<li><a href="comparison-of-several-mv-means-wk5.html#paired-comparison" id="toc-paired-comparison"><span class="toc-section-number">5.4.1</span> Paired Comparison<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-mean-vectors-from-two-populations" id="toc-comparing-mean-vectors-from-two-populations"><span class="toc-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#profile-analysis-for-g2" id="toc-profile-analysis-for-g2"><span class="toc-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)<span></span></a></li>
<li><a href="comparison-of-several-mv-means-wk5.html#comparing-several-multivariate-population-means" id="toc-comparing-several-multivariate-population-means"><span class="toc-section-number">5.4.4</span> Comparing Several Multivariate Population Means<span></span></a></li>
</ul></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression-wk6" id="toc-multivariate-multiple-regression-wk6"><span class="toc-section-number">5.5</span> Multivariate Multiple Regression (wk6)<span></span></a>
<ul>
<li><a href="multivariate-multiple-regression-wk6.html#overview-4" id="toc-overview-4"><span class="toc-section-number">5.5.1</span> Overview<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#multivariate-multiple-regression" id="toc-multivariate-multiple-regression"><span class="toc-section-number">5.5.2</span> Multivariate Multiple Regression<span></span></a></li>
<li><a href="multivariate-multiple-regression-wk6.html#example" id="toc-example"><span class="toc-section-number">5.5.3</span> Example)<span></span></a></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">5.6</span> PCA<span></span></a></li>
<li><a href="factor.html#factor" id="toc-factor"><span class="toc-section-number">5.7</span> Factor<span></span></a>
<ul>
<li><a href="factor.html#method-of-estimation" id="toc-method-of-estimation"><span class="toc-section-number">5.7.1</span> Method of Estimation<span></span></a></li>
<li><a href="factor.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">5.7.2</span> Factor Rotation<span></span></a></li>
<li><a href="factor.html#varimax-criterion" id="toc-varimax-criterion"><span class="toc-section-number">5.7.3</span> Varimax Criterion<span></span></a></li>
<li><a href="factor.html#factor-scores" id="toc-factor-scores"><span class="toc-section-number">5.7.4</span> Factor Scores<span></span></a></li>
</ul></li>
<li><a href="discrimination-and-classification.html#discrimination-and-classification" id="toc-discrimination-and-classification"><span class="toc-section-number">5.8</span> Discrimination and Classification<span></span></a>
<ul>
<li><a href="discrimination-and-classification.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">5.8.1</span> Bayes Rule<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-two-mv-n-populations" id="toc-classification-with-two-mv-n-populations"><span class="toc-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations<span></span></a></li>
<li><a href="discrimination-and-classification.html#evaluating-classification-functions" id="toc-evaluating-classification-functions"><span class="toc-section-number">5.8.3</span> Evaluating Classification Functions<span></span></a></li>
<li><a href="discrimination-and-classification.html#classification-with-several-populations-wk13" id="toc-classification-with-several-populations-wk13"><span class="toc-section-number">5.8.4</span> Classification with several Populations (wk13)<span></span></a></li>
<li><a href="discrimination-and-classification.html#other-discriminant-analysis-methods" id="toc-other-discriminant-analysis-methods"><span class="toc-section-number">5.8.5</span> Other Discriminant Analysis Methods<span></span></a></li>
</ul></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-distance-methods-and-ordination" id="toc-clustering-distance-methods-and-ordination"><span class="toc-section-number">5.9</span> Clustering, Distance Methods, and Ordination<span></span></a>
<ul>
<li><a href="clustering-distance-methods-and-ordination.html#overview-5" id="toc-overview-5"><span class="toc-section-number">5.9.1</span> Overview<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">5.9.2</span> Hierarchical Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">5.9.3</span> K-means Clustering<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#군집의-평가방법" id="toc-군집의-평가방법"><span class="toc-section-number">5.9.4</span> 군집의 평가방법<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#clustering-using-density-estimation-wk14" id="toc-clustering-using-density-estimation-wk14"><span class="toc-section-number">5.9.5</span> Clustering using Density Estimation (wk14)<span></span></a></li>
<li><a href="clustering-distance-methods-and-ordination.html#multidimensional-scaling-mds" id="toc-multidimensional-scaling-mds"><span class="toc-section-number">5.9.6</span> Multidimensional Scaling (MDS)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="linear.html#linear" id="toc-linear"><span class="toc-section-number">6</span> Linear<span></span></a>
<ul>
<li><a href="overview-svd.html#overview-svd" id="toc-overview-svd"><span class="toc-section-number">6.1</span> Overview &amp; SVD<span></span></a>
<ul>
<li><a href="overview-svd.html#spectral-decomposition-1" id="toc-spectral-decomposition-1"><span class="toc-section-number">6.1.1</span> Spectral Decomposition<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-general-version" id="toc-singular-value-decomposition-general-version"><span class="toc-section-number">6.1.2</span> Singular value Decomposition: General-version<span></span></a></li>
<li><a href="overview-svd.html#singular-value-decomposition-another-version" id="toc-singular-value-decomposition-another-version"><span class="toc-section-number">6.1.3</span> Singular value Decomposition: Another-version<span></span></a></li>
<li><a href="overview-svd.html#quadratic-forms" id="toc-quadratic-forms"><span class="toc-section-number">6.1.4</span> Quadratic Forms<span></span></a></li>
<li><a href="overview-svd.html#partitioned-matrices" id="toc-partitioned-matrices"><span class="toc-section-number">6.1.5</span> Partitioned Matrices<span></span></a></li>
<li><a href="overview-svd.html#geometrical-aspects" id="toc-geometrical-aspects"><span class="toc-section-number">6.1.6</span> Geometrical Aspects<span></span></a></li>
<li><a href="overview-svd.html#column-row-and-null-space" id="toc-column-row-and-null-space"><span class="toc-section-number">6.1.7</span> Column, Row and Null Space<span></span></a></li>
</ul></li>
<li><a href="introduction-1.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.2</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-1.html#what" id="toc-what"><span class="toc-section-number">6.2.1</span> What<span></span></a></li>
<li><a href="introduction-1.html#random-vectors-and-matrices" id="toc-random-vectors-and-matrices"><span class="toc-section-number">6.2.2</span> Random Vectors and Matrices<span></span></a></li>
<li><a href="introduction-1.html#multivariate-normal-distributions" id="toc-multivariate-normal-distributions"><span class="toc-section-number">6.2.3</span> Multivariate Normal Distributions<span></span></a></li>
<li><a href="introduction-1.html#distributions-of-quadratic-forms" id="toc-distributions-of-quadratic-forms"><span class="toc-section-number">6.2.4</span> Distributions of Quadratic Forms<span></span></a></li>
</ul></li>
<li><a href="estimation.html#estimation" id="toc-estimation"><span class="toc-section-number">6.3</span> Estimation<span></span></a>
<ul>
<li><a href="estimation.html#identifiability-and-estimability" id="toc-identifiability-and-estimability"><span class="toc-section-number">6.3.1</span> Identifiability and Estimability<span></span></a></li>
<li><a href="estimation.html#estimation-least-squares" id="toc-estimation-least-squares"><span class="toc-section-number">6.3.2</span> Estimation: Least Squares<span></span></a></li>
<li><a href="estimation.html#estimation-best-linear-unbiased" id="toc-estimation-best-linear-unbiased"><span class="toc-section-number">6.3.3</span> Estimation: Best Linear Unbiased<span></span></a></li>
<li><a href="estimation.html#estimation-maximum-likelihood" id="toc-estimation-maximum-likelihood"><span class="toc-section-number">6.3.4</span> Estimation: Maximum Likelihood<span></span></a></li>
<li><a href="estimation.html#estimation-minimum-variance-unbiased" id="toc-estimation-minimum-variance-unbiased"><span class="toc-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased<span></span></a></li>
<li><a href="estimation.html#sampling-distributions-of-estimates" id="toc-sampling-distributions-of-estimates"><span class="toc-section-number">6.3.6</span> Sampling Distributions of Estimates<span></span></a></li>
<li><a href="estimation.html#generalized-least-squaresgls" id="toc-generalized-least-squaresgls"><span class="toc-section-number">6.3.7</span> Generalized Least Squares(GLS)<span></span></a></li>
</ul></li>
<li><a href="one-way-anova.html#one-way-anova" id="toc-one-way-anova"><span class="toc-section-number">6.4</span> One-Way ANOVA<span></span></a>
<ul>
<li><a href="one-way-anova.html#one-way-anova-1" id="toc-one-way-anova-1"><span class="toc-section-number">6.4.1</span> One-Way ANOVA<span></span></a></li>
<li><a href="one-way-anova.html#more-about-models" id="toc-more-about-models"><span class="toc-section-number">6.4.2</span> More About Models<span></span></a></li>
<li><a href="one-way-anova.html#estimating-and-testing-contrasts" id="toc-estimating-and-testing-contrasts"><span class="toc-section-number">6.4.3</span> Estimating and Testing Contrasts<span></span></a></li>
<li><a href="one-way-anova.html#cochrans-theorem" id="toc-cochrans-theorem"><span class="toc-section-number">6.4.4</span> Cochran’s Theorem<span></span></a></li>
</ul></li>
<li><a href="testing.html#testing" id="toc-testing"><span class="toc-section-number">6.5</span> Testing<span></span></a>
<ul>
<li><a href="testing.html#more-about-models-two-approaches-for-linear-model" id="toc-more-about-models-two-approaches-for-linear-model"><span class="toc-section-number">6.5.1</span> More About Models: Two approaches for linear model<span></span></a></li>
<li><a href="testing.html#testing-models" id="toc-testing-models"><span class="toc-section-number">6.5.2</span> Testing Models<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure" id="toc-a-generalized-test-procedure"><span class="toc-section-number">6.5.3</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-linear-parametric-functions" id="toc-testing-linear-parametric-functions"><span class="toc-section-number">6.5.4</span> Testing Linear Parametric Functions<span></span></a></li>
<li><a href="testing.html#theoretical-complements" id="toc-theoretical-complements"><span class="toc-section-number">6.5.5</span> Theoretical Complements<span></span></a></li>
<li><a href="testing.html#a-generalized-test-procedure-1" id="toc-a-generalized-test-procedure-1"><span class="toc-section-number">6.5.6</span> A Generalized Test Procedure<span></span></a></li>
<li><a href="testing.html#testing-single-degrees-of-freedom-in-a-given-subspace" id="toc-testing-single-degrees-of-freedom-in-a-given-subspace"><span class="toc-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace<span></span></a></li>
<li><a href="testing.html#breaking-ss-into-independent-components" id="toc-breaking-ss-into-independent-components"><span class="toc-section-number">6.5.8</span> Breaking SS into Independent Components<span></span></a></li>
<li><a href="testing.html#general-theory" id="toc-general-theory"><span class="toc-section-number">6.5.9</span> General Theory<span></span></a></li>
<li><a href="testing.html#two-way-anova" id="toc-two-way-anova"><span class="toc-section-number">6.5.10</span> Two-Way ANOVA<span></span></a></li>
<li><a href="testing.html#confidence-regions" id="toc-confidence-regions"><span class="toc-section-number">6.5.11</span> Confidence Regions<span></span></a></li>
<li><a href="testing.html#tests-for-generalized-least-squares-models" id="toc-tests-for-generalized-least-squares-models"><span class="toc-section-number">6.5.12</span> Tests for Generalized Least Squares Models<span></span></a></li>
</ul></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">6.6</span> Generalized Least Squares<span></span></a>
<ul>
<li><a href="generalized-least-squares.html#a-direct-solution-via-inner-products" id="toc-a-direct-solution-via-inner-products"><span class="toc-section-number">6.6.1</span> A direct solution via inner products<span></span></a></li>
</ul></li>
<li><a href="flat.html#flat" id="toc-flat"><span class="toc-section-number">6.7</span> Flat<span></span></a>
<ul>
<li><a href="flat.html#flat-1" id="toc-flat-1"><span class="toc-section-number">6.7.1</span> 1.Flat<span></span></a></li>
<li><a href="flat.html#solutions-to-systems-of-linear-equations" id="toc-solutions-to-systems-of-linear-equations"><span class="toc-section-number">6.7.2</span> 2. Solutions to systems of linear equations<span></span></a></li>
</ul></li>
<li><a href="unified-approach-to-balanced-anova-models.html#unified-approach-to-balanced-anova-models" id="toc-unified-approach-to-balanced-anova-models"><span class="toc-section-number">6.8</span> Unified Approach to Balanced ANOVA Models<span></span></a></li>
</ul></li>
<li><a href="#part-21-02" id="toc-part-21-02">(PART) 21-02<span></span></a></li>
<li><a href="network-stats.html#network-stats" id="toc-network-stats"><span class="toc-section-number">7</span> Network Stats<span></span></a>
<ul>
<li><a href="introduction-2.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">7.1</span> Introduction<span></span></a>
<ul>
<li><a href="introduction-2.html#types-of-network-analysis" id="toc-types-of-network-analysis"><span class="toc-section-number">7.1.1</span> Types of Network Analysis<span></span></a></li>
<li><a href="introduction-2.html#network-modeling-and-inference" id="toc-network-modeling-and-inference"><span class="toc-section-number">7.1.2</span> Network Modeling and Inference<span></span></a></li>
<li><a href="introduction-2.html#network-processes" id="toc-network-processes"><span class="toc-section-number">7.1.3</span> Network Processes<span></span></a></li>
</ul></li>
<li><a href="descriptive-statistics-of-networks.html#descriptive-statistics-of-networks" id="toc-descriptive-statistics-of-networks"><span class="toc-section-number">7.2</span> Descriptive Statistics of Networks<span></span></a>
<ul>
<li><a href="descriptive-statistics-of-networks.html#vertex-and-edge-characteristics" id="toc-vertex-and-edge-characteristics"><span class="toc-section-number">7.2.1</span> Vertex and Edge Characteristics<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#characterizing-network-cohesion" id="toc-characterizing-network-cohesion"><span class="toc-section-number">7.2.2</span> Characterizing Network Cohesion<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#graph-partitioning" id="toc-graph-partitioning"><span class="toc-section-number">7.2.3</span> Graph Partitioning<span></span></a></li>
<li><a href="descriptive-statistics-of-networks.html#assortativity-and-mixing" id="toc-assortativity-and-mixing"><span class="toc-section-number">7.2.4</span> Assortativity and Mixing<span></span></a></li>
</ul></li>
<li><a href="data-collection-and-sampling.html#data-collection-and-sampling" id="toc-data-collection-and-sampling"><span class="toc-section-number">7.3</span> Data Collection and Sampling<span></span></a>
<ul>
<li><a href="data-collection-and-sampling.html#sampling-designs" id="toc-sampling-designs"><span class="toc-section-number">7.3.1</span> Sampling Designs<span></span></a></li>
<li><a href="data-collection-and-sampling.html#coping-strategies" id="toc-coping-strategies"><span class="toc-section-number">7.3.2</span> Coping Strategies<span></span></a></li>
<li><a href="data-collection-and-sampling.html#big-data-solves-nothing" id="toc-big-data-solves-nothing"><span class="toc-section-number">7.3.3</span> Big Data Solves Nothing<span></span></a></li>
</ul></li>
<li><a href="mathematical-models-for-network-graphs.html#mathematical-models-for-network-graphs" id="toc-mathematical-models-for-network-graphs"><span class="toc-section-number">7.4</span> Mathematical Models for Network Graphs<span></span></a>
<ul>
<li><a href="mathematical-models-for-network-graphs.html#classical-random-graph-models" id="toc-classical-random-graph-models"><span class="toc-section-number">7.4.1</span> Classical Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#generalized-random-graph-models" id="toc-generalized-random-graph-models"><span class="toc-section-number">7.4.2</span> Generalized Random Graph Models<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#network-graph-models-based-on-mechanisms" id="toc-network-graph-models-based-on-mechanisms"><span class="toc-section-number">7.4.3</span> Network Graph Models Based on Mechanisms<span></span></a></li>
<li><a href="mathematical-models-for-network-graphs.html#assessing-significance-of-network-graph-characteristics" id="toc-assessing-significance-of-network-graph-characteristics"><span class="toc-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics<span></span></a></li>
</ul></li>
<li><a href="introduction-to-ergm.html#introduction-to-ergm" id="toc-introduction-to-ergm"><span class="toc-section-number">7.5</span> Introduction to ERGM<span></span></a>
<ul>
<li><a href="introduction-to-ergm.html#exponential-random-graph-models" id="toc-exponential-random-graph-models"><span class="toc-section-number">7.5.1</span> Exponential Random Graph Models<span></span></a></li>
<li><a href="introduction-to-ergm.html#difficulty-in-parameter-estimation" id="toc-difficulty-in-parameter-estimation"><span class="toc-section-number">7.5.2</span> Difficulty in Parameter Estimation<span></span></a></li>
</ul></li>
<li><a href="parameter-estimation-of-ergm.html#parameter-estimation-of-ergm" id="toc-parameter-estimation-of-ergm"><span class="toc-section-number">7.6</span> Parameter Estimation of ERGM<span></span></a>
<ul>
<li><a href="parameter-estimation-of-ergm.html#current-methods-for-ergm" id="toc-current-methods-for-ergm"><span class="toc-section-number">7.6.1</span> Current Methods for ERGM<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#approximation-based-algorithm" id="toc-approximation-based-algorithm"><span class="toc-section-number">7.6.2</span> Approximation-based Algorithm<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#auxiliary-variable-mcmc-based-approaches" id="toc-auxiliary-variable-mcmc-based-approaches"><span class="toc-section-number">7.6.3</span> Auxiliary Variable MCMC-based Approaches<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#varying-trunction-stochastic-approximation-mcmc" id="toc-varying-trunction-stochastic-approximation-mcmc"><span class="toc-section-number">7.6.4</span> Varying Trunction Stochastic Approximation MCMC<span></span></a></li>
<li><a href="parameter-estimation-of-ergm.html#conclusion" id="toc-conclusion"><span class="toc-section-number">7.6.5</span> Conclusion<span></span></a></li>
</ul></li>
<li><a href="ergm-for-dynamic-networks.html#ergm-for-dynamic-networks" id="toc-ergm-for-dynamic-networks"><span class="toc-section-number">7.7</span> ERGM for Dynamic Networks<span></span></a>
<ul>
<li><a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm" id="toc-temporal-ergm-tergm-t-ergm"><span class="toc-section-number">7.7.1</span> Temporal ERGM (TERGM, T ERGM)<span></span></a></li>
<li><a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm" id="toc-separable-temporal-ergm-stergm-st-ergm"><span class="toc-section-number">7.7.2</span> Separable Temporal ERGM (STERGM, ST ERGM)<span></span></a></li>
</ul></li>
<li><a href="latent-network-models.html#latent-network-models" id="toc-latent-network-models"><span class="toc-section-number">7.8</span> Latent Network Models<span></span></a>
<ul>
<li><a href="latent-network-models.html#latent-position-model" id="toc-latent-position-model"><span class="toc-section-number">7.8.1</span> Latent Position Model<span></span></a></li>
<li><a href="latent-network-models.html#latent-position-cluster-model" id="toc-latent-position-cluster-model"><span class="toc-section-number">7.8.2</span> Latent Position Cluster Model<span></span></a></li>
</ul></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#additive-and-multiplicative-effects-network-models" id="toc-additive-and-multiplicative-effects-network-models"><span class="toc-section-number">7.9</span> Additive and Multiplicative Effects Network Models<span></span></a>
<ul>
<li><a href="additive-and-multiplicative-effects-network-models.html#introduction-3" id="toc-introduction-3"><span class="toc-section-number">7.9.1</span> Introduction<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#social-relations-regression" id="toc-social-relations-regression"><span class="toc-section-number">7.9.2</span> Social Relations Regression<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#multiplicative-effects-models" id="toc-multiplicative-effects-models"><span class="toc-section-number">7.9.3</span> Multiplicative Effects Models<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#inference-via-posterior-approximation" id="toc-inference-via-posterior-approximation"><span class="toc-section-number">7.9.4</span> Inference via Posterior Approximation<span></span></a></li>
<li><a href="additive-and-multiplicative-effects-network-models.html#discussion-and-example-with-r" id="toc-discussion-and-example-with-r"><span class="toc-section-number">7.9.5</span> Discussion and Example with R<span></span></a></li>
</ul></li>
<li><a href="stochastic-block-models.html#stochastic-block-models" id="toc-stochastic-block-models"><span class="toc-section-number">7.10</span> Stochastic Block Models<span></span></a>
<ul>
<li><a href="stochastic-block-models.html#stochastic-block-model" id="toc-stochastic-block-model"><span class="toc-section-number">7.10.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="stochastic-block-models.html#mixed-membership-block-model-mmbm" id="toc-mixed-membership-block-model-mmbm"><span class="toc-section-number">7.10.2</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="high-dimension.html#high-dimension" id="toc-high-dimension"><span class="toc-section-number">8</span> High Dimension<span></span></a>
<ul>
<li><a href="introduction-4.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">8.1</span> Introduction<span></span></a></li>
<li><a href="concentration-inequalities.html#concentration-inequalities" id="toc-concentration-inequalities"><span class="toc-section-number">8.2</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities.html#motivation" id="toc-motivation"><span class="toc-section-number">8.2.1</span> Motivation<span></span></a></li>
<li><a href="concentration-inequalities.html#from-markov-to-chernoff" id="toc-from-markov-to-chernoff"><span class="toc-section-number">8.2.2</span> From Markov to Chernoff<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-variables" id="toc-sub-gaussian-random-variables"><span class="toc-section-number">8.2.3</span> sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#properties-of-sub-gaussian-random-variables" id="toc-properties-of-sub-gaussian-random-variables"><span class="toc-section-number">8.2.4</span> Properties of sub-Gaussian random variables<span></span></a></li>
<li><a href="concentration-inequalities.html#equivalent-definitions" id="toc-equivalent-definitions"><span class="toc-section-number">8.2.5</span> Equivalent definitions<span></span></a></li>
<li><a href="concentration-inequalities.html#sub-gaussian-random-vectors" id="toc-sub-gaussian-random-vectors"><span class="toc-section-number">8.2.6</span> Sub-Gaussian random vectors<span></span></a></li>
<li><a href="concentration-inequalities.html#hoeffdings-inequality" id="toc-hoeffdings-inequality"><span class="toc-section-number">8.2.7</span> Hoeffding’s inequality<span></span></a></li>
<li><a href="concentration-inequalities.html#maximal-inequalities" id="toc-maximal-inequalities"><span class="toc-section-number">8.2.8</span> Maximal inequalities<span></span></a></li>
<li><a href="concentration-inequalities.html#section" id="toc-section"><span class="toc-section-number">8.2.9</span> </a></li>
</ul></li>
<li><a href="concentration-inequalities-1.html#concentration-inequalities-1" id="toc-concentration-inequalities-1"><span class="toc-section-number">8.3</span> Concentration inequalities<span></span></a>
<ul>
<li><a href="concentration-inequalities-1.html#sub-exponential-random-variables" id="toc-sub-exponential-random-variables"><span class="toc-section-number">8.3.1</span> Sub-exponential random variables<span></span></a></li>
<li><a href="concentration-inequalities-1.html#bernsteins-condition" id="toc-bernsteins-condition"><span class="toc-section-number">8.3.2</span> Bernstein’s condition<span></span></a></li>
<li><a href="concentration-inequalities-1.html#mcdiarmids-inequality" id="toc-mcdiarmids-inequality"><span class="toc-section-number">8.3.3</span> McDiarmid’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#levys-inequality" id="toc-levys-inequality"><span class="toc-section-number">8.3.4</span> Levy’s inequality<span></span></a></li>
<li><a href="concentration-inequalities-1.html#quadratic-form" id="toc-quadratic-form"><span class="toc-section-number">8.3.5</span> Quadratic form<span></span></a></li>
<li><a href="concentration-inequalities-1.html#the-johnsonlindenstrauss-lemma" id="toc-the-johnsonlindenstrauss-lemma"><span class="toc-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma<span></span></a></li>
</ul></li>
<li><a href="metric-entropy-and-its-uses.html#metric-entropy-and-its-uses" id="toc-metric-entropy-and-its-uses"><span class="toc-section-number">8.4</span> Metric entropy and its uses<span></span></a>
<ul>
<li><a href="metric-entropy-and-its-uses.html#metric-space" id="toc-metric-space"><span class="toc-section-number">8.4.1</span> Metric space<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#covering-numbers-and-metric-entropy" id="toc-covering-numbers-and-metric-entropy"><span class="toc-section-number">8.4.2</span> Covering numbers and metric entropy<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#packing-numbers" id="toc-packing-numbers"><span class="toc-section-number">8.4.3</span> Packing numbers<span></span></a></li>
<li><a href="metric-entropy-and-its-uses.html#section-1" id="toc-section-1"><span class="toc-section-number">8.4.4</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-2" id="toc-section-2"><span class="toc-section-number">8.4.5</span> </a></li>
<li><a href="metric-entropy-and-its-uses.html#section-3" id="toc-section-3"><span class="toc-section-number">8.4.6</span> </a></li>
</ul></li>
<li><a href="covariance-estimation.html#covariance-estimation" id="toc-covariance-estimation"><span class="toc-section-number">8.5</span> Covariance estimation<span></span></a>
<ul>
<li><a href="covariance-estimation.html#matrix-algebra-review" id="toc-matrix-algebra-review"><span class="toc-section-number">8.5.1</span> Matrix algebra review<span></span></a></li>
<li><a href="covariance-estimation.html#covariance-matrix-estimation-in-the-operator-norm" id="toc-covariance-matrix-estimation-in-the-operator-norm"><span class="toc-section-number">8.5.2</span> Covariance matrix estimation in the operator norm<span></span></a></li>
<li><a href="covariance-estimation.html#bounds-for-structured-covariance-matrices" id="toc-bounds-for-structured-covariance-matrices"><span class="toc-section-number">8.5.3</span> Bounds for structured covariance matrices<span></span></a></li>
</ul></li>
<li><a href="matrix-concentration-inequalities.html#matrix-concentration-inequalities" id="toc-matrix-concentration-inequalities"><span class="toc-section-number">8.6</span> Matrix concentration inequalities<span></span></a>
<ul>
<li><a href="matrix-concentration-inequalities.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">8.6.1</span> Matrix calculus<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#matrix-chernoff" id="toc-matrix-chernoff"><span class="toc-section-number">8.6.2</span> Matrix Chernoff<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#sub-gaussian-and-sub-exponential-matrices" id="toc-sub-gaussian-and-sub-exponential-matrices"><span class="toc-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices<span></span></a></li>
<li><a href="matrix-concentration-inequalities.html#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds" id="toc-랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><span class="toc-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds<span></span></a></li>
</ul></li>
<li><a href="principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.7</span> Principal Component Analysis<span></span></a>
<ul>
<li><a href="principal-component-analysis.html#pca-1" id="toc-pca-1"><span class="toc-section-number">8.7.1</span> PCA<span></span></a></li>
<li><a href="principal-component-analysis.html#matrix-perturbation" id="toc-matrix-perturbation"><span class="toc-section-number">8.7.2</span> Matrix Perturbation<span></span></a></li>
<li><a href="principal-component-analysis.html#spiked-cov-model" id="toc-spiked-cov-model"><span class="toc-section-number">8.7.3</span> Spiked Cov Model<span></span></a></li>
<li><a href="principal-component-analysis.html#sparse-pca" id="toc-sparse-pca"><span class="toc-section-number">8.7.4</span> sparse PCA<span></span></a></li>
</ul></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">8.8</span> Linear Regression<span></span></a>
<ul>
<li><a href="linear-regression.html#problem-formulation" id="toc-problem-formulation"><span class="toc-section-number">8.8.1</span> Problem formulation<span></span></a></li>
<li><a href="linear-regression.html#least-squares-estimator-in-high-dimensions" id="toc-least-squares-estimator-in-high-dimensions"><span class="toc-section-number">8.8.2</span> Least Squares Estimator in high dimensions<span></span></a></li>
<li><a href="linear-regression.html#sparse-linear-regression" id="toc-sparse-linear-regression"><span class="toc-section-number">8.8.3</span> Sparse linear regression<span></span></a></li>
</ul></li>
<li><a href="uniform-laws-of-large-numbers.html#uniform-laws-of-large-numbers" id="toc-uniform-laws-of-large-numbers"><span class="toc-section-number">8.9</span> Uniform laws of large numbers<span></span></a>
<ul>
<li><a href="uniform-laws-of-large-numbers.html#motivation-1" id="toc-motivation-1"><span class="toc-section-number">8.9.1</span> Motivation<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#a-uniform-law-via-rademacher-complexity" id="toc-a-uniform-law-via-rademacher-complexity"><span class="toc-section-number">8.9.2</span> A uniform law via Rademacher complexity<span></span></a></li>
<li><a href="uniform-laws-of-large-numbers.html#upper-bounds-on-the-rademacher-complexity" id="toc-upper-bounds-on-the-rademacher-complexity"><span class="toc-section-number">8.9.3</span> Upper bounds on the Rademacher complexity<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">9</span> Survival Analysis<span></span></a>
<ul>
<li><a href="introduction-5.html#introduction-5" id="toc-introduction-5"><span class="toc-section-number">9.1</span> Introduction<span></span></a></li>
<li><a href="section-4.html#section-4" id="toc-section-4"><span class="toc-section-number">9.2</span> </a></li>
<li><a href="counting-processes-and-martingales.html#counting-processes-and-martingales" id="toc-counting-processes-and-martingales"><span class="toc-section-number">9.3</span> Counting Processes and Martingales<span></span></a>
<ul>
<li><a href="counting-processes-and-martingales.html#conditional-expectation" id="toc-conditional-expectation"><span class="toc-section-number">9.3.1</span> Conditional Expectation<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#martingale" id="toc-martingale"><span class="toc-section-number">9.3.2</span> Martingale<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#key-martingales-properties" id="toc-key-martingales-properties"><span class="toc-section-number">9.3.3</span> Key Martingales Properties<span></span></a></li>
<li><a href="counting-processes-and-martingales.html#section-5" id="toc-section-5"><span class="toc-section-number">9.3.4</span> </a></li>
<li><a href="counting-processes-and-martingales.html#section-6" id="toc-section-6"><span class="toc-section-number">9.3.5</span> </a></li>
</ul></li>
<li><a href="section-7.html#section-7" id="toc-section-7"><span class="toc-section-number">9.4</span> </a></li>
<li><a href="cox-regression.html#cox-regression" id="toc-cox-regression"><span class="toc-section-number">9.5</span> Cox Regression<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#filtration의-개념을-정복하자" id="toc-filtration의-개념을-정복하자"><span class="toc-section-number">9.6</span> Filtration의 개념을 정복하자!<span></span></a>
<ul>
<li><a href="filtration의-개념을-정복하자.html#random-process를-이야기-하기까지의-긴-여정의-요약" id="toc-random-process를-이야기-하기까지의-긴-여정의-요약"><span class="toc-section-number">9.6.1</span> Random Process를 이야기 하기까지의 긴 여정의 요약<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#ft-measurable" id="toc-ft-measurable"><span class="toc-section-number">9.6.2</span> Ft-measurable<span></span></a></li>
<li><a href="filtration의-개념을-정복하자.html#epilogue" id="toc-epilogue"><span class="toc-section-number">9.6.3</span> EPILOGUE<span></span></a></li>
</ul></li>
<li><a href="concepts.html#concepts" id="toc-concepts"><span class="toc-section-number">9.7</span> Concepts<span></span></a></li>
</ul></li>
<li><a href="#part-22-01" id="toc-part-22-01">(PART) 22-01<span></span></a></li>
<li><a href="scikit.html#scikit" id="toc-scikit"><span class="toc-section-number">10</span> scikit<span></span></a>
<ul>
<li><a href="linear-models.html#linear-models" id="toc-linear-models"><span class="toc-section-number">10.1</span> Linear Models<span></span></a>
<ul>
<li><a href="linear-models.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">10.1.1</span> Ordinary Least Squares<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="#appendix-00-00" id="toc-appendix-00-00">(APPENDIX) 00-00<span></span></a></li>
<li><a href="concepts-1.html#concepts-1" id="toc-concepts-1"><span class="toc-section-number">11</span> Concepts<span></span></a>
<ul>
<li><a href="autologistic.html#autologistic" id="toc-autologistic"><span class="toc-section-number">11.1</span> Autologistics<span></span></a></li>
<li><a href="orderlogit.html#orderlogit" id="toc-orderlogit"><span class="toc-section-number">11.2</span> Ordered Logit<span></span></a></li>
<li><a href="concepts-questions.html#concepts-questions" id="toc-concepts-questions"><span class="toc-section-number">11.3</span> Concepts Questions<span></span></a>
<ul>
<li><a href="concepts-questions.html#통계-및-수학" id="toc-통계-및-수학"><span class="toc-section-number">11.3.1</span> 통계 및 수학<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="about-cluster-gcn.html#about-cluster-gcn" id="toc-about-cluster-gcn"><span class="toc-section-number">12</span> About Cluster-GCN<span></span></a>
<ul>
<li><a href="about-cluster-gcn.html#ann" id="toc-ann"><span class="toc-section-number">12.0.1</span> ANN<span></span></a></li>
<li><a href="about-cluster-gcn.html#cnn" id="toc-cnn"><span class="toc-section-number">12.0.2</span> CNN<span></span></a></li>
<li><a href="about-cluster-gcn.html#graph-convolution-network" id="toc-graph-convolution-network"><span class="toc-section-number">12.0.3</span> Graph Convolution Network<span></span></a></li>
<li><a href="about-cluster-gcn.html#cluster-gcn" id="toc-cluster-gcn"><span class="toc-section-number">12.0.4</span> Cluster-GCN<span></span></a></li>
</ul></li>
<li><a href="cnn-1.html#cnn-1" id="toc-cnn-1"><span class="toc-section-number">13</span> CNN<span></span></a></li>
<li><a href="cnn-2.html#cnn-2" id="toc-cnn-2"><span class="toc-section-number">14</span> CNN<span></span></a></li>
<li><a href="cnn-3.html#cnn-3" id="toc-cnn-3"><span class="toc-section-number">15</span> CNN<span></span></a></li>
<li><a href="section-8.html#section-8" id="toc-section-8"><span class="toc-section-number">16</span> 01<span></span></a></li>
<li><a href="section-9.html#section-9" id="toc-section-9"><span class="toc-section-number">17</span> 02<span></span></a></li>
<li><a href="서-론.html#서-론" id="toc-서-론"><span class="toc-section-number">18</span> 서 론<span></span></a>
<ul>
<li><a href="연구-배경.html#연구-배경" id="toc-연구-배경"><span class="toc-section-number">18.1</span> 연구 배경<span></span></a></li>
<li><a href="연구-목적.html#연구-목적" id="toc-연구-목적"><span class="toc-section-number">18.2</span> 연구 목적<span></span></a></li>
</ul></li>
<li><a href="method.html#method" id="toc-method"><span class="toc-section-number">19</span> Method<span></span></a>
<ul>
<li><a href="biterm.html#biterm" id="toc-biterm"><span class="toc-section-number">19.1</span> Biterm<span></span></a>
<ul>
<li><a href="biterm.html#section-10" id="toc-section-10"><span class="toc-section-number">19.1.1</span> 2.1.1<span></span></a></li>
<li><a href="biterm.html#줄-요약" id="toc-줄-요약"><span class="toc-section-number">19.1.2</span> 3줄 요약<span></span></a></li>
<li><a href="biterm.html#section-11" id="toc-section-11"><span class="toc-section-number">19.1.3</span> 2.1.2<span></span></a></li>
<li><a href="biterm.html#latent-space-item-response-model" id="toc-latent-space-item-response-model"><span class="toc-section-number">19.1.4</span> 2.1.3 Latent Space Item Response Model<span></span></a></li>
<li><a href="biterm.html#procrustes-matching-and-oblique-roation" id="toc-procrustes-matching-and-oblique-roation"><span class="toc-section-number">19.1.5</span> Procrustes Matching and Oblique Roation<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="latent-space-item-response-model-구현.html#latent-space-item-response-model-구현" id="toc-latent-space-item-response-model-구현"><span class="toc-section-number">20</span> Latent Space Item Response Model 구현<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브로-모델-설계" id="toc-python-네이티브로-모델-설계"><span class="toc-section-number">20.1</span> 3.1. python 네이티브로 모델 설계<span></span></a>
<ul>
<li><a href="python-네이티브로-모델-설계.html#python-네이티브에서의-속도-퍼포먼스" id="toc-python-네이티브에서의-속도-퍼포먼스"><span class="toc-section-number">20.1.1</span> 3.1.1. python 네이티브에서의 속도 퍼포먼스<span></span></a></li>
</ul></li>
<li><a href="python에-c-접합한-모델-설계.html#python에-c-접합한-모델-설계" id="toc-python에-c-접합한-모델-설계"><span class="toc-section-number">20.2</span> 3.2. python에 c++ 접합한 모델 설계<span></span></a>
<ul>
<li><a href="python에-c-접합한-모델-설계.html#wrapping-timing" id="toc-wrapping-timing"><span class="toc-section-number">20.2.1</span> Wrapping Timing<span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#library-needed-in-c" id="toc-library-needed-in-c"><span class="toc-section-number">20.2.2</span> Library needed in <code>c++</code><span></span></a></li>
<li><a href="python에-c-접합한-모델-설계.html#접합-모델-검증-및-성능-비교" id="toc-접합-모델-검증-및-성능-비교"><span class="toc-section-number">20.2.3</span> 3.2.1. 접합 모델 검증 및 성능 비교<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="implementation-1.html#implementation-1" id="toc-implementation-1"><span class="toc-section-number">21</span> Implementation<span></span></a>
<ul>
<li><a href="preprocess.html#preprocess" id="toc-preprocess"><span class="toc-section-number">21.1</span> <code>preprocess()</code><span></span></a></li>
<li><a href="btmize.html#btmize" id="toc-btmize"><span class="toc-section-number">21.2</span> <code>btmize()</code><span></span></a></li>
<li><a href="lsirmize.html#lsirmize" id="toc-lsirmize"><span class="toc-section-number">21.3</span> <code>lsirmize()</code><span></span></a></li>
</ul></li>
<li><a href="구현-모델-실적용-예시.html#구현-모델-실적용-예시" id="toc-구현-모델-실적용-예시"><span class="toc-section-number">22</span> 구현 모델 실적용 예시<span></span></a>
<ul>
<li><a href="데이터-서술.html#데이터-서술" id="toc-데이터-서술"><span class="toc-section-number">22.1</span> 4.1 데이터 서술<span></span></a></li>
<li><a href="알고리즘-결과.html#알고리즘-결과" id="toc-알고리즘-결과"><span class="toc-section-number">22.2</span> 4.2 알고리즘 결과<span></span></a></li>
</ul></li>
<li><a href="결론.html#결론" id="toc-결론"><span class="toc-section-number">23</span> 결론<span></span></a>
<ul>
<li><a href="section-12.html#section-12" id="toc-section-12"><span class="toc-section-number">23.1</span> 10.<span></span></a>
<ul>
<li><a href="section-12.html#stochastic-block-model-1" id="toc-stochastic-block-model-1"><span class="toc-section-number">23.1.1</span> Stochastic Block Model<span></span></a></li>
<li><a href="section-12.html#likelihood-function-1" id="toc-likelihood-function-1"><span class="toc-section-number">23.1.2</span> Likelihood function<span></span></a></li>
<li><a href="section-12.html#mixed-membership-block-model-mmbm-1" id="toc-mixed-membership-block-model-mmbm-1"><span class="toc-section-number">23.1.3</span> Mixed Membership Block Model (MMBM)<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ergm-for-dynamic-networks" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> ERGM for Dynamic Networks<a href="ergm-for-dynamic-networks.html#ergm-for-dynamic-networks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><pic></p>
<p>However, a need for statistical models representing the evolving phenomena ⇒ ”Dynamic Models” with a temporal structure</p>
<ul>
<li><strong>ERGM → TERGM → STERGM</strong></li>
</ul>
<p>One-step transition probability <span class="math inline">\((t-1) → (t)\)</span> (Markov Assumption)</p>
<p><span class="math display">\[
P_{\eta, g} \Big ( Y^t = y^t \Big | Y^{t-1} \; \; ; \; \; \theta \Big ) = \frac{\exp \Big \{ \eta(\theta) \cdot g(y^t, y^{t-1})\Big  \}}{c_{\eta, h}(\theta, y^{t-1})}
\]</span></p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="temporal-ergm-tergm-t-ergm" class="section level3 hasAnchor" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Temporal ERGM (TERGM, T ERGM)<a href="ergm-for-dynamic-networks.html#temporal-ergm-tergm-t-ergm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>시간 t에서의 네트워크는, t-1 시점의 (어쩌면 t-2도 가능하고) 네트워크로 조건을 건 ERGM 으로부터의 단일 생산으로 생각될 수 있음. 소셜 네트워크의 변화를 간단히 하기 위해 <strong>Markov assumption</strong> 적용.</p>
<p>이는 곧, <span class="math inline">\(A^t\)</span>가 t 시점에서의 단일-관계 소셜 네트워크의 weight 매트릭스를 표현하고, 우리에게 <span class="math inline">\(A^{t-1}\)</span> 의 값이 주어져 있다면, <span class="math inline">\(A^t\)</span> 는 <span class="math inline">\(A^1, \cdots, A^{t-2}\)</span> 으로부터는 독립임을 의미한다는 뜻. 수식으로 표현하면 아래와 같다.</p>
<p><span class="math display">\[
P\Big(A^2, A^3, \cdots, A^t \Big | A^1 \Big ) = P\Big(A^t \Big | A^{t-1} \Big ) P\Big(A^{t-1} \Big | A^{t-2} \Big ) \cdots P\Big(A^2 \Big | A^1 \Big ) \tag{Temporal ERGM}
\]</span></p>
<p>마르코프 가정이 주어져 있음을 고려하면, evolving 네트워크 전반에 대해 ERGM 을 일반화하는 방법이란 <span class="math inline">\(A^t \vert A^{t-1}\)</span> 가 ERGM 표현법을 채택했음을 가정하는 것. <mark>to assume <span class="math inline">\(A^t \vert A^{t-1}\)</span> admits an ERGM representation.</mark></p>
<p>함수 <span class="math inline">\(\Psi : \mathbb R_{n \times n} \times \mathbb R_{n \times n} \rightarrow \mathbb R^k\)</span> 를 생각해보자. 이는 시간적으로 인접한 2개의 네트워크 (<span class="math inline">\(t\)</span>, <span class="math inline">\(t-1\)</span> 등) 에 걸친 cliques 들의 잠재적은 potential로 인지될 수 있다. 이때 패러미터 벡터 <span class="math inline">\(\theta \in \mathbb R^k\)</span> 는 이하와 같은 conditional pdf를 가지며, <mark><span class="math inline">\(\theta_i\)</span> 는 곧 tendency to have more <span class="math inline">\(S_i\)</span> network statistics as time evolves.</mark></p>
<p><span class="math display">\[
P \bigg( A^t \Big | A^{t-1}, \theta \bigg) = \frac{1}{\kappa(\theta, A^{t-1})} \exp \left\{ \theta&#39; \Psi \left ( A^t, A^{t-1} \right ) \right\}
\]</span></p>
<p>joint likelihood 에서 <span class="math inline">\(\theta &#39;\)</span> 는, as time evolves, how likely to have this network statistics.</p>
<p>특히 우리는 해당 모델에서 이하와 같은 특수한 경우에 관심이 있다.</p>
<p><span class="math display">\[
\Psi \left ( A^t, A^{t-1} \right ) = \sum_{ij}\Psi_{ij} \left ( A^t_{ij}, A^{t-1} \right )
\]</span></p>
<p>이 형의 temporal potential 함수는 <span class="math inline">\(A^t | A^{t-1}\)</span>의 조건부 분포의 <mark>This form of the temporal potential function represents situations where the conditional distribution of <span class="math inline">\(A^t | A^{t-1}\)</span> factors over the entries <span class="math inline">\(A^t_{ij}\)</span> of <span class="math inline">\(A^t\)</span>.</mark></p>
<p><br>
<br>
<br></p>
<div id="network-statistics-for-temporal-ergm" class="section level4 hasAnchor" number="7.7.1.1">
<h4><span class="header-section-number">7.7.1.1</span> Network Statistics for Temporal ERGM<a href="ergm-for-dynamic-networks.html#network-statistics-for-temporal-ergm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>여기서 4개의 network Statistics 를 제안하자. 여기서 <span class="math inline">\(n\)</span> 은 # of dyad.</p>
<p>$$
<span class="math display">\[\begin{align}
S_D = \Psi_D \left ( A^t , A^{t-1}\right)

&amp;=

\frac{1}{n-1} \sum_{ij = (i&lt;j)} A^t_{ij}

\tag{Density}

\\

\Psi_S \left ( A^t , A^{t-1}\right)

&amp;=

\frac{1}{n-1} \sum_{ij}

\left \{ A^t_{ij} A^{t-1}_{ij} + \left (1-A^t_{ij} \right) \left (1-A^{t-1}_{ij} \right)
\right \}


\tag{Stability}

\\

\Psi_R \left ( A^t , A^{t-1}\right)


&amp;=

n \left ( \frac{\sum_\limits{ij} A_{ij}^t A_{ij}^{t-1}}{\sum_\limits{ij}A_{ij}^{t-1}}\right )

\tag{Reciprocity}

\\

\Psi_T \left ( A^t , A^{t-1}\right)

&amp;=

n \left ( \frac{\sum_\limits{ijk} A_{ik}^t A_{ij}^{t-1}A_{jk}^{t-1}}
{\sum_\limits{ijk}A_{ij}^{t-1}A_{jk}^{t-1}}\right )



\tag{Transitivity}

\end{align}\]</span></p>
<p>$$</p>
<ol style="list-style-type: decimal">
<li><strong>Density</strong> : 전체 네트워크에 들어있는 총 tie의 숫자. 단순 density.</li>
<li><strong>Stability</strong> : <span class="math inline">\(t-1\)</span> 시점에 존재했던 link가 <span class="math inline">\(t\)</span> 시점에도 여전히 존재하는 경향성</li>
<li><strong>Reciprocity</strong> : <span class="math inline">\(t-1\)</span> 시점에 <span class="math inline">\(i\)</span> 에서 <span class="math inline">\(j\)</span> 로 향하는 link가 있었다면 <span class="math inline">\(t\)</span> 시점에 <span class="math inline">\(j→i\)</span> 링크가 생겨날 경향</li>
<li><strong>Transitivity</strong> : <span class="math inline">\(t-1\)</span> 시점에 <span class="math inline">\(i→j\)</span> 와 <span class="math inline">\(j→k\)</span> 인 tie가 존재한다면, <span class="math inline">\(t\)</span> 에 <span class="math inline">\(i→k\)</span> tie의 발생으로 이어지는 경향</li>
</ol>
<p>Claim <strong>TERGM</strong> can avoid the <strong>model degeneracy</strong> problem: NOT CORRECT!!</p>
<p><br>
<br>
<br></p>
</div>
<div id="estimation-1" class="section level4 hasAnchor" number="7.7.1.2">
<h4><span class="header-section-number">7.7.1.2</span> Estimation<a href="ergm-for-dynamic-networks.html#estimation-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Notation <mark>&amp; Algorithm &amp; Convergence</mark></li>
</ul>
<p>observed 네트워크의 sequence <span class="math inline">\(N^1 , N^2 , \cdots, N^T\)</span> 를 사용하자. 무엇을 위해? 실제 패러미터값 <span class="math inline">\(\theta\)</span> 에 가까운 estimator <span class="math inline">\(\hat \theta\)</span> 을 찾기 위해. normalizing constant 는 보통 계산해내는 것이 불가능하여 MLE 방법론의 도입은 불가. 따라서 MCMC stochastic approximation 를 사용해 패러미터 estimate. 이하와 같이 notation 한다. 이때 t 시점의 네트워크인 랜덤변수 <span class="math inline">\(\underline N^t\)</span> 에 대해 기댓값들이 계산되었음을 notice.</p>
<p><span class="math display">\[
\begin{align}
L\Bigl(\theta:N^{1},{ N}^{2},\cdots ,{ N}^{T}\Bigr)
=\log P\Bigl({ N}^{2},{ N}^{3},\cdots,{ N}^{t}\,\Bigg \vert\,{ N}^{1},\theta\Bigr)
\\
M\Bigl(t,\theta\Bigr)
= E_{\theta}\Bigl(\downarrow\phi^{t},\Lambda\not v^{t-1}\Bigr)\mid{{N}}^{t-1}\Bigr)
\\
G\Bigl(t,\theta\Bigr)
&amp;=E_{\theta}\Bigl(\Psi\Bigl(\underline{{{\Lambda}}}^{t},\Lambda\not{N}^{t-1}\Bigr)\Psi\Bigl(\underline{{{\Lambda}}}^{t},\Lambda\not{N}^{t-1}\Bigr)^{T}\mid\Lambda\not=\Lambda\prime\prime
\end{align}
\]</span></p>
<p>이때 이하의 기댓값들은 조건부 분포로부터 Gibbs 샘플링을 돌리는 것으로 근사 가능. Newton 방법론과 유사한 과정을 통해 unconstrained optimization 을 하자. 기댓값을 근사하고, Likelihood를 증가시키는 방향으로 패러미터값을 업데이트. 이 과정을 수렴하기까지 반복.</p>
<p><span class="math display">\[
\Delta{ L}\Bigl(\theta:N^1 , N^2 , \cdots, N^T \Bigr) =
\sum_{t=2}^{T}\Bigl(\Psi\big( N^t, N^{t-1} \Bigr)-M\big(t,\theta\big)\Bigr)
\\
\triangle^{2} L\Big(\theta:N^1 , N^2 , \cdots, N^T\Big)= \sum_{t=2}^{T}\Big(\mathrm{M}\big(t,\theta\big)\mathrm{M}\big(t,\theta\big)^{\prime}-{{C}}\big(t,\theta\big)\Big)
\]</span></p>
<p><br>
<br>
<br></p>
<ul>
<li>algorithm</li>
</ul>
<p>randomly initialize <span class="math inline">\(\pmb \theta^{(1)}\)</span>.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
\hat{N}_{(i)}^{t,1},\cdots, \hat{N}_{(i)}^{t,B}
&amp; \sim\,{P}\left(\underline N^t\,\mid\,{N^{t-1}}_{\cdot}\,\pmb{\theta}^{(i)}\right)

\\

\hat{\mu}_{(i)}^{t}
&amp; = {\frac{1}{B}}\sum_{b=1}^{B}\Psi\Big(\hat{ N}_{(i)}^{t,b},N^{t-1}\Big)

\\

\hat{C}_{(i)}^{t}
&amp; = \frac{1}{B}\sum_{b=1}^{B}\Psi\left(\hat{N}_{(i)}^{t,b},N^{t-1}\right)\Psi\left(\hat{N}_{(i)}^{t,b},N^{t-1}\right)&#39;

\\

\hat{H}_{(i)}
&amp; {=}\sum_{i=2}^{T}\left(\mu_{(i)}^{t}\hat{\mu}_{(i)}^{t}-\hat{C}_{(i)}^{t}\right) \tag{after iteration}

\\

\end{alignat}\]</span>
$$</p>
<p><span class="math display">\[
\pmb \theta^{(i+1)}
= \pmb \theta^{(i)}-\hat{{H}}_{(i)}^{-1}\sum_{t=2}^T\Bigg\{\Psi\Big(\hat{N}_{(i)}^{t,b},N^{t-1}\Big)-\hat{\mu}_{(i)}^{t}\Bigg\}
\]</span></p>
</div>
<div id="degeneracy-of-temporal-ergms" class="section level4 hasAnchor" number="7.7.1.3">
<h4><span class="header-section-number">7.7.1.3</span> Degeneracy of Temporal ERGMs<a href="ergm-for-dynamic-networks.html#degeneracy-of-temporal-ergms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>간단한 케이스에는, <mark>where the transition distribution factors over the edges</mark>, 이 모델들은 그러한 문제들에서 완전히 자유롭다는 것이 알려져 있음.</p>
<p>이는 직관적으로도 와닿음. <span class="math inline">\(A^t_{ij} | A^{t−1}\)</span> 의 개개의 조건부 분포가 과하게 극단적이지 않은 한, <span class="math inline">\(A^{t-1}\)</span>이 주어졌을 때 <span class="math inline">\(A^t\)</span>의 edge는 조건부 독립이기 때문이지. 따라서 <span class="math inline">\(A^t | A^{t−1}\)</span> 의 조건부 엔트로피는 커야 하며, 이에 의해 <span class="math inline">\(A^t\)</span>의 조건부 엔트로피도 커야 할테니까.</p>
<p>물론 이 명제는 <span class="math inline">\(A^{t−1}\)</span> 에 대한 <span class="math inline">\(A^t\)</span> 의 의존이 그렇게 강하지 않을 때만 성립하는 것임. 이때 이 의존의 위력은 패러미터들의 위력에 의해 결정되지. 그러니까 패러미터가 이상하게 잡히면 해당 명제의 전제가 깨진다는 거.</p>
<p>동일한 확률값을 가진다는 것을 analytic 하게 보일 수 있는 그래프들의 class들, 즉 equivalence 클래스들에 대해서 이를 계산해보고, 엔트로피 계산에서 각각의 클래스의 크기에 따라서 weight를 부여하자.</p>
<p>첫 플랏의 경우를 생각해보자. <span class="math inline">\(A^2 | A^1\)</span> 의 조건부 분포는 결국 <span class="math inline">\(A^2\)</span> 에 존재하는 edge의 갯수와, 얼마나 많은 <span class="math inline">\(ij\)</span> 값들에게서 <span class="math inline">\(A^2_{ij} = A^1_{ij}\)</span>가 성립하고 있느냐, 의 2개의 값에 대한 함수일 뿐이다. 이에 더해 <span class="math inline">\(A^1\)</span>의 edge들은 exchangeable 하다는 점도 있다. 이들을 모두 생각해보면 결국 우리는 <span class="math inline">\(A^2\)</span>의 marginal 분포를 순수하게 edge의 숫자를 통해서만 서술하는 것이 가능하다.</p>
<p>따라서 우리는 <span class="math inline">\(n(n − 1)\)</span>의 확률값만 계산해내면 되며, 따라서 엔트로피는 weighted sum이다. 이때 weight는 각각의 edge 숫자에 대해, that many edges 를 가지고 있는 그래프의 숫자가 반영된 combinatorial quantities 가 된다.</p>
<p><pics></p>
<p><br>
<br>
<br></p>
</div>
<div id="assessing-statistic-importance-and-quality-of-fit" class="section level4 hasAnchor" number="7.7.1.4">
<h4><span class="header-section-number">7.7.1.4</span> Assessing Statistic Importance and Quality of Fit<a href="ergm-for-dynamic-networks.html#assessing-statistic-importance-and-quality-of-fit" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Description of Network Statistics - 108th U.S. Senate Network Example</p>
<p>Three Parameter Model, Seven, Nine</p>
<p><span class="math inline">\(\Psi_{R T}\left(\mathcal{A}_{\ \cdot}\mathcal{A}_{\ \ \ \ \ \ \ \ \ \mu}^{t-1}\right)\equiv\mathcal{H}\!\left(\sum_{i j k}\mathcal{A}_{i j}^{t}\mathcal{A}_{j k}^{t-1}\mathcal{A}_{k i}^{t-1}\right)\big/\left(\sum_{i j k}\mathcal{A}_{j k}^{t-1}\mathcal{A}_{k i}^{t-1}\right).\)</span></p>
<p><span class="math inline">\(\Psi_{C S o}\Bigl(\lambda_{~,}^{t},\lambda_{~}^{t-1}\Bigr)\mathop{\displaystyle=\,1\atop i j k}\mathcal{A}_{i j}^{t}\bar{A}_{k j}^{t-1}\mathcal{A}_{k j}^{t-1}\Bigr)\Bigl(\sum_{i j k}\mathcal{A}_{k i}^{t-1}\mathcal{A}_{k j}^{t-1}\Bigr)\dots\)</span></p>
<p><span class="math inline">\(\Psi_{C S d}\Bigl(\lambda_{\phantom{0},K}^{t},\lambda_{\phantom{-1}}^{t-1}\Bigr)\not=\imath\Bigl(\sum_{i j k}\lambda_{i j}^{t}\lambda_{i k}^{t-1}\lambda_{j k}^{t-1}\Bigr)\Bigl/\Bigl(\sum_{\textstyle{\frac{i j k}{j k}}}\lambda_{i k}^{t-1}\lambda_{j k}^{t-1}\Bigr).\)</span></p>
<p><span class="math inline">\(\Psi_{P}\Bigl(\mathcal{A}_{\phantom{0},}^{t},\mathcal{A}^{t-1}\Bigr)\equiv\mathcal{H}\Bigl(\sum_{j k}\mathcal{A}_{k j}^{t}\mathcal{A}_{j j}^{t-1}\Bigr)\big/\left(\bigotimes_{i j}\mathcal{A}_{k j}^{t-1}\right).\)</span></p>
<p><span class="math inline">\(\Psi_{G}\Bigl(\partial_{~,}^{t},\partial_{}^{t-1}\Bigr)\Longrightarrow\left(\sum_{i j k}\mathcal{A}_{i k}^{t}\mathcal{A}_{i j}^{t-1}\right)\Bigl/\left(\sum_{i j}\mathcal{A}_{i k}^{t-1}\right).\)</span></p>
<p>Reverse-Transitivity:
Co-Supported:
Co-Supporting:
Popularity
Generosity</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="separable-temporal-ergm-stergm-st-ergm" class="section level3 hasAnchor" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> Separable Temporal ERGM (STERGM, ST ERGM)<a href="ergm-for-dynamic-networks.html#separable-temporal-ergm-stergm-st-ergm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>STERGM = A Separable Model for Dynamic Network</li>
<li>Dynamic: social networks that evolve over time</li>
<li>Time(discrete): <span class="math inline">\(\cdots (t-2) → (t-1) → (t) → \cdots\)</span></li>
</ul>
<p>Shows longitudinal properties based on the ERGM</p>
<ul>
<li>Separable Temporal ERGM
<ul>
<li>formation of an edge: new ties</li>
<li>duration of an edge: lasting ties</li>
</ul></li>
<li>즉, model formation / duration seperatively.</li>
</ul>
<div id="temporal-ergm-interpretation" class="section level4 hasAnchor" number="7.7.2.1">
<h4><span class="header-section-number">7.7.2.1</span> Temporal ERGM Interpretation<a href="ergm-for-dynamic-networks.html#temporal-ergm-interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>하지만 이때 패러미터 해석할 때 주의해야할 부분이 있음.</p>
<ol style="list-style-type: decimal">
<li>Property1: incidence of ties / tie formation (the rate at which new ties are formed)</li>
</ol>
<p><span class="math display">\[
Y^+ = Y^{t-1} \cup Y^{t}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Property2: duration of ties / tie dissolution (how long they tend to last once they do)</li>
</ol>
<p><span class="math display">\[
Y^- = Y^{t-1} \cap Y^{t} \Rightarrow Y^t = Y^- \cup \Big( Y^+ \setminust Y^{t-1}\Big)
\]</span></p>
<p>given <span class="math inline">\(Y^{t-1}\)</span>, we assume <span class="math inline">\(Y^+\)</span> and <span class="math inline">\(Y^-\)</span> are conditionally independent.</p>
<p><span class="math display">\[
\begin{align}
P(Y^+ = y^+ |  Y^{t-1} = y^{t-1} ; \theta^+)
= \frac{1}{\kappa(\theta^+} \exp \Big( \sum_{i=1}^P \theta_i^+ S_i^+(Y^+ , y^{t-1})\Big)
\\
P(Y^- = y^- |  Y^{t-1} = y^{t-1} ; \theta^-)
= \frac{1}{\kappa(\theta^-} \exp \Big( \sum_{i=1}^P \theta_i^- S_i^-(Y^- , y^{t-1})\Big)
\end{align}
\]</span></p>
<ul>
<li><span class="math inline">\(S_i^\pm (Y^\pm , y^{t-1})\)</span> 는 <span class="math inline">\(S_i(y^\pm)\)</span>, <span class="math inline">\(S_i(y^{t-1})\)</span> 사이의 difference.</li>
<li><span class="math inline">\(S_i(\cdot)\)</span> 는 ERGM 상에서의 아무 network statistics</li>
</ul>
<p><span class="math display">\[
P(Y^t = y^t |  Y^{t-1} = y^{t-1})
=
P(Y^+ = y^+ |  Y^{t-1} = y^{t-1} ; \theta^+)
\cdot
P(Y^- = y^- |  Y^{t-1} = y^{t-1} ; \theta^-)
\]</span></p>
<ul>
<li>Network statstic</li>
</ul>
<p>(ex) edge count <span class="math inline">\(g(y^t , y^{t-1}) = | y^t |\)</span></p>
<p>coefficient on <span class="math inline">\(g\)</span> <span class="math inline">\(\propto\)</span> possibility of a network with many ties. 따라서 <span class="math inline">\(g\)</span>의 계수가 올라가면 tie가 많은 네트워크의 발생 확률 올라감.</p>
<p>But, this term simultaneously increases the weight of preservation of extant ties (fewer dissolved) ⇒ Both incidence and duration ↑</p>
<p>The two-sided nature of these effects tends to muddle parameter interpretation. ⇒ STERGM which separates the incidence and duration of ties and allows for the separate interpretation.</p>
<ul>
<li>: incidence/tie formation <span class="math inline">\(y^+ = y^{t-1} \cup y^t\)</span>
– : duration/tie dissolution <span class="math inline">\(y^- = y^{t-1} \cap y^t \Rightarrow y^t = y^- \cup (y^+ \setminus y^{t-1})\)</span></li>
</ul>
<p><span class="math inline">\(P r(y^{+}=y^{+}\vert Y^{t-1}=y^{\iota-1};\theta^{+})=\frac{\theta x p(\eta^{+}(\theta^{+})*\mathcal{O}^{+}(y^{+},y^{I-1}))}{G_{\eta^{+},g^{+}}(\theta^{+},y^{\iota-1})}\)</span></p>
<p><span class="math inline">\(P r(Y^{-}=y^{-}|Y^{t-1}=y^{t-1};\theta^{-})=\frac{\theta x p(\eta^{-}(\theta^{-})*g^{-}(y^{-},y^{t-1}))}{c_{\eta^{-},g^{-}}(\theta^{-},y^{t-1})}\)</span></p>
<p><span class="math inline">\({\cal P}_{I}(\mathcal{V}^{t}\underline{{{-}}}\mathcal{V}^{t-1}\underline{{{-}}}\mathcal{D}^{t-1}\underline{{{-}}}\mathcal{J}) \times \text{incidence} \times \text{duration}\)</span></p>
<p><span class="math inline">\(P r(y^{+}=y^{+}\vert Y^{t-1}=y^{\iota-1};\theta^{+})\)</span></p>
<p><span class="math inline">\(P r(y^{-}=y^{-}\vert Y^{t-1}=y^{\iota-1};\theta^{-})\)</span></p>
<p><br>
<br>
<br></p>
<p>:::{.definition name = “1”}
Definition 1 We say that a dynamic model is separable if Y+ is conditionally independent of Y− given Y
t−1 and the parameter space of θ is the product of the individual parameter spaces of θ+ and θ−.</p>
<p>:::</p>
<ul>
<li>Assumption: During a given discrete time step, the process by which the ties form does not interact with the process by which they dissolve.</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Lost: In the parameterization in terms of formation and dissolution, some flexibility(formation and dissolution processes interact within a given time step) is lost</p></li>
<li><p>Gain: Ease of specification, tractability of the model and substantial improvement in interpretability of TERGM</p></li>
</ol>
<p>Now the parameter and its interpretation have an implicit direction.
(formation or duration)
- Formation network
(+) is related to formation network only</p>
<p><span class="math inline">\(\Pr(\mathbf{V}^{-}={\boldsymbol{y}}^{-}|\mathbf{V}^{t-1}={\boldsymbol{y}}^{t-1};{\boldsymbol{\theta}}^{-})={\frac{\exp\{(\theta^{+})^{\cdot7}g^{+}(y^{+},y^{\dot{t}-1})}{c_{g^{+}}(\theta^{+},y^{t-1})}}\)</span></p>
<ul>
<li>Duration network (or Dissolution network)</li>
</ul>
<p><span class="math inline">\(\Pr(\mathbf{V}^{-}={\boldsymbol{y}}^{-}|\mathbf{V}^{t-1}={\boldsymbol{y}}^{t-1};{\boldsymbol{\theta}}^{-})={\frac{\exp\{({\boldsymbol{\theta}}^{-}),{\boldsymbol{\gamma}}^{t-1}\}}{c_{o}({\boldsymbol{\theta}}^{-},{\boldsymbol{\gamma}}^{t-1})}}\)</span></p>
<p>(-) is related to duration network only</p>
<ul>
<li>Example of Parameter Interpretation (Edge Count)</li>
</ul>
<p>Now the parameter and its interpretation have an implicit direction.
(formation or duration)
Formation network
Edge count g
+
(y
+
, y
t−1
) = |y
+
|, y
+ = y
t−1 ∪ y
t
Recall, y
+
is network about formation
θ
+ means log-odds of gaining new tie from y
t−1 =⇒ y
t
Dissolution network
Edge count g
−(y
−, y
t−1
) = |y
−| , y
− = y
t−1 ∩ y
t
Recall, y
− is network about duration
θ
− means log-odds of existing tie to survive at y
t−1 =⇒ y</p>
<ul>
<li>Likelihood-based Inference for STERGM</li>
</ul>
<p>Fit STERGM by finding conditional MLE under an order 1 Markov assumption:</p>
<p>$$
<span class="math display">\[\begin{align}

\hat{\theta}

&amp;= \arg\mathrm{max}_{\theta}&amp;&amp;\prod_{t=1}^{T}\mathrm{Pr} \Big ({Y}^{t}=y^{t} \Big | {Y}^{t-1}=y^{t-1} \Big)

\\



&amp;= &amp;&amp;\prod_{t=1}^{T}\frac{\exp \Big \{ (\theta^{+})^{\cdot T}g^{+}(y^{+},y^{t-1}) \Big\} } {c_{g^{+}}(\theta^{+},y^{t-1})}
\cdot
\frac{\exp\Big\{(\theta^{-})\cdot g^{-}(y^{-},y^{t-1})\Big\}}{c_{g^{-}}(\theta^{-},y^{t-1})}.

\end{align}\]</span>
$$</p>
<ul>
<li>where <span class="math inline">\(c_{g}(\theta,y^{t-1})=\sum_{y^{\prime}\in\psi}\exp \Big \{(\theta)^{\cdot T}g(y,y^{t-1}) \Big\}\)</span></li>
</ul>
<p>In practical, MLE can be obtained by maximizing the log-likelihood using numerical optimization.</p>
<p>The normalizing constant <span class="math inline">\(c_{g^+}(\theta^+,y^{t-1})\)</span> 와 <span class="math inline">\(c_{g^-}(\theta^-,y^{t-1})\)</span> 는 계산 불가. 각각은 시뮬레이션을 통해 (e.g. MCMCMLE) 를 통해 획득됨</p>
<p>i.e. maximizing <span class="math inline">\(I(\theta)-I(\theta^{0})=\{\theta-\theta^{0}\}\sum_{t=1}^{T}g(y^{t},y^{t-1})-\log\Big\{\prod_{t=1}^{T}\frac{c_{g}(\theta,y^{t-1})}{c_{g}(\theta^{0},y^{t-1})}\Big\}\)</span></p>
</div>
<div id="application-study" class="section level4 hasAnchor" number="7.7.2.2">
<h4><span class="header-section-number">7.7.2.2</span> Application Study<a href="ergm-for-dynamic-networks.html#application-study" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br>
<br>
<br></p>
</div>
<div id="conclusion-1" class="section level4 hasAnchor" number="7.7.2.3">
<h4><span class="header-section-number">7.7.2.3</span> Conclusion<a href="ergm-for-dynamic-networks.html#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Introduce statistical model for networks that evolve over time.</li>
<li>Separable parameterization of incidence and duration.</li>
<li>Greatly improve interpretability of model parameters, with sacrificing a little.</li>
<li>Identify the structure of incident and durational structure</li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="parameter-estimation-of-ergm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="latent-network-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyric2249/lyric2249.github.io/edit/main/212107_ERGMforDynamicNetworks.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
