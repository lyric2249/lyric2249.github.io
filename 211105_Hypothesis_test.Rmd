## Hypothesis Test

| 통계적 가설 | Statistical Hypothesis | 관심있는 population의 성질에 대한 단정이나 추측 등의 표현 (statement) <br> 이러한 가설은 흔히 모집단의 성질을 나타내는 rv의 분포에 대한 표현으로 나타난다. |
| 단순가설 | Simple Hypothesis | 어떤 가설이 확률분포 (pd) 를 완전히 결정한다 |
| 복합가설 | Composite Hypothesis | 그렇지 않다 | 

다양한 검정법에서 우선순위를 정하는 것은 옳은 결론을 내리는 빈도가 높은, 즉 **잘못된 결정을 내릴 확률이 낮은 검정법이 좋은 검정법**이라는 것.

검정통계량(Test Statistics): 주어진 rs에 근거하여 통계적 가설에 대한 증거를 살펴볼 때 사용되는 통계량

기각영역(Rejection Region, Critical Region): $H_0$를 기각하게 되는 검정통계량의 값을 가지는 **sample space의 부분집합** (event)

| | $H_0$ True | $H_0$ False |
| reject $H_0$ | | Type 2 Error ($\beta$) <br> 유죄인데 석방 |
| accept $H_0$ | Type 1 Error ($\alpha$) <br> **무죄인데 사형** | |

제1종 오류를 범활 확률 $\alpha$는 유의확률(Significance Level) 라고 따로 칭함. $H_1$은 기존으로부터의 변화이므로 채택에 있어 훨씬 엄격해야 함. 따라서 $\alpha$가 $\beta$보다 훨씬 더 중시됨. 

let Rejection Region $C$. then

$$
\begin{alignat*}{2}

\alpha &= P(\text{Type 1 Error}) \\
&= P(\text{accept }H_1 \vert H_0) \\
&= P(\pmb X_n \in C \vert H_0) 

\begin{aligned}[t]
           & = \int_C f(\pmb x \vert H_0) d \pmb x\\
           &= \sum_C f(\pmb x \vert H_0)
         \end{aligned}


\end{alignat*}
$$

This can also be written as Loss Function.

$$
\begin{align*}

L(H_i ; H_j ) = 

 \begin{cases}
    0, & \text{if } i = j  \\
    1, & \text{for } i \not = j, \; \; (i,j = 0, 1)
    
  \end{cases}

\end{align*}
$$

$$
\begin{align*}

E \left [ L(H_1 ; H_0 ) \right] &= P(\text{Type 1 Error}) \\
E \left [ L(H_0 ; H_1 ) \right] &= P(\text{Type 2 Error})

\end{align*}
$$

<img src="https://i.stack.imgur.com/3NO3M.png" width="480" alt="hi" class="inline"/>

<br>
<br>
<br>


## Power Fucntion

여기서, $H_0$에 대한 기각영역이 $C$인 test의 검정력함수 (power function)은 이하와 같다. 즉, 이는 **$H_0$를 기각하는 확률**로 정의된다.

$$
\pi(\theta) = P (\pmb X_n \in C \vert \theta)
$$

이는 패러미터 $\theta$의 참값이 무엇이냐에 따라 다른 값을 가지므로 $\theta$의 함수이다.

주어진 $\theta$에서의 power function의 값 $\pi(\theta)$은 이 $\theta$에서의 검정력 (power).

power는 $H_0$를 기각할 확률.
* if $\theta \in H_0$, power는 작을수록 좋다. 
	* $\theta = \theta_0 \in H_1$, 이 경우 power $\pi(\theta) = \pi(\theta_0) = \alpha$.
* if $\theta \in H_1$, power는 클수록 좋다. 
	* $\theta \in H_1$, and $H_1$이 simple hypothesis, 이 경우 power $\pi(\theta) = 1- \beta$.

이와 같이 power function은, 마치 MSE가 점추정의 기준이 되었던 것처럼, $\alpha$ (유의수준)이 고정되었을 때 test 방법의 성능을 결정하는 기준이 된다.

<br>
<br>
<br>

### Significance Probability (p-value)

앞에서 언급했던 것과 같이, 좋은 검정법을 찾기 위해 sample space를 $C$와 채택영역 $C^c$로 나누고 $\alpha$와 $\beta$를 계산하여 오류의 확률을 작게 만드는 검정법을 고르게 된다. 사용할 검정법을 결정하고 나면, 자료에서 관측된 값이 $C$에 속할 경우 $H_0$를 기각하고, 이외에는 $H_0$를 기각하지 않는다고 결론을 내리게 된다. 그런데 관찰된 test stat의 값이 $C$에 속한다 하더라도 값의 크기 등에 따라 **통계적 유의성**에 대한 의미가 다를 수 있다. 따라서 기각할 것인지, 하지 않을 것인지 이분법적인 결론만을 제시하기보다, 관측한 자료가 $H_0$에 대하여 어느 정도의 반증이 되는지를 수치적으로 나타낼 수 있는 $\alpha$ (유의확률)을 이용하여 test의 결론에 이르는 경우가 많이 있다.

p값 (p-value), 즉 관측된 유의수준 (observed significance level), 혹은 유의확률 (Significance Probability), 는 $H_0$가 참이라는 가정 하에, 우리가 관측한 값과 같거나 더 극단적인 값을 얻을 확률 (ex. $P(T \ge t \vert H_0 )$) 로 정의된다. 여기서 더 극단적이라는 것은, 관측한 값보다 $H_1$에 더 가까운 것을 의미한다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 아주 작은 값이 나왔다면, 우리가 관측한 값 자체가 이미 매우 극단적이라서 이보다 더 강한 $H_1$에 대한 증거를 관측할 확률이 작다는 것이다. 즉, **관측값이 $H_0$ 하에서 나오기 어려운 값**이라는 뜻이므로 $H_0$를 기각할 근거가 된다고 할 수 있다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 작지 않은 값이 나왔다면, 우리가 관측한 값이 $H_0$ 하에서 흔히 나올 수 있는 값이라는 것이고, 즉 $H_0$를 기각할 근거가 되지 않는다고 할 수 있다.

p값이 $H_0$를 기각할만큼 작은지를 결정하는 것은 보통 결과를 해석하는 사람에게 달려있다. 그러나 가설검정을 할 때는 흔히 적당한 유의수준 $\alpha$의 값을 생각하고 있기 마련이므로, p값이 $\alpha$보다 작으면 관측된 자료가 대립 가설에 대한 충분한 증거가 된다고 판단하여 $H_0$를 기각하게 된다. 정리하자면, p값은 $H_0$ 하에서 test stat의 관찰값 (test stats) 이 $H_0$를 기각하는 방향으로 나타나는 확률을 의미한다. 주어진 유의수준 $\alpha$보다 p값이 작으면 $H_0$를 기각하며, 그렇지 않은 경우에는 $H_0$를 받아들이게 된다.

<br>
<br>
<br>

## Optimal Testing Method

항상 옳은 결과를 가져다주는 검정법을 사용할 수 있다면 가장 좋겠지만, 샘플에서 주어지는 정보만을 가지고 모집단의 특성에 대한 결론을 내려야 하는 상황에서 언제나 옳은 결과를 가져다주는 test 방법을 찾을 수는 없다. 그렇기에 이 장의 목표는 옳은 결과를 가져다주는 빈도가 높은 test 방법을 찾는 것이 된다. 잘못된 결론을 내릴 확률은 두 가지 오류로 표현되므로, 제 1종 오류와 제 2종 오류의 발생확률을 낮게 하는 test 방법을 찾아야 한다. 불행히도, 샘플의 크게가 정해져 있는 경우 둘 다를 최소로 하는 test 방법을 찾는 거은 불가능하다. 예를 들면, $\alpha$를 최소로 하는 가장 간단한 방법은 언제나 $H_0$를 채택하는 것이지만 ($\alpha = 0$), 이는 $H_1$에서의 power를 0으로 최소화시키고, 즉, $\beta$를 극대화시킨다.

-----

let $\pmb X_{25} \overset {\text{iid}} {\sim} N(\mu, 10^2 )$. 

$$
H_0 : \mu = 100, \; \; \; \; \; H_1 : \mu > 100
$$

<img src="KakaoTalk_20210522_171926819.jpg" width="320" alt="hi" class="inline"/>

이때. $\mu=100$에서의 power는 유의수준 $\alpha$와 같고, $\mu>100$일 경우에는 $\pi(\mu) = 1-\beta(\mu)$. 이인즉 

$$
\begin{align*}

\lim_{\mu \downarrow 100} \beta(\mu) &= 1- \pi(100) \\
&= 1- \alpha

\end{align*}
$$

따라서 $H_0$와 $H_1$의 경계점에서 $\alpha + \beta = 1$이 된다. 즉, 샘플의 크기가 일정할 때 $\alpha$를 줄이고자 하면 경계점에서 $\beta$의 값이 커지며, 이 역 또한 성립한다. 이를 power로 표현하면, $H_0$ 하에서 power는 큰 것이 바람직하나 power $\pi (\mu)$를 늘이고자 하면 $\alpha$의 값이 같이 커지게 되므로 제1종 오류의 확률 ($\alpha$)의 확률을 최소화하면서 power를 최대화하는 일은 sample의 크기가 정해져 있는 경우 불가능하다.

만약 sample의 크기를 늘인다면, $\alpha$의 값을 고정시킨 상태에서 주어진 $H_1$ 하에서의 $\mu$ 값에서의 power를 크게 할 수 있다.

-----

이 절에서는 power function $\pi(\cdot)$을 기준으로 하는 Optimal Testing Method (최량검정법)에 대해 살펴볼 것이다. 우선, $H_0$와 $H_1$이 모두 simple인 경우를 생각해보자. 위에서 이야기하였듯 $\alpha$를 최소화하면서 $H_0$ 하에서의 power를 최대화하는 것은 불가능하므로, 이에 대한 합리적 대안으로 $\alpha$ (제1종 오류를 범할 확률)을 주어진 작은 값으로 제한한 상태에서, power를 최대화하는 의미에서의 OTM을 다음과 같이 정의한다.

-----

$$

H_0: \theta = \theta_0, \; \; \; \; \; H_1: \theta = \theta_1

$$

에 대한 rejection region $C^\ast$ 가 다음 조건을 만족할 때 이를 유의수준 $\alpha$ 에서의 MPT의 RR, 또는 MPRR이라고 한다.

$\pi^\ast$가 $C^\ast$에 해당하는 power function이라 하면,
1. $\pi^\ast (\theta_0) = \alpha$,
2. $\forall \text{ RR } C, \; \text{whose 유의수준과 power function } \alpha, \pi: \pi^\ast(\theta_1) \ge \pi(\theta_1)$.


-----






















