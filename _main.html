<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Self-Study</title>
  <meta name="description" content="Self-Study" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Self-Study" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="<a href="https://github.com/lyric2249/lyric2249.github.io" class="uri">https://github.com/lyric2249/lyric2249.github.io</a>" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Self-Study" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Self-Study</h1>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#part-20-02">(PART) 20-02</a></li>
<li><a href="#categorical"><span class="toc-section-number">1</span> Categorical</a>
<ul>
<li><a href="#overview"><span class="toc-section-number">1.1</span> Overview</a>
<ul>
<li><a href="#data-type-and-statistical-analysis"><span class="toc-section-number">1.1.1</span> Data Type and Statistical Analysis</a></li>
</ul></li>
</ul></li>
<li><a href="#bayesian"><span class="toc-section-number">2</span> Bayesian</a>
<ul>
<li><a href="#abstract"><span class="toc-section-number">2.1</span> Abstract</a>
<ul>
<li><a href="#변수의-독립성"><span class="toc-section-number">2.1.1</span> 변수의 독립성</a></li>
<li><a href="#교환가능성"><span class="toc-section-number">2.1.2</span> 교환가능성</a></li>
</ul></li>
<li><a href="#continual-aeassessment-method"><span class="toc-section-number">2.2</span> Continual Aeassessment Method</a></li>
<li><a href="#horseshoe-prior"><span class="toc-section-number">2.3</span> Horseshoe Prior</a></li>
</ul></li>
<li><a href="#part-21-01">(PART) 21-01</a></li>
<li><a href="#mathematical-stats"><span class="toc-section-number">3</span> Mathematical Stats</a>
<ul>
<li><a href="#inference"><span class="toc-section-number">3.1</span> Inference</a>
<ul>
<li><a href="#rao-blackwell-thm."><span class="toc-section-number">3.1.1</span> Rao-Blackwell thm.</a></li>
</ul></li>
<li><a href="#completeness"><span class="toc-section-number">3.2</span> Completeness</a>
<ul>
<li><a href="#레만-쉐페-thm."><span class="toc-section-number">3.2.1</span> 레만-쉐페 thm.</a></li>
<li><a href="#rao-blackwell-thm.-1"><span class="toc-section-number">3.2.2</span> Rao-Blackwell thm.</a></li>
</ul></li>
<li><a href="#hypothesis-test"><span class="toc-section-number">3.3</span> Hypothesis Test</a></li>
<li><a href="#power-fucntion"><span class="toc-section-number">3.4</span> Power Fucntion</a>
<ul>
<li><a href="#significance-probability-p-value"><span class="toc-section-number">3.4.1</span> Significance Probability (p-value)</a></li>
</ul></li>
<li><a href="#optimal-testing-method"><span class="toc-section-number">3.5</span> Optimal Testing Method</a></li>
<li><a href="#data-reduction"><span class="toc-section-number">3.6</span> Data Reduction</a>
<ul>
<li><a href="#sufficiency-principle"><span class="toc-section-number">3.6.1</span> Sufficiency Principle</a></li>
</ul></li>
<li><a href="#borel-paradox"><span class="toc-section-number">3.7</span> Borel Paradox</a></li>
<li><a href="#neymanpearson-lemma"><span class="toc-section-number">3.8</span> Neyman–Pearson lemma</a>
<ul>
<li><a href="#overview-1"><span class="toc-section-number">3.8.1</span> Overview</a></li>
<li><a href="#generalized-lrt"><span class="toc-section-number">3.8.2</span> Generalized LRT</a></li>
</ul></li>
<li><a href="#개념"><span class="toc-section-number">3.9</span> 개념</a></li>
</ul></li>
<li><a href="#mcmc"><span class="toc-section-number">4</span> MCMC</a>
<ul>
<li><a href="#importance-sampling"><span class="toc-section-number">4.1</span> Importance Sampling</a>
<ul>
<li><a href="#independent-monte-carlo"><span class="toc-section-number">4.1.1</span> Independent Monte Carlo</a></li>
</ul></li>
<li><a href="#markov-chain-monte-carlo"><span class="toc-section-number">4.2</span> Markov Chain Monte Carlo</a>
<ul>
<li><a href="#mh-algorithm"><span class="toc-section-number">4.2.1</span> MH Algorithm</a></li>
<li><a href="#random-walk-chains-most-widely-used"><span class="toc-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)</a></li>
<li><a href="#basic-gibbs-sampler"><span class="toc-section-number">4.2.3</span> Basic Gibbs Sampler</a></li>
<li><a href="#implementation"><span class="toc-section-number">4.2.4</span> Implementation</a></li>
</ul></li>
<li><a href="#advanced-mcmc-wk08"><span class="toc-section-number">4.3</span> Advanced MCMC (wk08)</a>
<ul>
<li><a href="#data-augmentation"><span class="toc-section-number">4.3.1</span> 1. Data Augmentation</a></li>
<li><a href="#hit-and-run-algorithm"><span class="toc-section-number">4.3.2</span> 2. Hit-and-Run Algorithm</a></li>
<li><a href="#metropolis-adjusted-langevin-algorithm"><span class="toc-section-number">4.3.3</span> 3. Metropolis-Adjusted Langevin Algorithm</a></li>
<li><a href="#multiple-try-metropolis-algorithm"><span class="toc-section-number">4.3.4</span> 4. Multiple-Try Metropolis Algorithm</a></li>
<li><a href="#reversible-jump-mcmc-algorithm"><span class="toc-section-number">4.3.5</span> 5. Reversible Jump MCMC Algorithm</a></li>
</ul></li>
<li><a href="#auxiliary-variable-mcmc"><span class="toc-section-number">4.4</span> Auxiliary Variable MCMC</a>
<ul>
<li><a href="#introduction"><span class="toc-section-number">4.4.1</span> Introduction</a></li>
<li><a href="#multimodal-target-distribution"><span class="toc-section-number">4.4.2</span> Multimodal Target Distribution</a></li>
<li><a href="#doubly-intractable-normalizing-constants"><span class="toc-section-number">4.4.3</span> Doubly-intractable Normalizing Constants</a></li>
</ul></li>
<li><a href="#approximate-bayesian-computation"><span class="toc-section-number">4.5</span> Approximate Bayesian Computation</a>
<ul>
<li><a href="#simulator-based-models"><span class="toc-section-number">4.5.1</span> Simulator-Based Models</a></li>
<li><a href="#abcifying-monte-carlo-methods"><span class="toc-section-number">4.5.2</span> ABCifying Monte Carlo Methods</a></li>
<li><a href="#abc-mcmc-algorithm"><span class="toc-section-number">4.5.3</span> ABC-MCMC Algorithm</a></li>
</ul></li>
<li><a href="#hamiltonian-monte-carlo"><span class="toc-section-number">4.6</span> Hamiltonian Monte Carlo</a>
<ul>
<li><a href="#introduction-to-hamiltonian-monte-carlo"><span class="toc-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo</a></li>
</ul></li>
<li><a href="#population-monte-carlo"><span class="toc-section-number">4.7</span> Population Monte Carlo</a>
<ul>
<li><a href="#adaptive-direction-sampling"><span class="toc-section-number">4.7.1</span> Adaptive Direction Sampling</a></li>
<li><a href="#conjugate-gradient-mc"><span class="toc-section-number">4.7.2</span> Conjugate Gradient MC</a></li>
<li><a href="#parallel-tempering"><span class="toc-section-number">4.7.3</span> Parallel Tempering</a></li>
<li><a href="#evolutionary-mc"><span class="toc-section-number">4.7.4</span> Evolutionary MC</a></li>
<li><a href="#sequential-parallel-tempering"><span class="toc-section-number">4.7.5</span> Sequential Parallel Tempering</a></li>
</ul></li>
<li><a href="#stochastic-approximation-monte-carlo"><span class="toc-section-number">4.8</span> Stochastic Approximation Monte Carlo</a></li>
<li><a href="#review"><span class="toc-section-number">4.9</span> Review</a>
<ul>
<li><a href="#wk01"><span class="toc-section-number">4.9.1</span> Wk01</a></li>
<li><a href="#wk03"><span class="toc-section-number">4.9.2</span> wk03</a></li>
<li><a href="#wk04-05"><span class="toc-section-number">4.9.3</span> wk04, 05</a></li>
</ul></li>
<li><a href="#else"><span class="toc-section-number">4.10</span> Else</a>
<ul>
<li><a href="#hw4.-rasch-model"><span class="toc-section-number">4.10.1</span> Hw4. Rasch Model</a></li>
<li><a href="#da-example-mvn"><span class="toc-section-number">4.10.2</span> DA) Example: MVN</a></li>
<li><a href="#bayesian-adaptive-clinical-trial-with-delayed-outcomes"><span class="toc-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes</a></li>
<li><a href="#nmar의-종류"><span class="toc-section-number">4.10.4</span> NMAR의 종류</a></li>
<li><a href="#wk10-bayesian-model-selection"><span class="toc-section-number">4.10.5</span> wk10) Bayesian Model Selection</a></li>
<li><a href="#autologistic-model"><span class="toc-section-number">4.10.6</span> Autologistic model</a></li>
<li><a href="#wk10-bayesian-model-averaging"><span class="toc-section-number">4.10.7</span> wk10) Bayesian Model Averaging</a></li>
</ul></li>
</ul></li>
<li><a href="#mva"><span class="toc-section-number">5</span> MVA</a>
<ul>
<li><a href="#overview-of-mva-not-ended"><span class="toc-section-number">5.1</span> Overview of mva (not ended)</a>
<ul>
<li><a href="#notation"><span class="toc-section-number">5.1.1</span> Notation</a></li>
<li><a href="#summary-statistics"><span class="toc-section-number">5.1.2</span> Summary Statistics</a></li>
<li><a href="#statistical-inference-on-correlation"><span class="toc-section-number">5.1.3</span> Statistical Inference on Correlation</a></li>
<li><a href="#standardization"><span class="toc-section-number">5.1.4</span> Standardization</a></li>
<li><a href="#missing-value-treatment"><span class="toc-section-number">5.1.5</span> Missing Value Treatment</a></li>
</ul></li>
<li><a href="#multivariate-nomral-wk2"><span class="toc-section-number">5.2</span> Multivariate Nomral (wk2)</a>
<ul>
<li><a href="#overview-2"><span class="toc-section-number">5.2.1</span> Overview</a></li>
<li><a href="#spectral-decomposition"><span class="toc-section-number">5.2.2</span> Spectral Decomposition</a></li>
<li><a href="#properties-of-mvn"><span class="toc-section-number">5.2.3</span> Properties of MVN</a></li>
<li><a href="#chi2-distribution"><span class="toc-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution</a></li>
<li><a href="#linear-combination-of-random-vectors"><span class="toc-section-number">5.2.5</span> Linear Combination of Random Vectors</a></li>
<li><a href="#multivariate-normal-likelihood"><span class="toc-section-number">5.2.6</span> Multivariate Normal Likelihood</a></li>
<li><a href="#sampling-distribtion-of-bar-pmb-y-s"><span class="toc-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></a></li>
<li><a href="#assessing-normality"><span class="toc-section-number">5.2.8</span> Assessing Normality</a></li>
<li><a href="#power-transformation"><span class="toc-section-number">5.2.9</span> Power Transformation</a></li>
</ul></li>
<li><a href="#inference-about-mean-vector-wk3"><span class="toc-section-number">5.3</span> Inference about Mean Vector (wk3)</a>
<ul>
<li><a href="#overview-3"><span class="toc-section-number">5.3.1</span> Overview</a></li>
<li><a href="#confidence-region"><span class="toc-section-number">5.3.2</span> 1. Confidence Region</a></li>
<li><a href="#simultaneous-ci"><span class="toc-section-number">5.3.3</span> 2. Simultaneous CI</a></li>
<li><a href="#note-bonferroni-multiple-comparison"><span class="toc-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison</a></li>
<li><a href="#large-sample-inferences-about-a-mean-vector"><span class="toc-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector</a></li>
<li><a href="#profile-analysis-wk4-5"><span class="toc-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)</a></li>
<li><a href="#test-for-linear-trend"><span class="toc-section-number">5.3.7</span> 2. Test for Linear Trend</a></li>
<li><a href="#inferences-about-a-covariance-matrix"><span class="toc-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix</a></li>
</ul></li>
<li><a href="#comparison-of-several-mv-means-wk5"><span class="toc-section-number">5.4</span> Comparison of Several MV Means (wk5)</a>
<ul>
<li><a href="#paired-comparison"><span class="toc-section-number">5.4.1</span> Paired Comparison</a></li>
<li><a href="#comparing-mean-vectors-from-two-populations"><span class="toc-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations</a></li>
<li><a href="#profile-analysis-for-g2"><span class="toc-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</a></li>
<li><a href="#comparing-several-multivariate-population-means"><span class="toc-section-number">5.4.4</span> Comparing Several Multivariate Population Means</a></li>
</ul></li>
<li><a href="#multivariate-multiple-regression-wk6"><span class="toc-section-number">5.5</span> Multivariate Multiple Regression (wk6)</a>
<ul>
<li><a href="#overview-4"><span class="toc-section-number">5.5.1</span> Overview</a></li>
<li><a href="#multivariate-multiple-regression"><span class="toc-section-number">5.5.2</span> Multivariate Multiple Regression</a></li>
<li><a href="#hypothesis-testing"><span class="toc-section-number">5.5.3</span> Hypothesis Testing</a></li>
<li><a href="#example"><span class="toc-section-number">5.5.4</span> Example)</a></li>
</ul></li>
<li><a href="#pca"><span class="toc-section-number">5.6</span> PCA</a></li>
<li><a href="#factor"><span class="toc-section-number">5.7</span> Factor</a>
<ul>
<li><a href="#method-of-estimation"><span class="toc-section-number">5.7.1</span> Method of Estimation</a></li>
<li><a href="#factor-rotation"><span class="toc-section-number">5.7.2</span> Factor Rotation</a></li>
<li><a href="#varimax-criterion"><span class="toc-section-number">5.7.3</span> Varimax Criterion</a></li>
<li><a href="#factor-scores"><span class="toc-section-number">5.7.4</span> Factor Scores</a></li>
</ul></li>
<li><a href="#discrimination-and-classification"><span class="toc-section-number">5.8</span> Discrimination and Classification</a>
<ul>
<li><a href="#bayes-rule"><span class="toc-section-number">5.8.1</span> Bayes Rule</a></li>
<li><a href="#classification-with-two-mv-n-populations"><span class="toc-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations</a></li>
<li><a href="#evaluating-classification-functions"><span class="toc-section-number">5.8.3</span> Evaluating Classification Functions</a></li>
<li><a href="#classification-with-several-populations-wk13"><span class="toc-section-number">5.8.4</span> Classification with several Populations (wk13)</a></li>
<li><a href="#other-discriminant-analysis-methods"><span class="toc-section-number">5.8.5</span> Other Discriminant Analysis Methods</a></li>
</ul></li>
<li><a href="#clustering-distance-methods-and-ordination"><span class="toc-section-number">5.9</span> Clustering, Distance Methods, and Ordination</a>
<ul>
<li><a href="#overview-5"><span class="toc-section-number">5.9.1</span> Overview</a></li>
<li><a href="#hierarchical-clustering"><span class="toc-section-number">5.9.2</span> Hierarchical Clustering</a></li>
<li><a href="#k-means-clustering"><span class="toc-section-number">5.9.3</span> K-means Clustering</a></li>
<li><a href="#군집의-평가방법"><span class="toc-section-number">5.9.4</span> 군집의 평가방법</a></li>
<li><a href="#clustering-using-density-estimation-wk14"><span class="toc-section-number">5.9.5</span> Clustering using Density Estimation (wk14)</a></li>
<li><a href="#multidimensional-scaling-mds"><span class="toc-section-number">5.9.6</span> Multidimensional Scaling (MDS)</a></li>
</ul></li>
</ul></li>
<li><a href="#linear"><span class="toc-section-number">6</span> Linear</a>
<ul>
<li><a href="#svd"><span class="toc-section-number">6.1</span> SVD</a>
<ul>
<li><a href="#spectral-decomposition-1"><span class="toc-section-number">6.1.1</span> Spectral Decomposition</a></li>
<li><a href="#singular-value-decomposition-general-version"><span class="toc-section-number">6.1.2</span> Singular value Decomposition: General-version</a></li>
<li><a href="#singular-value-decomposition-another-version"><span class="toc-section-number">6.1.3</span> Singular value Decomposition: Another-version</a></li>
<li><a href="#quadratic-forms"><span class="toc-section-number">6.1.4</span> Quadratic Forms</a></li>
<li><a href="#partitioned-matrices"><span class="toc-section-number">6.1.5</span> Partitioned Matrices</a></li>
<li><a href="#geometrical-aspects"><span class="toc-section-number">6.1.6</span> Geometrical Aspects</a></li>
<li><a href="#column-row-and-null-space"><span class="toc-section-number">6.1.7</span> Column, Row and Null Space</a></li>
</ul></li>
<li><a href="#introduction-1"><span class="toc-section-number">6.2</span> Introduction</a>
<ul>
<li><a href="#what"><span class="toc-section-number">6.2.1</span> What</a></li>
<li><a href="#random-vectors-and-matrices"><span class="toc-section-number">6.2.2</span> Random Vectors and Matrices</a></li>
<li><a href="#multivariate-normal-distributions"><span class="toc-section-number">6.2.3</span> Multivariate Normal Distributions</a></li>
<li><a href="#distributions-of-quadratic-forms"><span class="toc-section-number">6.2.4</span> Distributions of Quadratic Forms</a></li>
</ul></li>
<li><a href="#estimation"><span class="toc-section-number">6.3</span> Estimation</a>
<ul>
<li><a href="#identifiability-and-estimability"><span class="toc-section-number">6.3.1</span> Identifiability and Estimability</a></li>
<li><a href="#estimation-least-squares"><span class="toc-section-number">6.3.2</span> Estimation: Least Squares</a></li>
<li><a href="#estimation-best-linear-unbiased"><span class="toc-section-number">6.3.3</span> Estimation: Best Linear Unbiased</a></li>
<li><a href="#estimation-maximum-likelihood"><span class="toc-section-number">6.3.4</span> Estimation: Maximum Likelihood</a></li>
<li><a href="#estimation-minimum-variance-unbiased"><span class="toc-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased</a></li>
<li><a href="#sampling-distributions-of-estimates"><span class="toc-section-number">6.3.6</span> Sampling Distributions of Estimates</a></li>
<li><a href="#generalized-least-squaresgls"><span class="toc-section-number">6.3.7</span> Generalized Least Squares(GLS)</a></li>
</ul></li>
<li><a href="#one-way-anova"><span class="toc-section-number">6.4</span> One-Way ANOVA</a>
<ul>
<li><a href="#one-way-anova-1"><span class="toc-section-number">6.4.1</span> One-Way ANOVA</a></li>
<li><a href="#more-about-models"><span class="toc-section-number">6.4.2</span> More About Models</a></li>
<li><a href="#estimating-and-testing-contrasts"><span class="toc-section-number">6.4.3</span> Estimating and Testing Contrasts</a></li>
<li><a href="#cochrans-theorem"><span class="toc-section-number">6.4.4</span> Cochran’s Theorem</a></li>
</ul></li>
<li><a href="#testing"><span class="toc-section-number">6.5</span> Testing</a>
<ul>
<li><a href="#more-about-models-two-approaches-for-linear-model"><span class="toc-section-number">6.5.1</span> More About Models: Two approaches for linear model</a></li>
<li><a href="#testing-models"><span class="toc-section-number">6.5.2</span> Testing Models</a></li>
<li><a href="#a-generalized-test-procedure"><span class="toc-section-number">6.5.3</span> A Generalized Test Procedure</a></li>
<li><a href="#testing-linear-parametric-functions"><span class="toc-section-number">6.5.4</span> Testing Linear Parametric Functions</a></li>
<li><a href="#theoretical-complements"><span class="toc-section-number">6.5.5</span> Theoretical Complements</a></li>
<li><a href="#a-generalized-test-procedure-1"><span class="toc-section-number">6.5.6</span> A Generalized Test Procedure</a></li>
<li><a href="#testing-single-degrees-of-freedom-in-a-given-subspace"><span class="toc-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace</a></li>
<li><a href="#breaking-ss-into-independent-components"><span class="toc-section-number">6.5.8</span> Breaking SS into Independent Components</a></li>
<li><a href="#general-theory"><span class="toc-section-number">6.5.9</span> General Theory</a></li>
<li><a href="#two-way-anova"><span class="toc-section-number">6.5.10</span> Two-Way ANOVA</a></li>
<li><a href="#confidence-regions"><span class="toc-section-number">6.5.11</span> Confidence Regions</a></li>
<li><a href="#tests-for-generalized-least-squares-models"><span class="toc-section-number">6.5.12</span> Tests for Generalized Least Squares Models</a></li>
</ul></li>
<li><a href="#generalized-least-squares"><span class="toc-section-number">6.6</span> Generalized Least Squares</a>
<ul>
<li><a href="#a-direct-solution-via-inner-products"><span class="toc-section-number">6.6.1</span> A direct solution via inner products</a></li>
</ul></li>
<li><a href="#flat"><span class="toc-section-number">6.7</span> Flat</a>
<ul>
<li><a href="#flat-1"><span class="toc-section-number">6.7.1</span> 1.Flat</a></li>
<li><a href="#solutions-to-systems-of-linear-equations"><span class="toc-section-number">6.7.2</span> 2. Solutions to systems of linear equations</a></li>
</ul></li>
<li><a href="#unified-approach-to-balanced-anova-models"><span class="toc-section-number">6.8</span> Unified Approach to Balanced ANOVA Models</a></li>
</ul></li>
<li><a href="#part-21-02">(PART) 21-02</a></li>
<li><a href="#network-stats"><span class="toc-section-number">7</span> Network Stats</a>
<ul>
<li><a href="#introduction-2"><span class="toc-section-number">7.1</span> Introduction</a>
<ul>
<li><a href="#types-of-network-analysis"><span class="toc-section-number">7.1.1</span> Types of Network Analysis</a></li>
<li><a href="#network-modeling-and-inference"><span class="toc-section-number">7.1.2</span> Network Modeling and Inference</a></li>
<li><a href="#network-processes"><span class="toc-section-number">7.1.3</span> Network Processes</a></li>
</ul></li>
<li><a href="#descriptive-statistics-of-networks"><span class="toc-section-number">7.2</span> Descriptive Statistics of Networks</a>
<ul>
<li><a href="#vertex-and-edge-characteristics"><span class="toc-section-number">7.2.1</span> Vertex and Edge Characteristics</a></li>
<li><a href="#characterizing-network-cohesion"><span class="toc-section-number">7.2.2</span> Characterizing Network Cohesion</a></li>
<li><a href="#graph-partitioning"><span class="toc-section-number">7.2.3</span> Graph Partitioning</a></li>
<li><a href="#assortativity-and-mixing"><span class="toc-section-number">7.2.4</span> Assortativity and Mixing</a></li>
</ul></li>
<li><a href="#data-collection-and-sampling"><span class="toc-section-number">7.3</span> Data Collection and Sampling</a>
<ul>
<li><a href="#sampling-designs"><span class="toc-section-number">7.3.1</span> Sampling Designs</a></li>
<li><a href="#coping-strategies"><span class="toc-section-number">7.3.2</span> Coping Strategies</a></li>
<li><a href="#big-data-solves-nothing"><span class="toc-section-number">7.3.3</span> Big Data Solves Nothing</a></li>
</ul></li>
<li><a href="#mathematical-models-for-network-graphs"><span class="toc-section-number">7.4</span> Mathematical Models for Network Graphs</a>
<ul>
<li><a href="#classical-random-graph-models"><span class="toc-section-number">7.4.1</span> Classical Random Graph Models</a></li>
<li><a href="#generalized-random-graph-models"><span class="toc-section-number">7.4.2</span> Generalized Random Graph Models</a></li>
<li><a href="#network-graph-models-based-on-mechanisms"><span class="toc-section-number">7.4.3</span> Network Graph Models Based on Mechanisms</a></li>
<li><a href="#assessing-significance-of-network-graph-characteristics"><span class="toc-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics</a></li>
</ul></li>
<li><a href="#introduction-to-ergm"><span class="toc-section-number">7.5</span> Introduction to ERGM</a>
<ul>
<li><a href="#exponential-random-graph-models"><span class="toc-section-number">7.5.1</span> Exponential Random Graph Models</a></li>
<li><a href="#difficulty-in-parameter-estimation"><span class="toc-section-number">7.5.2</span> Difficulty in Parameter Estimation</a></li>
</ul></li>
<li><a href="#parameter-estimation-of-ergm"><span class="toc-section-number">7.6</span> Parameter Estimation of ERGM</a>
<ul>
<li><a href="#approximation-based-algorithm"><span class="toc-section-number">7.6.1</span> Approximation-based Algorithm</a></li>
<li><a href="#auxiliary-variable-mcmc-based-approaches"><span class="toc-section-number">7.6.2</span> Auxiliary Variable MCMC-based Approaches</a></li>
<li><a href="#varying-trunction-stochastic-approximation-mcmc"><span class="toc-section-number">7.6.3</span> Varying Trunction Stochastic Approximation MCMC</a></li>
</ul></li>
<li><a href="#ergm-for-dynamic-networks"><span class="toc-section-number">7.7</span> ERGM for Dynamic Networks</a>
<ul>
<li><a href="#temporal-ergm"><span class="toc-section-number">7.7.1</span> Temporal ERGM</a></li>
<li><a href="#separable-temporal-ergm"><span class="toc-section-number">7.7.2</span> Separable Temporal ERGM</a></li>
</ul></li>
<li><a href="#latent-network-models"><span class="toc-section-number">7.8</span> Latent Network Models</a>
<ul>
<li><a href="#latent-position-model"><span class="toc-section-number">7.8.1</span> Latent Position Model</a></li>
<li><a href="#latent-position-cluster-model"><span class="toc-section-number">7.8.2</span> Latent Position Cluster Model</a></li>
</ul></li>
<li><a href="#additive-and-multiplicative-effects-network-models"><span class="toc-section-number">7.9</span> Additive and Multiplicative Effects Network Models</a>
<ul>
<li><a href="#introduction-3"><span class="toc-section-number">7.9.1</span> Introduction</a></li>
<li><a href="#social-relations-regression"><span class="toc-section-number">7.9.2</span> Social Relations Regression</a></li>
<li><a href="#multiplicative-effects-models"><span class="toc-section-number">7.9.3</span> Multiplicative Effects Models</a></li>
<li><a href="#inference-via-posterior-approximation"><span class="toc-section-number">7.9.4</span> Inference via Posterior Approximation</a></li>
<li><a href="#discussion-and-example-with-r"><span class="toc-section-number">7.9.5</span> Discussion and Example with R</a></li>
</ul></li>
</ul></li>
<li><a href="#high-dimension"><span class="toc-section-number">8</span> High Dimension</a>
<ul>
<li><a href="#introduction-4"><span class="toc-section-number">8.1</span> Introduction</a></li>
<li><a href="#concentration-inequalities"><span class="toc-section-number">8.2</span> Concentration inequalities</a>
<ul>
<li><a href="#motivation"><span class="toc-section-number">8.2.1</span> Motivation</a></li>
<li><a href="#from-markov-to-chernoff"><span class="toc-section-number">8.2.2</span> From Markov to Chernoff</a></li>
<li><a href="#sub-gaussian-random-variables"><span class="toc-section-number">8.2.3</span> sub-Gaussian random variables</a></li>
<li><a href="#properties-of-sub-gaussian-random-variables"><span class="toc-section-number">8.2.4</span> Properties of sub-Gaussian random variables</a></li>
<li><a href="#equivalent-definitions"><span class="toc-section-number">8.2.5</span> Equivalent definitions</a></li>
<li><a href="#sub-gaussian-random-vectors"><span class="toc-section-number">8.2.6</span> Sub-Gaussian random vectors</a></li>
<li><a href="#hoeffdings-inequality"><span class="toc-section-number">8.2.7</span> Hoeffding’s inequality</a></li>
<li><a href="#maximal-inequalities"><span class="toc-section-number">8.2.8</span> Maximal inequalities</a></li>
<li><a href="#section"><span class="toc-section-number">8.2.9</span> </a></li>
</ul></li>
<li><a href="#concentration-inequalities-1"><span class="toc-section-number">8.3</span> Concentration inequalities</a>
<ul>
<li><a href="#sub-exponential-random-variables"><span class="toc-section-number">8.3.1</span> Sub-exponential random variables</a></li>
<li><a href="#bernsteins-condition"><span class="toc-section-number">8.3.2</span> Bernstein’s condition</a></li>
<li><a href="#mcdiarmids-inequality"><span class="toc-section-number">8.3.3</span> McDiarmid’s inequality</a></li>
<li><a href="#levys-inequality"><span class="toc-section-number">8.3.4</span> Levy’s inequality</a></li>
<li><a href="#quadratic-form"><span class="toc-section-number">8.3.5</span> Quadratic form</a></li>
<li><a href="#the-johnsonlindenstrauss-lemma"><span class="toc-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma</a></li>
</ul></li>
<li><a href="#metric-entropy-and-its-uses"><span class="toc-section-number">8.4</span> Metric entropy and its uses</a>
<ul>
<li><a href="#metric-space"><span class="toc-section-number">8.4.1</span> Metric space</a></li>
<li><a href="#covering-numbers-and-metric-entropy"><span class="toc-section-number">8.4.2</span> Covering numbers and metric entropy</a></li>
<li><a href="#packing-numbers"><span class="toc-section-number">8.4.3</span> Packing numbers</a></li>
<li><a href="#section-1"><span class="toc-section-number">8.4.4</span> </a></li>
<li><a href="#section-2"><span class="toc-section-number">8.4.5</span> </a></li>
<li><a href="#section-3"><span class="toc-section-number">8.4.6</span> </a></li>
</ul></li>
<li><a href="#covariance-estimation"><span class="toc-section-number">8.5</span> Covariance estimation</a>
<ul>
<li><a href="#matrix-algebra-review"><span class="toc-section-number">8.5.1</span> Matrix algebra review</a></li>
<li><a href="#covariance-matrix-estimation-in-the-operator-norm"><span class="toc-section-number">8.5.2</span> Covariance matrix estimation in the operator norm</a></li>
<li><a href="#bounds-for-structured-covariance-matrices"><span class="toc-section-number">8.5.3</span> Bounds for structured covariance matrices</a></li>
</ul></li>
<li><a href="#matrix-concentration-inequalities"><span class="toc-section-number">8.6</span> Matrix concentration inequalities</a>
<ul>
<li><a href="#matrix-calculus"><span class="toc-section-number">8.6.1</span> Matrix calculus</a></li>
<li><a href="#matrix-chernoff"><span class="toc-section-number">8.6.2</span> Matrix Chernoff</a></li>
<li><a href="#sub-gaussian-and-sub-exponential-matrices"><span class="toc-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices</a></li>
<li><a href="#랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds"><span class="toc-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</a></li>
</ul></li>
<li><a href="#principal-component-analysis"><span class="toc-section-number">8.7</span> Principal Component Analysis</a>
<ul>
<li><a href="#pca-1"><span class="toc-section-number">8.7.1</span> PCA</a></li>
<li><a href="#matrix-perturbation"><span class="toc-section-number">8.7.2</span> Matrix Perturbation</a></li>
<li><a href="#spiked-cov-model"><span class="toc-section-number">8.7.3</span> Spiked Cov Model</a></li>
<li><a href="#sparse-pca"><span class="toc-section-number">8.7.4</span> sparse PCA</a></li>
</ul></li>
<li><a href="#linear-regression"><span class="toc-section-number">8.8</span> Linear Regression</a>
<ul>
<li><a href="#problem-formulation"><span class="toc-section-number">8.8.1</span> Problem formulation</a></li>
<li><a href="#least-squares-estimator-in-high-dimensions"><span class="toc-section-number">8.8.2</span> Least Squares Estimator in high dimensions</a></li>
<li><a href="#sparse-linear-regression"><span class="toc-section-number">8.8.3</span> Sparse linear regression</a></li>
<li><a href="#sharing-your-book"><span class="toc-section-number">10.1.7</span> Sharing your book</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul></li>
<li><a href="#noname"><span class="toc-section-number">11</span> NoName</a></li>
<li><a href="#abstract-1"><span class="toc-section-number">12</span> ABSTRACT</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="intro" class="section level1 unnumbered">
<h1 class="unnumbered">Intro</h1>
<!--chapter:end:index.Rmd-->
</div>
<div id="part-20-02" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) 20-02</h1>
<!--chapter:end:202000.Rmd-->
</div>
<div id="categorical" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Categorical</h1>
<div id="overview" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> Overview</h2>
<div id="data-type-and-statistical-analysis" class="section level3" number="1.1.1">
<h3 number="1.1.1"><span class="header-section-number">1.1.1</span> Data Type and Statistical Analysis</h3>
<!--chapter:end:202206_Overview.Rmd-->
</div>
</div>
</div>
<div id="bayesian" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Bayesian</h1>
<div id="abstract" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> Abstract</h2>
<p>조건부 확률은 sample sapce가 <span class="math inline">\(S\)</span>에서 <span class="math inline">\(B\)</span>로 축소되었다는 것을 의미한다.</p>
<p>Bayesian의 Multiplication Rule은 사건이 시간순서대로 발생할 때 유용하게 사용될 수 있다.</p>
<p>set of events become <strong>partition</strong> of sample space <span class="math inline">\(S\)</span>:
1. mutually exclusive(disjoint)
2. Pr of union <span class="math inline">\(=1\)</span></p>
<p>event <span class="math inline">\(H\)</span>와 event <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>가 주어져 있다. <span class="math inline">\(A\)</span>와 <span class="math inline">\(B\)</span> 가 서로 독립이라면, <span class="math inline">\(H\)</span>가 주어졌을 때 <span class="math inline">\(A\)</span>가 추가되는 것이 <span class="math inline">\(B\)</span>에 대한 정보를 아는데 영향을 미치지 않는다. 수식으로 증명가능.</p>
<p><span class="math inline">\(Dirichlet\)</span>, <span class="math inline">\(Wishart\)</span></p>
<p><span class="math inline">\(posterior odds\)</span></p>
<div id="변수의-독립성" class="section level3" number="2.1.1">
<h3 number="2.1.1"><span class="header-section-number">2.1.1</span> 변수의 독립성</h3>
<p><span class="math inline">\(X_1 , \cdots, X_n\)</span>이 공통 sample space <span class="math inline">\(S\)</span>를 갖는 변수이고 <span class="math inline">\(\theta\)</span> is unknown parameter.</p>
<p>if <span class="math inline">\(S\)</span>, with for any subset(events) <span class="math inline">\(A_1 , \cdots, A_n\)</span>, $Pr(X_1 A_1 , , X_n A_n ) = Pr(X_1 A_1 ) * Pr(X_n A_n ), then <span class="math inline">\(X_1 , \cdots, X_n\)</span> 는 <span class="math inline">\(\theta\)</span>가 주어졌을 때 <strong>조건부 독립</strong>이다.</p>
<p>이는 앞서 말한 event의 독립성에 대응된다. 위의 독립성은 event의 독립성과 마찬가지로 $Pr(X_i A_i , X_j A_j) = Pr(X_i A_i ) 가 성립. 이는 <span class="math inline">\(\theta\)</span>가 주어졌을 때 <span class="math inline">\(X_j\)</span>의 정보가 <span class="math inline">\(X_i\)</span>에 대하여 아무런 추가정보를 주지 못함을 의미한다.</p>
<p>만약 세타가 주어진 상태에서 X1~Xn이 조건부 독립이라면 조건부 joint pdf는 각 조건부 margianl pdf의 곱과 같다. 만약 X-i가 모두 같은 분포를 따르면~. 이때 X_i들은 세타가 주어졌을 때 conditionally iid. 이는 marginal iid와는 구변된다. marginal iid는 X_i들의 marginal iid가 모두 같고 또한 독립이라는 소리.</p>
</div>
<div id="교환가능성" class="section level3" number="2.1.2">
<h3 number="2.1.2"><span class="header-section-number">2.1.2</span> 교환가능성</h3>
<p>독립성은 엄격한 조건. 만족안되는 경우 많음. 이것보다는 약조건이 <strong>교환가능성</strong>. 독립성 <span class="math inline">\(\rightarrow\)</span> 교환가능성이지만 교환가능성 <span class="math inline">\(\not \rightarrow\)</span> 독립성. 교환가능성까지만 만족되면 De Finetti thm은 성립함.</p>
<!--chapter:end:202401_Intro.Rmd-->
</div>
</div>
<div id="continual-aeassessment-method" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Continual Aeassessment Method</h2>
<!--chapter:end:202402_Bayesian_CAM.Rmd-->
</div>
<div id="horseshoe-prior" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> Horseshoe Prior</h2>
<!--chapter:end:202499_HorseshoePrior.Rmd-->
</div>
</div>
<div id="part-21-01" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) 21-01</h1>
<!--chapter:end:211000.Rmd-->
</div>
<div id="mathematical-stats" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Mathematical Stats</h1>
<div id="inference" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Inference</h2>
<p><span class="math inline">\(T(X)\)</span>가 <span class="math inline">\(\theta\)</span>의 추정량.
* bias $ = E - $
* if bias<span class="math inline">\(=0\)</span>, <span class="math inline">\(T(X)\)</span>는 <span class="math inline">\(\theta\)</span>의 UE.</p>
<p>이때, <span class="math inline">\(\theta\)</span> can be <span class="math inline">\(g(\theta)\)</span>. 즉슨, <span class="math inline">\(\theta\)</span>는 패러미터 그 자체만이 아니라 패러미터의 함수를 패러미터 삼아 이를 추정하려고 들 수도 있다. 이하의 전개에서는 <span class="math inline">\(\theta = g(\theta)\)</span> 로 이해하자.</p>
<p><span class="math inline">\(\theta\)</span>의 추정량 <span class="math inline">\(T(X)\)</span>의 MSE는 $MSE = Var +(bias)^2 $.</p>
<p><span class="math inline">\(T_1(X)\)</span>, <span class="math inline">\(T_2(X)\)</span>는 <span class="math inline">\(\theta\)</span>의 UE. <span class="math inline">\(T_1(X)\)</span>의 <span class="math inline">\(T_2(X)\)</span>에 대한 Relative Efficiency <span class="math inline">\(RE= \dfrac {Var \left[ T_2 (X) \right]} {Var \left[ T_1 (X) \right]}\)</span></p>
<p><br>
<br>
<br></p>
<hr />
<p>rv $X_1 , , X_n f(x_1 , , x_n ) $. 이하의 조건 하에서 추정량 <span class="math inline">\(T^\ast (X)\)</span>는 <span class="math inline">\(\theta\)</span>의 MVUE.
1. <span class="math inline">\(E \left [ T^\ast (X) \right] = \theta\)</span>. 즉 <span class="math inline">\(T^\ast (X)\)</span>는 <span class="math inline">\(\theta\)</span>의 UE.
2. $T(X):Var $.</p>
<p><br>
<br>
<br></p>
<hr />
<p>Fisher’s Information $I() = E { ^2 } $</p>
<p>regularity condition:
1. The partial derivative of <span class="math inline">\(f(X; \theta)\)</span> with respect to <span class="math inline">\(\theta\)</span> exists almost everywhere. (It can fail to exist on a null set, as long as this set does not depend on <span class="math inline">\(\theta\)</span>.)
2. The integral of <span class="math inline">\(f(X; \theta)\)</span> can be differentiated under the integral sign with respect to <span class="math inline">\(\theta\)</span>.
3. The support of <span class="math inline">\(f(X; \theta)\)</span> does not depend on <span class="math inline">\(\theta\)</span>.</p>
<p>e.g.,</p>
<ol style="list-style-type: decimal">
<li>패러미터 다르면 pdf 다름. 즉, <span class="math inline">\(\theta \not = \theta&#39;: f(x;\theta) \not = f(x;\theta&#39;)\)</span></li>
<li>set <span class="math inline">\(A = \{ x: f(x;\theta)&gt;0 \}\)</span>은 패러미터 <span class="math inline">\(\theta\)</span>에 의존하지 않고, <span class="math inline">\(\forall x \in A, \theta \in \Omega : \log f(x;\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 대해 두 번 미분 가능하고 도함수가 연속이다.</li>
<li>통계량 <span class="math inline">\(T(X)\)</span>가 <span class="math inline">\(\forall \theta \in \Omega: E \left [ T (X) \right] &lt; \infty\)</span> 라면, $  {} E $에 있어 미분과 적분의 순서를 바꿀 수 있다.</li>
</ol>
<p>Information inequality: <br>
under regularity condition, <span class="math inline">\(\forall g^{-1}(\theta) \in \Omega, Var \left [ T^\ast (X) \right] &lt; \infty, E \left [ T^\ast (X) \right] = \theta, 0&lt;I(\theta)&lt; \infty:\)</span> <span class="math inline">\(\theta\)</span> is differentiable, and <span class="math inline">\(Var \left [ T^\ast (X) \right] \ge \dfrac {1}{n} \dfrac {\left[ g&#39;(\theta) \right]^2}{I (\theta)}\)</span>.</p>
<p><br>
<br>
<br></p>
<hr />
<p>rv $X_1 , , X_n f(x_1 , , x_n ) $. <span class="math inline">\(l\)</span>개 stats(통계량)의 벡터 <span class="math inline">\(\pmb {S(X)} = \left[ S_1(X), \cdots, S_l(X) \right]\)</span>. <br>
이때 rv $X_1 , , X_n  $의 분포가 패러미터 $ = (_1 , , _k )$에 의존하지 않으면 stats <span class="math inline">\(\pmb {S(X)}\)</span>는 joint SS.</p>
<p>rv $X_1 , , X_n f(x_1 , , x_n ) $. 1개 stats(통계량) <span class="math inline">\(S(X)\)</span>. <br>
이때 rv <span class="math inline">\(X_1 , \cdots, X_n \rvert S(X)\)</span> 의 분포가 패러미터 <span class="math inline">\(\theta = (\theta_1 , \cdots, \theta_k )\)</span>에 의존하지 않으면 stats <span class="math inline">\(S(X)\)</span>는 SS.</p>
<p><br>
<br>
<br></p>
<hr />
<ul>
<li>Decomposition thm.:</li>
</ul>
<p>rv $X_1 , , X_n f(x_1 , , x_n ) $. <span class="math inline">\(k\)</span>개 stats(통계량) <span class="math inline">\(\pmb {S(X)} = \left[ S_1(X), \cdots, S_k(X) \right]\)</span>.</p>
<p>stats <span class="math inline">\(\pmb {S(X)}\)</span>는 joint SS <span class="math inline">\(\iff\)</span> $f(x_1 , , x_n ; ) = g h(x_1 , , x_n) $</p>
<p><br>
<br>
<br></p>
<hr />
<div id="rao-blackwell-thm." class="section level3" number="3.1.1">
<h3 number="3.1.1"><span class="header-section-number">3.1.1</span> Rao-Blackwell thm.</h3>
<p>패러미터의 함수 <span class="math inline">\(\theta\)</span>, <span class="math inline">\(S\)</span>는 SS, <span class="math inline">\(T(X)\)</span>는 UE. let <span class="math inline">\(\delta (S) = E \left [ T(X) \rvert S \right]\)</span>. 이때 <span class="math inline">\(\delta (S)\)</span>는 <span class="math inline">\(\theta\)</span>의 UE. 따라서</p>
<p>$$
<span class="math display">\[\begin{align*}

Var \left[ \delta (S) \right ] &amp;= E \left\{ \left[ \delta (S) - \theta \right]^2 \right\} \\
&amp;\le E \left\{ \left[ T(X) - \theta \right]^2 \right\} = Var \left [ T(X) \right]

\end{align*}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<hr />
</div>
</div>
<div id="completeness" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Completeness</h2>
<p>r<strong><em>s</em></strong> $X_1 , , X_n $의 stats $ T (X_1 , , X_n ) $에 대해, let</p>
<p><span class="math display">\[
\forall \theta \in \Omega: \; \; E \left[ g(T) \right]=0
\]</span></p>
<p>이때 이를 만족하는 <span class="math inline">\(\theta\)</span>에 무관한 함수 <span class="math inline">\(g\)</span>가 <span class="math inline">\(g(\cdot) \equiv 0\)</span> 뿐이라면, <span class="math inline">\(T\)</span>는 CS. <span class="math inline">\(T\)</span>가 <span class="math inline">\(\theta\)</span>에 대한 SS라면, 이는 CSS.</p>
<p>stats <span class="math inline">\(Y\)</span>가 분포모임 <span class="math inline">\(\{g(y;\theta);\theta \in \Theta \}\)</span>의 한 원소를 pdf로 가진다고 하자.</p>
<p><span class="math display">\[
\forall \theta \in \Theta: \; \; E_{\theta} \left[ \varphi(Y) \right] \overset{\theta}{=}{0} \; \; \; \rightarrow \; \; \; \varphi(y) \overset{y}{=} 0
\]</span></p>
<p>위의 명제가 성립할 때 위 분포족은 completeness를 지닌다.
* 여기서 <span class="math inline">\(\varphi\)</span>는 <span class="math inline">\(\theta\)</span>에 무관한 함수이다.
* 피명제는 보다 엄밀히는 <span class="math inline">\(\forall \theta: P_{\theta} \{ \varphi (Y)=0 \}=1\)</span>.
* <span class="math inline">\(\overset{\theta}{=}\)</span>는 모든 <span class="math inline">\(\theta \in \Omega\)</span>에 대해 등호가 성립함을 나타낸다.</p>
<p>Remarks:
1. completeness는 본질적으로 확률분포의 패러미터 <span class="math inline">\(\theta\)</span>가 통계량 <span class="math inline">\(Y\)</span>를 통해 추정될 수 있음을 보장하는 조건으로 이해될 수 있다.
* 즉, completeness는 서로 다른 패러미터값을 지니는 두 분포는 서로 구분(distinct)됨을 보장해주는 조건이다.
2. 통계량 <span class="math inline">\(Y\)</span>의 분포족이 completeness를 만족하면, <span class="math inline">\(Y\)</span>를 완비통계량 CS라고 부른다.
3. 완비성은 CS의 함수로 이루어지는 UE는 unique하다는 사실을 보이는 도구로 이용된다. 레만-쉐페 thm 참조.</p>
<p><br>
<br>
<br></p>
<hr />
<div id="레만-쉐페-thm." class="section level3" number="3.2.1">
<h3 number="3.2.1"><span class="header-section-number">3.2.1</span> 레만-쉐페 thm.</h3>
<p>패러미터 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(T\)</span>가 CSS, <span class="math inline">\(S(X)\)</span>는 <span class="math inline">\(\theta\)</span>의 UE. 이때 $(T)=E $는 <span class="math inline">\(\theta\)</span>의 UMVUE.</p>
<p><br></p>
<p>r<strong><em>s</em></strong> <span class="math inline">\(X_1 , \cdots, X_n \overset{iid}{\sim} f(x;\theta)\)</span>. <span class="math inline">\(\theta\)</span>에 대한 CSS <span class="math inline">\(Y=u(X_1 , \cdots, X_n)\)</span>. 이때 임의의 UE <span class="math inline">\(\hat \theta\)</span>에 대해</p>
<p><span class="math display">\[
\varphi (Y) = E(\hat \theta \rvert Y)
\]</span></p>
<p>는 <span class="math inline">\(\theta\)</span>에 대한 UMVUE. 이는 unique.</p>
<p><br>
<br>
<br></p>
<hr />
</div>
<div id="rao-blackwell-thm.-1" class="section level3" number="3.2.2">
<h3 number="3.2.2"><span class="header-section-number">3.2.2</span> Rao-Blackwell thm.</h3>
<p>r<strong><em>s</em></strong> <span class="math inline">\(X_1 , \cdots, X_n \overset{iid}{\sim} f(x;\theta), \theta \in \Theta\)</span>.
1. <span class="math inline">\(Y= u(X_1 , \cdots, X_n)\)</span>는 <span class="math inline">\(\theta\)</span>의 CSS.
2. <span class="math inline">\(Z= v(X_1 , \cdots, X_n)\)</span>의 분포는 <span class="math inline">\(\theta\)</span>에 의존하지 않는다.</p>
<p>이상의 조건이 만족되면 <span class="math inline">\(Y \perp Z\)</span>.</p>
<p><br>
<br>
<br></p>
<hr />
<ul>
<li>exponentail family: <br></li>
</ul>
<p>pdf가 적절한 함수 <span class="math inline">\(a, b, c_i, t_i (i=1,\cdots, k)\)</span>에 대해 <span class="math inline">\(f(x;\theta) = a(\theta) b(x) \exp \left[ \sum_{i=1}^k c_i (\theta) t_i (x) \right], -\infty\)</span></p>
<p><br>
<br>
<br></p>
<p>지수족에 속하는 pdf로부터 r<strong>s</strong> $X_1 , , X_n $를 얻었다면, 통계량 $S_1 = <em>{i=1}^n t_1 (X_i), , S_k = </em>{i=1}^n t_k (X_i) $ 는 패러미터 $_1 , , _k $에 대한 joint (C) SS이다.</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(g(\theta)\)</span>에 대한 est <span class="math inline">\(\tau(\pmb X)\)</span>가 <span class="math inline">\(\forall \epsilon &gt;0: \lim_{n \rightarrow \infty} P \left( \vert \tau(\pmb X) - g(\theta) \vert \le \epsilon \right) =1\)</span>을 만족하면 est <span class="math inline">\(\tau(\pmb X)\)</span>는 consistency를 가진다.</p>
<p>이는 표본의 크기가 커짐에 따라 est <span class="math inline">\(\tau(\pmb X)\)</span>가 <span class="math inline">\(g(\theta)\)</span>에 <strong>확률적으로 수렴</strong>한다는 것. 표본의 크기가 매우 클 때, est <span class="math inline">\(\tau(\pmb X)\)</span>로부터 계산된 추정값 estimates는 높은 확률로 참모수값에 매우 가까이 있다는 뜻.</p>
<p><br>
<br>
<br></p>
<hr />
<p>est <span class="math inline">\(\tau(\pmb X)\)</span>를 <span class="math inline">\(g(\theta)\)</span>의 것일 때, <span class="math inline">\(\forall \theta \in \Theta: \lim_{n \rightarrow \infty} P E \left\{ \tau(\pmb X)-g(\theta)\right\}^2 = 0\)</span>이 성립하면 est <span class="math inline">\(\tau(\pmb X)\)</span>는 consistent.</p>
<p><br>
<br>
<br></p>
<hr />
<p>est <span class="math inline">\(\tau(\pmb X)\)</span>가 <span class="math inline">\(\theta\)</span>의 consistent이고, <span class="math inline">\(g(x)\)</span>가 <span class="math inline">\(\theta\)</span>에서 연속인 함수라면, <span class="math inline">\(g\tau(\pmb X)\)</span></p>
<!--chapter:end:211101_Intro.Rmd-->
</div>
</div>
<div id="hypothesis-test" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Hypothesis Test</h2>
<div class="line-block">통계적 가설 | Statistical Hypothesis | 관심있는 population의 성질에 대한 단정이나 추측 등의 표현 (statement) <br> 이러한 가설은 흔히 모집단의 성질을 나타내는 rv의 분포에 대한 표현으로 나타난다. |<br />
단순가설 | Simple Hypothesis | 어떤 가설이 확률분포 (pd) 를 완전히 결정한다 |<br />
복합가설 | Composite Hypothesis | 그렇지 않다 |</div>
<p>다양한 검정법에서 우선순위를 정하는 것은 옳은 결론을 내리는 빈도가 높은, 즉 <strong>잘못된 결정을 내릴 확률이 낮은 검정법이 좋은 검정법</strong>이라는 것.</p>
<p>검정통계량(Test Statistics): 주어진 rs에 근거하여 통계적 가설에 대한 증거를 살펴볼 때 사용되는 통계량</p>
<p>기각영역(Rejection Region, Critical Region): <span class="math inline">\(H_0\)</span>를 기각하게 되는 검정통계량의 값을 가지는 <strong>sample space의 부분집합</strong> (event)</p>
<div class="line-block">| <span class="math inline">\(H_0\)</span> True | <span class="math inline">\(H_0\)</span> False |<br />
reject <span class="math inline">\(H_0\)</span> | | Type 2 Error (<span class="math inline">\(\beta\)</span>) <br> 유죄인데 석방 |<br />
accept <span class="math inline">\(H_0\)</span> | Type 1 Error (<span class="math inline">\(\alpha\)</span>) <br> <strong>무죄인데 사형</strong> | |</div>
<p>제1종 오류를 범활 확률 <span class="math inline">\(\alpha\)</span>는 유의확률(Significance Level) 라고 따로 칭함. <span class="math inline">\(H_1\)</span>은 기존으로부터의 변화이므로 채택에 있어 훨씬 엄격해야 함. 따라서 <span class="math inline">\(\alpha\)</span>가 <span class="math inline">\(\beta\)</span>보다 훨씬 더 중시됨.</p>
<p>let Rejection Region <span class="math inline">\(C\)</span>. then</p>
<p>$$
<span class="math display">\[\begin{alignat*}{2}

\alpha &amp;= P(\text{Type 1 Error}) \\
&amp;= P(\text{accept }H_1 \vert H_0) \\
&amp;= P(\pmb X_n \in C \vert H_0) 

\begin{aligned}[t]
           &amp; = \int_C f(\pmb x \vert H_0) d \pmb x\\
           &amp;= \sum_C f(\pmb x \vert H_0)
         \end{aligned}


\end{alignat*}\]</span>
$$</p>
<p>This can also be written as Loss Function.</p>
<p>$$
<span class="math display">\[\begin{align*}

L(H_i ; H_j ) = 

 \begin{cases}
    0, &amp; \text{if } i = j  \\
    1, &amp; \text{for } i \not = j, \; \; (i,j = 0, 1)
    
  \end{cases}

\end{align*}\]</span>
$$</p>
<p>$$
<span class="math display">\[\begin{align*}

E \left [ L(H_1 ; H_0 ) \right] &amp;= P(\text{Type 1 Error}) \\
E \left [ L(H_0 ; H_1 ) \right] &amp;= P(\text{Type 2 Error})

\end{align*}\]</span>
$$</p>
<p><img src="https://i.stack.imgur.com/3NO3M.png" width="480" alt="hi" class="inline"/></p>
<p><br>
<br>
<br></p>
</div>
<div id="power-fucntion" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> Power Fucntion</h2>
<p>여기서, <span class="math inline">\(H_0\)</span>에 대한 기각영역이 <span class="math inline">\(C\)</span>인 test의 검정력함수 (power function)은 이하와 같다. 즉, 이는 <strong><span class="math inline">\(H_0\)</span>를 기각하는 확률</strong>로 정의된다.</p>
<p><span class="math display">\[
\pi(\theta) = P (\pmb X_n \in C \vert \theta)
\]</span></p>
<p>이는 패러미터 <span class="math inline">\(\theta\)</span>의 참값이 무엇이냐에 따라 다른 값을 가지므로 <span class="math inline">\(\theta\)</span>의 함수이다.</p>
<p>주어진 <span class="math inline">\(\theta\)</span>에서의 power function의 값 <span class="math inline">\(\pi(\theta)\)</span>은 이 <span class="math inline">\(\theta\)</span>에서의 검정력 (power).</p>
<p>power는 <span class="math inline">\(H_0\)</span>를 기각할 확률.
* if <span class="math inline">\(\theta \in H_0\)</span>, power는 작을수록 좋다.
* <span class="math inline">\(\theta = \theta_0 \in H_1\)</span>, 이 경우 power <span class="math inline">\(\pi(\theta) = \pi(\theta_0) = \alpha\)</span>.
* if <span class="math inline">\(\theta \in H_1\)</span>, power는 클수록 좋다.
* <span class="math inline">\(\theta \in H_1\)</span>, and <span class="math inline">\(H_1\)</span>이 simple hypothesis, 이 경우 power <span class="math inline">\(\pi(\theta) = 1- \beta\)</span>.</p>
<p>이와 같이 power function은, 마치 MSE가 점추정의 기준이 되었던 것처럼, <span class="math inline">\(\alpha\)</span> (유의수준)이 고정되었을 때 test 방법의 성능을 결정하는 기준이 된다.</p>
<p><br>
<br>
<br></p>
<div id="significance-probability-p-value" class="section level3" number="3.4.1">
<h3 number="3.4.1"><span class="header-section-number">3.4.1</span> Significance Probability (p-value)</h3>
<p>앞에서 언급했던 것과 같이, 좋은 검정법을 찾기 위해 sample space를 <span class="math inline">\(C\)</span>와 채택영역 <span class="math inline">\(C^c\)</span>로 나누고 <span class="math inline">\(\alpha\)</span>와 <span class="math inline">\(\beta\)</span>를 계산하여 오류의 확률을 작게 만드는 검정법을 고르게 된다. 사용할 검정법을 결정하고 나면, 자료에서 관측된 값이 <span class="math inline">\(C\)</span>에 속할 경우 <span class="math inline">\(H_0\)</span>를 기각하고, 이외에는 <span class="math inline">\(H_0\)</span>를 기각하지 않는다고 결론을 내리게 된다. 그런데 관찰된 test stat의 값이 <span class="math inline">\(C\)</span>에 속한다 하더라도 값의 크기 등에 따라 <strong>통계적 유의성</strong>에 대한 의미가 다를 수 있다. 따라서 기각할 것인지, 하지 않을 것인지 이분법적인 결론만을 제시하기보다, 관측한 자료가 <span class="math inline">\(H_0\)</span>에 대하여 어느 정도의 반증이 되는지를 수치적으로 나타낼 수 있는 <span class="math inline">\(\alpha\)</span> (유의확률)을 이용하여 test의 결론에 이르는 경우가 많이 있다.</p>
<p>p값 (p-value), 즉 관측된 유의수준 (observed significance level), 혹은 유의확률 (Significance Probability), 는 <span class="math inline">\(H_0\)</span>가 참이라는 가정 하에, 우리가 관측한 값과 같거나 더 극단적인 값을 얻을 확률 (ex. <span class="math inline">\(P(T \ge t \vert H_0 )\)</span>) 로 정의된다. 여기서 더 극단적이라는 것은, 관측한 값보다 <span class="math inline">\(H_1\)</span>에 더 가까운 것을 의미한다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 아주 작은 값이 나왔다면, 우리가 관측한 값 자체가 이미 매우 극단적이라서 이보다 더 강한 <span class="math inline">\(H_1\)</span>에 대한 증거를 관측할 확률이 작다는 것이다. 즉, <strong>관측값이 <span class="math inline">\(H_0\)</span> 하에서 나오기 어려운 값</strong>이라는 뜻이므로 <span class="math inline">\(H_0\)</span>를 기각할 근거가 된다고 할 수 있다. 만약 어떤 관측값에 대하여 p값을 계산하였더니 작지 않은 값이 나왔다면, 우리가 관측한 값이 <span class="math inline">\(H_0\)</span> 하에서 흔히 나올 수 있는 값이라는 것이고, 즉 <span class="math inline">\(H_0\)</span>를 기각할 근거가 되지 않는다고 할 수 있다.</p>
<p>p값이 <span class="math inline">\(H_0\)</span>를 기각할만큼 작은지를 결정하는 것은 보통 결과를 해석하는 사람에게 달려있다. 그러나 가설검정을 할 때는 흔히 적당한 유의수준 <span class="math inline">\(\alpha\)</span>의 값을 생각하고 있기 마련이므로, p값이 <span class="math inline">\(\alpha\)</span>보다 작으면 관측된 자료가 대립 가설에 대한 충분한 증거가 된다고 판단하여 <span class="math inline">\(H_0\)</span>를 기각하게 된다. 정리하자면, p값은 <span class="math inline">\(H_0\)</span> 하에서 test stat의 관찰값 (test stats) 이 <span class="math inline">\(H_0\)</span>를 기각하는 방향으로 나타나는 확률을 의미한다. 주어진 유의수준 <span class="math inline">\(\alpha\)</span>보다 p값이 작으면 <span class="math inline">\(H_0\)</span>를 기각하며, 그렇지 않은 경우에는 <span class="math inline">\(H_0\)</span>를 받아들이게 된다.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="optimal-testing-method" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> Optimal Testing Method</h2>
<p>항상 옳은 결과를 가져다주는 검정법을 사용할 수 있다면 가장 좋겠지만, 샘플에서 주어지는 정보만을 가지고 모집단의 특성에 대한 결론을 내려야 하는 상황에서 언제나 옳은 결과를 가져다주는 test 방법을 찾을 수는 없다. 그렇기에 이 장의 목표는 옳은 결과를 가져다주는 빈도가 높은 test 방법을 찾는 것이 된다. 잘못된 결론을 내릴 확률은 두 가지 오류로 표현되므로, 제 1종 오류와 제 2종 오류의 발생확률을 낮게 하는 test 방법을 찾아야 한다. 불행히도, 샘플의 크게가 정해져 있는 경우 둘 다를 최소로 하는 test 방법을 찾는 거은 불가능하다. 예를 들면, <span class="math inline">\(\alpha\)</span>를 최소로 하는 가장 간단한 방법은 언제나 <span class="math inline">\(H_0\)</span>를 채택하는 것이지만 (<span class="math inline">\(\alpha = 0\)</span>), 이는 <span class="math inline">\(H_1\)</span>에서의 power를 0으로 최소화시키고, 즉, <span class="math inline">\(\beta\)</span>를 극대화시킨다.</p>
<hr />
<p>let <span class="math inline">\(\pmb X_{25} \overset {\text{iid}} {\sim} N(\mu, 10^2 )\)</span>.</p>
<p><span class="math display">\[
H_0 : \mu = 100, \; \; \; \; \; H_1 : \mu &gt; 100
\]</span></p>
<p><img src="KakaoTalk_20210522_171926819.jpg" width="320" alt="hi" class="inline"/></p>
<p>이때. <span class="math inline">\(\mu=100\)</span>에서의 power는 유의수준 <span class="math inline">\(\alpha\)</span>와 같고, <span class="math inline">\(\mu&gt;100\)</span>일 경우에는 <span class="math inline">\(\pi(\mu) = 1-\beta(\mu)\)</span>. 이인즉</p>
<p>$$
<span class="math display">\[\begin{align*}

\lim_{\mu \downarrow 100} \beta(\mu) &amp;= 1- \pi(100) \\
&amp;= 1- \alpha

\end{align*}\]</span>
$$</p>
<p>따라서 <span class="math inline">\(H_0\)</span>와 <span class="math inline">\(H_1\)</span>의 경계점에서 <span class="math inline">\(\alpha + \beta = 1\)</span>이 된다. 즉, 샘플의 크기가 일정할 때 <span class="math inline">\(\alpha\)</span>를 줄이고자 하면 경계점에서 <span class="math inline">\(\beta\)</span>의 값이 커지며, 이 역 또한 성립한다. 이를 power로 표현하면, <span class="math inline">\(H_0\)</span> 하에서 power는 큰 것이 바람직하나 power <span class="math inline">\(\pi (\mu)\)</span>를 늘이고자 하면 <span class="math inline">\(\alpha\)</span>의 값이 같이 커지게 되므로 제1종 오류의 확률 (<span class="math inline">\(\alpha\)</span>)의 확률을 최소화하면서 power를 최대화하는 일은 sample의 크기가 정해져 있는 경우 불가능하다.</p>
<p>만약 sample의 크기를 늘인다면, <span class="math inline">\(\alpha\)</span>의 값을 고정시킨 상태에서 주어진 <span class="math inline">\(H_1\)</span> 하에서의 <span class="math inline">\(\mu\)</span> 값에서의 power를 크게 할 수 있다.</p>
<hr />
<p>이 절에서는 power function <span class="math inline">\(\pi(\cdot)\)</span>을 기준으로 하는 Optimal Testing Method (최량검정법)에 대해 살펴볼 것이다. 우선, <span class="math inline">\(H_0\)</span>와 <span class="math inline">\(H_1\)</span>이 모두 simple인 경우를 생각해보자. 위에서 이야기하였듯 <span class="math inline">\(\alpha\)</span>를 최소화하면서 <span class="math inline">\(H_0\)</span> 하에서의 power를 최대화하는 것은 불가능하므로, 이에 대한 합리적 대안으로 <span class="math inline">\(\alpha\)</span> (제1종 오류를 범할 확률)을 주어진 작은 값으로 제한한 상태에서, power를 최대화하는 의미에서의 OTM을 다음과 같이 정의한다.</p>
<hr />
<p>$$</p>
<p>H_0: = _0, ; ; ; ; ; H_1: = _1</p>
<p>$$</p>
<p>에 대한 rejection region <span class="math inline">\(C^\ast\)</span> 가 다음 조건을 만족할 때 이를 유의수준 <span class="math inline">\(\alpha\)</span> 에서의 MPT의 RR, 또는 MPRR이라고 한다.</p>
<p><span class="math inline">\(\pi^\ast\)</span>가 <span class="math inline">\(C^\ast\)</span>에 해당하는 power function이라 하면,
1. <span class="math inline">\(\pi^\ast (\theta_0) = \alpha\)</span>,
2. <span class="math inline">\(\forall \text{ RR } C, \; \text{whose 유의수준과 power function } \alpha, \pi: \pi^\ast(\theta_1) \ge \pi(\theta_1)\)</span>.</p>
<hr />
<!--chapter:end:211105_Hypothesis_test.Rmd-->
</div>
<div id="data-reduction" class="section level2" number="3.6">
<h2 number="3.6"><span class="header-section-number">3.6</span> Data Reduction</h2>
<div id="sufficiency-principle" class="section level3" number="3.6.1">
<h3 number="3.6.1"><span class="header-section-number">3.6.1</span> Sufficiency Principle</h3>
<p><span class="math inline">\(X \vert T(X)\)</span>의 분포가 <span class="math inline">\(\theta\)</span>에 의존하지 않는다면, <span class="math inline">\(T(X)\)</span>는 <span class="math inline">\(\theta\)</span>의 SS.
- <span class="math inline">\(T(X)\)</span>가 <span class="math inline">\(\theta\)</span>의 SS라면, <span class="math inline">\(\theta\)</span>에 대한 모든 추론은 <span class="math inline">\(T(X)\)</span>를 거쳐서만이 <span class="math inline">\(X\)</span>에 의존함. 즉 <span class="math inline">\(T(X)\)</span> 값만 알 수 있다면 모든 <span class="math inline">\(X\)</span>에 대해 알지 못해도 무관.</p>
<p><br>
<br></p>
<p>비율 <span class="math inline">\(\dfrac{f_X(x \vert \theta)}{f_T(X) \left( T(x) \vert \theta \right)}\)</span>가 <span class="math inline">\(\forall x \in \Omega\)</span>에 대해 <span class="math inline">\(\theta\)</span>의 함수로서 constant 하다면, <span class="math inline">\(T(X)\)</span>는 <span class="math inline">\(\theta\)</span>의 SS. 이인즉 <span class="math inline">\(f(x \vert T(x))\)</span> 는 <span class="math inline">\(\theta\)</span>에 의존하지 않는다.
- rs itself와 rs의 order statistics는 SS이다.</p>
<p><br>
<br></p>
<p>Factorization thm.: sample point <span class="math inline">\(x\)</span>, parameter points <span class="math inline">\(\theta\)</span></p>
<p>$$</p>
<p>T(X)  x, : g , h(x) : f(x ) = g h(x)</p>
<p>$$</p>
<p>SS를 찾기 위해 factorization thm.을 쓰려면, 우리는 샘플의 joint pdf를 두 부분으로 나눠야 한다. 이는 <span class="math inline">\(\theta\)</span>를 포함하지 않는 (의존하지 않는) <span class="math inline">\(h(x)\)</span>와 <span class="math inline">\(\theta\)</span> 를 포함하는 <span class="math inline">\(g \left[ T(x) \vert \theta \right]\)</span> 이다. <span class="math inline">\(\theta\)</span>를 포함하는 <span class="math inline">\(g\)</span> 쪽의 식이 <span class="math inline">\(T(x)\)</span>로 표시될 수 있으면, 즉 <span class="math inline">\(x\)</span>에 의존하는 바가 <span class="math inline">\(T(x)\)</span>를 통해서만 의존한다면, <span class="math inline">\(T(x)\)</span>는 <span class="math inline">\(\theta\)</span>의 SS이다.</p>
<p><br>
<br></p>
<p>proof)</p>
<p><span class="math inline">\(X_1 , \cdots, x_n \overset {iid} {\sim} f(x \vert \pmb \theta) = h(x)c(\pmb \theta) \exp \left( \sum_{i=1}^k w_i (\pmb \theta)t_i(x) \right)\)</span>, s.t. exponential family, where <span class="math inline">\(\pmb \theta = (\theta_1 , \cdots, \theta_d), d \le k\)</span>. then</p>
<p><span class="math display">\[
T(X) = \left( \sum_{j=1}^n t_1 (X_j) , \cdots, \sum_{j=1}^n t_k (X_j) \right)
\]</span></p>
<p>is SS for <span class="math inline">\(\theta\)</span>.</p>
<!--chapter:end:211106_Data_Reduction.Rmd-->
</div>
</div>
<div id="borel-paradox" class="section level2" number="3.7">
<h2 number="3.7"><span class="header-section-number">3.7</span> Borel Paradox</h2>
<p>Throughout this chapter, for continuous rv <span class="math inline">\(X, Y\)</span>, we have been writing expressions such as <span class="math inline">\(E(Y \rvert X=x)\)</span> and <span class="math inline">\(P(Y \le y \rvert X=x)\)</span>. Thus far, we have not gotten into trouble. However, we might have.</p>
<p>Formally, the conditioning in a conditional expectation is done with respect to a sub sigma-algebra(1.2.1), and the conditional E $E(Y G) $ is defined as a rv whose integral, over any set in the sub sigma-algebra <span class="math inline">\(G\)</span>, agrees with that of <span class="math inline">\(X\)</span>. This is quite an advanced concept in probatbility theory (see Billingsley 1995, Section 34).</p>
<p>Since the conditional E is only defined in terms of its integral, it may not be unique even if the conditioning is well-defined. However, when we condition on sets of probatbility 0 (such as $ { X=x }$), conditioning may not be well defined, so different conditional expectations are more likely to appear. To see how this could affect us, it is easiest to look at conditional distributions, which amounts to calculating <span class="math inline">\(E \left[ I(Y \le y) \rvert X=x \right]\)</span>.</p>
<p>Proschan and Presnell (1998) tell the story of a statistics exam that had the question “If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent standard normals, what is the conditional distributions of <span class="math inline">\(Y\)</span> given that <span class="math inline">\(Y=X\)</span>?” Different students interpreted the condition <span class="math inline">\(Y=X\)</span> in the following ways:
1. <span class="math inline">\(Z_1 = 0\)</span>, where <span class="math inline">\(Z_1 = Y-X\)</span>;
2. <span class="math inline">\(Z_2 = 1\)</span>, where <span class="math inline">\(Z_2 = Y/X\)</span>;
3. <span class="math inline">\(Z_3 = 1\)</span>, where <span class="math inline">\(Z_3 = I(Y=X)\)</span>.</p>
<p>Each condtion is a correct interpretation of the conditon <span class="math inline">\(Y=X\)</span>, and each leads to a different conditional distribution (see Excercise 4.60.).</p>
<p>This is the <strong><em>Borel Paradox</em></strong> and arises b/c different (Correct) interpretations of the probatbility 0 conditioning sets result in different conditional E. How can we avoid the paradox? One way is to avoid conditioning on sets probatbility 0. That is, compute only <span class="math inline">\(E(Y \rvert X \in B )\)</span>, where <span class="math inline">\(B\)</span> is a set with <span class="math inline">\(P (X \in B)&gt;0\)</span>. So to compute something like <span class="math inline">\(E(Y \rvert X =x )\)</span>, take a sequence <span class="math inline">\(B_n \downarrow x\)</span>, and define <span class="math inline">\(E(Y \rvert X =x )= \lim_{n \rightarrow \infty} E(Y \rvert X \in B_n )\)</span>. We now avoid the paradox, as the different answers for <span class="math inline">\(E(Y \rvert X =x )\)</span> will arose from different sequences, so there should be no surprises (Exercise 4.61).</p>
<!--chapter:end:211110_Borel_Paradox.Rmd-->
</div>
<div id="neymanpearson-lemma" class="section level2" number="3.8">
<h2 number="3.8"><span class="header-section-number">3.8</span> Neyman–Pearson lemma</h2>
<p>rs <span class="math inline">\(X_1 , \cdots, X_n \overset {iid}{\sim} f(x_1 , \cdots, x_n ; \theta)\)</span>이고, $H_0 : =_0, ; ; ; H_1 : =_1 $. 이때 이하를 만족하면 rejection region <span class="math inline">\(R\)</span>은 MP test의 기각역.</p>
<p><span class="math inline">\(\exists k \ge 0\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\pmb x \in R\)</span> if <span class="math inline">\(f(\pmb x \vert \theta_1) &gt; k f(\pmb x \vert \theta_0)\)</span>.</li>
<li><span class="math inline">\(\pmb x \in R^c\)</span> if <span class="math inline">\(f(\pmb x \vert \theta_1) &lt; k f(\pmb x \vert \theta_0)\)</span>.</li>
<li><span class="math inline">\(\mathbb{P}_{\theta_0} \left( \pmb X \in R \right) = \alpha\)</span> for the prefiexed significance level <span class="math inline">\(\alpha\)</span>.</li>
</ol>
<p><br>
<br></p>
<p>Proof:</p>
<p><span class="math display">\[\begin{align}

P(\pmb X \in A \vert \theta) &amp;= \int_A L(\theta ; \pmb x) d \pmb x \\

&amp;= \int_A f(\pmb x ; \theta) d \pmb x 

\end{align}\]</span></p>
<p>이므로, <span class="math inline">\(A \subset C^\ast\)</span>라면</p>
<p><span class="math display">\[\begin{alignat}{4}

\int_A f(\pmb x ; \theta) d \pmb x &amp;\le \int_A &amp;&amp; k \ast f(\pmb x ; \theta) d \pmb x \\

\\

P(\pmb X \in A \vert \theta_0) &amp;\le &amp;&amp; k \ast P(\pmb X \in A \vert \theta_1)

\end{alignat}\]</span></p>
<p><br></p>
<p>마찬가지 방법으로 <span class="math inline">\(A \subset \left( C^\ast \right)^c\)</span>라면 <span class="math inline">\(P(\pmb X \in A \vert \theta_0) \ge k \ast P(\pmb X \in A \vert \theta_1)\)</span>.</p>
<p><br></p>
<p><span class="math inline">\(C^\ast\)</span>의 유의수준이 <span class="math inline">\(\alpha\)</span>라 하고, 유의수준이 동일한 임의의 RR <span class="math inline">\(C\)</span>를 가정하자. 이때 두 RR은 각각</p>
<p><span class="math display">\[\begin{align}

C^\ast &amp;= (C^\ast \cap C) \cup (C^\ast \cap C^c) \\


C &amp;= (C^\ast \cap C) \cup ({C^\ast}^c \cap C) 

\end{align}\]</span></p>
<p><br></p>
<p>로 표현할 수 있으며, 두 RR에 대한 power function은 각각</p>
<p><span class="math display">\[\begin{alignat}{4}

\pi^\ast(\theta) &amp;= P(\pmb X \in C^\ast \vert \theta)



&amp;&amp;= P(\pmb X \in C^\ast \cap C \vert \theta) &amp;&amp;+ P(\pmb X \in C^\ast \cap C^c \vert \theta) \\


\pi(\theta) &amp;= P(\pmb X \in C \vert \theta)

&amp;&amp;= P(\pmb X \in C^\ast \cap C \vert \theta) &amp;&amp;+ P(\pmb X \in {C^\ast}^c \cap C \vert \theta) \\


\end{alignat}\]</span></p>
<p><br></p>
<p>이때 <span class="math inline">\(H_0\)</span>에서 두 power의 차이는</p>
<p><span class="math display">\[\begin{alignat}{4}

\pi^\ast(\theta_1) -\pi(\theta_1)

&amp;= &amp;&amp; P(\pmb X \in C^\ast \cap C^c \vert \theta_1) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_1) \\

&amp;\ge \dfrac{1}{k} &amp;&amp; \left\{ P(\pmb X \in C^\ast \cap C^c \vert \theta_0) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_0) \right\} \\

&amp;=


\dfrac{1}{k} &amp;&amp; \left\{

 P(\pmb X \in C^\ast \cap C^c \vert \theta_0) - P(\pmb X \in {C^\ast}^c \cap C \vert \theta_0) \\

+ P(\pmb X \in C^\ast \cap C \vert \theta_0) - P(\pmb X \in C^\ast \cap C \vert \theta_0) 

\right\} \\

&amp;= \dfrac{1}{k} &amp;&amp; \left\{ \pi^\ast (\theta_0) - \pi (\theta_0) \right \} \\

&amp;=0 &amp;&amp;


\end{alignat}\]</span></p>
<p><br></p>
<p>이에 의해 MP test의 정의를 만족한다. 이때 <span class="math inline">\(C\)</span>의 유의수준이 <span class="math inline">\(&lt; \alpha\)</span>인 경우, <span class="math inline">\(\pi^\ast (\theta_1) &gt; \pi (\theta_1)\)</span>이 되므로, <span class="math inline">\(C^\ast\)</span>의 <span class="math inline">\(H_1\)</span>에서의 power인 <span class="math inline">\(\pi^\ast(\theta_1)\)</span>은 유의수준이 <span class="math inline">\(\le \alpha\)</span>인 모든 RR의 power보다 크거나 같음을 알 수 있다.</p>
<hr />
<p><br>
<br>
<br></p>
<div id="overview-1" class="section level3" number="3.8.1">
<h3 number="3.8.1"><span class="header-section-number">3.8.1</span> Overview</h3>
<ul>
<li>Example</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(f(x \vert \theta_0)\)</span></td>
<td align="center">.01</td>
<td align="center">.02</td>
<td align="center">.02</td>
<td align="center">.05</td>
<td align="center">.10</td>
<td align="center">.80</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(f(x \vert \theta_1)\)</span></td>
<td align="center">.03</td>
<td align="center">.05</td>
<td align="center">.15</td>
<td align="center">.10</td>
<td align="center">0</td>
<td align="center">.67</td>
</tr>
<tr class="odd">
<td align="center">$ $</td>
<td align="center">.33</td>
<td align="center">.4</td>
<td align="center">.13</td>
<td align="center">.5</td>
<td align="center"><span class="math inline">\(\infty\)</span></td>
<td align="center">1.19</td>
</tr>
</tbody>
</table>
<p>유의수준이란 기본적으로 <span class="math inline">\(H_0\)</span>이 사실인데 <span class="math inline">\(H_1\)</span>을 선택할 확률. 선택한 RR에 해당하는 <span class="math inline">\(H_0\)</span>와 <span class="math inline">\(H_1\)</span>에서의 density가 각각 있다면, <span class="math inline">\(H_0\)</span>에서의 density의 합이 된다. 기각을 해버렸는데 <span class="math inline">\(H_0\)</span>가 발생해버렸다는 소리니까.</p>
<p>power란 RR에서의 <span class="math inline">\(H_1\)</span>이 발생할 확률.</p>
<p>test 자체가 <span class="math inline">\(H_1\)</span>에 마음을 두고 시작하는 거임. power는 무조건 <span class="math inline">\(H_1\)</span>에만 직결. 실패하면 어쩌지? 무지성으로 <span class="math inline">\(H_1\)</span> 골라버리자. 이랬다가 <span class="math inline">\(H_0\)</span> 발생해버리면? 난 망하는거잖아. 이 망함의 risk를 고정해두자. 이게 <span class="math inline">\(\alpha\)</span>.</p>
<p>power function은 <span class="math inline">\(H_0\)</span>와 <span class="math inline">\(H_1\)</span> 각각에 대해서 존재한다. 이는 각각에서의 pdf이다.</p>
<p>즉, 표본을 통한 $ $의 값이 크면 <span class="math inline">\(H_0\)</span>를 기각할 이유가 없고, 작으면 기각할 근거를 갖는다. 이 값이 얼마나 작아야 기각할 수 있는가는 유의수준에 의해 결정. 이와 같이 rs의 LR을 통해 MP test의 RR을 찾을 수 있다. 이때 RR과 <strong>검정법</strong>은 실제로 동일한 것이므로 혼돈이 없다는 전제 하에 test라는 단어를 주로 사용한다.</p>
<p><span class="math inline">\(LR(\theta_0, \theta_1 ; \pmb x) = \dfrac{L(\theta_0 ; \pmb x)} {L(\theta_1 ; \pmb x)}\)</span> 는 표본의 <span class="math inline">\(\theta_0\)</span>에 대한 지지 (그리고 <span class="math inline">\(\theta_1\)</span>에 대한 반증)의 정도를 표현한다고 볼 수 있다.</p>
<hr />
<p><br>
<br>
<br></p>
</div>
<div id="generalized-lrt" class="section level3" number="3.8.2">
<h3 number="3.8.2"><span class="header-section-number">3.8.2</span> Generalized LRT</h3>
<p>rs <span class="math inline">\(\pmb X_n \overset {iid}{\sim} f(\pmb x ; \theta)\)</span>, <span class="math inline">\(H_0: \theta \in \Omega_0\)</span>, <span class="math inline">\(H_0: \theta \in \Omega_1 (=\Omega - \Omega_0)\)</span>.</p>
<p>$</p>
<p>(x) =  = </p>
<p>$</p>
<hr />
<p><br>
<br>
<br></p>
<p>rs <span class="math inline">\(X_1, \cdots, X_n\)</span>의 pdf가 <span class="math inline">\(f(x ; \theta), \; \; \; \theta \in \Omega\)</span>라고 하자. 확률구간 <span class="math inline">\(\left[ L(\pmb X_n ), U(\pmb X_n ) \right]\)</span>가</p>
<p><span class="math display">\[
P \left[ L(\pmb X_n ) \le \theta \le U(\pmb X_n ) \right] = 1- \alpha
\]</span></p>
<p>를 만족하면 이를 패러미터 <span class="math inline">\(\alpha\)</span>의 <span class="math inline">\(100(1-\alpha) \%\)</span> CI라 부른다.</p>
<hr />
<p><br>
<br>
<br></p>
<p>rs <span class="math inline">\(\pmb X_n\)</span> 의 분포가 pdf <span class="math inline">\(f(x ; \theta), \; \; \; \theta \in \Omega\)</span>를 따른다 하자. 이때 샘플과 패러미터 <span class="math inline">\(\theta\)</span>의 함수인 random quantity <span class="math inline">\(T(\pmb X_n ; \theta)\)</span>의 분포가 패러미터 <span class="math inline">\(\theta\)</span>에 의존하지 않으면 이는 <strong>pivotal quantity</strong>.</p>
<hr />
<p><br>
<br>
<br></p>
<p><span class="math inline">\(H_0: \theta \in \Omega_0, H_1: \theta \in \Omega - \Omega_0\)</span> 에 대한 RR <span class="math inline">\(C^\ast\)</span>가 이하를 만족하면 이는 UMP test. <span class="math inline">\(\pi^\ast\)</span>가 이 test의 power function이라면</p>
<p>$$</p>
<p>{ ^() _0 } =,</p>
<p>$$</p>
<p>모든 다른 power function에 대해 위의 기각역에서의 power 가 최대.</p>
<hr />
<p><br>
<br>
<br></p>
<p>rs $X_n $ 의 joint pdf가 <span class="math inline">\(f(\pmb X_n ; \theta)\)</span>일 때, <span class="math inline">\(LR( \theta_1 ,\theta_2 ; \pmb X_n) = \dfrac{L(\theta_1 ; \pmb X_n)}{L(\theta_1 ; \pmb X_n)}\)</span>가 <span class="math inline">\(\theta_1 &lt; \theta_2\)</span>에 대해 <span class="math inline">\(T(\pmb X_n)\)</span>의 non-dec 혹은 non-inc라면 <span class="math inline">\(L(\theta)\)</span>는 <span class="math inline">\(T(\pmb X_n)\)</span>에 대해 monotone LR를 갖는다.</p>
<hr />
<p><br>
<br>
<br></p>
<ul>
<li>Karlin-Rubin</li>
</ul>
<p><span class="math inline">\(H_0: \theta \le \theta_0, H_1: \theta \ge \theta_0\)</span>. <span class="math inline">\(T\)</span>가 <span class="math inline">\(\theta\)</span>에 대한 SS임을 가정하고, <span class="math inline">\(T\)</span>의 pdf의 family는 MLR을 가짐. then <span class="math inline">\(\forall t_0\)</span>, reject <span class="math inline">\(H_0 \; \; \; \iff \; \; \; T&gt;t_0\)</span> 하는 test는 level <span class="math inline">\(\alpha\)</span>의 UMP test이다. 이때, <span class="math inline">\(\alpha = P_{\theta_0} (T&gt;t_0)\)</span>.</p>
<p><br>
<br>
<br></p>
<p><span class="math inline">\(L(\theta ; \pmb X_n)\)</span>이 <span class="math inline">\(T(\pmb X_n)\)</span>에 대해 non-inc인 MLR. 이때</p>
<p><span class="math inline">\(H_0: \theta \le \theta_0, H_1: \theta \ge \theta_0\)</span>에 대한 level <span class="math inline">\(\alpha\)</span>의 UMP test는 <span class="math inline">\(C = \left\{ \pmb X_n : T(\pmb X_n) \ge k \right\}\)</span> 이며, 상수 <span class="math inline">\(k\)</span>는 <span class="math inline">\(P[T(\pmb X_n) \ge k \vert H_0 ] = \alpha\)</span>에 의해 결정.</p>
<p><span class="math inline">\(H_0: \theta \ge \theta_0, H_1: \theta \le \theta_0\)</span>는 <span class="math inline">\(C = \left\{ \pmb X_n : T(\pmb X_n) \le k \right\}\)</span>.</p>
<p><br>
<br>
<br></p>
<hr />
<p>MLE의 불변성</p>
<p>MLE의 함수는 MLE</p>
<p><br>
<br>
<br></p>
<hr />
<p>서로 독립인 rv X Y의 공통된 성공 확률 p의 MLE. f(X)와 f(Y)를 곱해서 쓴다.</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(\pmb X_n \sim U(\theta - \tfrac{1}{2}, \theta + \tfrac{1}{2})\)</span>. 이때 LF로 MLE 구하는 건 굳이 log 안 거쳐도 가능함. 안 거쳐야 증명이 깔끔한 부분이 있음.</p>
<p><br>
<br>
<br></p>
<hr />
<p>$$</p>
<p>= f(x;)</p>
<p>$$</p>
<p>에 의해</p>
<p>$$</p>
<p>E {</p>
<p> f(X;)</p>
<p>}^2</p>
<ul>
<li></li>
</ul>
<p>E {</p>
<p> f(X;)</p>
<p>}</p>
<p>=0</p>
<p>$$</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(X \sim U(0, \theta)\)</span>일 때, <span class="math inline">\(\theta^2\)</span>의 UE는? <span class="math inline">\(E(X^2) = \dfrac{\theta^2}{3}\)</span>이므로 <span class="math inline">\(T(X)=3X^2\)</span>는 <span class="math inline">\(\theta\)</span>의 UE.</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(\pmb X_n \sim U(-\theta, \theta)\)</span>일 때, <span class="math inline">\(c(X_{(n)}-X_{(1)}\)</span>가 <span class="math inline">\(\theta\)</span>의 UE가 되기 위한 c의 값은?</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(\pmb X_n \sim N(\mu, \sigma^2 )\)</span>. 이때 <span class="math inline">\(cS = c \sqrt{\dfrac{\sum (X_i - \bar X)^2}{n-1}}\)</span>가 <span class="math inline">\(\sigma\)</span>의 UE가 되도록 하는 c의 값은?</p>
<p><span class="math inline">\(Y=(n-1)\dfrac{S^2}{sigma^2}\)</span>이 카이제곱을 따르는 rv임을 이용하여 <span class="math inline">\(E(\sqrt{Y})\)</span>를 구하라.</p>
<p><br>
<br>
<br></p>
<hr />
<p><span class="math inline">\(Var \left( \sum a_i \hat \theta_i \right)\)</span>는 <span class="math inline">\(a_i = \dfrac{\tfrac{1}{\sigma^2_i}}{\sum \tfrac{1}{\sigma^2_i}}\)</span>일 때 최소화.</p>
<p><br>
<br>
<br></p>
<hr />
<p>통계량 <span class="math inline">\(S(X)\)</span>의 분포가 패러미터 <span class="math inline">\(\theta\)</span>에 의존하지 않는다면 이는 <strong>ancillary statistic</strong>.</p>
<p><br>
<br>
<br></p>
<hr />
<p>최소 SS가 존재한다면, 모든 CSS는 MSS이다.</p>
<p><br>
<br>
<br></p>
<hr />
</div>
</div>
<div id="개념" class="section level2" number="3.9">
<h2 number="3.9"><span class="header-section-number">3.9</span> 개념</h2>
<p>충분통계량</p>
<p>분해정리</p>
<p>Minimum 충분통계량</p>
<p>Completeness 6.3.</p>
<p>ancillary 통계량 (분포가 모수에 의존 안함)</p>
<p>바수정리 complete고 minimum 충분통계량이면 모든 ancillary랑 독립</p>
<p>지수족 만족하면 뭐의 묶음은 complete 충분통계량 (추가조건, 6.6</p>
<p>minimum 충분통계량 존재하면 모든 Complete 통계량은 동시에 minimum 충분통계량</p>
<hr />
<p>모먼트, MLE (2차까지 확인)</p>
<p>MLE 불변성</p>
<p>MSE를 통해 통계량 성능 비교 가능함
bias</p>
<p>MSE = precision + accuracy</p>
<p>UMVUE 7.5</p>
<p>크래머-라오 부등식 : 최저 분산 뽑아내는 수단</p>
<p>피셔 정보</p>
<p>2차원 피셔 정보</p>
<p>라오-블랙웰 : uniform better UE 뽑아내는 수단</p>
<p>unique best UE</p>
<p>best UE는 오직 하나뿐</p>
<p>(레만쉐페) CSS에 기반한 UE는 오직 유일함</p>
<p>W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7</p>
<p>consistent (점근성)</p>
<p>충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일</p>
<p>test으 unbaised 8.8</p>
<p>네이만 피어슨</p>
<p>카를린 루빈 8.3</p>
<p>빅 샘플 추정자들과 8.5</p>
<p>스코어 스탯 8.12</p>
<p>왈드 테스트 8.13</p>
<p>1-a confidence iterval = acceptance region of level 알파 test</p>
<p>뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨</p>
<p>pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT.</p>
<p>MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량.</p>
<p>cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2.</p>
<p>감마와 포아송간 변환</p>
<p>유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5.</p>
<p>dog-tired</p>
<p>Bubble Plot
3D Scatter Plot
Star Plot
Chernoff Faces
Parallel Coordinate Plot</p>
<p>1.Q-Q Plot
Shapiro-Wilks Test
Kolmogorov-Smirnov Test
Skewness Test ( )
Kurtosis Test: ( )
Lin and Mudholkar</p>
<p>Scatter Plot
Squared Generalized Distances
Chi-Square Plot (Gamma Plot)</p>
<p>nqplot
contour plot
cqplot</p>
<p>(Python – assumption check)</p>
<!--chapter:end:211111_NP_lemma.rmd-->
</div>
</div>
<div id="mcmc" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> MCMC</h1>
<div id="importance-sampling" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Importance Sampling</h2>
<div id="independent-monte-carlo" class="section level3" number="4.1.1">
<h3 number="4.1.1"><span class="header-section-number">4.1.1</span> Independent Monte Carlo</h3>
<p>타겟분포 <span class="math inline">\(f\)</span>로부터의 시뮬레이션의 랜덤 draws $ X_1 , , X_n $.</p>
<p>적분 범위에 걸쳐 (over) support가 펼쳐져 있는 분포로부터 무작위로 포인트를 추출해서 해당 포인트들의 적분값을 종합하여 만들어내는, 적분값에 대한 통계적 측정.</p>
<p>let <span class="math inline">\(f\)</span>는 <span class="math inline">\(X\)</span>의 density, <span class="math inline">\(\mu = E_f \left[ h(X) \right]\)</span>. 이때</p>
<p>$</p>
<p><em>{MC} =  </em>{i=1}^n h(X_i ) h(x)f(X) dx =; ; ; ; ;  n </p>
<p>$</p>
<p>let $ v(x) = { h(x)-}^2$, $ E_f { ^2 } &lt; $. Then, sampling <span class="math inline">\(Var\)</span> of $ _{MC} $ is $ = E {  }. This can be written as</p>
<p>$</p>
<p> (<em>{MC}) =  {n-1} </em>{i=1}^n ^2</p>
<p>$</p>
<p>when ^2 exists, by CLT, <span class="math inline">\(\hat \mu_MC \overset {\cdot} {\sim} N\)</span>, for large <span class="math inline">\(n\)</span>.</p>
<p>수치해석은 다차원 문제에는 적용하기 어렵다. 하지만, MC integration은 <span class="math inline">\(p\)</span>차원의 <span class="math inline">\(f\)</span>의 support에 걸쳐서 <span class="math inline">\(f\)</span>에서 랜덤하게 샘플링 한 후 이 영역에 대한 그 어떤 체계적인 탐색도 시도하지 않는다. 샘플링 후에는 그냥 냅둬버림. 따라서 MC는 고차원에서도 덜 피곤함.</p>
<p><br>
<br>
<br></p>
<div id="inverse-cdf" class="section level5" number="4.1.1.0.1">
<h5 number="4.1.1.0.1"><span class="header-section-number">4.1.1.0.1</span> Inverse-cdf</h5>
<p><span class="math inline">\(\forall F, X=F^{-1}(U) = \text{inf}\{ x:F(x) \ge U \}\)</span>는 <span class="math inline">\(F\)</span>와 같은 cdf를 가짐. 이때 <span class="math inline">\(F\)</span>는 continuous distribution function, <span class="math inline">\(U \sim U(0, 1)\)</span>.</p>
<p>이때, linear interpolation을 활용해, <span class="math inline">\(F^{-1}\)</span> 계산 없이 <span class="math inline">\(F\)</span>만으로 난수 샘플링 가능.
1. <span class="math inline">\(f\)</span>의 supoprt를 span하는 grid <span class="math inline">\(x_1 , \cdots, x_m\)</span> 정의
2. 각 grid point에서 <span class="math inline">\(u_i = F(x_i)\)</span> 계산하거나 approximate
3. 가장 가까운 grid points <span class="math inline">\(u_i , u_j\)</span>에 대해, <span class="math inline">\(u_i \le U \le u_j\)</span>에 해당하는 영역을 이하에 따라 linearly interpotate. <span class="math inline">\(X = \dfrac{u_j-U}{u_j - u_i}x_i + \dfrac{U-u_i}{u_j - u_i}x_j\)</span>. 이때 <span class="math inline">\(U \sim U(0, 1)\)</span>.
- illustration of Rejection Sampling for a target distribution <span class="math inline">\(f\)</span> using a Rejection Sampling envelope <span class="math inline">\(e\)</span>.</p>
<p><br>
<br>
<br></p>
</div>
<div id="rejection-sampling" class="section level5" number="4.1.1.0.2">
<h5 number="4.1.1.0.2"><span class="header-section-number">4.1.1.0.2</span> Rejection Sampling</h5>
<p><span class="math inline">\(f(x)\)</span>의 상수배 (proportionality constant) 만이라도 계산될 수 있다면, 정확한 타겟분포 <span class="math inline">\(f(x)\)</span>로부터의 샘플링을 위하여 <strong>Rejection Sampling</strong> 사용 가능. 이는 더 간단한 후보 (candidate) 분포로부터 샘플링한 후 이렇게 샘플링한 것 중 일부를 확률에 기반하여 랜덤하게 쳐냄으로써 샘플링 확률을 보정하는 것.
* <span class="math inline">\(g\)</span>는 우리가 분포의 형태를 정확히 알고 있고 <span class="math inline">\(g(x)\)</span> 계산도 쉬운 덴시티라고 정의.
* <span class="math inline">\(e\)</span>는 <strong>envelope</strong>, 이하의 성질을 갖는다. <span class="math inline">\(\forall x \; \; \; \text{s.t. for a given constant } \alpha \le 1, f(x)&gt;0 \; \; \; : \; \; \; e(x) = \dfrac {g(x)}{\alpha} \ge f(x)\)</span>.</p>
<p>방법은 이하와 같다.
1. <span class="math inline">\(Y \sim g\)</span>에서 샘플링.
2. <span class="math inline">\(U&gt;\dfrac {f(y)}{e(Y)}\)</span>일 경우 <span class="math inline">\(Y\)</span>를 기각. 기각된다면 <span class="math inline">\(Y\)</span>값을 target random sample의 요소로 기록하지 않음. step 1으로.
3. <span class="math inline">\(U \le \dfrac {f(y)}{e(Y)}\)</span>일 경우 set <span class="math inline">\(X=Y\)</span>로 한 후 <span class="math inline">\(X\)</span>를 타겟 랜덤샘플의 요소로 넣음. step 1으로.</p>
<p>여기서 <span class="math inline">\(\alpha\)</span>는 채택될 후보들의 expected 비율로 해석될 수 있다.</p>
<p>good RS envelope의 요건:
* 간단하게 제작되거나, 모든 값에서 타겟분포를 넘김이 간단하게 확인되어야 한다.
* 샘플링이 쉬어야 한다.
* rejected draws가 적어야 한다.</p>
<blockquote>
<p>Example: Normal From Double Exponential, Sampling a Bayesian Posterior</p>
</blockquote>
<p><br>
<br>
<br></p>
</div>
<div id="variants-of-the-rs-squeeze-rs" class="section level5" number="4.1.1.0.3">
<h5 number="4.1.1.0.3"><span class="header-section-number">4.1.1.0.3</span> Variants of the RS: Squeeze RS</h5>
<p><span class="math inline">\(f\)</span> 계산해내는 게 비용이 많이 들고 RS가 매력적인 상황이면 <strong>Squeeze RS</strong>에 의해 더 빠른 연산속도를 획득할 수 있음. nonnegative squeezing function <span class="math inline">\(s(x)\)</span>를 정의하고 이를 사용함. 이때 <span class="math inline">\(s\)</span>가 적합한 squeezing function이기 위해선 <span class="math inline">\(f\)</span>의 모든 support에서 <span class="math inline">\(s&lt;f\)</span>.
* illustration of squeezed Rs for a target distribution <span class="math inline">\(f\)</span>, using envelope <span class="math inline">\(e\)</span> and squeezing function <span class="math inline">\(s\)</span>. Keep First and Keep Later correspond to steps 3 and 4 of the algorithm, respectively.</p>
<p>proceeds:
1. <span class="math inline">\(Y \sim g\)</span>에서 샘플링.
2. if <span class="math inline">\(U \le \dfrac {s(Y)}{e(Y)}\)</span>, keep <span class="math inline">\(Y\)</span>.
3. if not, whether if <span class="math inline">\(U \le \dfrac {f(Y)}{e(Y)}\)</span>, keep <span class="math inline">\(Y\)</span>.
4. both are not, reject <span class="math inline">\(Y\)</span>.</p>
<p>2번에선 <span class="math inline">\(s\)</span>, 3번에선 <span class="math inline">\(f\)</span>임에 주목. 샘플링 쉬운 <span class="math inline">\(s\)</span>에서 먼저 비교해서 우선권 시드 주고, 그 후에 <span class="math inline">\(f\)</span>로 본선 해보는거.</p>
<blockquote>
<p>Example: Lower Bound for Normal Generation</p>
</blockquote>
<p><br>
<br>
<br></p>
<div id="variants-of-the-rs-adaptive-rs" class="section level6" number="4.1.1.0.3.1">
<h6 number="4.1.1.0.3.1"><span class="header-section-number">4.1.1.0.3.1</span> Variants of the RS: Adaptive RS</h6>
<p>적절한 envelope <span class="math inline">\(e\)</span>를 어떻게 만들 것인가? squeezed RS를 위해, support의 connected region에 대해 continuous, differentiable, log-concave인 덴시티를 만드는 자동화된 envelope 생산 전략에 해당함. 패키지로 실행.
* envelopes <span class="math inline">\(e\)</span> and squeezing function <span class="math inline">\(s\)</span> for adaptive RS. The target density <span class="math inline">\(f\)</span> is smooth, nearly bell-shaped curve. The first method discussed in the text, using the derivative of <span class="math inline">\(l\)</span>, produces the envelope <span class="math inline">\(e\)</span> shown as upper boundary of the lighter shaded region. This correponds to Equation (6.9) and Figure 6.4. Later in the text, a derivative-free method is presented. That envelope is the upper bound of the darker shaed region and corresponds to (6.11) and Figure 6.6. The squeezing function <span class="math inline">\(s\)</span> for both approaches is given by the dotted curve.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="importance-sampling-1" class="section level5" number="4.1.1.0.4">
<h5 number="4.1.1.0.4"><span class="header-section-number">4.1.1.0.4</span> Importance Sampling</h5>
<p><strong>Importance Sampling</strong> 접근법은 <span class="math inline">\(E\{h(x)\}\)</span> w.r.t. its density는 이하처럼 alternative form으로 쓰일 수 있다는 것에 기반한다. 이때 <span class="math inline">\(g\)</span>는 envelope의 importance sampling function.</p>
<p>$
<span class="math display">\[\begin{align*}



\mu &amp;= \int h(x)f(x)dx &amp;= \int \left( h(x) \dfrac {f(x)}{g(x)} \right)g(x)dx \tag{1} \\

\\
\\

&amp;= \dfrac {\int h(x)f(x) dx}{\int f(x) dx} &amp;= \dfrac {\int \left( h(x) \dfrac {f(x)}{g(x)} \right) g(x) dx}{\int \left( \dfrac {f(x)}{g(x)} \right) g(x) dx} \tag{2}

\end{align*}\]</span></p>
<p>$</p>
<ul>
<li>(1)은 <span class="math inline">\(E \{ h(X) \}\)</span>를 측정하기 위한 MC 접근법이 이하임을 제시한다. <span class="math inline">\(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} g\)</span>처럼 <span class="math inline">\(g\)</span>에서 랜덤샘플을 뽑고, 이의 (이를 활용한) estimator는 이하. 이때 <span class="math inline">\(w^{\ast} (X_i)\)</span>는 <strong>unstandardized weights</strong>, i.e., <strong>importance ratios</strong>.</li>
</ul>
<p>$</p>
<p><em>{IS}^{} =  </em>{i=1}^n h(X_i) w^{}(X_i) =  _{i=1}^n h(X_i) </p>
<p>$</p>
<p>(2)는 <span class="math inline">\(g\)</span>에서 <span class="math inline">\(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} g\)</span>의 랜덤샘플을 뽑고 이하를 계산. 이때 <span class="math inline">\(w(X_i)\)</span>는 standardized weight. <br>이 (2)는 <span class="math inline">\(f\)</span>의 상수배 (proportionality constant) 까지만 알 수 있더라도 적용할 수 있다는 점에서 매우 중요함. <span class="math inline">\(f\)</span>의 상수배까지만 알 수 있는 상황은 베이지안 분석의 post에서 빈번하게 발생함. <strong><em>Both estimators converge by the same argument applied to the simple Monte Carlo estimator.</em></strong></p>
<p>$</p>
<p><em>{IS} = </em>{i=1}^n h(X_i) w(X_i) = _{i=1}^n h(X_i) </p>
<p>$</p>
<p>Proceeds:
1. Sample <span class="math inline">\(X_j \sim g(\cdot)\)</span>.
2. Calculate <span class="math inline">\(w(X_j) = \dfrac {f(X_j)}{g(X_j)}\)</span>
3. 지정 샘플 갯수까지 반복</p>
<p>then,</p>
<p>$
<span class="math display">\[\begin{align*}

E\{\hat h(x)\} &amp;= \dfrac {1}{n} \sum_{j=1}^n w(X_j)h(X_j) \\

\hat \sigma^2 &amp;= \dfrac {1}{n-1}  \sum_{j=1}^n \left\{ h(X_j) - E\left[ \hat h(x) \right] \right\}^2

\end{align*}\]</span>
$</p>
<p>과도한 변동성을 회피하기 위해, <span class="math inline">\(\dfrac {f(x)} {g(x)}\)</span>는 bounded여야 하며 또한 <span class="math inline">\(g\)</span>는 <span class="math inline">\(f\)</span>보다 heavier tail을 가져야 한다. 이것이 만족되지 않는다면 standardized importance weight는 제법 커질 수 있음.</p>
<p>함수 <span class="math inline">\(g\)</span>는, <span class="math inline">\(h(x)\)</span>가 매우매우 작을 경우에만 <span class="math inline">\(\dfrac {f(x)} {g(x)}\)</span>가 커지게 만드는 녀석으로 잘 골라야 한다. 가령 <span class="math inline">\(h\)</span>가 아주 드문 상황에서만 1을 반환하는 indicator function이라면, 우리는 <span class="math inline">\(g\)</span>로 하여금 샘플링의 편의성을 위해 해당 사건을 좀 더 빈번하게 발생시키도록 하는 녀석을 고를 수도 있을 것이다. 이를 택한다면 우리는 우리의 관심사가 아닌 사건, 가령 <span class="math inline">\(h(x)=0\)</span>에 대한 적절한 샘플링 power을 어느정도 희생하게 된다. <strong><em>이는 낮은 확률에 해당하는 case의 측정에 특히 잘 들어맞는 방법론이다.</em></strong></p>
<p>$_{IS}^$ 자체는 unbiased지만, 이를 importance weight로 standardize 하는 과정에서 <span class="math inline">\(\hat \mu_{IS}\)</span>에 다소 bias가 생겨버린다.</p>
<p>standardized weight를 쓰는 건 <span class="math inline">\(w^\ast(X)\)</span>와 <span class="math inline">\(h(X)w^\ast(X)\)</span>가 서로 강하게 상관관계가 있는 상황에서 더욱 우수한 estimator를 반환한다.</p>
<p>standardized weight는 <span class="math inline">\(f\)</span>의 비례상수를 요구하지 않는다. (우리가 갖고 있는 덴시티가 <span class="math inline">\(f\)</span>의 얼마만큼의 상수배인지를 알지 않아도 된다)</p>
<p>IS 방법론의 매력은 시뮬레이션의 reusability이다. 같은 sample points들과 weight들이 다양한 다른 quantity의 MC 적분 estimates를 구하는데 사용될 수 있다. (<strong>컴퓨팅 파워가 증가한 오늘날에 와서는 유의미한 장점은 아니다.</strong>)</p>
<blockquote>
<p>Example: Small Tail Probabilities</p>
</blockquote>
<p><br>
<br>
<br></p>
</div>
<div id="antithetic-sampling" class="section level5" number="4.1.1.0.5">
<h5 number="4.1.1.0.5"><span class="header-section-number">4.1.1.0.5</span> Antithetic Sampling</h5>
<p>let <span class="math inline">\(\hat \mu_1, \hat \mu_2\)</span>. 이 둘은 identically distributed, UE, and <span class="math inline">\(Corr(\hat \mu_1, \hat \mu_2)&lt;0\)</span>.</p>
<p>이 estimator 둘을 평균한 <span class="math inline">\(\hat \mu_{AS} = \dfrac{\hat \mu_1 + \hat \mu_2}{2}\)</span>는 각 estimator들의 샘플을 2배 한 것보다 우월함. <strong><span class="math inline">\(Corr(\hat \mu_1, \hat \mu_2)&lt;0\)</span>이기 때문에 성립한다는 것을 유의.</strong></p>
<p>$</p>
<p>Var(_{AS}) =  ( Var(_1) + Var(_2) ) +  Cov(_1, _2) =   {n} (1+)</p>
<p>$</p>
<p><span class="math inline">\(\hat \mu_1 (X)\)</span>를 MC integral estimate로 잡는다면, 이는</p>
<p>$</p>
<p><em>1 (X) =  </em>{i=1}^n h_1 { F_1^{-1}(U_{i1}), , F_m^{-1}(U_{im}) }</p>
<p>$</p>
<p>이때 <span class="math inline">\(h_1\)</span>은 그의 <strong>arguments</strong>에 monotone이며, <span class="math inline">\(F_j\)</span>는 각 <span class="math inline">\(X_{ij}, \; j=1,\cdots,m\)</span>의 cdf이며 <span class="math inline">\(U_{ij} \sim U(0,1)\)</span>. 이에 의해 <span class="math inline">\(1-U_{ij} \sim U(0,1)\)</span>이기도 하며, 이에 의해 이하도 성립.</p>
<p>$</p>
<p><em>2 (X) =  </em>{i=1}^n h_1 { F_1^{-1}(1-U_{i1}), , F_m^{-1}(1-U_{im}) }</p>
<p>$</p>
<p>이는 <span class="math inline">\(\mu\)</span>의 2번째 estimator이며, 이는 <span class="math inline">\(\hat \mu_1 (X)\)</span>와 같은 분포를 가짐.</p>
<p>따라서 <span class="math inline">\(\hat \mu_{AS} = \dfrac{\hat \mu_1 + \hat \mu_2}{2}\)</span>는 <span class="math inline">\(\hat \mu_1\)</span>의 샘플을 2배 한 것(2n)보다 더 작은 <span class="math inline">\(Var\)</span>을 가지며, 따라서 더 우월함.</p>
<p><br>
<br>
<br></p>
</div>
<div id="control-variates" class="section level5" number="4.1.1.0.6">
<h5 number="4.1.1.0.6"><span class="header-section-number">4.1.1.0.6</span> Control Variates</h5>
<p>우리는 알지 못하는 quantity <span class="math inline">\(\mu = E \{ h(X) \}\)</span>를 알고자 하며, 이에 연관된 quantity <span class="math inline">\(\theta = E[c(Y)]\)</span>에 대해서는 알고 있음. 후자는 수치적으로 획득 가능. <span class="math inline">\((X_1 , Y_1 ) ,\cdots, (X_n , Y_n )\)</span>은 simulation outcom에서 독립적으로 관측된 pairs of rv.</p>
<p>이때 MC estimator는 이하와 같다. <span class="math inline">\(\hat \mu_{MC}, \hat \theta_{MC}\)</span> 간에 상호연관이 있음을 유의.</p>
<p>$
<span class="math display">\[\begin{align*}

\hat \mu_{MC} = \dfrac {1}{n} \sum_{i=1}^n h(X_i), &amp; \; \; \; \; \; \; \; \; \; \; \hat \theta_{MC} = \dfrac {1}{n} \sum_{i=1}^n c(Y_i)

\end{align*}\]</span>
$</p>
<p>즉 우리는 여기서</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(\mu = E[h(x)]\)</span></th>
<th align="center"><span class="math inline">\(\theta = E[c(Y)]\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">MC (ex. <span class="math inline">\(\theta_{MC}\)</span>)</td>
<td align="center">able</td>
<td align="center">able</td>
</tr>
<tr class="even">
<td align="center">itself</td>
<td align="center"></td>
<td align="center">able</td>
</tr>
</tbody>
</table>
<p>즉 <span class="math inline">\(\theta\)</span>와 <span class="math inline">\(\theta_{MC}\)</span> 간의 차이를 알아내고, 이 차이를 적당히 스케일링해서 <span class="math inline">\(\mu\)</span>에 적용한다는 것이 기본 메커니즘.</p>
<p>여기서 Control Variate Estimator는 <span class="math inline">\(\hat \mu_{CV} = \hat \mu_{MC} + \lambda(\hat \theta_{MC} - \theta)\)</span>. <span class="math inline">\(\lambda\)</span>는 사용자에 의해 정해지는 임의의 parameter. 이에 의해</p>
<p>$</p>
<p>Var(<em>{CV} ) = Var (</em>{MC}) + ^2 Var (<em>{MC}) + 2 Cov(</em>{MC}, _{MC})</p>
<p>$</p>
<p>이며 이가 최소가 된 경우의 분산은 아래와 같으며, 이를 최소로 하는 <span class="math inline">\(\lambda\)</span>는 아래와 같다.</p>
<p>when <span class="math inline">\(\lambda = - \dfrac {Cov(\hat \mu_{MC}, \hat \theta_{MC})}{Var(\hat \theta_{MC})}\)</span>, <span class="math inline">\(\min_\lambda \left( Var(\hat \mu_{CV} ) \right) = Var(\hat \mu_{MC}) - \dfrac{\left[ Cov(\hat \mu_{MC}, \hat \theta_{MC}) \right]^2} {Var(\hat \theta_{MC})}\)</span>.</p>
<p><br>
<br>
<br></p>
</div>
<div id="rao-blackwellizaiton" class="section level5" number="4.1.1.0.7">
<h5 number="4.1.1.0.7"><span class="header-section-number">4.1.1.0.7</span> Rao-Blackwellizaiton</h5>
<p>rs <span class="math inline">\(X_1 , \cdots, X_n \overset {\text{iid}}{\sim} f\)</span>를 활용해 <span class="math inline">\(\mu = E \{ h(X) \}\)</span>를 estimation.</p>
<p>각각의 <span class="math inline">\(X_i = (X_{i1}, X_{i2})\)</span>라고 가정하고, 조건부 기댓값 <span class="math inline">\(E\{ h(X_i) \rvert x_{i2} \}\)</span>가 수치적으로 풀릴 수 있다고 가정하자.</p>
<p>$ E{h(X_i)} = E_{X_{i2}}{ E }$라는 사실을 활용하여 $ _{MC} $ 에 대한 다른 estimator를 구축해보자.</p>
<p>Rao-Blackwellized estimator <span class="math inline">\(\hat \mu_{RB} = \dfrac 1 n \sum_{i=1}^n E \{ h(X_i) \rvert X_{i2} \}\)</span>. 이는 ordinary MC estimator <span class="math inline">\(\hat \mu_{MC}\)</span>와 같은 mean을 갖는다. Note that</p>
<p>$</p>
<p>Var(<em>{MC}) =  {n^2} Var { E} +  {n^2} E { Var } Var (</em>{RB})</p>
<p>$</p>
<p>따라서 Mean Squared Error, MSE 관점에서 <span class="math inline">\(\hat \mu_{RB}\)</span>는 <span class="math inline">\(\hat \mu_{MC}\)</span> 보다 우수하다.</p>
<p><br>
<br>
<br></p>
</div>
<div id="sampling-importance-resampling" class="section level5" number="4.1.1.0.8">
<h5 number="4.1.1.0.8"><span class="header-section-number">4.1.1.0.8</span> Sampling Importance Resampling</h5>
<p>SIR 알고리즘은 몇 타겟분포에서 실현값을 모사적으로 시뮬레이트한다. SIR은 Importance Sampling의 개념에 기초하고 있다. IS에서 우리는 IS function <span class="math inline">\(g\)</span>에서 샘플링하는 식으로 진행했었다. 샘플의 각 point는 샘플링 확률을 보정 (correct)하기 위해 weighted 되었었으며, 이에 의해 weighted 샘플들은 타겟분포 <span class="math inline">\(f\)</span>와 연결지어질 수 있었다. 타겟분포 <span class="math inline">\(f\)</span>를 획득하기 위해 샘플링 확률 보정 목적으로 가해지는 weight는 <strong>standardized importance weight</strong> <span class="math inline">\(w(x_i)\)</span>로 불렸으며,</p>
<p>$
w(x_i) = 이 만으로 난수 샘플링 가능.

{}
{_{i=1}^m }</p>
<p>$</p>
<p>이렇게 획득했던 standardized weight는 이후에 출신 density가 아닌 다른 타겟 <span class="math inline">\(f\)</span>에서 다른 샘플을 생산할 때 재사용되는 것이 가능하다.</p>
<p>for a collection of values, <span class="math inline">\(x_i , \cdots, x_m \overset {\text{iid}} {\sim} g\)</span>, 이때 <span class="math inline">\(g\)</span>는 Importance Sampling Function.</p>
<p>proceeds:
1. sample candidates <span class="math inline">\(Y_1 , \cdots, Y_m \overset {\text{iid}} {\sim}\)</span> 타겟분포 <span class="math inline">\(g\)</span>. <strong><span class="math inline">\(g\)</span>가 타겟분포라고?????? 수업발언</strong>
2. caculate the standardized importance weights, <span class="math inline">\(w(Y_1) , \cdots, w(Y_m)\)</span>.
3. resample <span class="math inline">\(X_1 , \cdots, X_m\)</span> from <span class="math inline">\(Y_1 , \cdots, Y_m\)</span> with probabilities, <span class="math inline">\(w(Y_1) , \cdots, w(Y_m)\)</span>.</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">for <span class="math inline">\(n\)</span> samples</th>
<th align="center">Rejection Sampling</th>
<th align="center">SIR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">perfect</td>
<td align="center">not perfect</td>
</tr>
<tr class="even">
<td align="center">distribution of generation draw is</td>
<td align="center">exactly <span class="math inline">\(f\)</span></td>
<td align="center">random degree of approxiamtion to <span class="math inline">\(f\)</span></td>
</tr>
<tr class="odd">
<td align="center">required number of draws</td>
<td align="center">random</td>
<td align="center">determined</td>
</tr>
</tbody>
</table>
<p>It is important to consider the relative sizes of the initial sample and the resample. In principle, we require <span class="math inline">\(\dfrac n m \rightarrow 0\)</span> for distributional convergence of the sample.</p>
<p>1만개를 생산해놓고 이 안에서 추가적으로 공정을 진행해서 목표했던 랜덤한 샘플을 뽑아내는 것이 SIR. 그러나 전 영역에서 체크하는것과 생산해놓은 1만개에 randomness를 첨가하여 만들어낸 샘플은 퍼포먼스 차이가 당연히 존재. 그러나 전 영역 대비 1만개라는 한정된 영역에서 추가공정을 진행하므로 cost down.</p>
<p>기존에 만들어두었던 weight를 재사용하므로 시뮬레이션을 다시 할 필요가 없음. 시간 down.</p>
<div class="line-block">Rejection Sampling | envelope <span class="math inline">\(e\)</span>를 만들고 이 안에서 뽑음. 이는 continuous point. | perfect, exact |<br />
SIR | n개의 candidate point를 이미 선택해놓고 이 안에서 뽑음. discrete. | approximate sampling |</div>
<p>candidate <span class="math inline">\(m\)</span>개, 샘플 <span class="math inline">\(n\)</span>개. 당연하지만 candidate <span class="math inline">\(m\)</span>의 숫자가 커질수록 효율성 (approximate 성능) 은 높아짐. The maximum tolerable ratio <span class="math inline">\(\dfrac n m\)</span> depends on the quality of the envelope, bsed on <span class="math inline">\(m\)</span> candidate samples and their weights. 이상적으로는 <span class="math inline">\(m\)</span>이 무한해지면 SIR 조차도 exact sampling일 수 있다.</p>
<p>The SIR algorithm can be sensitive to the choice of <span class="math inline">\(g\)</span>.
* The support of <span class="math inline">\(g\)</span> must include the entire support of <span class="math inline">\(f\)</span>, for a reweighted sample from <span class="math inline">\(g\)</span> is to approximate a sample from <span class="math inline">\(f\)</span>.
* <span class="math inline">\(g\)</span> should have heavier tails than <span class="math inline">\(f\)</span>, or more generally <span class="math inline">\(g\)</span> should be chosen to ensure that $ $ never grows to o large.
* If <span class="math inline">\(g(x)\)</span> is nearly zero anywhere where <span class="math inline">\(g(x)\)</span> is positive, then a draw from this region will happen only extremely rarely, but when it does it will receive a huge weight.
* weight-degeneracy problem</p>
<blockquote>
<p>Example: Slash Distribution
Example: Sampling a Bayesian Posterior</p>
</blockquote>
<p><br>
<br>
<br></p>
</div>
<div id="sequential-monte-carlo" class="section level5" number="4.1.1.0.9">
<h5 number="4.1.1.0.9"><span class="header-section-number">4.1.1.0.9</span> Sequential Monte Carlo</h5>
<p>When the target density <span class="math inline">\(f\)</span> becomes high dimensional, SIR is increasingly inefficient and can be difficult to implement. Specifying a very good high-dimensional envelope that closely approximates the target with sufficiently heavy tails but little waste can be challenging.</p>
<p>Sequential Monte Carlo methods address the problem by splitting the high-dimensional task into a sequence of simpler steps, each of which updates the previous one.</p>
<p><span class="math inline">\(\pmb X_{1:t} = (X_1 , \cdots, X_t )\)</span> represents a discrete time stochastic process with <span class="math inline">\(X_t\)</span> being the observation at time <span class="math inline">\(t\)</span>.</p>
<p><span class="math inline">\(\pmb X_{1:t}\)</span> represents the entire history of the sequence.</p>
<p>Suppose the density of <span class="math inline">\(\pmb X_{1:t}\)</span> is <span class="math inline">\(f_t\)</span> and we wish to estimate the expected value of <span class="math inline">\(h(\)</span>X_{1:t}<span class="math inline">\()\)</span> w.r.t. <span class="math inline">\(f_t\)</span>.</p>
<p>A direct application of the SIR approach would be to draw a sample <span class="math inline">\(\pmb x_{1:t}\)</span> sequences from an envelope gt and then calculate the importance weighted average of this sample of <span class="math inline">\(h(\pmb X_{1:t})\)</span> values.</p>
<p>This SIR approach overlooks a key aspect of the problem.
* As t increases, <span class="math inline">\(\pmb X_{1:t}\)</span> and the expected value of <span class="math inline">\(h(\pmb x_{1:t})\)</span> evlove.
* At time <span class="math inline">\(t\)</span> it would be better to update previous inferences than to act as if we had no previous information. <strong>Inefficient !!!</strong></p>
<p>Need to develop a strategy that will simulate <span class="math inline">\(X_t\)</span> from previously simulated <span class="math inline">\(\pmb X_{1:t-1}\)</span> and adjust the previous importance weights in order to estimate the expected value of <span class="math inline">\(h(\pmb X_{1:t})\)</span> . <strong>Sequential Importance Sampling</strong>.</p>
<p><br>
<br>
<br></p>
</div>
<div id="sis-for-markov-process" class="section level5" number="4.1.1.0.10">
<h5 number="4.1.1.0.10"><span class="header-section-number">4.1.1.0.10</span> SIS for Markov Process</h5>
<p>Simplify assumption that <span class="math inline">\(\pmb X_{1:t}\)</span> is a Markov process.</p>
<p>The target density <span class="math inline">\(f_t (\pmb x_{1:t})\)</span> may be expressed as</p>
<p>$
<span class="math display">\[\begin{align*}

f_t (\pmb x_{1:t}) &amp;= f_1 (x_1) &amp;\ast f_2 (x_2 \rvert \pmb x_{1:1}) &amp;\ast f_3 (x_3 \rvert \pmb x_{1:2}) &amp;\cdots &amp;\ast f_t (x_t \rvert \pmb x_{1:t-1}) \\


&amp;= f_1 (x_1) &amp;\ast f_2 (x_2 \rvert x_1) &amp;\ast f_3 (x_3 \rvert x_2) &amp;\cdots &amp;\ast f_t (x_t \rvert x_{t-1})

\end{align*}\]</span>
$</p>
<p>Suppose that we adopt the same Markov form for the envelope, namely</p>
<p>$</p>
<p>g_t (x_{1:t})= g_1 (x_1) g_2 (x_2 x_1) g_3 (x_3 x_2) g_t (x_t x_{t-1})</p>
<p>$</p>
<p>Sample from <span class="math inline">\(g_t (\pmb x_{1:t})\)</span> and reweight each <span class="math inline">\(\pmb x_{1:t}\)</span> value by <span class="math inline">\(w_t = \dfrac {f_t (\pmb x_{1:t})}{g_t (\pmb x_{1:t})}\)</span>.</p>
<p>The weight at time <span class="math inline">\(t\)</span> is <span class="math inline">\(w_t = \dfrac {f_1 (x_1) \ast f_2 (x_2 \rvert x_1) \ast \cdots} {g_1 (x_1) \ast g_2 (x_2 \rvert x_1) \ast \cdots}\)</span>.</p>
<p>A sample of <span class="math inline">\(n\)</span> such points and their weights can be used to approximate <span class="math inline">\(f_t (\pmb x_{1:t} )\)</span> and calculate the expected value of <span class="math inline">\(h(\pmb x_{1:t} )\)</span>.</p>
<p>The sequential Monte Carlo algorithm for generating one sample is
1. Sample $X_1 g_1 $. Let <span class="math inline">\(w_1 = u_1 = \dfrac {f_1(x_1)}{g_1(x_1)}\)</span>. Set <span class="math inline">\(t = 2\)</span>.
2. Sample <span class="math inline">\(X_t \rvert x_{t-1} \sim g_t (x_t \rvert x_{t-1})\)</span>.
3. Append <span class="math inline">\(x_t\)</span> to <span class="math inline">\(\pmb x_{1:t-1}\)</span>, obtaining <span class="math inline">\(\pmb x_{1:t}\)</span>.
4. <span class="math inline">\(u_t = \dfrac{f_t (x_t \rvert x_{t-1})}{g_t (x_t \rvert x_{t-1})}\)</span>.
5. let <span class="math inline">\(w_t = w_{t-1}u_t\)</span>. <span class="math inline">\(w_t\)</span> is the importance weight for <span class="math inline">\(\pmb x_{1:t}\)</span> .
6. Increment t and return to step 2.</p>
<p>The weighted average <span class="math inline">\(\sum_{i=1}^n \left( \dfrac {w_t^{(i)}}{\sum_{i=1}^n w_t^{(i)}} \right) \ast h(\pmb X_{1:t}^{(i)})\)</span> serves as the estimate of <span class="math inline">\(E_{f_T} h(\pmb X_{1:t})\)</span>.</p>
<p><br>
<br>
<br></p>
</div>
<div id="generalized-sequential-importance-sampling" class="section level5" number="4.1.1.0.11">
<h5 number="4.1.1.0.11"><span class="header-section-number">4.1.1.0.11</span> Generalized Sequential Importance Sampling</h5>
<p>Assume that <span class="math inline">\(\pmb X_{1:t}\)</span> is not a Markov process.</p>
<p>target density <span class="math inline">\(f_t (\pmb x_{1:t})\)</span> and envelope <span class="math inline">\(g_t (\pmb x_{1:t})\)</span> may be expressed as</p>
<p>$
<span class="math display">\[\begin{align*}

f_t (\pmb x_{1:t}) &amp;= f_1 (x_1) \ast f_2 (x_2 \rvert \pmb x_{1:1}) \ast f_3 (x_3 \rvert \pmb x_{1:2}) &amp;\cdots &amp;\ast f_t (x_t \rvert \pmb x_{1:t-1}) \\

g_t (\pmb x_{1:t}) &amp;= g_1 (x_1) \ast g_2 (x_2 \rvert \pmb x_{1:1}) \ast g_3 (x_3 \rvert \pmb x_{1:2}) &amp;\cdots &amp;\ast g_t (x_t \rvert \pmb x_{1:t-1})
\end{align*}\]</span>
$</p>
<p>the importance weight at time <span class="math inline">\(t\)</span> is</p>
<p>$</p>
<p>w_t (x_{1:t}) =  {g_1 (x_1) g_2 (x_2 x_{1:1}) g_3 (x_3 x_{1:2}) g_t (x_t x_{1:t-1})}
$</p>
<p>and the recursive updating expression for the importance weights is</p>
<p><span class="math inline">\(w_t(\pmb x_{1:t}) = w_t(\pmb x_{1:t}) \dfrac {f_t (x_t \rvert \pmb x_{1:t-1})}{g_t (x_t \rvert \pmb x_{1:t-1})}, \; \; \; \; \; \; \; \; \text{for }t&gt;1\)</span></p>
<!--chapter:end:211201_ImportanceSampling.Rmd-->
</div>
</div>
</div>
<div id="markov-chain-monte-carlo" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Markov Chain Monte Carlo</h2>
<p><span class="math inline">\(f\)</span> 가 측정은 되는데 샘플화가 안되면, MC를 통해 유사한 샘플을 만들어낼 수 있었다. 이를 넘어서 MCMC는 $ f $ 의 모사함수에서 샘플링하는 게 가능하지만, 이 이상으로 이는 임의의 함수 <span class="math inline">\(p\)</span>에 대해 <span class="math inline">\(E[p(X)]\)</span>가 신뢰도 높게 측정되는 경우에만 샘플링 가능한 별개의 방법론으로 보는 게 정확하다.</p>
<table>
<thead>
<tr class="header">
<th align="center">MC</th>
<th align="center">MCMC</th>
<th align="center">numerical integration approach</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">iterative nature</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">can be customized to very diverse &amp; <br> difficult problem</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">무관하며 implementation이 complex하지도 않음</td>
<td align="center">문제가 고차원이면 수렴이 느려짐</td>
</tr>
</tbody>
</table>
<p>시퀀스 <span class="math inline">\(\{\textbf X^{(t)}\}\)</span>는 MC, <span class="math inline">\(t = 0, 1, 2, ….\)</span>. <span class="math inline">\(\textbf X^{(t)} = (X_1^{t} , \cdots, X_p^{(t)})\)</span> 와 <strong>state space</strong> 는 양쪽 모두 연속이거나 discrete.</p>
<p>For the types of Markov chains, <span class="math inline">\(\{ \textbf X^{(t)} \}\)</span>의 분포는 체인의 limiting stationary distribution으로 수렴한다. 체인이 irreducible, aperiodic 할 때.</p>
<p>MCMC의 샘플링 전략은 irreducible, aperiodic MC를 만드는 것. stationary distribution이 목표분포 <span class="math inline">\(f\)</span> 와 일치하는.</p>
<p>t가 충분히 크다면 이 체인으로부터의 <span class="math inline">\(\textbf X^{(t)}\)</span>의 실현값은 근사적으로 마지널 분포 <span class="math inline">\(f\)</span> 를 갖는다.</p>
<p>이런 MCMC의 특성은 베이지안 추론에 크게 도움이 되며 자주 쓰인다.</p>
<p><br />
<br />
<br /></p>
<p>Markov Chain 자체는 <strong>어떤 상태에서 다른 상태로 넘어갈 때, 바로 전 단계의 상태에만 영향을 받는</strong> (Markov Property) 확률 과정을 의미한다.</p>
<ul>
<li>보통 사람들은 전날 먹은 식사와 유사한 식사를 하지 않으려는 경향이 있다.</li>
<li>가령, 어제 짜장면을 먹었다면 오늘은 면종류의 음식을 먹으려고 하지 않는다.</li>
</ul>
<p><br />
<br />
<br />
<br />
<br /></p>
<div id="mh-algorithm" class="section level3" number="4.2.1">
<h3 number="4.2.1"><span class="header-section-number">4.2.1</span> MH Algorithm</h3>
<p>MCMC 중 가장 유명한 적용법은 MH 알고리즘. <span class="math inline">\(t=0\)</span>에서 시작. 시작 distribution <span class="math inline">\(g\)</span>에서 추출한, <span class="math inline">\(f(\textbf x^{(0)} )&gt; 0\)</span> 을 만족하는 <span class="math inline">\(\textbf x^{(0)}\)</span>를 <span class="math inline">\(\textbf X^{(0)} = \textbf x^{(0)}\)</span> 로 잡고 개시한다.</p>
<p>이때 제안분포 <span class="math inline">\(g\)</span> 에서 후보 <span class="math inline">\(\textbf X^{( \ast )}\)</span> 를 하나 만들고, MH ratio <span class="math inline">\(R (\textbf {x}^{(t)}, \textbf X^{\ast} )\)</span> 는</p>
<p><span class="math display">\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} ) 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )} | \textbf X^{( \ast )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )} | \textbf x^{( t )}) } 
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf X^{( \ast )} | \textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )} | \textbf X^{( \ast )})}
}
=\dfrac
{\dfrac
{f(\textbf X^{( t+1 )})}
{g(\textbf X^{( t+1 )} | \textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )} | \textbf X^{( t+1 )})}
}
\]</span></p>
<p><mark>
<strong>warning</strong></p>
<p><mark>
여기서 단순 Metropolis 알고리즘은 단순히 $  {f(x_0)}$ &gt; $1 $ 이기만 하면 새로운 샘플을 수용한다. 이인즉 <span class="math inline">\(g\)</span>로 표준화해주는 것의 가장 주요한 요점은 둘의 시작 높이, 즉 쥐고 나온 수저가 다를 수 있으므로 이를 표준화해준다는 것이다. 아웃풋이 높은 <span class="math inline">\(x_i\)</span>를 선택하는 것은 MLE 관점에 기반한다.</p>
<p><mark>
단 언제나 그렇듯 이렇게 샘플을 다쳐내면 오히려 음질의 결과가 나온다. 따라서 샘플의 풀을 넓히기 위해 탈락할 녀석들도 확률적으로 살려서 합류시킨다. 이게 고정된 기준점으로 샘플을 쳐내는 것이 아닌, <span class="math inline">\(\dfrac {f(x_1)} {f(x_0)}\)</span> &gt; <span class="math inline">\(u \sim U {(0,1)}\)</span> 을 기준으로 삼아 샘플을 생존시키는 것이다. 이 조건을 실패하면 생산해두었던 샘플 <span class="math inline">\(\textbf X^{(t)}\)</span> 는 버려지고 새로운 샘플을 <span class="math inline">\(t+1\)</span>으로 설정해 재진행한다.
</mark></p>
<p>이후</p>
<p><span class="math display">\[
\textbf {X}^{(t+1)} = \left\{\begin{array}{@{}lr@{}}
    \textbf {X}^{\ast}, &amp; \text{with probability } min \left\{ R \left( \textbf {x}^{(t+1)}, \textbf {X}^{\ast} \right), 1 \right\} \\
    \textbf {x}^{(t)}, &amp; o.w.
    \end{array}\right\}
\]</span></p>
<p>이러한 MH 알고리즘에 의해 생성된 MC가 aperiodic &amp; irreducible 이라면, 해당 체인은 정적분포로 수렴.</p>
<p>우리는 이러한 MH 체인에 의해 생성된 정적분포의 실현값들을 평균함으로써 rv의 함수의 기댓값을 구할 수 있다.</p>
<p><span class="math inline">\(E \left[ h \left( \textbf {X} \right) \right] \approx \dfrac {1} {n} \sum_{i=1}^n {h \left( \textbf {x}^{(i)} \right)},\)</span></p>
<p><span class="math inline">\(E { \left\{ h \left( \textbf {X} \right) - E \left[ h \left( \textbf {X} \right) \right] \right\} }^2\)</span>,</p>
<p><span class="math inline">\(E \{ I_{h ( \textbf {X} \le q )} \}\)</span></p>
<p>시퀀스 <span class="math inline">\(\{ \textbf x^{(\inf)} \}\)</span> 는 state space의 몇몇 포인트들의 multiple copies를 가질 수 있다는 것을 명심. 이는 <span class="math inline">\(\textbf {X}^{(t+1)}\)</span>가 제안값 <span class="math inline">\(\textbf {x}^{(\ast )}\)</span>가 아니라 <span class="math inline">\(\textbf {x}^{(t)}\)</span>를 채택했을 때 발생.</p>
<ul>
<li>Burn-in Period: 체인의 초기값에 대한 persistent dependence는 이의 성능을 심각하게 낮출 수 있다. 이는 샘플 평균을 계산할 때 체인의 초기 실현값 일부를 제하는 것으로 보정될 수 있다.</li>
</ul>
<p>consistent 결과들을 관측하기 위해 MCMC를 여러 시작점에서 각각 돌려본다.</p>
<p>잘 골라진 제안분포 $ g $가 생산하는 후보값들은 <strong>stationary 분포</strong>의 서포트를 합리적인 반복 안에서 전부 커버하고, 내놓는 후보값들이 지나치게 여러번 accepted되거나 rejected 되지 않는다.</p>
<ul>
<li>proposal 분포 $ g $ 가 지나치게 퍼져있으면, 후보값들은 자주 reject되고 체인은 타겟분포 $ f $ 의 space를 탐색하기 위해 많은 반복을 요구하게 된다.</li>
<li>proposal 분포 $ g $ 가 지나치게 모여있으면, 체인은 다회의 반복동안 타겟분포 $ f $의 한 작은 구역에 모여있게 된다. 따라서 타겟분포의 다른 영역은 적절하게 탐색되지 못한다.</li>
</ul>
<p><br /><br />
<br /><br />
<br /></p>
<div id="independent-chains" class="section level4" number="4.2.1.1">
<h4 number="4.2.1.1"><span class="header-section-number">4.2.1.1</span> Independent Chains</h4>
<p>acceptance 여부 결정시에 ratio 자체는 MH ratio를 사용한다. 이 MC ratio에는 과거 실현값(<span class="math inline">\(x^{(t)}\)</span>)이 들어있다. 따라서 이는 MCMC 방법론에 해당한다. 하지만 새로운 value <span class="math inline">\(g(x&#39;)\)</span>을 생산할 때, 이 자체는 <span class="math inline">\(g(x&#39;\rvert x^{(t)})=g(x&#39; \rvert \cdot )\)</span>을 따르게, 즉 <span class="math inline">\(g(x&#39;\rvert x^{(t)})=g(x&#39; )\)</span> 마냥 과거의 실현값에 dependent 하지 않게 새로운 값을 생산해내는 방법론. 즉 새로이 제시되는 candidate value가 과거의 실현값들과 independent 하므로 명칭이 저러한 것이다.</p>
<p>즉 <strong>MH ratio 자체는 과거의 샘플을 이용해서</strong> MCMC 범주에 들어가나 샘플 자체는 과거의 샘플과 independent하게 생산.</p>
<p>MH 알고리즘의 제안분포는 고정된 덴시티 <span class="math inline">\(g\)</span>에 대해서 $ g ( ^{} ^{(t)} )$ 따위로 생성. 이는 <strong>independent chain</strong> 이라고 불리며, 이에 사용되는 각 후보값들은 과거에서 독립적으로 추출되었다. MH ratio는</p>
<p><span class="math display">\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} ) 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )} | \textbf X^{( \ast )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )} | \textbf x^{( t )}) } 
= \dfrac 
{f(\textbf X^{( \ast )}) g(\textbf x^{( t )})} 
{f(\textbf x^{( t )}) g(\textbf X^{( \ast )}) } 
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf x^{( t )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf X^{( \ast )})}
}
=\dfrac
{\dfrac
{f(\textbf X^{( \ast )})}
{g(\textbf X^{( \ast )})}
}
{\dfrac
{f(\textbf x^{( t )})}
{g(\textbf x^{( t )})}
}
= \dfrac {w^{\ast}} {w^{(t)}}
\tag{1}
\]</span></p>
<ul>
<li>importance ratio of <span class="math inline">\(X&#39;\)</span>, importance ratio of <span class="math inline">\(X^{(t)}\)</span>. This can be seen as weight also.</li>
</ul>
<p>이때 가장 우측의 등식은 importance ratio (<span class="math inline">\(r\)</span>)의 등식으로 재표현된 것이며, 이때 <span class="math inline">\(f\)</span> 는 타겟분포, <span class="math inline">\(g\)</span> 는 그것의 envelope로 본 것이다.</p>
<p><br /><br />
<br /><br />
<br /></p>
<div id="example-bayesian-inference-mixture-distribution" class="section level5" number="4.2.1.1.1">
<h5 number="4.2.1.1.1"><span class="header-section-number">4.2.1.1.1</span> Example: Bayesian Inference, Mixture Distribution</h5>
<p>MCMC 알고리즘은 <span class="math inline">\(p(\theta \rvert y ) = c \cdot p(\theta) L(\theta \rvert y)\)</span> 로 표현될 수 있는 베이지안 추론에서 특히 강력하다. 베이지안 추론에서 <span class="math inline">\(c\)</span>의 계산이 드럽게 어렵다는 것이 이것 이상의 다른 추론전략을 방해하기 때문이다.</p>
<p>보유하는 stationary 분포가 타겟 post인 MCMC에서 생산된 샘플들은 post 모먼트, tail 확률, 그리고 다른 유용한 quantity 계산에 쓰일 수 있다.</p>
<p>independent 체인에서 prior를 proposal 분포(<span class="math inline">\(g\)</span>)로 쓰자. 즉 <span class="math inline">\(f\)</span>가 post, <span class="math inline">\(g\)</span>가 prior다. 이런다면</p>
<p><span class="math display">\[
R ({\theta}^{(t)}, \theta^{\ast} ) 
=\dfrac
{\dfrac
{f(\theta^{( \ast )})}
{g(\theta^{( \ast )})}
}
{\dfrac
{f(\theta^{( t )})}
{g(\theta^{( t )})}
}
=\dfrac
{c \; \cdot \; \pi( \theta^{\ast} ) L( \theta^{\ast} \rvert y )}
{c \; \cdot \; \pi( \theta^{(t)} ) L( \theta^{(t)} \rvert y )}
\cdot
\dfrac { \pi (\theta^{(t)} )}{ \pi (\theta^{\ast})}
=\dfrac
{\dfrac
{\pi (\theta^{\ast} \rvert y)}
{\pi (\theta^{\ast})}
}
{\dfrac
{\pi (\theta^(t) \rvert y)}
{\pi (\theta^{(t)})}
}
= \dfrac
{L \left( \theta^{\ast} \rvert y \right)}
{L \left( \theta^{(t)} \rvert y \right)}
\]</span></p>
<ul>
<li>Mixing Properties:
<ul>
<li>Good Mixing: 첫번째 그림의 MC는 시작점에서 빠르게 멀어지며 <span class="math inline">\(\delta\)</span>에 대한 post에서의 모든 서포트에 해당하는 패러미터 space의 모든 부분을 훑으면서 샘플을 뽑아내는게 쉬워보인다.</li>
<li>Bad Mixing: 두번째 그림은 starting value에서 멀어지는 것도 느리고, posterior support의 영역을 탐색하는 게 시원찮아보인다.</li>
</ul></li>
<li>Burn-in 이후의 실현값들을 히스토그램으로 만들어서 살펴보면 <span class="math inline">\(BETA(1,1)\)</span> proposal 덴시티를 쓴 MCMC만이 <span class="math inline">\(\delta\)</span>의 참값을 잘 모사하는듯.</li>
</ul>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
</div>
</div>
<div id="random-walk-chains-most-widely-used" class="section level3" number="4.2.2">
<h3 number="4.2.2"><span class="header-section-number">4.2.2</span> Random Walk Chains (Most Widely Used)</h3>
<p>MH method 에 해당.</p>
<p>let <span class="math inline">\(\textbf {X}^{\ast} = \textbf {X}^{(t)} + \epsilon , \epsilon \sim h(\epsilon )\)</span>. 이때 <span class="math inline">\(h\)</span>는 임의의 덴시티.</p>
<ul>
<li><span class="math inline">\(h\)</span> 로 자주 선택되는건 <span class="math inline">\(U, \textbf{N}, \text {Student&#39;s } t\)</span>.</li>
</ul>
<p>이러면 proposal 덴시티 <span class="math inline">\(g\)</span>는 어떻게 되는가? <span class="math inline">\(x^{&#39;} g \sim N( \cdot \rvert x^{(t)}, \sigma^2 )\)</span>. 가장 빈번하게 쓰이는게 <span class="math inline">\(N\)</span>이므로 <span class="math inline">\(N\)</span>으로 설명. 여기서 <span class="math inline">\(x^{(t)}\)</span>는 평균으로 사용되었고, <span class="math inline">\(\sigma^2\)</span>은 <strong>Jumping Rule</strong>에 해당한다.</p>
<ul>
<li>proposal can be
<ul>
<li>too diffused: Jumping rule is too big</li>
<li>too focused: Jumping rule is too small</li>
</ul></li>
<li>Random Walk
<ol style="list-style-type: decimal">
<li>generate <span class="math inline">\(x^{&#39;} g \sim N( \cdot \rvert x^{(t)}, \sigma^2 )\)</span></li>
<li><span class="math inline">\(u \sim U(0,1)\)</span>.</li>
<li>calculate MH ratio: <span class="math inline">\(r = \dfrac {f(x&#39;)}{f(x^{(t)}} \dfrac {g(x&#39; \rightarrow x^{(t)}} {g(x^{(t)} \rightarrow x&#39;} = \dfrac {f(x&#39;)}{f(x^{(t)}}\)</span>, cause it’s <span class="math inline">\(N\)</span>.</li>
<li>if <span class="math inline">\(u&lt;r\)</span>, <span class="math inline">\(x^{(t+1)} = x&#39;\)</span>. o.w., <span class="math inline">\(x^{(t+1)} = x^(t)\)</span>.</li>
</ol></li>
</ul>
<p><br /><br />
<br /><br />
<br /></p>
<div id="example-mixture-distribution" class="section level4" number="4.2.2.1">
<h4 number="4.2.2.1"><span class="header-section-number">4.2.2.1</span> Example: Mixture Distribution</h4>
<p>let proposal <span class="math inline">\(\delta^{(t+1)} = \delta^{(t)} + U(-a, a)\)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. 이인즉 몇몇 proposal들은 <span class="math inline">\([0, 1]\)</span> 이외에서 생산된다.</p>
<ul>
<li>note that <span class="math inline">\(\forall \delta \notin [0,1]\)</span>, post is zero,</li>
<li>Reparameterize the problem by letting <span class="math inline">\(U = \log{\dfrac {\delta}{1-\delta}}\)</span>(logit). 왜? Probabilty Space is bounded: <span class="math inline">\(0 \le P(\cdot) \le 1\)</span>.</li>
</ul>
<p>Run a random walk chain on <span class="math inline">\(U\)</span> by adding <span class="math inline">\(U(-b,b)\)</span>.</p>
<p>Two ways of Reparamaterization:</p>
<ul>
<li>Run MCMC in <span class="math inline">\(\delta\)</span>-space. <span class="math inline">\(u\)</span> 값을 다시 T해와서 <span class="math inline">\(\delta\)</span>-space에서 돌림.</li>
<li>Run MCMC in <span class="math inline">\(u\)</span>-space. <span class="math inline">\(u\)</span>-space에서 돌리고 마지막에 모델 샘플들을 전부 <span class="math inline">\(\delta\)</span>-space로 환원.</li>
</ul>
<p><br /></p>
<div id="delta-space에서-돌리는-방법" class="section level5" number="4.2.2.1.1">
<h5 number="4.2.2.1.1"><span class="header-section-number">4.2.2.1.1</span> <span class="math inline">\(\delta\)</span>-space에서 돌리는 방법</h5>
<p>개략적으로는 <span class="math inline">\(T^{-1}: \delta&#39; \leftarrow u&#39; \sim g( \cdot \rvert u^{(t)})\)</span> 와 같은 형을 띤다. 조건부 proposal <span class="math inline">\(g\)</span>에서 생산된 u를 하나하나마다 <span class="math inline">\(\delta\)</span>로 역변환해서 그 하나하나의 역변환 값으로 MH 알고리즘을 돌린다. proposal 덴시티 <span class="math inline">\(g( \cdot \rvert u^{(t)} )\)</span> 는 <span class="math inline">\(\delta\)</span>-space에서의 proposal 덴시티로 변환되어야 한다. 이경우 MH ratio는</p>
<p><span class="math display">\[
R (\textbf {x}^{(t)}, \textbf X^{\ast} )
=\dfrac
{\dfrac
{f(\delta^{\ast})}
{g \left( logit(\delta^{\ast}) \rvert logit(\delta^{(t)}) \right) \cdot \left| J(\delta^{\ast})\right|}
}
{\dfrac
{f(\delta^{(t)})}
{g \left( logit(\delta^{(t)})|logit(\delta^{\ast}) \right) \cdot \left| J(\delta^{(t)})\right|}
}
\]</span></p>
<p>$J(^{(t)}) $ 는 $T: u $에 대한 <span class="math inline">\(J\)</span>를 <span class="math inline">\(\delta^{(t)}\)</span>에서 측정한 값. 주의해야 할 것이 해당 방법론에서는 <span class="math inline">\(T\)</span>한 value를 사용하였으므로 <span class="math inline">\(g\)</span>에 대한 <span class="math inline">\(J\)</span>를 구해야 한다.</p>
<p><br /></p>
</div>
<div id="u-space에서-돌리는-방법" class="section level5" number="4.2.2.1.2">
<h5 number="4.2.2.1.2"><span class="header-section-number">4.2.2.1.2</span> <span class="math inline">\(u\)</span>-space에서 돌리는 방법</h5>
<p>이 상황에서 쓰이는 proposal은 <span class="math inline">\(\dfrac {g(u^{(t)} \rightarrow u&#39;)} {g(u&#39; \rightarrow u^{(t)})}\)</span>. <span class="math inline">\(\delta\)</span>에 대한 타겟 덴시티는 <span class="math inline">\(u\)</span>에 대한 덴시티로 변형되어야 한다. 이때 <span class="math inline">\(\delta = logit^{-1}(U) = \dfrac{\exp(U)}{1+\exp(U)}\)</span> 였으므로, <span class="math inline">\(U^{\ast} = u^{\ast}\)</span> 로 두었을 때 생산되는 MH ratio는</p>
<p><br>
<br></p>
<p>$$
R (^{(t)}, ^{} )</p>
<p>=
{
{f(logit^{-1} {(u^{})})}
{g (u<sup>{}|u</sup>{(t)}) ) * | J(u^{(t)})|}
}
{
{f(logit^{-1} {(u^{(t)})})}
{g (u<sup>{(t)}|u</sup>{()}) ) * | J(u^{})|}
}
$$</p>
<p><br>
<br></p>
<p>우리가 transform value를 사용한데가 <span class="math inline">\(f\)</span> 덴시티이므로 <span class="math inline">\(f\)</span> 덴시티에 대한 야코비안을 붙여줘야 하는데 그 덴시티에 대한 야코비안은 <span class="math inline">\(u\)</span>에 대한 야코비안이므로 쓰인 야코비안은 위와 같다. 이때 <span class="math inline">\(\lvert J(u^{\ast})\ \rvert = \dfrac {1} {\lvert J(\delta^{\ast}) \rvert}\)</span> 이므로 위와 아래에서 만들어지는 <strong>MH ratio는 같다.</strong> 따라서 두 관점은 equivalent한 체인을 생산한다.</p>
<ul>
<li>Sample paths for <span class="math inline">\(\delta\)</span> from RW chains in Ex. 7.3, run in <span class="math inline">\(u\)</span>-space iwth b=1 (top) and b=0.01 (bottom).</li>
</ul>
</div>
</div>
<div id="example-autocorrelation-plot-acf" class="section level4" number="4.2.2.2">
<h4 number="4.2.2.2"><span class="header-section-number">4.2.2.2</span> Example: Autocorrelation Plot (ACF)</h4>
<p>배우지 않은 MCMC 방법론 중 하나.</p>
<p><img src="2-1.png">
<img src="2-2.png"></p>
<p>reminder. thinning을 하더라도 거의 줄지 않아서 MCMC 샘플로서 거의 가치가 없는 케이스가 존재한다.</p>
<p>no</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
</div>
<div id="basic-gibbs-sampler" class="section level3" number="4.2.3">
<h3 number="4.2.3"><span class="header-section-number">4.2.3</span> Basic Gibbs Sampler</h3>
<ul>
<li>need to derive the conditional density for all, 모든 joint density에 대해 coefficient를 1개씩 제한 상황의 <strong>모든 conditional density를 구한 후</strong> GS 제작이 가능
<ul>
<li>if conditional densities are not available, we can use MH algorithm when updating <span class="math inline">\(x_i\)</span> -&gt; 이런식으로 접근할 경우 이를 MH-within-Gibbs라고 부른다.
<ul>
<li>1PL IRT HW</li>
</ul></li>
</ul></li>
</ul>
<p>let <span class="math inline">\(\textbf {X} = (X_1 , \cdots, X_p )^{&#39;}\)</span> , <span class="math inline">\(\textbf {X}_{-i} = (X_1 , \cdots, X_{i-1}, X_{i+1}, \cdots, X_p )^{&#39;}\)</span>.</p>
<p>시작값 $^{(0)} $를 잡고, <span class="math inline">\(t=0\)</span>으로 설정한다. 이후 각각을 <span class="math inline">\(t+1\)</span> 단계의 시퀀스의 구성요소 각각을 <span class="math inline">\(X_i^{(t+1)} \vert \; \; \cdot \sim f \left( x_1 \rvert x_2^{(t)}, \cdots, x_p^{(t)} \right)\)</span> 에 따라서 생산한다.</p>
<p>Gibbs Sampler의 stationary 분포는 <span class="math inline">\(f\)</span>.</p>
<p><span class="math inline">\(X_i^{(t)}\)</span>의 limiting 마지널 분포는 <span class="math inline">\(i\)</span>번째 coordinate에 따른 타겟분포의 단변량 마지널化와 같다.</p>
<p>MH 알고리즘과 마찬가지로, 우리는 <span class="math inline">\(X\)</span>의 임의의 함수 <span class="math inline">\(g(X)\)</span>에 대해 <span class="math inline">\(E \left[ g(X) \right]\)</span> 를 추정하기 위해 체인에서의 실현값을 사용할 수 있다.</p>
<p><br /><br />
<br /><br />
<br /></p>
<div id="example-fur-seal-pup-capture-recapture-model" class="section level4" number="4.2.3.1">
<h4 number="4.2.3.1"><span class="header-section-number">4.2.3.1</span> Example: Fur Seal Pup Capture-Recapture Model</h4>
<p>1800년대 후반 (by the late 1800s) 뉴질랜드 물범은 거의 전멸했다가 요즘 들어 폭증함 (abundance). 물범의 고름 숫자를 capture-recapture 사용해서 해보자.</p>
<p>사이즈 불명인 모집단의 크기 파악 위에 반복 연구 실행. 각 연구마다 <strong><em>포획</em></strong>었던 개체는 표식 새기고 풀어줌. 후속 연구에서 또 포획되면 <strong><em>재포획</em></strong>으로 표기. 높은 재포획 비율은 참 모집단 사이즈값이 포획되었던 개체들의 총량을 크게 넘지 않을 것임을 암시.</p>
<ul>
<li><span class="math inline">\(N\)</span>: 불명인 모집단 사이즈. <span class="math inline">\(l\)</span>회의 조사 통해 얻어진 각 회의 총 <strong><em>포획</em></strong> 숫자는 각각 <span class="math inline">\(c=(c_1, \cdots, c_l)\)</span>로 저장. 모집단 사이즈는 샘플링 동안에는 변동 없다(죽음, 출생, 이주 없음 inconsequential)고 가정한다.</li>
<li><span class="math inline">\(r\)</span>: 연구 동안에 포획되었던 이질 동물들의 총 숫자.</li>
<li>각 연구 시도에서 상응하는 구분되고 알려지지 않은 <strong><em>포획 확률</em></strong>은 <span class="math inline">\(\alpha = (\alpha_1 , \cdots, \alpha_l )\)</span>. 이 모델은 모든 동물들이 각 1회의 포획 발생에서 잡힐 가능성 자체는 각각의 동물에 대해서 동일하나, 이 被포획 확률은 시간이 지남에 따라 변할 수 있다는 것을 말함.</li>
</ul>
<p>이 모델의 likelihood는</p>
<p><span class="math display">\[
L \left( N, \alpha \rvert c, r \right) 
\propto 
\dfrac {N!}{(n-r)!} \prod_{=1}^{l} \alpha_i^{c_i} 
\]</span>
Fur Seal Data for Seven Studies in One Season on the Otago Peninsula가 주어졌으며, prior은 <span class="math inline">\(\pi(N) \propto 1\)</span>, <span class="math inline">\(\pi (\alpha_i ) = BETA(\theta_1 , \theta_2)\)</span> 이다. 계산하라.</p>
<p>해당 모델의 conditional posterior distribution에서 시뮬레이트하는 것으로 Gibbs Sampler를 제작할 수 있다.</p>
<p><span class="math display">\[
N^{(t+1)}-r \rvert \cdot \sim Negative Binomial \left( r+1, 1- \prod_{i=1}^7 \left( 1- \alpha_i^{(t)} \right) \right)
\]</span></p>
<p><span class="math display">\[
\alpha_i^{(t+1)} \rvert \cdot \sim BETA \left( c_i + \dfrac{1}{2}, N^{(t+1)} - c_i + \dfrac{1}{2} \right)
\]</span></p>
<p>for <span class="math inline">\(i= 1, \cdots, 7\)</span>, <span class="math inline">\(r = \sum_{i=1}^7 {m_i} =84\)</span>. 이는 unique fur seals were observed during the sampling period.</p>
<ul>
<li>Split boxplots of <span class="math inline">\(\bar {\alpha}^{(t)}\)</span> against $N^{(t)} $ for the seal pup example.</li>
<li>Estimated marginal posterior probabilities for <span class="math inline">\(N\)</span> for the seal pup example.</li>
</ul>
<p><br /><br />
<br /><br />
<br /></p>
</div>
<div id="mh-within-gibbs-sampler" class="section level4" number="4.2.3.2">
<h4 number="4.2.3.2"><span class="header-section-number">4.2.3.2</span> MH-within-Gibbs Sampler</h4>
<p><strong>실제 implementation에 무지막지 유용하다.</strong> 이는 각각의 사이클을 GS의 사이클로 만들어놓고, conditional density는 MH 알고리즘으로 획득하는 것이다. <strong>Gibbs Sampler는 MH Sampler의 특별한 경우라고 볼 수 있다.</strong> MH 알고리즘의 proposal 분포를 시간에 따라 변화하도록 함으로써, GS와 MH 알고리즘 사이에 연결고리가 생긴다. 각 Gibbs 사이클은 <span class="math inline">\(p\)</span> 개의 MH 스텝으로 구성되어 있다. 사이클 내에서의 <span class="math inline">\(i\)</span>번째 Gibbs 스텝은, 체인의 현 상태 <span class="math inline">\((x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\)</span> 가 주어졌을 때, 효과적으로 후보 벡터 <span class="math inline">\((x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, {\underline{X_i^{*}}}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\)</span> 를 생산한다. 밑줄 차이점에 주목.</p>
<p><span class="math inline">\(i\)</span>번째 단변량 Gibbs 업데이트는 이하와 같이 MH 스텝 drawing으로 볼 수 있다.</p>
<p><span class="math display">\[
{\underline{X_i^{*}}} \rvert  (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)}, x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})}) \sim g_i \left( \cdot \rvert (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)},  x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})}) \right)
\]</span></p>
<p>where</p>
<p><span class="math display">\[
g_i \left( \cdot \rvert (x_{1}^{(t+1)}, \cdots, x_{i-1}^{(t+1)},  x_{i+1}^{(\underline{t})}, \cdots, x_{p}^{(\underline{t})})\right) 
= \left\{
\begin{array}{@{}lr@{}}
f(x_i^{*} \rvert x_i^{(t)} ), &amp; \text{if } \; \; \; X_i^{*} = x_i^{(t)} \\
0 &amp;  o.w.
\end{array}\right\}
\]</span></p>
<p>이 경우, MH ratio는 1과 같아진다. 즉슨 모든 후보들은 언제나 accept 된다. 즉슨 GS는 MH 알고리즘에서 acceptance ratio가 항상 1인 경우에 해당한다. 따라서 <strong>conditional density</strong>을 구할 수만 있으면 GS를 사용하는게 좋다. 샘플을 버릴 필요가 없고, 버려지는 샘플이 없기 때문.</p>
<p><br /><br />
<br /><br />
<br /></p>
</div>
<div id="update-ordering" class="section level4" number="4.2.3.3">
<h4 number="4.2.3.3"><span class="header-section-number">4.2.3.3</span> Update Ordering</h4>
<p><strong>Random Scan Gibbs Sampling</strong>: 기본 GS에서 $  $ 에 가해지는 업데이트의 순서는 <strong><em>한 사이클에서 다음 사이클로 넘어갈 때마다 바뀔 수 있다. 패러미터들이 높은 수준에서 상호연관되어있을 경우, 각 사이클을 랜덤하게 순서배치하는 것은 효과적일 수 있다.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></em></strong> 특정 모델에 대한 전문화된 지식이 없다면, 한 이터레이션에서 다음으로 넘어갈 때 패러미터끼리 높이 상호연관되어있다면 deterministic 한 방법과 RSGS 양쪽 모두를 시도해보는 것이 권장된다.</p>
</div>
<div id="blocking" class="section level4" number="4.2.3.4">
<h4 number="4.2.3.4"><span class="header-section-number">4.2.3.4</span> Blocking</h4>
<p>with <span class="math inline">\(p=4\)</span>, e.g., 각 사이클을 다음 절차를 따르면서 업데이트:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X_1^{(t+1)}\rvert \cdot \sim f \left(x_1 \rvert x_2^{(t)}, x_3^{(t)}, x_4^{(t)} \right)\)</span>.</li>
<li><span class="math inline">\(X_2^{(t+1)}, X_3^{(t+1)}\rvert \cdot \sim f \left(x_2, x_3 \rvert x_1^{(t+1)}, x_4^{(t)} \right)\)</span>.</li>
<li><span class="math inline">\(X_4^{(t+1)}\rvert \cdot \sim f \left(x_4 \rvert x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)} \right)\)</span>.</li>
</ol>
<p><strong>Blocing</strong>은 <span class="math inline">\(X\)</span>의 구성요소들이 서로 상관관계가 있을 때 <strong><em><span class="math inline">\(X_i\)</span> 내부가 상관이라는 건가, 아니면 <span class="math inline">\(X_t, X_{t+1}\)</span> 이 상관이라는 건가?</em></strong> 유용함. 해당 알고리즘을 통해 더욱 상관된 구성요소끼리는 한 블럭 안에서 샘플링됨.</p>
</div>
<div id="hybrid-gibbs-sampling" class="section level4" number="4.2.3.5">
<h4 number="4.2.3.5"><span class="header-section-number">4.2.3.5</span> Hybrid Gibbs Sampling</h4>
<p>하나 이상의 <span class="math inline">\(X\)</span>에 대한 조건부 분포는 대부분 closed form으로 만들 수 없음. 깁스 샘플러의 주어진 스텝에서, 적절한 조건부 분포에서 샘플링하기 위해 MH 알고리즘이 쓰인다면 <strong>Hybrid MCMC</strong> 알고리즘이 완성됨.</p>
<p>with <span class="math inline">\(p=5\)</span>, e.g., 하이브리드 MCMC 알고리즘은 다음 절차를 따르면서 업데이트:</p>
<ol style="list-style-type: decimal">
<li>Update <span class="math inline">\(X_1^{(t+1)} \rvert \left( x_2^{(t)}, x_3^{(t)}, x_4^{(t)}, x_5^{(t)} \right)\)</span> with 깁스 스텝.</li>
<li>Update ( x_2^{(t+1)}, x_3^{(t+1)} ) $ ( x_1^{(t+1)}, x_4^{(t)}, x_5^{(t)} )$ with MH 스텝.</li>
<li>Update <span class="math inline">\(X_4^{(t+1)} \rvert \left( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_5^{(t)} \right)\)</span> with 랜덤워크.</li>
<li>Update <span class="math inline">\(X_5^{(t+1)} \rvert \left( x_1^{(t+1)}, x_2^{(t+1)}, x_3^{(t+1)}, x_4^{(t+1)} \right)\)</span> with 깁스 스텝.</li>
</ol>
<div id="example-fur-seal-pup-capture-recapture-study" class="section level5" number="4.2.3.5.1">
<h5 number="4.2.3.5.1"><span class="header-section-number">4.2.3.5.1</span> Example: Fur Seal Pup Capture-Recapture Study</h5>
<p><br>
<br>
<br>
<br></p>
</div>
</div>
</div>
<div id="implementation" class="section level3" number="4.2.4">
<h3 number="4.2.4"><span class="header-section-number">4.2.4</span> Implementation</h3>
<p>MCMC의 목적은 타겟분포 <span class="math inline">\(f\)</span>의 특징들을 알아내는 것. 모든 MCMC는 정답인 limiting 정적분포를 가지고 있음. 실전에는 체인을 얼마나 충분히 오래 돌릴지를 결정하는 게 중요함. <span class="math inline">\(X\)</span>의 dimensionality(차원)이 높다면 수렴이 엄청 느려서 엄청 긴 run을 요할 수도 있음. 이하의 요건들을 생각해서 long run을 결정해야 함.</p>
<ul>
<li>Has the chain run long enough?</li>
<li>Is the first portion of the chain highly influenced by the starting value?</li>
<li>Should the chain be run from several different starting values?</li>
<li>Has the chain traversed all portions of the region of support of <span class="math inline">\(g\)</span>?</li>
<li>Are the sampled values approximate draws from <span class="math inline">\(f\)</span>?</li>
<li>How shall the chain output be used to produce estimates and assess their precision?</li>
</ul>
<p><br>
<br></p>
<div id="ensuring-good-mixing-and-convergence" class="section level4" number="4.2.4.1">
<h4 number="4.2.4.1"><span class="header-section-number">4.2.4.1</span> Ensuring Good Mixing and Convergence</h4>
<p>MCMC 알고리즘이 대상 문제에 얼마나 쓸만한 정보를 주는지 고민해야 함. 이는 곧</p>
<ol style="list-style-type: decimal">
<li>체인이 얼마나 빠르게 체인의 starting value를 까먹는가</li>
<li>얼마나 빠르게 체인이 타겟분포 <span class="math inline">\(f\)</span>의 모든 서포트를 훑는가</li>
<li>체인이 그것의 정적분포에 근사적으로나마 닿는가를 고민.</li>
<li>There is substantial overlap between the goals of diagnosing convergence to the stationary distribution and investigating the mixing properties of the chain.</li>
</ol>
<p><br>
<br></p>
</div>
<div id="simple-graphical-diagnostics" class="section level4" number="4.2.4.2">
<h4 number="4.2.4.2"><span class="header-section-number">4.2.4.2</span> Simple Graphical Diagnostics</h4>
<p>트레이스 플롯 (sample path)은 이터레이션 횟수 <span class="math inline">\(t\)</span>와 <span class="math inline">\(X^{(t)}\)</span>의 실현값 간의 플롯이다.</p>
<ul>
<li>체인의 mixing이 구리면 이는 장기간의 이터레이션동안 동일값 근처에서 머무르게 됨.</li>
<li>체인의 mixing이 좋으면 시작값에서 빠르게 떠나서 <span class="math inline">\(f\)</span>의 서포트에 해당하는 영역을 열심히 훑음.</li>
</ul>
<p><br>
<br></p>
<p><strong>autocorrelation 플롯</strong>은 <span class="math inline">\(X^{(t)}\)</span>의 시퀀스에서 다른 <strong>이터레이션 래그</strong>에서의 상관관계를 서술한다. 래그 <span class="math inline">\(i\)</span>에서의 autocorrelation은 <span class="math inline">\(i\)</span> 이터레이션만큼 떨어진 이터레이트 간의 상관관계이다. 구린 mixing 프로퍼티를 가지는 체인은 이터레이션 간의 래그가 증가하더라도 autocorrelation의 부식(decay)이 느림.</p>
<p>MCMC 체인에서의 첫 <span class="math inline">\(D\)</span> 개의 값은 보통 <strong>burn-in period</strong>라고 해서 버려짐. 체인의 시작점에 대한 의존이 강하게 남아있을지도 모르기 때문. 어느정도가 적절한 번인 피리어드인가는 <strong>Gelman-Rubin diagnostics</strong>에 의해 결정된다. 결정된 번인 피리어드가 제대로 된 값을 못내면 <span class="math inline">\(D\)</span>가 늘어나던가 <span class="math inline">\(L\)</span>이 늘어나던가 둘다 늘리던가 해야함.
- Motivated by an Analysis of Variance
- 사슬간 분산 (between-chain variance)이 사슬내 분산 (within-chain variance)보다 유의하게 크면 번인 피리어드나 MCMC 길이가 늘어나야 함
- Difficulties
- multimodal <span class="math inline">\(f\)</span>에서 적절한 스타팅 밸류를 찾는건 어렵고, 체인이 로컬 region이나 mode에서 갇힐수 있음
- 이의 단일차원성 (uni-dimensionality) 때문에 타겟분포 <span class="math inline">\(f\)</span>가 멀티디멘션이면 타겟분포의 수렴에 대한 정보에 대한 잘못된 직관을 줘버릴 수 있음</p>
<p><br>
<br></p>
<p>proposal <span class="math inline">\(g\)</span> 선택할 때 고려해야할 요소는? mixing은 proposal 분포 <span class="math inline">\(g\)</span>의 특질에 큰 영향을 받으며 특히 이의 스프레드(spread)에 큰 영향을 받음. 타겟분포 <span class="math inline">\(f\)</span>와 <span class="math inline">\(g\)</span>간의 닮음에 있어서, 프로포절 <span class="math inline">\(g\)</span>의 tail behavior의 닮음은 high density의 닮음보다 훨씬 중요함. <span class="math inline">\(f/g\)</span>가 bounded 라면, MC의 정적분포로의 수렴은 <strong>대체로(overall)</strong> 빠름. 실전에선 정보를 줄 수 있는 이터레이티브 프로세스를 통해 proposal 분포의 분산이 택해질 수 있음. (In practice, the variance of the proposal distribution can be selected through an informal iterative process.) 20%~50% 사이의 acceptance rate가 선호되어야 함.</p>
<p><br>
<br></p>
<ul>
<li><strong>Reparameterization</strong></li>
</ul>
<p>모델의 reparameterization은 MCMC 알고리즘의 mixing behavior에 상당한 기능향상을 가져올 수 있음. reparameterization은 dependence를 낮추기 위해 가장 우선되어야 할 전략 중 하나임. 서로 다른 모델들은 서로 다른 reparameterization 전략을 적용해야 함. reparameterization 접근법은 보통 특정 모델에 대한 원오프로서 채택되므로 일반화된 조언을 하기에는 어려운 부분이 있음.</p>
<p><br>
<br></p>
<ul>
<li><strong>Comparing Chains</strong></li>
</ul>
<p>MCMC 실현값이 크게 상관관계있다면, MCMC의 각 이터레이션에서 주어지는 정보는 run length에서 주어지는 정보 대비 보잘것 없다(will be less than suggested by the run length). 여기서 reduced information은 <strong>effective sample size</strong>라고 칭해지는 더 작은 iid 샘플에 담겨있는 정보와 동등하다. 여기서 샘플의 총 숫자와 effective sample size 사이의 차이는 잃게 된 효율을 의미한다. 관심있는 변량을 확인하기 위해 우리가 MC 체인에서의 correlated 샘플들을 사용했을 때 잃게된 효율.</p>
<p><br>
<br></p>
<ul>
<li><strong>Number of Chains</strong></li>
</ul>
<p>모델 진단에 있어서 가장 진단을 어렵게 하는 부분은 체인이 타겟분포 <span class="math inline">\(f\)</span>의 1개 이상의 모드에 걸리냐 안걸리냐 하는 부분. 이 경우 모든 수렴진단은 체인이 수렴하긴 한다는 결론을 내리게 된다. 정작 체인이 타겟분포 <span class="math inline">\(f\)</span>의 모든 특성을 나타내지 못하는데도. 그래서 여러번 돌려보게 되는 것. 최소한 그 여러번의 run들 중 체인 1개에서라도 타겟분포 <span class="math inline">\(f\)</span>의 모든 흥미로운 특질들이 드러났으면 하니까. 이러한 특질을을 찾아내는데 실패한 개별 체인들의 경우에는 mixing을 더 좋게 만들기 위해 체인 길이가 늘어나거나 문제가 reparameterize 되어야 함.</p>
<!--chapter:end:211202_MCMC.Rmd-->
</div>
</div>
</div>
<div id="advanced-mcmc-wk08" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Advanced MCMC (wk08)</h2>
<p><strong>1, 3, 5번이 자주 사용됨</strong>
2, 3, 4의 목적은 proposal density 개선</p>
<p>1번은 missing data handling</p>
<p>5번은 variable selection</p>
<p>기본적으로 <span class="math inline">\(f(x) = c \psi (x) = c \exp \left( -\dfrac{U(x)}{t} \right)\)</span>의 개형을 따름.</p>
<div id="data-augmentation" class="section level3" number="4.3.1">
<h3 number="4.3.1"><span class="header-section-number">4.3.1</span> 1. Data Augmentation</h3>
<ul>
<li>Missing Pattern</li>
</ul>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">MCAR</th>
<th align="center">MAR</th>
<th align="center">NMAR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">in missingness <br> in missing on a variable</td>
<td align="center">No patterns</td>
<td align="center"><strong>can be predicted</strong> by <strong>other</strong> variables</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Missing values <br> related to variable?</td>
<td align="center">not to any</td>
<td align="center">other variables</td>
<td align="center">the variable itself</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">complete data considered as a random subsample from the original target sample</td>
<td align="center"></td>
<td align="center">whether data is NMAR is a theoretical and conceptual considerate</td>
</tr>
<tr class="even">
<td align="center">Assumption power</td>
<td align="center">3</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">missing을 의식할 필요가 있는 상황인가?</td>
<td align="center">No.<br>missing 자체를 무시 (ignore).</td>
<td align="center">Yes.<br>predict missing by other variable</td>
<td align="center">Yes.<br>impute with seperate model</td>
</tr>
</tbody>
</table>
<p><strong>bayesian 분석에서 Handling Missing Data에 자주 사용된다.</strong></p>
<p>Data Augmentation(DA) 알고리즘은, 불완전 데이터에 대한 bayesian 분석으로 설명될 수 있다.</p>
<div class="line-block"><span class="math inline">\(X_{obs}\)</span> | observed data |<br />
<span class="math inline">\(X_{mis}\)</span> | missing data |<br />
$X_{com}= (X_{obs},X_{mis} ) $ | complete data |</div>
<p>assume complete 데이터 모델 <span class="math inline">\(X_{com} = (X_{obs}, X_{mis}) \sim g \left( X_{obs}, X_{mis} \rvert \theta \right)\)</span>, where 패러미터 $^d, d ^+ $.</p>
<p>여기서 목적은 패러미터 <span class="math inline">\(\theta\)</span>에 대한 prior 분포 <span class="math inline">\(\pi (\theta)\)</span>와 함께 bayesian 추론을 만드는 것. 이는 곧 <span class="math inline">\(g \left( X_{obs}, X_{mis} \rvert \theta \right) \ast \pi(\theta)\)</span> 를 말한다.</p>
<div class="line-block">Multiple Imputation | 데이터 impute, 그 impute한걸로 패러미터 업데이트, 다시 impute, …. 여기선 impute 셋을 여러개를 만들어놓고, 그걸 패러미터를 계산을 해서 패러미터 분포를 갖고 inference. |<br />
Data Augmentation | interatively하게 패러미터 impute, 업데이트, impute, 업데이트, …. |</div>
<ul>
<li>proceeds: MCMC로 DA</li>
</ul>
<p>let observed-data model <span class="math inline">\(f(X_{obs} \rvert \theta)\)</span>. 이는 아래와 같이 joint pdf에서 마지널을 뽑아냄으로써 (integrate) 단독 pdf를 획득하는 것이 가능함.</p>
<p>MCMC 방법론을 사용해 <span class="math inline">\(\theta\)</span>에 대한 Bayesian 추론을 진행하면 true or observed-data post를 샘플링하거나, 혹은 더욱 일반적으로는 <span class="math inline">\(\theta\)</span>와 <span class="math inline">\(X_{mis}\)</span>의 joint 분포를 샘플링할 것을 요구한다. 이의 각각을 수식으로 나타내면 다음과 같다.</p>
<p>$
<span class="math display">\[\begin{alignat}{4}

&amp; &amp;&amp;f(X_{obs} \rvert \theta) &amp;&amp; &amp;&amp;= \int_{\mathbb{X}_{mis}} g(X_{obs}, X_{mis} \rvert \theta) \; dX_{mis}, \; \; \; &amp;&amp; \theta \in \Theta \\ 

\\

\pi (\theta \lvert X_{obs}) &amp;\propto \; &amp;&amp;f (X_{obs} \lvert \theta) &amp;&amp; \pi(\theta), &amp;&amp; \; \; \; \; \; \; \; &amp;&amp; \theta \in \Theta \tag{1}\\

\\

\pi (\theta, X_{mis} \lvert X_{obs}) &amp;\propto \; &amp;&amp;g (X_{obs}, X_{mis} \lvert \theta) &amp;&amp; \pi(\theta), &amp;&amp; \; \; \; \; \; \; \; &amp;&amp; \theta \in \Theta \tag{2}\\

\end{alignat}\]</span>
$</p>
<p><br></p>
<ol style="list-style-type: decimal">
<li>integrate하여 획득한 위의 likelihood <span class="math inline">\(f(X_{obs} \rvert \theta)\)</span>에 post를 곱하여 direct하게 업데이트 하는 1번 방법</li>
<li>missing을 하나의 unknown 패러미터로 두고, 이 missing 업데이트 한 다음에 missing까지 포함하여 <span class="math inline">\(\theta\)</span>를 inference하고, 그 후에 다시 missing을 업데이트 하는 방법. <br>1번에서는 마지널化한 pdf를 사용했고, 2번에서는 complete의 pdf를 통채로 사용했다. 1번에서는 마지널 시켜서 missing의 영향력을 삭제했다는 것을 발견할 수 있어야 한다.</li>
</ol>
<p>의 2가지 방법을 취하는 것이 가능하다.</p>
<p>let <span class="math inline">\(h( X_{mis} \lvert \theta, X_{obs})\)</span>는 <span class="math inline">\(X_{mis}, X_{obs}\)</span>의 conditional 분포. 이때, 이 분포와</p>
<p>$</p>
<p>(X_{obs}, X_{mis}) g (X_{mis}, X_{obs} ) () </p>
<p>$</p>
<p>상기의 분포 2개가 양쪽 모두 샘플링이 간단하다고 가정하자.</p>
<p>이 두 조건부 분포 2개에 기반한 2단계 GS로 이를 해결하고자 하는 것은 당연한 귀결이다. 이를 <strong>Data Augmentation 알고리즘 (DA)</strong>라 칭한다. 이는 이하와 같이 설명될 수 있다.</p>
<p>take <span class="math inline">\(\theta^{(0)} \in \Theta\)</span>, and iterate for <span class="math inline">\(t=1,2, \cdots\)</span>.
1. Imputation-step: <br>generate <span class="math inline">\(X_{mis}^{(t)} \sim f_{mis}(X_{mis} \rvert \theta^{(t-1)}, X_{obs})\)</span>. (이는 정식적인 likelihood가 아니라 missing variable과 observed variable 간의 관계를 의미하는 것). <br>해당 스텝에서 missing을 대체. 다른 조건들 (패러미터, obs) 들이 주어졌을 때의 mis의 조건부분포를 구하여 이를 기반으로 mis를 imputation.
2. Parameter update-step: <br> generate <span class="math inline">\(\theta^{(t)} \sim \pi (\theta \lvert X_{obs}, X_{mis} )\)</span>. <br>해당 스텝에서 패러미터를 갱신. 위에서 채운 mis와 obs를 합쳐 com 데이터로 삼고 이를 토대로 패러미터 추정한다.</p>
<p>As a two-step GS, DA creates two interleaving Markov Chain:</p>
<p>$
<span class="math display">\[\begin{align*}

\{ \theta(t) &amp;: t=1,2,\cdots \} \\
\{ X_{mis}^{(t)} &amp;: t=1,2,\cdots \}

\end{align*}\]</span>
$</p>
<blockquote>
<p>Example: Multivariate Normal Distribution</p>
</blockquote>
<p><br>
<br>
<br></p>
</div>
<div id="hit-and-run-algorithm" class="section level3" number="4.3.2">
<h3 number="4.3.2"><span class="header-section-number">4.3.2</span> 2. Hit-and-Run Algorithm</h3>
<p><em>for improving the inefficiency of the RW</em></p>
<p>이를 위해 proposal 분포에 대한 수정이 요구된다.</p>
<p>이는 RW에 추가적인 요소를 넣어 변형하는 것인데, RW의 거리와 방향을 거리에 대응하는 pdf, 방향에 대응하는 pdf를 각각 만들어 거기서 랜덤하게 생산하는 것이다.</p>
<p><img src="3-0.png"></p>
<ol style="list-style-type: decimal">
<li>draw below two parameters, and compute an MH acceptance probability <span class="math inline">\(\alpha(x,y)\)</span>, where <span class="math inline">\(x = x^{(t)} = X^{(t)}\)</span>.
<ul>
<li>direction <span class="math inline">\(d \sim g(d) \; \; \;(d \in \mathbb{O})\)</span>.</li>
<li>distance <span class="math inline">\(\lambda \sim I(\lambda \rvert d,x )\)</span> over <span class="math inline">\(\mathcal{X}_{x,d}\)</span>.</li>
</ul></li>
<li>$ X^{(t+1)} =
<span class="math display">\[\begin{cases} x^{(t)}+ \lambda d, &amp; \text{if } \; U \le \alpha(x,y) = \dfrac{f(x&#39;)}{f(x^{(t)})}\dfrac{g(x&#39; -&gt; x^{(t)})}{g(x^{(t)}-&gt; x&#39; ))}\\ x^{(t)}, &amp; o.w.\\ \end{cases}\]</span>
$.</li>
</ol>
<p>이때, <span class="math inline">\(g(d)\)</span>에 대한 가장 흔한 choice는 <span class="math inline">\(\mathbb{O}\)</span>에 대한 <span class="math inline">\(U\)</span>. 이외에 <span class="math inline">\(g(\cdot \rvert x, d)\)</span>, <span class="math inline">\(\alpha(x,y)\)</span>에 대한 가장 흔한 choice도 논해졌던 바가 있다.</p>
<p>이는 특히 sharply constrained 패러미터 space (<span class="math inline">\(\Theta\)</span>) 와 함께하는 문제에 효과적이다.
- Wrapped Normal Distribution</p>
<p><img src="3-1.png"></p>
<p><br>
<br>
<br></p>
</div>
<div id="metropolis-adjusted-langevin-algorithm" class="section level3" number="4.3.3">
<h3 number="4.3.3"><span class="header-section-number">4.3.3</span> 3. Metropolis-Adjusted Langevin Algorithm</h3>
<p><strong>how do we propose a new value? proposal improvement에 자주 사용된다. 또한, Hamiltonian MC와 아주 밀접한 관련이 있다.</strong></p>
<p>Langevin 방정식에 기반하여 생성된 알고리즘. 해당 알고리즘은 기본적으로 <span class="math inline">\(f\)</span>를 정적 (stationary) 분포로서 내버려두게 된다.</p>
<p><strong>gradient flow에 의해 발생하면 얘도 로컬트랩 가능성 있는거 아님?</strong></p>
<p>$</p>
<p>dX_t = dB_t +  f(X_t )</p>
<p>$</p>
<p>이때 <span class="math inline">\(B_t\)</span>는 표준 브라운 운동.</p>
<p>이의 실적용은 Langevin diffusion process를 RW-like Transition으로 대체한 discretion step을 포함하는 아래의 식으로 이루어진다.</p>
<p>$</p>
<p>x^{(t+1)} = x^{(t)} +  f(X^{(t)} ) + _t, ; ; ; ; ; ; _t N_d (0, I_d)</p>
<p>$</p>
<p>이때 <span class="math inline">\(\sigma\)</span>는 step size of discretization.</p>
<p>하지만 discretized 된 프로세스는 transient (일시적, 해당 성질이 이후에도 이어질 것이라 장담 불가) 할 우려가 있으며 <span class="math inline">\(f\)</span>에 대해 더이상 reversible 하지 않음. 이 negative behavior (악영향)을 보정 (correct)하기 위해서 discretization step을 MH acceptance-rejection rule에 기반하여 완화하는 것이 제기됨. 이인즉슨 실적용되는 수식을 conventional MH 제안 (proposal) 분포로서 취급하자는 것.</p>
<ul>
<li>새로운 state: Langevin Dynamics 사용해서 제안</li>
<li>새로운 state의 accept 여부: MH 알고리즘 사용해서 평가</li>
</ul>
<p>따라서 Langevin 알고리즘의 1회의 이터레이션은:
1. 새로운 state <span class="math inline">\(x^\ast = x^{(t)} + \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^{(t)}) + \sigma \epsilon_t\)</span>. 이때 <span class="math inline">\(\sigma\)</span>는 user-specified 패러미터. <br>For limited classes of target distributions, the optimal acceptance rate for this algorithm can be shown to be 0.574.
2. MH ra tio <span class="math inline">\(r = \dfrac {f(x^\ast)}{f(x^{(t)})} \ast \dfrac {\exp \left\{ - \dfrac {1} {2\sigma^2} \left[ x^{(t)} - x^\ast - \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^\ast) \right]^2 \right\}}{\exp \left\{ - \dfrac {1} {2\sigma^2} \left[ x^{\ast} - x^{(t)} - \dfrac {\sigma^2} {2} \bigtriangledown \log f(x^{(t)}) \right]^2 \right\}}\)</span>.
3. set <span class="math inline">\(x^{(t+1)} = x^\ast\)</span> with probability <span class="math inline">\(\min (1, r)\)</span>, 남는 확률로는 <span class="math inline">\(x^{(t+1)} = x^{(t)}\)</span></p>
<p><br>
<br></p>
<ul>
<li>Advantages
<ul>
<li>gradient flow 방법론에 따라 높은 density region으로 향하도록 RW를 충동질함. RW 대비 mixing이나 convergence 관점에서 효과적.</li>
<li>고차원 분포에서 유리</li>
</ul></li>
<li>Disadvantages
<ul>
<li>gradient 계산에 자원 다쳐먹는 경우 있음</li>
<li>multi-mode 관장 불가</li>
</ul></li>
</ul>
<p>이때 with probability <span class="math inline">\(\min (1, r)\)</span>라는 것은 <span class="math inline">\(u &lt; min(1,r), \; \; \; \; \; u \sim U(0,1)\)</span>과 동치라는 것을 알아두자. 앞으로는 모두 이렇게 서술할 것.</p>
<p><br>
<br>
<br></p>
</div>
<div id="multiple-try-metropolis-algorithm" class="section level3" number="4.3.4">
<h3 number="4.3.4"><span class="header-section-number">4.3.4</span> 4. Multiple-Try Metropolis Algorithm</h3>
<p><strong>H&amp;R, MALA, MTMA + HMC는 모두 proposal의 성능을 높이기 위함</strong></p>
<p>MH Transition rule에 기반한 MC에서, 이의 효율성은 제안 (proposal) 분포에 크게 의존한다.</p>
<p><img src="3-2.png"></p>
<p>여러번의 이동을 거치면 과거의 실값과는 멀어지기 때문에 independent하기 때문에 어떤 측면에선 효율적이지만 acceptance 측면에선 떨어짐.</p>
<p>let <span class="math inline">\(\lambda(x,y)\)</span> <strong>non-negative symmetric function</strong>. <span class="math inline">\(q(y \rvert x) &gt;0\)</span> 이면 항상 <span class="math inline">\(\lambda(x,y)&gt;0\)</span>임을 가정. define <span class="math inline">\(w(x,y)=f(x) \ast q(y \rvert x) \ast \lambda(x,y)\)</span>.</p>
<p>At here, when <span class="math inline">\(q(y \rvert x)\)</span> is symmetric, for example, one can choose <span class="math inline">\(\lambda(x,y) = \dfrac {1} {q(y \rvert x)}\)</span>, and then <span class="math inline">\(w(x, y) = f(x)\)</span>. 이 경우, MTM 알고리즘은 orientational bias MC 알고리즘으로 축소되는데, 이는 molecular simulation에서 사용되는 방법론 중 하나다. See Liu, Liang and Wong (2000) for the details.
위의 수식에서 proposal인 <span class="math inline">\(q(y \vert x)\)</span>에 symmetric이라는 조건을 붙이자. 그러면 <span class="math inline">\(q(y \vert x) = {1}{\lambda(x,y)}\)</span>라는 상황을 가정하는 것이 가능하다.</p>
<ul>
<li>Current state is at $x $. Proceeds:
<ol style="list-style-type: decimal">
<li>draw <span class="math inline">\(y_1 , \cdots, y_k \sim T(\pmb x \rightarrow \pmb y)\)</span>, <span class="math inline">\(T\)</span> is proposal.</li>
<li>select <span class="math inline">\(\pmb y = y_j\)</span> with probability <span class="math inline">\(\propto w(y_j , \pmb x)\)</span>.</li>
<li>draw <span class="math inline">\(x_1^\ast, \cdots, x_{k-1}^\ast\)</span> from <span class="math inline">\(T(y \rightarrow x)\)</span>. let <span class="math inline">\(x_k^\ast = \pmb x\)</span>.
<ul>
<li>이때 ** 3번에서 원본 데이터로 돌아가는 프로세스가 포함된 이유는 MHMCMC 알고리즘에서는 얼마만큼 original proposal로 잘 돌아갈 수 있는지를 항상 고려해주어야 함. for reversability. **</li>
</ul></li>
<li>accept proposed <span class="math inline">\(\pmb y\)</span> with probability <span class="math inline">\(p = \min \left\{ 1, \dfrac{w(y_1, \pmb x) + \cdots + w(y_k, \pmb x)} {w(x_1^\ast, \pmb y) + \cdots + w(x_k^\ast, \pmb y)} \right \} \tag{1}\)</span>.
<ul>
<li>(1)의 확률 자체가 결정된 메커니즘은 고급확률론이 필요하므로 이해 불가능함</li>
</ul></li>
</ol></li>
</ul>
<p>current state <span class="math inline">\(\pmb x\)</span>에서, <span class="math inline">\(\pmb x \rightarrow y_1\rightarrow y_2 \rightarrow \cdots \rightarrow y_k\)</span>로 가도록 한다. 이때 각 y에 대해 weight값이 존재.</p>
<p><img src = "3-3.png"></p>
<p><br>
<br>
<br></p>
</div>
<div id="reversible-jump-mcmc-algorithm" class="section level3" number="4.3.5">
<h3 number="4.3.5"><span class="header-section-number">4.3.5</span> 5. Reversible Jump MCMC Algorithm</h3>
<p><strong>number of variable이 작을 때, 베이지안 Variable Selection에 자주 사용됨</strong></p>
<div id="bayesian-variable-dimension-model" class="section level5" number="4.3.5.0.1">
<h5 number="4.3.5.0.1"><span class="header-section-number">4.3.5.0.1</span> Bayesian Variable Dimension Model</h5>
<p>A Bayesian variable dimension model is defined as a collection of models</p>
<p>$</p>
<p>_k = { f(_k ) ; ; ; _k _k }, ; ; ; ; ; k=1, , K</p>
<p>$</p>
<p>with a collection of priors <span class="math inline">\(\pi_k (\theta_k)\)</span> on the 패러미터 of these models. 이는 곧 model의 변화에 따라 각각의 model들 또한 다른 prior를 갖는다는 이야기이다. and a prior distribution <span class="math inline">\(\rho_k, \; \; \; k=1, \cdots, K\)</span> on the indices of these models.</p>
<p>※ Note: 당연히 각각의 model space <span class="math inline">\(\Theta_k\)</span>들은 may have different dimensions. may라고 했지만 대부분의 경우 다름.</p>
<p>In this setting one can compute the <strong>posterior probability of models</strong>, i.e.</p>
<p>$
p ( _k y ) =  {_j _j f_j (y _j) _j (_j) d_j }
$</p>
<p><br>
<br>
<br></p>
<hr />
<p>RJMCMC 알고리즘이란, 패러미터 space의 dim이 정해지지 않은 상황에서, 이 dim과 상관없이 모델 space 자체를 이동할 수 있게 만들어준 MCMC 알고리즘.</p>
<p>단, 패러미터 space의 dim은 모르지만, 여기서는 모델의 총 갯수인 <span class="math inline">\(k\)</span>로 fix가 되어 있다.</p>
<ol style="list-style-type: decimal">
<li>모델 간을 이동시키면서 모델 셀렉션</li>
<li>이와 동시에 패러미터 estimation까지 동시에 한다</li>
</ol>
<p>는 것이 RJMCMC 알고리즘. 즉 RJMCMC 중에는 2가지 공정이 동시에 돌아간다</p>
<p>A variable dimension model is a “model where one among things you do not know is the number of things you do now know,” 연구자 모르는 것들 중 하나에, 니가 지금 알고 있는 것들의 갯수가 있는 모델. 즉, 내가 지금 알고 있는 것이 총 몇개인지조차도 모른다는 이야기이다. <strong>그럼 대체 아는게 뭐야;</strong> e.g., 패러미터 space의 dimension이 고정되어 있지 않음. model selection, checking, improvement, 등등 다양한 상황에서 발생 가능. 모델 <span class="math inline">\(\mathcal{M}_k\)</span> 사이에서의 움직임을 설계하는데 있어 적절한 framework를 구축하고 싶다.</p>
<p>즉슨 모델에 대한 다양한 예상들이 있고, 이러한 모델의 예상도를 확률적으로 옮겨다니면서 이게 맞나? 이게 맞나? 를 체크한다는 이야기.</p>
<p>이를 위한 Green의 원칙:
- 모델 한 쌍 간의 움직임(채택 모델의 변경)만을 고려.
- “dimension matching” moves를 설계.
- MH 알고리즘과 유사하게 움직임을 with probability로 수용. 여기서의 probability 노테이션은 <span class="math inline">\(q\)</span>.</p>
<p>let <span class="math inline">\(x_t = (k^{(t)}, \theta_k^{(t)} )\)</span>가 현 상태를 나타내고, <span class="math inline">\(x^{(t+1)}\)</span>에 대한 proposed state <span class="math inline">\(x&#39; = (k&#39;, \theta_k&#39;)\)</span>.
- if <span class="math inline">\(k&#39;=k\)</span>, proposed move 가 같은 subspace <span class="math inline">\(\mathcal{X}_k\)</span>에서 다른 위치를 탐색한다는 것이다. 따라서 dimension-matching problem 자체가 발생하지 않는다.
- if <span class="math inline">\(k&#39; \not= k\)</span>, 분포 <span class="math inline">\(\psi_{k^{(t)} \rightarrow k&#39;} (u)\)</span>로부터의 <span class="math inline">\(s\)</span>개의 rv <span class="math inline">\(\pmb u = (u_1 , \cdots, u_s)\)</span> 를 생산한다. 그리고 bijection <span class="math inline">\((\theta_k &#39; , u&#39; ) = T(\theta_k^{(t)}, u)\)</span>를 생각하자. 이때 <span class="math inline">\(s&#39;\)</span> 차원의 rvec<span class="math inline">\(u&#39; = (u_1 , \cdots, u_{s&#39;})\)</span>이며, <span class="math inline">\(s\)</span>와 <span class="math inline">\(s&#39;\)</span>는 dimension-matching condition <span class="math inline">\(s+d_k = s&#39; + d_{k&#39;}\)</span>를 만족한다.</p>
<p>Proceeds:
1. 모델 <span class="math inline">\(\mathcal{M}_k\)</span> with probability <span class="math inline">\(q(k^{(t)}, k&#39;)\)</span>에 의해 선택.
2. generate <span class="math inline">\(u_1 , \cdots, u_s \sim \psi_{k^{(t)} \rightarrow k&#39;} (u)\)</span>
3. <span class="math inline">\((\theta_{k&#39;}&#39;, u&#39;) = T(\theta_k^{(t)}, u)\)</span>.
4. Compute MH ratio <span class="math inline">\(r = \dfrac {f(k&#39;, \theta&#39;_{k&#39;} \rvert Y) } {f(k^{(t)}, \theta^{(t)}_{k} \rvert Y) } \dfrac {g(k^{(t)} \rvert k&#39;)} {g(k&#39; \rvert k^{(t)})} \dfrac {\psi_{k&#39; \rightarrow k^{(t)}} (u&#39;)} {\psi_{k^{(t)} \rightarrow k&#39;} (u)} \left\lvert {\dfrac{\partial (\theta&#39;_{k&#39;}, u&#39;)}{\partial (\theta^{(t)}_{k}, u)}} \right\rvert\)</span><br>where $ $ is Jacobian of Transformation.
5. set <span class="math inline">\(X^{(t+1)} = (k&#39;, \theta&#39;_{k})\)</span> with probability <span class="math inline">\(\min (1,r)\)</span>.</p>
<p>그러나 이렇게 무제한 모델을 만들면 너무 어려움. 따라서 보통 제약식을 추가해서 간단한 모델을 사용함. 사용되는 제약식은 각 이터레이션에서 이전 것과 이후 것 간의 dim 차이가 ±1 이라는 것.</p>
<blockquote>
<p>Example: Reversible Jump MCMC Algorithm</p>
</blockquote>
<!--chapter:end:211203_AdvancedMCMC.Rmd-->
</div>
</div>
</div>
<div id="auxiliary-variable-mcmc" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> Auxiliary Variable MCMC</h2>
<p>실전에서 마주치는 대부분의 상황에서 ABC나 HMC 문제를 제외하고는 대부분의 경우 MCMC 문제를 완벽하게 풀어내는 건 불가능. 이때 주어진 variable 말고 보조변수 (Auxiliary Variable)을 추가함으로써 시뮬레이션 품질을 좀 더 높일 수 있지 않을까 하는 것이 논하고자 하는 바.</p>
<div id="introduction" class="section level3" number="4.4.1">
<h3 number="4.4.1"><span class="header-section-number">4.4.1</span> Introduction</h3>
<ul>
<li>Difficulties with MH Algorithm. 일반적인 MH 알고리즘으로 풀어낼 수 없는 2가지 상황이 존재:
<ol style="list-style-type: decimal">
<li>Local-trap problem: 에너지 계가 울퉁불퉁한 complex system에서 시뮬레이션을 진행했을 때 끝없이 로컬 최적값에서 빠져나오지 못함. 시뮬레이션을 비효율적으로 만듬.
<ul>
<li>density가 높다는 것은 해당 파트의 에너지가 낮다는 것이며, density가 낮은 에너지가 많은 파트에서 high density로 가는 것은 쉽고 자주 일어나도 역은 드뭄. 조밀하면 움직일 여력이 없으니까. 이것이 local trap의 원인</li>
<li>에너지는 이하로 표시 가능: energy function <span class="math inline">\(= -log \pi(\theta \vert x)\)</span>, 즉 negative log posterior, 혹은 negative log density.</li>
</ul></li>
<li>Doubly-intractable normalizing constants problem:
<ul>
<li>Inability to sample from distributions with intractable integrals
<ul>
<li>보통이라면, <span class="math inline">\(pi(\theta \vert x) \propto \kappa(x) f(x\vert\theta)\pi(\theta)\)</span>. <span class="math inline">\(r= \dfrac{pi(\theta &#39; \vert x)}{pi(\theta^{(t)} \vert x)} = \dfrac{\kappa(x) f(x\vert\theta &#39; )\pi(\theta &#39; )}{\kappa(x) f(x\vert\theta^{(t)})\pi(\theta^{(t)})}\)</span> 과정에서 normarlizing constant <span class="math inline">\(\kappa\)</span>가 알아서 캔슬되어 MH 돌리는데 문제가 없음.</li>
</ul></li>
<li>let <span class="math inline">\(f(x) \propto \kappa(x;\theta) \psi(x)\)</span> 는 알고자 하는 분포. 여기서 <span class="math inline">\(\kappa(x)\)</span>는 unnormalized density의 함수. 이때 <span class="math inline">\(\kappa(x)\)</span>는 패러미터의 함수이며 각 이터레이션의 다른 패러미터 추정값마다 변화해버려서 캔슬되지 않음. 그러면 계산하면 되는거 아님? 계산 불가능한 상황 존재 - nearly infinite summation or integration 포함하는 경우. (ex:) 이는 곧 intractable integral. acceptance <span class="math inline">\(Pr\)</span>이 알 수 없는 비 <span class="math inline">\(\kappa(x&#39;)/\kappa(x)\)</span>를 포함하므로 MH 알고리즘은 사용불가. <br> 이러한 문제는 bayesian 추론에서 spatial statistical models, random effects models, 그리고 exponential random graph models 등 다양한 통계적 모형에서 부딪히게 된다.
<ul>
<li>ex: Lattice system of areal model (Lattice의 승만큼 연산 필요)</li>
<li>e.g., <strong>Random Effect Model</strong>. 이때는 각 individual별로 Random Effect를 integration 해줘야 하므로 문제터짐</li>
<li>ex: Exponential Random Graph model: 네트워크에 사용되는 모델. 얘도 power임.</li>
<li>이러한 상황에서는 대부분의 optimization 알고리즘도 다 먹통됨</li>
</ul></li>
</ul></li>
</ol></li>
</ul>
<p><img src = "4-1.png"></p>
<ul>
<li>이러한 2개의 문제점을 극복하기 위해 다양한 진보된 MCMC 방법론이 제시되었음.
<ol style="list-style-type: decimal">
<li>Auxiliary variable-based methods</li>
<li>Population-based methods</li>
<li><del>Importance weight-based methods</del></li>
<li>Stochastic approximation-based methods</li>
</ol></li>
</ul>
<p><br>
<br>
<br></p>
<div id="auxiliary-variable-mcmc-methods" class="section level5" number="4.4.1.0.1">
<h5 number="4.4.1.0.1"><span class="header-section-number">4.4.1.0.1</span> Auxiliary Variable MCMC Methods</h5>
<p><span class="math inline">\(f(x)\)</span>를 가지는 mv 분포에서의 샘플링을 생각해보자. <strong>Rao-Blackwellization</strong>이 MC 시뮬레이션에의 최우선원칙임은 알려져 있다. 시뮬레이션의 수렴을 좀 더 강화하기 위해 우리는 가능한한 많은 <span class="math inline">\(x\)</span>의 구성물을 integrate하는 것을 시도해보아야 한다. 하지만 이하의 두가지 경우(이외에도 존재)에 시뮬레이션을 양질로 만들기 위해 우리는 1개 이상의 변수를 추가하는 상황을 고려할 수 있다.
1. 타겟분포 <span class="math inline">\(f(x)\)</span>가 multimodal. 온도 혹은 아직 관측되지 않은 측정값과 같은 auxiliary variable이 계가 <strong>로컬 트랩</strong>에서 빠져나올 수 있도록 도움을 줌. multimodal 상황.
2. 타겟분포 <span class="math inline">\(f(x)\)</span>가 intractable normalizing constant 포함. <span class="math inline">\(X\)</span>의 auxiliary 실현값이 시뮬레이션에 포함됨으로써 시뮬레이션에서 normalizing constant 를 무력화시킴.</p>
<p>MH 알고리즘 $   $은 이하의 2가지 기본적인 부품을 가지고 있다.
1. 타겟분포 (左)
2. proposal 분포 (右)</p>
<p>이에 더해서 auxiliary variable 방법론은 이하의 2가지 방법으로 행해질 수 있다. 타겟과 제안 어느쪽에 변수를 추가하는지에 대한 이야기이다.
1. 타겟분포 augmentation 방법론: Augmenting auxiliary variables to the <strong>target</strong> distribution
* auxiliary variable <span class="math inline">\(u\)</span>와 조건부 분포 <span class="math inline">\(f(u \rvert x )\)</span>를 정의한다. joint 분포 <span class="math inline">\(f(x,u) = f(u \rvert x) f(x)\)</span>를 만들기 위해. 이후 MH 알고리즘이나 GS를 사용해 <span class="math inline">\((x,u)\)</span>를 업데이트. <span class="math inline">\(f(x)\)</span>의 샘플은 <span class="math inline">\((X, U)\)</span>의 실현값 <span class="math inline">\((x_1, u_1), \cdots, (x_N, u_N)\)</span>를 이용해 marginalization이나 프로젝션 등을 이용해 획득될 수 있다.
2. Method of Proposal Distribution Augmentation: Augmenting auxiliary variables to the <strong>proposal</strong> distribution.
* proposal 분포 <span class="math inline">\(T(x&#39;, u \rvert x)\)</span>를 특정하고, 이의 reversible version <span class="math inline">\(T(x, u \rvert x&#39;)\)</span>도 특정한다. 즉슨 <span class="math inline">\(\int T(x&#39;, u \vert x)du = T(x&#39; \vert x)\)</span>, <span class="math inline">\(\int T(x, u \vert x&#39;)du = T(x \vert x&#39;)\)</span>의 관계가 성립한다.<br> 이제 proposal <span class="math inline">\(T(x&#39;, u \vert x)\)</span> 로부터 후보 (candidate) 샘플 <span class="math inline">\(x&#39;\)</span>를 생산하고, 이를 with probability <span class="math inline">\(\min \left\{ 1, r(x, x&#39;, u) \right \}\)</span>. 이때 <span class="math inline">\(r(x, x&#39;, u) = \dfrac {f(x&#39;)} {f(x)} \dfrac {T(x,u \vert x&#39;)} {T(x&#39;,u \vert x)}\)</span>.</p>
<p>실현값 (realizations) <span class="math inline">\(x_1 , \cdots, x_N\)</span>을 생산할 때까지 이를 반복한다. 이제 <span class="math inline">\(N\)</span>이 충분히 크다면, 이 실현값들은 근사적으로 <span class="math inline">\(f(x)\)</span>에 의해 분포되어 있다.</p>
<p>이러한 방법론의 타당성은 이하를 통해 보일 수 있다.</p>
<p>$</p>
<p>K(x’ x) = _{} s(x, x’, u) du + (x=x’) </p>
<p>$</p>
<p>이는 <span class="math inline">\(x\)</span>로부터 <span class="math inline">\(x&#39;\)</span>로의 <strong><em>integrated transition kernel</em></strong>을 의미하며, 이때 <span class="math inline">\(s(x, x&#39;, u) = T(x&#39;, u \rvert x) \ast r(x, x&#39;, u)\)</span>. Then,</p>
<p>$</p>
<p>f(x) <em>{} s(x, x’, u) du = </em>{} du</p>
<p>$</p>
<p>이는 <span class="math inline">\(x\)</span>와 <span class="math inline">\(x&#39;\)</span> 에 대해 symmetric. 이는 곧 <span class="math inline">\(f(x)K(x&#39; \vert x) = f(x&#39;)K(x \vert x&#39;)\)</span> 임을 의미한다.</p>
<p><br>
<br>
<br></p>
<p>original density</p>
</div>
</div>
<div id="multimodal-target-distribution" class="section level3" number="4.4.2">
<h3 number="4.4.2"><span class="header-section-number">4.4.2</span> Multimodal Target Distribution</h3>
<div id="simulated-tempering" class="section level5" number="4.4.2.0.1">
<h5 number="4.4.2.0.1"><span class="header-section-number">4.4.2.0.1</span> Simulated Tempering</h5>
<p>분포 <span class="math inline">\(f(x) \propto \exp \left(-H(x) \right), x \in X\)</span> 에서 샘플링하는데에 관심이 있다고 하자. simulated annealing에서 그러했던 것처럼, simulated tempering <span class="math inline">\(f(x, T) \propto \exp \left( -\dfrac {H(x)} {T} \right)\)</span>로 타겟 분포를 확장시켰다. 이는 auxiliary variable인 temperture <span class="math inline">\(T\)</span>를 포함함으로서 이루어진다. <span class="math inline">\(T\)</span>는 <strong>사용자가 미리 지정한 값들의 finite set</strong>이 된다. <span class="math inline">\(H(x)\)</span>는 사실상 energy function.</p>
<p>Temperatur Transition Matrix <span class="math inline">\(T = \begin{bmatrix} q_{11} &amp; q_{12} &amp; \cdots &amp; q_{1n} \\ q_{21} &amp; \ddots &amp; &amp; \\ \vdots &amp; &amp; \ddots &amp; \\ q_{n1} &amp; \cdots &amp; &amp; q_{nn} \end{bmatrix}\)</span>. 이때 row는 current 온도 <span class="math inline">\(T_1, \cdots, T_n\)</span>, column은 행선지 온도.</p>
<hr />
<p><strong>Parallel Tempering</strong>은 인접한 온도로만 이동 가능 (가장 높은 온도에서 가장 낮은 온도로 한단계 한단계씩). 온도 자체를 시뮬레이션한게 아니라 온도의 chain이 주어져 있어 각 온도 간의 움직임을 만드는 것에 그친다. 따라서 이는 multiple chain을 이용하는 population MC 방법론 쪽에 소속됨.</p>
<p>Simulated Tempering과는 이 점에서 차이를 보임. 후자는 어느 온도로든 다 이동. 온도 매트릭스 만들어놓고, <span class="math inline">\(U(0,1)\)</span> 분포에서 온도 하나 생산하고 이 온도로 이동할 것인지의 여부를 MH 알고리즘으로 결정.</p>
<hr />
<p><span class="math inline">\(U(0,1)\)</span>에서 랜덤하게 숫자를 뽑고, <span class="math inline">\(j\)</span>의 값을 proposal transition matrix <span class="math inline">\((q_{ij})\)</span>에 따라서 정한다. <span class="math inline">\(u&lt;q_{11}\)</span>이면 <span class="math inline">\(T_1 \rightarrow T_1\)</span>, <span class="math inline">\(q_{11}&lt;u&lt;q_{11} + q_{12}\)</span>이면 <span class="math inline">\(T_1 \rightarrow T_2\)</span>, ….
- if <span class="math inline">\(j=i_t\)</span>, let <span class="math inline">\(i_{t+1}=i_t\)</span>, and let <span class="math inline">\(x_{t+1}\)</span>을 MH kernal <span class="math inline">\(K_{i_t}(x,y)\)</span>에서 뽑는다. 이때 <span class="math inline">\(K_{i_t}(x,y)\)</span>는 <span class="math inline">\(f(x, T_{i_t})\)</span>을 invariant distribution로 허용하는 아이이다. 즉 새로운 <span class="math inline">\(x\)</span>를 생산하면 된다.
- if <span class="math inline">\(j \not= i_t\)</span>, let <span class="math inline">\(x_{t+1}=x_t\)</span>하고 proposal을 이하의 <span class="math inline">\(Pr\)</span>에 따라 채택한다. 이때 <span class="math inline">\(Z\)</span>는 <span class="math inline">\(Z_i\)</span>의 측정값이다. 채택된다면 <span class="math inline">\(i_{t+1} = j\)</span>이고, 그외의 경우에는 <span class="math inline">\(i_{t+1} = i_t\)</span>로 한다. 새로운 <span class="math inline">\(x\)</span>를 생산하는 것이 아니라 들고 있던 <span class="math inline">\(x\)</span>를 쓰되, 이걸 accept 할건지 안할건지를 체크한다.</p>
<p>$
$</p>
<p>이때 $ {q_{i_t , j}} $는 proposal distribution이라고 생각할 수 있다. 나머지는 Likelihood part이며, 이때 <span class="math inline">\(\dfrac {\hat Z_j} {\hat Z_{i_t}}\)</span>가 normalizing constant의 ratio이다. 온도가 변화하였으므로 두 식의 normalizing constant가 같지 않기 때문이다.</p>
<p><br>
<br></p>
<hr />
<p>** ~~Issues on Simulated Tempering: ~~ **</p>
<ol style="list-style-type: decimal">
<li><strong>Temperature Ladder를 어떻게 고를 것인가.</strong> -&gt; 각 chain별로 이동이 원활하게 잡는 것이 핵심.
<ul>
<li>가장 높은 온도 <span class="math inline">\(T_1\)</span>은 대부분의 uphill move가 해당 레벨에서 accept 될 수 있도록 설정되어야 한다.</li>
<li>사이의(intermediate) 온도들은 sequential manner로 설정될 수 있다. <span class="math inline">\(T_1\)</span>에서 시작해서, 점차적으로 다음으로 낮은 온도를 <span class="math inline">\(Var_i \left\{ H(x) \right\} \ast \delta^2 = O(1)\)</span>을 만족하도록 설정하는 것이다. 이때 <span class="math inline">\(\delta = \dfrac {1}{T_{i+1}} - \dfrac{1}{T_i}\)</span>이며, <span class="math inline">\(Var_i(\cdot)\)</span>은 <span class="math inline">\(H(x)\)</span> (taken with respect to <span class="math inline">\(f(x, T_i)\)</span>) 의 분산을 의미한다.
<ul>
<li>이러한 조건들은 <span class="math inline">\(f(x,T_i), f(x,T_{i+1})\)</span> 사이에 상당히 겹치는 점이 많아야 한다는 것을 의미하기도 한다. 실전에선 <span class="math inline">\(Var_i \left( H(x) \right)\)</span>는 샘플러를 레벨 <span class="math inline">\(T_i\)</span>에서 예비적으로(preliminary) 돌려보았던 결과에서 러프하게나마 예측될 수 있다.<br />
</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(Z_i\)</span>를 어떻게 estimate 할 것인가.</strong> -&gt; accept 여부가 normalizing constant에도 의존해서 이거 이상하게 고르면 효율 떨어짐. 엄청난 단점이라서 요즘은 이 알고리즘 자체를 잘 안씀
<ul>
<li>이는 simulated tempering의 효율에 직결되는 부분이다. <span class="math inline">\(Z_i\)</span>들이 잘 estimate 되었다면, simulated tempering은 temperature ladder을 따라 <strong>symmetric RW</strong>처럼 동작한다. (<span class="math inline">\(x\)</span>-updating step을 제하고 볼 경우) 그렇지 않다면 이는 특정 temperature 레벨에서 멈춰버린다. 시뮬레이션이 실패함은 물론이다(rendering). <br> 실전에서 <span class="math inline">\(Z_i\)</span>들은 stochastic approximation MC 방법론을 사용해서 estimate 가능하다. 혹은 reverse logistic regression 방법론을 사용해서도 <span class="math inline">\(Z_i\)</span>를 estimate 할 수 있다.</li>
</ul></li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="slice-sampler" class="section level5" number="4.4.2.0.2">
<h5 number="4.4.2.0.2"><span class="header-section-number">4.4.2.0.2</span> Slice Sampler</h5>
<p>density <span class="math inline">\(f(x), \; \; \; x \in \chi\)</span>에서 샘플링하고자 한다. $ x f(x)$에서 샘플링하는 것은, <span class="math inline">\(f(x)\)</span> 그래프 이하의 영역에서 uniform하게 샘플링하는 것과 동등하다. 해당 영역은 <span class="math inline">\(A = \{ (x,u): 0 \le u \le f(x) \}\)</span>이며, 이것이 acceptance-rejection 알고리즘의 기초(basis)였다. 이 목적을 달성하기 위해 우리는 타겟분포 <span class="math inline">\(f\)</span>를 auxiliary variable <span class="math inline">\(U\)</span>를 사용하여 확장해볼 수 있다. 이 <span class="math inline">\(U\)</span>는, <span class="math inline">\(x\)</span>에 대해서 조건부일 때, 구간 <span class="math inline">\([0, f(x)]\)</span>에서 uniform하게 분포되어 있다.</p>
<p><img src="4-2.png"></p>
<p>따라서, <span class="math inline">\((X, U)\)</span>의 joint density function은 <span class="math inline">\(f(x,u)=f(x)f(u \rvert x) \propto I_{(x,u)\in \textit A}\)</span>. 후자의 인디케이터는 언급되었던 영역 안에 속한다는 의미. 이는 GS에 의해 이하와 같이 샘플링 가능하다.
1. draw <span class="math inline">\(u_{t+1} \sim U[0, f(x_t)]\)</span>.
2. draw <span class="math inline">\(x_{t+1}\)</span> uniformly from the region <span class="math inline">\(\{ x: f(x) \ge u_{t+1} \}\)</span>.</p>
<p>위의 샘플러는 <strong>slice sampler</strong>라고 불림. 이는 multimodal 분포들에 대해 단순 MH 알고리즘보다 더 나을 가능성이 있음. slice 때문에 b/w-mode-transition에 자유롭기 때문. 현재도 핫한 샘플러중 하나임. horseshoe prior 에서의 패러미터 estimate에 대표적으로 이녀석이 쓰인다.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="doubly-intractable-normalizing-constants" class="section level3" number="4.4.3">
<h3 number="4.4.3"><span class="header-section-number">4.4.3</span> Doubly-intractable Normalizing Constants</h3>
<p>Spatial models, e.g., the autologistic model, the Potts model, and the autonormal model (Besag, 1974)는 많은 과학적 문제들을 위한 모델링에 쓰이고 있음. 이러한 모델들에 해당하는 주요한 문제는 normalizing constant가 doubly-intractable하다는데 있음.</p>
<p>for dataset <span class="math inline">\(X\)</span>, 패러미터 <span class="math inline">\(\theta\)</span>, normalizing constant <span class="math inline">\(\kappa (\theta)\)</span>. 이때 <span class="math inline">\(\kappa (\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 의존하나 closed form으로는 만들 수 없음. 이하는 dataset을 생산한 likelihood function.</p>
<p>$
<span class="math display">\[\begin{align*}
X \sim f(x \vert \theta) = \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \}, &amp;x \in \mathcal{X}, &amp;\theta \in \Theta
\end{align*}\]</span>
$</p>
<p><span class="math inline">\(\pi(\theta)\)</span>는 <span class="math inline">\(\theta\)</span>의 prior. 이 경우 post는 <span class="math inline">\(f(\theta \vert x) \propto \dfrac{1}{\kappa (\theta)} exp \{ -U(x, \theta) \} \ast \pi(\theta)\)</span>.</p>
<p><br>
<br></p>
<div id="boltzmann-density" class="section level5" number="4.4.3.0.1">
<h5 number="4.4.3.0.1"><span class="header-section-number">4.4.3.0.1</span> Boltzmann Density</h5>
<p>known as <strong>Ising Model</strong>, 그리고 ~로 확장될 경우 <strong>autologistic model</strong>.</p>
<p>Consider a 2-D Ising model with the Boltzmann density</p>
<p>$</p>
<p>f(x) { K _{ij} x_i x_j }</p>
<p>$</p>
<ul>
<li>spins <span class="math inline">\(x_i = \pm 1\)</span> (S극이 -1)</li>
<li><span class="math inline">\(K\)</span>는 inverse temperature (measure for interaction : <span class="math inline">\(x_i\)</span>가 주변에 있는 값과 얼마나 많은 같은 값을 가지는지, 다른 값을 가지는지에 대해 측정해주는 패러미터) 온도가 낮을수록 interaction가 강해지며, 이에 의해 동일값 확률이 높아짐.</li>
<li><span class="math inline">\(i\sim j\)</span>는 lattice 상의 가장 가까운 neighbors.</li>
</ul>
<p>온도가 높다면, 이 모델은 GS를 사용해 쉽게 시뮬레이션 가능하다. 조건부 분포에 따라 각 spin의 값을 iteratively 초기화한다. 아래의 식에서 <span class="math inline">\(n(i)\)</span>는 spin <span class="math inline">\(i\)</span>의 neighbors의 집합 (set). 이하의 수식은 autologistic 과 그 과정이 유사하다.</p>
<p>$
<span class="math display">\[\begin{align*}

P(x_i =1 \vert x_j, \; \; j \in n(i)) &amp;= \dfrac {1}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} \\
P(x_i =-1 \vert x_j, \; \; j \in n(i)) &amp;= \dfrac {\exp \left \{ -2K \sum_{j \in n(i)} \right\}}{1+ \exp \left \{ -2K \sum_{j \in n(i)} \right\}} &amp;= 1- P(x_i =1 \vert x_j, \; \; j \in n(i))

\end{align*}\]</span>
$</p>
<p>하지만, GS는 temperature가 critical temperature로 근접하거나 이하로 내려갈 경우 GS가 빠르게 느려진다. 온도가 낮으면 interaction이 강해져, 주변값과 비슷한 값을 generate 해야만 하기 때문이다. 이렇게 샘플링이 어려워지는 지점, 온도를 <strong>critical point</strong>라고 부른다. 이는 대략 <span class="math inline">\(\theta \approx 0.43\)</span>. 이것이 소위 <strong>critical slowing down</strong> 이라고 불리는 현상이다.</p>
<div id="perfect-sampler" class="section level6" number="4.4.3.0.1.1">
<h6 number="4.4.3.0.1.1"><span class="header-section-number">4.4.3.0.1.1</span> Perfect Sampler</h6>
<p>과거 샘플들의 굉장히 많은 조합을 커플링해서 샘플을 생산. previous realization 전체에 대해 (이는 그 이전의 샘플, 아니면 그 이전의 샘플, 혹은 original 데이터에 대해서조차도) independent한 샘플을 생산해내는 sampler. 즉 그 어떤 것에서도 independent한 sample을 생산해낸다. 문제는 이 샘플러는 <span class="math inline">\(\theta&gt;0.43\)</span>인 순간 바로 작동을 안함. <span class="math inline">\(\theta&gt;0.32, 0.35\)</span> 정도로 엔간 크기만 해도 드럽게 느림.</p>
<p><br>
<br>
<br></p>
</div>
<div id="swendsen-wang-algorithm" class="section level6" number="4.4.3.0.1.2">
<h6 number="4.4.3.0.1.2"><span class="header-section-number">4.4.3.0.1.2</span> Swendsen-Wang Algorithm</h6>
<p>slice sampling에서 Boltzmann 덴시티는 이하의 형으로 다시 쓰여진다. 이때 <span class="math inline">\(\beta = 2K\)</span>. indicator function으로 변형했을 때 저 둘이 어떻게 equation이 성립하는지 유의.</p>
<p>$</p>
<p>f(x)</p>
<p>; </p>
<p>; _{ij} { K(1+x_i x_j) }</p>
<p>; =</p>
<p>; _{ij} { </p>
<p>(x_i = x_j)</p>
<p>}</p>
<p>$</p>
<p>이때 우리가 auxiliary variable <span class="math inline">\(\pmb u = (u_{i \sim j})\)</span>, where each component <span class="math inline">\(u_{i \sim j}\)</span>, conditional on <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>, is uniformly distributed on <span class="math inline">\(\left[ 0, \; \exp \{\beta \ast \mathbf{1}(x_i = x_j)\} \right]\)</span>, then</p>
<p>$</p>
<p>f(x, u)</p>
<p>; ;</p>
<p><em>{i j}  ( 0 u</em>{i j } {  (x_i = x_j) } )</p>
<p>$</p>
<p>이때 <span class="math inline">\(u_{i \sim j}\)</span> 자체는 <strong>bond variable</strong>이라고 명명된다. 이는 spin <span class="math inline">\(i\)</span>와 spin <span class="math inline">\(j\)</span> 사이의 가장자리에 물리적으로 앉아 있는 변수로서 생각될 수 있다. (i와 j가 묶여져 있는지, 같은 group 안에 존재하는 것인지 아닌지에 대한 indicator가 되는 variable)
* if <span class="math inline">\(u_{i \sim j}&gt;1\)</span>, then <span class="math inline">\(\exp \left\{ \beta \ast \mathbf{1}(x_i = x_j) \right \}&gt;1\)</span>, 따라서 반드시 <span class="math inline">\(x_i = x_j\)</span>.
* if <span class="math inline">\(u_{i \sim j}&lt;1\)</span>, 이 경우 <span class="math inline">\(x_i, x_j\)</span>에 제약 (constraint) 이 없다.</p>
<p><span class="math inline">\(b_{i \sim j}\)</span>가 제약에 대한 indicator variable이라고 정의하자. 즉, <span class="math inline">\(x_i, x_j\)</span>가 같도록 제약되었다면, <span class="math inline">\(b_{i \sim j}=1\)</span>이며 이외엔 0이다. for any 2개의 “like-spin” (i.e. 2개의 spin이 같은 값을 가진다) neighbors에 대해서, 이 둘은 with probability <span class="math inline">\(1-\exp (-\beta)\)</span>를 따라 bonded 될 수 있는 가능성이 있음을 기억하라. <span class="math inline">\(\pmb u\)</span>의 설정 (configuration)에 따라, “mutual bond” (i.e., <span class="math inline">\(b_{i \sim j}=1\)</span>) 을 통하여 연결될 수 있는지 없는지 여부에 따라 spin들을 군집 (cluster) 할 수 있다. (위에서 i와 j가 같다고 indicator가 판별했을 경우에만 이런 cluster 로 묶는 것이 가능하다) Then 동일 클러스터 내의 모든 spin은 같은 값을 가질 것이다. 또한 군집 내부의 모든 spin을 동시에 뒤집는 (flip) 것은 <span class="math inline">\(f(\pmb x , \pmb u)\)</span>의 평형 (equilibrium)을 해치지 않을 것이다.</p>
<p>Proceeds:
1. Update the bond values: check all “like-spin” neighbors, and set <span class="math inline">\(b_{i \sim j}=1\)</span> with probability <span class="math inline">\(1-\exp (-\beta)\)</span>.
2. Update the spin values: Cluster spins by connecting neighboring sites with a mutual bond, and then flip each cluster with probability <span class="math inline">\(0.5\)</span>.</p>
<p>For the Ising model, the introduction of the auxiliary variable <span class="math inline">\(\pmb u\)</span> has the dependence between neighboring spins partially decoupled, and the resulting sampler can thus converge substantially faster than the single site updating algorithm. As demonstrated by Swendsen and Wang (1987), this algorithm can eliminate much of the <strong>critical slowing down</strong>.</p>
<p><img src = "4-3.png"></p>
<p>같은 값들이 모여있는 cluster를 판별하여 각각을 grouping. grouping을 랜덤으로 하므로 인접해 있는 동일값임에도 그룹에 포함되지 못하는 경우가 존재함. Swendsen-Wang에서는 이렇게 그룹을 만든 후, 해당 그룹을 통채로 toggling. group을 통채로 토글링하기 때문에 dependency가 있는 것들이 통채로 toggling되어서 dependency가 있는 것들은 나머지 것들과 인제 이렇게 independent한 것도 있지만 dependent한 것을 통채로 묶어서 하는 것이므로 좀더 한꺼번에 뒤집으니까 실제로 우리가 업데이트하는 것은 group 내부 말고 group 외부 간들에는 independent하다고 가정될 수 있는 몇몇개의 group들만이 남음. 이 덩어리들을 한꺼번에 업데이트하므로 따라서 샘플러 generate가 상대적으로 쉬움. 하지만 이 만든 덩어리는 매 이터레이션마다 덩어리를 새로 만들어야 함. 매 이터레이션마다 클러스터를 새로 만들고 flip하여 이를 accept할지 말지를 결정하는 이런 형태의 구조를 가짐.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="møollers-algorithm" class="section level5" number="4.4.3.0.2">
<h5 number="4.4.3.0.2"><span class="header-section-number">4.4.3.0.2</span> <del>Møoller’s Algorithm</del></h5>
<p>auxiliary variable <span class="math inline">\(y\)</span>, 이는 <span class="math inline">\(x\)</span>와 같은 state space를 공유한다고 정의. 그 경우 이하의 joint pdf <span class="math inline">\(f\)</span> 를 생각해볼 수 있다. <span class="math inline">\(f(y \vert \theta , x)\)</span>는 <span class="math inline">\(y\)</span>의 분포.</p>
<p>$
f(, y x) = f(x ) f() f(y , x)
$</p>
<p>$ f(, y x) $ 에서 MH 알고리즘을 통해 시뮬레이트하기 위해서는 이하와 같은 제안분포 <span class="math inline">\(q\)</span> 를 사용해볼 수 있다. 이는 패러미터 벡터 <span class="math inline">\(\theta \rightarrow \theta&#39;\)</span>의 usual change에 상응하며, 이 후에는 <span class="math inline">\(q(\cdot \vert \theta &#39; )\)</span>에서 <span class="math inline">\(y&#39;\)</span>를 추출하는 exact sampling step이 따른다.</p>
<p>$</p>
<p>q(’ , y’ , y) = q(‘, y) q(y’ ’)</p>
<p>$</p>
<p><span class="math inline">\(q(y&#39; \vert \theta &#39; )\)</span>가 <span class="math inline">\(f(y&#39; \vert \theta)\)</span>로 설정되었다면, MH ratio <span class="math inline">\(r\)</span>은 이하와 같이 쓰일 수 있다. 이때 unknown normalizing constant <span class="math inline">\(\kappa(\theta)\)</span>가 상쇄 (cancel) 되었음에 주목하라.</p>
<p>$
<span class="math display">\[\begin{align*}

r(\theta, y, \theta&#39;, y&#39; \vert x)

&amp;= 


\dfrac 
{f(x \vert \theta&#39;) f(\theta&#39;) f(y&#39; \vert \theta&#39; , x) \ast q(\theta\vert \theta&#39; , y&#39;) q(y \vert \theta)} 
{f(x \vert \theta) f(\theta) f(y \vert \theta , x) \ast q(\theta&#39;\vert \theta , y) q(y&#39; \vert \theta&#39;)}

 \\

&amp;= 

\dfrac {f(\theta&#39;, y&#39; \vert x)}{f(\theta, y \vert x)} \ast 
\dfrac {q(\theta , y \vert \theta&#39; , y&#39;))}{q(\theta&#39; , y&#39; \vert \theta , y)}


 \\
&amp;=

\dfrac
{
\dfrac {f(\theta&#39;, y&#39; \vert x)}{q(\theta&#39; , y&#39; \vert \theta , y)} 
}
{
\dfrac{f(\theta, y \vert x) }{q(\theta , y \vert \theta&#39; , y&#39;))}
}



\end{align*}\]</span>
$</p>
<p>여기서 계산을 간단하게 하기 위해 제안분포 <span class="math inline">\(q\)</span>와 auxiliary distribution을 이하와 같이 정리하는 것을 생각해볼 수 있다. 이때 <span class="math inline">\(\hat \theta\)</span>는 <span class="math inline">\(\theta\)</span>의 estimate로써, 예를 들어 pseudo-likelihood function을 극대화하는 것으로 얻어진 값이다.</p>
<p>$
<span class="math display">\[\begin{align*}

q(\theta&#39; \vert \theta , y) &amp;= q(\theta&#39; \vert \theta ) , q(\theta \vert \theta &#39;, y&#39;) &amp;= q(\theta \vert \theta &#39;) \\

f(y \vert \theta , x) &amp;= f(y \vert \hat \theta ), f(y&#39; \vert \theta&#39; , x) &amp;= f(y&#39; \vert \hat \theta )

\end{align*}\]</span>
$</p>
<p>분포 <span class="math inline">\(f(x \vert \theta)\)</span>를 auxiliary variable, 가령 normalizing constant ratio <span class="math inline">\(\dfrac {\kappa(\theta)} {\kappa(\theta&#39;)}\)</span> 등으로 살찌워놓은 것은, 시뮬레이션 진행 과정에서 상쇄시키는 것이 가능하다.
1. generate <span class="math inline">\(\theta \sim q(\theta&#39; \vert \theta_t)\)</span>
2. generate exact sample <span class="math inline">\(y&#39; \sim f(y \vert \theta&#39;)\)</span>
3. accept <span class="math inline">\((\theta&#39;, y&#39;)\)</span> with probability <span class="math inline">\(\min (1, r)\)</span>, <span class="math inline">\(r=\dfrac {f(x \vert \theta&#39;) f(\theta&#39;) f(y&#39; \vert \hat \theta&#39;) \ast q(\theta_t \vert \theta&#39;) q(y \vert \theta_t)} {f(x \vert \theta_t) f(\theta_t) f(y \vert \hat \theta) \ast q(\theta&#39;\vert \theta_t) q(y&#39; \vert \theta&#39;)}\)</span>.
* 채택된다면, set <span class="math inline">\((\theta_{t+1}, y_{t+1}) = (\theta&#39;, y&#39; )\)</span>.
* o.w., <span class="math inline">\((\theta_{t+1}, y_{t+1}) = (\theta_t, y&#39;_t)\)</span>.</p>
<p><br>
<br></p>
</div>
<div id="exchange-algorithm" class="section level5" number="4.4.3.0.3">
<h5 number="4.4.3.0.3"><span class="header-section-number">4.4.3.0.3</span> Exchange Algorithm</h5>
<p>Møller’s 알고리즘을 <strong>parallel tempering</strong> 개념을 도입하여 개선.
1. propose candidate point $’ $ proposal distribution <span class="math inline">\(q(\theta&#39; \vert \theta, x)\)</span>.
2. propose auxiliary variable <span class="math inline">\(y \sim\)</span> perfect sampler <span class="math inline">\(f(y \vert \theta &#39; )\)</span>.
3. accept $’ $ with probability <span class="math inline">\(\min \{ 1, r(\theta, \theta&#39; \vert x) \}\)</span>.
- <span class="math inline">\(r(\theta, \theta&#39; \vert x) = \dfrac{\pi(\theta&#39;) }{\pi(\theta) } \ast \dfrac{f(x \vert \theta &#39;) }{f(x \vert \theta)} \ast \dfrac{f(y \vert \theta) }{f(y \vert \theta&#39;)} \ast \dfrac{f(\theta \; \vert \theta&#39;, x) }{f(\theta&#39; \vert \theta, x)}\)</span></p>
<p>The exchange algorithm can be viewed as an auxiliary variable MCMC algorithm with the proposal distribution being augmented, for which the proposal distribution can be written as</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

T \left( \theta \rightarrow (\theta&#39; , y) \right) &amp;= q(\theta &#39; \vert \theta) f(y \vert \theta &#39;) \\
T \left( \theta&#39; \rightarrow (\theta , y) \right) &amp;= q(\theta \vert \theta &#39; ) f(y \vert \theta)


\end{align}\]</span>
$</p>
<p>This simply validates the algorithm, following the arguments for auxiliary variable Markov chains.</p>
<p>The exchange algorithm generally improves the performance of the Møller algorithm, as it avoids an initial estimation step (for <span class="math inline">\(\theta\)</span>) that required by the Møller.</p>
<p>Although the Møller’s and exchange algorithms work well for some discrete models, such as the Ising and autologistic models, they cannot be applied to many other models for which perfect sampling is not available.</p>
<p>Even for the Ising and autologistic models, perfect sampling may be very expensive when the temperature is near or below the critical point.</p>
<hr />
</div>
<div id="adaptive-exchange-algorithm" class="section level5" number="4.4.3.0.4">
<h5 number="4.4.3.0.4"><span class="header-section-number">4.4.3.0.4</span> Adaptive Exchange Algorithm</h5>
<p>Object</p>
<p>An adaptive exchange algorithm (AEX) is an adaptive Monte Carlo version of the exchange algorithm, where the auxiliary variables are generated via an importance sampling procedure from a Markov chain running in parallel.</p>
<ul>
<li>Advantage
<ul>
<li>Removes the requirement of perfect sampling</li>
<li>Overcomes its theoretical difficulty caused by inconvergence of finite MCMC runs</li>
</ul></li>
</ul>
<p>AEX consists of two chains running in parallel.</p>
<p>The first chain is <strong>auxiliary</strong>, which is run in the space <span class="math inline">\({\mathcal{x}}\)</span> with an aim to draw samples from a family of distributions <span class="math inline">\(f(X \vert \theta^{(1)}), \; \; \cdots, \; \; f(X \vert \theta^{(m)})\)</span> for a set of pre-specified parameter values <span class="math inline">\(\theta^{(1)}, \; \cdots, \; \theta^{(m)}\)</span>.</p>
<p>The second chain is the <strong>target</strong> chain, which is run in the space <span class="math inline">\(\theta\)</span> with an aim to draw samples from the target posterior <span class="math inline">\(\pi(\theta \vert y)\)</span>. For a candidate point <span class="math inline">\(\theta&#39;\)</span>, the auxiliary variable <span class="math inline">\(x\)</span> is resampled from the past samples of the auxiliary chain via an importance sampling procedure.</p>
<p>Assume that the neighboring distributions <span class="math inline">\(f(X \vert \theta^{(i)})\)</span>’s have a reasonable overlap and the set <span class="math inline">\(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\)</span> has covered the major part of the support of <span class="math inline">\(\pi (\theta \vert y)\)</span>.</p>
<ul>
<li>ALGORITHM: PART 1 - (Auxiliary Chain) Auxiliary Sample Collection via SAMC</li>
</ul>
<ol style="list-style-type: decimal">
<li>(Sampling) Choose to update <span class="math inline">\(\vartheta\)</span> or <span class="math inline">\(\pmb z_t \vert \vartheta\)</span> with pre-specified probabilities, e.g., <span class="math inline">\(0.75\)</span> for updating <span class="math inline">\(\vartheta\)</span> and <span class="math inline">\(0.25\)</span> for updating <span class="math inline">\(z_t\)</span>.</li>
</ol>
<p>1-a. Update <span class="math inline">\(\vartheta_{t}\)</span> : Draw <span class="math inline">\(\vartheta &#39;\)</span> from the set <span class="math inline">\(\left \{ \theta^{(1)}, \; \cdots, \; \theta^{(m)} \right \}\)</span> according to a proposal distribution <span class="math inline">\(T_1 ( \; \cdot \; \vert \vartheta_{t})\)</span>,</p>
<p>set <span class="math inline">\((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta &#39; , \pmb z_{t+1} )\)</span> with probability <span class="math inline">\(\min \left\{ 1, \; \; \dfrac{\omega_t^{J(\vartheta_t)}}{\omega_t^{J(\vartheta &#39;)}} \ast \dfrac {\varphi (\pmb z_{t} \vert \vartheta &#39;)} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_1 (\vartheta_{t} \vert \vartheta &#39; )}{T_1 (\vartheta &#39; \vert \vartheta_{t} )} \right\}\)</span>,</p>
<p>and set <span class="math inline">\((\vartheta_{t+1}, \pmb z_{t+1}) = (\vartheta_{t}, \pmb z_t)\)</span> with remaining probability, where <span class="math inline">\(J(\vartheta_t)\)</span> denotes the index of <span class="math inline">\(\vartheta_t\)</span>, i.e., <span class="math inline">\(J(\vartheta_t) = j\)</span> if <span class="math inline">\(\vartheta_t = \theta_i^{(k)}\)</span> and <span class="math inline">\(\varphi(\pmb z \vert \vartheta)\)</span> is an unnormalized density of <span class="math inline">\(f(\pmb z \vert \vartheta)\)</span>.</p>
<p>1-b. Update <span class="math inline">\(\pmb z_t\)</span> : Draw <span class="math inline">\(\pmb z &#39;\)</span> according to a proposal distribution <span class="math inline">\(T_2 ( \; \cdot \; \vert \pmb z_t)\)</span>,</p>
<p>set <span class="math inline">\((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z &#39; , \vartheta_{t})\)</span> with probability <span class="math inline">\(\min \left\{ 1, \; \; \dfrac {\varphi (\pmb z &#39; \vert \vartheta_{t})} {\varphi (\pmb z_{t} \vert \vartheta_{t})} \ast \dfrac{T_2 (\pmb z_{t} \vert \pmb z &#39; )}{T_2 (\pmb z &#39; \vert \pmb z_{t} )} \right\}\)</span>,</p>
<p>and set <span class="math inline">\((\pmb z_{t+1} , \vartheta_{t+1}) = (\pmb z_t , \vartheta_{t})\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>(Abundance Factor Updating) Set</li>
</ol>
<p>$</p>
<p>(<em>{t+0.5}^{(j)}) =(</em>{t}^{(j)}) + a_{t+1} (e_{t+1, ; j} - p_j), ; ; ; ; ; j=1, , m</p>
<p>$</p>
<p>where <span class="math inline">\(e_{t+1, \; j} = \begin{cases} 1 &amp; &amp;&amp; \vartheta^{t+1} = \theta^{(j)} \\ 0 &amp; &amp;&amp; o.w. \end{cases}\)</span>.</p>
<p>If <span class="math inline">\(\omega_{t+0.5}^{(j)} \in \mathcal{K}_{\varsigma_t}\)</span>, set <span class="math inline">\((\omega_{t+1}, \pmb z_{t+1}) = (\omega_{t+0.5}, \pmb z_{t+1})\)</span> and <span class="math inline">\(\varsigma_{t+1} = \varsigma_t\)</span>.
o.w., set <span class="math inline">\((\omega_{t+1}, \pmb z_{t+1}) = \mathbb{T}(\omega_{t}, \pmb z_{t})\)</span> and <span class="math inline">\(\varsigma_{t+1} = \varsigma_t + 1\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>(Auxiliary Sample Collection) Append the sample <span class="math inline">\(\left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right)\)</span> to the collection <span class="math inline">\(S_t\)</span>. Denote the new collection by <span class="math inline">\(S_{t+1}\)</span> which is set by <span class="math inline">\(S_{t+1} = S_t \cup \left\{ \left(\pmb z_{t+1} , \vartheta_{t+1}, \omega_{t+1}^{J(\vartheta_{t+1}} \right) \right\}\)</span>.</li>
</ol>
<ul>
<li>ALGORITHM: PART 2 - (Target Chain) Adaptive Exchange Sampler</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>(Proposal) Propose a candidate point <span class="math inline">\(\theta &#39;\)</span> from a proposal distribution <span class="math inline">\(q(\theta &#39; \vert \theta)\)</span></p></li>
<li><p>(Resampling for Auxiliary Variables) Resample an auxiliary variable <span class="math inline">\(\pmb x\)</span> from the collection <span class="math inline">\(S_{t+1}\)</span> via a dynamic importance sampling procedure;</p></li>
</ol>
<p>that is, setting <span class="math inline">\(\pmb x = \pmb z_k\)</span> with probability</p>
<p>$</p>
<p>P(x = z_k)</p>
<p>{<em>{j=1}^{S</em>{t+1} } _t^{( J(<em>j) )}  {(z_k <em>j ’ )} I(z_j = z_k )}
{</em>{j=1}^{S</em>{t+1} } _t^{( J(_j) )}  {(z_k _j ’ )}}</p>
<p>$</p>
<ul>
<li><span class="math inline">\(\left(\pmb z_{j} , \vartheta_{j}, \omega_{t}^{J(\vartheta_{j}} \right)\)</span> denotes the <span class="math inline">\(j\)</span>-th element of the set <span class="math inline">\(S_{t+1}\)</span>.</li>
<li><span class="math inline">\(\vert S_{t+1} \vert\)</span>는 <span class="math inline">\(S_{t+1}\)</span>의 size.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>(Exchange Algorithm) Set <span class="math inline">\(\theta_{t+1} = \theta &#39;\)</span> with the probability <span class="math inline">\(\alpha(\theta_t , \pmb x, \theta&#39; )\)</span>, and <span class="math inline">\(\theta_{t+1} = \theta_{t}\)</span> with probability <span class="math inline">\(1-\alpha(\theta_t , \pmb x, \theta&#39; )\)</span>.</li>
</ol>
<p>$</p>
<p>(_t , x, ’ ) =</p>
<p> {(_t )}</p>
<p> {(y _t )}</p>
<p> {q(’ _t )}</p>
<p> {(x ’ )}</p>
<p>$</p>
<ul>
<li>Why this algorithm is adaptive?</li>
</ul>
<p>Since the underlying true proposal distribution for generating auxiliary variables in part II is changing from iteration to iteration, the new algorithm falls into the class of adaptive MCMC algorithms (for which the proposal distribution is changing from iteration to iteration).</p>
<!--chapter:end:211204_AuxiliaryVariableMCMC.Rmd-->
</div>
</div>
</div>
<div id="approximate-bayesian-computation" class="section level2" number="4.5">
<h2 number="4.5"><span class="header-section-number">4.5</span> Approximate Bayesian Computation</h2>
<p>Likelihood를 사용하지 않고 Summary Stat을 사용함. 이와 같은 성질로 인해 Likelihood-free inference라고도 불리며, 이의 근거는 simulator-based model (모델 자체를 data generation process라고 보는 것. 모델을 통해 data를 생산해내는 것이 가능하다는 소리). 모델이 있으면, 이 모델과 대응하는 패러미터가 존재할 것. 이 모델 자체를 하나의 data generating process라고 본다면, 당연히 우리는 Auxiliary Data를 생산하는 것 또한 가능. 이 AD를 생산하는 것이 가능하기 때문에, 이렇게 생산한 AD 데이터가 기존 데이터 (original data) 와 얼마만큼 가까운지, 아니면 얼마만큼 떨어져 있는지를 체크하는 것이 ABC 방법론. 이것이 충분히 가깝다면 우리가 가지고 있는 패러미터를 패러미터의 샘플로 인정하는 것이 가능하다는 것. 이때 직접 AD와 OD를 비교하는 것인 대단히 어려우므로 대체재로 Summary Stat을 사용함. 이것이 ABC 방법론의 핵심. 이는 genetics에서 개발됨.</p>
<div id="simulator-based-models" class="section level3" number="4.5.1">
<h3 number="4.5.1"><span class="header-section-number">4.5.1</span> Simulator-Based Models</h3>
<p><strong>deterministic model</strong>은 뭐임?</p>
<p>모든 모델이 pdf <span class="math inline">\(p(y \vert \theta)\)</span>의 family로 특정되는 것은 아님.</p>
<ul>
<li>Simulator-based Models: Models which are specified via a mechanism (rule) for generating data.</li>
</ul>
<p>Models specified via a data generating mechanism occur in multiple and diverse scientific fields.</p>
<ul>
<li>Different communities use different names for simulator-based models:
<ul>
<li>Generative Models: 데이터를 생성해주는 메커니즘을 연구하는 모델</li>
<li>Implicit Models</li>
<li>Stochastic Simulation Models</li>
<li>Probabilistic Programs</li>
</ul></li>
<li>Examples
<ul>
<li>Astrophysics: Simulating the formation of galaxies, stars, or planets.</li>
<li>Evolutionary Biology: Simulating Evolution</li>
<li>Neuroscience: Simulating Neural Circuits</li>
<li>Ecology: Simulating Species Migration</li>
<li>Health Science: Simulating the spread of an infectious disease</li>
</ul></li>
<li>Advantages of Simulator-Based Models
<ul>
<li>Direct implementation of hypotheses of how the observed data were generated. obs가 어떻게 생산되었는지에 대한 가설을 입증할 수 있는 하나의 방법이 됨.</li>
<li>Neat interface with physical or biological models of data. 갖고 있는 데이터는 한둘에서 끝나고 이의 variation을 고려하는 것이 중요한데 이 variation을 연구하는건 데이터 한둘로는 어려움. 이때 가지고 있는 데이터를 replicate하고 simulator-based model을 이용해 비슷한 데이터를 만들어내서 variation을 연구해 좀더 정확한 inference를 가능케 하고, 그러면서 uncertainty quantification도 가능하게 함.<br />
</li>
<li>Modeling by replicating the mechanisms of nature which produced the</li>
<li>observed/measured data. (“Analysis by synthesis”)</li>
<li>Possibility to perform experiments.</li>
</ul></li>
<li>Disadvantages of Simulator-Based Models
<ul>
<li>Generally elude analytical treatment. analytic한 solution이 없어 수학적 증명이 어려움. Approximate BC인 이유가 여기 있음</li>
<li>Can be easily made more complicated than necessary.</li>
<li>Statistical inference is difficult but possible.</li>
</ul></li>
<li>Family of pdfs Induced by the Simulator:</li>
</ul>
<p>For any fixed <span class="math inline">\(\theta\)</span> (패러미터 <span class="math inline">\(\theta\)</span> 는 주어져 있다는 소리), the output of the simulator <span class="math inline">\(y_\theta = g( \cdot \; , \theta)\)</span> is a <strong>random variable</strong>. 즉 <span class="math inline">\(\theta \longrightarrow y_\theta\)</span>. No closed-form available for <span class="math inline">\(p(y \vert \theta)\)</span>, and Simulator defines the model pdfs <span class="math inline">\(p(y \vert \theta)\)</span> implicitly.</p>
<table style="width:7%;">
<colgroup>
<col width="6%" />
</colgroup>
<tbody>
<tr class="odd">
<td><br>
<br>
<br></td>
</tr>
<tr class="even">
<td>### Approximate Bayesian Computation (ABC)</td>
</tr>
<tr class="odd">
<td>##### Intractability</td>
</tr>
<tr class="even">
<td>$
(D ) = 
$</td>
</tr>
<tr class="odd">
<td>- Usual intractability in Bayesian inference is not knowing <span class="math inline">\({\pi (D)}\)</span>, which is marginal Likelihood of Data.
- <span class="math inline">\(\pi (D \vert \theta) = \kappa(\theta)\pi (D \vert \theta)\)</span> 인 경우라면, MH 알고리즘을 사용하면 됨. 계산 과정에서 <span class="math inline">\(\pi (D \vert \theta)\)</span>가 캔슬되니까. 그러나 <span class="math inline">\(\pi (D \vert \theta) = \kappa(\theta)f (D \vert \theta)\)</span>, <span class="math inline">\(f (D \vert \theta)\)</span> 가 unnormalized density인 경우라면 이는 <strong>doubly-intractable</strong> 케이스. 캔슬도 안되고 고려해줄수밖에 없음. (with <span class="math inline">\(\kappa(\theta)\)</span> unknown.)
- ABC가 해법이 된다. 만능은 아님. 적용에 약간 회의적.
- A problem is <strong>completely-intractable</strong> if <span class="math inline">\(\pi (D \vert \theta)\)</span> is unknown and cannot be evaluated (unknown is subjective). That is, if the analytic distribution of the simulator, <span class="math inline">\(f(\theta)\)</span> run at <span class="math inline">\(\theta\)</span> is unknown. 모델이 지나치게 복잡해서 명시적으로 Likelihood 자체가 주어지지 않는 경우가 존재함.</td>
</tr>
<tr class="even">
<td>Completely intractable models are where we need to resort to ABC methods. (Likelihood가 intractable한 모델에서 ABC가 많이 사용된다. 전 챕터에서 언급된 Doubly Intractable 모델이 대표적인 예. 단 ABC가 스켈레톤 키는 아님. ABC도 패러미터 튜닝이 요구되고, 이 패러미터 튜닝은 상당히 어려움. 따라서 ABC도 상당히 약점이 많음.)</td>
</tr>
<tr class="odd">
<td>- Genetic Background of ABC
- ABC is a recent computational technique that only requires being able to sample from the likelihood <span class="math inline">\(f(\cdot \; \theta)\)</span>
- This technique stemmed from population genetics models, about 15 years ago, and population geneticists still contribute significantly to methodological developments of ABC.
- Population Genetics
- Describe the genotypes (AA, AO, etc ⇔ penotypes A) , estimate the alleles frequencies, determine their distribution among individuals, populations and between populations.
- Predict and understand the evolution of gene frequencies in populations as a result of various factors.
- Analyses the effect of various evolutive forces (mutation, drift, migration, selection) on the evolution of gene frequencies in time and space.</td>
</tr>
<tr class="even">
<td>If the likelihood function is intractable, then ABC (approximate Bayesian computation) is one of the few approaches we can use to do inference.</td>
</tr>
<tr class="odd">
<td><br></td>
</tr>
<tr class="even">
<td>ABC algorithms are a collection of Monte Carlo methods used for calibrating simulators. ABC 자체는 simulator-based model을 calibration한 모델이기 때문에 우리가 Likelihood function에 대해 명시적으로 알 필요가 없다.
- they do not require explicit knowledge of the likelihood function.
- inference is done using simulation from the model (they are ‘likelihood-free’).</td>
</tr>
<tr class="odd">
<td>ABC methods are popular in biological disciplines, particularly genetics. They are
- Simple to implement
- Intuitive
- Embrassingly parallelizable (MCMC 모델이 아니기 때문에 생기는 성질. multiple chain으로 돌려도 괜찮다는 이야기이다.) MCMC의 사용 상황은 아래의 그림과 같이 도식화된다.
- Can usually be applied</td>
</tr>
<tr class="even">
<td><img src="5-1.png"></td>
</tr>
<tr class="odd">
<td>- Proceeds:</td>
</tr>
<tr class="even">
<td>Target is <span class="math inline">\(\pi(\theta)f(x \vert \theta)\)</span>. When likelihood <span class="math inline">\(f(x \vert \theta)\)</span> not in closed form, likelihood-free rejection technique of ABC Algorithm is:</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(y \sim f(y \vert \theta)\)</span>, under the prior <span class="math inline">\(\pi(\theta)\)</span> (population genetics에서는 prior information이 대단히 강력하다. 따라서 prior에서 샘플을 생산해도 무관하며, ABC의 이러한 성질은 이의 연장선이다.), keep jointly simulating</td>
</tr>
<tr class="even">
<td>$
’  () \
\
 z f(z ’ )
$</td>
</tr>
<tr class="odd">
<td>until the <span class="math inline">\(z\)</span> is equal to the observed value <span class="math inline">\(y\)</span>. <span class="math inline">\(z = y\)</span>라는 결과를 얻을 때까지 위의 과정을 반복. <span class="math inline">\(z = y\)</span>가 된다면 $’ $를 accept.</td>
</tr>
<tr class="even">
<td>- Proof</td>
</tr>
<tr class="odd">
<td>$
\begin{alignat}{4}
f(<em>i) &amp;</em>{z } (_i) f(z _i) l_y(z) &amp;&amp; \</td>
</tr>
<tr class="even">
<td>&amp;(_i) f(y _i) &amp;&amp;= (_i y)</td>
</tr>
<tr class="odd">
<td>\end{alignat}
$</td>
</tr>
<tr class="even">
<td>- Tolerance Condition</td>
</tr>
<tr class="odd">
<td>When <span class="math inline">\(y\)</span> is a continuous rv, <span class="math inline">\(z = y\)</span> is replaced with a tolerance condition, <span class="math inline">\(\rho(y,z) \le \epsilon\)</span>, where <span class="math inline">\(\rho\)</span> is a <strong>distance</strong>.</td>
</tr>
<tr class="even">
<td>Output distributed from</td>
</tr>
<tr class="odd">
<td>$</td>
</tr>
<tr class="even">
<td>() P_{ (y,z) &gt; } ; ; ; ; ( (y,z) &gt; )</td>
</tr>
<tr class="odd">
<td>$</td>
</tr>
<tr class="even">
<td>하지만 이 방법은
- <span class="math inline">\(\epsilon\)</span> 결정이 어려움
- distance <span class="math inline">\(d(z,y)\)</span> 계산이 어려움</td>
</tr>
<tr class="odd">
<td>The idea behind ABC is that the <strong>summary statistics</strong> coupled with a small tolerance should provide a good approximation of the posterior: 위의 난점을 해결하기 위해 <strong>summary statistics</strong> <span class="math inline">\(\eta(z), \eta(y)\)</span>를 사용하여 <span class="math inline">\(dist\left\{ \eta(z), \eta(y) \right\}\)</span>를 구하여 이를 기준점으로 사용.</td>
</tr>
<tr class="even">
<td>$
<span class="math display">\[\begin{align}
\pi_\epsilon (\theta \vert y) &amp;= \int \pi_\epsilon (\theta , z \vert y)dz  \\ &amp;\approx \pi \left( \theta \vert \eta(y) \right)
\end{align}\]</span>
$</td>
</tr>
<tr class="odd">
<td>where <span class="math inline">\(\eta(y)\)</span> defines a (<strong>not necessarily sufficient</strong>) statistic. 하지만 대부분의 경우에는 SS를 이용은 함.</td>
</tr>
<tr class="even">
<td>- Proceeds:</td>
</tr>
<tr class="odd">
<td>For each iteration,
1. Repeat followings until <span class="math inline">\(\rho \left( \eta(z), \eta(y) \right) \le \epsilon\)</span>.
- Generate <span class="math inline">\(\theta &#39;\)</span> from the prior distribution <span class="math inline">\(\pi(\cdot)\)</span>.
- Generate <span class="math inline">\(z\)</span> from the likelihood <span class="math inline">\(f(\cdot \; \vert \theta &#39; )\)</span>.
2 Set $_i = ’ $.</td>
</tr>
<tr class="even">
<td>However, Simulating from the prior is often poor in efficiency. (population genetics에서는 strong prior를 사용했기 때문에 이러한 문제가 표면화되지 않았었음. 그러나 통계적 상황에서는 Bayesian prior를 사용하는 경우도 많으므로 이러한 문제가 유의해짐. 특히 <strong>non-informative prior</strong>를 쓸 때 poor performance 가능성 높아짐)
- By modifying the proposal distribution on <span class="math inline">\(\theta\)</span> to increase the density of <span class="math inline">\(x\)</span>’s within the vicinity of <span class="math inline">\(y\)</span>. <span class="math inline">\(\theta\)</span>의 proposal 제안할 때 그 과정을 개선한다는 소리.
- By viewing the problem as a conditional density estimation and by developing techniques to allow for larger <span class="math inline">\(\epsilon\)</span>. <span class="math inline">\(\epsilon\)</span> 잡기가 너무 어려워서 ABC 자체가 애매해짐. summary statistics 따라 <span class="math inline">\(\epsilon\)</span>이 항상 바뀌고 이거에 대한 규칙성도 현재로서는 없음. Summary Statistics가 모든 정보를 담고 있지 않아서, summary statistics로 <strong>model selection</strong>을 하려는 시도는 있었지만 실패했음. summary statistics가 담고 있는 정보가 데이터의 성질을 온전히 드러내고 있는지조차도 불명확함.
- By including <span class="math inline">\(\epsilon\)</span> in the inferential framework.</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\epsilon\)</span> reflects the tension between computability and accuracy.
- As <span class="math inline">\(\epsilon \rightarrow \infty\)</span>, we get observations from the prior, <span class="math inline">\(\pi(\theta)\)</span>.
- If <span class="math inline">\(\epsilon=0\)</span>, we generate observations from <span class="math inline">\(\pi(\theta \vert D)\)</span>. posterior에서 뽑는 것이라고 생각할 수 있다. <span class="math inline">\(\epsilon=0\)</span>에 가까우면 (최소한 summary statistics로는) <span class="math inline">\(y=z\)</span> 조건을 만족하는 것.</td>
</tr>
<tr class="even">
<td>ABC가 사용 불가한 상황은?
- if the data are too high dimensional, we never observe simulations that are ‘close’ to the field data.
- 데이터가 고차원이라면, 데이터의 차원들간의 interaction이 반드시 존재할 수밖에 없으므로, 기존 데이터와 같은 데이터를 생산해내는 것은 사실상 불가능
-Reduce the dimension using summary statistics.
- 1개의 실현값 <span class="math inline">\(\theta&#39;\)</span> 에서 summary statistics를 10000개 <span class="math inline">\(\eta(z^{(1)}), \cdots, \eta(z^{(10000)})\)</span> 를 가령 생산한 상황이라면, 이 summary statistics의 distribution이 multimodal이면 절대로 사용불가.</td>
</tr>
</tbody>
</table>
<div id="potential-risks-and-remedies-in-abc" class="section level5" number="4.5.1.0.1">
<h5 number="4.5.1.0.1"><span class="header-section-number">4.5.1.0.1</span> Potential Risks and Remedies in ABC</h5>
<p>Non-zero tolerance <span class="math inline">\(\epsilon\)</span>
- The inexactness introduces a bias in the computed posterior distribution.
- Practical studies of the sensitivity of the posterior distribution to the tolerance.
- sensitivity analysis, specification difficult
- summary statistics를 쓰지 sufficient statistics를 쓰는게 아니기 때문에 필연적으로 information loss가 있고 CI가 넓어짐</p>
<p>Non-sufficient summary statistics
- The information loss causes inflated credible intervals.
- Automatic selection/semi-automatic identification of sufficient statistics. Model validation check.</p>
<p>Small number of models/Mis-specified models
- The investigated models are not representative/lack predictive power.
- Careful selection of models. Evaluation of the predictive power.</p>
<p>Priors and parameter ranges
- Conclusions may be sensitive to the choice of priors. Model choice may be meaningless.
- Check sensitivity of Bayes factors to the choice of priors. Use alternative methods for model validation.</p>
<p>Curse-of-dimensionality
- Low parameter acceptance rates. Model errors cannot be distinguished from an insufficient exploration of the parameter space. Risk of overfitting.
- Methods for model reduction if applicable. Methods to speed up the parameter exploration. Quality controls to detect overfitting.</p>
<p>Model ranking with summary statistics
- The computation of Bayes factors on summary statistics may not be related to the Bayes factors on the original data, which may therefore render the results meaningless.
- Only use summary statistics that fulfill the necessary and sufficient conditions to produce a consistent Bayesian model choice. Use alternative methods for model validation.</p>
<p>Implementation
- Low protection to common assumptions in the simulation and the inference process.
- Sanity checks of results.</p>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="abcifying-monte-carlo-methods" class="section level3" number="4.5.2">
<h3 number="4.5.2"><span class="header-section-number">4.5.2</span> ABCifying Monte Carlo Methods</h3>
<p>Rejection ABC is the basic ABC algorithm: rejection 알고리즘임
- Inefficient as it repeatedly samples from prior <br> More efficient sampling algorithms allow us to make better use of the available computational resource: spend more time in regions of parameter space likely to lead to accepted values.
- allows us to use smaller values of <span class="math inline">\(\epsilon\)</span>, and hence finding better approximations. <br> Most Monte Carlo algorithms now have ABC versions for when we don’t know the likelihood</p>
<p>이를 개선하기 위해 제안되는 모델이 아래의 ABC-MCMC 알고리즘</p>
<hr />
<p><br>
<br>
<br></p>
</div>
<div id="abc-mcmc-algorithm" class="section level3" number="4.5.3">
<h3 number="4.5.3"><span class="header-section-number">4.5.3</span> ABC-MCMC Algorithm</h3>
<p>이 알고리즘에서는 Embrassingly parallelizable 성질을 잃어버리게 된다.</p>
<p>We are targeting the joint distribution</p>
<p>$
<em>{ABC} (, x D) </em>{} (D x) (x ) ()
$</p>
<p>To explore the <span class="math inline">\((\theta, x)\)</span> space, proposals of the form</p>
<p>$
Q ( (, x), (‘, x’) ) = q(, ‘) (x’ ’ )
$</p>
<p>seem to be inevitable.</p>
<p>The MH acceptance probability is then</p>
<p>$
<span class="math display">\[\begin{align}
r &amp;= \dfrac{\pi_{ABC} (\theta&#39; , x&#39; \vert D) Q \left( (\theta&#39;, x&#39;), (\theta, x) \right)}{\pi_{ABC} (\theta , x \vert D) Q \left( (\theta, x), (\theta&#39;, x&#39;) \right)} \\


&amp;= \dfrac{\pi_{\epsilon} (D \vert x&#39;) \pi (x&#39; \vert \theta&#39;) \pi(\theta&#39;)}{\pi_{\epsilon} (D \vert x) \pi (x \vert \theta) \pi(\theta)} \dfrac{q(\theta&#39;, \theta) \pi (x&#39; \vert \theta )}{q(\theta, \theta&#39;) \pi (x&#39; \vert \theta &#39; )}

&amp;= \dfrac{\pi_{\epsilon} (D \vert x&#39;)  \pi(\theta&#39;)}{\pi_{\epsilon} (D \vert x)  \pi(\theta)} \dfrac{q(\theta&#39;, \theta) }{q(\theta, \theta&#39;) }

\end{align}\]</span>
$</p>
<p>For each iteration,</p>
<ol style="list-style-type: decimal">
<li>Repeat followings until <span class="math inline">\(\rho \left( \eta(z), \eta(y) \right) \le \epsilon\)</span>.
<ul>
<li>Propose <span class="math inline">\(\theta &#39;\)</span> from a transition kernel <span class="math inline">\(g(\theta &#39; \vert \theta^{(t)})\)</span></li>
<li>Generate <span class="math inline">\(z\)</span> from the likelihood <span class="math inline">\(f(\cdot \vert \theta &#39;)\)</span></li>
</ul></li>
<li>accept or stay $ =
<span class="math display">\[\begin{cases} \theta &#39; &amp; \text{with probability MH ratio } \alpha = \min \left( 1, \; \; \dfrac{\pi(\theta &#39;)}{\pi(\theta^{(t)})} \dfrac{g(\theta^{(t)} \vert \theta &#39;)}{g(\theta &#39; \vert  \theta^{(t)} )} \right) \\ \theta &amp; o.w. \end{cases}\]</span>
$</li>
</ol>
<p>즉 <span class="math inline">\(\theta &#39;\)</span>를 MH 알고리즘에서 생산하며, MH 알고리즘에서 생산하였으므로 <span class="math inline">\(z\)</span>와 <span class="math inline">\(\theta &#39;\)</span> 양쪽 모두가 수용할지 여부의 평가 대상. <span class="math inline">\(z\)</span>가 수용되지 않았다면 <span class="math inline">\(\theta &#39;\)</span>도 수용되지 않고 <span class="math inline">\(\theta&#39;\)</span>를 새로 생산한다.</p>
<hr />
<div id="sequential-abc-algorithms" class="section level5" number="4.5.3.0.1">
<h5 number="4.5.3.0.1"><span class="header-section-number">4.5.3.0.1</span> <del>Sequential ABC Algorithms</del></h5>
<p>The most popular efficient ABC algorithms are those based on sequential methods.</p>
<p>We aim to sample N particles successively from a sequence of distributions</p>
<p>$
_1 () , , _T () = 
$</p>
<p>For ABC, we decide upon a sequence of tolerance <span class="math inline">\(\epsilon_1 &gt;\epsilon_2 &gt; \cdots &gt; \epsilon_T\)</span>, and let <span class="math inline">\(\pi_t\)</span> be the ABC distribution found by the ABC algorithm when we use tolerance <span class="math inline">\(\epsilon_t\)</span>.</p>
<hr />
</div>
<div id="synthetic-likelihood" class="section level5" number="4.5.3.0.2">
<h5 number="4.5.3.0.2"><span class="header-section-number">4.5.3.0.2</span> <del>Synthetic Likelihood</del></h5>
<p>The synthetic likelihood approach of Wood (2010) is an ABC algorithm which uses a Gaussian likelihood. However, instead of using</p>
<p>$
<span class="math display">\[\begin{align}

\pi_\epsilon(D \vert X) &amp;= N(D; X, \epsilon) \\
\pi_{ABC}(D \vert \theta)  &amp;= \int N(D; X, \epsilon)\pi(X \vert \theta) dX

\end{align}\]</span>
$</p>
<p>they repeatedly run the simulator at <span class="math inline">\(\theta\)</span>, generating <span class="math inline">\(X_1, \cdots, X_n\)</span>, and then use</p>
<p>$
(D ) = N ( D ; <em>, </em>)
$</p>
<p>where <span class="math inline">\(\mu_\theta\)</span> and <span class="math inline">\(\Sigma_\theta\)</span> is the sample mean and covariance of the (summary of the) simulator output.</p>
<!--chapter:end:211205_ApproximateBayesianComputation.Rmd-->
</div>
</div>
</div>
<div id="hamiltonian-monte-carlo" class="section level2" number="4.6">
<h2 number="4.6"><span class="header-section-number">4.6</span> Hamiltonian Monte Carlo</h2>
<p>RW의 단점 (randomness에서 오는 inefficiency를 줄이기 위해) 을 보완하기 위해 나온 개념.</p>
<p>Hamiltonian Monte Carlo borrows an idea from physics to suppress the local random walk behavior in the Metropolis algorithm, thus allowing it to move much more rapidly through the target distribution.</p>
<p>Version of Metropolis where you take many “steps” per “iteration”</p>
<p>Use “Hamiltonian dynamics” and a latent “momentum (<span class="math inline">\(\phi_j\)</span>)” vector so the steps within an iteration move along a “trajectory.”</p>
<p>Requires computation of gradient of log target density. 한번의 스텝에서 어느정도 움직이는지를 알기 위해선 이것이 요구되기 때문.</p>
<p>Take <span class="math inline">\(L\)</span> leapfrog steps (leapfrog를 몇번을 할 것인지), each of distance <span class="math inline">\(\epsilon\)</span> (1번의 leapfrog에서 얼마만큼을 움직일 것인지), then accept/reject.</p>
<p>In a leapfrog step, both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> are changed, each in relation to the other.</p>
<p>Effecitive Sample Size <span class="math inline">\(=ESS/S\)</span>: correlated되지 않았을 경우에 샘플 사이즈로 볼 수 있는 크기. MCMC는 과거 체인에 dependent하므로 당연히 correlated되어 있으며, 따라서 10000개를 생산했다고 치면 10000개의 샘플 사이즈에서 independent한 샘플의 사이즈가 얼마만큼인지를 체크하는 것. 따라서 ESS가 크면 클 수록 좋음. 마지막에 computation time <span class="math inline">\(S\)</span>로 나누어준 이유는 단위시간 당 샘플로 비교해야 하니까. 해당 개념은 알고리즘 comparison에서 대단히 많이 사용됨.</p>
<p>Rstan은 GS가 아니라 HMC를 사용함. 그래서 샘플 크기가 상대적으로 작아도 OK.</p>
<p>How far to jump in each step?
- If <span class="math inline">\(\epsilon\)</span> is too small, you waste time shuffling along.
- If <span class="math inline">\(\epsilon\)</span> is too large, the physical approximation breaks and you find yourself rejecting.</p>
<p>How many steps? (No U-turn Sampler)
- If <span class="math inline">\(L\)</span> is too small, you might not go far enough in each iteration.
- If <span class="math inline">\(L\)</span> is too large, you’ll waste time circling around and around.</p>
<p>Still HMC can be much better than Gibbs or Metropolis in high dimensions.</p>
<p>Energy Barrier. Multimodal에 취약.</p>
<p><br>
<br></p>
<ul>
<li>Proceeds:</li>
</ul>
<p>우선 momentum부터 만들어야 함. 운동에너지를 위치에너지로 바꾸는 것이 Hamiltonian의 기본적인 메커니즘. 이때 운동에너지 + 위치에너지는 항상 일정한 상수로 일정하다. 이를 위해 momentum을 생산해야 하는데, 이때 가장 손쉽게 momentum을 생산할 수 있는 방법이 <span class="math inline">\(M=I\)</span> 로 잡는 것. 단, 어떤 측면에서는 <span class="math inline">\(I\)</span>가 inefficient하기도 함. 다른 제안으로 Inverse Fisher’s Information 사용이 제안된 적도 있음. <strong>하지만 중간중간에 fixed point iteration으로 패러미터를 정해줘야 한다고?</strong> 경사가 완만할 때 더 많은 거리 이동 가능.</p>
<p>A. The iteration begins by updating <span class="math inline">\(\phi\)</span> with a random draw from its posterior distribution - which is the same as its prior distribution <span class="math inline">\(\phi \sim N(0, M)\)</span>.</p>
<p>B. A simultaneous update of <span class="math inline">\((\theta, \phi)\)</span> conducted in an elaborate but effective fashion via a discrete mimicking of physical dynamics. B step의 1회 이터레이션이 leapfrog Step 1회에 해당한다.</p>
<ol style="list-style-type: decimal">
<li>Use the gradient of the log-posterior density of <span class="math inline">\(\theta\)</span> to make a half-step of <span class="math inline">\(\phi\)</span>.</li>
</ol>
<p>$
<span class="math display">\[\begin{align}

\phi_{half.new} \; \; \; &amp;\leftarrow \; \; \; \phi + \dfrac {1}{2} \epsilon \ast \dfrac{d \log \pi(\theta \vert y)}{d \theta} \\

&amp;= \; \; \; \dfrac{1}{2} \epsilon \bigtriangledown_{\pmb \theta} \log f(\theta^\ast) \\

&amp;= \; \; \; \phi + \dfrac {1}{2} \epsilon \ast \dfrac{d \log \pi(\theta \vert y)}{d \theta} \Bigg \vert_{\theta^\ast}

\end{align}\]</span>
$</p>
<p>{:start=“2”}</p>
<ol start="2" style="list-style-type: decimal">
<li>Use the ‘momentum’ vector <span class="math inline">\(\phi\)</span> to update the ‘position’ vector <span class="math inline">\(\theta\)</span>:</li>
</ol>
<p>$
; ; ; ; ; ; + M^{-1} 
$</p>
<p>{:start=“3”}</p>
<ol start="3" style="list-style-type: decimal">
<li>Use the gradient of <span class="math inline">\(\theta\)</span> to half-update <span class="math inline">\(\phi\)</span>:</li>
</ol>
<p>$
<em>{new} ; ; ; ; ; ; </em>{half.new} +  
$</p>
<p>C. label <span class="math inline">\(\theta^{t-1}, \phi^{t-1}\)</span> as the value of the parameter and momentum vectors at the start of the leapfrog process and <span class="math inline">\(\theta^{\ast}, \phi^{\ast}\)</span> as the value after the <span class="math inline">\(L\)</span> steps. In the accept-reject step, we compute</p>
<p>$
r =  
$</p>
<p>D. Set <span class="math inline">\(\theta^t = \begin{cases} \theta^\ast &amp; \text{with probability } \min(1,r) \\ \theta^{t-1} &amp; o.w. \end{cases}\)</span></p>
<hr />
<div id="hmc-example-trajectory" class="section level5" number="4.6.0.0.1">
<h5 number="4.6.0.0.1"><span class="header-section-number">4.6.0.0.1</span> HMC Example Trajectory</h5>
<p><img src="6-1.png"></p>
<ul>
<li>Blue ellipse is contour of target distribution</li>
<li>Initial position at black solid circle.</li>
<li>Arrows indicate a U-turn in momentum</li>
</ul>
<p><img src="6-2.png"></p>
<p>“One practical impediment to the use of Hamiltonian Monte Carlo is the need to select suitable values for the leapfrog stepsize, <span class="math inline">\(\epsilon\)</span>, and the number of leapfrog steps <span class="math inline">\(L\)</span>. Tuning HMC will usually require preliminary runs with trial values for <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(L\)</span>. Unfortunately, preliminary runs can be misleading….”</p>
<hr />
</div>
<div id="introduction-to-hamiltonian-monte-carlo" class="section level3" number="4.6.1">
<h3 number="4.6.1"><span class="header-section-number">4.6.1</span> Introduction to Hamiltonian Monte Carlo</h3>
<p>Hamiltonian Monte Carlo (HMC) was originally developed in the late 1980s as Hybrid Monte Carlo to tackle calculations in Lattice Quantum Chromodynamics, a field focused on understanding the structure of the protons and neutrons.</p>
<p>Neal (1995, 2011) introduced the Hamiltonian Monte Carlo into the mainstream of statistical computing.</p>
<p>HMC is built upon a rich theoretical foundation, which is formulated in terms of differential geometry, that makes it uniquely suited to the high-dimensional problems of applied interest.</p>
<hr />
<div id="foundations-of-hamiltonian-monte-carlo" class="section level5" number="4.6.1.0.1">
<h5 number="4.6.1.0.1"><span class="header-section-number">4.6.1.0.1</span> Foundations of Hamiltonian Monte Carlo</h5>
<p><img src="6-3.png"></p>
<p>Most Markov Transitions are diffusive, concentrating around the initial point such that the corresponding MArkov chains linger in small neighborhoods of the typical set for long periods of time. In order to maximize the utility of our computational resources, we need coherent Markov Transitions that are able to glide across the typical set towards new, unexplored neighborhoods.</p>
<p>In order to make large jumps away from the initial point, and into new, unexplored regions of the typical set, we need to exploit information about the geometry of the typical set.</p>
<p>HMC is the unique procedure for automatically generating this coherent exploration for sufficiently well-behaved target distributions.</p>
<p>Introduce some intuition to motivate how we can generate the desired exploration by carefully exploiting the differential structure of the target probability density.</p>
<p>Discuss the procedure with the complete construction of the Hamiltonian Markov transition.</p>
<p><img src="6-4.png"></p>
<p>A vector field is the assignment of a direction at every point in parameter space. When those directions are aligned with the typical set, we can follow them like guide posts, generating coherent exploration of the target distribution.</p>
<p>When the sample space is continuous, a natural way of encoding this direction information is with a vector field aligned with the typical set.</p>
<p>A vector field is the assignment of a direction at every point in parameter space, and if those directions are aligned with the typical set then they act as a guide through this neighborhood of largest target probability.</p>
<p>By construction this, we follow the direction assigned to each at point for a small distance.</p>
<p>Continuing this process traces out a coherent trajectory through the typical set that efficiently moves us far away from the initial point to new, unexplored regions of the typical set as quickly as possible.</p>
<p><img src="6-5.png"></p>
<p>The gradient of the target pdf encodes information about the geometry of the typical set, but not enough to guide us <strong>through</strong> the typical set by itself. Follwing along the gradient instead pulls us away from the typical set and towards the mode of the target density. In order to generate motion through the typical set we need to introduce additional structure that carefully twists the gradient into alignment with the typical set.</p>
<p>Need to construct a vector field aligned with the typical set using only information that we can extract from the target distribution.</p>
<p>The natural information is the differential structure of the target distribution which we can query through the gradient of the target probability density.</p>
<p>The gradient defines a vector field in parameter space sensitive to the structure of the target distribution.</p>
<p>Unfortunately, that sensitivity is not sufficient as the gradient will never be aligned with the typical set. Following the guidance of the gradient pulls us away from the typical set and towards the mode of the target density.</p>
<p><img src="6-6.png"></p>
<ol style="list-style-type: lower-alpha">
<li>Without enough transverse momentum to balance againts the gravitational attraction of the planet, a satellte will still crash into the planet.</li>
<li>On the other hand, if the satelite is given too much momentum then the gravitational attraction will be too weak to capture the satelite in a stable orbit, which will instead abandon the planet for the depths of space.</li>
</ol>
<p><img src="6-7.png"></p>
<p>When we introduce exactly the right amount of momentum to the physical system, the equations describing the evolution of the satelite define a vector field aligned with the orbit. The subsequent evolution of the system will then trace out orbital trajectories.</p>
<p>The gradient can direct us towards only parameterization sensitive neighborhoods like that around the mode, and not the parameterization-invariant neighborhoods within the typical set.</p>
<p>To utilize the information in the gradient we need to complement it with additional geometric constraints, carefully removing the dependence on any particular parameterization while twisting the directions to align with the typical set.</p>
<p>If we add the right amount of momentum, then the momentum will exactly balance against the gradient information, and the corresponding dynamics of the system will be conservative.</p>
<p>The key is twisting the gradient vector field into a vector field aligned with the typical set, and hence once capable of generating efficient exploration, is to expand our original probabilistic system with the introduction of auxiliary momentum parameters.</p>
<p>There is only one procedure for introducing auxiliary momentum with such a probabilistic structure: Hamiltonian Monte Carlo.</p>
<hr />
</div>
<div id="phase-space-and-hamiltons-equations" class="section level5" number="4.6.1.0.2">
<h5 number="4.6.1.0.2"><span class="header-section-number">4.6.1.0.2</span> Phase Space and Hamilton’s Equations</h5>
<p><img src="6-8.png"></p>
<p>A defining feature of conservative dynamics is the preservation of volume in position-momentum phase space. For example, althou dynamics might compress volumes in position space, the corresponding volume in momentum space expands to compensate and ensure that the total volume is invariant. Such volume-preserving mapping are also known as <strong>shear</strong> Transformations.</p>
<p>Conservative dynamics in physical systems requires that volumes are exactly preserved.</p>
<p>As the system evolves, any compression or expansion in position space must be compensated with a respective expansion or compression in momentum space to ensure that the volume of any neighborhood in position-momentum <strong>phase space</strong> is unchanged.</p>
<p>In order to mimic this behavior in our probabilistic system we need to introduce auxiliary momentum parameter, <span class="math inline">\(p_n\)</span>, to complement each dimension of our target parameter space, <span class="math inline">\(q_n\)</span>, expanding the D-dimensional into a 2D-dimensional phase space.</p>
<p>$
q_n ( q_n, p_n )
$</p>
<p>Moreover, these auxiliary momentum have to be dual to the target parameters, transforming in the opposite way under any reparameterization so that phase space volumes are invariant.</p>
<p>Having expanded the target parameter space to phase space, we can lift the target distribution onto a joint probability distribution on phase space called the canonical distribution. Then, the choice of a conditional probability distribution over the auxiliary momentum, $ (q, p) = (p q) (q) $, which ensures that if we marginalize out the momentum we immediately recover our target distribution.</p>
<p><img src="6-9.png"></p>
<p>By constructing a probability distribution on phase space that marginalizes to the target distribution, we ensure that the typical set on phase space projects to the typical set of the target distribution. In particular, if we can construct trajectories that efficiently explore the joint distribution (black) they will project to trajectories that efficientyl explore the target distribution (green).</p>
<p>The canonical density <span class="math inline">\(\pi(q, p)\)</span> does not depend on a particular choice of parameterization, and we can write it in terms of an invariant <strong>Hamiltonian</strong> function, <span class="math inline">\(H(q, p)\)</span>,</p>
<p>$</p>
<p>(q,p) = ( - H(q, p) )</p>
<p>$</p>
<p>Because <span class="math inline">\(H(q, p)\)</span> is <strong>independent of the details of any parameterization</strong>, it captures the invariant probabilistic structure of the phase space distribution and, the geometry of its typical set.</p>
<p>The value of the Hamiltonian at any point in phase space is called the energy at that point.</p>
<p>Hamiltonian decomposes into two terms, Density over the auxiliary momentum, <span class="math inline">\(K(p,q)\)</span> is called the <strong>kinetic energy</strong> (unconstrained and specified by the implementation), while the term corresponding to the density of the target distribution, <span class="math inline">\(V(q)\)</span> is known as the <strong>potential energy</strong> (determined by the target distribution).</p>
<p>$</p>
<p>H(q,p)</p>
<ul>
<li>(q,p) = - (p q) - (q)</li>
</ul>
<p>K(p,q) + V(q)</p>
<p>$</p>
<p>Because the Hamiltonian captures the geometry of the typical set, it should be able to use it to generate a vector field oriented with the typical set of the canonical distribution.</p>
<p>The desired vector field can be generated from a given Hamiltonian with</p>
<p>$</p>
<p>= +  {p}</p>
<p>=  {p},</p>
<p>; ; ; ; ;</p>
<p>= -  {q}</p>
<p>= - {q} - {q}</p>
<p>$</p>
<p>By channeling the gradient through the momentum instead of the target parameter directly, Hamilton’s equations twist differential information to align with the typical set of canonical distribution.</p>
<p>Following the Hamiltonian vector field for some time, <span class="math inline">\(t\)</span>, generates trajectories <span class="math inline">\(\phi_t (q, p)\)</span>, that rapidly move through phase space while being constrained to the typical set.</p>
<p>Projecting these trajectories back down onto the target parameter space finally yields the efficient exploration of the target typical set for which we are searching.</p>
<p><img src="6-10.png"></p>
<p>Every Hamiltonian Markov Transition is comprised of a random lift from the target parameter space onto phase space (light red), a deterministic Hamiltonian trajectory through phase space (dark red), and a projection back down to the target parameter space (light red).</p>
<p><br>
<br></p>
<ul>
<li>Need a mechanism for introducing momentum to a given point in thetarget parameter space.</li>
</ul>
<p>To lift an initial point in parameter space into one on phase space, we simply sample from the conditional distribution over the momentum, <span class="math inline">\(p \sim \pi(p \vert q)\)</span>.</p>
<p>Once on phase space we can explore the joint typical set by integrating Hamilton’s equations for some time, <span class="math inline">\((q,p) \rightarrow \phi_t (q,p)\)</span>. By construction these trajectories coherently push the Markov transition away from the initial point, and neighborhoods that we have already explored, while staying confined to the joint typical set.</p>
<p>After integrating Hamilton’s equations, we can return to the target parameter space by simply projecting away the momentum, <span class="math inline">\((q,p) \rightarrow q\)</span>.</p>
<!--chapter:end:211206_HamiltonianMonteCarlo.Rmd-->
</div>
</div>
</div>
<div id="population-monte-carlo" class="section level2" number="4.7">
<h2 number="4.7"><span class="header-section-number">4.7</span> Population Monte Carlo</h2>
<p>Population-Based MCMC. population이란? 즉, multiple 체인을 돌린다는 것. 로컬 트랩 문제를 회피하기 위해서. 이는 이하의 조건을 탄다.</p>
<ol style="list-style-type: decimal">
<li>각 체인이 가지는 분포는 서로 달라야 하지만, 아예 그 분포들끼리 아예 무관해서는 안된다. (2번을 위해)</li>
<li>체인들 간에 정보의 교환이 이루어져야 한다. 서로가 가지고 있는 정보를 공유하는 것으로 체인들의 타겟 분포로의 수렴을 가속시키는 것이 이 여러개의 체인의 존재 목적이기 때문이다.</li>
</ol>
<p>이는 패러렐 컴퓨팅을 가능하게 한다.</p>
<p><br>
<br></p>
<ul>
<li>Embarrassingly Parallel MCMC</li>
</ul>
<p>언급하였듯 위의 다중체인은 서로간에 정보의 교환이 이루어져 속도가 다소 느려지는 측면이 분명히 생긴다. 이러한 발목잡힘을 피하기 위해 체인간의 정보교환이 전혀 없는 MCMC.</p>
<hr />
<p>타겟분포 <span class="math inline">\(f(x)\)</span>에서 샘플 생산.</p>
<p>f(x_1 , , x_N)=_{i=1}^N f_i (x_i)</p>
<p>이때 f(x)와 f_i(x_i) 사이에는 반드시 연관이 존재해야 하며, 적어도 하나의 i값에 대해 f(x) = f_i(x_i)를 만족해야 함.</p>
<p>N은 체인의 갯수, 혹은 population의 size.</p>
<div id="adaptive-direction-sampling" class="section level3" number="4.7.1">
<h3 number="4.7.1"><span class="header-section-number">4.7.1</span> Adaptive Direction Sampling</h3>
<p>가장 기본적인 형태. 여러개의 체인을 돌린 후 특정 방향으로 다른 샘플을 이동시키는 방법.</p>
</div>
<div id="conjugate-gradient-mc" class="section level3" number="4.7.2">
<h3 number="4.7.2"><span class="header-section-number">4.7.2</span> Conjugate Gradient MC</h3>
</div>
<div id="parallel-tempering" class="section level3" number="4.7.3">
<h3 number="4.7.3"><span class="header-section-number">4.7.3</span> Parallel Tempering</h3>
<p>temperature 개념 사용. 따라서 T_1&gt;T_2&gt;&gt;T_n=1 이어야 하며, T_n은 타겟분포에 상응한다. 이때 각 temperature에 대응하는 pdf f_i(x) ( - )</p>
<p>simulated tempering은 temperature를 생산해서 해당 temperature를 accept한 후 해당 temperature로 이동.
Parallel Tempering은 n개의 온도에 대응하는 체인 n개를 만들어 각각의 온도에 대응시킨 후 n개의 체인을 병렬적으로 돌림. 이때 높은 온도인 T_1은 넓은 space를 탐색하고 낮은 온도인 T_n은 좁은 space를 탐색. 이때 태생의 온도에 따라 탐색시키는 것은 탐색 효율이 떨어지므로 체인이 일정 경과할 때마다 swapping (Exhange) opertation을 하여 출신 이외의 다른 체인과 서로 바꿈. 이 바꿈은 인접한 체인과만 발생. 이를 통해 상황이 맞아떨어지면 T_1 출신의 탐색자가 T_n까지 가서 탐색하는 상황도 나올 수 있음. 이러한 swapping opertation을 Auxiliary Variable Generation까지 확장시킨 것이 Exhange Algorithm.</p>
<p>Proceeds:
1. local MH. MH 알고리즘을 통해 X_i^{(t)} X_i^{(t+1)} 로 업데이트.
2. Exhange 스텝. 인접한 체인이 2개라면 각각으로 이동할 확률을 0.5로 잡고, 1개라면 서로밖에 교환 못하니 이는 1로 설정. 이후 해당 교환을 accept할지 여부는 확률 { 1, ; ; ; }에 따라 결정. 이외면 교환 안 한 채로 남긴다.</p>
<p>이를 고차원으로 확장시키면 Sequential Parallel Tempering.</p>
<div id="exchange-algorithm-1" class="section level5" number="4.7.3.0.1">
<h5 number="4.7.3.0.1"><span class="header-section-number">4.7.3.0.1</span> Exchange Algorithm</h5>
</div>
</div>
<div id="evolutionary-mc" class="section level3" number="4.7.4">
<h3 number="4.7.4"><span class="header-section-number">4.7.4</span> Evolutionary MC</h3>
<p>Combinatorial Optimization Problem, 무수히 많은 조합 중에 local optimal 찾는 문제에서 가장 자주 사용되는 방법론인 genetic Algorithm, 의 MC 버전이라고 볼 수 있다. 다른 모델, 크로스오버 (스위치), 뮤테이션.</p>
<p>다만 Evolutionary MC 자체는 Combinatorial Optimization을 푼다기보단 Multimodal 문제를 푸는 용도에 가까움. genetic Algorithm과 Evolutionary MC 둘 모두 local mode를 찾는 알고리즘, <strong>local Trap</strong> 문제를 해결하는 알고리즘.</p>
<p>또한 Evolutionary MC는 local trap 해결 이외에 Variable Selection에도 아주 유용하며 자주 사용됨. 이 Variable Selection 자체가 일종의 Combinatorial Optimization 문제로 생각될 수 있음. 가용 변수의 조합 중 어떤 조합을 써야 효율이 잘 나올 것인가를 고민하는 거니까.</p>
<p>Evolutionary MC 또한 temperature 개념을 사용하므로 parallel Tempering과 유사. 온도 설정과 온도에 따른 체인 설정 후 탐색은 완전히 똑같지만, parallel tempering의 swapping operator가 바로 인접한 체인과의 교환만 발생했던 반면 evolutionary MC는 crossover operator를 사용하여 인접한 것만이 아닌 모든 체인 중에 교환할 체인을 선정. 이렇게 교환 범위가 넓기 때문에 parallel tempering보다 성능이 훨씬 좋음.</p>
<p>Proceeds:
1. Mutation은 자주 일어나는 일이 아니므로 확률로 판정하여 Mutation과 Crossover 둘 중 하나만 일어나도록 함. Mutation의 확률은 q_m, Crossover의 확률은 1-q_m. 이 확률 q_m은 uniform에서 획득. 잘 모르면 0.5.
1. Local MH. 이는 genetic Algorithm에서의 Mutation에 대응. <br> x_1 , , x_N 중 1개를 균일확률로 선정해서 뽑고 뽑은 그 x_k 1개에 대응하는 y_k = x_k + e_k 를 만들어 이로 대체할 것을 제안. 이는 (1, r_m)의 확률로 accept되고, 이때 accpetance ratio r_m = { - } . 이때 뒤쪽의 fraction은 proposal density에 해당.
2. Crossover Operator: (1) 현 population x에서 x_i를 고른 후, (2) x / x_i 에서 x_j 를 고른다. 이때 x_j를 선정할 때 ( -  )의 확률에 따라 선정한다. k는 앞서 선정되었던 i를 제외한 모든 수. (3) e=x_i - x_j, y_i = x_j + r e. 이때 r은 direction에 해당하며 모든 실수일 수 있고, r의 선정은 density f(r) r ^{d-1} f(x_i + re)에 따른다. (4) 여기서 획득한 y_i로 x_i를 교체한 후 이렇게 교체한 집합을 새로운 population으로 삼는다.
3. Exchange 스텝. 이를 통해 X 내용물을 구성하는 <span class="math inline">\(x_i\)</span>, 즉 각 온도 H(x_i) 에 대응하는 chromosome들의 교환이 이루어짐. Exchange Operator: parallel tempering과 마찬가지로 양옆의 것들과 확률 판정해서 교환.</p>
</div>
<div id="sequential-parallel-tempering" class="section level3" number="4.7.5">
<h3 number="4.7.5"><span class="header-section-number">4.7.5</span> Sequential Parallel Tempering</h3>
<!--chapter:end:211207_PopulationMC.Rmd-->
</div>
</div>
<div id="stochastic-approximation-monte-carlo" class="section level2" number="4.8">
<h2 number="4.8"><span class="header-section-number">4.8</span> Stochastic Approximation Monte Carlo</h2>
<p>Neural Network의 Multimodality issue. 패러미터는 p개인데 equation은 q개. q가 p보다 훨씬 작아서 관계성이 식으로밖에 나오지 않음. 따라서 identifiability 이슈가 발생하기 때문. gradient descent 방법으로 최적해 찾아내다 뭐 이렇게 말을 하는데 사실 이걸 최적해로 말할 수 없음.</p>
<p>combinatorial optimization에도 로컬 최적해가 다수 존재하고 글로벌 최적해 파악이 어려우므로 유사하게 multimodal issue 존재.</p>
<p>SAMC는 과거의 샘플 전체를 이용하므로 Monte Carlo긴 하나 MCMC는 아님.</p>
<p>에너지 펑션 <span class="math inline">\(-\log \psi (x)\)</span>, $ (x)$는 unnormalized density. 이 에너지 펑션을 U(X)로 둔다면 이는 결국 y축에 대응되는 값. 이 U(X)를 파티션한다. 이렇게 나눈 영역 E_i들은 각각 고유한 weight를 보유하고 있음. 난수 1개를 샘플링했을 때 이 난수가 영역 E_i에서 나왔다고 한다면, 이 영역 E_i에 배정되었던 weight를 줄이고 다른 모든 구간의 weight를 높인다. 이를 통해서 모든 영역에서의 고른 샘플링을 기대할 수 있음. 이 weight의 증감량을 얼마만큼 시킬 것인지가 stochastic Approximation을 통해서 얻어짐.</p>
<p>이를 모두 반영한 식은</p>
<p>c (x) _{i=1}^m  I(X E_i)</p>
<p>이때 이의 denominator는 E_i에 대한 weight이며, 이것이 결국 c에 대응하는 부분인데 영역이 partition되었으므로 이를 mixture distribution의 형태로 나타내줌.</p>
<p>여기서 ^{(i)}=log g_i이고, g_i = _{E_i} (x). 따라서 이를 exp의 승으로 만드는 것은 log를 취했던 것을 벗기는 작업임.</p>
<p>_i : 구간 i에서 얼마만큼의 샘플을 생산할 것인가. 보통은 구간별 생산 갯수를 동일하게 하는 것을 목적으로 함. 이에 의해서 보통 이 알고리즘을 flat-histrogram 알고리즘이라고 부름.</p>
<p>gain factor sequence { <em>k }</em>{k=0}^. 이는 Stochastic Approximation에 필요함. gain factor _k =  . 이때 t_0는 prospected value. 따라서 첫 이터레이션때는 1로 유지되고, 이후에 빠르게 감소함. 따라서 weight도 이에 영향받아 첫번째 이터레이션때는 일정하게 유지되다가 이후에 떨어진다. t_0가 크면 수렴이 빠르지만 그렇기 때문에 지나치게 커서는 안됨.</p>
<p>이렇게 생산한 샘플을 그냥 써서는 안되고, 획득한 샘플 ^{(t)}와 weight (theta^{(t)} )= g_i를 사용하여 Importance Sampling을 한번 해서 그 결과물을 사용해야 함.</p>
<p>????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????</p>
<p>3시 18분</p>
<!--chapter:end:211208_StochasticAMC.Rmd-->
</div>
<div id="review" class="section level2" number="4.9">
<h2 number="4.9"><span class="header-section-number">4.9</span> Review</h2>
<hr />
<div id="wk01" class="section level3" number="4.9.1">
<h3 number="4.9.1"><span class="header-section-number">4.9.1</span> Wk01</h3>
<ol style="list-style-type: decimal">
<li>Write the inverse-CDF method and state how we can generate random numbers from <span class="math inline">\(W(\alpha, \beta)\)</span>.</li>
</ol>
<p>inverse-CDF method는, 우리가 알다싶이 <span class="math inline">\(0 \le F(x) \le 1\)</span>. 즉 <span class="math inline">\(F(x) \sim U(0,1)\)</span>나 다름없다. <span class="math inline">\(u \sim U(0,1)\)</span>을 하나 샘플링. 이는 <span class="math inline">\(F(x)\)</span>의 range와 일치한다. 따라서 <span class="math inline">\(F(x)=u \iff x=F^{-1} (u)\)</span>.</p>
<ul>
<li>Weibull Dist: <br> shape parameter <span class="math inline">\(k\)</span>, scale parameter <span class="math inline">\(\lambda\)</span>에 대해</li>
</ul>
$
f(x) =
<span class="math display">\[\begin{cases} \left( \dfrac {k}{\lambda} \right) \left( \dfrac {x}{\lambda} \right)^{k-1} \exp{- \left( \dfrac{x}{\lambda} \right) } &amp; x\ge 0 \\ \\ 0 &amp; o.w. \end{cases}\]</span>
<p>$</p>
<p>let quantity <span class="math inline">\(X\)</span> is “time-to-failure.”</p>
<p>$
<span class="math display">\[\begin{align}
F(x) = 1- \exp{- \left( \dfrac{x}{\lambda} \right) } &amp;= u \\
\Longrightarrow x &amp;= \lambda \left[ -\log (1-u) \right]^{\tfrac{1}{k}}

\end{align}\]</span>
$</p>
<ol start="2" style="list-style-type: decimal">
<li>State the RS algorithm.</li>
</ol>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">target density <br> <span class="math inline">\(f(x)\)</span></th>
<th align="center">proposal density <br> <span class="math inline">\(g(x)\)</span></th>
<th align="center">envelope density <br> <span class="math inline">\(e(x) = c \ast g(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">evaluate</td>
<td align="center">easy</td>
<td align="center">easy</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">generate</td>
<td align="center">difficult</td>
<td align="center">easy</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">cover all areas of <span class="math inline">\(f(x)\)</span>, <br> in all parameter supports, <span class="math inline">\(f(x) \le e(x)\)</span></td>
</tr>
</tbody>
</table>
<p><img src="1-1.png"></p>
<ol start="3" style="list-style-type: decimal">
<li>State how we can generate random numbers using RS.
<ol style="list-style-type: decimal">
<li>generate sample <span class="math inline">\(x\)</span> from <span class="math inline">\(g(x)\)</span></li>
<li>generate <span class="math inline">\(u \sim U(0,1)\)</span></li>
<li>위에서 언급하였듯, envelope는 proposal의 상수배이며, envelope는 target보다 항상 크므로 <span class="math inline">\(\dfrac{f(x)}{e(x)}\)</span>는 항상 0 이상이며 1 이하. 이는 곧 <span class="math inline">\(U(0,1)\)</span>에서 생산되는 값과 동일한 분포를 지니며, <span class="math inline">\(e(x)\)</span> 아래의 값들 중 <span class="math inline">\(f(x)\)</span> 아래에도 해당하는 값들은 곧 <span class="math inline">\(f(x)\)</span>에서 생산된 난수라고 볼 수 있었다. 따라서 if <span class="math inline">\(u \le \dfrac{f(x)}{e(x)}\)</span>, sample <span class="math inline">\(x\)</span>를 accept, 이외엔 reject.</li>
</ol></li>
</ol>
<hr />
</div>
<div id="wk03" class="section level3" number="4.9.2">
<h3 number="4.9.2"><span class="header-section-number">4.9.2</span> wk03</h3>
<ol style="list-style-type: decimal">
<li>State one iteration of squeezing RS.</li>
</ol>
<p><span class="math inline">\(f(x)\)</span>가 evaluate 자체는 가능한데 그거조차도 비용이 expensive 한 경우를 가정. <span class="math inline">\(f(x)\)</span>가 샘플 generate가 어려우니 RS를 쓰는건데 평가 비용조차 높으니 샘플링 과정이 비효율적일 수밖에 없음. 따라서 squeeze function <span class="math inline">\(s(x)\)</span>를 설정하여 확실하게 <span class="math inline">\(f(x)\)</span>에 속하는 샘플들은 먼저 우선선발 시켜서 패스시키고, 우선선발이 아닌 샘플들만 <span class="math inline">\(f(x)\)</span>를 직접 사용해서 조건을 통과하였는지 여부를 체크. 당연하지만 <span class="math inline">\(s(x)\)</span>는 모든 support에서 <span class="math inline">\(f(x)\)</span>보다 작아야 하며, evaluate 비용이 cheap해야 함.</p>
<p>proceeds:
1. <span class="math inline">\(Y \sim g\)</span>에서 샘플링.
2. sample <span class="math inline">\(u \sim U(0,1)\)</span>.
3. if <span class="math inline">\(U \le \dfrac {s(Y)}{e(Y) = c \ast g(y)}\)</span>, keep <span class="math inline">\(Y\)</span>.
4. if not, whether if <span class="math inline">\(U \le \dfrac {f(Y)}{e(Y)}\)</span>, keep <span class="math inline">\(Y\)</span>.
5. both are not, reject <span class="math inline">\(Y\)</span>.</p>
<p>이때 <span class="math inline">\(s(x)\)</span>를 생산하기 위해 Talyor Series Expansion을 사용하는 경우 잦다.</p>
<ol start="2" style="list-style-type: decimal">
<li>State the adaptive RS.</li>
</ol>
<p>Make envelope function <span class="math inline">\(e(x)\)</span> adaptively to the shape of <span class="math inline">\(f(x)\)</span>.</p>
<p><img src = "1-2.png"></p>
<p>adaptive RS 자체에는 제약이 있다. 이는 log concave function인 density에만 적용이 가능하다는 것. 즉슨 multimodal인 density에는 적용이 불가하다. 이 제약을 해소하기 위해 Adaptive Rejection Metropolis Sampling이 존재.</p>
<p><strong>mode가 필수라는 게 RS 자체가 mode가 필수라는 소리인가?</strong></p>
<ol start="3" style="list-style-type: decimal">
<li>State the Importance Sampling</li>
</ol>
<p><span class="math inline">\(\mu = E[h(x)]\)</span>. 이때 <span class="math inline">\(h(x)\)</span>는 <span class="math inline">\(x\)</span>의 함수이며, <span class="math inline">\(x\)</span>는 <span class="math inline">\(f(x)\)</span>를 따르므로 <span class="math inline">\(h(x)\)</span>의 기댓값 계산 또한 이를 따르지만, 이는 기댓값 계산에서 density를 <span class="math inline">\(g\)</span>로 바꾸고 이의 각 확률에 발생하는 값들을 <span class="math inline">\(h \ast \dfrac{f}{g}\)</span>로 바꾸는 것과 다르지 않음. 이는 <span class="math inline">\(f\)</span>에서 샘플 생산이 힘들때 <span class="math inline">\(f\)</span>를 거치지 않고도 샘플을 생산하여 기댓값을 계산할 수 있다는 점에서 빛을 발함. 즉 확률은 <span class="math inline">\(g\)</span>를 참조하고, 이 확률에서 발생하는 값들이 있을 것이고, 이 값들을 다시 한번 함수에 넣어서 역변환하면 <span class="math inline">\(f\)</span>의 확률에서 발생했었을 각 값들을 획득하는 것이 가능하다는 소리.</p>
<p>이러한 역변환 함수에서 <span class="math inline">\(f, g\)</span>가 차지하는 부분을 weight라고 부르는 것이고, 이를 weight의 총합으로 표준화하면 standardized weight.</p>
<p><span class="math inline">\(g\)</span>의 support가 <span class="math inline">\(f\)</span>의 그것을 다 덮을 필요는 없음. 하지만 1. <span class="math inline">\(\dfrac{f}{g}\)</span>는 bounded여야 하고, 가장 중요하게, <span class="math inline">\(g\)</span>는 <span class="math inline">\(f\)</span>보다 꼬리가 두꺼워야 함. 이는 극단적인 <span class="math inline">\(x\)</span>값이 나왔을 때 <span class="math inline">\(g\)</span>의 확률이 <span class="math inline">\(f\)</span>보다 지나치게 작으면 해당 부분에서의 weight가 너무너무 커져서 다른 샘플 실값들의 영향력을 다 잡아먹어버리는 <strong>weight-degeneracy</strong>가 발생해버리기 때문.</p>
<ol start="4" style="list-style-type: decimal">
<li>State the polar methods for generating normal random variable.</li>
</ol>
<p>$ X, Y  {} N(0,1)$</p>
<p>f(x,y) =  {2} ( - (x^2 + y^2 ))</p>
<p><span class="math inline">\(\theta \sim U(0, 2\pi)\)</span>, <span class="math inline">\(R^2 \sim \EXP (\tfrac{1}{2})\)</span>.</p>
<p><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>를 모은 만큼의 샘플이 <span class="math inline">\(N\)</span>을 따른다.</p>
</div>
<div id="wk04-05" class="section level3" number="4.9.3">
<h3 number="4.9.3"><span class="header-section-number">4.9.3</span> wk04, 05</h3>
<ol style="list-style-type: decimal">
<li>State the effect of proposaldensity <span class="math inline">\(g\)</span> in IS.</li>
</ol>
<p>과도한 variability를 피하기 위해, <span class="math inline">\(\dfrac{f}{g}\)</span>로 설정하고 <span class="math inline">\(g\)</span>가 <span class="math inline">\(f\)</span>보다 두꺼운 꼬리를 지니도록 설정해야 함. <span class="math inline">\(g\)</span>가 너무 작으면 weight-degeneracy.</p>
<p><span class="math inline">\(h\)</span>가 너무 작다면, <span class="math inline">\(\dfrac{f}{g}\)</span>를 크게 할 수 있는 <span class="math inline">\(g\)</span>를 선정한다.</p>
<ol start="2" style="list-style-type: decimal">
<li>State the antithetic sampling, Control Variate, and Rao-Balckwellization.</li>
</ol>
<p>antithetic: use two id UE, whose <span class="math inline">\(Corr(\hat \mu_1 , \hat \mu_2)&lt;0\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>State one iteration of sampling Importance Resampling.</p></li>
<li><h2 id="왜-옛날에는-variance-reduction-하고-요즘엔-안함">왜 옛날에는 variance reduction 하고 요즘엔 안함?</h2></li>
</ol>
<!--chapter:end:211298_Review.Rmd-->
</div>
</div>
<div id="else" class="section level2" number="4.10">
<h2 number="4.10"><span class="header-section-number">4.10</span> Else</h2>
<div id="hw4.-rasch-model" class="section level3" number="4.10.1">
<h3 number="4.10.1"><span class="header-section-number">4.10.1</span> Hw4. Rasch Model</h3>
<p>$
<span class="math display">\[\begin{align}

L(\theta, \beta) &amp;= \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}} \\



\pi (\theta, \beta \vert y) &amp;= \pi(\theta) \pi(\beta) \ast \prod_{k=1}^n \prod_{i=1}^p \left\{ \dfrac{\exp(\theta_k + \beta_i)}{1 + \exp(\theta_k + \beta_i)}\right\}^{y_{ki}} \left\{ \dfrac{1}{1 + \exp(\theta_k + \beta_i)}\right\}^{1-y_{ki}}


\end{align}\]</span>
$</p>
<p>$</p>
<p>0&lt;{ }^{y_{ki}} &lt;1, ; ; ; ; ; 0&lt;{ }^{1-y_{ki}}&lt;1</p>
<p>$</p>
<p><strong>underflow problem</strong>. log 취하면 해결.</p>
<p>$</p>
<p>(_k) N(0, ^2), ; ; ; ; ; (^2 ) IG(0.001, 0.001)</p>
<p>$</p>
<p>update <span class="math inline">\(\theta_k , k=1, \cdots, n\)</span>"</p>
<p>$
(r) = (<em>k ’ y, ^{(t)}. </em>{-k}^{(t)} - (^{(t)} y, ^{(t)}. _{-k}^{(t)}
$</p>
<p>if <span class="math inline">\(\log U &lt; min(\log(r), 0))\)</span>, accept. else, reject.</p>
<hr />
</div>
<div id="da-example-mvn" class="section level3" number="4.10.2">
<h3 number="4.10.2"><span class="header-section-number">4.10.2</span> DA) Example: MVN</h3>
<p>for DA 알고리즘, I-step과 P-step이 존재.</p>
<div id="i-step" class="section level5" number="4.10.2.0.1">
<h5 number="4.10.2.0.1"><span class="header-section-number">4.10.2.0.1</span> 1. I-Step</h5>
<p>$
<span class="math display">\[\begin{alignat}{4}



Y_2 \vert Y_1 &amp;\sim N &amp;&amp; \Big( \mu_2 + \Sigma_{21} \Sigma_{11}^{-1} (Y_1 - \mu_1) , &amp;&amp; \Sigma_{22}  - \Sigma_{21}\Sigma_{11}^{-1} \Sigma_{12} \Big) \\

Y_{i, mis} \vert Y_{i, obs}, \mu, \Sigma &amp;\sim N_{dim(Y_{mis}^{(i)})} &amp;&amp; \Big( \mu_{mis}^{(i)} + \Sigma_{mis, obs}^{(i)} \Sigma_{obs, obs}^{-1} (Y_{i, obs} - \mu_{i, mis}^{(i)}) , &amp;&amp; \Sigma_{mis,mis}^{(i)}  - \Sigma_{mis,obs}^{(i)}[\Sigma_{obs,obs}^{(i)}]^{-1} \Sigma_{obs,mis}^{(i)} \Big)

\end{alignat}\]</span>
$</p>
<p>상기의 conditional pdf로 우리는 <span class="math inline">\(Y_{i, mis}\)</span>를 impute 가능.</p>
<p><strong>for <span class="math inline">\(i=1, \cdots, n\)</span>, <span class="math inline">\(Y_{i, mis} \vert Y_{i, obs}\)</span> 에서 <span class="math inline">\(Y_{i, mis}\)</span>를 draw.</strong></p>
</div>
<div id="p-step" class="section level5" number="4.10.2.0.2">
<h5 number="4.10.2.0.2"><span class="header-section-number">4.10.2.0.2</span> 2. P-Step</h5>
<p>베이지안 분석을 위해선 prior가 필요. 여기서 prior는 이하로 설정하자. <span class="math inline">\(q\)</span>는 known integer이며, <span class="math inline">\(q=p\)</span>인 상황에 이는 <span class="math inline">\(\Sigma\)</span>에 대한 Jefferey’s prior.</p>
<p>$</p>
<p>(, ) ^{-}</p>
<p>$</p>
<p>위와 같이 식들을 구성하였을 때, com 데이터에 대한 posterior distribution <span class="math inline">\(\pi(\mu, \Sigma \vert Y_1 , \cdots, Y_n)\)</span>는 이하와 같이 characterized 가능. 이는 inverse-Wishart 분포.</p>
<p>$</p>
<p>Y_1 , , Y_n  { - tr( ^{-1} S ) }</p>
<p>$</p>
<p>이렇게 획득해온 패러미터들을 사용해 <span class="math inline">\(\mu\)</span>의 post를 구하면 이하와 같다.</p>
<p>$</p>
<p>, Y_1 , , Y_n N_p ( Y  )</p>
<p>$</p>
<p><strong><span class="math inline">\(\Sigma \vert Y_1 , \cdots, Y_n\)</span>에서 <span class="math inline">\(\Sigma\)</span> 를 생산</strong></p>
<p><strong>이후 <span class="math inline">\(\mu \vert \Sigma, Y_1 , \cdots, Y_n\)</span>에서 <span class="math inline">\(\mu\)</span> 를 생산</strong></p>
<hr />
</div>
</div>
<div id="bayesian-adaptive-clinical-trial-with-delayed-outcomes" class="section level3" number="4.10.3">
<h3 number="4.10.3"><span class="header-section-number">4.10.3</span> Bayesian adaptive clinical trial with delayed outcomes</h3>
<div id="continual-reassessment-method" class="section level5" number="4.10.3.0.1">
<h5 number="4.10.3.0.1"><span class="header-section-number">4.10.3.0.1</span> Continual Reassessment Method</h5>
<p>Clinical Trial: Toxicity -&gt; Efficacy -&gt; Confirmation</p>
<p>희귀병 케이스에서는 도즈 레벨을 1~n까지 정해둔 후, 샘플을 slice 하여 1번 subsample에 도즈1 투입. 유효하면 (1차시에 3명 투입했다고 하고 그중에 1명이 독성 나왔으면 독성 확률은 1/3. 해당 여부로 도즈2로 넘어갈 것인지를 판단) 2투입. 2에서 문제 생기면 1로 복귀하고 2번 subsample에 도즈1 투입해봐서 유효한지 검증. 이렇게 모든 서브샘플에 도즈레벨 오가면서 투입해보고 최적 도즈레벨 결정.</p>
<p><img src="99-0.png"></p>
<p>이때 CRM을 시작하기 전 대략적으로 이정도의 도즈레벨이 최적 도즈레벨일 것이라는 예측 (Skeleton)을 정하고 CRM을 시작함.</p>
<hr />
<ul>
<li>delay outcome</li>
</ul>
<p>이전 환자들의 evaluation이 끝나기 전에 (evaluation period가 경과하기 전이나, 결과가 나오기 전에) 환자 풀이 증가하는 상황</p>
<p>이 상황에서는 관측이 더 된 환자보다 덜 된 환자에서 outcome이 발생할 확률이 높음. 9개월 누워있던 놈보다 2개월 누워있던 놈이 12개월 경과 전에 뭔가 변화를 보이기 쉽다는 소리.</p>
<p>이때 아직 결과를 관찰하지 못한 환자들을 mis로 지정. 이 상황은 누워있던 기간이 결과 발생 여부라는 variant와 직결되어 있으므로 NMAR. 그러니까, 여기서 결과값은 outcome이 발생했는지 안했는지, 그리고 variable은 환자나 누워있던 기간.</p>
<p>위에서 언급했듯 누워있던 기간이 짧으면 변이확률 높음. 따라서 각각에 대해 다른 survival function을 적용하여 각각의 다른 확률 뽑아낸 후 이거 기반으로 DA 진행하면 해결.</p>
<hr />
</div>
</div>
<div id="nmar의-종류" class="section level3" number="4.10.4">
<h3 number="4.10.4"><span class="header-section-number">4.10.4</span> NMAR의 종류</h3>
<p><span class="math inline">\(m_i\)</span>는 missing indicator. <span class="math inline">\(Y_i\)</span>가 mis면 1.</p>
<p>$
f(M, Y X, , ) = _{i=1}^n f(m_i , y_i x_i , , psi)
$</p>
<p>interested in <strong>direct</strong> relationship b/w <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, rather than in subpopulation defined by missing-data pattern.</p>
<div class="line-block">Selection Model | characterize <span class="math inline">\(y\)</span> | missing mechanism |<br />
<span class="math inline">\(f(m_i, y_i \vert x_i, \theta, \psi) =\)</span> | <span class="math inline">\(f_y(y_i \vert x_i, \theta)\)</span> | <span class="math inline">\(\ast f_{m \vert y}(m_i \vert x_i, y_i, \psi)\)</span> |<br />
<span class="math inline">\(f(m_i, y_i \vert x_i, \xi, \psi) =\)</span> | <span class="math inline">\(f(y_i \vert x_i, \xi)\)</span> | <span class="math inline">\(\ast f(m_i \vert x_i, \xi)\)</span> |<br />
Pattern Mixture model | mis 데이터의 다른 패턴들에 의해 <br>정의되는 각각 다른 strata에서의 <span class="math inline">\(y_i \vert x_i\)</span>의 분포 | probability of different patterns in missingness |</div>
<p>missing의 다른 패턴에 따라 <span class="math inline">\(x_i\)</span>가 결정이 되고, 그 <span class="math inline">\(x_i\)</span>를 기준으로 놓았을 때의 <span class="math inline">\(y_i\)</span>의 분포가 궁금.</p>
<hr />
</div>
<div id="wk10-bayesian-model-selection" class="section level3" number="4.10.5">
<h3 number="4.10.5"><span class="header-section-number">4.10.5</span> wk10) Bayesian Model Selection</h3>
<p>해당 문제는 prior을 어떻게 고르느냐에 따라서 해결될 수 있음. 이하는 해당 문제에 대한 다양한 해결책들.</p>
<div id="spike-and-slab-prior" class="section level5" number="4.10.5.0.1">
<h5 number="4.10.5.0.1"><span class="header-section-number">4.10.5.0.1</span> 1. Spike-and-Slab prior</h5>
<p>let <span class="math inline">\(X_{n \times p} , Y_{n \times 1}\)</span>, then <span class="math inline">\(Y = X \beta\)</span>, where <span class="math inline">\(\beta_{p \times 1}\)</span>.</p>
<p>p가 많다, 즉 배리어블이 많다는 이야기는 실제 각각의 x의 정보량이 중첩될 가능성이 큼. 그러면 수학적으로는 x’x가 full rank matrix가 아닐 것이며, 이는 곧 몇몇 변수들 간에 서로간의 의존관계가 강하여 의미없는 정보를 포함하는 변수들이 많아질 것. 이러한 의미없는 변수를 삭제하고 실제로 필요한 변수들만 골라내어 y에 대한 inference를 하고 싶음. 이것이 모델 셀렉션 문제이며 이걸 베이지안적으로 풀어내는 것이 곧 Bayesian Model Selection.</p>
<p>무지성 prior로는 <span class="math inline">\(\pi(\beta) \sim N(0, \sigma^2)\)</span>가 쓰이지만, 이로는 variable selection이 불가. <span class="math inline">\(\beta\)</span> 중 하나의 component가 0에 가깝게 나왔다고 한들 이것을 0으로 판정할 indicator가 없기 때문. (HPD interval을 구성해서 이것이 0을 포함하면 내치는 식의 방법도 있지만 일단은.)</p>
<p>따라서 다른 prior를 필요로 함. 바로 여기서 사용되는 것이 <strong>Spike-and-Slab prior</strong>. 이름에서 알 수 있듯이 mixture distribution을 prior로 사용함. <span class="math inline">\(\beta\)</span>의 component가 spike 부분에 포함되면 이를 0으로 판정함, 즉 not significant로 판정. 이의 역은 slab part.</p>
<p>이는 곧 prior로 variable selection을 한다는 이야기이다. 즉 이 상황에서는 prior가 패널티로 들어간 것이 된다. 정의적으로 엄밀하게 패널티는 아니지만 사실상의 패널티로 작동. 패널티 term (error penalty)으로 골라내는 것은 full context에서 많이 사용? 이때는 라플라스 프라이어를 쓰고, 노멀을 프라이어 주면? 패널티 텀을 베이지안 인퍼런스로 연결지어서 생각할 수 있지만, 이 배리어블 셀렉션은 디멘션 셀렉션과 연관이 있기 때문에 위와는 정확하게는 다른 개념?</p>
<p>variable selection에는 3가지 방법:
1. 패널티 텀
2. mixture prior
3. 컴퓨테이셔널 (reversible jump, dimension selection) (gradient descent는 아님!)</p>
<p><img src = "99-1.png"></p>
<p>spike 파트 (아래에서는 <span class="math inline">\((1-\lambda)N(0, \sigma^2)\)</span>) 에는 double exponential을 쓰거나, normal 을 변형해서 사용함. 혹은 극단적으로는 dirac 분포 (point mass) 를 쓸 수도 있음.</p>
<p>이하에서 예시로 제시된 수식은 SS prior이며, 이는 spike와 slab 모두 Normal을 사용하였음.</p>
<p>$
() (1-)N(0, ^2) + N(0, ^2), ; ; ; ; ; w 
$</p>
<p>위에서 <span class="math inline">\(\sigma^2\)</span>는 spike variance, <span class="math inline">\(w \sigma^2\)</span>는 slab variance.</p>
<p>여기서 <span class="math inline">\(\lambda\)</span>가 취할 수 있는 값은 0 아니면 1. 확인할 수 있듯이 1이면 slab part, 즉 significant하고, 0이면 역으로 not significant. 우리는 이에 MCMC 알고리즘을 적용하게 되며, 따라서 MCMC 샘플로 계산을 하면 해당 샘플에서 0인 propotion과 1인 비율이 나오게 될 것. 이때 1인 비율이 0.5 이상이면? 해당 component (변수) 는 significant 하다고 결론짓는 것이 가능하다.</p>
<p>$
<span class="math display">\[\begin{alignat}{3}

\pi(\beta, \lambda, \sigma^2, \omega \vert y, x) &amp;\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) &amp;&amp; f(y \vert x, \beta, \lambda, \sigma^2, \omega) \\
&amp;\sim \pi(\beta \vert \lambda, \sigma^2, \omega )  \pi(\lambda, \sigma^2, \omega) &amp;&amp;L( x, \beta, \lambda, \sigma^2, \omega \vert y) \\

\\

\pi(\lambda) &amp;\sim BETA(1,1), \; \; \; \pi(\sigma^2) \sim \cdot \tag{1}, \; \; \; \omega \sim 1 + GAM(\alpha, \beta)

\end{alignat}\]</span>
$</p>
<ol style="list-style-type: decimal">
<li>이때 <span class="math inline">\(\sigma^2\)</span>는 우리가 임의로 fixed 해서 given으로 잡거나, 위처럼 prior로 해서 시뮬레이션 중에 생산되도록 할수도 있다. 여기선 <span class="math inline">\(\dfrac{1}{U(4,100)}\)</span>을 사용.</li>
</ol>
<p>accept를 하기 위해선 위를 돌리면 됨. 이는 <strong>Stochastic Search Variable Selection (SSVS)</strong>라고 불림. 이는 GS를 통하여 패러미터를 sequentially update. 이의 결과값은 다음과 같으며, 프로세스는 그 다음과 같다.</p>
<p>$
(_1 , , _p, _1, , _p, ^2, )
$</p>
<ul>
<li>Proceeds:
<ol style="list-style-type: decimal">
<li>update model parameter <span class="math inline">\(\beta_i^{(t+1)} \sim \pi( \beta_{i} \vert y, x, \beta_{-i}^{(t)}, \lambda_{i}^{(t)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>
<ul>
<li>where <span class="math inline">\(\beta_{-i}^{(t)} = \left( \beta_{1}^{(t+1)}, \cdots, \beta_{i-1}^{(t+1)}, \beta_{i+1}^{(t)}, \cdots, \beta_{p}^{(t)} \right)\)</span></li>
<li><strong>Simple GS로도 가능하고, MH-within-Gibbs로도 가능함</strong></li>
</ul></li>
<li>update <span class="math inline">\(\lambda_I^{(t+1)} \sim \pi(\lambda_i \vert y, x, \lambda_{-i}^{(t)}, \beta_{i}^{(t+1)}, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>
<ul>
<li>where <br> $P( <em>{i}^{(t+1)} = 1 y, x, </em>{-i}^{(t)}, _{i}^{(t+1)}, {<sup>2}</sup>{(t)}, ^{(t)} )=  {a+b} BER( {a+b} ) $.
<ul>
<li><span class="math inline">\(a = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=1, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>.</li>
<li><span class="math inline">\(b = \pi( \beta_{i}^{(t+1)} \vert y, x, \lambda_{i}^{(t+1)}=0, {\sigma^2}^{(t)}, \omega^{(t)} )\)</span>,</li>
</ul></li>
</ul></li>
<li>update <span class="math inline">\(\sigma^2\)</span></li>
<li>update <span class="math inline">\(\omega\)</span></li>
</ol></li>
</ul>
<hr />
</div>
<div id="horseshoe-prior-scale-mixture-prior" class="section level5" number="4.10.5.0.2">
<h5 number="4.10.5.0.2"><span class="header-section-number">4.10.5.0.2</span> 2. Horseshoe prior (Scale-mixture prior)</h5>
<p><strong>distribution에서 scale이란 Variance</strong>.</p>
<p>위와 동일 케이스 가정. 그 경우</p>
<p>$
<span class="math display">\[\begin{alignat}{4}

\pi(\beta \vert y, x) \propto f(y \vert x, \beta) \pi(\beta), \; \; \; \; \; &amp;\pi(\beta) &amp;&amp; \sim N(0, \sigma^2) \\
 
\Longrightarrow &amp;\pi(\beta_i \vert \tau, \lambda_i) &amp;&amp; \sim N(0, \tau^2 \lambda_i^2) 

\end{alignat}\]</span>
$</p>
<ul>
<li>where <span class="math inline">\(pi(\tau^2), \pi(\lambda_i^2) \sim Cauchy^{+}(0,1)\)</span></li>
</ul>
<p>이때 common variance component <span class="math inline">\(\tau\)</span>는 각 component마다 공유하는 1개의 variance component, 그리고 각 component마다 indiviually 고유한 individual parameter variance component <span class="math inline">\(\lambda_i\)</span>를 설정한 것.</p>
<hr />
</div>
</div>
<div id="autologistic-model" class="section level3" number="4.10.6">
<h3 number="4.10.6"><span class="header-section-number">4.10.6</span> Autologistic model</h3>
<p><img src="99-2.png">
<img src="99-3.png">
<img src="99-4.png"></p>
<hr />
</div>
<div id="wk10-bayesian-model-averaging" class="section level3" number="4.10.7">
<h3 number="4.10.7"><span class="header-section-number">4.10.7</span> wk10) Bayesian Model Averaging</h3>
<p>해당 상황에서 연구자는 다양한 모델 예측 후보를 생각해볼 수 있음. 보통은 프로세스를 거쳐 이 모델들 중의 하나를 선택하게 됨. 하지만 완벽한 모델이라는 건 (보통) 존재할 수 없음, 어떤 모델 후보를 선택하든 해당 후보가 내포하고 있는 uncertainty가 존재하며 이를 수용하게 됨. 따라서 모델을 선택한다는 것은 동시에 over-confidence inference 문제를 발생시킨다. 따라서 모델 후보군을 하나만 골라야 한다는 고정관념을 벗어나 다양한 모델 후보군들 각각을 동시에 반영하자. 이 동시 반영할 때 각 모델이 내포하고 있는 확률 (uncertainty)에 의해 각 모델의 반영 정도를 가감하게 된다.</p>
<p>BMA는 패러미터 estimate를 획득할 때, 이러한 model uncertainty를 설명하기 위한 일관된 메커니즘을 제공한다.</p>
<p>given 데이터 <span class="math inline">\(D\)</span>, posterior prob of <span class="math inline">\(\mathcal{M}_k\)</span> <span class="math inline">\(= P(\mathcal{M}_k \vert D) = \dfrac{L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}{\sum_{k=1}^k L(D \vert \mathcal{M}_k) P(\mathcal{M}_k)}\)</span>.</p>
<p>이때 marginal likelihood under <span class="math inline">\(\mathcal{M}_k)\)</span> <span class="math inline">\(L(D \vert \mathcal{M}_k) = \int L(D \vert \theta \mathcal{M}_k) \pi(\theta \vert \mathcal{M}_k) d \theta\)</span>이며, integral 안의 수식은 posterior of model의 상수배</p>
<p>In brief, BMA는 model uncertainty를 설명할 수 있는 posterior density를 획득하기 위해 integral을 취한다 (model에 대해 마지널化). (각각의 모델에 대한 model uncertainty를 구한다)</p>
<p>이를 통해 최종적으로 posterior sample 같은 경우에는 각 모델 별로 model probability에 posterior sample의 probability를 다 더해준 값이 실제로 우리의 <span class="math inline">\(\theta\)</span>에 대한 post가 된다.</p>
<p>즉슨 BMA란 다양한 모델 후보군들이 존재할 때, 그 어떤 상황에서도 robust inference를 가능케 하는 tool이 바로 BMA.</p>
<hr />
<div id="ex-bma-crm" class="section level5" number="4.10.7.0.1">
<h5 number="4.10.7.0.1"><span class="header-section-number">4.10.7.0.1</span> Ex: BMA-CRM</h5>
<p>CRM 시작 전에 skeleton 정하고 시작하는 건 자명. 근데 이 skeleton이 잘못 선정되었다면 제대로된 도즈 selection이 불가능해지므로 skeleton의 선정이 잘못되어 있다면 이는 치명적임. 상식적으로, 하나의 skeleton으로만 도즈 셀렉션을 진행한다면 문제가 생길 확률은 당연히 높음. 이런 리스크를 희석하기 위해 skeleton을 다수를 정하고 CRM을 시작하면 이런 문제를 다소 회피할 수 있지 않을까? 이때 이 각각의 스켈레톤 하나하나를 모델로 인식한다. 이 각각의 모델에 따라서 CRM을, 즉 도즈레벨을 업데이트할 확률을, 즉 업데이트 할 때 패러미터 evaluation을 하는데, 그때 나오는 패러미터 값과 그 각각의 모델 probability를 비교하여 그 모델 averaging을 해주면 그 어떤 상황이 와도 굉장히 robust 한 값을 획득할 수 있을 것.</p>
<hr />
<ol style="list-style-type: decimal">
<li><p>Main research question</p></li>
<li><p>Justification for your research question (why is it important to answer the question?)</p></li>
<li><p>Data source</p></li>
<li><p>Data analysis</p></li>
<li><p>Summary of the data analysis results and conclusion</p></li>
<li><p>Appendix (if needed)
– R scripts (scripts or codes for any other software)</p></li>
</ol>
<p>1
– Technical details regarding the statistical tools used in the analysis</p>
<p>비교적 오랜 기간 데이터가 잘 정립된 MLB 기록 활용을 위해
수업 시 활용하였던 Lahman package(R) 사용</p>
<p>야구는 공격과 수비로 이루어지며, 따라서 분석을 진행함에 있어</p>
<p>야구는</p>
<p>야구 스탯들 간에 상당한 수준의 선형성이 보장되어 이</p>
<p>타자의 가치 = α∗Batting+β∗Fielding, α,β는 임의의 패러미터</p>
<p>선수의 타격능력은 이른바 클래식 스탯으로 불리는 다양한 구형 통계량으로도 표기하는데 문제가 없지만, 수비능력은 선수별로 할당된 수비범위가 천차만별이며 선수가 수비시도를 하지 않으면 선수의 실책으로 이어지지 않는다는 점 때문에 선수 개별의 수비능력이 객관적으로 평가되기 시작한 것은 구장의 정보를 훨씬 자세하게 담을 수 있게 된 2000년대 중반부 이후부터의 이야기.</p>
<p>최신야구에서 선수 수비능력의 평가는 주로 Ultimate Zone Rating (UZR) 로 이루어지며, 해당 스탯은 ARM (달린거리), DPR (병살), RngR (수비커버리지), ErrR (에러빈도) 등 수비에 관련된 스탯을 총집합하여 망라하는 고밀도 스탯이다. 그러나 해당 스탯의 계산은 2002년 BIS (Baseball Info Solutions)라는 회사에서 제공하는 유료 데이터셋과 15년 도입된 스탯캐스트 데이터에 거의 전적으로 의존하고 있다. 스탯캐스트 데이터는 민간에 어느정도는 공개되어 있어 접근이 불가능하지 않지만 (<a href="https://baseballsavant.mlb.com/statcast_leaderboard" class="uri">https://baseballsavant.mlb.com/statcast_leaderboard</a>), BIS 데이터는 접근이 어렵다.</p>
<p>이와 같은 이유로 선수별 수비 스탯을 구하기를 시도하기보단 팀별 수비력에 대한 척도인 Defensive Efficiency Ratio (DER)를 사용하고자 한다. 최대 12개의 팀인만큼 팀 간의 차이를 포착하기 쉬우며, 12개의 팀으로 표준화되니만큼 아웃라이어들이 평준화되어 전반적인 경향성으로 기능하는 것을 기대해볼 수 있다. DER의 수식은 다음과 같다.</p>
<p>DER의 계산법은 이하와 같다.</p>
<p>DER=1−(Hits+Reached.On.Error−HomeRunsPlate.Appearance−BB(Walks)−Strike.Out−Hit.By.Pitch−HomeRuns)</p>
<p>Teams %&gt;%
mutate(., DER = 1-((H + E - HR)/((AB + SF) - SO - HR))) %&gt;%
##select(., yearID, teamID, Rank, SO, SOA)
select(.,yearID, teamID, franchID, Rank, G,DER) -&gt; Teams_DER</p>
<p>물론 같은 팀에 속했다는 이유만으로 모든 선수들에게 동급의 수비스탯을 배정하는 건 합리적이라고 말하기 어렵다. 팀의 수비에 기여하는 정도가 높은 선수가 있다면 낮은 선수도 있을 것이 자명하기 때문이다. 따라서 팀별로 획득한 DER을 수비에 대한 클래식 스탯인 각 선수의 Fielding Percentage(FPCT) 나 Range Factor(RF)의 비율로 스케일링해서 부여하자. 두 스탯은 각각 수비능력과 개인의 수비범위 평가를 위해 시도되었던 스탯들이지만, 전자는 개인의 수비범위가 좁으면 더 좋은 값이 나온다는 한계, 후자는 공이 본인 위치로 떨어졌을 때 스탯계산에서 이득을 본다는 한계를 넘지 못해 좋은 스탯으로는 평가받지 못했던 값들이다. 그러나 팀 단위로 한번 수비력을 표준화한 후 팀 내에서 상대적인 기여도를 보는 식으로 보정이 한 번 들어갔으므로 어느정도 기준선으로서는 기능할 것이라고 기대된다.</p>
<p>이를 위해 선수생활 중의 메인 수비포지션 지정하고 해당 포지션에서의 통계량만 사용.</p>
<!--chapter:end:211299_Else.Rmd-->
</div>
</div>
</div>
</div>
<div id="mva" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> MVA</h1>
<div id="overview-of-mva-not-ended" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Overview of mva (not ended)</h2>
<p>Find relationships b/w <span class="math inline">\(\pmb x_p, \pmb y_q\)</span>, e.g.,
* Response variables (variable directed)
* PCA
* Factor Analysis
* mv Regression
* Cannonical Correlation Analysis
* Experiment units (individual directed)
* Discriminant Analysis
* Cluster Analysis
* MANOVA</p>
<p>Multivariate techniques tend to be exploratory.
* i.e. not hypothesis testing type</p>
<p>Experimental units <strong>must be independent</strong>. Time series data are not appropriate for this course.</p>
<p><br>
<br>
<br></p>
<div id="notation" class="section level3" number="5.1.1">
<h3 number="5.1.1"><span class="header-section-number">5.1.1</span> Notation</h3>
<p>Variable <span class="math inline">\(y_1 , \cdots, y_p\)</span></p>
<p>One observation <span class="math inline">\(\pmb y &#39; = (y_1 , \cdots, y_p )\)</span></p>
<p>Data Matrix <span class="math inline">\(Y_{n \times p} = \begin{bmatrix} \pmb y &#39; = (y_1 , \cdots, y_p ) \\ \vdots \\ \pmb y &#39; = (y_1 , \cdots, y_p ) \end{bmatrix}\)</span></p>
<p>Random Samples: Suppose we intend to collect n sets of measurements on p variables, but not been observed yet. If $x_1 ‘, , x_n’ $ are independent observation from pdf <span class="math inline">\(f(\pmb x) = f(x_1, \cdots, x_p)\)</span>, then $x_1 ‘, , x_n’ $ are said to be rs from <span class="math inline">\(f(\pmb x)\)</span>.</p>
<p>rvec <span class="math inline">\(\pmb X = X_{p \times n} = \begin{bmatrix} \pmb x_1 \\ \vdots \\ \pmb x_p \end{bmatrix}\)</span></p>
<p>mean vector <span class="math inline">\(\pmb \mu = E (\pmb x) = \begin{bmatrix} \mu1 \\ \vdots \\ \mup \end{bmatrix}\)</span></p>
<p>Covariance Matrix <span class="math inline">\(\Sigma\)</span></p>
<p>Correlation Matrix <span class="math inline">\(\rho\)</span>, <span class="math inline">\(\rho_{ij} = \tfrac{\sigma_{ij}}{\sigma_{ii}\sigma_{jj}}\)</span>
* Correlation measures linear association.
* Correlation is 0 if <strong>symmetric</strong> non-linear association exists.</p>
<p><br>
<br>
<br></p>
</div>
<div id="summary-statistics" class="section level3" number="5.1.2">
<h3 number="5.1.2"><span class="header-section-number">5.1.2</span> Summary Statistics</h3>
<ol style="list-style-type: decimal">
<li>Sample Mean Vector <span class="math inline">\(\bar X=\)</span> estimate of <span class="math inline">\(\pmb \mu\)</span></li>
<li>Sample Covariance Matrix</li>
<li>Sample Correlation Matrix</li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="statistical-inference-on-correlation" class="section level3" number="5.1.3">
<h3 number="5.1.3"><span class="header-section-number">5.1.3</span> Statistical Inference on Correlation</h3>
<p>$
H_0: = 0
$</p>
<p>test stat <span class="math inline">\(T=\dfrac {r \sqrt{n-2}}{\sqrt{1-r^2}} \sim t_{n-2}\)</span>, where <span class="math inline">\(r=Corr(x,y)\)</span> and <span class="math inline">\(x \sim N_2, y \sim N_2\)</span>
Notes:
1. Correlation measures a linear relationships
2. it is still difficult to get a CI for <span class="math inline">\(\rho\)</span>.</p>
<p><br>
<br></p>
<div id="ci-for-rho" class="section level5" number="5.1.3.0.1">
<h5 number="5.1.3.0.1"><span class="header-section-number">5.1.3.0.1</span> CI for <span class="math inline">\(\rho\)</span></h5>
<ol style="list-style-type: decimal">
<li>Fisher’s Method:</li>
</ol>
<p><span class="math inline">\(100(1-\alpha)%\)</span> CI for <span class="math inline">\(\rho\)</span> $=((r)  )</p>
<ol start="2" style="list-style-type: decimal">
<li>Ruben’s Method</li>
</ol>
<p>let <span class="math inline">\(u=z_{\alpha/2}, r^\ast = \dfrac {r}{\sqrt{1-r^2}\)</span></p>
<p>$
<span class="math display">\[\begin{align*}
a &amp;= 2n-3-u^2
b &amp;= r^\ast \ast \sqrt{(2n-3)(2n-5)}
c &amp;= (2n-5-u^2} \ast (r^\ast)^2 - 2u^2

\end{align*}\]</span>
$</p>
<p>set <span class="math inline">\(ay^2 - 2by +c =0\)</span>, then root of this equation will be <span class="math inline">\(y_1, y_2 = \dfrac{b}{a} \pm \dfrac {\sqrt{b^2-ac}}{a}\)</span>.</p>
<p>이때 <span class="math inline">\(100(1-\alpha)%\)</span> CI for <span class="math inline">\(\rho\)</span> <span class="math inline">\(=\left[ \dfrac{y_1}{\sqrt{1+y_1^2}, \dfrac{y_2}{\sqrt{1+y_2^2}, \right]\)</span>
* 이때, input은 <span class="math inline">\(n, \alpha, r\)</span>, output은 <span class="math inline">\(\rho\)</span>의 CI.</p>
</div>
</div>
<div id="standardization" class="section level3" number="5.1.4">
<h3 number="5.1.4"><span class="header-section-number">5.1.4</span> Standardization</h3>
</div>
<div id="missing-value-treatment" class="section level3" number="5.1.5">
<h3 number="5.1.5"><span class="header-section-number">5.1.5</span> Missing Value Treatment</h3>
<!--chapter:end:211301_Overview.Rmd-->
</div>
</div>
<div id="multivariate-nomral-wk2" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Multivariate Nomral (wk2)</h2>
<div id="overview-2" class="section level3" number="5.2.1">
<h3 number="5.2.1"><span class="header-section-number">5.2.1</span> Overview</h3>
<p>let rvec <span class="math inline">\(Z=(Z_1 , \cdots, Z_p)&#39;, Z_i \overset {iid}{\sim} N(0,1)\)</span>.</p>
<p>then <span class="math inline">\(X=(X_1 , \cdots, X_p)&#39; = A_{k \times p} Z + \pmb \mu_{k \times 1}\)</span> follows MVN.</p>
<p>at here, if <span class="math inline">\(rank(A)=p(\le k), AA&#39; = \Sigma\)</span>, then <span class="math inline">\(X \sim N_p (0, \Sigma)\)</span>.</p>
<hr />
<p>notation: <span class="math inline">\(\pmb y \sim N_p (\pmb \mu , \Sigma)\)</span></p>
<p>rvec <span class="math inline">\(\pmb y &#39; = [y_1 , \cdots , y_p ]\)</span> have <strong>Multivariate Normal Distribution</strong>, if <span class="math inline">\(\sum_{i=1}^p a_i y_u = \pmb a&#39; y\)</span> has Univariate Normal Distribution, for every possible set of values for the elements in <span class="math inline">\(\pmb a\)</span>.</p>
<p>pdf for <span class="math inline">\(f(\pmb y) = \dfrac{1}{(2\pi)^p {\vert \Sigma \vert}^{1/2}} \exp \left\{ -\dfrac{1}{2} (\pmb y - \pmb \mu)&#39; \Sigma^{-1} (\pmb y - \pmb \mu) \right\}\)</span>.</p>
<hr />
<p>Ellipsoid:
- path of <span class="math inline">\(\pmb y\)</span> values yielding a constant height for the density, <br> i.e., all <span class="math inline">\(\pmb y\)</span> s.t. <span class="math inline">\(\{ (\pmb y - \pmb \mu)&#39; \Sigma^{-1} (\pmb y - \pmb \mu)=c^2 \}\)</span>.</p>
<p><br></p>
<p>Standard Normal Distribtion:
- <span class="math inline">\(\pmb z = \left( {\Sigma^{1/2}}\right)^{-1} (\pmb y -\pmb \mu) \sim N_p (\pmb 0, I_p)\)</span>, <br>where <span class="math inline">\(\left( {\Sigma^{1/2}}\right)^{-1}\)</span> satiesfy $ = ( {<sup>{1/2}})</sup>{-1} ( {<sup>{1/2}})</sup>{-1}$.</p>
<p><br></p>
<p>Property of <span class="math inline">\(\Sigma\)</span>:
1. symmetric Matrix
2. positive definite Matrix
3. $Cov(A y + b) = A A’ $.</p>
<p>※ if <span class="math inline">\(A\)</span> is symmetric and non-singular, then <span class="math inline">\(A=CC&#39;\)</span>, where <span class="math inline">\(C\)</span> is lower triangular Matrix. This is called <strong>Cholesky Decomposition</strong> of <span class="math inline">\(A\)</span>.</p>
<hr />
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E(X)=\mu, Cov(X)=AA&#39; = \Sigma\)</span></li>
<li><span class="math inline">\(M_X (t) = \exp (t&#39; \mu + \dfrac {1}{2} t&#39; \Sigma t\)</span></li>
<li>if <span class="math inline">\(\Sigma=AA&#39;\)</span> is non-singular Matrix <span class="math inline">\(\iff rank(A)=p\)</span></li>
<li><span class="math inline">\(\Sigma = Cov(X)\)</span>는 symmetric, n.n.d.</li>
</ol>
<p>이상의 <span class="math inline">\(X\)</span>에 대해 이하는 TFAE.
1. <span class="math inline">\(X \sim N_p (0, \Sigma)\)</span>.
2.
3.
4.
5.</p>
</div>
<div id="spectral-decomposition" class="section level3" number="5.2.2">
<h3 number="5.2.2"><span class="header-section-number">5.2.2</span> Spectral Decomposition</h3>
<p>if <span class="math inline">\(A\)</span> is symmetric, non-singular, then <span class="math inline">\(A=E \Lambda E&#39;\)</span>, where <span class="math inline">\(\lambda_i\)</span> are ev (<span class="math inline">\(\lambda_1 \ge \cdots \ge \lambda_n\)</span>), and <span class="math inline">\(\pmb e_i\)</span> are evec (<span class="math inline">\(E&#39;E = I_p)\)</span>. This is called <strong>Spectral Decomposition</strong> of <span class="math inline">\(A\)</span>.</p>
<p>$</p>
<p>=</p>
<span class="math display">\[\begin{bmatrix}

\lambda_1 &amp; &amp; \pmb 0 \\  
&amp; \ddots &amp; \\ 
\pmb 0 &amp; &amp; \lambda_n 

\end{bmatrix}\]</span>
<p>, ; ; ; ; ; E=</p>
<p>$</p>
<p>이때 <span class="math inline">\(\Sigma = E \Lambda E&#39; = E \Lambda \Lambda^{1/2} E&#39; = E \Lambda E&#39; E \Lambda^{1/2} E&#39; = \Sigma^{1/2} \Sigma^{1/2}\)</span>.</p>
<p>Center &amp; Axis of ellipsoids of <span class="math inline">\(\{ (\pmb y - \mu)&#39; \Sigma^{-1} (\pmb y - \mu)=c^2 \}\)</span>:
* center: <span class="math inline">\(\pmb \mu\)</span>
* axis : <span class="math inline">\(\pm c \sqrt{\lambda_i \pmb e_i}\)</span></p>
<p><br>
<br></p>
<p>Square root Matrix:</p>
<p>let symmetric non-negative Matrix <span class="math inline">\(A_{p \times p}\)</span>. the square root matrix of <span class="math inline">\(A\)</span> is defined as <span class="math inline">\(A^{1/2} = E \Lambda^{1/2} E&#39;\)</span>, where</p>
<p>$
^{1/2} =</p>
<span class="math display">\[\begin{bmatrix}

\sqrt{\lambda_1} &amp; &amp; \pmb 0 \\  
&amp; \ddots &amp; \\ 
\pmb 0 &amp; &amp; \sqrt{\lambda_n }

\end{bmatrix}\]</span>
<p>$</p>
<p><br>
<br></p>
<p>Negative Square Root Matrix:</p>
<p>Let <span class="math inline">\(A\)</span> be of <strong>full rank</strong> and all of its <strong><span class="math inline">\(\lambda_i\)</span> are positive</strong>, in addition to symmetry. <span class="math inline">\(A^{-1/2} = E \Lambda^{-1/2} E&#39;\)</span>, where</p>
<p>$
^{-1/2} =</p>
<span class="math display">\[\begin{bmatrix}

\dfrac{1}{\sqrt{\lambda_1}} &amp; &amp; \pmb 0 \\  
&amp; \ddots &amp; \\ 
\pmb 0 &amp; &amp; \dfrac{1}{\sqrt{\lambda_n }}

\end{bmatrix}\]</span>
<p>$</p>
<p><br>
<br></p>
<p>Generalized Inverse:</p>
<p>let <span class="math inline">\(A\)</span> be a non-negative M. if <span class="math inline">\(\lambda_1&gt; \lambda_2 &gt; \cdots &gt; \lambda_r &gt; 0 = \lambda_{r+1} = \cdots = \lambda_{p}\)</span>, i.e., not full rank, then the <strong>Moore-Penrose generalized inverse of <span class="math inline">\(A\)</span></strong> is given by</p>
<p>$</p>
<p>A^{-} =</p>
<p> e_1 e_1 ’ + +
 e_r e_r ’</p>
<p>$</p>
<p>where</p>
<p>$
^{-} =</p>
<span class="math display">\[\begin{bmatrix}



\dfrac{1}{\lambda_1} &amp; &amp; &amp; &amp; \pmb 0 \\  
&amp; \ddots &amp; &amp; &amp; \\ 
&amp; &amp; \dfrac{1}{\lambda_n } &amp; &amp; &amp; \\
&amp; &amp; &amp; 0 &amp; &amp;  \\
&amp; &amp; &amp; &amp; \ddots &amp;  \\
\pmb 0 &amp; &amp; &amp; &amp; &amp; 0  \\
\end{bmatrix}\]</span>
<p>$</p>
<p><br>
<br></p>
<p>Marginal Distribtion:</p>
<p>$
<span class="math display">\[\begin{align*}
\pmb y \sim N_p (\pmb \mu , \Sigma)

&amp;\Longrightarrow

y_i \sim N(\mu_i, \sigma^{ii}), \; \; \; i= 1, \cdots, p \\

&amp;\not \Longleftarrow

\end{align*}\]</span>
$</p>
</div>
<div id="properties-of-mvn" class="section level3" number="5.2.3">
<h3 number="5.2.3"><span class="header-section-number">5.2.3</span> Properties of MVN</h3>
<ol style="list-style-type: decimal">
<li>linear combination of the components of <span class="math inline">\(\pmb y\)</span> are normally distributed.</li>
<li>any subset of <span class="math inline">\(\pmb y\)</span> have MVN.</li>
<li>conditional distribution of the components of <span class="math inline">\(\pmb y\)</span> are MVN:</li>
<li></li>
<li></li>
<li></li>
</ol>
<p>$ y N_p(, ) a ’ y N( a ’ , a ’ a ) $</p>
<p>$ y N_p(, ) , ; ;</p>
<p>A_{n times p} =</p>
<span class="math display">\[\begin{bmatrix}

a_{11} &amp; \cdots &amp; a_{1p} \\
\vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; \cdots &amp; a_{np}

\end{bmatrix}\]</span>
<p>A y N_n(A , A A’)
$
즉슨 dimension 변화</p>
<p>if $ y N_p(, )$, and cvec <span class="math inline">\(\pmb d\)</span>, then $ y + d N_p(+ d , )$.</p>
<ol start="2" style="list-style-type: decimal">
<li>If we partition y, μ, S
! !
as follows</li>
</ol>
<p>Let
1
11
2
~ ( , ) p
y
y N
y
μ
é ù
ê ú
= ê ú S
ê ú
ë û
!"
! !
!
with</p>
</div>
<div id="chi2-distribution" class="section level3" number="5.2.4">
<h3 number="5.2.4"><span class="header-section-number">5.2.4</span> <span class="math inline">\(\Chi^2\)</span> distribution</h3>
<p>if <span class="math inline">\(\pmb z \sim N_p ( \pmb 0 , I_p )\)</span>, then <span class="math inline">\(\pmb z &#39; \pmb z = \sum_{i=1}^p z_i^2 \sim \Chi_p^2\)</span>.</p>
<p>if $ y N_p(, )$, then $(y - )’ ^{-1} (y - ) _p^2 $</p>
<p>the <span class="math inline">\(N_p(\pmb \mu , \Sigma)\)</span> distribution assigns probability <span class="math inline">\(1-\alpha\)</span> to the solid ellipsoid <span class="math inline">\(\left \{ \pmb y : (\pmb y - \pmb \mu)&#39; \Sigma^{-1} (\pmb y - \pmb \mu) \le \chi_p^2 (\alpha) \right \}\)</span>, where <span class="math inline">\(\chi_p^2 (\alpha)\)</span> denotes upper <span class="math inline">\((100 \ast \alpha)\)</span> th percentile of the <span class="math inline">\(\chi_p^2\)</span> distribution.</p>
</div>
<div id="linear-combination-of-random-vectors" class="section level3" number="5.2.5">
<h3 number="5.2.5"><span class="header-section-number">5.2.5</span> Linear Combination of Random Vectors</h3>
</div>
<div id="multivariate-normal-likelihood" class="section level3" number="5.2.6">
<h3 number="5.2.6"><span class="header-section-number">5.2.6</span> Multivariate Normal Likelihood</h3>
</div>
<div id="sampling-distribtion-of-bar-pmb-y-s" class="section level3" number="5.2.7">
<h3 number="5.2.7"><span class="header-section-number">5.2.7</span> Sampling Distribtion of <span class="math inline">\(\bar {\pmb y}, S\)</span></h3>
<p>let rvec $ y_1, y_n N_p(, )$.</p>
<p><span class="math inline">\(\bar {\pmb y} \sim N_p (\pmb \mu , \dfrac{1}{n} \Sigma)\)</span></p>
<p>(n-1) S $ Wishart distribution, with <span class="math inline">\(df=n-1\)</span>
* <span class="math inline">\(S\)</span> is random Matrix, e.g., Wishart is distribution of rM.</p>
<p><span class="math inline">\(\bar {\pmb y} \perp S\)</span>.</p>
<div id="wishart-distribtion" class="section level5" number="5.2.7.0.1">
<h5 number="5.2.7.0.1"><span class="header-section-number">5.2.7.0.1</span> Wishart Distribtion</h5>
<p>※ <span class="math inline">\(\dfrac {\sum (x_i - \barx )^2}{\sigma^2} = \dfrac {S^2} {\dfrac{\sigma^2}{n-1}} \sim \chi_{n-1}^2\)</span>, i.e., <span class="math inline">\(\sum (x_i - \barx )^2 = (n-1)S^2 \sim \sigma^2 \ast \chi_{n-1}^\)</span></p>
<p>for let rvec $ y_1, y_n N_p(, )$,</p>
<p>$
<span class="math display">\[\begin{align*}

\sum_{i=1}^n(\pmb y - \pmb \mu)(\pmb y - \pmb \mu)&#39; &amp;\sim W_p (n, \Sigma) \\
\\

(n-1)S^2 = \sum_{i=1}^n(\pmb y - \bar {\pmb y} )(\pmb y - \bar {\pmb y} )&#39; &amp;\sim W_p (n-1, \Sigma)
\end{align*}\]</span>
$</p>
<p>if <span class="math inline">\(A \sim W_p (n, \Sigma), B \sim W_p (m, \Sigma)\)</span>, and <span class="math inline">\(A \perp B:\)</span> <span class="math inline">\(A+B \sim W_p (n+m, \Sigma)\)</span></p>
<p>if <span class="math inline">\(A \sim W_p (n, \Sigma)\)</span>, then <span class="math inline">\(CAC&#39; \sim W_p (n, C \Sigma C&#39;)\)</span></p>
<p><strong><em>if <span class="math inline">\(A \sim W_p (n-1, \Sigma)\)</span>, <span class="math inline">\(f(A)\)</span>, where gamma function.</em></strong></p>
<p><br>
<br></p>
</div>
<div id="mv-t-distribtion" class="section level5" number="5.2.7.0.2">
<h5 number="5.2.7.0.2"><span class="header-section-number">5.2.7.0.2</span> MV t-Distribtion</h5>
<p>※ univariate t-Distribtion <span class="math inline">\(t=\tfrac{\tfrac{U}{\sigma}}{\sqrt{\tfrac{V}{nu}}} \sim t_{\nu}\)</span>, where <span class="math inline">\(U \sim N(0, \sigma^2), V \sim \chi_{\nu}^2\)</span>, and <span class="math inline">\(U \perp V\)</span>.</p>
<p>let $ y = (y_1, , y_n)’ N_p(, )$, and <span class="math inline">\(V \sim \chi_{\nu}^2\)</span>, and <span class="math inline">\(\pmb y \perp V\)</span>.</p>
<p>assume rvec <span class="math inline">\(\pmb t = (t_1 , \cdots, t_p)&#39;\)</span>,<span class="math inline">\(t_i = \tfrac {\tfrac{y_i - \mu_I}{\sigma_i}{\sqrt{V/\nu}}, i=1, \cdots, p\)</span>
* Note that each <span class="math inline">\(t_i \sim t\)</span>.</p>
<p>at here, joint distribution of <span class="math inline">\(\pmb t\)</span> is called MV t-distribution, with <span class="math inline">\(df=\nu\)</span> and matrix parameter <span class="math inline">\(\Sigma\)</span>.</p>
<p><strong><em>denote this distribution by </em></strong></p>
<p><br>
<br></p>
</div>
<div id="dirichlet-distribution" class="section level5" number="5.2.7.0.3">
<h5 number="5.2.7.0.3"><span class="header-section-number">5.2.7.0.3</span> Dirichlet Distribution</h5>
<p>※ is MV generalization of <span class="math inline">\(BETA\)</span>.</p>
<p>let $ y D_p(<em>1 , </em>{p+1})$
* parameters: <span class="math inline">\(\{\nu_i, i=1, \cdots, p+1\}\)</span>
* pdf: f(y) =  _{i=1}^p y_i^{v_i - 1}$</p>
<p>?????????????????????????????????????????????????</p>
<p><br>
<br></p>
</div>
<div id="clt" class="section level5" number="5.2.7.0.4">
<h5 number="5.2.7.0.4"><span class="header-section-number">5.2.7.0.4</span> CLT</h5>
<p>let</p>
<p>$ y_1 , , y_n  {} , &lt; $. then</p>
<p>$
<span class="math display">\[\begin{align*}

\sqrt {n} (\hat {\pmb y} - \pmb \mu) &amp;\overset {d} {\rightarrow} N_p (\pmb 0 , \Sigma) \\

n (\hat {\pmb y} - \pmb \mu)&#39; S^{-1} (\hat {\pmb y} - \pmb \mu)
&amp;\overset {d} {\rightarrow} \chi_p^2

\end{align*}\]</span>
$</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="assessing-normality" class="section level3" number="5.2.8">
<h3 number="5.2.8"><span class="header-section-number">5.2.8</span> Assessing Normality</h3>
<div id="univariate-marginal-distribtion" class="section level5" number="5.2.8.0.1">
<h5 number="5.2.8.0.1"><span class="header-section-number">5.2.8.0.1</span> 1. Univariate Marginal Distribtion</h5>
<div id="a.-q-q-plot" class="section level6" number="5.2.8.0.1.1">
<h6 number="5.2.8.0.1.1"><span class="header-section-number">5.2.8.0.1.1</span> a. Q-Q Plot</h6>
<p>※ Sample quantile vs. quantile of N distribution</p>
<p>let order statitics, or sample quantiles <span class="math inline">\(x_{(1)} \le \cdots \le x_{(n)}\)</span>.</p>
<p>the proportion of sample below <span class="math inline">\(x_{(j)}\)</span> is approximated by <span class="math inline">\(\tfrac{j-\tfrac{1}{2}}{n}\)</span>.</p>
<p>the quantiles <span class="math inline">\(q_{(j)}\)</span> for std. N are defined as</p>
<p>$
P(z q_{j)}) = <em>{-}^{q</em>{(j)}}  ( - z^2 ) dz  
$</p>
<p>if the data arise from a N population, then <span class="math inline">\((\sigma \ast q_{(j)} + \mu \congruent x_{(j)}\)</span>.</p>
<p>Similarly, the pairs <span class="math inline">\((q_{(j)}, x_{(j)})\)</span> will be linearly related.</p>
<p>Proceeds:
1. get <span class="math inline">\(x_{(1)} \le \cdots \le x_{(n)}\)</span> from original obs.
2. calculate probability values <span class="math inline">\(\tfrac{j-1/2}{n}, \; \; j= 1, \cdots, n\)</span>
3. calculate standard normal quantities <span class="math inline">\(q_{(1)}, \cdots, q_{(n)}\)</span>
4. plot the pairs of observations $(q_{(1)}, x_{(1)}), , <span class="math inline">\((q_{(n)}, x_{(n)})\)</span></p>
<p><br></p>
<p>Checking the straightness of Q-Q plot:
* using corr coef
* Hypothesis tesiting: <span class="math inline">\(H_0: \rho=0\)</span>, $T=  t_{n-2}</p>
<p><br>
<br></p>
</div>
<div id="b.-others" class="section level6" number="5.2.8.0.1.2">
<h6 number="5.2.8.0.1.2"><span class="header-section-number">5.2.8.0.1.2</span> b. others</h6>
<ul>
<li><ol style="list-style-type: decimal">
<li>Shapiro-Wilks Test:</li>
</ol></li>
</ul>
<p>Test of correlation coefficient b/w <span class="math inline">\(x_{(j)}, r_{(j)}\)</span>. <span class="math inline">\(r_{(j)}\)</span> is function of the expected value of standard normal order statistics, and their <span class="math inline">\(Cov\)</span>.</p>
<p><br></p>
<ul>
<li><ol start="2" style="list-style-type: decimal">
<li>Kolmogorov-Smirnov Test</li>
</ol></li>
</ul>
<p>Compare cdf’s:</p>
<p>If the data arise from a normal population, the differences are small.</p>
<p>$
T = _x F(x) - S(x) 
$</p>
<p>where cdf <span class="math inline">\(F(x)\)</span>, empirical cdf <span class="math inline">\(S(x)\)</span>.</p>
<p><br></p>
<ul>
<li><ol start="3" style="list-style-type: decimal">
<li>Skewness Test</li>
</ol></li>
</ul>
<p>skewness <span class="math inline">\(\sqrt{b_1} = \tfrac{\sqrt{n} \sum_{i=1}^n (x_i - \bar x)^3} {\left[ \sum_{i=1}^n (x_i - \bar x)^2 \right]^{\tfrac{3}{2}}}\)</span></p>
<p>When the population is normal, the skewness = 0.</p>
<p><br></p>
<ul>
<li><ol start="4" style="list-style-type: decimal">
<li>Kurtosis Test:</li>
</ol></li>
</ul>
<p>kurtosis <span class="math inline">\({b_2} = \tfrac{n \sum_{i=1}^n (x_i - \bar x)^4} {\left[ \sum_{i=1}^n (x_i - \bar x)^2 \right]^{3}}\)</span></p>
<p>When the population is normal, the kurtosis is 3.</p>
<p><br></p>
<ul>
<li><ol start="5" style="list-style-type: decimal">
<li>Lin and Mudholkar (1980):</li>
</ol></li>
</ul>
<p>$</p>
<p>Z = ^{-1}(r) =  (  )
$</p>
<p>where <span class="math inline">\(r\)</span> is the sample <span class="math inline">\(corr\)</span> of <span class="math inline">\(n\)</span> pair <span class="math inline">\((x_i , q_i), \; \; i=1, \cdots, n\)</span> with <span class="math inline">\(q_i = \tfrac {1}{n} \left( \sum_{i \not = j} x_j^2 - \tfrac{1}{n-1} \left( \sum_{i \not = j} x_j\right)^2 \right)^{\tfrac{1}{3}}\)</span>.</p>
<p>if the data arise from a normal population, <span class="math inline">\(Z \sim N(0, \tfrac 3 n)\)</span>.</p>
</div>
</div>
<div id="bivariate-normality" class="section level5" number="5.2.8.0.2">
<h5 number="5.2.8.0.2"><span class="header-section-number">5.2.8.0.2</span> 2. Bivariate Normality</h5>
<p>※ If the data are generated from a multivariate normal, <strong>each bivariate distribution</strong> would be normal.</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Scatter Plot</li>
</ol></li>
</ul>
<p>the contours of bivariate normal density are ellipses. The pattern of the scatter plot must be near elliptical.</p>
<p><br></p>
<ul>
<li><ol start="2" style="list-style-type: decimal">
<li>Squared Generalized Distances</li>
</ol></li>
</ul>
<p>※ <span class="math inline">\(\pmb y \sim N_p (\pmb \mu, \Sigma) \; \; \; \Longrightarrow \; \; \; (\pmb y - \pmb \mu)&#39; \Sigma^{-1} (\pmb y - \pmb \mu) \sim \chi_p^2\)</span>.</p>
<p>it means, for bivariate cases, <strong>Squared Generalized Distances</strong> <span class="math inline">\(d_j^2 = (\pmb x_j - \hat {\pmb x})&#39; S^{-1} (\pmb x_j - \hat {\pmb x}) \sim \chi_2^2\)</span>.</p>
<p><br></p>
<ul>
<li><ol start="3" style="list-style-type: decimal">
<li>Chi2 Plot (Gamma Plot)</li>
</ol></li>
</ul>
<p><span class="math inline">\(d_1^2 , \cdots, d_n^2\)</span> should behave like <span class="math inline">\(\chi_2^2\)</span> rv.
1. order the squared distances <span class="math inline">\(d_{(1)}^2 \le \cdots \le d_{(n)}^2\)</span>
2. calculate the probabilitt values <span class="math inline">\(\tfrac{j-1/2}{n}\)</span>, <span class="math inline">\(j=1,\cdots, n\)</span>
3. Calculate quantiles of <span class="math inline">\(\chi_2^2\)</span> distribution <span class="math inline">\(q_{(1)}, \cdots, q_{(n)}\)</span>.
4. Plot the pairs <span class="math inline">\((q_{(j)}, d_{(j)}^2 ), \; \; j=1, \cdots, n\)</span> where <span class="math inline">\(q_{(j)} = \chi_2^2 \left( \tfrac{j-1/2}{n} \right)\)</span></p>
<p><img src></p>
<p>The plot should resemble a straight line through the origin having slope 1.</p>
<p><br>
<br></p>
</div>
<div id="multivariate-normality" class="section level5" number="5.2.8.0.3">
<h5 number="5.2.8.0.3"><span class="header-section-number">5.2.8.0.3</span> 2. Multivariate Normality</h5>
<p>Practically, it is usually sufficient to investigate the univariate and bivariate distributions.</p>
<p>Chi-square plot is still useful. When the parent population is multivariate normal, and both <span class="math inline">\(n\)</span> and <span class="math inline">\(n-p\)</span> are greater than 25 or 30, the squared generalized distance <span class="math inline">\(d_{1}^2 \le \cdots \le d_{n}^2\)</span> should behave like <span class="math inline">\(\chi_p^2\)</span>.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="power-transformation" class="section level3" number="5.2.9">
<h3 number="5.2.9"><span class="header-section-number">5.2.9</span> Power Transformation</h3>
<p>$
x^=</p>
<span class="math display">\[\begin{cases}

\tfrac{1}{x},                   &amp; \lambda = -1                              \tag{\text{Reciprocal Transformation}}\\
\tfrac{1}{\sqrt{x}},            &amp; \lambda = -\tfrac{1}{2} \\
\ln(x),                             &amp; \lambda = 0 \\
\sqrt{x},                       &amp; \lambda = \tfrac{1}{2} \\
x,                                  &amp; \lambda = 1                   \tag{\text{No Transformation}}

\end{cases}\]</span>
<p>$</p>
<p>Examine Q-Q plot to see whether the normal assumption is satisfactory after power transformation.</p>
<p><br>
<br></p>
<div id="power-transformation-1" class="section level5" number="5.2.9.0.1">
<h5 number="5.2.9.0.1"><span class="header-section-number">5.2.9.0.1</span> Power Transformation</h5>
<p>$
x^() =</p>
<span class="math display">\[\begin{cases}

\tfrac{x^\lambda - 1}{\lambda},                     &amp; \lambda \not = 0 \\
\ln(x),                             &amp; \lambda = 0

\end{cases}\]</span>
<p>$</p>
<p>at here, find <span class="math inline">\(\lambda\)</span> that maximizes</p>
<p>$</p>
<p>l() = - ln+ () _{j=1}^n x_j</p>
<p>$</p>
<p>where <span class="math inline">\(\hat{x_j}^{(\lambda)} = \tfrac{1}{n} \sum_{j=1}^n x_j^{(\lambda)}\)</span></p>
<p>x^{()} is the most feasible values for normal distribution, but not guaranteed to follow normal distribution.
* Transformation (Box-Cox) usually improves the approximation to normality.
* Trial-and-error calculations may be necessary to find <span class="math inline">\(\lambda\)</span> that maximizes <span class="math inline">\(l(\lambda)\)</span>
* Usually, change <span class="math inline">\(\lambda\)</span> values from -1 to 1 with increment 0.1.
* Examine Q-Q plot after the Box-Cox transformation.</p>
</div>
<div id="nqplot-contour-plot-cqplot-cqplot-and-box-cox-plot" class="section level5" number="5.2.9.0.2">
<h5 number="5.2.9.0.2"><span class="header-section-number">5.2.9.0.2</span> nqplot, contour plot, cqplot, cqplot and box-cox plot</h5>
<p><img src></p>
<!--chapter:end:211302_MVN.Rmd-->
</div>
</div>
</div>
<div id="inference-about-mean-vector-wk3" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Inference about Mean Vector (wk3)</h2>
<div id="overview-3" class="section level3" number="5.3.1">
<h3 number="5.3.1"><span class="header-section-number">5.3.1</span> Overview</h3>
<p>Recall:
univariate case <span class="math inline">\(x_1 , \cdots, x_n \overset {iid} {\sim} N(\mu, \sigma^2)\)</span></p>
<p><span class="math inline">\(H_0 : \mu = \mu_0\)</span></p>
<p>$
<span class="math display">\[\begin{alignat*}{2}

\text{test stat } &amp;t &amp;&amp;=\tfrac{\bar X - \mu_0}{\tfrac{S}{\sqrt{n}}} &amp;\overset{H_0}{\sim} t_{n-1} \\


&amp;t^2 &amp;&amp;=\tfrac{(\bar X - \mu_0)^2}{\tfrac{S^2}{n}} &amp;\overset{H_0}{\sim} F_{1, \; n-1}

\end{alignat*}\]</span>
$</p>
<p>reject <span class="math inline">\(H_0\)</span> if as below, which means upper <span class="math inline">\((100-\alpha)\)</span>th percentile.</p>
<hr />
<p>$
<span class="math display">\[\begin{alignat*}{1}
\tfrac{(\bar X - \mu_0)^2}{\tfrac{S^2}{n}} = n(\bar X - \mu_0)\tfrac{1}{S^2}(\bar X - \mu_0) &amp;&gt; F_{1,n-1}(\alpha)
\end{alignat*}\]</span>
$</p>
<p>therefore, with assumption <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\)</span>,</p>
<p>$</p>
<p>H_0 : = _0</p>
<p>$</p>
<p>$
<span class="math display">\[\begin{alignat*}{3}

\text{Hotelling&#39;s }T^2 \; \; T^2 &amp;= n(\bar {\pmb X} - \pmb \mu_0)&#39; S^{-1} (\bar {\pmb X} - \pmb \mu_0) \\

&amp;\overset{H_0}{\sim} \tfrac{(n-1)p}{(n-p)} F_{p,n-p} \\

\iff \; \; \tfrac {(n-p)} {(n-1)p} T^2 &amp;\overset{H_0}{\sim} F_{p,n-p}
\end{alignat*}\]</span>
$</p>
<p>reject <span class="math inline">\(H_0\)</span>, if <span class="math inline">\(T^2 &gt; \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)\)</span>.</p>
<p><br>
<br>
assumption check: <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n \overset{iid}{\sim} N_p (\pmb \mu , \Sigma)\)</span>.</p>
<p><img src></p>
<p><br>
<br></p>
<div id="remark" class="section level5" number="5.3.1.0.1">
<h5 number="5.3.1.0.1"><span class="header-section-number">5.3.1.0.1</span> Remark</h5>
<p>stat <span class="math inline">\(T^2\)</span>는 측정 단위에 invariant. proof)</p>
<p>let $Y_{p } = C_{p p} X_{p } + d_{p } $. then</p>
<p>$
<span class="math display">\[\begin{align*}
\bar {\pmb Y} &amp;= C \bar {\pmb X} + \pmb d \\
\\

S_{\pmb y} &amp;= CSC&#39;\\
\\

\mu_y &amp;= E(\pmb Y) \\
&amp;=C \ast E(\pmb X) + \pmb d \\
&amp;= C \pmb \mu_0 + \pmb d

\end{align*}\]</span>
$</p>
<p>therefore,</p>
<p>$
<span class="math display">\[\begin{align*}

T^2
&amp;= n(\bar {\pmb Y} - \pmb \mu_y)&#39; S_y^{-1} (\bar {\pmb Y} - \pmb \mu_y) \\
&amp;= n \left[ C(\bar {\pmb X} - \pmb \mu_0) \right]&#39; (CSC&#39;)^{-1} \left[ C(\bar {\pmb X} - \pmb \mu_0) \right] \\
&amp;= n (\bar {\pmb X} - \pmb \mu_0)&#39; C&#39; (C&#39;)^{-1} S^{-1}(C)^{-1}  C(\bar {\pmb X} - \pmb \mu_0) \\
&amp;= n (\bar {\pmb X} - \pmb \mu_0)&#39; S^{-1}(\bar {\pmb X} - \pmb \mu_0) 

\end{align*}\]</span>
$</p>
<p><strong><em>여기서 <span class="math inline">\(C^{-1}\)</span>이 존재한다는게 뭔수로 보장되는거지?</em></strong></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="confidence-region" class="section level3" number="5.3.2">
<h3 number="5.3.2"><span class="header-section-number">5.3.2</span> 1. Confidence Region</h3>
<div id="confidence-region-1" class="section level5" number="5.3.2.0.1">
<h5 number="5.3.2.0.1"><span class="header-section-number">5.3.2.0.1</span> Confidence Region</h5>
<p>region <span class="math inline">\(R(\pmb X)\)</span>, is $100(1-) % $ <strong>CR</strong> of</p>
<p>$
<span class="math display">\[\begin{alignat*}{3}


&amp;P \left\{
R(\pmb X) \text{ will cover the true } \pmb \theta 
\right\}

&amp;&amp;= 1-\alpha \\




&amp;P \left\{

n (\hat {\pmb X} - \pmb \mu)&#39; S^{-1}(\hat {\pmb X} - \pmb \mu) \le \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)

\right\}

&amp;&amp;=



\end{alignat*}\]</span>
$</p>
<p>the inequality <span class="math inline">\(n (\bar {\pmb X} - \pmb \mu)&#39; S^{-1}(\bar {\pmb X} - \pmb \mu) \le \tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)\)</span> will define a region <span class="math inline">\(R(\pmb X)\)</span>.</p>
<p><img src></p>
<p>The region is an ellipsoid centered at <span class="math inline">\(\bar {\pmb X}\)</span>.</p>
<p>Testing <span class="math inline">\(H_0 : \mu = \mu_0\)</span> at <span class="math inline">\(\alpha =.05\)</span> is equivalent to see whether <span class="math inline">\(\mu_0\)</span> falls within the CR.</p>
<ul>
<li>with ev <span class="math inline">\(\lambda_1 , \cdots, \lambda_p\)</span>, evec <span class="math inline">\(\pmb e_1 , \cdots, \pmb e_p\)</span> of <span class="math inline">\(S\)</span>,
<ul>
<li>CR Axis: <span class="math inline">\(\pm \sqrt{\lambda}\sqrt{\tfrac{(n-1)p}{(n-p)} F_{p,n-p} (\alpha)} \ast \pmb e_i&#39;\)</span></li>
<li>CR half-length: $ $</li>
</ul></li>
</ul>
</div>
</div>
<div id="simultaneous-ci" class="section level3" number="5.3.3">
<h3 number="5.3.3"><span class="header-section-number">5.3.3</span> 2. Simultaneous CI</h3>
<p>let <span class="math inline">\(\pmb X \sim N_p (\pmb \mu, \Sigma)\)</span>, then linear combination <span class="math inline">\(\pmb a&#39; \pmb X \sim N_p (\pmb a&#39; \pmb \mu, \pmb a&#39; \Sigma \pmb a)\)</span></p>
<p>$
<span class="math display">\[\begin{align*}

t=\dfrac{\bar X - \mu} {S / \sqrt{n}} &amp;\sim t_{n-1} \tag{recall: univariate}\\

t= \dfrac {\pmb a &#39; \bar X - \pmb a &#39; \pmb \mu} {\sqrt{\pmb a &#39; S \pmb a / n } } = \dfrac {\sqrt{n}(\pmb a &#39; \bar X - \pmb a &#39; \pmb \mu)} {\sqrt{\pmb a &#39; S \pmb a} } &amp;\sim t_{n-1} \tag{MV}

\end{align*}\]</span>
$</p>
<p>therefore, <span class="math inline">\(100(1-\alpha)\%\)</span> CI for <span class="math inline">\(\pmb a &#39; \mu\)</span> (at here, <span class="math inline">\(\pmb a\)</span>is fixed) is <span class="math inline">\(\pmb a &#39; \bar {\pmb X} \pm t_{n-1} \dfrac {\alpha} {2} \dfrac{\sqrt{\pmb a &#39; S \pmb a} } {\sqrt{n}}\)</span>. <strong>This is not a simultaneous CI.</strong> let each <span class="math inline">\((a_1 , a_2), (b_1, b_2)\)</span> be CI for <span class="math inline">\(\mu_1 , \mu_2\)</span>. then simultaneous CI <span class="math inline">\((a_1 , a_2), (b_1, b_2)\)</span> has confidence <span class="math inline">\(95\% \ast 95\% = 90.25\%\)</span>. <strong>need a wider interval</strong>.</p>
<p>let rs <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\)</span>.</p>
<p>then, simultaneously for all <span class="math inline">\(\pmb a\)</span>, the interval <span class="math inline">\(\pmb a &#39; \bar {\pmb X} \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p,n-p} (\alpha) \pmb a &#39; S \pmb a}\)</span> will contain <span class="math inline">\(\pmb a &#39; \pmb \mu\)</span> with probability <span class="math inline">\(1-\alpha\)</span>.</p>
<p>$
<span class="math display">\[\begin{alignat*}{3}
\because 1-\alpha 


&amp;=  

P \left[
n 
(\bar {\pmb X } - \pmb \mu)&#39;
S^{-1}
(\bar {\pmb X } - \pmb \mu)


\le

(n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)

\right] \\





&amp;=  

P \left[




(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)&#39;
(\pmb a&#39; S \pmb a)^{-1}
(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)


\le


\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)


\right] \\





&amp;=  

P \left[

(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)&#39;
(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)

\le

\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a&#39; S \pmb a)

\right] 

\tag{∵ Scalar}
\\





&amp;=  

P \left[

(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)^2

\le

\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a&#39; S \pmb a)

\right] \\





&amp;=  

P \left[


-

\sqrt{\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a&#39; S \pmb a)}


\le

(\pmb a&#39; \bar {\pmb X } - \pmb a&#39; \pmb \mu)

\le

\sqrt{\dfrac{1}{n} (n-1) \dfrac {p}{n-p} F_{p,n-p} (\alpha)
\; \ast \;
(\pmb a&#39; S \pmb a)}


\right] 







\end{alignat*}\]</span>
$</p>
<div id="simultaneous-ci-for-mu_i---mu_k" class="section level5" number="5.3.3.0.1">
<h5 number="5.3.3.0.1"><span class="header-section-number">5.3.3.0.1</span> Simultaneous CI for <span class="math inline">\(\mu_i - \mu_k\)</span></h5>
<p>let <span class="math inline">\(\pmb a &#39; = [0,\cdots, 0, a_i, 0, \cdots, 0, a_k, 0, \cdots, 0]\)</span>. then as below, where <span class="math inline">\(S =\begin{bmatrix} S_{11} &amp; \cdots &amp;S_{1p} \\ &amp; \ddots &amp; \\ S_{p1} &amp; \cdots &amp; S_{pp} \end{bmatrix}\)</span>.</p>
<p>$
<span class="math display">\[\begin{align*}
\pmb a &#39; \pmb \mu &amp;= \mu_i - \mu_k \\

\pmb a &#39; S \pmb a  =S_{ii} -2 S_{ik} + S_kk
\end{align*}\]</span>
$</p>
<p>therefore, the simultaneous CI for <span class="math inline">\(\mu_i - \mu_k\)</span>, is <span class="math inline">\((\bar x_i - \bar x_k ) \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p, n-p}(\alpha)S_{ii} -2 S_{ik} + S_kk}\)</span>.</p>
<hr />
<p>at here, if we let <span class="math inline">\(\pmb a &#39; = [1, 0, \cdots, 0]\)</span>.</p>
<p>then</p>
<p>$
<span class="math display">\[\begin{align*}
\pmb a &#39; \pmb \mu &amp;= \mu_1\\

\pmb a &#39; S \pmb a  =S_{11}
\end{align*}\]</span>
$</p>
<p>therefore, the simultaneous CI for $_1 $, is <span class="math inline">\(\bar x_1 \pm \sqrt{\dfrac{n-1}{n} \dfrac{p}{n-p} F_{p, n-p}(\alpha)S_{11}}\)</span>.</p>
<hr />
</div>
</div>
<div id="note-bonferroni-multiple-comparison" class="section level3" number="5.3.4">
<h3 number="5.3.4"><span class="header-section-number">5.3.4</span> 3. Note: Bonferroni Multiple Comparison</h3>
<p>Bonferroni’s CI, <span class="math inline">\(\bar x_1 \pm \left\{ t_{n-1} \left( \dfrac{\alpha}{2p} \right) \right\} \sqrt{\dfrac{S_11}{n}}\)</span>, is more precise (narrower) than simultaneous CI.</p>
<hr />
</div>
<div id="large-sample-inferences-about-a-mean-vector" class="section level3" number="5.3.5">
<h3 number="5.3.5"><span class="header-section-number">5.3.5</span> 4. Large Sample Inferences about a Mean Vector</h3>
<p><em>Recall</em> mv CLT:</p>
<p>let <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\)</span> and for <span class="math inline">\(n-p\)</span> large. then</p>
<p>$
<span class="math display">\[\begin{align*}

\sqrt{n} (\bar {\pmb X} - \pmb \mu) &amp;\overset {d}{\Longrightarrow} N_p (\pmb 0, \Sigma) \\


n (\bar {\pmb X} - \pmb \mu)&#39; S^{-1}(\bar {\pmb X} - \pmb \mu) &amp;\overset {d}{\Longrightarrow} \chi^2_p

\end{align*}\]</span>
$</p>
<hr />
<p>when the sample size is large, the MVN assumption is less critical. therefore,</p>
<p>let <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\)</span>.</p>
<p>$
H_0: = _0
$</p>
<p>when <span class="math inline">\(n-p\)</span> is large, the <span class="math inline">\(H_0\)</span> is rejected if <span class="math inline">\(n (\bar {\pmb X} - \pmb \mu)&#39; S^{-1}(\bar {\pmb X} - \pmb \mu) &gt; \chi^2_p (\alpha)\)</span>.</p>
<p>Note: <span class="math inline">\((n-1) \dfrac{p}{n-p} F_{p,n-p} )\alpha \simeq \chi_p^2(\alpha)\)</span>, for large <span class="math inline">\(n-p\)</span>.</p>
<hr />
<ul>
<li>CI:</li>
</ul>
<p>$
P = 1-
$</p>
<p>the inequality $ n ({X } - )’ S^{-1} ({X } - ) _p^2 () $ will define a region, which means, <span class="math inline">\(100(1-\alpha) \%\)</span> region.</p>
<ul>
<li>Simultaneous CI:</li>
</ul>
<p>let <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n {\sim} ?(\pmb \mu, \Sigma)\)</span> and for <span class="math inline">\(n-p\)</span> large. then</p>
<p><span class="math inline">\(\forall \pmb a\)</span>, <span class="math inline">\(100(1-\alpha) \%\)</span> simultaneous CI for <span class="math inline">\(\pmb a &#39; \pmb \mu\)</span> <span class="math inline">\(= \pmb a &#39; \bar {\pmb X} \pm \sqrt{ \chi_p^2 (\alpha)} \sqrt{ \dfrac{\pmb a &#39; S \pmb a} {n}}\)</span>.</p>
<ul>
<li>Simultaneous CI for <span class="math inline">\(\mu_i\)</span></li>
</ul>
<p>$
x_i  
$</p>
<ul>
<li>Bonferroni’s CI for <span class="math inline">\(\mu_i\)</span></li>
</ul>
<p>$
x_i z_{}
$
- Bonferroni’s CI is more precise. as also.</p>
</div>
<div id="profile-analysis-wk4-5" class="section level3" number="5.3.6">
<h3 number="5.3.6"><span class="header-section-number">5.3.6</span> 1. Profile Analysis (wk4, 5)</h3>
<p>if <span class="math inline">\(\pmb X \sim N_p (\pmb \mu, \Sigma)\)</span>, and the variables in <span class="math inline">\(\pmb X\)</span> are measured in the same unit, we may with to compare the means <span class="math inline">\(\mu_1 , \cdots, \mu_p\)</span> in <span class="math inline">\(\pmb \mu\)</span>.</p>
<p>ex) repeated measure: a measurement is taken at the same experimental unit <span class="math inline">\(p\)</span> successive times.</p>
<p>A profile is a plot, connecting <span class="math inline">\((i, \mu_i), i= 1, \cdots, p\)</span></p>
<hr />
<p>Question: is the profile flat?</p>
<p>$
<span class="math display">\[\begin{align*}

&amp;H_0: \mu_1 = \cdots = \mu_p \\

\iff &amp;H_0: C_1 \pmb \mu = \pmb 0 , \left[ C_1\right]_{(p-1) \times p} \\

\iff &amp;H_0: C_2 \pmb \mu = \pmb 0 , \left[ C_2\right]_{(p-1) \times p}

\end{align*}\]</span>
$</p>
<hr />
<p>if <span class="math inline">\(\pmb X \sim N_p (\pmb \mu, \Sigma)\)</span>, then <span class="math inline">\(C \pmb X \sim N_{p-1} (C \pmb \mu, C \Sigma C&#39;)\)</span>, thus when <span class="math inline">\(H_0 : C \pmb \mu = 0\)</span> is true, then <span class="math inline">\(C \bar X \sim N_{p-1} (C \pmb \mu, C \Sigma C&#39;)\)</span>.</p>
<p>test stat <span class="math inline">\(T^2 = n (C \bar {\pmb X})&#39; (C S C&#39;)^{-1} (C \bar {\pmb X}) \overset{H_0}{\sim} (n-1) \dfrac{p-1}{n-p+1} F_{p-1,n-p+1}\)</span></p>
<p>reject <span class="math inline">\(H_0\)</span>, if <span class="math inline">\(T^2 &gt; (n-1) \dfrac{p-1}{n-p+1} F_{p-1,n-p+1} (\alpha)\)</span>.</p>
<p>**Note: <span class="math inline">\(C_{(p-1) \times p}\)</span> is not square, so there’s no inverse. thus <span class="math inline">\(C\)</span> in test stat doesn’t be canceled.</p>
<p>$
H_0 : C = 0
$</p>
<p>where <span class="math inline">\(C_{q \times p} (q \le p)\)</span>, and <span class="math inline">\(rank(C)=q\)</span>. then</p>
<p>test stat <span class="math inline">\(T^2 = n (C \bar {\pmb X})&#39; (C S C&#39;)^{-1} (C \bar {\pmb X}) \overset{H_0}{\sim} (n-1) \dfrac{q}{n-q} F_{q,n-q}\)</span></p>
<p>which means <span class="math inline">\(p-1\)</span> become <span class="math inline">\(q\)</span>.</p>
<hr />
</div>
<div id="test-for-linear-trend" class="section level3" number="5.3.7">
<h3 number="5.3.7"><span class="header-section-number">5.3.7</span> 2. Test for Linear Trend</h3>
<p>suppose <span class="math inline">\(p\)</span> variables are measured across equally spaced time periods. Also suppose <span class="math inline">\(H_0 : \mu_1 = \cdots = \mu_p\)</span> is rejected.</p>
<p>Question: Do the means fall onto a straight line?</p>
<p>$
<span class="math display">\[\begin{align*}

&amp;H_0: \mu_2-\mu_1 = \cdots = \mu_p-\mu_{p-1} \\

\iff &amp;H_0: \mu_3 -2 \mu_2+\mu_1 = 0, \; \; \cdots, \; \; \mu_p - 2 \mu_{p-1} + \mu_{p-2} = 0 \\

\iff C_{(p-2) \times p},  &amp;H_0: C \pmb \mu = \pmb 0

\end{align*}\]</span>
$</p>
<p>at here, we acquire test stat <span class="math inline">\(T^2 \overset {H_0} {\sim} (n-1) \dfrac{p-2}{n-p+2} F_{p-2,n-p+2}\)</span>.</p>
<hr />
</div>
<div id="inferences-about-a-covariance-matrix" class="section level3" number="5.3.8">
<h3 number="5.3.8"><span class="header-section-number">5.3.8</span> 3. Inferences about a Covariance Matrix</h3>
<p>let rs <span class="math inline">\(\pmb X_1 , \cdots, \pmb X_n \overset {iid} {\sim} N_p (\pmb \mu , \Sigma)\)</span>.</p>
<p>$
H_0 : = _0
$</p>
<p>let <span class="math inline">\(W = (n-1)S = \sum_{i=1}^n (\pmb X_i - \bar {\pmb X})(\pmb X_i - \bar {\pmb X})&#39;\)</span>. then</p>
<p>$</p>
<p>^</p>
<p>= (  )^{} _0^{-1} W ^{} , ; ; ; ; ; ; ; v=n-1</p>
<p>$</p>
<p>then calculate <span class="math inline">\(L=-2 ln \Lambda^\ast \; \; \; \; \; \; \; \overset {H_0}{\sim}\)</span> function of <span class="math inline">\(\chi^2\)</span>-distribution.</p>
<hr />
<ul>
<li>Test for Sphericity (Test for no Correlation)</li>
</ul>
<p>$
H_0 : = ^2 I
$</p>
<p>$ =   $ function of <span class="math inline">\(\chi^2\)</span>-distribution.</p>
<hr />
<ul>
<li>Test for Compound Symmetry</li>
</ul>
<p>if <span class="math inline">\(\Sigma = \begin{bmatrix} \sigma^2 &amp; \rho &amp; \cdots &amp; \rho \\\rho &amp; \sigma^2 &amp; &amp; \vdots \\ \vdots &amp; \rho &amp; \ddots &amp; \rho \\ \rho &amp; \cdots &amp; \rho &amp; \sigma^2 \\ \end{bmatrix}\)</span>, then <span class="math inline">\(\Sigma\)</span> has compound symmetry.</p>
<p>$
H_0: 
$</p>
<p>Compute <span class="math inline">\(\Lambda = \dfrac{\vert S \vert} {(S^2)^p (1-r)^{p-1} (1+ (p-1)r)}\)</span>, where
- $S^2 = <em>{i=1}^p S</em>{ii} $.
- $r =   <em>{i&lt;j}^p S</em>{ij} $.</p>
<p><br></p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(Q&gt; \chi_f^2 (\alpha), \; \; \; \; \; f= \tfrac{p(p+1)-4}{2}\)</span>
- <span class="math inline">\(Q = -\dfrac{(N-1)-p(p+1)^2(2p-3)}{6(p-1)(p^2+p-4)} \ast \ln\Lambda\)</span>.</p>
<!--chapter:end:211305_InferenceaboutMeanVector.Rmd-->
</div>
</div>
<div id="comparison-of-several-mv-means-wk5" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Comparison of Several MV Means (wk5)</h2>
<div id="paired-comparison" class="section level3" number="5.4.1">
<h3 number="5.4.1"><span class="header-section-number">5.4.1</span> Paired Comparison</h3>
<p><em>Recall:</em></p>
<p>for univariate, let <span class="math inline">\(X_i - Y_i = D_i \sim N(\delta, \sigma_d^2)\)</span>, <span class="math inline">\(i=1, \cdots, n\)</span></p>
<p>then for <span class="math inline">\(H_0 : \delta = 0\)</span>, test stat <span class="math inline">\(t = \tfrac{\bar D}{\tfrac{S_d}{\sqrt{n}}} \overset {H_0}{\sim} t_{n-1}\)</span>.</p>
<hr />
<p>Assume independent rvec <span class="math inline">\(\pmb D_1 , \cdots, \pmb D_n \sim N_p (\pmb \delta , \Sigma_{\pmb d})\)</span>.</p>
<p>then test stat <span class="math inline">\(T^2 = n(\bar {\pmb D} - \pmb \delta)&#39; S^{-1}_{\pmb d} (\bar {\pmb D} - \pmb \delta) \sim (n-1)\tfrac{p}{n-p} F_{p, n-p}\)</span>.</p>
<ul>
<li>Hypothesis Testing:</li>
</ul>
<p>$
H_0 : = 
$</p>
<p>$</p>
<p>T^2 = n({D} )’ S^{-1}<em>{d} ({D} )  F</em>{p, n-p}</p>
<p>$</p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T^2 &gt; \tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)\)</span>.</p>
<p><br>
<br></p>
<ol style="list-style-type: decimal">
<li>$100(1-) % $ CR for <span class="math inline">\(\pmb \delta\)</span>:</li>
</ol>
<p>$</p>
<p>({D} - )’ S^{-1}<em>{d} ({D} - )   F</em>{p, n-p} ()</p>
<p>$</p>
<ol start="2" style="list-style-type: decimal">
<li><p>$100(1-) % $ simultaneous CI for individual <span class="math inline">\(\delta_i\)</span>:</p></li>
<li><p>Bonferroni’s $100(1-) % $ simultaneous CI for individual <span class="math inline">\(\delta_i\)</span>:</p></li>
</ol>
<p>$
<span class="math display">\[\begin{alignat*}{3}

\bar d_i \pm 
&amp;\sqrt{\tfrac{(n-1)p}{n-p} F_{p, n-p} (\alpha)} 
&amp;\sqrt{\tfrac{S^2_{d_i}}{n}} \tag{2} \\

\bar d_i \pm 
&amp;t_{n-1} \left( \tfrac {\alpha} {2p} \right)
&amp;\sqrt{\tfrac{S^2_{d_i}}{n}}\tag{3}


\end{alignat*}\]</span>
$</p>
<p><br>
<br></p>
<ul>
<li></li>
</ul>
<p>–</p>
<hr />
<hr />
<p>====</p>
<div id="different-approach" class="section level5" number="5.4.1.0.1">
<h5 number="5.4.1.0.1"><span class="header-section-number">5.4.1.0.1</span> Different Approach</h5>
<p>let <span class="math inline">\(\pmb X = \left[ x_{11}, \cdots, x_{1p}, x_{21}, \cdots, x_{2p} \right]_{1 \times 2p}&#39; \sim N_{2p}(\pmb \mu, \Sigma)\)</span>.</p>
then <span class="math inline">\(\pmb D = C \pmb X\)</span>, where $C = (
<span class="math display">\[\begin{matrix} 1 &amp;  &amp; \pmb 0 &amp; \vdots &amp; -1 &amp;  &amp; \pmb 0 \\  &amp; \ddots &amp;  &amp; \vdots &amp;  &amp; \ddots &amp;  \\ \pmb 0 &amp;  &amp; 1 &amp; \vdots &amp; \pmb 0 &amp;  &amp; -1 \end{matrix}\]</span>
<p>)_{p 2p} $.</p>
<p>at here,</p>
<p>$
<span class="math display">\[\begin{align*}

E(\pmb D) 
&amp;= E(C \pmb X) = C \pmb \mu \\ 
&amp;= \pmb \delta\\
\\

Cov(\pmb D)  
&amp;= Cov(C \pmb X) = C \Sigma C&#39; \\ 
&amp;= \Sigma_d\\

\\

\pmb D &amp;= C \pmb X \sim N_p (C \pmb \mu, C \Sigma C&#39;)

\end{align*}\]</span>
$</p>
<p>therefore, given <span class="math inline">\(H_0 : C \pmb \mu = \pmb 0\)</span>,</p>
<p>test stat <span class="math inline">\(T^2 = n (C \bar {\pmb X})&#39; (CSC&#39;)^{-1} (C \bar {\pmb X}) \overset {H_0}{\sim} \tfrac{(n-1)p}{n-p} F_{p, n-p}\)</span></p>
<p><br></p>
<ul>
<li>graph, check normality:</li>
</ul>
<p><img src></p>
<hr />
</div>
</div>
<div id="comparing-mean-vectors-from-two-populations" class="section level3" number="5.4.2">
<h3 number="5.4.2"><span class="header-section-number">5.4.2</span> Comparing Mean Vectors from Two Populations</h3>
<p><em>Recall:</em>
univariate, $ t =  {sqrt{S_p^2 (  + )}}  t_{n_1 + n_2 - 2}$</p>
<hr />
<p>for MV, assume below, where <span class="math inline">\((\pmb X_{11}, \cdots, \pmb X_{1n_1})\)</span> and <span class="math inline">\((\pmb X_{21}, \cdots, \pmb X_{2n_2})\)</span> are independent.</p>
<p>$
X_{11}, , X_{1n_1} N_p (_1 , _1 )</p>
<p>$
$</p>
<p>X_{21}, , X_{2n_2} N_p (_2 , _2 )
$</p>
<p>at here,</p>
<p>$
H_0 : _1 - _2 = 
$</p>
<hr />
<div id="case-1-_1-_2" class="section level5" number="5.4.2.0.1">
<h5 number="5.4.2.0.1"><span class="header-section-number">5.4.2.0.1</span> case 1: $ _1 = _2 = $</h5>
<p>이하 대부분은 벡터에 관한 이야기이다.</p>
<p><span class="math inline">\(\bar X_i\)</span> estimates <span class="math inline">\(\mu_i\)</span>, <span class="math inline">\(i=1,2\)</span>.</p>
<p><span class="math inline">\(S_p\)</span> estimates <span class="math inline">\(\Sigma\)</span>, where $S_p =  {(n_1-1) + (n_2-1)} $.</p>
<p><br></p>
<p>the test stats <strong>Hotelling’s </strong> $ T^2 =  ( {X_1 } - {X_2} ) ’ S_p^{-1} ( {X_1 } - {X_2} ) $</p>
<p>where $  {p [ (n_1 - 1) + (n_2 - 1) ]} ; T^2 =  {p [ (n_1 + n_2 - 2) ]} ; T^2  F_{p, n_1 + n_2 -p - 1}$. (p.285 for pf)</p>
<p><br></p>
<ul>
<li><strong>CR for <span class="math inline">\(\mu_1 - \mu_2\)</span></strong> will be</li>
</ul>
<p>$</p>
<p>Pr = 1-</p>
<p>$</p>
<p>where $ c^2=  {n_1 + n_2 - p - 1} ; T^2  F_{p, n_1 + n_2 -p - 1} ()$.
* 이때 constant가 역수가 되었음을 눈치.
* The equality will define the boundary of a region.
* The region is an ellipsoid centered at <span class="math inline">\((\bar X_1 - \bar X_2)\)</span>.</p>
<div id="example-testing-h_0-mu_1---mu_2-0-at-alpha0.05-is-equivalent-to-see-whether-falls-within-the-confidence-region" class="section level6" number="5.4.2.0.1.1">
<h6 number="5.4.2.0.1.1"><span class="header-section-number">5.4.2.0.1.1</span> Example) Testing <span class="math inline">\(H_0 : \mu_1 - \mu_2 = 0\)</span> at <span class="math inline">\(\alpha=0.05\)</span> is equivalent to see whether falls within the confidence region</h6>
<ul>
<li>Axes of the confidence region
* let <span class="math inline">\(\lambda_1 , \cdots, \lambda_p\)</span> are ev of <span class="math inline">\(S_p\)</span>.
* let <span class="math inline">\(e_1 , \cdots, e_p\)</span> are evc of <span class="math inline">\(S_p\)</span>.
<ul>
<li>then <span class="math inline">\(e_i\)</span>’s are the direction of CI</li>
<li>$  $are the half-length of the CR <a href="">Link</a></li>
</ul></li>
</ul>
<p>let $ c^2=  {n_1 + n_2 - p - 1} ; T^2  F_{p, n_1 + n_2 -p - 1} ()$.</p>
<ul>
<li><span class="math inline">\(100(1-\alpha)%\)</span> <strong>simultaneous CI</strong> for <span class="math inline">\(a&#39;(\mu_1 - \mu_2)\)</span>, <span class="math inline">\(\forall a\)</span>:<br />
$</li>
</ul>
<p>a’ ( X_1 - X_2 ) c </p>
<p>$</p>
</div>
<div id="example-simultaneous-ci-for-mu_1i---mu_2i-i1-cdots-p." class="section level6" number="5.4.2.0.1.2">
<h6 number="5.4.2.0.1.2"><span class="header-section-number">5.4.2.0.1.2</span> Example) simultaneous CI for <span class="math inline">\((\mu_{1i} - \mu_{2i}), i=1, \cdots, p\)</span>.</h6>
<p>let <span class="math inline">\(a&#39; = \left[0, \cdots, 0, 1, 0, \cdots, 0 \right]\)</span>. 이때 <span class="math inline">\(a&#39;\)</span>가 하나만 1이고 나머지 0이면, 어떤 특별한 한 axis로 proj하라는 의미. <a href="">link</a></p>
<p>let <span class="math inline">\(\mu_1 - \mu_2 = \left[ \mu_{1i} - \mu_{2i} \right]_{i=1,\cdots,p}\)</span>.</p>
<p>$ a’(X_1 - X_2) = X_{1i} - X_{2i}$, <span class="math inline">\(a&#39; \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_p a = \left( \dfrac {1}{n_1} + \dfrac {1}{n_2} \right) S_{p \; ii}\)</span>
* <span class="math inline">\(S_{p \; ii}\)</span> : p번째 변수의 표본 cov. 이는 단변량에서 나왔던 공통 cov, 즉 샘플 se와 표기법이 동일해지며 유사하다. (ch1) <a href="">link</a></p>
<p>the Bonferroni’s $100(1-)% $ simultaneous CI for <span class="math inline">\((\mu_{1i} - \mu_{2i})\)</span> is $ (X_1 - X_2) t_{n_2 + n_2 -2, ()} $.</p>
<hr />
</div>
</div>
<div id="case-2-_1-_2" class="section level5" number="5.4.2.0.2">
<h5 number="5.4.2.0.2"><span class="header-section-number">5.4.2.0.2</span> case 2: $ _1 = _2 $</h5>
<p>assume <span class="math inline">\(n_1 - p , \; n_2 - p\)</span> are large.</p>
<p>for <span class="math inline">\(H_0 : \mu_1 - \mu_2 = 0\)</span>, test stat becomes <span class="math inline">\(T^2 = (\bar X_1 - \bar X_2 )&#39; \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2 \right]^{-1} (\bar X_1 - \bar X_2 ) \overset{H_0}{\sim} \chi_p^2\)</span>.</p>
<pre class="note"><code>
$
E(\bar X_1 - \bar X_2 ) = \mu_1 - \mu_2
$

$
Cov(\bar X_1 - \bar X_2 ) = Cov(\bar X_1) + Cov(\bar X_2 ) - 2 Cov(\bar X_1, \bar X_2 ) = \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2 - 0
$


$
\bar X_1 - \bar X_2 \overset{\cdot}{\sim} N_p \left( \mu_1 - \mu_2, \dfrac{1}{n_1} \Sigma_1 + \dfrac {1}{n_2} \Sigma_2  \right)
\tag{∵ CLT}
$

$\\[3ex]
$

$
\text{under } H_0, 
$

$
S_1 \overset{p}{\to} \Sigma_1, S_2 \overset{p}{\to} \Sigma_2 \tag{∵ WLLN}
$

$
(\bar X_1 - \bar X_2 )&#39; \left[ \dfrac{1}{n_1} S_1 + \dfrac {1}{n_2} S_2\right]^-1 (\bar X_1 - \bar X_2 ) \overset{app}{\sim} \chi_p^2 \tag{∵ Slutsky&#39;s thm}
$</code></pre>
<p><strong><em>why Cov become 0???</em></strong></p>
<p>i.e. reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T^2 &gt; \chi_p^2 (\alpha)\)</span>.</p>
<p>CI becomes</p>
<p>$</p>
<p>Pr = 1-</p>
<p>$</p>
<p>차이는~~</p>
<p>Remark: if <span class="math inline">\(n_1 = n_2 = 2\)</span>,</p>
<p>$
<span class="math display">\[\begin{align*}

\dfrac{1}{n_1} S_1 + \dfrac{1}{n_2} S_2 

&amp;=  \dfrac{1}{n} (S_1 + S_2) \\

&amp;= \dfrac{1}{n}

\left[

\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{1i} - \bar {\pmb X_1})(\pmb X_{1i} - \bar {\pmb X_1})&#39; + 
\dfrac{1}{n-1} \sum_{n=1}^n (\pmb X_{2i} - \bar {\pmb X_2})(\pmb X_{2i} - \bar {\pmb X_2})&#39;

\right] \\

&amp;= \dfrac{1}{n} \dfrac{1}{n-1} S_p \ast 2(n-1) 

= \dfrac{2}{n}  S_p 


\end{align*}\]</span>
$</p>
<p>i.e. case 1 and case 2 are the same procedure when the sample sizes are the same for large sample sizes.</p>
<ul>
<li><span class="math inline">\(100(1-\alpha)%\)</span> <strong>simultaneous CI</strong> for <span class="math inline">\(\pmb a&#39;(\pmb \mu_1 - \pmb \mu_2)\)</span>, <span class="math inline">\(\forall \pmb a\)</span>:</li>
</ul>
<p>$</p>
<p>a’ ( {X_1} - {X_2} )  </p>
<p>$</p>
<hr />
</div>
<div id="other-statistics-for-testing-two-mean-vectors" class="section level5" number="5.4.2.0.3">
<h5 number="5.4.2.0.3"><span class="header-section-number">5.4.2.0.3</span> Other Statistics for Testing two Mean Vectors</h5>
<ul>
<li><p>let <span class="math inline">\(W=(n_1-1)S_1 + (n_2-1)S_2\)</span>: within SS, <span class="math inline">\(B=n_1 (\bar {\pmb X_1} - \bar {\pmb X})(\bar {\pmb X_1} - \bar {\pmb X})&#39; + n_2 (\bar {\pmb X_2} - \bar {\pmb X})(\bar {\pmb X_2} - \bar {\pmb X})&#39;\)</span></p></li>
<li><p>Wilk’s Lambda:</p>
<ul>
<li>when two-sample procedure, Hotelling’s <span class="math inline">\(T^2\)</span></li>
</ul></li>
</ul>
<p>$
^= 
$</p>
<ul>
<li>Lawley-Hotelling’s Trace:</li>
</ul>
<p>$
tr(BW^{-1})
$</p>
<ul>
<li>Pillai Trace:</li>
</ul>
<p>$
tr $</p>
<ul>
<li>Roy’s Largest Root:
<ul>
<li>maximum ev of <span class="math inline">\(B(B+W)^{-1}\)</span>.</li>
</ul></li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="testing-equality-of-covariance-matrices" class="section level5" number="5.4.2.0.4">
<h5 number="5.4.2.0.4"><span class="header-section-number">5.4.2.0.4</span> Testing Equality of Covariance Matrices</h5>
<p>$
H_0 : _1 = _2
$</p>
<p>let <span class="math inline">\(S_p = \dfrac{1}{n_1 + n_2 - 2} \left[ (n_1 - 1) S_1 + (n_2 - 1) S_2 \right]\)</span>.</p>
<p>$
<span class="math display">\[\begin{align*}

M &amp;= (n_1 + n_2 - 2) \ln \vert S_p \vert - (n_1 - 1) \ln \vert S_1 \vert - (n_2 - 1) \ln \vert S_2 \vert \tag{test stat} \\

C^{-1} &amp;= 1 - \dfrac{2p^2 + 3p -1}{6(p+1)} \left( \dfrac {n_1 + n_2 - 2}{(n_1-1)(n_2 - 1)} - \dfrac {1}{n_1 + n_2 - 2} \tag{Scale Factor} \\

MC^{-1} &amp;\sim \chi_v^2, \; \; \; \; \; v=\dfrac{p(p+1)}{2}
\end{align*}\]</span>
$</p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(MC^{-1} &gt; \chi_v^2(\alpha)\)</span></p>
<hr />
</div>
</div>
<div id="profile-analysis-for-g2" class="section level3" number="5.4.3">
<h3 number="5.4.3"><span class="header-section-number">5.4.3</span> Profile Analysis (for <span class="math inline">\(g=2\)</span>)</h3>
<p>Recall:</p>
<p><span class="math inline">\(H_0: \pmb \mu_1 = \pmb \mu_2\)</span>, when <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span></p>
<p>$
<span class="math display">\[\begin{align*}

T^2 &amp;= (\bar {\pmb X_1} - \bar {\pmb X_2})&#39; \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) S_p \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&amp;\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)p} {n_1 + n_2-p-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}\]</span>
$</p>
<hr />
<p>let’s <span class="math inline">\(H_0: C \pmb \mu_1 = C \pmb \mu_2\)</span>, when <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span>, where <span class="math inline">\(C_{q \times p}\)</span>, <span class="math inline">\(q \le p\)</span> and <span class="math inline">\(rank(C)=q\)</span>.</p>
<p>$
<span class="math display">\[\begin{align*}

T^2 &amp;= (\bar {\pmb X_1} - \bar {\pmb X_2})&#39; C&#39; \left[ \left( \tfrac{1}{n_1} + \tfrac{1}{n_2} \right) CS_p C&#39;\right]^{-1} C(\bar {\pmb X_1} - \bar {\pmb X_2}) \\

&amp;\overset {H_0} {\sim} \tfrac {(n_1 + n_2 -2)q} {n_1 + n_2-q-1} F_{p, \; \; n_1 + n_2 -p -1}

\end{align*}\]</span>
$</p>
<p>Profiles are constructed for each group.</p>
<p><img src></p>
<p>Consider two groups. Questions:</p>
<ol style="list-style-type: decimal">
<li>Are the profiles parallel?</li>
</ol>
<p>$
<span class="math display">\[\begin{alignat*}{3}

&amp;&amp;H_0 : \mu_{11}-\mu{12} = \mu_{21}-\mu{22}, \mu_{12}-\mu{13} = \mu_{22}-\mu{23}, \mu_{13}-\mu{14} = \mu_{23}-\mu{24}, \cdots, \mu_{1,p-1}-\mu{1,p} = \mu_{2,p-1}-\mu{2,p} \\
&amp;\iff &amp; H_0 : \mu_{11}-\mu{21} = \mu_{12}-\mu{22} = \cdots = \mu_{1p}-\mu{2p}} \\

&amp;\iff C_{(p-1) \times p} &amp;H_0: C \pmb \mu_1 = C \pmb \mu_2

\end{alignat*}\]</span>
$</p>
<p>This is equivalent to test the equal mean vector of the transformed data <span class="math inline">\(C \pmb X_1\)</span> and <span class="math inline">\(C \pmb X_2\)</span>.</p>
<p>Populations 1: <span class="math inline">\(C \pmb X_{11}, \cdots, C \pmb X_{1n_1} \sim N_{p-1} (C \pmb \mu_1 , C \Sigma C&#39;)\)</span>
Populations 2: <span class="math inline">\(C \pmb X_{21}, \cdots, C \pmb X_{2n_2} \sim N_{p-1} (C \pmb \mu_2 , C \Sigma C&#39;)\)</span></p>
<p>reject <span class="math inline">\(H_0: C \pmb \mu_1 = C \pmb \mu_2\)</span> (i.e. paralle profiles), if
$</p>
<p>T^2 = ({X_1} - {X_2})‘C’ ^{-1} C({X_1} - {X_2}) &gt; d^2 = (n_1 + n_2 - 2)  F_{p-1,n_1+n_2-p} ()</p>
<p>$</p>
<hr />
<div id="coincident-profiles" class="section level5" number="5.4.3.0.1">
<h5 number="5.4.3.0.1"><span class="header-section-number">5.4.3.0.1</span> 2. Coincident Profiles</h5>
<ol start="2" style="list-style-type: decimal">
<li>Assuming that the profiles are parallel, are the profiles coincident?</li>
</ol>
<p>$
<span class="math display">\[\begin{align*}

&amp;H_0 : \mu_{1i} = \mu_{2i}, i=1, \cdots, p \\
\iff &amp; H_0 : \pmb 1 &#39; \pmb \mu_1 = \pmb 1 &#39; \pmb \mu_2

\end{align*}\]</span>
$</p>
<p>is the case where <span class="math inline">\(C\)</span> is replaced by <span class="math inline">\(\pmb 1 &#39;\)</span>.</p>
<p>reject <span class="math inline">\(H_0\)</span> if</p>
<p>$
<span class="math display">\[\begin{alignat*}{2}
T^2 &amp;= \pmb 1 &#39; (\bar {\pmb X_1} - \bar {\pmb X_2}) \left[ \left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 &#39; S_p \pmb 1 \right]^{-1} (\bar {\pmb X_1} - \bar {\pmb X_2}) &amp;&amp; \\





&amp;= 

\left( 

\dfrac{\pmb 1 &#39; (\bar {\pmb X_1} - \bar {\pmb X_2})}{\sqrt{\left(\dfrac{1}{n_1} + \dfrac{1}{n_2} \right) \pmb 1 &#39; S_p \pmb 1}}

\right)^2

&amp;&amp;&gt; F_{1, n_1 + n_2 -2} (\alpha)

(n_1 + n_2 - 2) \dfrac{p-1}{n_1 + n_2 - p } F_{p-1,n_1+n_2-p} (\alpha)



\end{alignat*}\]</span>
$</p>
<hr />
</div>
<div id="flat-profiles" class="section level5" number="5.4.3.0.2">
<h5 number="5.4.3.0.2"><span class="header-section-number">5.4.3.0.2</span> 3. Flat Profiles</h5>
<p>3.Assuming that the profiles are coincident, are the profiles level?</p>
<p>$
H_0 : <em>{11} = </em>{12} = } = <em>{1p} = </em>{21} = <em>{22} = } = </em>{2p}
$</p>
<p>by 1 and 2, we can collapse two groups into one.</p>
<p>$
X_{11}, , X_{1n_1}, X_{21}, , X_{2n_2} N_p (, )
$</p>
<p>this is one population problem</p>
<p>$
C_{(p-1) p}, H_0: C = 0
$</p>
<p>reject <span class="math inline">\(H_0\)</span>, iff</p>
<p>$
T^2 = (n_1+n_2) {X}‘C’ [CSC’]^{-1} C {X} &gt; d^2 = (n_1 + n_2 - 1)  F_{p-1,n_1+n_2-p+1} ()
$</p>
<p>이는 1번에서의 그것과는 <span class="math inline">\(F\)</span>분포의 df가 변화했다는 점에 주목.
- <span class="math inline">\(\bar {\pmb X} = \tfrac{1}{n_1 + n_2} \left( \sum_{j=1}^{n_1} \pmb X_{1j}+ \sum_{j=1}^{n_2} \pmb X_{2j} right)\)</span>.
- <span class="math inline">\(S = n_1 + n_2\)</span> sample covariance matrix, using data.</p>
<hr />
</div>
</div>
<div id="comparing-several-multivariate-population-means" class="section level3" number="5.4.4">
<h3 number="5.4.4"><span class="header-section-number">5.4.4</span> Comparing Several Multivariate Population Means</h3>
<p><em>Recall:</em></p>
<p>In univariate, two-sample t-test is extended to Analysis of Variance(ANOVA).</p>
<p>$
H_0:_1 = =_g
$</p>
<p>$
F^=  {SSE/df_2}  F_{df_1 , df_2}
$
- where
- SSR: sum of squared regression,
- SSE: sum of squared error,
- SST: sum of squared total
- <span class="math inline">\(df_1 = g-1, df_2 = N-g, N=\sum_{i=1}^g n_i\)</span>.</p>
<hr />
<p>Assume <span class="math inline">\(g\)</span> population or treatment groups, and <strong>each groups are independent</strong>. 각 population은 같은 Cov를 갖고 같은 숫자의 패러미터를 갖되 총 observation 숫자랑 각각의 population mean은 다름.</p>
<p>Population 1~g: <span class="math inline">\(\pmb X_{i1}, \cdots, \pmb X_{in_i} \sim N_p(\pmb \mu_i , \Sigma)\)</span>.</p>
<ul>
<li>Model</li>
</ul>
<p>$
X_{ij} = <em>{i} + </em>{ij}, ; ; ; ; ; i=1, , g, ; ; j = 1, , n_i</p>
<p>$</p>
<p>$
H_0: _1 = _g
$</p>
$
 X_{ij} =
<span class="math display">\[\begin{bmatrix} X_{ij1} \\ X_{ij2} \\ \vdots \\X_{ijp} \end{bmatrix}\]</span>
<em>{p } , </em>{ij} =
<span class="math display">\[\begin{bmatrix} \mu_{i1} \\ \mu_{i2} \\ \vdots \\ \mu_{ip} \end{bmatrix}\]</span>
<em>{p }, </em>{ij} =
<span class="math display">\[\begin{bmatrix} \epsilon_{ij1} \\ \epsilon_{ij2} \\ \vdots \\ \epsilon_{ijp} \end{bmatrix}\]</span>
<p>_{p }
$</p>
<ul>
<li>Assumptions
<ol style="list-style-type: decimal">
<li>The random samples from different populations are independent.</li>
<li>All populations have a common covariance matrix <span class="math inline">\(\Sigma\)</span>.</li>
<li>Each population is Multivariate Normal. This assumption can be relaxed by C.L.T., when the sample sizes <span class="math inline">\(n_1 , \cdots, n_g\)</span> are large.</li>
</ol></li>
</ul>
<div id="one-way-manova" class="section level5" number="5.4.4.0.1">
<h5 number="5.4.4.0.1"><span class="header-section-number">5.4.4.0.1</span> One-Way MANOVA</h5>
<p>The quantities SSR, SSE and SST become matrices in MANOVA.</p>
<p>$
<span class="math display">\[\begin{align*}
B &amp;= \sum_{i=1}^g n_i (\pmb X_i - \pmb X) (\pmb X_i - \pmb X)&#39; \tag{SSR} \\

W &amp;= \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \pmb X_i) (\pmb X_{ij} - \pmb X_i)&#39; \\

&amp;= (n_1 -1)S_1 + \cdots + (n_g -1)S_g \tag{SSE}

\end{align*}\]</span>
$</p>
<ul>
<li>Note:</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{3}

(\pmb X_{ij} - \bar {\pmb X}) 

&amp;= 


(\bar {\pmb X_i} - \bar {\pmb X}) 


+ (\pmb X_{ij} - \bar {\pmb X_i})&amp;&amp;

\\

(\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) &#39;


&amp;= 


(\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39; + 

&amp;&amp;(\bar {\pmb X_i} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X_i})&#39;


+ (\pmb X_{ij} - \bar {\pmb X_i}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39;



+ (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})&#39;


\\

\sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X}) (\pmb X_{ij} - \bar {\pmb X}) &#39;

&amp;= \sum_{i=1}^g n_i (\bar {\pmb X_i} - \bar {\pmb X}) (\bar {\pmb X_i} - \bar {\pmb X}) &#39; 

&amp;&amp;+ \sum_{i=1}^g \sum_{j=1}^{n_i} (\pmb X_{ij} - \bar {\pmb X_i})(\pmb X_{ij} - \bar {\pmb X_i})&#39;

\\

T &amp;= B &amp;&amp;+ W



\end{alignat*}\]</span>
$</p>
<ul>
<li>B: Between Sum of Squares</li>
<li>W: Within Sum of Squares</li>
</ul>
<hr />
<p>Any test statistic will be a function of B and W. Popular test statistics use eigenvalues of <span class="math inline">\(BW^{-1}\)</span>.</p>
<p>let <span class="math inline">\(\lambda_1, \cdots, \lambda_r\)</span> be ev of <span class="math inline">\(BW^{-1}\)</span>, where <span class="math inline">\(r=\)</span> ## of non-zero ev’s.</p>
<ol style="list-style-type: decimal">
<li>Wilk’s Lambda (LRT)</li>
</ol>
<p>$
=  =  = _{i=1}^r (1+_1)^{-1}
$</p>
<ol start="2" style="list-style-type: decimal">
<li>Pillai’s Trace</li>
</ol>
<p>$
<span class="math display">\[\begin{align*}
V &amp;= tr[B(B+W)^{-1}] =  tr[B(B(I+B^{-1}W))^{-1}] = tr[B(I+B^{-1}W)^{-1}B^{-1}] \\

&amp;=tr[B^{-1}B(I+B^{-1}W)^{-1}] = tr[(I+B^{-1}W)^{-1}] = tr[I+(B^{-1}W)^{-1}]\\

&amp;=\sum_{i=1}^r \left( \dfrac{\lambda_i}{1+\lambda_i}\right)

\end{align*}\]</span>
$</p>
<ol start="3" style="list-style-type: decimal">
<li>Lawley-Hotelling’s Trace</li>
</ol>
<p>$
T = tr(BW^{-1}) = _{i=1}^r _i
$</p>
<ol start="4" style="list-style-type: decimal">
<li>Roy’s Largest Root</li>
</ol>
<p>$
U = _{i=1,,r} { _i }
$</p>
<hr />
<ul>
<li>Sampling Distribution of Wilk’s Lambda</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{2}
p=1, g \ge 2:

&amp;\left(\dfrac{\sum_{i=1}^g n_i - g}{g-1}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&amp;&amp;\overset{H_0}{\sim} F_{g, \sum_{i=1}^g n_i - g}

\\






p=2, g \ge 2:

&amp;\left(\dfrac{\sum_{i=1}^g n_i - g-1}{g-1}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&amp;&amp;\overset{H_0}{\sim} F_{2(g-1), 2(\sum_{i=1}^g n_i - g-1)}

\\







p\ge1, g = 2:

&amp;\left(\dfrac{n_1 + n_2 - p -1}{p}\right) \left(\dfrac{1-\Lambda^\ast}{\Lambda^\ast}\right)

&amp;&amp;\overset{H_0}{\sim} F_{p, n_1 + n_2 - p -1}

\\







p \ge 1, g \ge 3:

&amp;\left(\dfrac{\sum_{i=1}^3 n_i - p-2}{p}\right) \left(\dfrac{1-\sqrt{\Lambda^\ast}}{\sqrt{\Lambda^\ast}}\right)

&amp;&amp;\overset{H_0}{\sim} F_{2p, 2(\sum_{i=1}^g n_i - p-2)} 

\\

\text{large sample sizes}:



&amp;- \left( \sum_{i=1}^g n_i -1 -\dfrac{p+q}{2}\right) \ln \Lambda^\ast

&amp;&amp;\overset{H_0}{\sim} \chi^2_{p(g-1)} \tag{Why?}

\end{alignat*}\]</span>
$</p>
<!--chapter:end:211306_ComparisonofSeveralMVMeans.Rmd-->
</div>
</div>
</div>
<div id="multivariate-multiple-regression-wk6" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Multivariate Multiple Regression (wk6)</h2>
<div id="overview-4" class="section level3" number="5.5.1">
<h3 number="5.5.1"><span class="header-section-number">5.5.1</span> Overview</h3>
<p>Recall:</p>
<p>univariate Linear Regression:</p>
<p>repsponse variable <span class="math inline">\(Y\)</span>, <span class="math inline">\(r\)</span> predictor variables <span class="math inline">\(Z_1 , \cdots, Z_r\)</span>.</p>
<ul>
<li>model:</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{3}
Y_j &amp;= \beta_0 + \beta_1 Z_{j1} + \cdots + \beta_j Z_{jr} + \epsilon_j , \; \; \; \; \; &amp;E(\epsilon_j) = 0, Var(\epsilon_j) = \sigma^2


\pmb Y_{n \times 1} &amp;= \pmb Z_{n \times (r+1)} \pmb \beta_{(r+1) \times 1} + \pmb \epsilon_{n \times 1}, \; \; \; \; \; &amp;E(\pmb \epsilon) = 0, Var(\pmb \epsilon) = \sigma^2 I

\end{alignat*}\]</span>
$</p>
<ul>
<li>estimation:</li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat*}{3}
\hat {\pmb \beta} &amp;= (\pmb Z &#39; \pmb Z )^{-1} \pmb Z &#39; \pmb Y \\

\hat {\pmb \epsilon} &amp;= (\pmb Y - \pmb Z \hat {\pmb \beta}) = \pmb Y - \pmb Z (\pmb Z &#39; \pmb Z )^{-1} \pmb Z &#39; \pmb Y = (I - \pmb Z (\pmb Z &#39; \pmb Z )^{-1} \pmb Z &#39;) \pmb Y \\ &amp;= (I-H)\pmb Y

\end{alignat*}\]</span>
$</p>
<ul>
<li>inference:</li>
</ul>
<p>let <span class="math inline">\(\epsilon \sim N_n (\pmb 0, \sigma^2 I)\)</span>. then</p>
<p>$
<span class="math display">\[\begin{alignat*}{3}

\hat {\pmb \beta} &amp;\sim  N_{r+1} (\pmb \beta , \sigma^2(\pmb Z &#39;\pmb Z )^{-1}) \\

\hat {\pmb \epsilon} &#39; \hat {\pmb \epsilon} &amp;\sim \sigma^2 \chi^2_{n-r-1} \\

\\  

E(\hat {\pmb \epsilon} ) &amp;= \pmb 0 \\

Cov(\hat {\pmb \epsilon} ) &amp;= \sigma^2 (I - \pmb Z (\pmb Z &#39; \pmb Z )^{-1} \pmb Z &#39;) \\

E\left( \dfrac{\hat {\pmb \epsilon} &#39; \hat {\pmb \epsilon}}{n-r-1} \right) &amp;= \sigma^2

\end{alignat*}\]</span>
$</p>
<hr />
</div>
<div id="multivariate-multiple-regression" class="section level3" number="5.5.2">
<h3 number="5.5.2"><span class="header-section-number">5.5.2</span> Multivariate Multiple Regression</h3>
<ul>
<li><p><strong>Notation</strong></p></li>
<li><p>Model</p></li>
</ul>
<p>$</p>
<p>Y_{n m} = Z_{n (r+1)} <em>{(r+1) m} + </em>{n m}, ; ; ; ; ; E(<em>{(i)} ) = , Cov(</em>{(i)}, <em>{(j)}) = </em>{ik} I, ; ; ; i,k = 1, , m</p>
<p>$</p>
<ul>
<li><ul>
<li>Cov of <span class="math inline">\(m\)</span> responses:</li>
</ul></li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{3}

&amp;\Sigma = \begin{bmatrix} \sigma_{11} &amp; &amp; \sigma_{1m} \\ &amp; \ddots &amp; \\ \sigma_{m1}&amp;&amp; \sigma_{mm} \end{bmatrix}, \; \; \; \; \; 

&amp;&amp;Var(\pmb \epsilon_{(i)}) = \sigma_{ii} I,\; \; \; \; \; 

&amp;&amp;Cov(\pmb \epsilon_{(i)}, \pmb \epsilon_{(j)}) = \begin{bmatrix} \sigma_{ik} &amp; &amp; \pmb 0 \\ &amp; \ddots &amp; \\ \pmb 0 &amp;&amp; \sigma_{ik} \end{bmatrix}

\end{alignat*}\]</span>
$</p>
<ul>
<li>the meaning of
<ul>
<li><span class="math inline">\(0\)</span>: observations from different trials, are uncorrelated</li>
<li><span class="math inline">\(\sigma_{ik}\)</span>: errors for different responses on the same trial are correlated</li>
</ul></li>
<li><span class="math inline">\(i\)</span>th response <span class="math inline">\(\pmb Y_{(i)}\)</span>:</li>
</ul>
<p>$
Y_{(i)} = Z <em>{(i)} + </em>{(i)}, ; ; ; ; ;  Corr(<em>{(i)}) = </em>{ii}I ,  = (Z ’ Z )^{-1} Z ’ Y_{(i)}</p>
<p>$</p>
<hr />
<div id="least-square" class="section level5" number="5.5.2.0.1">
<h5 number="5.5.2.0.1"><span class="header-section-number">5.5.2.0.1</span> Least Square</h5>
<ul>
<li>Collecting Univariate Least Squares Estimates (LSE)</li>
<li>Errors</li>
</ul>
<p>$</p>
<p>Y - Z  =</p>
<p>$</p>
<ul>
<li>Error Sum of Squares (SSE)
<ul>
<li>diagonal elements: Error SS for univariate least squares <span class="math inline">\((\pmb Y_{(i)}-\pmb Z \pmb \beta_{(i)})&#39; (\pmb Y_{(i)}-\pmb Z \pmb \beta_{(i)})\)</span> is minimized.</li>
<li>the generalized <span class="math inline">\(Var\)</span> <span class="math inline">\(\lvert (\pmb Y-\pmb Z \pmb \beta)&#39; (\pmb Y-\pmb Z \pmb \beta) \rvert\)</span> is also minimized.</li>
</ul></li>
<li>Properties</li>
</ul>
<p>$
<span class="math display">\[\begin{align*}


\hat {Y} &amp;= Z \hat \beta = Z(Z&#39;Z)^{-1} Z&#39; Y \\
&amp;= HY \tag{Predicted Values}\\

\hat {\pmb \epsilon} &amp;=  Y - \hat Y = \left[ I - Z(Z&#39;Z)^{-1} Z&#39; \right] Y \\
&amp;= (I-H)Y \tag{residuals} \\

Z&#39; \hat {\pmb \epsilon} &amp;=  Z&#39; \left[ I - Z(Z&#39;Z)^{-1} Z&#39; \right] Y \\
&amp;=  [Z-Z&#39;] Y =\pmb 0 \tag{3}


\hat Y&#39; \hat {\pmb \epsilon} &amp;=  \hat {\beta} &#39; Z&#39; \left[ I - Z(Z&#39;Z)^{-1} Z&#39; \right] Y \\
&amp;=  [\hat {\beta} &#39;  Z- \hat {\beta} &#39;  Z&#39;] Y =\pmb 0 \tag{4}

\end{align*}\]</span>
$
- - by (3), residuals are orthogonal to <span class="math inline">\(Z\)</span>
- by (4), residuals are orthogonal to <span class="math inline">\(\hat Y\)</span></p>
<ul>
<li>Error Sum of Squares</li>
</ul>
<p>$
<span class="math display">\[\begin{align*}

Y&#39;Y &amp;= (\hat Y \hat {\pmb \epsilon} ) &#39; (\hat Y \hat {\pmb \epsilon} ) \\
&amp;= \hat Y &#39; \hat Y  + \hat{\pmb \epsilon}&#39; \hat{\pmb \epsilon} \\

\\  

\hat {\pmb \epsilon}&#39; \hat {\pmb \epsilon}&amp;= Y&#39;Y - \hat Y &#39; \hat Y \\

&amp;= \hat Y &#39; \hat Y - \hat \beta &#39; Z&#39; Z \hat \beta 


\end{align*}\]</span>
$</p>
<ul>
<li>Results 1
$
\begin{alignat*}{2}</li>
</ul>
<p>E() &amp;= , ; ; ; ; ; Cov(, ) &amp;= _{il} (Z’Z)^{-1} \
\<br />
E() = , ; ; ; ; ;E ( ’ ) = </p>
<p>\end{alignat*}
$
- - at here, <span class="math inline">\(\hat {\pmb \epsilon}\)</span> and <span class="math inline">\(\hat {\pmb \beta}\)</span> are correlated.</p>
<ul>
<li>Results 2
<ul>
<li>If <span class="math inline">\(\pmb \epsilon_j\)</span> has a <span class="math inline">\(N_m (\pmb 0 , \Sigma)\)</span>, then <span class="math inline">\(\hat {\pmb \beta}= (\pmb Z &#39; \pmb Z )^{-1}\pmb Z &#39;Y\)</span> is MLE of <span class="math inline">\(\pmb \beta\)</span></li>
</ul></li>
</ul>
<p>$
<span class="math display">\[\begin{align*}

\hat {\pmb \beta_{(i)}} &amp;\sim N_{r+1} ({\pmb \beta_{(i)}}, \sigma_{ii} (\pmb Z &#39; \pmb Z )^{-1}) \\

\hat \Sigma &amp;= \dfrac{1}{n} \hat {\pmb \epsilon} &#39; \hat {\pmb \epsilon} \\
&amp;= \dfrac{1}{n} (\pmb Y - \pmb Z \hat {\pmb \beta}) &#39; (\pmb Y - \pmb Z \hat {\pmb \beta}) \tag{5}

\end{align*}\]</span>
$</p>
<ul>
<li><ul>
<li><ol start="5" style="list-style-type: decimal">
<li>is MLE of <span class="math inline">\(\Sigma\)</span></li>
</ol></li>
<li><span class="math inline">\(n \hat \Sigma \sim W_{p,n-r-1} (\Sigma)\)</span>.</li>
</ul></li>
<li>Comment
<ul>
<li>Multivariate regression requires no new computational problems.</li>
<li>Univariate least squares <span class="math inline">\(\hat {\pmb \beta_{(i)}}\)</span> are computed individually for each response variable.</li>
<li>Diagnostics check must be done as in univariate regression.</li>
<li>Residual vectors <span class="math inline">\([ \pmb \epsilon_{j1}, \cdots, \pmb \epsilon_{jm} ]\)</span> can be examined for multivariate normality.</li>
</ul></li>
</ul>
</div>
</div>
<div id="hypothesis-testing" class="section level3" number="5.5.3">
<h3 number="5.5.3"><span class="header-section-number">5.5.3</span> Hypothesis Testing</h3>
<ul>
<li>Note:</li>
</ul>
<p>$
<span class="math display">\[\begin{align*}

&amp;H_0: \text{ responses do not depend on } Z_{q+1}, Z_{q+2}, \cdots, Z_{r} \\

\iff

&amp;H_0: \begin{bmatrix} \beta_{(q+1)1} &amp; \beta_{(q+2)1} &amp; \cdots &amp; \beta_{(q+1)m} \\ \vdots &amp;&amp;&amp; \vdots \\ \beta_{r1} &amp; \beta_{r1} &amp; \cdots &amp; \beta_{rm} \end{bmatrix} = 0 \\

\iff

&amp;H_0: \pmb{\beta_{(2)}} = \pmb 0, \; \; \; \; \; \ \pmb \beta = \begin{bmatrix} \pmb{\beta_{(1)}}_{(q+1) \times m} \\ cdots \\ \pmb{\beta_{(2)}}_{(r-q) \times m} \end{bmatrix}


\end{align*}\]</span>
$</p>
<div id="full-model-vs.-reduced-model" class="section level5" number="5.5.3.0.1">
<h5 number="5.5.3.0.1"><span class="header-section-number">5.5.3.0.1</span> Full Model vs. Reduced Model</h5>
<p>let <span class="math inline">\(Z = \begin{bmatrix} Z_1 &amp; \vdots Z_2 \end{bmatrix}\)</span>, then <span class="math inline">\(Z \beta = Z_1 \beta_{(1)} + Z_2 \beta_{(2)}\)</span>.</p>
<p>under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(Y = Z \beta_{(1)} + \epsilon\)</span>,</p>
<p>let</p>
<p>$
<span class="math display">\[\begin{align*}

E &amp;= n \hat \Sigma &amp;\\
&amp;= (\pmb Y - \pmb Z \hat{\pmb \beta})&#39;(\pmb Y - \pmb Z \hat{\pmb \beta})&amp; \tag{Full Model}\\
\\  
H &amp;= n(\hat \Sigma_1 - \hat \Sigma), &amp;\text{ where } E_1 = n(\hat \Sigma_1) = (\pmb Y - \pmb Z \hat{\pmb \beta_{(1)}})&#39;(\pmb Y - \pmb Z \hat{\pmb \beta_{(1)}}) \tag{under H0}

\end{align*}\]</span>
$</p>
<ul>
<li>$ E=n $. 여기서 E라는 것은 오차행렬이기 때문에, 즉 univariate 를 4번 반복해서 나온 오차를 모은 것이 바로 이 <span class="math inline">\(E\)</span>라는 행렬.</li>
</ul>
<p>let <span class="math inline">\(\lambda_1 \ge \cdots \ge \lambda_s\)</span> be non-zero ev of <span class="math inline">\(HE^{-1}\)</span>, <span class="math inline">\(s=min(m, r-q)\)</span>.</p>
<hr />
<ul>
<li>Four Test Stat:</li>
</ul>
<ol style="list-style-type: decimal">
<li>Wilk’s Lambda:</li>
</ol>
<p>$
 = _{i=1}^s 
$</p>
<ol start="2" style="list-style-type: decimal">
<li>Pillai Trace:</li>
</ol>
<p>$
tr = _{i=1}^s 
$</p>
<ol start="3" style="list-style-type: decimal">
<li>Lawley-Hotelling’s Trace:</li>
</ol>
<p>$
tr(HE^{-1}) = _{i=1}^s {_i}
$</p>
<ol start="4" style="list-style-type: decimal">
<li>Roy’s Largest Root:
<ul>
<li>maximum ev of <span class="math inline">\(H(H+E)^{-1} = \lambda_1\)</span>.</li>
</ul></li>
</ol>
<hr />
</div>
</div>
<div id="example" class="section level3" number="5.5.4">
<h3 number="5.5.4"><span class="header-section-number">5.5.4</span> Example)</h3>
<p>fit FM <span class="math inline">\(Y = Z \beta + \epsilon\)</span>.</p>
<p>fit <span class="math inline">\(Y_1 , Y_2 , Y_3 , Y_4 = X_1,X_2,X_3\)</span>, then we acquire <span class="math inline">\(E=n \hat \Sigma\)</span>.</p>
<pre><code>
1. $~H_0: \begin{bmatrix} \beta_{31},\beta_{32},\beta_{33},\beta_{34} \end{bmatrix} =0~$,
</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \begin{bmatrix} \beta_{21},\beta_{22},\beta_{23},\beta_{24}\\\beta_{31},\beta_{32},\beta_{33},\beta_{34} \end{bmatrix} =0\)</span>,</li>
</ol>
<p>under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(Y=Z \beta_{(1)} + \epsilon\)</span></p>
<p>$</p>
Z_1 =
<span class="math display">\[\begin{bmatrix} 1 &amp; X_{11} \\ \cdots &amp; \cdots \\ 1 &amp; X_{n1} \end{bmatrix}\]</span>
<p>_{n }, ; ; ; ; ;</p>
_{(1)} =
<span class="math display">\[\begin{bmatrix} \beta_{01} &amp; \cdots &amp; \beta_{0m} \\ \beta_{11} &amp; \cdots &amp; \beta_{1m}  \end{bmatrix}\]</span>
<p>_{2 m}</p>
<p>$</p>
<p>now, fit <span class="math inline">\(Y_1 , Y_2 , Y_3 , Y_4 = X_1\)</span> (X_2, X_3 excluded), then we acquire <span class="math inline">\(E_1 =n \hat \Sigma_1, H = n \hat \Sigma_1 - n \hat \Sigma = E_1 - E\)</span>.</p>
<p>let’s calculate ev of <span class="math inline">\(HE^{-1}\)</span>, and compute Wilk’s Lambda <span class="math inline">\(\Lambda^\ast = \dfrac{\vert E \vert }{\vert E+H\vert }\)</span>.</p>
<hr />
<div id="sampling-distribution-of-the-wilks-lambda" class="section level5" number="5.5.4.0.1">
<h5 number="5.5.4.0.1"><span class="header-section-number">5.5.4.0.1</span> Sampling Distribution of the Wilk’s Lambda</h5>
<p>let Z be full rank of <span class="math inline">\(r+1\)</span>, and <span class="math inline">\((r+1) + m \le n\)</span>.</p>
<p>let <span class="math inline">\(\epsilon\)</span> be normally distributed.</p>
<p>under <span class="math inline">\(H_0\)</span>, $ - (^) ^2_{m(r-q)}$.</p>
<hr />
</div>
<div id="prediction" class="section level5" number="5.5.4.0.2">
<h5 number="5.5.4.0.2"><span class="header-section-number">5.5.4.0.2</span> Prediction</h5>
<p>$</p>
<p><em>{n m} = Z </em>{(r+1) m}</p>
<p>$</p>
<p>assume fixed values <span class="math inline">\(\pmb {Z_0}_{(r+1) \times 1}\)</span> of the predictor variables. then <span class="math inline">\(\hat {\pmb \beta}&#39;_{m \times (r+1)} \pmb Z_0 \sim N_m(\pmb \beta &#39; \pmb Z_0 , \pmb Z_0 &#39; (\pmb Z &#39; \pmb Z)^{-1} \pmb Z_0 \Sigma)\)</span>.</p>
<p><br>
<br>
<br></p>
<ul>
<li><span class="math inline">\(100(1-\alpha)\%\)</span> simultaneous CI for <span class="math inline">\(E(Y_i) = \pmb Z_0 &#39; \pmb \beta_{(i)}\)</span>:</li>
</ul>
<p>$</p>
<p>Z_0 ’ _{(i)}  , ; ; ; ; ; i=1,, m</p>
<p>$</p>
<ul>
<li><ul>
<li>where <span class="math inline">\(\pmb \beta_{(i)}\)</span> is the <span class="math inline">\(i\)</span>th column of <span class="math inline">\(\pmb \beta\)</span>.</li>
<li><span class="math inline">\(\hat \sigma_{ii}\)</span> is the <span class="math inline">\(i\)</span>th diagonal element of <span class="math inline">\(\hat \Sigma\)</span>.</li>
</ul></li>
</ul>
<p><br>
<br>
<br></p>
<ul>
<li><span class="math inline">\(100(1-\alpha)\%\)</span> simultaneous C.I. for the individual responses <span class="math inline">\(Y_{0i} = \pmb Z_0 &#39; \pmb \beta_{(i)} + \epsilon_{0i}\)</span>:</li>
</ul>
<p>$</p>
<p>Z_0 ’ _{(i)}  , ; ; ; ; ; i=1,, m</p>
<p>$</p>
<!--chapter:end:211307_MultivariateMultipleRegression.Rmd-->
</div>
</div>
</div>
<div id="pca" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> PCA</h2>
<p>PCA는 상관관계 있는 반응변수 <span class="math inline">\(y\)</span>의 집합을 상관관계 없는 더 작은 집합으로 바꿈. 이 더 작은 직합들의 이름은 <strong>principal components</strong>. 이는 더 작은 principal components들이 어쩌면 원본 데이터에 들어있는(available) <strong>거의</strong> 대부분의 정보를 보유하고 있을지도 모른다는 생각에서 출발함.
1. Outlier
2. Cluster
3. Discriminant: Cov 매트릭스 invert 하려면 필요. 샘플 사이즈 작으면 <span class="math inline">\((n&lt;p)\)</span> 문제터져서 변수 갯수를 줄임.
4. Regression: predictors 사이에 multicollinearity 존재하는지 체크
5. Multivariate Nomality</p>
<p>semi-positive definite</p>
<p>벡터의 매트릭스 <span class="math inline">\(\textbf {X}_{1 \times p}\)</span> 의 Cov 매트릭스 <span class="math inline">\(\Sigma\)</span>, 이의 <span class="math inline">\(ev\)</span> <span class="math inline">\(\lambda_1 \le \cdots \le \lambda_p \le 0\)</span>.</p>
<p><span class="math inline">\(\textbf a&#39;_i\)</span>는 $ p $인 열벡터. 이것이 <span class="math inline">\(i=1~p\)</span>개만큼 존재. <span class="math inline">\(Y_i = \textbf a&#39;_i \textbf {X}_{i}\)</span>, 즉 <span class="math inline">\(Y\)</span>는 <span class="math inline">\(a\)</span>와 <span class="math inline">\(X\)</span>의 선형결합.</p>
<p>$Cov(Y_1 , Y_2) = Cov(’_1  , ’_2  ) = _1 ’ _2 ( = 0 ) $</p>
<p>벡터와 스칼라 여부 주의. Transpose 여부 주의. 0이 되는 건 $_1 ’ $과 $ _2 $ 가 orthogonal.</p>
<p>Var가 클수록 정보량 많음. 1번은 분산이 가장 큼. 2번은 분산이 2번째로 크되 1번째의 $<em>{1}  $과 orthogonal 해야함. e.g. $ Cov ( </em>{1}’  _{2}’  )$.</p>
<p>이를 반복.</p>
<p><br></p>
<p>1st principal component: <span class="math inline">\(= \textbf e_1 &#39; \textbf X\)</span>.
* <span class="math inline">\(Var \left( \textbf e_1 &#39; \textbf X \right)= \textbf e_1 &#39; \Sigma \textbf e_1 = \lambda_1\)</span>.
* 이때, <span class="math inline">\(e \textbf v\)</span>의 정의에 의해 $_1 = _1 _1 $ .
* <span class="math inline">\(Var \left( \textbf e_1 &#39; \textbf X \right)\)</span> 는 $_1 ’ _1 $ 를 만족하는 값들 중 <span class="math inline">\(Var \left( \textbf e_1 &#39; \textbf X \right)\)</span>를 최대화시키는 값.</p>
<p><br></p>
<p>2nd principal component: <span class="math inline">\(= \textbf e_2 &#39; \textbf X\)</span>.
* <span class="math inline">\(Var \left( \textbf e_2 &#39; \textbf X \right)= \textbf e_2 &#39; \Sigma \textbf e_2 = \lambda_2\)</span> 는 모든 <span class="math inline">\(\textbf a_2 &#39; \textbf X\)</span> 중 $Cov ( _1 ’ _1 _2 ’  ) = 0 $ 과 $_2 ’ _2 $를 만족하는 녀석.</p>
<p><br></p>
<p>즉 PC 자체는 <span class="math inline">\(\textbf e_i &#39; \textbf X\)</span> 로 정해짐. <code>note ***이건 proj의 일종인 모양.***</code> 근데 이걸로 정해지는 이유가 상기의 조건을 만족해야 한다는 거고, 해당 체크 조건들을 <span class="math inline">\(\textbf e_i &#39; \textbf X\)</span> 가 모두 통과할 수 있으므로 이걸 PC로 삼는 것에 문제가 없다는 것.</p>
<p>$
<span class="math display">\[\begin{align*}

    \sum_{i=1}^p Var(\textbf X_i) &amp;=tr(\Sigma) \\
    &amp;= \sigma_{11} + \sigma_{22} + \cdots + \sigma_{pp} \\
    &amp;= \lambda_1 + \lambda_2 + \cdots + \lambda_p \\
    &amp;= \sum_{i=1}^p Var(\textbf Y_i)


\end{align*}\]</span>
$</p>
<p>따라서 kth PC에 의해 유발되는 총 Var의 비율은 $ =  $.</p>
<p>이인즉 PCA를 거쳐도 p개의 variable 갯수를 유지한다면 설명력의 총합은 동일함. 하지만 우리는 설명력을 1만큼 잃고 변수를 10만큼 줄이기를 원함. 따라서 어느정도 설명력을 잃더라도 그 이상으로 변수의 갯수를 줄이는 선이면 하꼬변수를 쳐냄. 이는 PCA 분석때 기본적으로 분산의 80% 설명을 기준으로 함.</p>
<p>Cov 매트릭스 <span class="math inline">\(\Sigma\)</span>, PC <span class="math inline">\(Y_i = \textbf e_i &#39; \textbf X\)</span>. 이때 <span class="math inline">\(\rho_{Y_i , X_k } = Corr (Y_i , X_k ) = \dfrac {e_{ik} \sqrt{\lambda_i}} {\sqrt{\sigma_{kk}}}, \; \; \; i,k=1,\cdots,p\)</span>.</p>
<p>다룰 때의 편의를 위해 PC 구성 단계에서 <span class="math inline">\(Y_i =\textbf {e}_i ( \pmb {X} - \pmb {\mu} )\)</span> 로 구성하는 경우도 잦음.</p>
<p>PC Score. n개의 관측 중에서 r번째 관측의 variable의 벡터를 $<em>r $이라고 설정하자. 그렇다면 <span class="math inline">\(Y_{ri} = \textbf e_i &#39; (\textbf X_r - \pmb \mu_r)\)</span>. 이때 <span class="math inline">\(r=1,\cdots, n\)</span>. 이때 PC Score는 $ Y</em>{ri} =  ’ (_r - { _r})$ 로 추정될 수 있다.</p>
<pre class="note"><code>***elbow***</code></pre>
<p>PCA prerequisite
* variable들이 same unit
* variable들이 have similar Var</p>
<p>해결책
* $ $로 표준화하고 PCA. <span class="math inline">\(E(\textbf Z) = 0, Cov(\textbf Z )=\rho\)</span>
* PCA 자체를 corr 매트릭스에 적용</p>
<p>$
<span class="math display">\[\begin{align*}

    \sum_{i=1}^p Var(\textbf Y_i) &amp;= \sum_{i=1}^p Var(\lambda_i) \\
    &amp;= tr(\pmb \rho) \\
    &amp;= \sum_{i=1}^p Var(\textbf Z_i) \\
    &amp;= p

\end{align*}\]</span>
$</p>
<p>따라서 이때의 kth PC에 의해 유발되는 총 Var의 비율은 $ =  $.</p>
<p><span class="math inline">\(Corr\)</span>을 썼을 때 PC를 어디까지 쓸지를 솎아낼 때는 scree plot이나 <span class="math inline">\(ev&gt;1\)</span>인지를 기준으로 한다. 모든 기존 변수들의 분산이 1이므로 최소한의 설명력이 1이라는건데, 1도 안되면 그냥 쓰레기들이므로.</p>
<p>Checking Multivariate Normal: 기존 데이터가 mv normal이라면, 각 PC Score는 normal로 분포되어 있다. 각 PC들을 QQ plot 사용해서 체크하면 답나옴.</p>
<!--chapter:end:211308_PCA.Rmd-->
</div>
<div id="factor" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> Factor</h2>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>PCA</th>
<th>FA</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>concern with <br> explaining</td>
<td><span class="math inline">\(Cov\)</span> and/or <span class="math inline">\(Corr\)</span> structure <br> among measured variables</td>
<td>Variability in the variables</td>
</tr>
<tr class="even">
<td>Objectives</td>
<td></td>
<td>1. Partition the <span class="math inline">\(p\)</span> response variables into <span class="math inline">\(m\)</span> subsets, each consisting of a group of variables tending to be more highly related to others. <br> 2. Create a new set of uncorrelated variables, called <strong>underlying factors</strong> or <strong>underlying characteristics</strong>. <br> 3. Use the new variables in future analysis.</td>
</tr>
<tr class="odd">
<td>Warnings</td>
<td></td>
<td>1. If the original variables are already uncorrelated, no reason to consider FA.<br>2. Subjective decisions are necessary to determine number of factors, to determine the method to get the underlying factors <br>3. FA solutions are not unique.</td>
</tr>
</tbody>
</table>
<div id="orthogonal-factor-model" class="section level5" number="5.7.0.0.1">
<h5 number="5.7.0.0.1"><span class="header-section-number">5.7.0.0.1</span> Orthogonal Factor Model</h5>
<p><span class="math inline">\(\pmb X \sim \pmb \mu , \Sigma\)</span>.</p>
<p><strong>Common Factors</strong> $F_1 , F_m $은 $X $와 linearly dependent.
<strong>errors, Specific Factors</strong> $_1 , , _p $.</p>
<p>$ $</p>
<p><strong>loading</strong> <span class="math inline">\(l_{ij}\)</span>은 <span class="math inline">\(i\)</span>번째 variable의 <span class="math inline">\(j\)</span>번째 factor에 대한 loading.
<strong>matrix of Factor Loadings</strong> <span class="math inline">\(\pmb L\)</span></p>
<p><br></p>
<p>즉슨, <span class="math inline">\(X_i - \mu_i\)</span>는 <span class="math inline">\(F_j\)</span>의 선형결합과 <span class="math inline">\(\epsilon_i\)</span>를 더하는 것으로 서술될 수 있다는 게 요지.</p>
<p>다만 관측되지 않은 quantity가 너무 많아서 Factor Model의 직접적인 검증은 사실상 불가능함.
따라서 <span class="math inline">\(\pmb F\)</span>와 <span class="math inline">\(\pmb \epsilon\)</span>에 추가적인 조건을 덧붙인 후, <span class="math inline">\(Cov\)</span> 관계성을 체크하는 것으로 대신한다.</p>
<p><span class="math inline">\(E(\pmb F) = \pmb 0, Cov(\pmb F) = E(\pmb F \pmb F&#39; ) = I_{m \times m}\)</span></p>
$E() = , Cov() = E(’) = _{p p} =
<span class="math display">\[\begin{bmatrix}\Psi_1 &amp;  &amp; 0 \\ &amp; \ddots &amp;  \\ 0 &amp;  &amp; \Psi_p \end{bmatrix}\]</span>
<p>_{p p} $</p>
<p>$ F $, so $Cov(, F ) = E(’) = _{p m} $</p>
<p><br>
<br>
<br></p>
<p>이때</p>
<p>$
<span class="math display">\[\begin{align*}

\Sigma = Cov(\pmb X) &amp;= E \left[ (\pmb X - \pmb \mu) (\pmb X - \pmb \mu) &#39; \right] \\
&amp;= E \left[ \pmb{LF (LF)&#39; + \epsilon(LF)&#39; + (LF) \epsilon&#39; + \epsilon \epsilon&#39;} \right] \\
&amp;= \pmb {LE(FF&#39;)L&#39; + E(\epsilon \epsilon&#39;)} \\
&amp;= \pmb{LL&#39; + \Psi}

\end{align*}\]</span>
$</p>
<p>ㅁㄴㅇㄹ</p>
<p>$
<span class="math display">\[\begin{align*}

Cov (\pmb {X, F}) = \pmb {E \left[ (X-\mu)(F-0)&#39; \right]} &amp;= E \left[ \pmb {(X-\mu)F&#39; }\right] \\
&amp;= \pmb { E \left[ (LF + \epsilon)F&#39; \right]} \\
&amp;= \pmb { LE(FF&#39;) + E(\epsilon F&#39;) }\\
&amp;= \pmb { L}

\end{align*}\]</span>
$</p>
<p><br>
<br>
<br></p>
<p>따라서 Total Variation은:</p>
<hr />
<strong>communality</strong> <span class="math inline">\(h_j^2 = \sum_{j=1}^m l_{ij}^2\)</span>.
* contribution by <span class="math inline">\(m\)</span> column factors
* $ ’ =
<span class="math display">\[\begin{bmatrix}h_1^2 &amp;  &amp; \sigma_{1p} \\ &amp; \ddots &amp;  \\ \sigma_{p1} &amp;  &amp; h_p^2 \end{bmatrix}\]</span>
<p>_{p p}$.</p>
<p><strong>specific variance</strong> <span class="math inline">\(\Psi_i\)</span></p>
<p>$</p>
<p>Var(X_i) = <em>{j=1}^m l</em>{ij}^2 + <em>i \
Cov(X_i, X_k) = </em>{j=1}^m l_{ij}l_{kj} \
Cov(X_i, F_j) = l_{ij}
$</p>
<p><br>
<br></p>
<p>Notes:
* When <span class="math inline">\(m=p\)</span>, any <span class="math inline">\(Cov\)</span> matrix <span class="math inline">\(S\)</span> can be reproduced exactly as <span class="math inline">\(\pmb{LL}&#39;\)</span>, so <span class="math inline">\(\pmb \Psi\)</span> is the zero matrix.
* When <span class="math inline">\(m &lt; p\)</span>, the FA is most useful. The FA model provides a “simple” explanation of covariance in <span class="math inline">\(\pmb X\)</span>.
* When <span class="math inline">\(m \lll p\)</span>, most <span class="math inline">\(Cov\)</span> matrices <strong>cannot</strong> be factored as <span class="math inline">\(\pmb{LL}&#39;+\pmb \Psi\)</span>(while maintaining basic statistical properties).</p>
</div>
<div id="uniqueness" class="section level5" number="5.7.0.0.2">
<h5 number="5.7.0.0.2"><span class="header-section-number">5.7.0.0.2</span> Uniqueness</h5>
<p>Orthogonal factor model is not unique, b/c rotation.</p>
</div>
<div id="method-of-estimation" class="section level3" number="5.7.1">
<h3 number="5.7.1"><span class="header-section-number">5.7.1</span> Method of Estimation</h3>
<p>Choosing the appropriate Number of Factors:
1. Similar to PCA. Determine the number of factors using scree plot or eigenvalue <span class="math inline">\(\ge 1\)</span>
2. Do not include <strong>trivial factors</strong> (only one variable assigned to one factor).
3. Test the adequacy of the chosen number of factors.(Use ML method and LRT) for standardized variable.
4. Use AIC. Choose m that produces the minimum value for AIC.
5. Use SBC (Schwarz’s Bayesian Criterion).</p>
<p><br>
<br></p>
<p>Notes:
* $= ’ + 
* objective is estimating <span class="math inline">\(\pmb L\)</span></p>
<div id="principal-component-method" class="section level5" number="5.7.1.0.1">
<h5 number="5.7.1.0.1"><span class="header-section-number">5.7.1.0.1</span> 1. Principal Component Method</h5>
<p>$ =  = $. 여기서 기여도가 낮은 <span class="math inline">\(\lambda_i\)</span>에 해당하는 ev를 뒤에서부터 쳐내서 적당한 ev만으로 구성. 그 경우 <span class="math inline">\(=\pmb {L_{p \times m} L_{m \times p}&#39;}\)</span>.</p>
<p>여기서 specific factors <span class="math inline">\(\pmb \Psi\)</span>의 <span class="math inline">\(Var\)</span>을 <span class="math inline">\(\Sigma - \pmb {LL&#39;}\)</span>의 diagonal elements 를 사용해서 구할 수 있다. 근사는 <span class="math inline">\(\Sigma \approx \pmb {LL&#39; + \Psi}\)</span>.</p>
<p>$</p>
<p><em>i = <em>i^2 - </em>{j=1}^m l</em>{ij}^2 = <em>i^2 - </em>{j=1}^m <em>j e</em>{ij}^2</p>
<p>$</p>
<p>이는 위에서 <span class="math inline">\(l_{ij} = \sqrt {\lambda_j e_{ij}}\)</span>임을 보여놨기에 가능.</p>
<p><br>
<br></p>
<p>the importance of <span class="math inline">\(j\)</span>th factor</p>
<p>$
<span class="math display">\[\begin{align*}
= \dfrac {\lambda_j}{\sum_{i=1}^p \lambda_i} &amp;= \dfrac {\sum_{i=1}^p l_{ij}^2} {\sum_{i=1}^p \sigma^2} \\

&amp;= \dfrac {\sum_{i=1}^p l_{ij}^2} {p} \; \; \; \; \; \; \; \; \; \; \text{if} \; \; \Sigma=\pmb \rho

\end{align*}\]</span>
$</p>
<p>at here, <strong>communality</strong> <span class="math inline">\(h_i^2 = \sum_{j=1}^m l_{ij}^2\)</span>.</p>
</div>
<div id="ml-method" class="section level5" number="5.7.1.0.2">
<h5 number="5.7.1.0.2"><span class="header-section-number">5.7.1.0.2</span> 3. ML Method</h5>
<p>assumption is needed: <span class="math inline">\(\pmb X \sim N_p (\pmb mu , \Sigma)\)</span>, where $=  + $.</p>
<p>이때 <span class="math inline">\(L(\pmb \mu, \Sigma)\)</span>는 $=  + $ 이기에 <span class="math inline">\(\pmb L\)</span>, <span class="math inline">\(\Psi\)</span>에 의존.</p>
<p><span class="math inline">\(\hat \pmb L_{MLE}\)</span>, <span class="math inline">\(\hat \pmb \Psi_{MLE}\)</span>는 수치해석으로 찾아짐.</p>
<p>estimated communalities들은 $ h_i^2 = <em>{j=1}^m l</em>{ij}^2$, <span class="math inline">\(i=1, \cdots, p\)</span>.</p>
<p>The importance of <span class="math inline">\(j\)</span>th factor는~.</p>
<div id="test-for-the-number-of-factors" class="section level6" number="5.7.1.0.2.1">
<h6 number="5.7.1.0.2.1"><span class="header-section-number">5.7.1.0.2.1</span> 3.5. Test for the number of factors</h6>
<p><span class="math inline">\(H_0: \; \; \Sigma_{p \times p} = \pmb L_{p \times m} \pmb L&#39;_{m \times} + \pmb \Psi_{p \times p}\)</span>
<span class="math inline">\(H_1: \Sigma_{p \times p}\)</span>는 any other positive definite matrix.</p>
<p>assume <span class="math inline">\(\pmb X \sim N_p (\pmb mu , \Sigma)\)</span>.</p>
<p>under <span class="math inline">\(H_0\)</span>, $=  + $. 이때 $_{MLE} =   + $.</p>
<p>under <span class="math inline">\(H_1\)</span>, <span class="math inline">\(\hat \Sigma_{MLE} = S_n\)</span>. 이떄 $ S_n$은 sample <span class="math inline">\(Cov\)</span> matrix.</p>
<p>LRT for testing <span class="math inline">\(H_0\)</span>:</p>
<p>$
-2log = n log ( ) = n log ( )
$</p>
</div>
<div id="bartletts-approx." class="section level6" number="5.7.1.0.2.2">
<h6 number="5.7.1.0.2.2"><span class="header-section-number">5.7.1.0.2.2</span> 3.7. Bartlett’s Approx.</h6>
<p>reject <span class="math inline">\(H_0\)</span> if~.</p>
</div>
</div>
<div id="minimum-residual-method" class="section level5" number="5.7.1.0.3">
<h5 number="5.7.1.0.3"><span class="header-section-number">5.7.1.0.3</span> 3. Minimum Residual Method</h5>
<p>let $Cov(X) = =  + $, and mv regression <span class="math inline">\(pmb{Y_{n \times m}=Z_{n \times (r+1)} \beta_{(r+1)\times m)} + \epsilon_{n \times m}\)</span>와 유사한 개형.</p>
<p>estimate factor loadings so that the sum of squares of off-diagonal residuals be minimized.</p>
<p><span class="math inline">\(\hat \pmb L_{MLE}\)</span>, <span class="math inline">\(\hat \pmb \Psi_{MLE}\)</span>는 수치해석으로 찾아짐.</p>
<p>estimated communalities들은 $ h_i^2 = <em>{j=1}^m l</em>{ij}^2$, <span class="math inline">\(i=1, \cdots, p\)</span>.</p>
<p>The importance of <span class="math inline">\(j\)</span>th factor는~.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="factor-rotation" class="section level3" number="5.7.2">
<h3 number="5.7.2"><span class="header-section-number">5.7.2</span> Factor Rotation</h3>
<p>All factor loadings obtained from the initial loading by an orthogonal transformation have the same ability to reproduce the covariance matrix.
* $=  + =  + =  + $. at here, must be <span class="math inline">\(TT&#39; = I\)</span> by characteristics of rotation in linear algebra.</p>
<p>From matrix algebra, we know that an orthogonal transformation corresponds to a rigid rotation of the coordinate axes.</p>
<p>An orthogonal transformation of factor loading is called factor rotation.</p>
<p>The communalities <span class="math inline">\(\hat h_i^2\)</span> and the specific variances <span class="math inline">\(\hat \Psi_i\)</span> are not changed, b/c $ =  $, and diagonal elements of this is communalities.</p>
<p>Rationale: Since the original loadings <span class="math inline">\(L\)</span> may not be easily interpretable, it is usual practice to rotate them until a “simpler structure” is achieved.</p>
</div>
<div id="varimax-criterion" class="section level3" number="5.7.3">
<h3 number="5.7.3"><span class="header-section-number">5.7.3</span> Varimax Criterion</h3>
<p>define <span class="math inline">\(\hat l_{ij}^\ast = \dfrac {l_{ij}^\ast}{\hat h_j}\)</span> to be the rotated coefficients. Then the Varimax procedure selects the orthogonal transformation T that makes <span class="math inline">\(V=\)</span> as large as possible. 이는 일종의 분산으로서 관점될 수 있다.</p>
<p>In words, $V _{j=1}^mVar( l_j^2 ) $ , which is variance of squares of loading for jth factor.</p>
<p>Maximizing <span class="math inline">\(V\)</span> corresponding to “spreading out” the squares of loadings on each factor as much as possible.</p>
<div id="oblique-rotation" class="section level5" number="5.7.3.0.1">
<h5 number="5.7.3.0.1"><span class="header-section-number">5.7.3.0.1</span> Oblique Rotation</h5>
<ul>
<li>It is not possible to rotate the axes so that one axes goes through each cluster of variables while keeping the axes orthogonal to one another.</li>
<li>Such rotation can be achieved by multiplying L by a matrix Q where Q is not an orthogonal matrix.</li>
<li>Oblique rotations do not produce new factors that remain uncorrelated, which is a contradiction of the initial FA assumptions <span class="math inline">\(\rightarrow\)</span> not good!</li>
</ul>
</div>
</div>
<div id="factor-scores" class="section level3" number="5.7.4">
<h3 number="5.7.4"><span class="header-section-number">5.7.4</span> Factor Scores</h3>
<p>In</p>
<!--chapter:end:211309_Factor.Rmd-->
</div>
</div>
<div id="discrimination-and-classification" class="section level2" number="5.8">
<h2 number="5.8"><span class="header-section-number">5.8</span> Discrimination and Classification</h2>
<ol style="list-style-type: decimal">
<li>여러개의 다른 모집단으로부터 나온 데이터들을 <strong>설명</strong>. discriminants (구분자) 들의 발견.</li>
<li>관찰치를 <strong>분류</strong>하여 이를 클래스로 묶고 싶다. why인지는 크게 중요하지 않고, <strong>예측</strong>을 하고 싶다.</li>
</ol>
<p><br>
<br></p>
<div id="bayes-rule" class="section level3" number="5.8.1">
<h3 number="5.8.1"><span class="header-section-number">5.8.1</span> Bayes Rule</h3>
<p><img src="11-1.png" width="480" alt="hi" class="inline"/></p>
<p>let r<span class="math inline">\(v\)</span> for populations <span class="math inline">\(\pi_1 , \pi_2\)</span>, <span class="math inline">\(\pmb X = (x_1 , \cdots, x_p)&#39;\)</span>. 이때, <span class="math inline">\(f_i(\pmb X)\)</span>는 <span class="math inline">\(\pi_i\)</span>의 pdf. <span class="math inline">\(R_i\)</span>는 우리가 해당 object를 <span class="math inline">\(\pi_i\)</span>로 분류하는 <span class="math inline">\(\pmb X\)</span> 값들의 set.</p>
<p>$</p>
<p>R_1 :  {f_2 ( X)} , ; ; ; ; ; R_2 :  {f_2 ( X)}  </p>
<p>$</p>
<p><br>
<br></p>
<p><img src="11-2.png" width="480" alt="hi" class="inline"/></p>
<p>let prior of each <span class="math inline">\(P_i\)</span> be <span class="math inline">\(\pi_i\)</span>, and <span class="math inline">\(\sum_{i=1}^n P_i = 1\)</span>.</p>
<p>$</p>
<p>R_1 :  {f_2 ( X)} , ; ; ; ; ; R_2 :  {f_2 ( X)}  </p>
<p>$</p>
<p><br>
<br></p>
<p>let the costs of misclassification can be defined by a cost matrix:</p>
<div class="line-block">| classify <span class="math inline">\(\pi_1\)</span>| <span class="math inline">\(\pi_2\)</span> |<br />
True Population <span class="math inline">\(\pi_1\)</span> | 0 | <span class="math inline">\(C(2 \vert 1)\)</span> |<br />
<span class="math inline">\(\pi_2\)</span> | <span class="math inline">\(C(1 \vert 2)\)</span> | 0 |</div>
<p>$</p>
<p>R_1 :  {f_2 ( X)} , ; ; ; ; ; R_2 :  {f_2 ( X)}  </p>
<p>$</p>
<p><br>
<br></p>
<p>and let both.</p>
<p>$</p>
<p>R_1 :  {f_2 ( X)}  , ; ; ; ; ; R_2 :  {f_2 ( X)}   </p>
<p>$</p>
<p><br>
<br>
<br></p>
</div>
<div id="classification-with-two-mv-n-populations" class="section level3" number="5.8.2">
<h3 number="5.8.2"><span class="header-section-number">5.8.2</span> Classification with Two mv <span class="math inline">\(N\)</span> Populations</h3>
<p>assume <span class="math inline">\(\pmb X_1 \sim N_p( \pmb \mu_1 , \Sigma_1), \pmb X_2 \sim N_p( \pmb \mu_2 , \Sigma_2)\)</span></p>
<p><br>
<br></p>
<div id="if-sigma_1-sigma_2-sigma-lda" class="section level5" number="5.8.2.0.1">
<h5 number="5.8.2.0.1"><span class="header-section-number">5.8.2.0.1</span> 1. if <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span> (LDA)</h5>
<p>this is called Linear Discriminant Analysis, e.g., LDA.</p>
<p><img src="11-3.png" width="480" alt="hi" class="inline"/></p>
<p>$</p>
<p>f_i ( X ) =  {(2)^{p/2} {}^{1/2}} </p>
<p>$</p>
<p>suppose the populations parameters, <span class="math inline">\(\pmb \mu_1, \pmb \mu_2, \Sigma\)</span> are known.</p>
<p>The minimum expected cost rule is</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat*}{2}


&amp;R_1 : \dfrac {f_1 ( \pmb X)} {f_2 ( \pmb X)} &amp;
&amp;\ge  \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \\



&amp;\exp \left[ 
-\dfrac {1} {2} (\pmb X - \pmb \mu_1)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_1)&#39; +\dfrac {1} {2} (\pmb X - \pmb \mu_2)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_2)

\right]&amp;

&amp;\ge \\



&amp;-\dfrac {1} {2} (\pmb X - \pmb \mu_1)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_1)&#39; +\dfrac {1} {2} (\pmb X - \pmb \mu_2)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_2) &amp;

&amp;\ge \log \left[ \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \right] \\

\\
\\


\Rightarrow \; \; \; \; \;



&amp;(\pmb \mu_1 - \pmb \mu_2)&#39; \Sigma^{-1} \pmb X - \dfrac {1}{2} (\pmb \mu_1 - \pmb \mu_2)&#39; \Sigma^{-1} (\pmb \mu_1 + \pmb \mu_2) &amp;

&amp;\ge 


\\
\\


\Rightarrow \; \hat R_1 \colon \; \; \; \; \; 



&amp;(\bar {\pmb X}_1 - \bar {\pmb X}_2)&#39; {S_p}^{-1} \pmb X - \dfrac {1}{2} (\bar {\pmb X}_1 - \bar {\pmb X}_2)&#39; {S_p}^{-1} (\bar {\pmb X}_1 + \bar {\pmb X}_2) &amp;

&amp;\ge \tag{1}


\\
\\


\Rightarrow \; \hat R_1 \colon \; \; \; \; \; 


&amp; \hat {\pmb a}&#39; \pmb X - \dfrac {1}{2} ( \hat {\pmb a}&#39; \bar {\pmb X_1} + \hat {\pmb a}&#39; \bar {\pmb X_2}) &amp;

&amp;\ge \tag{2}


\end{alignat*}\]</span></p>
<p>$</p>
<p><br></p>
<p>Allocate (Classify) <span class="math inline">\(\pmb X_0\)</span> to <span class="math inline">\(\pi_1\)</span> if <span class="math inline">\(R_1\)</span> holds.</p>
<p>Note that <span class="math inline">\(R_1\)</span> has changed to $ R_1$ at last expression.</p>
<p><br>
<br></p>
<p><span class="math inline">\((1):\)</span> However, in practice, <span class="math inline">\(\pmb \mu_1, \pmb \mu_2, \Sigma\)</span> are unknown. 따라서 해당 룰은 상응하는 패러미터를 샘플 패러미터로 대체해서 이루어짐.</p>
<p><span class="math inline">\(\pmb \mu_i\)</span>는 ${X}_i $ 로 대체.</p>
<p>we assumed <span class="math inline">\(\Sigma_1 = \Sigma_2 = \Sigma\)</span>, therefore <span class="math inline">\(\Sigma\)</span> can be replaced by <span class="math inline">\(S_p = \dfrac{n_1 - 1 } {n_1 + n_2 -2} S_1 + \dfrac{n_2 - 1 } {n_1 + n_2 -2} S_2\)</span>.</p>
<hr />
<p><span class="math inline">\((2):\)</span> Note that <span class="math inline">\((\bar {\pmb X}_1 - \bar {\pmb X}_2)&#39; {S_p}^{-1} \pmb X\)</span> is linear combination of variable <span class="math inline">\(\pmb X\)</span>.</p>
<p>let <span class="math inline">\((\bar {\pmb X}_1 - \bar {\pmb X}_2)&#39; {S_p}^{-1} = \hat {\pmb a}&#39;\)</span>.</p>
<hr />
<div id="lda-intuition" class="section level6" number="5.8.2.0.1.1">
<h6 number="5.8.2.0.1.1"><span class="header-section-number">5.8.2.0.1.1</span> LDA intuition</h6>
<p><img src="11-4.png" width="480" alt="hi" class="inline"/></p>
<p><br>
<br></p>
</div>
<div id="posterior" class="section level6" number="5.8.2.0.1.2">
<h6 number="5.8.2.0.1.2"><span class="header-section-number">5.8.2.0.1.2</span> Posterior</h6>
<p>assuming equal prior, equal misclassification cost:</p>
<p>$
<span class="math display">\[\begin{alignat*}{1}

P(\pi_1 \vert \pmb X) &amp;= \dfrac{f_1 ( \pmb X) } {f_1 ( \pmb X) + f_2 ( \pmb X) } \\

&amp;= 

\dfrac
{\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_1)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_1)&#39; \right] } 

{\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_1)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_1)&#39;\right] + 
\exp \left[ - \dfrac {1}{2} (\pmb X - \pmb \mu_2)&#39; \Sigma^{-1} (\pmb X - \pmb \mu_2)&#39;\right]}


\end{alignat*}\]</span>
$</p>
<p>Allocate <span class="math inline">\(\pmb X_0\)</span> to <span class="math inline">\(\pi_1\)</span>, if $P(_1 X_0) P(_2 X_0) $.</p>
<p>This is equivalent to the Bayes Rule $R_1 f_1 (X) f_2 (X) $.</p>
<p><br>
<br></p>
</div>
</div>
<div id="sigma_1-not-sigma_2-qda" class="section level5" number="5.8.2.0.2">
<h5 number="5.8.2.0.2"><span class="header-section-number">5.8.2.0.2</span> 2. <span class="math inline">\(\Sigma_1 \not = \Sigma_2\)</span> (QDA)</h5>
<p>This is called Quadratic Discriminant Analysis (QDA).</p>
<p>suppose the populations parameters, <span class="math inline">\(\pmb \mu_1, \pmb \mu_2, \Sigma_1, \Sigma_2\)</span> are known.</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat*}{2}


R_1 \colon \; &amp;-\dfrac {1} {2} (\pmb X - \pmb \mu_1)&#39; \Sigma_1^{-1} (\pmb X - \pmb \mu_1)&#39; +\dfrac {1} {2} (\pmb X - \pmb \mu_2)&#39; \Sigma_2^{-1} (\pmb X - \pmb \mu_2)&#39;&amp;

&amp;\ge \log \left[ \dfrac {P_2}{P_1} \ast \dfrac {C(1\vert2)}{C(2\vert1)} \right] 

\\
\\


\Rightarrow \; \; \; \; \;

&amp;(\pmb \mu_1 \Sigma_1 ^{-1} - \pmb \mu_2 \Sigma_2 ^{-1} )&#39;  \pmb X - \dfrac {1}{2} \pmb X &#39; (\Sigma_1^{-1} - \Sigma_2^{-1} ) \pmb X \; \; \; \; \; -k&amp;

&amp;\ge  \tag{3}


\\
\\

\Rightarrow \; \hat R_1 \colon \; \; \; \; \;

&amp;(\pmb \mu_1 S_1 ^{-1} - \pmb \mu_2 S_2 ^{-1} )&#39;  \pmb X - \dfrac {1}{2} \pmb X &#39; (S_1^{-1} - S_2^{-1} ) \pmb X \; \; \; \; \; - k&amp;

&amp;\ge 





\end{alignat*}\]</span></p>
<p>$</p>
<p><br></p>
<p>allocate <span class="math inline">\(\pmb X_0\)</span> to <span class="math inline">\(\pi_1\)</span> if <span class="math inline">\(R_1\)</span> holds.</p>
<hr />
<p><span class="math inline">\((3)\)</span> where</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat*}{2} 

k &amp;= \dfrac {1} {2} \log \left( \dfrac {\vert \Sigma_1 \vert}{\vert \Sigma_2 \vert}\right) + \dfrac {1}{2} (\pmb \mu_1 &#39; \Sigma_1^{-1} \pmb \mu_1 - \pmb \mu_2 &#39; \Sigma_2^{-1} \pmb \mu_2) \\ 

&amp;= \dfrac {1} {2} \log \left( \dfrac {\vert S_1 \vert}{\vert S_2 \vert}\right) + \dfrac {1}{2} (\hat {\pmb X}_1 &#39; S_1^{-1} \hat {\pmb X}_1 - \hat {\pmb X}_2 &#39; S_2^{-1} \hat {\pmb X}_2) 

\end{alignat*}\]</span></p>
<p>$</p>
<p><br>
<br></p>
<p>When <span class="math inline">\(\Sigma_1 = \Sigma_2\)</span>, <span class="math inline">\(\pmb X &#39; (\Sigma_1^{-1} - \Sigma_2^{-1} ) \pmb X\)</span> disappears, which means LDA.</p>
<hr />
<p>This regions <span class="math inline">\(R_1\)</span> is defined by quadratic functions of <span class="math inline">\(\pmb X\)</span>.</p>
<p><img src="11-5.png" width="480" alt="hi" class="inline"/></p>
</div>
</div>
<div id="evaluating-classification-functions" class="section level3" number="5.8.3">
<h3 number="5.8.3"><span class="header-section-number">5.8.3</span> Evaluating Classification Functions</h3>
<p><img src="11-6.png" width="480" alt="hi" class="inline"/></p>
<p>The misclassification probability is <span class="math inline">\(P(1 \vert 2) + P(2 \vert 1)\)</span>. . If <span class="math inline">\(R_1, R_2\)</span> are selected by Bayes Rule, then this misclassification probability is the minimum.</p>
<hr />
<p>Sample Misclassification Probability:</p>
<p>$P_1 <em>{R_2} f_1 (x) dx + P_2 </em>{R_1} f_2 (x) dx $</p>
<p>assume <span class="math inline">\(f_1(\pmb x), f_2(\pmb x)\)</span> are unkown. 우리가 분포를 가정하지 않으면 이를 측정하는 것은 상당히 어렵다.</p>
<div id="apparent-error-rate-aper" class="section level5" number="5.8.3.0.1">
<h5 number="5.8.3.0.1"><span class="header-section-number">5.8.3.0.1</span> Apparent Error Rate (APER)</h5>
<p>이는 training 샘플 중에서 sample classification function에 의해 분류될 때 잘못 분류된 관찰값들의 분수.
* Training Sample: classification function 제작을 위해 사용되는 데이터
* Test Sample: classification function 평가를 위해 사용되는 데이터. 이는 training sample과는 독립.</p>
<div id="confusion-matrix" class="section level6" number="5.8.3.0.1.1">
<h6 number="5.8.3.0.1.1"><span class="header-section-number">5.8.3.0.1.1</span> Confusion Matrix</h6>
<div class="line-block">| Predicted <br> Membership <br> <span class="math inline">\(\pi_1\)</span> | <span class="math inline">\(\pi_2\)</span> | |<br />
Actual<br><span class="math inline">\(\pi_1\)</span> | <span class="math inline">\(n_{11}\)</span> | <span class="math inline">\(n_{12}\)</span> | <span class="math inline">\(n_1\)</span> |<br />
<span class="math inline">\(\pi_2\)</span> | <span class="math inline">\(n_{21}\)</span> | <span class="math inline">\(n_{22}\)</span> | <span class="math inline">\(n_2\)</span> |</div>
<p>the APER <span class="math inline">\(= \dfrac {n_{21} + n_{12}} {n_1 + n_2}\)</span>: 오분류된 item들의 비율.</p>
<p><strong>APER은 true 오분류 확률을 과소평가한다.</strong> 이는 classification function 생산에 활용된 데이터들이 또한 이를 평가하기 위해서도 사용되기 때문. 생산에 쓰였던 놈들인만큼 생산된 classification function은 얘들한테 좀 더 최적화되어있을 수밖에 없고 이에 의해 에러율이 낮아진다.</p>
<p><br>
<br></p>
</div>
</div>
<div id="test-sample-error-rate" class="section level5" number="5.8.3.0.2">
<h5 number="5.8.3.0.2"><span class="header-section-number">5.8.3.0.2</span> Test Sample Error Rate</h5>
<p>training 샘플과 독립인, test 샘플이 따로 존재한다면,우리는 misclassification probability를 test 샘플에서 오분류된 비율로 misclassification probability를 계산하는 것이 가능하다.</p>
<p>test 샘플이 없다면, 총 데이터를 training과 test 샘플로 쪼갠다. training 샘플은 classification function의 구축에 사용되고, test 샘플은 이를 평가하는데 쓰인다. 이 과정은 large sample을 필요로 한다.</p>
<p><br>
<br></p>
</div>
<div id="hold-out-error-rate" class="section level5" number="5.8.3.0.3">
<h5 number="5.8.3.0.3"><span class="header-section-number">5.8.3.0.3</span> Hold-out Error Rate</h5>
<p><span class="math inline">\(= \dfrac {n_{21}^{(H)} + n_{12}^{(H)}} {n_1 + n_2}\)</span></p>
<p>Also called ‘leave-one-out’ or ‘cross-validation’ error rate.
1. 관측값 1개를 뽑아서 (omit) 제외한 후 나머지 데이터들을 사용해서 cf 생산.
2. 위에서 생산한 function을 써서 <strong>hold-out</strong> 관측값을 분류.
3. 모든 관측값들이 분류될 때까지 1, 2를 반복.</p>
<p>이에 의해, 역으로 1-LOO는 accuracy rate.</p>
<hr />
</div>
</div>
<div id="classification-with-several-populations-wk13" class="section level3" number="5.8.4">
<h3 number="5.8.4"><span class="header-section-number">5.8.4</span> Classification with several Populations (wk13)</h3>
<p>let associated with <span class="math inline">\(\pi_i , i = 1, \cdots, g\)</span>:
* density $f_i (x) $
* Prior distribution <span class="math inline">\(P_i\)</span>
* misclassification cost <span class="math inline">\(C(k \vert i)\)</span>
* set of <span class="math inline">\(\pmb x\)</span> classified as, <span class="math inline">\(R_k\)</span></p>
<p><span class="math inline">\(R_k\)</span> is the region that
* <span class="math inline">\(f_k(\pmb x) \propto P_k f_k(\pmb x)\)</span> is largest
* <span class="math inline">\(\sum_{\not k} f_i(\pmb x) \propto \sum_{\not k} P_i f_i(\pmb x) \propto \sum_{\not k} C(k \vert i) P_i f_i(\pmb x)\)</span> is smallest</p>
<p><br></p>
<ul>
<li><strong>under equal misclassification cost</strong>, allocate <span class="math inline">\(\pmb X_0\)</span> to <span class="math inline">\(\pi_k\)</span> if:</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat*}{3}
\forall i \not = &amp;k: P_k f_k (\pmb x) &amp;&amp;&gt;P_i f_i (\pmb x) \\
&amp;\log P_k f_k (\pmb x) &amp;&amp;&gt;\log P_i f_i (\pmb x) \\
\end{alignat*}\]</span>
$</p>
<p><br></p>
<ul>
<li><ul>
<li>the Bayes rule is identical to the rule that maximizes Posterior Probability <span class="math inline">\(P(\pi \vert \pmb X) = \dfrac{P_k f_k (\pmb x)}{\sum_{i=1}^g P_i f_i (\pmb x)}\)</span></li>
</ul></li>
</ul>
<hr />
<div id="classification-with-several-normal-populations" class="section level5" number="5.8.4.0.1">
<h5 number="5.8.4.0.1"><span class="header-section-number">5.8.4.0.1</span> Classification with several Normal Populations</h5>
<p>assume <span class="math inline">\(f_i (\pmb x) \sim N_p (\pmb \mu_i , \Sigma_i )\)</span>, and <strong>equal misclassification cost</strong>.</p>
<p><br></p>
<hr />
<div id="sigma_1-cdots-sigma_g-sigma-lda" class="section level6" number="5.8.4.0.1.1">
<h6 number="5.8.4.0.1.1"><span class="header-section-number">5.8.4.0.1.1</span> 1. <span class="math inline">\(\Sigma_1 = \cdots = \Sigma_g = \Sigma\)</span> (LDA)</h6>
<p>MVN을 따르는 것에서 <span class="math inline">\(f_k\)</span>의 형은 알 수 있다.</p>
<p>according to Bayes rule, we allocate <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi_k\)</span> if</p>
<p>$
P_k f_k ( x_0 ) = _i P_i f_i ( x_0 )
$</p>
<p>이때 constant $- (2 ) - () - x_0 ’ ^{-1} x_0 $는 모든 <span class="math inline">\(\log P_i f_i (\pmb x_0)\)</span>에 대해 공통 (<span class="math inline">\(k\)</span>에 의존하지 않으므로). 따라서 해당 constant 부위는 비교 목적으로는 무시될 수 있음.</p>
<p><br></p>
<p>$
<span class="math display">\[\begin{align*}

d_i (\pmb x) &amp;= \pmb \mu_i &#39; \Sigma^{-1} \left( \pmb x \right) - \tfrac{1}{2} \pmb \mu_i &#39; \Sigma^{-1} \pmb \mu_i + \log P_i \tag{1} \\

\\

S_p &amp;= \tfrac{1}{(n_1 + \cdots +n_g) - g} \left[ (n_1-1)S_1 + \cdots (n_g - 1)S_g  \right] \tag{2} \\

\\

\Longrightarrow \hat d_i (\pmb x) &amp;= \bar { \pmb x_i} S_p^{-1} \ast \pmb x - \tfrac{1}{2} \bar { \pmb x_i} &#39; S_p^{-1} \bar { \pmb x_i} + \log P_i \tag{3}

\end{align*}\]</span></p>
<p>$</p>
<ol style="list-style-type: decimal">
<li>define linear discriminant function (LDF) <span class="math inline">\(d_i (\pmb x)\)</span>, where <span class="math inline">\(i=1, \cdots, g\)</span>.</li>
<li><span class="math inline">\(\Sigma\)</span>’s pooled estimate <span class="math inline">\(S_p\)</span></li>
<li><span class="math inline">\(d_i (\pmb x)\)</span>’s estimate <span class="math inline">\(\hat d_i (\pmb x)\)</span>, 실질적으로 사용할 LDF function.</li>
</ol>
<ul>
<li>Estimated Bayes Rule:
<ul>
<li>allocate <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi_k\)</span>, <br>if <span class="math inline">\(\hat d_k(\pmb x_0) = \max \{ \hat d_1(\pmb x_0), \cdots, \hat d_g(\pmb x_0) \}\)</span>. 뒤의 조건을 만족하는 것이 Likelihood의 키가 가장 큰 population이므로.</li>
</ul></li>
</ul>
<p><br>
<br></p>
<hr />
</div>
<div id="not-sigma-qda" class="section level6" number="5.8.4.0.1.2">
<h6 number="5.8.4.0.1.2"><span class="header-section-number">5.8.4.0.1.2</span> 2. <span class="math inline">\(\not = \Sigma\)</span> (QDA)</h6>
<p>$
P_k f_k ( x_0 ) = _i P_i f_i ( x_0 )
$</p>
<p>constant <span class="math inline">\(-\dfrac{p}{2} \log(2 \pi)\)</span>는 모든 <span class="math inline">\(\log P_i f_i (\pmb x_0)\)</span>에 대해 공통, 무시 가능.</p>
<ul>
<li>define quadratic discriminant function <span class="math inline">\(d_i^Q (\pmb x)\)</span>, where <span class="math inline">\(i=1, \cdots, g\)</span>:</li>
</ul>
<p>$
<span class="math display">\[\begin{align*}

d_i^Q (\pmb x) &amp;= -\dfrac{1}{2} \log\vert\Sigma_i \vert -\dfrac{1}{2} (\pmb x - \pmb \mu_i)&#39; \Sigma_i^{-1} (\pmb x - \pmb \mu_i) +\log P_i \\

\\

\hat {d}_i^Q (\pmb x) &amp;= -\dfrac{1}{2} \log\vert S_i \vert -\dfrac{1}{2} (\pmb x - \bar {\pmb x_i})&#39; S_i^{-1} (\pmb x - \bar {\pmb x_i}) +\log P_i \tag{Sample}

\end{align*}\]</span>
$</p>
<ul>
<li>Estimated Bayes Rule:
<ul>
<li>allocate <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi_k\)</span>, <br>if <span class="math inline">\(\hat d_k^Q(\pmb x_0) = \max \{ \hat d_1^Q(\pmb x_0), \cdots, \hat d_g^Q(\pmb x_0) \}\)</span></li>
</ul></li>
</ul>
<p><br>
<br>
<br></p>
<hr />
</div>
</div>
</div>
<div id="other-discriminant-analysis-methods" class="section level3" number="5.8.5">
<h3 number="5.8.5"><span class="header-section-number">5.8.5</span> Other Discriminant Analysis Methods</h3>
<ul>
<li>Nearest Neighbor Discriminant Analysis (거리 함수 사용)
<ol style="list-style-type: decimal">
<li>Nonparametric approach – <strong>no assumption on distribution</strong>
<ul>
<li>Idea
*For a new observation, first find the observation in the training sample that is closest to the new observation. (i.e. its Mahalanobis distance is smallest) <br>Then assign the new observation to the group from which the observation’s nearest neighbor comes.</li>
<li>Variations: K-nearest neighbor
<ul>
<li>assign each new observation to the group to which a majority of its k nearest neighbors belongs. e.g. k=5.</li>
</ul></li>
</ul></li>
</ol></li>
</ul>
<p><br>
<br></p>
<hr />
<div id="knn" class="section level5" number="5.8.5.0.1">
<h5 number="5.8.5.0.1"><span class="header-section-number">5.8.5.0.1</span> KNN</h5>
<p><img src></p>
<p><span class="math inline">\(K_1\)</span> belongs to group 1, <span class="math inline">\(K_2\)</span> belongs to group 2. 우리는 <span class="math inline">\(K_1 + K_2 =K =5\)</span> 로 설정함. 즉 가장 가까운 이웃 5개를 뽑되 Group 1과 Group 2에서 뽑은 애들을 합하면 총 5개여야 함.</p>
<p>assign <span class="math inline">\(\pmb x_0\)</span> to group 1 (<span class="math inline">\(\pi1\)</span>) if <span class="math inline">\(K_1 \ge K_2\)</span>.
- if <span class="math inline">\(n_1 \not = n_2\)</span>, then assign <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi1\)</span> if <span class="math inline">\(\dfrac{K_1}{n_1} \ge \dfrac{K_2}{n_2}\)</span>.
- if <span class="math inline">\(P_1 \not = P_2\)</span>, then assign <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi1\)</span> if <span class="math inline">\(P_1\dfrac{K_1}{n_1} \ge P_2\dfrac{K_2}{n_2}\)</span>.</p>
<ul>
<li>choice of <strong>hyper-parameters</strong> <span class="math inline">\(K\)</span>:</li>
</ul>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(K = \sqrt{n_1}\)</span>.</li>
<li>select <span class="math inline">\(K\)</span> s.t. minimizes the error rate</li>
</ol>
<p><br>
<br></p>
<hr />
</div>
<div id="kernel-density-estimation-discriminant-analysis-kda" class="section level5" number="5.8.5.0.2">
<h5 number="5.8.5.0.2"><span class="header-section-number">5.8.5.0.2</span> Kernel (Density Estimation) Discriminant Analysis (KDA)</h5>
<ol style="list-style-type: decimal">
<li><p>Bayes Rule 이론에서 출발, Likelihood 함수 사용 (KNN과는 이 부분부터 다름. KNN은 Bayes Rule 안썼음): allocate <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi_k\)</span>, if <span class="math inline">\(\dfrac{f_1 (\pmb x)}{f_2 (\pmb x)} \ge \dfrac{P_2 C(1 \vert 2)}{P_1 C(2 \vert 1)}\)</span>
분포에 대한 가정 없이 개시하므로, 밀도함수 자체를 추정해버리자. density estimation: estimate f_1 (x) and f_2 (x) for each point <span class="math inline">\(\pmb x\)</span>, where <span class="math inline">\(N(\pmb x_0)\)</span> is neighborhood around <span class="math inline">\(\pmb x_0\)</span> of width <span class="math inline">\(\lambda\)</span></p>
<p>이동 히스토그램
람다는 벽돌 하나의 넓이이며, 람다값이 달라지면 추정된 pdf의 형 또한 조금씩 바뀔 수 있음</p>
<p>$
f(x_0) = 
$</p>
<p><img src></p>
<p>this estimate is bumpy. 더 발전된 추정법을 찾아내자. 개선된 추정법:</p></li>
<li><p>Parzen Estimate</p></li>
</ol>
<p>$
f(x_0) =  <em>{i=1}^N K</em>{} (x_0 , x_i)
$</p>
<p>위의 초기형 추정에서 사용된 커널함수는 uniform. 가우시안 커널은 정규분포의 형을 따르므로 이는 당연히 분산을 필요로 함. 여기서 분산 부분에 들어가는건 람다이며, 따라서 람다는 벽돌의 넓이, width를 결정하게 된다. 따라서 람다는 called as smoothing parameters, or bandwidth. 추정의 성능은 거의 전적으로 람다의 selection에 달려있음. 람다 잘 고르면 추정 성능 높고, 람다 잘못 고르면 떡락함. 람다를 너무 좁게 잡으면 삐쭉삐쭉해서 과반영되고, 너무 넓게 잡으면 민둥산이 나와서 값 간의 density가 다 비슷비슷한 나쁜 pdf가 추정됨.</p>
<p>at here, popular choice of <span class="math inline">\(K_{\lambda}\)</span> is Gaussian kernal:</p>
<p>$</p>
<p>K_{} (x_0 , x) = (  ) =  {  ( x_i - x_0 )^2 }</p>
<p>$</p>
<ul>
<li><ol start="3" style="list-style-type: decimal">
<li>estimated Bayes Rule:</li>
</ol>
<ul>
<li>allocate <span class="math inline">\(\pmb x_0\)</span> to <span class="math inline">\(\pi_1\)</span>, <br> if <span class="math inline">\(\dfrac{\hat f_1 (\pmb x_0)}{\hat f_2 (\pmb x_0)} \ge \dfrac{P_2 C(1 \vert 2)}{P_1 C(2 \vert 1)}\)</span></li>
</ul></li>
</ul>
<p>이런 식의 비율 접근법은 클래스가 2개인 경우 한정. 늘어나면 달라?</p>
<p><br>
<br></p>
<hr />
</div>
<div id="modern-classification-methods" class="section level5" number="5.8.5.0.3">
<h5 number="5.8.5.0.3"><span class="header-section-number">5.8.5.0.3</span> Modern Classification Methods:</h5>
<ol style="list-style-type: decimal">
<li>Decision Trees
<ul>
<li>Classification Trees</li>
<li>Regression Trees</li>
</ul></li>
<li>Neutral Networks</li>
<li>Support Vector Machines</li>
<li>Ensemble</li>
</ol>
<!--chapter:end:211311_DiscriminationandClassification.Rmd-->
</div>
</div>
</div>
<div id="clustering-distance-methods-and-ordination" class="section level2" number="5.9">
<h2 number="5.9"><span class="header-section-number">5.9</span> Clustering, Distance Methods, and Ordination</h2>
<div id="overview-5" class="section level3" number="5.9.1">
<h3 number="5.9.1"><span class="header-section-number">5.9.1</span> Overview</h3>
<ul>
<li>Example: Customer Segmentation</li>
</ul>
<p><img src = "12-1.png"></p>
<hr />
<div id="clustering" class="section level5" number="5.9.1.0.1">
<h5 number="5.9.1.0.1"><span class="header-section-number">5.9.1.0.1</span> Clustering</h5>
<ul>
<li>군집화의 기준</li>
</ul>
<p>동일한 군집에 속하는 개체 (또는 개인) 은 여러 속성이 비슷하고, 서로 다른 군집에 속한 관찰치는 그렇지 않도록 (여러 속성이 비슷하지 않도록) 군집을 구성</p>
<ul>
<li>군집화를 위한 변수: 전체 개체 (개인) 의 속성을 판단하기 위한 기준
<ul>
<li>인구통계적 변인 (성별, 나이, 거주지, 직업, 소득, 교육 등)</li>
<li>구매패턴 변인 (상품, 주기, 거래액 등)</li>
</ul></li>
</ul>
<p>군집분석에서는 관측값들이 서로 얼마나 유사한지, 또는 유사하지 않은지를 측정할 수 있는 측도가 필요하다.
- 군집분석에서는 보통 유사성(similarity)보다는 비유사성(dissimilarity)를 기준으로 하며, 거리(distance)를 사용한다.</p>
<p><span class="math inline">\(x\)</span>가 연속형일 때 CA의 위력이 최고로 발휘됨. 유사성의 척도로 거리가 사용되는데, 카테고리컬 변수에는 거리 계산이 불가능하기 때문. 꼭꼭 카테고리컬 변수로 CA를 해야겠다면 지시변수로 대체하여 CA를 시도할 수는 있겠으나, 이는 어느정도 억지로 하는 것이고 오점없는 CA는 아님.</p>
<hr />
</div>
<div id="distance-measures" class="section level5" number="5.9.1.0.2">
<h5 number="5.9.1.0.2"><span class="header-section-number">5.9.1.0.2</span> Distance Measures</h5>
<p>거리 (Distance) 라는 함수. CA에서 사용되는 모든 거리는 pairwise 거리.</p>
<ol style="list-style-type: decimal">
<li>Euclid 거리 (Euclidean) : 가장 메이저함</li>
</ol>
<p>p차원 공간에서 주어진 두 점 <span class="math inline">\(\pmb x=(x_1 , \cdots, x_p), \; \; \pmb y=(y_1 , \cdots, y_p)\)</span> 사이의 유클리드 거리는</p>
<p>$
d(x, y) = 
$</p>
<p>if <span class="math inline">\(p=2\)</span>,</p>
<p><img src = "12-2.png"></p>
<p><br>
<br></p>
<p>{:start=“2”}</p>
<ol start="2" style="list-style-type: decimal">
<li>Minkowski 거리</li>
</ol>
<p>$
d(x, y) = { {_{i=1}^p (x_i - y_i)^m} }^{}
$</p>
<p><span class="math inline">\(m=2\)</span>일 때 이는 Euclidean과 같아진다. 보통은 m의 값으로 짝수를 많이 씀. 민코프는 결국 Euclidean의 일반화.</p>
<p><br>
<br></p>
<p>{:start=“3”}</p>
<ol start="3" style="list-style-type: decimal">
<li>Mahalanobis 거리</li>
</ol>
<p><img src = "12-3.png"></p>
<p>위에서 A와 B의 거리만을 보는 것이 아니라 위의 점들의 군집의 패턴 또한 고려함. x축과 y축에 해당하는 변수들 사이에 correlation이 있다는 것을 반영함. 중앙의 <span class="math inline">\(S^{-1}\)</span>으로 corr 구조를 반영하는 것. <strong>뭔 메커니즘으로?</strong> 위 케이스를 생각하면 A는 전체적인 패턴의 연장선 상에서 멀리 있는데, B는 패턴에서 직교해서 벗어나면서 가까이 있음. 따라서 A보다 B가 멀다고 평가 가능.</p>
<p>$
d(x, y) = 
$</p>
<p>{:start=“4”}</p>
<ol start="4" style="list-style-type: decimal">
<li>Manhattan 거리</li>
</ol>
<p>$
d_{Manhattan} (x, y) = {_{i=1}^p x_i - y_i }
$</p>
<hr />
<ul>
<li>Standardization</li>
</ul>
<p>CA는 자료 사이의 거리를 이용하여 수행되기 때문에, 각 자료의 단위가 결과에 큰 영향을 미친다. 이러한 문제를 해결하기 위하여, 가장 널리 쓰이는 방법이 <strong>표준화 방법</strong>이다. 표준화 방법이란 각 변수의 관찰값으로부터 그 변수의 평균을 빼고, 그 변수의 표준편차로 나누는 것이다. 표준화된 모든 변수가 평균이 0이고 표준편차가 1이 된다. <strong>사실상 필수</strong>.</p>
<p><br></p>
<ul>
<li>Graphical Tools
<ul>
<li>Scatter Plot</li>
<li>Scatter Plot using PCA</li>
<li>Andrews Plot</li>
<li>Star Plot</li>
<li>Chernoff Faces</li>
</ul></li>
</ul>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="hierarchical-clustering" class="section level3" number="5.9.2">
<h3 number="5.9.2"><span class="header-section-number">5.9.2</span> Hierarchical Clustering</h3>
<ol style="list-style-type: decimal">
<li><p>Start with <span class="math inline">\(N\)</span> clusters, each containing a single entity and an <span class="math inline">\(N \times N\)</span> symmetric matrix of distances, <span class="math inline">\(D=\{d_{ik}\}\)</span>.</p></li>
<li><p>Search the distance Matrix <span class="math inline">\(D\)</span> for the nearest pair of clusters. Let the distance b/w the most similar (가장 거리가 작은) clusters <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> be <span class="math inline">\(d_{UV}\)</span>.</p></li>
<li><p>Mearge clusters <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>. Label the newly formed cluster <span class="math inline">\((UV)\)</span>. Update the entries in the distance Matrix <span class="math inline">\(D\)</span> by squences below. The distance b/w <span class="math inline">\((UV)\)</span> and other cluster <span class="math inline">\(W\)</span> is denoted by <span class="math inline">\(d_{(UV)W}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>deleting rows and columns corresponding to clusters <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>, then</li>
<li>adding a row and a column giving the distance b/w <span class="math inline">\((UV)\)</span> and the remaining clusters.</li>
</ol></li>
<li><p>repeat steps 2 and 3 a total of <span class="math inline">\(N-1\)</span> times. Then, all observations will be in single clusters. Record the identity of clusters that are merged and the levels at which the mergers take place.</p></li>
</ol>
<hr />
<div id="계층적-군집분석-example" class="section level5" number="5.9.2.0.1">
<h5 number="5.9.2.0.1"><span class="header-section-number">5.9.2.0.1</span> 계층적 군집분석 Example</h5>
<p>distance Matrix <span class="math inline">\(D\)</span>는 <span class="math inline">\(n^2\)</span>에 의존하여 변수 숫자가 증가하면 연산 시간도 기하급수적으로 증가.</p>
<p>{:start=“5”}
5. 계층적 분석에서만 덴드로그램을 그릴 수 있음. a graphical tool to illustrate the merges or divisions.</p>
<p><img src = "12-4-3.png"></p>
<p>python 라이브러리 함수 기준 총 distance의 70%에서 짤라서 clutser를 판정. color_threshold.</p>
<hr />
</div>
<div id="hca의-종류" class="section level5" number="5.9.2.0.2">
<h5 number="5.9.2.0.2"><span class="header-section-number">5.9.2.0.2</span> HCA의 종류</h5>
<ol style="list-style-type: decimal">
<li>Single Linkage, 단일 연결 (mimum distance, or nearest neighbor)</li>
</ol>
<p>$
d_{(UV)W} = ( d_{UW}, d_{VW} )
$</p>
<p>{:start=“2”}
2. Complete Linkage, 완전 연결 (maximum distance, or farthest neighbor)</p>
<p>$
d_{(UV)W} = ( d_{UW}, d_{VW} )
$</p>
<p>{:start=“3”}
3. <strong>Average Linkage, 평균 연결</strong> (average distance)
- 위의 둘이 변동이 너무 심해서 이를 해결하기 위해 제시됨</p>
<p>$
d_{(UV)W} =  ( <em>{i=1}^{n</em>{UV}} <em>{j=1}^{n</em>{W}} d_{ij} )
$</p>
<p><img src = "12-4.png"></p>
<p>{:start=“4”}
4. <strong>Centriod Method, 중심점 연결</strong> (For each cluster, compute the centroid)</p>
<p>$
d_{(UV)W} =  U  V
$</p>
<p><img src = "12-4-2.png"></p>
<p>{:start=“5”}
5. <strong><del>Ward’s Method</del></strong></p>
<p>bold들이 무난함</p>
<hr />
</div>
<div id="hca의-장단점" class="section level5" number="5.9.2.0.3">
<h5 number="5.9.2.0.3"><span class="header-section-number">5.9.2.0.3</span> HCA의 장단점</h5>
<p>Advantage:
- cluster의 수를 알 필요가 없음
- 덴드로그램 통해 군집화 프로세스와 결과물을 표현 가능</p>
<p>Disadvantage:
- 계산속도가 느림
- 아웃라이어 (이상치) 가 존재할 경우, 초기 단계에 잘못 분류된 군집은 분석이 끝날때까지 소속 cluster가 변하지 않음
- 아웃라이어에 대한 사전검토 필요, Centroid 방법이 아웃라이어에 덜 민감함</p>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="k-means-clustering" class="section level3" number="5.9.3">
<h3 number="5.9.3"><span class="header-section-number">5.9.3</span> K-means Clustering</h3>
<p>K-평균 군집분석법. 사전에 결정된 군집수 <span class="math inline">\(k\)</span>에 기초하여 전체 데이터를 상대적으로 유사한 k개의 군집으로 구분한다.</p>
<p>Proceeds:
1. 군집수 k를 결정한다
2. 초기 k개 군집의 중심을 선택한다 (랜덤하게)
3. 각 관찰치를 그 중심과 가장 가까운 거리에 있는 군집에 할당한다.
4. 형성된 군집의 중심 (centroid) 을 계산한다.
5. 3-4의 과정을 기존의 중심과 새로운 중심의 차이가 없을 때까지 반복한다.</p>
<p><img src = "12-5.png">
<img src = "12-6.png"></p>
<div id="determination-of-k" class="section level5" number="5.9.3.0.1">
<h5 number="5.9.3.0.1"><span class="header-section-number">5.9.3.0.1</span> Determination of K</h5>
<p>KCA의 결과는 초기 군집수 k의 결정에 민감하게 반응한다.</p>
<ol style="list-style-type: decimal">
<li>여러가지의 k값을 선택하여 CA를 수행한 후 가장 좋다고 생각되는 k값을 이용.
<ul>
<li>Elbow point 계산하여 k 선택</li>
<li>Silhouette plot으로 k 선택</li>
</ul></li>
<li>자료의 시각화를 통하여 K를 결정 (ex. star plot을 2차원 df로 바꾸어 평균 체크했었음)
<ul>
<li>자료의 시각화를 위해서는 차원축소가 필수적이고, 이를 위하여 PCA가 널리 사용된다.</li>
</ul></li>
<li>대용량 데이터에서 sampling한 데이터 (이것이 스몰데이터가 됨) 로 HCA를 우선 수행하여 (여기서 덴드로그램이 얻어짐) k의 값을 선택 (즉 HCA와 KCA를 둘 다 쓰므로 hybrid)</li>
</ol>
<p><img src="12-elbowplot.png"></p>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="군집의-평가방법" class="section level3" number="5.9.4">
<h3 number="5.9.4"><span class="header-section-number">5.9.4</span> 군집의 평가방법</h3>
<ul>
<li>Silhouette Score (Silhouette Plot)</li>
</ul>
$
s(i) =  =
<span class="math display">\[\begin{cases} 1-\dfrac{a(i)}{b(i)}, &amp; if \; \; a(i) &lt; b(i) \\ 0, &amp; if \; \; a(i) = b(i) \\ \dfrac{b(i)}{a(i)} - 1, &amp; if \; \; a(i) &gt; b(i) \end{cases}\]</span>
<p>$</p>
<ul>
<li><span class="math inline">\(a(i)\)</span>: 개체 <span class="math inline">\(i\)</span>로부터 <strong>같은</strong> 군집 내에 있는 <strong>모든 다른</strong> 개체들 사이의 평균 거리. <strong>작을수록 좋다.</strong> 작을수록 해당하는 군집 안에서 중앙 부분에 components가 모여 있다는 소리이므로.</li>
<li><span class="math inline">\(b(i)\)</span>: 개체 <span class="math inline">\(i\)</span>로부터 <strong>다른</strong> 군집 내에 있는 개체들 사이의 평균 거리 <strong>중 가장 작은 값</strong>. <strong>클수록 좋다.</strong> 클수록 다른 군집에 헷갈려서 속할 일 없이 확실하게 현재 소속되어 있는 군집에 소속되어 구분된다는 소리이므로.</li>
</ul>
<p>1을 넘어갈 수 없으며, 1에 가까울수록 군집화가 잘 된 관찰값. 몇개의 cluster가 설정되었을 때 가장 해당 stat이 높게 나오는지를 통해 판정하는 것이 이 접근법. 평균 Silhouette Score는 모든 obs마다 <span class="math inline">\(s(i)\)</span>를 구하여 이를 평균낸 값이므로, 평균 Silhouette Score가 1에 가까울수록 군집분석이 잘됐다고 판단 가능.</p>
<p><img src="12-SilhouettePlot.png"></p>
<hr />
<p><br>
<br>
<br></p>
</div>
<div id="clustering-using-density-estimation-wk14" class="section level3" number="5.9.5">
<h3 number="5.9.5"><span class="header-section-number">5.9.5</span> Clustering using Density Estimation (wk14)</h3>
<p>Based on <strong>nonparametric</strong> density estimation
The clusters may be viewed as high-density regions in the space separated by low-density regions between them.
No need to specify the number of clusters. It is determined by the method itself.</p>
<p>밀도기반 추정에 요구되는 (hyper) Parameter: bandwidth. 해당 값이 달라지면 결과도 달라짐.
Iris 데이터 예</p>
<div id="kernel-density-estimation-kde" class="section level5" number="5.9.5.0.1">
<h5 number="5.9.5.0.1"><span class="header-section-number">5.9.5.0.1</span> Kernel Density Estimation (KDE)</h5>
<p>$
f(x_0) =  _{i=1}^N K (  ) , ; ; ; ; ; x R
$</p>
<p>N은 샘플사이즈, 람다는 밴드위스, K는 스무딩 커널, x_i는 obs</p>
<p>closed form처럼 보이지만 그냥 상징적인 공식일 뿐. closed form이 있는게 아니라 데이터 포인트마다 고유한 값이 추정되는 것으로 진행됨.</p>
<p>밀도추정에서 가장 많이 쓰는 방법. 추정하고 싶은 포인트는 <span class="math inline">\(x_0\)</span>. <span class="math inline">\(x_0\)</span>라는 포인트에 대해 density를 추정하고 싶다. <span class="math inline">\(x_0\)</span> 인근의 관찰치는 더 많은 가중치를 가짐. <span class="math inline">\(x_0\)</span> 로 부터 멀어질수록 가중치는 감소함. 각 obs 별로 커널함수 부여하고 최종적으로 그 커널함수 다 더한 다음에 스케일링하면 끝.</p>
<p>K의 가장 흔한 선택은 정규분포함수, 즉 Gaussian Kernel</p>
<p>Bandwidth 의 효과: 커널함수의 좌우 넓이에 해당하는 것으로서, 가우시안 커널에서는 표준편차에 해당함. Bandwith가 크면 x값들 간에 차별화가 덜되어서 추정 위력이 떨어짐</p>
<p>봉우리의 갯수는 군집의 갯수로 생각할 수 있음. 지나치게 밴드위스가 좁으면 뾰족한 부분이 다수 튀어나와 군집의 과다추정 발생</p>
<p>그래프는 1차원 밀도 추정에 해당
회색: 정답. 표준정규분포
붉은색: undersmoothed, 𝜆𝜆 = 0.05 (too small)
녹색: oversmoothed, 𝜆𝜆 =
2 (too large)
검정색: optimally smoothed, 𝜆𝜆 = 0.337</p>
<p>Bandwidth 추정</p>
<ul>
<li>2D Kernel Density Estimation: 2차원에서의 KDE는 어떻게 확장될 것인가?</li>
</ul>
<hr />
<p><br>
<br>
<br></p>
</div>
</div>
<div id="multidimensional-scaling-mds" class="section level3" number="5.9.6">
<h3 number="5.9.6"><span class="header-section-number">5.9.6</span> Multidimensional Scaling (MDS)</h3>
<p>Dimension Reduction Methods
- PCA : x변수들끼리의 분산을 최대화시키는 방향으로 차원축소. 한 변수의 분산이 최대화되어야 함
- Factor: 변수간의 correlation을 최대한 깨트리지 않고 반영하는 방향으로 DR. Corr 구조가 최대한 유지
- MDS
- Canonical Discriminant Analysis</p>
<p>이중 위의 둘은 original data의 Variance 설명에 집중함. (ex. 1명이 401호, 1명이 501호에 있다고 하면, 둘의 직선 거리가 그렇게 크게 떨어져있다고 하기는 어렵지만 위의 두 분석법은 멀리 떨어져 있는 것처럼 그래프에 표현될 수 있음. 거리 개념이 없기 땨문)</p>
<ul>
<li>MDS
<ul>
<li>Fit (projection) the original data into a low-dimensional coordinate system such that any distortion caused by a reduction in dimensionality is minimized.</li>
<li><strong>Map the distances</strong> between points in a high dimensional space into a lower dimensional space.</li>
</ul></li>
<li>distortion이란? dissimilarity (distance) among the original data points
<ul>
<li>For a given set of observed similarities (or distances) between every pair of N items, find a representative of the items in as few dimensions as possible such that the similarities (or distances) in the lower dimensions match, as close as possible with the original similarities (or distances).</li>
</ul></li>
<li><ol style="list-style-type: decimal">
<li>Nonmetric MDS</li>
</ol>
<ul>
<li>Only the rank orders of the N(N-1)/2 original similarities are used to arrange N items in a lower-dimensional coordinate system. 거리 없이 rank만 주어져있음. rank만 안무너지도록</li>
</ul></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Metric MDS (자주씀. Principal Coordinate Analysis)</li>
</ol>
<ul>
<li>The actual magnitudes of the original similarities are used to obtain a geometric representation.</li>
</ul></li>
</ul>
<div id="kruskals-stress" class="section level5" number="5.9.6.0.1">
<h5 number="5.9.6.0.1"><span class="header-section-number">5.9.6.0.1</span> <strong>Kruskal’s Stress</strong></h5>
<p>so-called <strong>Badness of fit</strong> criterion. MDS가 잘됐다면 기존 오리지널 차원의 거리나 차원축소된 이후의 거리나 비슷해야 함. 크루스칼 스트레스가 작으면 왜곡도 작은 것. 스트레스가 최소인 DR이 최고의 DR.</p>
<ul>
<li><p>Let <span class="math inline">\(D_{rs}\)</span> denote the actual distance (or dissimilarity) between item r and item s, then the ordered distances are $D_{r_1 s_1 } &lt;D_{r_2 s_2 } &lt; &lt; D_{r_M s_M }, ; ; ; M=</p>
<span class="math display">\[\begin{pmatrix} N \\ 2 \end{pmatrix}\]</span>
<p>$.</p></li>
<li><p>Let <span class="math inline">\(d_{rs}\)</span> denote the distance between item r and item s in the lower dimensional space.</p></li>
<li><p>MDS seeks (iteratively) to find a set of <span class="math inline">\(d\)</span>’s such that <span class="math inline">\(d_{r_1 s_1 } &lt;d_{r_2 s_2 } &lt; \cdots &lt; d_{r_M s_M }\)</span> and <span class="math inline">\(Stress = \left\{ \dfrac{\sum_{i=1}^N \sum_{j=1}^{i-1}(D_{ij} - d_{ij})^2} {\sum_{i=1}^N \sum_{j=1}^{i-1} \left( D_{ij} \right)^2} \right\}^{\tfrac{1}{2}}\)</span> is minimized.</p></li>
<li><p>Interpretation Guideline</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">Stress</th>
<th align="center">Goodness of Fit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">20%</td>
<td align="center">Poor</td>
</tr>
<tr class="even">
<td align="center">10%</td>
<td align="center">Fair</td>
</tr>
<tr class="odd">
<td align="center"><strong>5%</strong></td>
<td align="center"><strong>Good</strong></td>
</tr>
<tr class="even">
<td align="center">2.5%</td>
<td align="center">Excellent</td>
</tr>
<tr class="odd">
<td align="center">0%</td>
<td align="center">Perfect</td>
</tr>
</tbody>
</table>
<ul>
<li>Goodness of fit = monotonic relationship between the similarities and the final distances.</li>
</ul>
<p><strong>Takane’s Stress</strong></p>
<p>$</p>
<p>Stress = {  {<em>{i=1}^N </em>{j=1}<sup>{i-1}(D_{ij}</sup>2)^2} }^{}</p>
<p>$</p>
<p>Algorithm:
1. For N items, obtain <span class="math inline">\(M=\dfrac{N(N-1)}{2}\)</span> 개의 distances <span class="math inline">\(D_{r_1 s_1 }, D_{r_2 s_2 } , \cdots , D_{r_M s_M }\)</span>. Tehn an <span class="math inline">\(N \times N\)</span> matrix <span class="math inline">\(D = \{D_{ij} \}\)</span> is constructed.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Using a trial configuration in q dimensions, determine distances <span class="math inline">\(d_{ij}^{(q)}\)</span>. The method to get initial <span class="math inline">\(d_{ij}^{(q)}\)</span> is given later.</p></li>
<li><p>Using the <span class="math inline">\(d_{ij}^{(q)}\)</span>, move the points around to obtain an improved configurations. <br> A new configuration: new <span class="math inline">\(d_{ij}^{(q)}\)</span> and smaller stress (e.g. Newton-Raphson method) The process is repeated until the best (minimum stress) representation is obtained.</p></li>
<li><p>Plot minimum stress (q) versus q and choose the best number of dimensions, <span class="math inline">\(q^\ast\)</span> from an examination of this plot. x축은 축소된 차원, y축은 stress. 차원이 작아질수록 Stress는 높고, 차원이 p라면 (original 차원과 같다면) Stress는 0. PCA와 달리 여기서는 <strong>elbow에서 멈춤</strong>.</p>
<ul>
<li>similar to scree plot</li>
</ul></li>
</ol>
<p>Note:
1. The larger the dimension, the better the fit.
2. Higher dimension means harder to visualize.</p>
</div>
<div id="algorithm-to-find-초기값-d_ijq" class="section level5" number="5.9.6.0.2">
<h5 number="5.9.6.0.2"><span class="header-section-number">5.9.6.0.2</span> Algorithm to find 초기값 <span class="math inline">\(d_{ij}^{(q)}\)</span></h5>
<p>q값을 줄이려면 수치해석을 시작하기 전에 넣어줄 초기값에 해당하는 초기좌표들이 필요함. 그 값을 구하는 방법.</p>
<ol style="list-style-type: decimal">
<li><p>Construct the <span class="math inline">\(N \times N\)</span> matrix <span class="math inline">\(A = \{ a_{ij} \} = \left\{ -\dfrac{1}{2} D_{ij}^2 \right\}\)</span>.</p></li>
<li><p>Construct the <span class="math inline">\(N \times N\)</span> matrix <span class="math inline">\(B = \left(I - \dfrac{1}{N} J \right) A \left(I - \dfrac{1}{N} J \right) = \{ b_{ij} \} = \{ \bar a_{ij} - \bar a_{i.} - \bar a_{.j} + \bar a_{..} \}\)</span>.</p></li>
</ol>
where
$
a_{..} = ^N ^N , ; ; ; ; ; J =
<span class="math display">\[\begin{bmatrix} 1 &amp; \cdots &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; \cdots &amp; 1 \end{bmatrix}\]</span>
<p>$</p>
<p>{:start=“3”}</p>
<p>D행렬은 distance들의 SSE 행렬 정도에 해당.</p>
<ol start="3" style="list-style-type: decimal">
<li>Since <span class="math inline">\(B\)</span> is a symmetric matrix, use the <strong>spectral decomposition</strong> to write <span class="math inline">\(B\)</span> in the <span class="math inline">\(B = V \Lambda V&#39;\)</span>. <br> If B is positive semidefinite of rank <strong>q</strong> (p차원 아님!! <span class="math inline">\(q \le p\)</span>. 거리행렬이 일정 ev까지는 유의할 수 있는데 그 후로는 0만 튀어나올 수 있으며 DR은 바로 이상황에서 일어남. p는 위에서 보였던 유사 scree plot에서 original data의 차원으로 지정되었던 숫자) , there are q positive eigenvalues.</li>
</ol>
<p>if</p>
<p>$</p>
_1 =
<span class="math display">\[\begin{bmatrix} \lambda_1 &amp; \cdots &amp; \pmb 0 \\ &amp; \ddots &amp; \\ \pmb 0 &amp; \cdots &amp; \lambda_q \end{bmatrix}\]</span>
_{q q}, ; ; ; ; ; V_1 =
<span class="math display">\[\begin{bmatrix} \pmb v_1 ,  \pmb v_2 ,  \cdots, \pmb v_q \end{bmatrix}\]</span>
<p>_{N q}</p>
<p>$</p>
<p>then we can express</p>
<p>$</p>
<p>B = { V_1 }<em>{N q} { <em>1 }</em>{q q} { V_1 ’ }</em>{q N}</p>
<p>= V_1 _1^{1/2} _1^{1/2} V_1 ’ = ZZ’</p>
<p>$</p>
<p>where</p>
<p>$</p>
<p>Z = V_1 _1^{1/2}</p>
=
<span class="math display">\[\begin{bmatrix} \sqrt{\lambda_1} \pmb v_1 , \sqrt{\lambda_2} \pmb v_2 , \cdots, \sqrt{\lambda_q} \pmb v_q \end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix} \pmb z_1 &#39; \\ \pmb z_2 &#39; \\ \vdots \\ \pmb z_q &#39; \end{bmatrix}\]</span>
<p>_{N q}</p>
<p>$</p>
<p>{:start=“4”}</p>
<ol start="4" style="list-style-type: decimal">
<li><p>The rows $z_1 ’ , z_2 ’ , , z_q $ of <span class="math inline">\(Z\)</span> are the points whose interpoint distance <span class="math inline">\(d_{ij}^{(q)} = (\pmb z_i - \pmb z_j)&#39;(\pmb z_i - \pmb z_j)\)</span> match $D_{ij} $s in the original distance matrix <span class="math inline">\(D\)</span>.</p></li>
<li><p>Since <span class="math inline">\(q\)</span> will typically be too large to be of practical interest and we would prefer a smaller dimension <span class="math inline">\(k\)</span> for plotting, we can use the first <span class="math inline">\(k\)</span> eigenvalues and corresponding eigenvectors to obtain <span class="math inline">\(N\)</span> points whose distances <span class="math inline">\(d_{ij}^{(k)}\)</span> are approximately equal to the corresponding <span class="math inline">\(D_{ij}\)</span>. 오리지널 데이터의 차원 p가 15개였다면, 이 차원을 SVD했을 때 ev 중 5개가 0이어서 q는 15개로 하였다. 여기서 차원을 더 줄이고 싶다면, 가령 k=5개까지 임의로 내려버리고 싶다면, 뒤쪽의 ev 10개에 해당하는 걸 쳐내는 것</p></li>
</ol>
<p>Rank is clearly rank 2. 즉 차원을 2차원까지 줄여도 손실되는 정보가 전혀 없다. 따라서 orginal data Distance Matrix에서 보였던 특성이 그대로 똑같이 드러난다.</p>
<!--chapter:end:211312_ClusterAnalysis.Rmd-->
</div>
</div>
</div>
</div>
<div id="linear" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Linear</h1>
<div id="svd" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> SVD</h2>
<div id="spectral-decomposition-1" class="section level3" number="6.1.1">
<h3 number="6.1.1"><span class="header-section-number">6.1.1</span> Spectral Decomposition</h3>
<p>$
<span class="math display">\[\begin{align}


A = 

\begin{pmatrix} 

a_{11} &amp; &amp; \cdots  &amp;  &amp; a_{1n} \\
\vdots &amp; \ddots &amp;   &amp;  &amp; \vdots \\
a_{i1} &amp; &amp;  \ddots &amp;  &amp; a_{1n} \\
\vdots &amp; &amp;  &amp; \ddots &amp; \vdots \\
a_{m1} &amp; &amp; \cdots  &amp;  &amp; a_{mn}

\end{pmatrix} 

= (a_{ij})









&amp;\; \; \; \; \; \; \;= 

\begin{pmatrix}

\pmb r_1 \\
\vdots \\
\pmb r_m

\end{pmatrix}



\\\

\\\



&amp;\; \; \; \; \; \; \;= 
\begin{pmatrix}

\pmb c_1 &amp;
\cdots &amp;
\pmb c_m

\end{pmatrix}




\end{align}\]</span>
$</p>
<p>for symmetric matrix <span class="math inline">\(A\)</span>:</p>
<p>$</p>
<p>A_{p p} = ^{T} = _{j=1}^p _j _j _j^T</p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

&amp;\Lambda = diag \{\lambda_1 , \cdots, \lambda_p \} &amp;&amp;\; \; \; \; \;=

\begin{pmatrix}

\lambda_1 &amp; \cdots &amp; 0\\
\vdots &amp; \ddots &amp; \vdots\\
0 &amp; \cdots &amp; \lambda_p



\end{pmatrix}

_{p \times p}


\\

&amp;\Gamma &amp;&amp;\; \; \; \; \;= 

\begin{pmatrix}

\pmb\gamma_1 ,&amp; \cdots, &amp;\pmb\gamma_p

\end{pmatrix}_{p \times p}


\end{alignat}\]</span></p>
<p>$</p>
<p>where <span class="math inline">\(\pmb \gamma_j\)</span> is evec of <span class="math inline">\(A\)</span>. Therefore <span class="math inline">\(\Gamma\)</span> is orthogonal Matrix.</p>
<p>let symmetric Matrix of rank <span class="math inline">\(r\)</span>, <span class="math inline">\(A_{p \times p}\)</span>, <span class="math inline">\((r \le p)\)</span>. Then there exists orthogonal Matrix <span class="math inline">\(\Gamma_{p \times p}\)</span>, which means <span class="math inline">\(\Gamma^T \Gamma = I_p\)</span> and</p>
<p>$
A = ^T = </p>
<span class="math display">\[\begin{pmatrix}

\Lambda_1 &amp; 0 \\
0 &amp; 0

\end{pmatrix}\]</span>
<p>^T =</p>
<p>_1 _1 ^T_1
$</p>
<p>where letting <span class="math inline">\(\delta_i=\)</span> i-th ev, <span class="math inline">\(i=1, \cdots, r\)</span>, then</p>
<p>$</p>
<p>\<br />
\<br />
</p>
=
<span class="math display">\[\begin{pmatrix} \{\Gamma_1\}_{p \times r} , \; \; \; \{\Gamma_0\}_{p \times (p-r)} \end{pmatrix}\]</span>
<p>\<br />
\<br />
</p>
<p>= diag {_1 , , _r } =</p>
<span class="math display">\[\begin{pmatrix}

\lambda_1 &amp; \cdots &amp; 0\\
\vdots &amp; \ddots &amp; \vdots\\
0 &amp; \cdots &amp; \lambda_r



\end{pmatrix}\]</span>
<p>_{r r}</p>
<p>$</p>
<p>then <span class="math inline">\(\Gamma_1^T \Gamma_1 = I_r, \; \; \; \; \Gamma_1^T \Gamma_0 = 0\)</span> and</p>
<p>$</p>
<p>A^2 = A’A = AA’ =</p>
<p>(_1 _1 ^T_1)’ _1 _1 ^T_1 = _1 _1 ^T_1 _1 _1 ^T_1</p>
<p>= _1 _1^2 ^T_1</p>
<p>$</p>
<p>let <span class="math inline">\(\{\pmb \gamma_i\}_{p \times 1}\)</span> be i-th column vector of <span class="math inline">\(\Gamma\)</span>. then</p>
$
_i’ _i =
<span class="math display">\[\begin{cases} 1 &amp; &amp; i=j \\ 0 &amp; &amp; i \not = j \end{cases}\]</span>
<p>$</p>
<p>thus</p>
<p>$
<span class="math display">\[\begin{alignat}{2}

A &amp;= \Gamma_1 \Lambda_1 \Gamma^T_1 

&amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \gamma_i &#39;


\\

A&#39;A &amp;= \Gamma_1 \Lambda_1^2 \Gamma^T_1

&amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i &#39;

\\

AA&#39;&amp;= 

&amp;&amp;

\\

\gamma_k &#39; A 

&amp;=  \lambda_k \gamma_k &#39; \gamma_k \gamma_k &#39;  

&amp;&amp;= \lambda_k \pmb\gamma_k &#39; 



\\

A \gamma_k 

&amp;=  \lambda_k \gamma_k \gamma_k &#39; \gamma_k  

&amp;&amp;= \lambda_k \pmb \gamma_k 


\end{alignat}\]</span></p>
<p>$</p>
<p><br /><br />
<br /><br />
<br /></p>
<div id="remark-1" class="section level5" number="6.1.1.0.1">
<h5 number="6.1.1.0.1"><span class="header-section-number">6.1.1.0.1</span> remark</h5>
<p>let orthogonal Matrix <span class="math inline">\(\Gamma\)</span>, therefore <span class="math inline">\(\Gamma &#39; \Gamma = I\)</span>, and <span class="math inline">\(\det(\Gamma) = \vert \Gamma \vert = 1\)</span>.</p>
<p>let symmetric Matrix <span class="math inline">\(A_{p \times p}\)</span> with full rank. then by SVD,</p>
<p>$</p>
<p>(A) = A = ^T = =</p>
<span class="math display">\[\begin{vmatrix}
\lambda &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \lambda_p

\end{vmatrix}\]</span>
<p>= _{i=1}^p _i</p>
<p>$</p>
<p>let symmetric Matrix <span class="math inline">\(A_{p \times p}\)</span> with full rank. then by SVD,</p>
<p>$</p>
<p>n: ; ; ;</p>
<p>A^n = (‘) (’)(‘) = ^n ’
$</p>
<p>in particular, a Cov Matrix <span class="math inline">\(\Sigma\)</span> can be written by</p>
<p>$
= ^T = _{i=1}^r _i _i _i’</p>
<p>\</p>
<p>^{-1} = ^{-1} ^T = _{i=1}^r _i^{-1} _i _i’</p>
<p>\</p>
<p>^{-} = ^{-} ^T = _{i=1}^r _i^{-} _i _i’</p>
<p>$</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
</div>
<div id="singular-value-decomposition-general-version" class="section level3" number="6.1.2">
<h3 number="6.1.2"><span class="header-section-number">6.1.2</span> Singular value Decomposition: General-version</h3>
<p>decomposition of any aribtrary Matrix with rank <span class="math inline">\(r\)</span>, <span class="math inline">\(A_{n \times p} = \Gamma_{n \times r} \Lambda \triangle_{p \times r} &#39; = \sum_{j=1}^r \lambda_j \pmb \gamma_j \pmb \delta_j &#39;\)</span>.</p>
<p><span class="math inline">\(\Lambda = diag(\lambda_1 , \cdots, \lambda_r), \; \; \; \; \lambda_j &gt;0\)</span>. 이때 <span class="math inline">\(\lambda_i\)</span>는 <span class="math inline">\(AA&#39;\)</span>나 <span class="math inline">\(A&#39;A\)</span>의 non-zero ev.</p>
<p><span class="math inline">\(\Gamma, \triangle\)</span>는 <span class="math inline">\(AA&#39;\)</span>와 <span class="math inline">\(A&#39;A\)</span>의 corresponding <span class="math inline">\(r\)</span> evec으로 구성. 따라서 Both $’ = ’ = I_r $, i.e., are column orthogonal.</p>
<p>thus</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}




A &amp;= \Gamma \Lambda \triangle^T 

&amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i &#39;


\\

A&#39;A &amp;= \triangle \Lambda^2 \triangle^T

&amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \delta_i \pmb \delta_i &#39;

\\

AA&#39;&amp;= \Gamma \Lambda^2 \Gamma^T

&amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i &#39;


\\

\gamma_k &#39; A 

&amp;=  \gamma_k &#39; \Gamma \Lambda \triangle^T 

&amp;&amp;= \lambda_k \pmb \delta_k &#39;





\\

A \delta_k 

&amp;=  \Gamma \Lambda \triangle^T  \delta_k  

&amp;&amp;= \lambda_k \pmb \gamma_k 


\end{alignat}\]</span></p>
<p>$</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">a</th>
<th align="center">b</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\begin{alignat}{2} A &amp;= \Gamma \Lambda \triangle^T &amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i &#39; \\ A&#39;A &amp;= \triangle \Lambda^2 \triangle^T &amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \delta_i \pmb \delta_i &#39; \\ AA&#39;&amp;= \Gamma \Lambda^2 \Gamma^T &amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i &#39; \\ \gamma_k &#39; A &amp;= \gamma_k &#39; \Gamma \Lambda \triangle^T &amp;&amp;= \lambda_k \pmb \delta_k &#39; \\ A \delta_k &amp;= \Gamma \Lambda \triangle^T \delta_k &amp;&amp;= \lambda_k \pmb \gamma_k \end{alignat}\)</span></td>
<td align="center">$<span class="math display">\[\begin{alignat}{2} A &amp;= \Gamma_1 \Lambda_1 \Gamma^T_1 &amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \gamma_i &#39; \\ A&#39;A &amp;= \Gamma_1 \Lambda_1^2 \Gamma^T_1 &amp;&amp;=\sum_{i=1}^r \lambda_i^2 \pmb \gamma_i \pmb \gamma_i &#39; \\ AA&#39;&amp;=  &amp;&amp; \\ \gamma_k &#39; A &amp;=  \lambda_k \gamma_k &#39; \gamma_k \gamma_k &#39;  &amp;&amp;= \lambda_k \pmb\gamma_k &#39; \\ A \gamma_k &amp;=  \lambda_k \gamma_k \gamma_k &#39; \gamma_k  &amp;&amp;= \lambda_k \pmb \gamma_k \end{alignat}\]</span> $</td>
</tr>
<tr class="even">
<td align="center">c</td>
<td align="center">d</td>
</tr>
</tbody>
</table>
<p>therefore, generalized inverse matrix, G-inverse Matrix <span class="math inline">\(A^-\)</span> will be</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}




A &amp;= \Gamma \Lambda \triangle^T 

&amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i &#39;

\\


A^- &amp;= \triangle 

 \Lambda^{-1}  \Gamma&#39;

&amp;&amp;=\sum_{i=1}^r \lambda_i^{-1} \pmb \delta_i \pmb \gamma_i &#39;



\\

AA^- A &amp;= \Gamma \Lambda \triangle^T \ast \triangle \Lambda^{-1}  \Gamma&#39; \ast \Gamma \Lambda \triangle^T 

&amp;&amp;=\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i &#39; \; \; \; \; \;  \; \; \; \; \; = A




\end{alignat}\]</span></p>
<p>$</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
<div id="singular-value-decomposition-another-version" class="section level3" number="6.1.3">
<h3 number="6.1.3"><span class="header-section-number">6.1.3</span> Singular value Decomposition: Another-version</h3>
<p>rank <span class="math inline">\(r\)</span> arbitrary Matrix <span class="math inline">\(A_{n \times p} = \Gamma_{n \times r} \Lambda \triangle^T_{p \times r} =\sum_{i=1}^r \lambda_i^{\tfrac{1}{2}} \pmb \gamma_i \pmb \delta_i &#39;\)</span></p>
<p><span class="math inline">\(\Lambda = diag(\lambda_1^{\tfrac{1}{2}} , \cdots, \lambda_r^{\tfrac{1}{2}}), \; \; \; \; \; \lambda_j^{\tfrac{1}{2}} &gt;0\)</span>. 이때 <span class="math inline">\(\lambda_i\)</span>는 <span class="math inline">\(AA&#39;\)</span>와 <span class="math inline">\(A&#39;A\)</span>의 non-zero ev.</p>
<p><span class="math inline">\(\Gamma, \triangle\)</span>는 <span class="math inline">\(AA&#39;\)</span>와 <span class="math inline">\(A&#39;A\)</span>의 corresponding <span class="math inline">\(r\)</span> evec으로 구성. 따라서 Both $’ = ’ = I_r $, i.e., are column orthogonal.</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
<div id="quadratic-forms" class="section level3" number="6.1.4">
<h3 number="6.1.4"><span class="header-section-number">6.1.4</span> Quadratic Forms</h3>
<p>for symmetric Matrix <span class="math inline">\(A_{p \times p}\)</span>, vector <span class="math inline">\(\pmb x \in \mathbb{R}^p\)</span>:</p>
<p>$
Q(x) = x’ A x = <em>{i=1}^p </em>{j=1}^p a_{ij} x_i x_j 
$</p>
<p>$
<span class="math display">\[\begin{align}

\forall x \not = 0: Q(x) &amp;&gt; 0 \tag{positive definite} \\

\\



\forall x \not = 0: Q(x) &amp;\ge 0 \tag{positive semi-definite}



\end{align}\]</span>
$</p>
<p>if corresponding quadratic form <span class="math inline">\(Q(\cdot)\)</span> is positive definite(semi-definite), <span class="math inline">\(A\)</span> is called positive definite(semi-definite). This is written by <span class="math inline">\(A&gt;0 \; \; \; (\ge 0)\)</span>.</p>
<p><br /><br />
<br /><br />
<br /></p>
<div id="propositions" class="section level5" number="6.1.4.0.1">
<h5 number="6.1.4.0.1"><span class="header-section-number">6.1.4.0.1</span> propositions</h5>
<p>if <span class="math inline">\(A=A&#39;\)</span>, and <span class="math inline">\(Q(x) = \pmb x &#39; A \pmb x\)</span> is corresponding quadratic form, then $y = ^T x: ; ; ; Q(x) = x’ A x = _{i=1}^p _1 y_i^2 $, <span class="math inline">\(\lambda_i\)</span> is ev of <span class="math inline">\(A\)</span>.</p>
<p>$
A&gt;0 _i&gt;0, ; ; ; i=1, , p
$</p>
<p>$
A&gt;0 ; ; ; ; ; ; A &gt;0, ; A^{-1}
$</p>
<p><span class="math inline">\(A=A&#39;, \; B=B&#39;, \; B&gt;0\)</span>, then maximum of <span class="math inline">\(\dfrac{\pmb x &#39; A \pmb x}{\pmb x &#39; B \pmb x}\)</span> is given by the largest ev of <span class="math inline">\(B^{-1}A\)</span>.</p>
<p>the vector which maximizes(minimizes) <span class="math inline">\(\dfrac{\pmb x &#39; A \pmb x}{\pmb x &#39; B \pmb x}\)</span> is the corresponding evec of <span class="math inline">\(B^{-1}A\)</span> for largest(smallest) ev of <span class="math inline">\(B^{-1}A\)</span>.</p>
<p>more generally, for ev of <span class="math inline">\(B^{-1}A\)</span>, <span class="math inline">\(\lambda_1, \cdots, \lambda_p\)</span>,</p>
<p>$</p>
<p>(  )</p>
<p>= ; ; ; ; ;_1 _p ; ; ; ; ; =</p>
<p>(  )</p>
<p>$</p>
<p>if <span class="math inline">\({\pmb x &#39; B \pmb x}=1\)</span>, then</p>
<p>$</p>
<p>( {x ’ A x} )</p>
<p>= ; ; ; ; ;_1 _p ; ; ; ; ; =</p>
<p>( {x ’ A x} )</p>
<p>$</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
</div>
<div id="partitioned-matrices" class="section level3" number="6.1.5">
<h3 number="6.1.5"><span class="header-section-number">6.1.5</span> Partitioned Matrices</h3>
<p><span class="math inline">\(A_{n \times p}, B_{p \times n}\)</span> and <span class="math inline">\(n \ge p\)</span>. then</p>
<p>$</p>
<span class="math display">\[\begin{vmatrix} 

-\lambda I_n &amp; -A \\
B &amp; I_p 

\end{vmatrix}\]</span>
<p>= (-)^{n-p} BA - I_n = AB - I_n </p>
<p>$</p>
<p>for <span class="math inline">\(A_{n \times p}, B_{p \times n}\)</span>, the non-zero ev of <span class="math inline">\(AB\)</span> and <span class="math inline">\(BA\)</span> are the same and have the same multiplicity. if <span class="math inline">\(\pmb x\)</span> is evec of <span class="math inline">\(AB\)</span> for an ev <span class="math inline">\(\lambda \not = 0\)</span>, then <span class="math inline">\(y=B \pmb x\)</span> is an evec of <span class="math inline">\(BA\)</span>.</p>
<p>for <span class="math inline">\(A_{n \times p}, B_{q \times n}, \pmb a_{p \times 1}, \pmb b_{q \times 1}\)</span>, if <span class="math inline">\(rank \left( A \pmb a \pmb b B \right) \le 1\)</span>, then non-zero ev, if it exists, equals <span class="math inline">\(\pmb b&#39; BA \pmb a\)</span> with evec <span class="math inline">\(A \pmb a\)</span>.</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
<div id="geometrical-aspects" class="section level3" number="6.1.6">
<h3 number="6.1.6"><span class="header-section-number">6.1.6</span> Geometrical Aspects</h3>
<p>mutually orthogonal <span class="math inline">\(\pmb x_1 , \cdots, \pmb x_k \iff \forall {i,j}: \; \pmb x_i &#39; \pmb x_j\)</span></p>
<p>In that case, $X= ( x_1 , , x_k ) $ has rank <span class="math inline">\(k\)</span>, and <span class="math inline">\(X&#39;X\)</span> is a diagonal Matrix with <span class="math inline">\(x_i &#39; x_i\)</span> in the i-th diagonal position.</p>
<p>let’s consider bivariate data <span class="math inline">\((x_i , y_i), \; \; \; i= 1, \cdots, n\)</span>, and let <span class="math inline">\(\tilde x_i = x_i - \bar {\pmb x}, \; \tilde y_i = y_i - \bar {\pmb y}\)</span>. then correlation b/w <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is</p>
<p>$

{_{i=1}^n (x_i - {x})(y_i - {y})}
{}</p>
<p>=</p>
<p>{x ’ y}
{x y}</p>
<p>= ()</p>
<p>$</p>
<p>where <span class="math inline">\(\theta\)</span> is the angle b/w the deviation vectors <span class="math inline">\({\tilde x}\)</span> and <span class="math inline">\({\tilde y}\)</span>.</p>
<p>For two dimensions, the rotation can be expressed:</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\pmb y &amp;= \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}


&amp;&amp;=


\begin{pmatrix} 

\cos(\theta) &amp; \sin(\theta) \\

-\sin(\theta) &amp; \cos(\theta) 


\end{pmatrix}




\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}



&amp;&amp; = \Gamma 

\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

\\
 
&amp;= \Gamma \pmb x \tag{clockwise rotation}



\\\
\\\



\pmb y &amp;


&amp;&amp;=


\begin{pmatrix} 

\cos(\theta) &amp; -\sin(\theta) \\

\sin(\theta) &amp; \cos(\theta) 


\end{pmatrix}




\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

&amp;&amp;= \Gamma  &#39; 

\begin{pmatrix} 

x_1 \\ x_2 

\end{pmatrix}

\\

&amp; = \Gamma  &#39;  \pmb x \tag{counter-clockwise rotation}




\end{alignat}\]</span>
$</p>
<p><br /><br />
<br /><br />
<br /><br />
<br /><br />
<br /></p>
</div>
<div id="column-row-and-null-space" class="section level3" number="6.1.7">
<h3 number="6.1.7"><span class="header-section-number">6.1.7</span> Column, Row and Null Space</h3>
<p>Matrix <span class="math inline">\(X_{n \times p}\)</span>:</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\mathcal{C}(X)

&amp;=



\{ \pmb x \in \mathbb{R}^n  \; \vert \; \exists \pmb a \in \mathbb{R}^p \; \; s.t. \; \; X \pmb a = \pmb x\}  

&amp;&amp;\subseteq 
\mathbb{R}^n

\tag{column (range) space}

\\


\mathcal{N}(X)

&amp;=

\{ \pmb y \in \mathbb{R}^p  \; \vert \; X \pmb y = 0 \}  &amp;&amp;\subseteq \mathbb{R}^p

\tag{null space}


\\


\mathcal{R}(X)



&amp;= 

\{ \pmb z \in \mathbb{R}^p  \; \vert \; \exists \pmb b \in \mathbb{R}^n \; \; s.t. \; \; X&#39; \pmb b = \pmb z \}


&amp;&amp;\subseteq 
\mathbb{R}^p

\tag{row space}


\\

&amp;= \mathcal{C}(X&#39;)


\tag{column space of X`}


\end{alignat}\]</span></p>
<p>$</p>
<p>Spaces by Singular Value Decomposition: General-version,</p>
<p>Matrix <span class="math inline">\(X_{n \times p}\)</span> with <span class="math inline">\(rank(X)=r\)</span>:</p>
<p>$</p>
<p>\</p>
<p><span class="math display">\[\begin{alignat}{2}

X &amp;= \Gamma \Lambda \triangle^T 

\\

&amp; =\sum_{i=1}^r \lambda_i \pmb \gamma_i \pmb \delta_i &#39;

\\

\mathcal{C}(X)

&amp;= \{ \gamma_1 , \cdots, \gamma_r \}



\\



\mathcal{N}(X)

&amp;= \{ \delta_{r+1} , \cdots, \delta_{p} \}

\\


\mathcal{R}(X)

&amp;= \{ \delta_{1} , \cdots, \delta_{r} \}


\end{alignat}\]</span></p>
<p>$</p>
<ul>
<li>note: Matrix <span class="math inline">\(X_{n \times p}\)</span> with <span class="math inline">\(rank(X)=r\)</span></li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\mathcal{N}(X) &amp;= \mathcal{C}(X&#39;)^{\perp} = \mathcal{R}(X)^{\perp} \\

\mathcal{N}(X)^{\perp}

&amp;= \mathcal{C}(X&#39;)
= \mathcal{R}(X) \\

\\

\\

\mathcal{C}(X&#39;X) &amp;= \mathcal{C}(X&#39;) = \mathcal{R}(X) \\

\\

\\

\dim \left( \mathcal{C}(X) \right) &amp;= 
\dim \left( \mathcal{R}(X) \right) \\
= \; \; \; \; \; 
rank(X) &amp;= 
rank(X&#39;) = 
rank(X&#39;X) \\ &amp;= r \le \min(n, p)

\end{alignat}\]</span>
$</p>
<p><span class="math inline">\(X&#39;X\)</span> has full rank (is nonsingular) <span class="math inline">\(\iff\)</span> if <span class="math inline">\(X\)</span> has full column rank (<span class="math inline">\(X\)</span> has linearly independent columns).</p>
<!--chapter:end:211401_Overview.Rmd-->
</div>
</div>
<div id="introduction-1" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Introduction</h2>
<div id="what" class="section level3" number="6.2.1">
<h3 number="6.2.1"><span class="header-section-number">6.2.1</span> What</h3>
<p>for linear model <span class="math display">\[Y = X \beta + \epsilon\]</span></p>
$$
Y_{n } =
<span class="math display">\[\begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix}\]</span>
<p>; ; ; ; ; ; ;</p>
_{(p+1) } =
<span class="math display">\[\begin{pmatrix} \beta_0 \\ \vdots \\ \beta_p \end{pmatrix}\]</span>
<p>; ; ; ; ; ; ;</p>
_{n } =
<span class="math display">\[\begin{pmatrix} \epsilon_1 \\ \vdots \\ \epsilon_n \end{pmatrix}\]</span>
<p>\
\<br />
\<br />
\<br />
</p>
X_{n (p+1)} =
<span class="math display">\[\begin{pmatrix} 1 &amp; X_{11} &amp; \cdots &amp; X_{1p} \\ 

1 &amp; X_{21} &amp; \cdots &amp; X_{2p} \\ 

\vdots &amp;  &amp; \ddots &amp; \vdots \\ 

1 &amp; X_{n1} &amp; \cdots &amp; X_{np} \\ 


\end{pmatrix}\]</span>
<p>$$</p>
<ul>
<li>linear regression</li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}

y_i &amp;= \beta_0 + \beta_1 x_i &amp;&amp;+ \epsilon_i \tag{Simple}

\\


y_i &amp;= \beta_0 + \sum_{j=1}^p \beta_j x_{ij} &amp;&amp;+ \epsilon_i \tag{Multiple}


\end{alignat}\]</span>
$$</p>
<ul>
<li>ANOVA</li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}

y_{ij} &amp;= \mu + \alpha_i &amp;&amp;+ \epsilon_{ij} \tag{One-Way} 

\\

y_{ij} &amp;= \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} &amp;&amp;+ \epsilon_{ij} \tag{Two-Way with interaction}



\end{alignat}\]</span>
$$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="random-vectors-and-matrices" class="section level3" number="6.2.2">
<h3 number="6.2.2"><span class="header-section-number">6.2.2</span> Random Vectors and Matrices</h3>
<p>let rv <span class="math display">\[Y = \begin{pmatrix} y_1, &amp; \cdots &amp;, y_n \end{pmatrix}&#39;\]</span> with <span class="math display">\[E(y_i) = \mu_i , \; \; \; Var(y_i)=\sigma_{ii} \; \; (=\sigma_i^2), \; \; \; Cov(y_i , y_j) = \sigma_{ij}\]</span>.</p>
<ul>
<li>define the statistics of <span class="math display">\[Y\]</span></li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}


&amp;E(Y) &amp;&amp;= \begin{pmatrix} E(y_1), &amp; \cdots &amp; E(y_n) \end{pmatrix}&#39; = \begin{pmatrix} \mu_1, &amp; \cdots &amp; \mu_n \end{pmatrix}&#39; &amp;&amp;= \pmb \mu \tag{Expected Value of Y elementwise as } 

\\

&amp;Cov(Y) &amp;&amp;= E \left[ (Y-\pmb \mu) (Y-\pmb \mu) &#39; \right] &amp;&amp;= (\sigma_{ij}) \tag{Covariance Matrix}

\end{alignat}\]</span>
$$</p>
<ul>
<li>Note:</li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}


E(AY+\pmb b) &amp;= A \pmb \mu + \pmb b

\\

Cov(AY+\pmb b) &amp;= A \ast Cov(Y) \ast A &#39;

\end{alignat}\]</span>
$$</p>
<ul>
<li>Prove or disprove that Cov(Y) is nonnegative definite. how?</li>
</ul>
<hr />
<p>Covariance of <span class="math display">\[W_{r \times 1}, \; Y_{s \times 1}\]</span> with <span class="math display">\[E(W)=\gamma, \; E(Y) = \mu\]</span>:</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

Cov(W, Y) &amp;= E \left [(W-\gamma)(Y-\mu)&#39; \right ]_{r \times s} &amp;&amp;

\\

Cov(AW+a, NY+b) &amp;= A \ast Cov(W,Y) \ast B &#39; &amp;&amp;

\\

Cov(AW+NY) &amp;= A \ast Cov(W) \ast A&#39; + N \ast Cov(Y) \ast B&#39; \\
&amp;\; \; \; \; \; \; \; + A \ast Cov(W,Y) \ast B&#39; + B \ast Cov(W) \ast A&#39; \tag{why?}

\end{alignat}\]</span>
$$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="multivariate-normal-distributions" class="section level3" number="6.2.3">
<h3 number="6.2.3"><span class="header-section-number">6.2.3</span> Multivariate Normal Distributions</h3>
<p>$$</p>
<p>Z = (z_1 , , z_n) ’ N_n (0, ; I_n), ; ; ; ; ; z_1 , , z_n  N(0,1)</p>
<p>$$</p>
<p>which means <span class="math display">\[E(Z)=\pmb 0, \; Cov(Z)=I_n\]</span>.</p>
<p><span class="math display">\[
A_{r \times n}, \; b \in \mathbb{R}^r
\]</span></p>
<p>Y has an r-dimensional MVN distribution</p>
<p>Definition 1.2.1. Let A be r  n and b 2 Rr . Then Y has an
r-dimensional multivariate normal distribution :
Y = AZ + b  Nr (b;AAT ):
Theorem 1.2.2. Let Y  N(;V) and W  N(;V). Then Y
and W have the same distribution (Proof: p.5)</p>
<p>The density of nonsingular <span class="math display">\[Y \sim N(\mu,V)\]</span> is given by</p>
<p>$$</p>
<p>f(y) = (2)^{-} ^{-} </p>
<p>$$</p>
<p>Theorem 1.2.3. Let Y  N(;V) and Y =</p>
<p>Y1
Y2
!
. Then
Cov(Y1;Y2) = 0 if and only if Y1 Y2
Corollary 1.2.4. Let Y  N(; 2I) and ABT = 0. Then
AY BY</p>
<p>Definition 1.3.1. Quadratic Form of Y: for n  n; A
YTAY =
X
ij
aijyiyj
Theorem</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="distributions-of-quadratic-forms" class="section level3" number="6.2.4">
<h3 number="6.2.4"><span class="header-section-number">6.2.4</span> Distributions of Quadratic Forms</h3>
<p><span class="math display">\[E(Y) = \mu, \; Cov(Y) = V\]</span>. then <span class="math display">\[E(Y&#39;AY) = tr(AV) + \mu &#39; A \mu\]</span>. prf)</p>
<p>let’s consider <span class="math display">\[Z \sim N_n (\mu, I_n)\]</span>. then <span class="math display">\[ Z&#39;Z \sim \chi^2 \left(n, \; \dfrac{\mu&#39; \mu}{2} \right) \tag{second one is non-centrality parameter}\]</span></p>
<p><br/>
<br/></p>
<p>Let <span class="math display">\[Y \sim N(\mu , I)\]</span> and any orthogonal projection Matrix <span class="math display">\[M\]</span>. then <span class="math display">\[Y&#39;MY \sim \chi^2 \left(r(M), \dfrac{\mu &#39; M \mu}{2} \right)\]</span></p>
<p><br/>
<br/></p>
<p>Let <span class="math display">\[Y \sim N(\mu , \sigma^2 I)\]</span> and any orthogonal projection Matrix <span class="math display">\[M\]</span>. then <span class="math display">\[Y&#39;MY \sim \chi^2 \left(r(M), \dfrac{\mu &#39; M \mu}{2\sigma^2} \right)\]</span></p>
<p><br/>
<br/></p>
<p>Let <span class="math display">\[Y \sim N(\mu , M)\]</span>with <span class="math display">\[\mu \in \mathcal{C}(M)\]</span> and <span class="math display">\[M\]</span> be an orthogonal projection Matrix. then <span class="math display">\[Y&#39;Y \sim \chi^2 \left(r(M), \dfrac{\mu &#39; M \mu}{2\sigma^2} \right)\]</span>.</p>
<p><br/>
<br/></p>
<p>let <span class="math display">\[E(Y)=\mu, \; Cov(Y)=V\]</span>. then <span class="math display">\[Pr \left[ (Y-\mu) \in \mathcal{C}(V) \right]=1\]</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Exercise 1.6.
Let <span class="math display">\[Y\]</span> be a vector with <span class="math display">\[E(Y) = 0\]</span> and <span class="math display">\[Cov(Y) = 0\]</span>. Then <span class="math display">\[Pr(Y = 0) = 1\]</span>.</li>
</ul>
<p><br/>
<br/></p>
<p>let <span class="math display">\[Y \sim N(\mu, \; V)\]</span>. then <span class="math display">\[Y&#39; A Y \sim \chi^2 \left( tr(AV), \dfrac{\mu&#39; A \mu}{2}\right)\]</span>, provided that
1. <span class="math display">\[VAVAV=VAV\]</span>.
2. <span class="math display">\[\mu &#39; AVA \mu = \mu &#39; a \mu\]</span>.
3. <span class="math display">\[VAVA \mu = VA \mu\]</span> prf)</p>
<p><br/>
<br/></p>
<ul>
<li>Exercise 1.7.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Show that if <span class="math display">\[V\]</span> is nonsingular, then the three conditions in Theorem 1.3.6 reduce to <span class="math display">\[AVA = A\]</span>.</li>
<li>Show that <span class="math display">\[Y&#39;V^{-} Y\]</span> has a chi-squared distribution with <span class="math display">\[r(V)\]</span> degrees of freedom when <span class="math display">\[\mu \in \mathcal{C}(V)\]</span>.</li>
</ol>
<p><br/>
<br/></p>
<p>let <span class="math display">\[Y \sim N(\mu, \; \sigma^2 I)\]</span> and <span class="math display">\[BA=0\]</span>. then, for <span class="math display">\[A=A&#39;\]</span>,
1. <span class="math display">\[Y&#39;AY \perp BY\]</span>.
2. <span class="math display">\[Y&#39;AY \perp Y&#39; BY\]</span> for <span class="math display">\[B=B&#39;\]</span>.</p>
<p><br/>
<br/></p>
<p>let <span class="math display">\[Y \sim N(\mu, \; V)\]</span> and <span class="math display">\[A \ge 0, \; B \ge 0\]</span>, and <span class="math display">\[VAVBV=0\]</span>. then <span class="math display">\[Y&#39;AY \perp Y&#39;BY\]</span>.</p>
<p><br/>
<br/></p>
<p>let <span class="math display">\[Y \sim N(\mu, \; V)\]</span>. provided that
1. <span class="math display">\[VAVBV=0\]</span>.
2. <span class="math display">\[VAVB \mu = 0\]</span>.
3. <span class="math display">\[VBVA \mu = 0\]</span>.
4. <span class="math display">\[\mu &#39; ABV \mu = 0\]</span>.</p>
<p><br/>
<br/></p>
<p>and also conditions of above thm,
1. <span class="math display">\[VAVAV=VAV\]</span>.
2. <span class="math display">\[\mu &#39; AVA \mu = \mu &#39; a \mu\]</span>.
3. <span class="math display">\[VAVA \mu = VA \mu\]</span> prf)</p>
<p>hold for both <span class="math display">\[Y&#39;AY\]</span> and <span class="math display">\[Y&#39;BY\]</span>, then <span class="math display">\[Y&#39;AY \perp Y&#39;BY\]</span>.</p>
<!--chapter:end:211402_Introduction.Rmd-->
</div>
</div>
<div id="estimation" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> Estimation</h2>
<p>이하와 같은 linear model 고려. 이때 <span class="math inline">\(x_i &#39;\)</span>는 <span class="math inline">\(X\)</span>의 i번째 row vector이며, <span class="math inline">\(E(\epsilon)=0, \; Cov(\epsilon)=\sigma^2 I = \sigma^2 \Sigma\)</span>.</p>
$
Y_{n } = X_{n p} <em>{p } + </em>{n } =
<span class="math display">\[\begin{pmatrix} x_i &#39;  \beta \end{pmatrix}\]</span>
<ul>
<li>$</li>
</ul>
<p><br/>
<br/></p>
<div id="identifiability-and-estimability" class="section level3" number="6.3.1">
<h3 number="6.3.1"><span class="header-section-number">6.3.1</span> Identifiability and Estimability</h3>
<div id="identifiable" class="section level4" number="6.3.1.1">
<h4 number="6.3.1.1"><span class="header-section-number">6.3.1.1</span> Identifiable</h4>
<p>모델에서의 무한한 갯수의 관측치를 보유한다면, 모델의 underlying 패러미터의 참값을 획득하는 것이 가능한 성질.</p>
<p>A general linear model is a parameterization</p>
<p>$
<span class="math display">\[\begin{align}
E(Y) &amp;= f(X) \\
&amp;= E(X\beta + \epsilon)\\
&amp;= X\beta + E(\epsilon) \\
&amp;= X\beta  + 0 \\
&amp;= X\beta  

\end{align}\]</span>
$</p>
<p>The parameter <span class="math inline">\(\beta\)</span> is <strong>identifiable</strong> if for any <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> <span class="math inline">\(f(\beta_1) = f(\beta_2)\)</span> implies <span class="math inline">\(\beta_1 = \beta_2\)</span>. If <span class="math inline">\(\beta\)</span> is identifiable, we say that the parameterization <span class="math inline">\(f(\beta)\)</span> is identifiable. (패러미터 <span class="math inline">\(\beta\)</span>가 identifiable하다면, 우리는 해당 패러미터의 parameterization <span class="math inline">\(f(\beta)\)</span> 또한 identifiable 하다) Moreover, a vector-valued function <span class="math inline">\(g(\beta)\)</span> is identifiable if <span class="math inline">\(f (\beta_1) = f(\beta_2)\)</span> implies <span class="math inline">\(g (\beta_1) = g(\beta_2)\)</span>.</p>
<p>For regression models for which <span class="math inline">\(r(X) = p\)</span>, the parameters are identifiable: <span class="math inline">\(X&#39;X\)</span> is nonsingular, so if <span class="math inline">\(X\beta_1 = X\beta_2\)</span>, then</p>
<p>$
_1 = (X’X)^{-1} X’X _1 = (X’X)^{-1} X’X _2 = _2
$</p>
<p>A function <span class="math inline">\(g(\beta)\)</span> is identifiable <span class="math inline">\(\iff\)</span> <span class="math inline">\(g(\beta)\)</span> is a function of <span class="math inline">\(f(\beta)\)</span>.</p>
<p><br/>
<br/>
<br/></p>
</div>
<div id="estimable" class="section level4" number="6.3.1.2">
<h4 number="6.3.1.2"><span class="header-section-number">6.3.1.2</span> Estimable</h4>
<p>The results in the last section suggest that some linear combinations of <span class="math inline">\(\beta\)</span> in the less than full rank case will not be estimable.</p>
<p>The linear parametric function <span class="math inline">\(c&#39;β\)</span> is an <strong>estimable</strong> function if there exists a vector <span class="math inline">\(a \in \mathbb{R}^n\)</span> such that <span class="math inline">\(\forall \beta: E(a &#39; y ) = c &#39; \beta\)</span>.</p>
<p>A vector-valued linear function of <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\Lambda &#39; \beta\)</span> is <strong>estimable</strong> if <span class="math inline">\(\Lambda &#39; \beta = P &#39; X \beta\)</span> for some matrix P; In other words, <span class="math inline">\(\Lambda &#39; \beta\)</span> is estimable if <span class="math inline">\(\Lambda = X &#39; P \in \mathcal{C}(X&#39;)\)</span>.</p>
<p>Clearly, if <span class="math inline">\(\Lambda &#39; \beta\)</span> is estimable, it is identifiable and therefore it is a reasonable thing to estimate.</p>
<ul>
<li>estimable <span class="math inline">\(\rightarrow\)</span> identifiable</li>
</ul>
<p>For estimable functions <span class="math inline">\(\Lambda&#39; \beta = P &#39; X \beta\)</span>, although <span class="math inline">\(P\)</span> need not be unique, its perpendicular projection (columnwise) onto <span class="math inline">\(\mathcal{C}(X)\)</span> is unique: <br/>
let <span class="math inline">\(P_1 , \; P_2\)</span> be matrices with <span class="math inline">\(\Lambda &#39; = P_1 &#39; X = P_2 &#39; X\)</span>, then</p>
<p>$</p>
<p>MP_1 = X(X’X)^{-}X’P_1 = X(X’X)^{-}= X(X’X)^{-}X’P_2 = MP_2</p>
<p>$</p>
<p><br/>
<br/>
<br/></p>
<ul>
<li>Example 2.1.4 and 2.1.5</li>
</ul>
<p><span class="math inline">\(g(\beta)\)</span>’s estimate, <span class="math inline">\(f(Y)\)</span>, is <strong>unbiased</strong> if <span class="math inline">\(\forall \beta: \; E[f(Y)] = g(\beta)\)</span>.</p>
<p>if <span class="math inline">\(f (Y) = a_0 + a&#39; Y\)</span> for some scalar <span class="math inline">\(a_0\)</span> and vector <span class="math inline">\(a\)</span>, <span class="math inline">\(f(Y)\)</span> is a <strong>linear estimate</strong> of <span class="math inline">\(\Lambda &#39; \beta\)</span>.</p>
<p>if <span class="math inline">\(\Lambda &#39; \beta\)</span> <span class="math inline">\(\iff\)</span> <span class="math inline">\(a_0 = 0\)</span> and <span class="math inline">\(a &#39; X = \Lambda&#39;\)</span>; say, <span class="math inline">\(\Lambda = X &#39; a \in \mathcal{C}(X&#39;)\)</span>, then a <strong>linear estimate</strong> <span class="math inline">\(a_0 + a &#39; Y\)</span> is <strong>unbiased</strong></p>
<p><span class="math inline">\(\Lambda &#39; \beta\)</span> is <strong>estimable</strong> <span class="math inline">\(\iff\)</span> there exists <span class="math inline">\(\rho\)</span> such that <span class="math inline">\(E(\rho &#39; Y ) = \Lambda &#39; \beta\)</span> for any <span class="math inline">\(\beta\)</span>.</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
</div>
<div id="estimation-least-squares" class="section level3" number="6.3.2">
<h3 number="6.3.2"><span class="header-section-number">6.3.2</span> Estimation: Least Squares</h3>
<p>Estimating <span class="math inline">\(E(Y)\)</span> is to take a vector in <span class="math inline">\(\mathcal{C}(X)\)</span> closest to <span class="math inline">\(Y\)</span>;</p>
<p>$
<span class="math display">\[\begin{alignat}{2}

E(Y) &amp;= X\beta \; &amp;&amp;\in \; \mathcal{C}(X)\\

\\

\hat \beta &amp;= \min_\beta \left\{ (Y-X \beta) &#39; (Y-X \beta)  \right\} \\
&amp;= \min_\beta \left\{ \Vert Y-X \beta \Vert^2   \right\}

\tag{Least Squares Estimate of beta}


\end{alignat}\]</span>
$</p>
<p>for any Least Squares Estimate <span class="math inline">\(\hat \beta\)</span>, LSE of <span class="math inline">\(\Lambda &#39; \beta is \Lambda &#39; \hat \beta\)</span>, e.g., <span class="math inline">\(\hat {\Lambda &#39; \beta}_{LSE} = \Lambda &#39; \hat \beta\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.2.1</li>
</ul>
<p>where <span class="math inline">\(M\)</span> is the perpendicular projection operator onto <span class="math inline">\(\mathcal{C}(X)\)</span>, then</p>
<p>$
$ is a LSE of <span class="math inline">\(\beta\)</span> <span class="math inline">\(\iff\)</span> $X = M Y
$</p>
<p><br/>
<br/></p>
<ul>
<li>Corollary 2.2.2</li>
</ul>
<p><span class="math inline">\(\hat \beta_{LSE} = X(X&#39;X)^{-}X&#39; Y\)</span></p>
<p><br/>
<br/></p>
<ul>
<li>Corollary 2.2.3</li>
</ul>
<p>The unique LSE of <span class="math inline">\(\rho &#39; X \beta = \rho &#39; M Y\)</span>.</p>
<p>※ Note: the unique LSE of <span class="math inline">\(\Lambda &#39; \beta = \Lambda &#39; \hat \beta = P&#39; M Y\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.2.4</li>
</ul>
<p>the LSE of <span class="math inline">\(\Lambda &#39; \beta\)</span> is unique only if <span class="math inline">\(\Lambda &#39; \beta\)</span> is estimable: <span class="math inline">\(\Lambda = X&#39;\rho\)</span> if <span class="math inline">\(\Lambda &#39; \hat \beta_1 =\Lambda &#39; \hat \beta_2\)</span>, so that <span class="math inline">\(X \hat \beta_1 = X \hat \beta_2 = MY\)</span>.</p>
<p>※ Note: When <span class="math inline">\(\beta\)</span> is not identifiable, we need side conditions imposed on the parameters to estimate nonidentifiable parameters.</p>
<p>※ Note: With <span class="math inline">\(r = r (X) &lt; p\)</span> (overparameterized model), we need <span class="math inline">\(p - r\)</span> individual side conditions to identify and estimate the parameters.</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 2.2.5</li>
</ul>
<p>If <span class="math inline">\(\Lambda = X &#39; \rho\)</span>, then <span class="math inline">\(E(\rho &#39; MY) = \Lambda &#39; \beta\)</span>.</p>
<p>let’s decompose</p>
<p>$
<span class="math display">\[\begin{alignat}{2}

Y 

&amp;= X \hat \beta &amp;&amp;+ Y - X \hat \beta

\\


&amp;= MY &amp;&amp;+ (I-M)Y

\\



&amp;= \hat Y &amp;&amp;+ e 

\end{alignat}\]</span>
$</p>
<p>이때
$
<span class="math display">\[\begin{align}
\hat Y &amp;\in \mathcal{C}(X) \tag{fitted values of Y} \\
e &amp;\in \mathcal{C}(X)^{\perp} \tag{residuals}
\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.2.6</li>
</ul>
<p>Let <span class="math inline">\(r (X) = r\)</span> and <span class="math inline">\(Cov(\epsilon) = \sigma^2 I\)</span>. At below formula, denominator is <strong>degrees of freedom for error</strong>.</p>
<p>Then an <strong>UE</strong> of <span class="math inline">\(\sigma^2\)</span>, MSE, is as below.</p>
<p>$
^2 = = 
$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="estimation-best-linear-unbiased" class="section level3" number="6.3.3">
<h3 number="6.3.3"><span class="header-section-number">6.3.3</span> Estimation: Best Linear Unbiased</h3>
<ul>
<li>Definition 2.3.1</li>
</ul>
<p><span class="math inline">\(a&#39;Y\)</span> is a Best Linear Unbiased Estimate(BLUE) of <span class="math inline">\(\lambda &#39; \beta\)</span> if <span class="math inline">\(a &#39; Y\)</span> is unbiased.</p>
<p>e.g., <span class="math inline">\(E(a &#39; Y) = \lambda &#39; \beta\)</span> and if for any other linear unbiased estimate <span class="math inline">\(b &#39; Y\)</span>, <span class="math inline">\(Var(a &#39; Y) \le Var(b&#39;Y)\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.3.2: Gauss-Markov thm</li>
</ul>
<p>Consider <span class="math inline">\(Y = X \beta + \epsilon\)</span> with <span class="math inline">\(E(\epsilon) = 0\)</span>, <span class="math inline">\(Cov(\epsilon) = \sigma^2 I\)</span>. Let <span class="math inline">\(\lambda &#39; \beta\)</span> be estimable.</p>
<p>Then LSE of <span class="math inline">\(\lambda &#39; \beta=\)</span> BLUE of <span class="math inline">\(\lambda &#39; \beta\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Corollary 2.3.3</li>
</ul>
<p>Let <span class="math inline">\(\sigma^2 &gt; 0\)</span>. Then there exists a unique BLUE for any estimable function <span class="math inline">\(\lambda &#39; \beta\)</span>.</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="estimation-maximum-likelihood" class="section level3" number="6.3.4">
<h3 number="6.3.4"><span class="header-section-number">6.3.4</span> Estimation: Maximum Likelihood</h3>
<p>Assume that <span class="math inline">\(Y \sim N_n(X\beta , \; \sigma^2 I_n)\)</span>. Then the Maximum Likelihood Estimates (MLEs) of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> are obtained by maximizing the log of the likelihood so that</p>
<p>$
<span class="math display">\[\begin{align}

\left( 

\hat \beta , \; \hat \sigma^2


\right)

&amp;= \text{ MLE of }

\left( 

\beta , \; \sigma^2


\right)


\\

&amp;=

\max_{\left( \beta , \; \sigma^2 \right)} \left\{ 

-\dfrac{n}{2}log(2 \pi) - \dfrac{1}{2} \log \left[ (\sigma^2 )^n\right] - \dfrac{(Y-X\beta)&#39;(Y-X\beta)}{2\sigma^2}




\right\}


\end{align}\]</span></p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

\hat \beta &amp;= \text{ LSE of } \beta \\

\\\

\hat \sigma^2 &amp;= \dfrac{1}{n} \left\{Y&#39;(I-M)Y \right\}


\end{align}\]</span>
$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="estimation-minimum-variance-unbiased" class="section level3" number="6.3.5">
<h3 number="6.3.5"><span class="header-section-number">6.3.5</span> Estimation: Minimum Variance Unbiased</h3>
<p>Assume that <span class="math inline">\(Y = X \beta + \epsilon\)</span> with <span class="math inline">\(\epsilon \sim N_n(0, \; \sigma^2 I_n)\)</span>.</p>
<p>if <span class="math inline">\(\forall \beta, \sigma^2: \; E \left \{h[T(Y)] \right\} = 0\)</span> implies that <span class="math inline">\(Pr[h(T(Y)) = 0] = 1\)</span>, A vector-valued sufficient statistic <span class="math inline">\(T(Y)\)</span> is said to be <strong>complete</strong></p>
<p>If <span class="math inline">\(T(Y)\)</span> is a complete sufficient statistic, then <span class="math inline">\(f(T(Y))\)</span> is a <strong>Minimum Variance Unbiased Estimate (MVUE)</strong> of <span class="math inline">\(E \Big [ f (T(Y)) \Big ]\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.5.3</li>
</ul>
<p>let <span class="math inline">\(\theta = (\theta_1 , \cdots, \theta_s)&#39;\)</span> and let <span class="math inline">\(Y\)</span> be a rvec with pdf as below. then <span class="math inline">\(T(Y) = \Big( T_1(Y), \cdots, T_s(Y) \Big)&#39;\)</span> is a <strong>complete sufficient statistics</strong> provided that neither <span class="math inline">\(\theta\)</span> nor <span class="math inline">\(T(Y)\)</span> satisfies any linear constraints.</p>
<p>$
f(Y) = c() h(Y)
$</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2.5.4</li>
</ul>
<p>MSE is a $_{MVUE} $, and <span class="math inline">\(\hat { \rho &#39; X \beta }_{MVUE} = \rho &#39; M Y\)</span> whenever <span class="math inline">\(\epsilon \sim N(0, \; I)\)</span>.</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="sampling-distributions-of-estimates" class="section level3" number="6.3.6">
<h3 number="6.3.6"><span class="header-section-number">6.3.6</span> Sampling Distributions of Estimates</h3>
<p>Assume that <span class="math inline">\(Y = X \beta + \epsilon\)</span> with <span class="math inline">\(\epsilon \sim N_n(0, \; \sigma^2 I_n)\)</span>. Then <span class="math inline">\(Y \sim N_n(X \beta, \; \sigma^2 I_n)\)</span>. then</p>
<p>$
<span class="math display">\[\begin{alignat}{4}
\Lambda &#39; \hat \beta &amp;= P&#39; M Y &amp;&amp;\sim N(\Lambda &#39; \beta , \; &amp;&amp;\sigma^2 P&#39;MP&amp;&amp;\; \; \; ) &amp;&amp; \; \; \; \; \; \; \; \; \; \;&amp;&amp; &amp;&amp; &amp;&amp;  \\


&amp; &amp;&amp;\sim N(\Lambda &#39; \beta , \; &amp;&amp;\sigma^2 \Lambda &#39; (X&#39;X)^{-} \Lambda&amp;&amp;\; \; \; ) &amp;&amp;    &amp;&amp; \because &amp;&amp; \;M &amp;&amp; =X(X&#39;X)^- X&#39; \\



&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; \; \hat Y &amp;&amp; = MY &amp;&amp;\sim N(X\beta, \sigma^2 M)


\\

\hat \beta &amp;= (X&#39;X)^- X&#39;Y &amp;&amp;\sim N(\beta , \; &amp;&amp;\sigma^2 (X&#39;X)^{-1}) &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; (\text{if X is of full rank})



\end{alignat}\]</span>
$</p>
<p><br/>
<br/></p>
<p>Do Exercise 2.1. Show that
$
 ^2 ( r(I-M), ;  )
$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="generalized-least-squaresgls" class="section level3" number="6.3.7">
<h3 number="6.3.7"><span class="header-section-number">6.3.7</span> Generalized Least Squares(GLS)</h3>
<p>Assume that for some known positive definite <span class="math inline">\(\Sigma\)</span>,</p>
<p>$
Y = X + , ; ; ; ; ;
$</p>
<p>$
<span class="math display">\[\begin{alignat}{3}

Y &amp;= X \beta &amp;&amp;+ \epsilon &amp;&amp; \; \; \; \; \; \; \; \; \; \; 

&amp;&amp; E(\epsilon)&amp;&amp;=0, \; \; &amp;&amp;\; Cov(\epsilon) &amp;&amp;= \sigma^2 \Sigma \tag{1}\\








\Sigma^{-\tfrac{1}{2}}Y &amp;= \Sigma^{-\tfrac{1}{2}} X \beta &amp;&amp;+ \Sigma^{-\tfrac{1}{2}} \epsilon 


 &amp;&amp; \; \; \; \; \; \; \; \; \; \; &amp;&amp; E(\Sigma^{-\tfrac{1}{2}} \epsilon)&amp;&amp;=0, &amp;&amp;\; Cov(\Sigma^{-\tfrac{1}{2}} \epsilon) &amp;&amp;= \sigma^2 I \tag{2, by SVD}
\\

Y_\ast &amp;= X_\ast \beta &amp;&amp;+ \epsilon_\ast



 &amp;&amp; \; \; \; \; \; \; \; \; \; \; &amp;&amp; E( \epsilon_\ast)&amp;&amp;=0, &amp;&amp;\; Cov( \epsilon_\ast) &amp;&amp;= \sigma^2 I



\end{alignat}\]</span>
$</p>
<p>$
<span class="math display">\[\begin{alignat}{2}

\hat \beta_{GLS} &amp;= \min_\beta (Y_\ast - X_\ast \beta)&#39;(Y_\ast - X_\ast \beta) \\

&amp;= \min_\beta \Vert Y_\ast - X_\ast \beta \Vert^2 \\



&amp;= \min_\beta (Y - X \beta)&#39; \Sigma^{-1} (Y - X \beta) \tag{Generalized LSE (GLSE) of β}


\end{alignat}\]</span>
$</p>
<ul>
<li>Theorem 2.7.1</li>
</ul>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\lambda &#39; \beta\)</span> estimable in model (1) <span class="math inline">\(\iff\)</span> if <span class="math inline">\(\lambda &#39; \beta\)</span> is estimable in model (2).</li>
<li>$$ is GLSE of <span class="math inline">\(\beta\)</span> <span class="math inline">\(\iff\)</span> <span class="math inline">\(X(X&#39; \Sigma^{-1} X)^{-}X&#39; \Sigma^{-1}Y = X \hat \beta\)</span>, which is Normal Equation of GLS.</li>
</ol>
<ul>
<li>For any estimable function, there exists a unique GLSE.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>GLSE estimate of estimable <span class="math inline">\(\lambda&#39; \beta\)</span>, is BLUE of $’ $.</li>
<li>let <span class="math inline">\(\epsilon \sim N(0, \; \Sigma^2 \Sigma)\)</span>. then, GLSE of estimable <span class="math inline">\(\lambda &#39; \beta\)</span>, is MVUE.</li>
<li>let <span class="math inline">\(\epsilon \sim N(0, \; \Sigma^2 \Sigma)\)</span>. then, <span class="math inline">\(\hat \beta_{GLS} = \hat \beta_{MLE}\)</span>.</li>
</ol>
<p><br/>
<br/>
<br/></p>
<p>Normal Equation of GLS can be rewritten as</p>
<p>$
<span class="math display">\[\begin{align}

X(X&#39; \Sigma^{-1} X)^{-}X&#39; \Sigma^{-1}Y &amp;= X \hat \beta \\
AY &amp;=
\end{align}\]</span>
$</p>
<p><span class="math inline">\(A\)</span> is a projection operator onto <span class="math inline">\(\mathcal{C}(X)\)</span>.</p>
<p><span class="math inline">\(Cov(X \hat \beta_{GLS}) = \sigma^2 \ast X(X&#39; \Sigma^{-1} X)^{-}X&#39;\)</span>
Let <span class="math inline">\(\lambda &#39; \beta\)</span> be estimable. Then <span class="math inline">\(Var(\lambda &#39; \hat \beta_{GLS}) = \sigma^2 \ast \lambda &#39; (X&#39; \Sigma^{-1} X)^- \lambda\)</span>.</p>
<ul>
<li>Note: <span class="math inline">\((I-A)Y\)</span> is residual vector of GLSE.</li>
</ul>
<p>$
<span class="math display">\[\begin{align}

SSE_{GLS} &amp;= (Y_\ast - \hat Y_\ast)&#39; (Y_\ast - \hat Y_\ast) \\

&amp;\; \; \vdots \\

&amp;= Y&#39;(I-A)&#39; \Sigma^{-1}(I-A)Y \\

\\\

MSE_{GLS} &amp;= \hat \sigma^2 \\
&amp; = \dfrac{1}{n-r(X)} \ast SSE_{GLS}\\

\\\

\dfrac{1}{\hat \sigma^2}

\dfrac{\lambda&#39; \Big(\hat \beta_{GLS} - \beta_{GLS} \Big)}{ \lambda &#39; (X&#39; \Sigma^{-1} X)^- \lambda} &amp;\sim t\Big( n-r(x) \Big)





\end{align}\]</span>
$</p>
<p>denominator는 <span class="math inline">\(Var(\lambda &#39; \hat \beta_{GLS}) = \sigma^2 \ast \lambda &#39; (X&#39; \Sigma^{-1} X)^- \lambda\)</span>.</p>
<p>Let <span class="math inline">\(\Sigma\)</span> be nonsingular and <span class="math inline">\(\mathcal{C}(\Sigma X) \subset \mathcal{C}(X)\)</span>. Then least squares estimates are BLUEs.</p>
<ul>
<li>Note: for diagonal <span class="math inline">\(\Sigma\)</span>, GLS is referred to as <strong>Weighted Least Squares (WLS)</strong>.</li>
</ul>
<p><br/>
<br/></p>
<ul>
<li>Exercise 2.5.</li>
</ul>
<p>Show that <span class="math inline">\(A\)</span> is the perpendicular projection operator onto <span class="math inline">\(\mathcal{C}(X)\)</span> when the inner product between two vectors <span class="math inline">\(\pmb x\)</span> and <span class="math inline">\(\pmb y\)</span> is defined as <span class="math inline">\((\pmb x, \pmb y)_\Sigma \equiv \pmb x&#39; \Sigma^{-1} \pmb y\)</span>.</p>
<!--chapter:end:211403_Estimation.Rmd-->
</div>
</div>
<div id="one-way-anova" class="section level2" number="6.4">
<h2 number="6.4"><span class="header-section-number">6.4</span> One-Way ANOVA</h2>
<div id="one-way-anova-1" class="section level3" number="6.4.1">
<h3 number="6.4.1"><span class="header-section-number">6.4.1</span> One-Way ANOVA</h3>
<p>General form of One-Way ANOVA model is</p>
<p>$
y_{ij} = + <em>{i} + </em>{ij}, ; ; ; ; ; i=1, , a ; ; ; ; ; j=1, , N_i
$</p>
<p>$
n=_{i=1}^a N_i \</p>
<p>\</p>
<p>E(<em>{ij})=0, ; Var(</em>{ij})=^2, ; Cov(<em>{ij}, </em>{ab})=0
$</p>
<ul>
<li><strong>i-th treatment (group) effect</strong> <span class="math inline">\(a_i\)</span>
<ul>
<li><strong>Balanced model</strong> is <span class="math inline">\(\forall i: N_i = b\)</span></li>
<li><strong>Unbalanced model</strong> is <span class="math inline">\(\forall i: N_i\)</span>’s are different</li>
</ul></li>
</ul>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="more-about-models" class="section level3" number="6.4.2">
<h3 number="6.4.2"><span class="header-section-number">6.4.2</span> More About Models</h3>
<ul>
<li>Example 4.1.1:</li>
</ul>
<p><span class="math inline">\(a = 3, \; N_1 = 5, \; N_2 = 3, \; N_3 = 3\)</span>,</p>
<p>$
Y = X + =</p>
<span class="math display">\[\begin{pmatrix} 
J_5 &amp; J_5 &amp;  0 &amp; 0 \\
J_3 &amp; 0 &amp; J_3 &amp; 0 \\
J_3 &amp; 0 &amp; 0 &amp; J_3


\end{pmatrix}\]</span>
<span class="math display">\[\begin{pmatrix} 

\mu \\
\alpha_1 \\
\alpha_2 \\
\alpha_3


\end{pmatrix}\]</span>
<ul>
<li></li>
</ul>
<span class="math display">\[\begin{pmatrix} 

\epsilon_{11} \\
\epsilon_{12} \\
\vdots \\
\epsilon_{33}

\end{pmatrix}\]</span>
<p>$</p>
<p>let <span class="math inline">\(N_1 = N_2 = N_3 = 5\)</span>. then</p>
<p>$
X =</p>
<span class="math display">\[\begin{pmatrix} 

J_3 \otimes J_5 &amp; I_3 \otimes J_5
\end{pmatrix}\]</span>
<p>$</p>
<p>In general, balanced design such as <span class="math inline">\(i = 1, \cdots, a \; \; \; \; \; j = 1, \cdots, b\)</span>:</p>
<p>$
X =</p>
<span class="math display">\[\begin{pmatrix} 

J_a \otimes J_b &amp; I_a \otimes J_b
\end{pmatrix}\]</span>
<p>$</p>
<p><br/>
<br/></p>
<ul>
<li>Notation: <span class="math inline">\(J_r^c \equiv J_r J_c&#39; = J_r \otimes J^c\)</span> is a <span class="math inline">\(r \times c\)</span> matrix of <span class="math inline">\(1\)</span>’s.</li>
</ul>
<p><br/>
<br/></p>
<p>Let <span class="math inline">\(Z\)</span> be the model matrix for the alternative one-way analysis of variance model</p>
<p>$
y_{ij} = <em>i + </em>{ij} ; ; ; ; ; i=1, , a ; ; ; ; ; k= 1, , N_i
$</p>
<p>then, letting <span class="math inline">\(X_i X_j = \delta_{ij}\)</span> with 1 for <span class="math inline">\(i=j\)</span> and 0 for <span class="math inline">\(i \not = j\)</span>,</p>
<p>$
<span class="math display">\[\begin{align}

X &amp;= \begin{bmatrix}J &amp; Z\end{bmatrix} &amp;&amp;= \begin{bmatrix}J &amp; (X_1 , \cdots, X_a)\end{bmatrix}

\\

\Longrightarrow \; \; \; \; \; \mathcal{C}(X) &amp;=\mathcal{C}(Z)

\\

Z&#39;Z &amp;= diag(N_1 , N_2 , \cdots, N_a)

\\

Z(Z&#39;Z)^{-1}Z&#39; &amp;=Blk \; \; diag \Big[ N_i^{-1} J_{N_i}^{N_i} \Big]

\\

M &amp;=X (X&#39;X)^{-1}X&#39;

\\

M_\alpha &amp;= Z_\ast(Z_\ast &#39; Z_\ast)^{-1} Z_\ast &#39; &amp;&amp;=M- M_J = M-\dfrac{1}{n}J_n^n

\\

Z_\ast &amp;=(I-M_j)Z

\\

M &amp;= M_j + M_\alpha



\end{align}\]</span>
$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="estimating-and-testing-contrasts" class="section level3" number="6.4.3">
<h3 number="6.4.3"><span class="header-section-number">6.4.3</span> Estimating and Testing Contrasts</h3>
<p>A contrast in the one-way ANOVA</p>
<p>$</p>
<p>’ = _{i=1}^a <em>i <em>i ; ; ; ; ; with ; ; ; ’ J</em>{a+1} = </em>{i=1}^a _i = 0</p>
<p>$</p>
<p>For estimable <span class="math inline">\(\lambda &#39; \beta\)</span>, find <span class="math inline">\(\rho\)</span> so that $‘X = ’ $, <span class="math inline">\(\rho &#39; = \begin{pmatrix} \dfrac{J_{N_i} &#39; \lambda_i}{N_i} \end{pmatrix}\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 4.2.1.</li>
</ul>
<p><span class="math inline">\(\lambda &#39; \alpha = \rho &#39; X \beta\)</span> is a contrast <span class="math inline">\(\iff\)</span> <span class="math inline">\(\rho &#39; J = 0\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 4.2.2.</li>
</ul>
<p><span class="math inline">\(\lambda &#39; \alpha = \rho &#39; X \beta\)</span> is a contrast <span class="math inline">\(\iff\)</span> <span class="math inline">\(M_\rho \in \mathcal{C}(M_\alpha)\)</span>.</p>
<p>since <span class="math inline">\(\sum_{i=1}^a \lambda_i =0\)</span>,</p>
<p>$
_{i=1}^a _i <em>i =</em>{i=1}^a _i {+ <em>i} = </em>{i=1}^a <em>i y</em>{i+}
$
because <span class="math inline">\(\mu + \alpha_i\)</span> is estimable, and its unique LSE is <span class="math inline">\(\bar y_{i+}\)</span>.</p>
<p><br/>
<br/>
<br/></p>
<p>At significance level <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(H_0: \lambda &#39; \alpha=0\)</span> is rejected if</p>
<p>$
<span class="math display">\[\begin{alignat}{2}


&amp;F 

&amp;&amp;= 

\dfrac
{
\dfrac{ \Big( \sum_{i=1}^a \lambda_i \bar y_{i+} \Big) ^2}
{\dfrac{\sum_{i=1}^a \lambda_i^2}{N_i}}
}
{MSE}

&amp;&amp;&gt; F \Big(1-\alpha, \; \; 1, \; \;  dfE \Big)


\\

\\

\\



\iff

\; \; \; \; \; 

&amp; t  \

&amp;&amp;= 


\dfrac
{\Bigg \vert \sum_{i=1}^a \lambda_i \bar y_{i+} \Bigg \vert}
{\sqrt{MSE \left( \sum_{i=1}^a\dfrac{\lambda_i^2}{N_i}\right)  }}


&amp;&amp;&gt; 


t \left( 1-\dfrac{\alpha}{2}, \; \; dfE \right)

\end{alignat}\]</span>
$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="cochrans-theorem" class="section level3" number="6.4.4">
<h3 number="6.4.4"><span class="header-section-number">6.4.4</span> Cochran’s Theorem</h3>
<p>let <span class="math inline">\(A_1 , \cdots, A_m\)</span> be <span class="math inline">\(n \times n\)</span> symmetric Matrices, and <span class="math inline">\(A = \sum_{j=1}^m A_j\)</span> with <span class="math inline">\(rank(A_j) = n_j\)</span>. consider the following four statements:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A_j\)</span> is an orthogonal projection for all <span class="math inline">\(j\)</span>.</li>
<li><span class="math inline">\(A\)</span> is an orthogonal projection (possibly <span class="math inline">\(A=I\)</span>).</li>
<li><span class="math inline">\(A_j A_k = 0\)</span> for all <span class="math inline">\(j \not = k\)</span>.</li>
<li><span class="math inline">\(\sum_{j=1}^m n_j = n\)</span>.</li>
</ol>
<p><br/></p>
<p>If any two of these conditions hold, then all four hold.</p>
<ul>
<li>Note: Cochran’s theorem is a standard result that is the basis of the ANalysis Of VAriance. If we can write the total sum of squares as a sum of sum of squares components, and if the degree of freedom add up, then the <span class="math inline">\(A_j\)</span> must be projections, they are orthogonal to each other, and they jointly span <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
</ul>
<!--chapter:end:211404_One-WayANOVA.Rmd-->
</div>
</div>
<div id="testing" class="section level2" number="6.5">
<h2 number="6.5"><span class="header-section-number">6.5</span> Testing</h2>
<div id="more-about-models-two-approaches-for-linear-model" class="section level3" number="6.5.1">
<h3 number="6.5.1"><span class="header-section-number">6.5.1</span> More About Models: Two approaches for linear model</h3>
<p>$
<span class="math display">\[\begin{alignat}{2}

Y &amp;= E(Y) &amp;&amp;+ Y - E(Y)  \\

&amp;= \mu &amp;&amp;+ \epsilon \tag{Parameter-free approach }

\\
\\

Y &amp;= E(Y) &amp;&amp;+ Y - E(Y)  \\

&amp;= X \beta &amp;&amp;+ \epsilon \tag{Parameter approach}




\end{alignat}\]</span>
$</p>
<p>$
<span class="math display">\[\begin{alignat}{2}

E(\epsilon) &amp;= 0, \; \; \;  &amp;&amp; Cov(\epsilon) &amp;&amp;= \sigma^2 I \tag{Ordinary Least Square, OLS}

\\ 

E(\epsilon) &amp;= 0, &amp;&amp; Cov(\epsilon) &amp;&amp;= \sigma^2 \Sigma \tag{Generalized Least Square, GLS}



\end{alignat}\]</span>
$</p>
<p><br/>
<br/>
<br/></p>
<ul>
<li>Consider</li>
</ul>
<p>$
Y=X + , ; ; ; ; ; E()=0, ; Cov() = ^2 I
$</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(\mathcal{C}(X)\)</span></th>
<th align="center"><span class="math inline">\(\mathcal{C}(X)^\perp\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">itslef</td>
<td align="center">Estimation Space</td>
<td align="center">Error Space</td>
</tr>
<tr class="even">
<td align="center">orthogonal projection onto</td>
<td align="center"><span class="math inline">\(M \\ = X(X&#39;X)^-X&#39;\)</span></td>
<td align="center"><span class="math inline">\(I - M \\= I - X(X&#39;X)^-X&#39;\)</span></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(E(Y) = X \beta \in \mathcal{C}(X)\)</span></td>
<td align="center"><span class="math inline">\(E(\epsilon) \in \mathcal{C}(X)^\perp\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"><span class="math inline">\(Cov(Y) = \sigma^2 I\)</span></td>
<td align="center"><span class="math inline">\(Cov(\epsilon) = \sigma^2 I\)</span></td>
</tr>
</tbody>
</table>
<p><br/>
<br/>
<br/></p>
<ul>
<li>One-Way ANOVA</li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{4}



y_{ij} &amp;= \mu_i &amp;&amp;+ \epsilon_{ij} \\
&amp;= E(y_{ij}) &amp;&amp;+ \epsilon_{ij} \\


&amp;= \mu + \alpha_i &amp;&amp;+ \epsilon_{ij} \\

\\\

\bar \mu &amp;= \mu + \bar \alpha_+ \\


\mu_1 - \mu_2 &amp;= \alpha_1 - \alpha_2



\end{alignat}\]</span>
$</p>
<p>the parameters in the two models are different, but they are related.</p>
<p><br/>
<br/>
<br/></p>
<ul>
<li>Simple Linear Regression</li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{4}
y_i &amp; = \beta_0 + \beta_1 x_i &amp;&amp;+\epsilon_i

\\


&amp; = E(y_i) &amp;&amp;+\epsilon_i
 
\\

&amp; = \gamma_0 + \gamma_1(x_i - \bar x) &amp;&amp;+\epsilon_i


\end{alignat}\]</span>
$</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\mathcal{C}(X_1) = \mathcal{C}(X_2) \; \; \Longrightarrow \; \;\; \; \; X_1 &amp;= X_2 T


\\

X_1 \beta_1 &amp;= X_2 T \beta_1 &amp;&amp; = X_2 \beta_2

\\

&amp; &amp;&amp;= X_2 (T \beta_1 + \nu), \; \; \; \forall\nu \in \mathcal{C}(X_2&#39;)^\perp


\end{alignat}\]</span>
$</p>
<p>※ Note: A unique parameterization for <span class="math inline">\(X_j, \; j=1,2\)</span> occurs <span class="math inline">\(\iff\)</span> <span class="math inline">\(X_j &#39; X_j\)</span> is nonsingular.</p>
<ul>
<li>Exercise: Show that a unique parameterization for <span class="math inline">\(X_j, \; j=1,2\)</span> means <span class="math inline">\(\mathcal{C}(X_2 &#39; )^\perp = \{0\}\)</span>.</li>
</ul>
</div>
<div id="testing-models" class="section level3" number="6.5.2">
<h3 number="6.5.2"><span class="header-section-number">6.5.2</span> Testing Models</h3>
<p>Consider</p>
<p>$
Y=X + , ; ; ; ; ; N(0, ; I_n)
$</p>
let’s partition <span class="math inline">\(X\)</span> into $X =
<span class="math display">\[\begin{pmatrix} X_0, &amp; X_1 \end{pmatrix}\]</span>
<p>: ; (X_0) (X) $</p>
<p>$
<span class="math display">\[\begin{alignat}{2}


Y &amp;= X_0 \beta_0 + X_1 \beta_1 &amp;&amp;+ \epsilon \tag{Full Model, FM}

\\


Y &amp;= X_0 \gamma &amp;&amp;+ \epsilon \tag{Reduced Model, RM}

\end{alignat}\]</span>
$</p>
<p>이때 Hypothesis testing procedure can be described as <span class="math inline">\(H_0:\)</span> Reduced Model, <span class="math inline">\(H_1:\)</span> Full Model. (Example 3.2.0: pp. 52–54).</p>
<p><br/>
<br/>
<br/></p>
<p>Let <span class="math inline">\(M\)</span> and <span class="math inline">\(M_0\)</span> be the orthogonal projection onto <span class="math inline">\(\mathcal{C}(X)\)</span> and <span class="math inline">\(\mathcal{C}(X_0)\)</span> respectively.</p>
<p>Note that with <span class="math inline">\(\mathcal{C}(X_0) \subset \mathcal{C}(X)\)</span>, <span class="math inline">\(M - M_0\)</span> is the orthogonal projection onto the orthogonal complement of <span class="math inline">\(\mathcal{C}(X_0)\)</span> with respect to <span class="math inline">\(\mathcal{C}(X)\)</span>, that is,</p>
<p>$
<span class="math display">\[\begin{align}

\mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp  &amp;= \mathcal{C}(M - M_0) \\

&amp;= \mathcal{C}(M \cap M_0^\perp ) \\

\\\

\hat\mu &amp;= \hat E(Y) = MY \tag{under FM}



\\

\hat\mu_0 &amp;= \hat E(Y) = M_0 Y \tag{under RM}





\end{align}\]</span>
$</p>
<p>If RM is true, then <span class="math inline">\(MY-M_0 Y = (M - M_0)Y\)</span> should be reasonably small. Note that <span class="math inline">\(E(M-M_0)Y = 0\)</span>.</p>
<p><br/>
<br/>
<br/></p>
<p>The decision about whether RM is appropriate hinges on deciding whether the vector <span class="math inline">\((M - M_0)Y\)</span> is large.</p>
<p>The size of <span class="math inline">\((M - M_0)Y\)</span>’s <strong>obvious measure</strong> is <span class="math inline">\([(M - M_0)Y]&#39;[(M - M_0)Y] = Y&#39;(M-M_0)Y\)</span>.</p>
<p>The size of <span class="math inline">\((M - M_0)Y\)</span>’s <strong>reasonable measure</strong> is given by <span class="math inline">\(\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}\)</span>.</p>
<ul>
<li>※ Note that $E (  ) = ^2 +  $.</li>
</ul>
<p><br/>
<br/>
<br/></p>
<ul>
<li>Theorem 3.2.1.</li>
</ul>
<p>Consider</p>
<p>$
Y=X + , ; ; ; ; ; N(0, ; I_n) , ; ; ; ; ; (X_0) (X) \</p>
<p>\
\</p>
<p><span class="math display">\[\begin{alignat}{2}


Y &amp;= X_0 \beta_0 + X_1 \beta_1 &amp;&amp;+ \epsilon \tag{Full Model, FM}

\\


Y &amp;= X_0 \gamma &amp;&amp;+ \epsilon \tag{Reduced Model, RM}

\end{alignat}\]</span></p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\dfrac
{\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}}
{\dfrac{Y&#39;(I-M)Y}{r(I-M)}}



&amp;=


\dfrac
{\dfrac{Y&#39;(M-M_0)Y}{df_1}}
{\dfrac{Y&#39;(I-M)Y}{df_2}} 




&amp;&amp;\sim 


F \Bigg( df_1 , df_2, \dfrac{\beta&#39; X&#39; (M-M_0)X \beta }{2 \sigma^2} 



&amp;&amp; \Bigg) \tag{Under the FM}

\\

\\\


\\\




\dfrac
{\dfrac{Y&#39;(M-M_0)Y}{r(M-M_0)}}
{\dfrac{Y&#39;(I-M)Y}{r(I-M)}}



&amp;=


\dfrac
{\dfrac{Y&#39;(M-M_0)Y}{df_1}}
{\dfrac{Y&#39;(I-M)Y}{df_2}}


&amp;&amp;\sim 


F \big( df_1 , df_2, 0 

&amp;&amp; \big) 

\tag{Under the RM}

\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<ul>
<li>Note: Example 3.2.2.; pp. 58–59</li>
</ul>
<p>$
<span class="math display">\[\begin{alignat}{2}


M-M_0 &amp;= (I-M_0) &amp;&amp;-(I-M)

\\

Y&#39;(M-M_0)Y &amp;= Y&#39;(I-M_0)Y &amp;&amp;-Y&#39;(I-M)Y

\\

 &amp;= SSE_{RM} &amp;&amp;-SSE_{FM}




\end{alignat}\]</span>
$</p>
</div>
<div id="a-generalized-test-procedure" class="section level3" number="6.5.3">
<h3 number="6.5.3"><span class="header-section-number">6.5.3</span> A Generalized Test Procedure</h3>
<p>Assume that <span class="math inline">\(Y = X \beta + \epsilon\)</span> is correct. Want to test the adequacy of a model <span class="math inline">\(Y = X_0 \gamma + Xb + \epsilon\)</span>, where <span class="math inline">\(\mathcal{C}(X_0) \subset \mathcal{C}(X)\)</span> and some known vector <span class="math inline">\(Xb=\)</span> offset.</p>
<p><br/>
<br/></p>
<ul>
<li>Example 3.2.3.; Multiple Regression</li>
</ul>
<p>$
Y = _0 J + _1 X_1 + _2 X_2 + _3 X_3 + 
$</p>
<p>want to test <span class="math inline">\(H_0: \beta_2 = \beta_3+5, \; beta_1 = 0, \cdots\)</span>.</p>
<p>$
<span class="math display">\[\begin{alignat}{2}


Y &amp;= X \beta &amp;&amp; &amp;&amp;+ \epsilon \tag{FM}

\\

Y^\ast &amp;\equiv Y &amp;&amp; - X b &amp;&amp;

\\

&amp;=X \beta &amp;&amp; - Xb &amp;&amp;+ \epsilon

\\

&amp;=X (\beta &amp;&amp; - b) &amp;&amp;+ \epsilon


\\

&amp;=X \beta^\ast &amp;&amp; &amp;&amp;+ \epsilon \tag{FM}

\\
\\\
\\\


Y &amp;= X_0 \gamma &amp;&amp; + Xb &amp;&amp;+ \epsilon \tag{RM}

\\

Y^\ast &amp;\equiv Y &amp;&amp; &amp;&amp; &amp;&amp; - X b 

\\

&amp;=X \gamma &amp;&amp;  &amp;&amp;+ \epsilon \tag{RM}




\end{alignat}\]</span>
$</p>
<p><br/>
<br/></p>
<p>In addition, when <span class="math inline">\(Y^\ast = Y_\ast\)</span>,</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\dfrac
{\dfrac{ Y_\ast &#39; (M-M_0) Y_\ast }{ r(M-M_0)}}
{\dfrac{ Y_\ast &#39; (I-M) Y_\ast }{r(I-M)}}

&amp;\sim F \Big( r(M-M_0), r(I-M), \delta^2 \Big)

\\
\\

\delta^2 &amp;=\dfrac{1}{2 \sigma^2} \Big( {\beta^\ast} &#39; X &#39; (M-M_0) X \beta^\ast \Big) \tag{non-centrality parameter}


\end{alignat}\]</span>
$</p>
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

0 &amp;= \beta_\ast &#39;  X&#39; &amp;&amp;(M-M_0) X \beta_\ast


\\


&amp;\Updownarrow   

\\


0 &amp;= &amp;&amp;(M-M_0)X \beta_\ast

\\

&amp;\Updownarrow   


\\

X\beta &amp; = M_0 (X &amp;&amp;\beta - X b) + Xb \tag{3}

\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<ol start="3" style="list-style-type: decimal">
<li>will hold if</li>
</ol>
<p>$
<span class="math display">\[\begin{align}
\gamma &amp;= (X_0 &#39; X_0)^- X_0(X \beta - Xb) \\

&amp;= (X_0 &#39; X_0)^- X_0 X \beta_\ast 

\end{align}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<p>Furthermore,</p>
<p>$
<span class="math display">\[\begin{alignat}{2}
Y_\ast &#39; (M-M_0)Y_\ast &amp;= 


Y_\ast &#39; (I-M_0)Y_\ast &amp;&amp;- &amp;&amp;Y_\ast &#39; (I-M)Y_\ast  \; \; \; \; \;\text{ , and }




\\

Y &#39; (I-M)Y &amp;= &amp;&amp; &amp;&amp; Y_\ast &#39; (I-M)Y_\ast  




\end{alignat}\]</span></p>
<p>$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="testing-linear-parametric-functions" class="section level3" number="6.5.4">
<h3 number="6.5.4"><span class="header-section-number">6.5.4</span> Testing Linear Parametric Functions</h3>
<p><span class="math inline">\(H_0: Y= X \beta + \epsilon, \; \; \; \; \; \Lambda&#39; \beta=0 \tag{1}\)</span></p>
<p>$
<span class="math display">\[\begin{alignat}{2}


\Lambda &#39; \beta = 0 \; \; \; &amp;\iff \beta &amp;&amp;\in \mathcal{N}(\Lambda &#39;) = \mathcal{C}(X)^\perp

\\

&amp;\iff \beta \perp \mathcal{C}(\Lambda)



\\

&amp;\iff \beta \perp \mathcal{C}(\Gamma) \; \; \; \; \; \; \; \; \; \; &amp;&amp;\text{ if } \exists\Gamma \; \; s.t. \; \mathcal{C}(\Gamma) = \mathcal{C}(\Lambda)

\\

&amp;\iff \beta \perp \mathcal{C}(U) &amp;&amp;\text{ if } \exists U \; \; s.t. \; \mathcal{C}(U) = \mathcal{C}(\Lambda)^\perp

\\

&amp;\iff \beta = U_\gamma &amp;&amp; \exists \gamma \tag{2}



\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<p>Thus, letting <span class="math inline">\(X_0 = XU\)</span>, (in general, <span class="math inline">\(\mathcal{C}(X_0) \subset \mathcal{C}(X)\)</span>), then</p>
<p>$
<span class="math display">\[\begin{alignat}{2}



Y &amp;= X \beta &amp;&amp;+ \epsilon

\\

&amp;= X U \gamma &amp;&amp;+ \epsilon

\\

&amp;= X_0 \gamma &amp;&amp;+ \epsilon \tag{3}

\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<p>Suppose <span class="math inline">\(\mathcal{C}(X_0) = \mathcal{C}(X)\)</span>. Then there is nothing to test and <span class="math inline">\(\Lambda&#39; \beta = 0\)</span> involves only arbitrary side conditions that do not affect the model. (EXAMPLE 3.3.1. pp. 62–64)</p>
<p>$
’ ; ;  ; ; ; ; P:= X’ P
$</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

\mathcal{C}(MP) &amp;\equiv \mathcal{C}(M-M_0) \\




&amp;= \mathcal{C}(X-X_0) \\



&amp;= \mathcal{C}(X) \; \cap \; \mathcal{C}(X_0)^\perp\\


&amp;= \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp


\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<p>thus, its distribution for testing <span class="math inline">\(H_0: \Lambda &#39; \beta = 0\)</span> is given by</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\dfrac
{\dfrac{Y&#39;(M_{MP})Y}{r(M_{MP})}}
{\dfrac{Y&#39;(I-M)Y}{r(I-M)}}

&amp;\sim F \Big( r(M_{MP}), r(I-M), \delta^2 \Big)

 \tag{5}

\\
\\\

\delta^2 &amp;= \beta &#39; X&#39; M_{MP}X \beta

 \tag{non-centrality parameter}





\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 3.3.2</li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

\mathcal{C}(M-M_0) 


&amp;= \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp \\

&amp;= \mathcal{C}(XU)_{\mathcal{C}(X)}^\perp


= \mathcal{C}(MP) 

\end{alignat}\]</span></p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

H_0: Y=X\beta + \epsilon, \; \; \; \; \; \Lambda &#39; \beta = 0

\\

\Updownarrow

\\

H_0: Y=X\beta + \epsilon, \; \; \; \; \; P&#39;X \beta = 0

\\

\Updownarrow

\\


H_0: Y=X\beta + \epsilon, \; \; \; \; \; P&#39;MX \beta = 0 (\because MX = X)

\\

\Updownarrow

\\

E(Y) \in \mathcal{C}(X), \; \; \; \; E(Y) \perp \mathcal{C}(MP)

\\

\Updownarrow

\\

E(Y) \in \mathcal{C}(X) \; \cap \;  \mathcal{C}(MP)^\perp, \; \; \; \; 
\mathcal{C}(X_0)=\mathcal{C}(X) \; \cap \; \mathcal{C}(MP)^\perp = \mathcal{C}(MP)^\perp_{\mathcal{C}(X)}

\Longrightarrow

\mathcal{C}(X_0)^\perp_{\mathcal{C}(X)} = \mathcal{C}(MP)





\\

\Updownarrow

\\




X_0 = (I-M_{MP})X








\end{alignat}\]</span></p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

\mathcal{C} \Big[ (I-M_{MP})X \ \Big] 


&amp;= \mathcal{C} (X) \; \cap \; \mathcal{C} (MP)^\perp \\

&amp;= \mathcal{C} (X) \; \cap \; \mathcal{C} (P)^\perp \tag{EXAMPLE 3.3.4.: pp.66–67}


\end{align}\]</span>
$</p>
<p>let <span class="math inline">\(\Lambda &#39; \beta\)</span> is estimable, i.e., <span class="math inline">\(\Lambda = X&#39;P\)</span>. then <span class="math inline">\(\mathcal{C}(\Lambda) = \mathcal{C}(X&#39;P) =\mathcal{C}(MP)\)</span>, and <span class="math inline">\(X \hat \beta = MY\)</span>, and <span class="math inline">\(\Lambda &#39; \hat \beta = P&#39; X \hat \beta = P&#39; M Y\)</span>. then</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

Y&#39; M_{MP}Y &amp;= Y&#39; M &amp;&amp; (P&#39;  M  P)^- &amp;&amp; MPY




\\

&amp;= \hat \beta &#39; \Lambda  &amp;&amp; [P&#39; X(X&#39;X)^-X&#39; P]^- &amp;&amp; \Lambda &#39; \hat \beta

\\

&amp;= \hat \beta &#39; \Lambda  &amp;&amp; [\Lambda&#39; (X&#39;X)^- \Lambda]^- &amp;&amp; \Lambda &#39; \hat \beta






\end{align}\]</span></p>
<p>$</p>
<p><strong><em>이윗부분 전혀모르겠음</em></strong></p>
<p><br/>
<br/></p>
<p>thus,</p>
<p>$
<span class="math display">\[\begin{align}
(5) = \dfrac{\dfrac{\hat \beta &#39; \Lambda [\Lambda &#39; (X&#39;X)^- \Lambda]^- \Lambda&#39; \hat \beta}{r(\Lambda)}}{MSE} &amp;\sim F \Big( r(MP), r(I-M), \delta^2 \Big)\\


\\\
\\\



\delta^2  &amp;= \dfrac{\hat \beta &#39; \Lambda [\Lambda &#39; (X&#39;X)^- \Lambda]^- \Lambda&#39; \hat \beta}{2 \sigma^2} \\

Cov\Big(\Lambda &#39; \hat \beta \Big)  &amp;= \sigma^2 \Lambda &#39; (X&#39; X)^{-} \Lambda 



\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<p>For <span class="math inline">\(H_0: \lambda &#39; \beta =0, \; \; \; \lambda \in \mathbb{R}^p\)</span>,</p>
<p>$</p>
<p><span class="math display">\[\begin{align}


Y&#39;M_{MP}Y &amp;= \hat \beta &#39; \lambda \big [\lambda &#39; (X&#39;X)^- \lambda \big]^- \lambda&#39; \hat \beta

\\

&amp;=\dfrac{\big( \lambda&#39; \hat \beta \big)^2}{\lambda&#39;(X&#39;X)^-\lambda}

\end{align}\]</span></p>
<p>$</p>
<p><br/>
<br/></p>
<p>and, under <span class="math inline">\(H_0: \lambda &#39; \beta =0\)</span>,</p>
<p>$
F = (5) =  F ( 1, ; r(I-M) )
$</p>
<p><br/>
<br/></p>
<ul>
<li>Definition 3.3.5.</li>
</ul>
<p>The condition <span class="math inline">\(E(Y) \perp \mathcal{C}(MP)\)</span> is called the constraint by <span class="math inline">\(\Lambda &#39; \beta = 0\)</span> where <span class="math inline">\(\Lambda = X&#39; P\)</span>. in other words, <span class="math inline">\(\mathcal{C}(MP)\)</span> is the <strong>constraint</strong> by <span class="math inline">\(\Lambda &#39; \beta = 0\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Do Exercise 3.5:</li>
</ul>
<p>Show that a necessary and sufficient condition for <span class="math inline">\(\rho_1 &#39; X \beta = 0\)</span> and <span class="math inline">\(\rho_2 &#39; X \beta = 0\)</span> to determine the orthogonal constraints on the model is that <span class="math inline">\(\rho_1 &#39; X \rho_2 = 0\)</span></p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="theoretical-complements" class="section level3" number="6.5.5">
<h3 number="6.5.5"><span class="header-section-number">6.5.5</span> Theoretical Complements</h3>
<p>Consider testing <span class="math inline">\(\Lambda &#39; \beta = 0\)</span> when <span class="math inline">\(\Lambda &#39; \beta\)</span> is NOT estimable.</p>
<p>let <span class="math inline">\(\Lambda_0 &#39; \beta\)</span> be estimable part of <span class="math inline">\(\Lambda &#39; \beta\)</span>.</p>
<p><span class="math inline">\(\Lambda_0\)</span> is chosen, so that <span class="math inline">\(\mathcal{C}(\Lambda_0) = \mathcal{C}(\Lambda) \; \cap \; \mathcal{C}(X&#39;)\)</span>, which means that <span class="math inline">\(\Lambda &#39; \beta = 0\)</span> implies that <span class="math inline">\(\Lambda_0 &#39; \beta = 0\)</span> but <span class="math inline">\(\Lambda_0 &#39; \beta\)</span> is <strong>estimable</strong>, because <span class="math inline">\(\mathcal{C}(\Lambda_0) \subset \mathcal{C}(X&#39;)\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 3.3.6.</li>
</ul>
<p>let <span class="math inline">\(\mathcal{C}(\Lambda_0) = \mathcal{C}(\Lambda) \; \cap \; \mathcal{C}(X&#39;)\)</span> and <span class="math inline">\(\mathcal{C}(U_0) = \mathcal{C}(\Lambda_0)^\perp\)</span>. Then <span class="math inline">\(\mathcal{C}(XU) = \mathcal{C}(XU_0)\)</span>. Thus <span class="math inline">\(\Lambda &#39; \beta = 0\)</span> and <span class="math inline">\(\Lambda_0 &#39; \beta = 0\)</span> induce the same RM.</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 3.3.7.</li>
</ul>
<p>let <span class="math inline">\(\Lambda_0 &#39; \beta\)</span> be estimable and <span class="math inline">\(\Lambda \not = 0\)</span>. then <span class="math inline">\(\Lambda &#39; \beta = 0 \; \; \Longrightarrow \; \; \mathcal{C}(XU) \not = \mathcal{C}(X)\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Corollary 3.3.8.</li>
</ul>
<p>$</p>
<p>(_0) = () ; ; (X’) = {0 }</p>
<p>\</p>
<p>\</p>
<p>(XU) ; ; (X)</p>
<p>$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="a-generalized-test-procedure-1" class="section level3" number="6.5.6">
<h3 number="6.5.6"><span class="header-section-number">6.5.6</span> A Generalized Test Procedure</h3>
<p>Consider as below, whose column space is solvable.</p>
<p><span class="math inline">\(H_0: \Lambda&#39; \beta = d, \; \; \; \; \; d \in \mathcal{C}(X&#39;), \; \; \; \; \Lambda&#39; b =d\)</span></p>
<p>$
<span class="math display">\[\begin{alignat}{2}




\Lambda &#39; \beta = 

\Lambda &#39; b =  d



 \; \; \; &amp;\iff \Lambda &#39; (\beta - b) &amp;&amp;= 0





\\

&amp;\iff (\beta - b) &amp;&amp;\perp \mathcal{C}(\Lambda)

\\

&amp;\iff (\beta - b) &amp;&amp;\in \mathcal{C}(U) \; \; \; \; \; \; &amp;&amp;\text{where } \; \mathcal{C}(U) = \mathcal{C}(\Lambda)^\perp

\\

&amp;\iff (\beta - b) &amp;&amp;= U_\gamma &amp;&amp;\exists \gamma


\\

&amp;\iff X\beta - Xb &amp;&amp;= XU_\gamma

\\

&amp; \; \; \; \Updownarrow

\\

X\beta  &amp;= XU_\gamma + Xb, \\

Y &amp;= X \beta + \epsilon \\
&amp;= X U_\gamma + Xb + \epsilon \\
&amp;= X_0 \gamma + Xb + \epsilon, &amp;&amp; &amp;&amp; \text{where } \; X_0 = XU








\end{alignat}\]</span></p>
<p>$</p>
<p>if <span class="math inline">\(\Lambda = X&#39;P\)</span>, then <span class="math inline">\(\mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp = \mathcal{C}(MP)\)</span> and its test statistics is</p>
<p>$
<span class="math display">\[\begin{align}



F = \dfrac
{\dfrac{(Y-Xb)&#39;M_{MP}(Y-Xb)}{r \Big(M_{MP} \Big)}}
{\dfrac{(Y-Xb)&#39;(I-M)(Y-Xb)}{r \Big(I-M \Big)}}

= 






\dfrac
{\dfrac{(\Lambda &#39; \hat \beta - d)&#39; \Big[ \Lambda&#39;(X&#39;X)^{-}\Lambda \Big]^- (\Lambda &#39; \hat \beta - d)}{r(\Lambda)}}
{MSE}


\sim F(?, ?, ?)

\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>Remark: (EXAMPLE 3.3.9.: pp.71–72, EXAMPLE 3.4.1.: pp.75)</li>
</ul>
<p>If <span class="math inline">\(\Lambda &#39; \beta = d\)</span>, the same reduced model results if we take <span class="math inline">\(\Lambda &#39; \beta = d_0\)</span>, where <span class="math inline">\(d_0 = d + \Lambda &#39; \nu\)</span> and <span class="math inline">\(\nu \perp \mathcal{C}(X&#39;)\)</span>. Note that, in this construction, if <span class="math inline">\(\Lambda &#39; \beta = d\)</span> is estimable, <span class="math inline">\(d_0 = d\)</span> for any <span class="math inline">\(\nu\)</span>.</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="testing-single-degrees-of-freedom-in-a-given-subspace" class="section level3" number="6.5.7">
<h3 number="6.5.7"><span class="header-section-number">6.5.7</span> Testing Single Degrees of Freedom in a Given Subspace</h3>
<p>$
RM: Y=X_ 0 + ; ; ; ; ; vs. ; ; ; ; ;</p>
<p>FM: Y=X + , ; ; ; ; ; with; ; (X_0) (X)</p>
<p>$</p>
<p>let <span class="math inline">\(M_\ast = M - M_0\)</span>, consider <span class="math inline">\(H_0 : \Lambda &#39; \beta = 0\)</span>.</p>
<p>if <span class="math inline">\(\Lambda = X&#39;P\)</span>, i.e. <span class="math inline">\(\Lambda \in \mathcal{C}(X&#39;)\)</span>, then <span class="math inline">\(M_\ast = M_{MP}\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Proposition 3.3.2</li>
</ul>
<p>Since <span class="math inline">\(M M_\ast = M_\ast\)</span>,</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

&amp;\mathcal{C}(M - M_0) = \mathcal{C}(X_0)_{\mathcal{C}(X)}^\perp \equiv \mathcal{C}(XU)_{\mathcal{C}(X)}^\perp = \mathcal{C}(MP)

\\

\Longrightarrow \; \; \; 

&amp;M \rho \in \mathcal{C}(M_\ast)


\\

\Longrightarrow \; \; \; 

&amp;M \rho = M_\ast M \rho =  M_\ast \rho


\\

\Longrightarrow \; \; \; 

&amp;\rho &#39; \hat \beta = \rho &#39; M_\ast Y = \rho &#39; M Y 



\end{align}\]</span>
$</p>
<p>thus the test statistic for <span class="math inline">\(H_0 : \Lambda &#39; \beta = 0\)</span> is</p>
<p>$</p>
<p>=</p>
<p>$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="breaking-ss-into-independent-components" class="section level3" number="6.5.8">
<h3 number="6.5.8"><span class="header-section-number">6.5.8</span> Breaking SS into Independent Components</h3>
<p>Consider <span class="math inline">\(X = \begin{pmatrix} X_0, &amp; X_1 \end{pmatrix}\)</span>. set</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}
&amp;SSR(X_1 \vert X_0) &amp;&amp;\equiv Y &#39; (M-M_0)Y &amp;&amp; \tag{Sum of Squares for regression X1 after X0}\\

&amp;SSR(X) &amp;&amp;\equiv Y &#39; MY \\

&amp;SSR(X_0) &amp;&amp;\equiv Y &#39; M_0 Y \\

&amp;SSR(X) &amp;&amp;= SSR(X_0) &amp;&amp;+ SSR (X_1 \vert X_0)

\end{alignat}\]</span>
$</p>
<ul>
<li>Note: if <span class="math inline">\(\epsilon \sim N(0, \; \sigma I)\)</span>, then <span class="math inline">\(SSR(X_0) \perp SsR(X_1 \vert X_0)\)</span>.</li>
</ul>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="general-theory" class="section level3" number="6.5.9">
<h3 number="6.5.9"><span class="header-section-number">6.5.9</span> General Theory</h3>
<p>Let <span class="math inline">\(M\)</span> and <span class="math inline">\(M_\ast\)</span> be the orthogonal projection operator into <span class="math inline">\(\mathcal{C}(X)\)</span> and <span class="math inline">\(\mathcal{C}(X_\ast)\)</span> respectively. Then, with <span class="math inline">\(\mathcal{C}(X_\ast) \subset \mathcal{C}(X)\)</span>, <span class="math inline">\(M_\ast\)</span> defines a test statistic as below.</p>
<p>$</p>
<p>{}
{}</p>
<p>; ; ; :Y = X_+ </p>
<p>$</p>
<p>$
<span class="math display">\[\begin{align}

&amp;I-(M-M_\ast ) &amp;&amp;= (I-M) + M_\ast

\\

&amp;\mathcal{C}(M-M_\ast) &amp;&amp;:\tag{Estimation Space, under H0}

\\

&amp;\mathcal{C}(M_\ast)  &amp;&amp;:\tag{Test Space, under H0}

\\


&amp;\mathcal{C} \Big(I - (M-M_\ast)\Big)  &amp;&amp;:\tag{Error Space, under H0}





\end{align}\]</span></p>
<p>$</p>
<p>Using Gram-Schmidt procedure, let’s construct <span class="math inline">\(M_\ast\)</span> so that</p>
<p>$</p>
<p>M_= RR’ = <em>{i=1}^r R_iR_i ’ = </em>{i=1}^r M_i, ; ; ; ; ; R=(R_1 , , R_r)</p>
<p>$</p>
<p>and <span class="math inline">\(M_i M_j=0\)</span> for <span class="math inline">\(i \not = j\)</span>. By <strong>Theorem 1.3.7</strong>,</p>
<p>$
Y’M_i Y Y’M_j Y ; ; ; ; ; ; M_i M_j =0
$</p>
<p>Next, $ Y’M Y = _{i=1}^r Y’M_i Y $, therefore when <span class="math inline">\(r(M_i)=1\)</span>,</p>
<p>$</p>
<p>{}
{}</p>
<p>F ( 1, r(I-M),  ’ X’ M_i X )</p>
<p>$</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}

&amp; &amp;&amp; &amp;&amp;   &amp;&amp;\beta &#39; X&#39; M_\ast X \beta \; \; &amp;&amp;= \; \; \sum_{i=1}^r \beta &#39; X&#39; M_i X \beta  &amp;&amp;  =0

\; \; \;

\\

&amp;\iff &amp;&amp; &amp;&amp; \forall i \; \; : \; \; &amp;&amp; \beta &#39; X&#39; M_i X \beta &amp;&amp; &amp;&amp;=0

\\

&amp;\iff &amp;&amp; &amp;&amp;\forall i \; \; : \; \; &amp;&amp;R_i &#39; X \beta &amp;&amp; &amp;&amp;= 0

\\

&amp;\iff &amp;&amp; &amp;&amp; &amp;&amp;H_0 \text{ is true.}




\end{alignat}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>EXAMPLE 3.6.1.: Balanced design; pp.79–80</li>
<li>EXAMPLE 3.6.2.: Unbalanced design;pp.80–81</li>
</ul>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="two-way-anova" class="section level3" number="6.5.10">
<h3 number="6.5.10"><span class="header-section-number">6.5.10</span> Two-Way ANOVA</h3>
<p>$
<span class="math display">\[\begin{alignat}{2}
y_{ijk} &amp;= \mu + \alpha_i + \eta_j &amp;&amp;+ \epsilon_{ijk} \tag{FM}

\\





y_{ijk} &amp;= \mu + \alpha_i  &amp;&amp;+ \epsilon_{ijk} \tag{RM}


\end{alignat}\]</span>
$</p>
<p>$
<span class="math display">\[\begin{align}
M &amp;= M_\mu + M_\alpha + M_\eta

\\

Y&#39;(M-M_0)Y &amp;= R(\eta \; \Big \vert \; \alpha, \; \mu) \tag{1}


\end{align}\]</span>
$</p>
<ol style="list-style-type: decimal">
<li>Reduction in SSE, due to fitting <span class="math inline">\(\eta_j\)</span>’s after <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\alpha_i\)</span>’s.</li>
</ol>
<p>Next,</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}
y_{ijk} &amp;= \mu + \alpha_i &amp;&amp;+ \epsilon_{ijk} \tag{FM}

\\





y_{ijk} &amp;= \mu &amp;&amp;+ \epsilon_{ijk} \tag{RM}


\\

\\\

\\\


Y&#39;(M_0-M_J)Y &amp;= R(\alpha \; \Big \vert \; \mu) 

\\

Y&#39;(M-M_J)Y &amp;= R(\alpha, \; \eta \; \Big \vert \; \mu)

\\

&amp;= R(\eta \; \Big \vert \; \mu, \; \alpha) &amp;&amp;+ R(\alpha \; \Big \vert \; \mu)  



\end{alignat}\]</span></p>
<p>$</p>
<p>In general,</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) &amp;\not = R(\eta \; \Big \vert \; \mu)  
 
\\

R(\alpha \; \Big \vert \; \eta, \; \mu) &amp; \not = R(\alpha \; \Big \vert \; \mu)  
 


\end{alignat}\]</span></p>
<p>$</p>
<p>In paricular, for balanced design, if <span class="math inline">\(\mathcal{C}(X_\alpha) \perp \mathcal{C}(X_\eta)\)</span>,</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) &amp; = R(\eta \; \Big \vert \; \mu)  
 
\\

R(\alpha \; \Big \vert \; \eta, \; \mu) &amp; = R(\alpha \; \Big \vert \; \mu)  
 


\end{alignat}\]</span></p>
<p>$</p>
<ul>
<li>Proposition 3.6.3.</li>
</ul>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}


R(\eta \; \Big \vert \; \alpha, \; \mu) &amp; = R(\eta \; \Big \vert \; \mu)  
 


\; \; \; \; \; &amp;&amp;\iff \; \; \; \; \;


\mathcal{C}(X_1 - M_j) \perp \mathcal{C}(X_0 - M_j)

\\



\text{that is}\; \; \; \; \; \; \; 


M_1 - M_J&amp; = M-M_0
 


\; \; \; \; \; &amp;&amp;\iff \; \; \; \; \;


(M_1 - M_J)(M_0 - M_J) = 0, 


\; \; \; \; \; \text{where} \; &amp;&amp;R(\eta \; \Big \vert \; \alpha, \; \mu) &amp;&amp;= Y&#39;(M-M_0)Y

\\

&amp; &amp;&amp; &amp;&amp; R(\eta \; \Big \vert \; \mu) &amp;&amp;= Y&#39;(M_1 -M_0)Y

\end{alignat}\]</span></p>
<p>$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="confidence-regions" class="section level3" number="6.5.11">
<h3 number="6.5.11"><span class="header-section-number">6.5.11</span> Confidence Regions</h3>
<p><span class="math inline">\(100(1-\alpha)\%\)</span> Confidence Region(CR) for <span class="math inline">\(\Lambda &#39; \beta\)</span> consists of all the vectors <span class="math inline">\(d\)</span> satisfying the inequality</p>
<p>$</p>
<p>{}
{MSE}</p>
<p>( 1- , ; r(), ; r(I-M) )</p>
<p>$</p>
<p>These vectors form an ellipsoid in <span class="math inline">\(r(\Lambda)\)</span>-dimensional space.</p>
<p>For regression problems, if we take <span class="math inline">\(P&#39; = (X&#39;X)^{-1}X&#39;\)</span>, then <span class="math inline">\(\Lambda&#39;\beta = P&#39; X \beta = \beta = d\)</span>.</p>
<p>The <span class="math inline">\(100(1-\alpha)\%\)</span> CR is</p>
<p>$
<span class="math display">\[\begin{alignat}{2}


&amp;
\dfrac
{\dfrac{\Big[\Lambda &#39; \hat \beta - d\Big]&#39; \Big[\Lambda &#39; (X&#39;X)^- \Lambda\Big]^- \Big[\Lambda &#39; \hat \beta - d\Big]}{r(\Lambda)}}
{MSE}

\; \; \; 
&amp;&amp;
= 

\; \; \; 
&amp;
\dfrac
{\dfrac{\Big(\hat \beta - \beta \Big)&#39; \Big( X&#39;X \Big)\Big(\hat \beta - \beta \Big)}

{p}}
{MSE}

\; \; \; 

&amp;&amp;\le 

\; \; \; 
\Big( 1- \alpha, \; p, \; n-p \Big)


\end{alignat}\]</span></p>
<p>$</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="tests-for-generalized-least-squares-models" class="section level3" number="6.5.12">
<h3 number="6.5.12"><span class="header-section-number">6.5.12</span> Tests for Generalized Least Squares Models</h3>
<p>$
<span class="math display">\[\begin{alignat}{4}

&amp;Y &amp;&amp;= &amp;&amp;X \beta &amp;&amp;+ &amp;&amp;\epsilon \; \; \; \; \; &amp;&amp;vs. \; \; \; \; \; &amp;&amp;Y = &amp;&amp;X_0 \beta_0 &amp;&amp;+ &amp;&amp;\epsilon

, \; \; \; \; \; &amp;&amp; \epsilon \sim N(0, \; \sigma^2 V)



\tag{1}

\\


&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp; \Updownarrow

\\







Q^{-1}&amp;Y &amp;&amp;= Q^{-1} &amp;&amp;X \beta &amp;&amp;+ Q^{-1} &amp;&amp;\epsilon \; \; \; \; \; \; \; \;  \; &amp;&amp;vs. \; \; \; \; \; Q^{-1} &amp;&amp;Y = Q^{-1} &amp;&amp;X_0 \beta_0 &amp;&amp;+ Q^{-1} &amp;&amp;\epsilon



, \; \; \; \; \; Q^{-1} &amp;&amp; \epsilon \sim N(0, \; \sigma^2 I)

\tag{2}

\end{alignat}\]</span>
$</p>
<p>test (1) and (2) is equal.</p>
<ul>
<li>Note: <span class="math inline">\(\mathcal{C}(Q^{-1}X_0) \subset \mathcal{C}(Q^{-1}X)\)</span>.</li>
</ul>
<p><br/>
<br/></p>
<p>From Section 2.7,</p>
<p>$
<span class="math display">\[\begin{align}


A &amp;= X(X&#39;V^{-1}X)^- X&#39; \ast V^{-1}

\\
\\

MSE &amp;= \dfrac{Y&#39; (I-A)&#39; V^{-1} (I-A)Y}{n-r(X)}

\\
\\

A_0 &amp;= X_0(X_0&#39;V^{-1}X_0)^- X_0&#39; \ast V^{-1}

\end{align}\]</span>
$</p>
<ul>
<li>Theorem 3.8.1</li>
</ul>
<p>$
<span class="math display">\[\begin{align}

\dfrac{\dfrac{Y&#39; (A-A_0) V^{-1} (A-A_0)Y}{r(X) - r(X_0 )}}{MSE} &amp;\sim F \Big( r(X)-r(X_0), \; n-r(X) , \; \delta^2 \Big)

\\
\\

\delta^2 &amp;= \dfrac{\beta &#39; X&#39; (A-A_0) V^{-1} (A-A_0)X \beta}{2\sigma^2} \tag{1}


\\

\\

\\\


{\beta &#39; X&#39; (A-A0) V^{-1} (A-A_0)X \beta} \; \; \; \; \; &amp;\iff \; \; \; \; \; E(Y) \in \mathcal{C}(X_0) \tag{2}


\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 3.8.2</li>
</ul>
<p>let <span class="math inline">\(\Lambda &#39; \beta\)</span> be estimable. then the test statistic for <span class="math inline">\(H_0 : \Lambda &#39; \beta = 0\)</span> is</p>
<p>$
<span class="math display">\[\begin{align}




\dfrac{\dfrac{\hat \beta &#39; \Lambda \Big[ \Lambda &#39; (X&#39;V^{-1}X)^- \Lambda \Big]^- \Lambda &#39; \hat \beta}{r(\Lambda)}}{MSE} &amp;\sim F \Big( r(\lambda), \; n-r(X) , \; \delta^2 \Big)

\\
\\

\delta^2 &amp;= \dfrac{\beta &#39; \Lambda \Big[ \Lambda &#39; (X&#39;V^{-1}X)^- \Lambda \Big]^- \Lambda &#39; \beta}{2\sigma^2} \tag{1}


\\

\\

\\\


{\beta &#39; \Lambda \Big[ \Lambda &#39; (X&#39;V^{-1}X)^- \Lambda \Big]^- \Lambda &#39; \beta} \; \; \; \; \; &amp;\iff \; \; \; \; \; \Lambda &#39; \beta  = 0\tag{2}


\end{align}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 3.8.3</li>
</ul>
<p>$
<span class="math display">\[\begin{align}

\dfrac{Y&#39; (A-A_0) V^{-1} (A-A_0)Y}{\sigma^2} &amp;\sim \chi^2\Big(r(x) - r(X_0), \; \delta^2 \Big)

\\
\\

\delta^2 &amp;= \dfrac{\beta &#39; X&#39; (A-A_0) V^{-1} (A-A_0)X \beta}{2\sigma^2},

\\
\\

\sigma^2 = 0 \; \; \; \; \; &amp;\iff E(Y) \in \mathcal{C}(X_0)




\tag{1}


\\

\\

\\\

\dfrac{\hat \beta &#39; \Lambda \Big[ \Lambda &#39; (X&#39;V^{-1}X)^- \Lambda \Big]^- \Lambda &#39; \hat \beta}{2\sigma^2} 

&amp;\sim \chi^2 \Big( r(\Lambda) , \; \delta^2 \Big)


\\
\\

\delta^2 &amp;= {\hat \beta &#39; \Lambda \Big[ \Lambda &#39; (X&#39;V^{-1}X)^- \Lambda \Big]^- \Lambda &#39; \hat \beta}, 

\\
\\

\sigma^2 = 0 \; \; \; \; \; &amp;\iff \Lambda &#39; \beta = 0 \tag{2}


\end{align}\]</span>
$</p>
<!--chapter:end:211405_Testing.Rmd-->
</div>
</div>
<div id="generalized-least-squares" class="section level2" number="6.6">
<h2 number="6.6"><span class="header-section-number">6.6</span> Generalized Least Squares</h2>
<p>Consider a full rank parameterization</p>
<p>$
Y = X + ; ; ; ; ; ; ; ; ; ; E()=0, ; ; ; Cov() = ^2 &gt;0
$</p>
<p>by SVD of <span class="math inline">\(\Sigma\)</span>,</p>
<p>$</p>
<p><span class="math display">\[\begin{alignat}{2}


\Sigma

&amp;= \Gamma &#39; \Lambda \Gamma
= \Gamma &#39; \Lambda^{\tfrac{1}{2}} \Lambda^{\tfrac{1}{2}}\Gamma
= \Gamma &#39; \Lambda^{\tfrac{1}{2}} \Gamma&#39; \Gamma \Lambda^{\tfrac{1}{2}}\Gamma
= \Lambda^{\tfrac{1}{2}} 

\\

\\

Z &amp;\equiv \Lambda^{-\tfrac{1}{2}} Y = \Lambda^{-\tfrac{1}{2}}(X \beta + \epsilon) = \Lambda^{-\tfrac{1}{2}}X \beta + \Lambda^{-\tfrac{1}{2}} \epsilon = W \beta + \epsilon^\ast

\end{alignat}\]</span></p>
<p>$</p>
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
<p>$
<span class="math display">\[\begin{align}

\hat \beta &amp;= (W&#39;W)^{-1} W&#39; Z = (X&#39; \Sigma^{-1}X)^{-1}X&#39;\Sigma^{-1}Y

\\

E(\hat \beta) &amp;= (X&#39; \Sigma^{-1}X)^{-1} X&#39;\Sigma^{-1} X \beta = \beta

\\

Cov(\hat \beta) &amp;= \sigma^2 (X&#39; \Sigma^{-1}X)^{-1}

\\

\hat \sigma^2 &amp;= \dfrac{\Vert Z - \mu_Z \Vert^2}{n-p} = \dfrac{(Y-\hat \mu)&#39; \Sigma^{-1} (Y-\hat \mu)}{n-p}

\end{align}\]</span>
$</p>
<p>the projection Matrix is $ ^{-} X (X’ <sup>{-1}X)</sup>{-1}X’ ^{-}$, which is symmetric, and hence is an orthogonal projection.</p>
<p>Now all computations have been done in the <span class="math inline">\(z\)</span> coordinates, so in particular <span class="math inline">\(x&#39; \beta\)</span> estimates <span class="math inline">\(\mu_Z = \Sigma^{-\tfrac{1}{2}} \mu\)</span>.</p>
<p>Since linear combinations of Gauss-Markov estimates are Gauss-Markov, it follows immediately that <span class="math inline">\(\hat \mu_Z = \Sigma^{-\tfrac{1}{2}} \hat \mu\)</span>.</p>
<div id="a-direct-solution-via-inner-products" class="section level3" number="6.6.1">
<h3 number="6.6.1"><span class="header-section-number">6.6.1</span> A direct solution via inner products</h3>
<p>We can approach the problem of determining the <strong>Generalized Least Squares</strong> estimators in a different way by viewing <span class="math inline">\(\Sigma\)</span> as determining an intter product.</p>
<p>We do this by returning to first principles, carefully defining means and covariances in a general inner product space.</p>
<p>let <span class="math inline">\(x, \; y \in \mathbb{R}^n\)</span> and <span class="math inline">\((x,y) = x&#39;y\)</span> be the usual innter product.</p>
<p>choose a basis <span class="math inline">\(\{e_1 , \cdots, e_n \}\)</span>, the usual coordinate vectors. then a rvec <span class="math inline">\(x\)</span> has coordinates <span class="math inline">\((e_i, x) = x_i\)</span>.</p>
<p><br/>
<br/>
<br/></p>
<ul>
<li>Definition 1.</li>
</ul>
<p><span class="math inline">\(E(x)=\mu= \begin{pmatrix} \mu_i \end{pmatrix}\)</span> where <span class="math inline">\(\mu_i = E(e_i , \; x)\)</span>. For any <span class="math inline">\(a \in \mathbb{R}^n\)</span>,</p>
<p>$
E( (a, x) ) =</p>
<p>E( (_{i=1}^n a_i e_i, ; x ) ) =</p>
<p>E( _{i=1}^n a_i (e_i, ; x) ) =</p>
<p>_{i=1}^n a_i _i =</p>
<p>(a, ; )
$</p>
<p>thus, another characterization of <span class="math inline">\(\mu\)</span> is: <span class="math inline">\(\mu\)</span> is the unique vector that satisfies <span class="math inline">\(E\Big( (a, x) \Big) = (a, \; \mu)\)</span> for all <span class="math inline">\(a \in \mathbb{R}^n\)</span>.</p>
<p>Now, turn to Cov. use the same set-up as above. if <span class="math inline">\(E(x_i^2)&lt;\infty\)</span>, then <span class="math inline">\(Cov(x_i , x_j) = (x_i = \mu_i) (x_j - \mu_j) = \sigma_{ij} = \sigma_{ji}\)</span> exists for all <span class="math inline">\(i,j\)</span>, and defines <span class="math inline">\(\Sigma = (\sigma_{ij})\)</span>.</p>
<p>For any <span class="math inline">\(a, b \in \mathbb{R}^n\)</span>,</p>
<p>$
Cov( (a, x), (b, x) ) =</p>
<p>E( (<em>{i=1}^n a_i x_i, ; </em>{j=1}^n b_j x_j ) ) =</p>
<p><em>{i=1}^n </em>{j=1}^n a_i b_j Cov(x_i, ; x_j) =</p>
<p><em>{i=1}^n </em>{j=1}^n a_i b_j _{ij}</p>
<p>=(a, b)</p>
<p>$</p>
<p><br/></p>
<ul>
<li>Definition 2</li>
</ul>
<p>Assume <span class="math inline">\(E\Bigg( (a,x)^2 \Bigg) &lt; \infty\)</span>. The unique non-negative definite linear transformation <span class="math inline">\(\Sigma: V \rightarrow V\)</span> that satisfies <span class="math inline">\(Cov\Bigg( (a,x), (b,x) \Bigg) = (a, \Sigma b)\)</span> for all <span class="math inline">\(a, b \in V\)</span> is called the covariance of <span class="math inline">\(X\)</span> and is denoted <span class="math inline">\(Cov(x)\)</span>.</p>
<p><br/></p>
<ul>
<li>Theorem 1</li>
</ul>
<p>let <span class="math inline">\(Y \in V\)</span> with innerproduct <span class="math inline">\((\cdot, \; \cdot)\)</span>, <span class="math inline">\(Cov(Y)=\Sigma\)</span>. Define another inner product <span class="math inline">\((\cdot, \; \cdot )\)</span> on <span class="math inline">\(V\)</span> by <span class="math inline">\([x,y] - (x, \; Ay)\)</span> for some positive definite <span class="math inline">\(A\)</span>. Then the covariance of <span class="math inline">\(X\)</span> in the inner product sapce <span class="math inline">\(V, \; [\cdot, \; \cdot])\)</span> is <span class="math inline">\(\Sigma A\)</span>.</p>
<p><br/></p>
<ul>
<li>Note 1:
This shows that if <span class="math inline">\(Cov(X)\)</span> exists in one inner product, it exists in all inner products.</li>
</ul>
<p>If <span class="math inline">\(Cov(X)=\Sigma\)</span> in <span class="math inline">\(\begin{pmatrix} V &amp; (\cdot, \; \cdot) \end{pmatrix}\)</span>, then if <span class="math inline">\(\Sigma &gt; 0\)</span> in the inner product <span class="math inline">\([x,y] = (x, \; \Sigma^{-1}y)\)</span>, the covariance is <span class="math inline">\(\Sigma^{-1} \Sigma = I\)</span>.</p>
<p><br/></p>
<ul>
<li>Theorem 2</li>
</ul>
<p>Suppose <span class="math inline">\(Cov(X) = \Sigma\)</span> in <span class="math inline">\(\begin{pmatrix} V &amp; (\cdot, \; \cdot) \end{pmatrix}\)</span>. If <span class="math inline">\(\Sigma_1\)</span> is symmetric on <span class="math inline">\(\begin{pmatrix} V &amp; (\cdot, \; \cdot) \end{pmatrix}\)</span>, and <span class="math inline">\(Cov \Big( (a,x) \Big) = (a, \; \Sigma_1 a)\)</span> for all <span class="math inline">\(a \in V\)</span>, then <span class="math inline">\(\Sigma_1 = \Sigma\)</span>. This implies that the covariance is unique.</p>
<p>Consider the inner product sapce given by <span class="math inline">\(\begin{pmatrix} \mathbb{R}^n &amp; (\cdot, \; \cdot) \end{pmatrix}\)</span>, where <span class="math inline">\([x,y] = (x, \; \Sigma^{-1}y)\)</span>, <span class="math inline">\(E(Y)=\mu \in \mathcal{E}\)</span> and <span class="math inline">\(Cov(Y) = \sigma^2 \Sigma\)</span>.</p>
<p>Let <span class="math inline">\(P_\Sigma\)</span> be the projection on <span class="math inline">\(\mathcal{E}\)</span> in this inner product space, and let <span class="math inline">\(Q_\Sigma = I - P_\Sigma\)</span>, so <span class="math inline">\(y = P_{\Sigma} y + Q_{\Sigma} y\)</span>.</p>
<p><br/></p>
<ul>
<li>Theorem 3</li>
</ul>
<p>with <span class="math inline">\([x,y] = (x, \; \Sigma^{-1}y)\)</span>, <span class="math inline">\(P_\Sigma = X(X&#39;\Sigma^{-1} X )^{-1} X&#39; \Sigma^{-1}\)</span> is an orthogonal projection.</p>
<p><br/></p>
<ul>
<li>Theorem 4</li>
</ul>
<p>let the OLS estimate <span class="math inline">\(\hat \beta = (X&#39;X)^{-1}X&#39;Y\)</span> and the GLS estimate <span class="math inline">\(\tilde \beta = (X&#39;\Sigma^{-1}X)^{-1} X&#39; \Sigma^{-1}Y\)</span>. then</p>
<p>$
= ; ; ; ; ; ; ; ; ; ; (^{-1}X) = (X)
$</p>
<p><br/></p>
<ul>
<li>Corollary 1</li>
</ul>
<p><span class="math inline">\(\mathcal{C}(\Sigma^{-1}X) = \mathcal{C}(X)= \mathcal{C}(\Sigma X)\)</span></p>
<p>So <span class="math inline">\(\Sigma\)</span> need not be inverted to apply the theory.</p>
<p>To use this equivalence theorem (due to W. Kruskal), we usually characterize the <span class="math inline">\(\Sigma\)</span>’s for a given <span class="math inline">\(X\)</span> for which <span class="math inline">\(\hat \beta = \tilde \beta\)</span>.</p>
<p>if <span class="math inline">\(X\)</span> is completely arbitrary, then only <span class="math inline">\(\Sigma = \sigma^2 I\)</span> works.</p>
<p><br/></p>
<ul>
<li>Intra-class correlation model:</li>
</ul>
<p>let <span class="math inline">\(J_n \in \mathcal{C}(X)\)</span>. then any <span class="math inline">\(\Sigma\)</span> of the form</p>
<p>$
= ^2 (1-)I + ^2 J_n J_n ’
$</p>
<p>with <span class="math inline">\(-\dfrac{1}{n-1} &lt; \rho &lt; 1\)</span> will work.</p>
<p>to apply the theorem, we write,</p>
<p>$
X = ^2 (1-)X + ^2 J_n J_n ’ X
$</p>
<p>so for <span class="math inline">\(i&gt;1\)</span>, the i-th coluimn of <span class="math inline">\(\Sigma X\)</span> is</p>
<p>$
( X )_i = ^2 (1-)X_i + ^2 J_n a_i
$</p>
<p>with <span class="math inline">\(a_i = J_n &#39; X\)</span>.</p>
<p>Thus, the i-th column of <span class="math inline">\(\Sigma X\)</span> is a linear combination of the i-th column of <span class="math inline">\(X\)</span> and the column of <span class="math inline">\(1\)</span>’s.</p>
<p>For the first column of <span class="math inline">\(\Sigma X\)</span>, we compute <span class="math inline">\(a_1 = J_n\)</span> and <span class="math inline">\(\Big ( \Sigma X \Big)_1 = \sigma^2 (1- \rho) J_n + n \sigma^2 \rho J_n = \sigma^2 \Big ( 1 + \rho(n-1) \Big )J_n\)</span>, So <span class="math inline">\(\mathcal{C}(\Sigma X) = \mathcal{C}(X)\)</span> as required, provided that <span class="math inline">\(1+\rho(n-1) \not = 0\)</span> or <span class="math inline">\(\rho &gt; -\dfrac{1}{n-1}\)</span>.</p>
<!--chapter:end:211406_GeneralizedLeastSquares.Rmd-->
</div>
</div>
<div id="flat" class="section level2" number="6.7">
<h2 number="6.7"><span class="header-section-number">6.7</span> Flat</h2>
<div id="flat-1" class="section level3" number="6.7.1">
<h3 number="6.7.1"><span class="header-section-number">6.7.1</span> 1.Flat</h3>
<p>Sometimes in statistical applications it is useful to consider a linear subspace that is shifted or translated from the origin. This will happen, for example, in models that include an intercept. It is therefore helpful to have the following definition of a space that is displaced from the origin.</p>
<p><br/>
<br/></p>
<ul>
<li>Definition 1 (Flat)</li>
</ul>
<p>suppose <span class="math inline">\(M \subset V\)</span> is a linear subspace, and <span class="math inline">\(y_0 \in V\)</span>. Then a <strong>flat</strong> consists of <span class="math inline">\(\{x + y_0 \; \Big \vert \; x \in M\}\)</span>. We will write <span class="math inline">\(y_0 +M\)</span> where <span class="math inline">\(M\)</span> is a subspace to indicate a flat.</p>
<p>By considering <strong>translations</strong>, <strong>flats</strong> are equivalent to vector spaces. If <span class="math inline">\(Y\)</span> is a rv whose domain is the flat <span class="math inline">\(y_0 +M\)</span>, then, if <span class="math inline">\(y_0\)</span> is fixed, <span class="math inline">\(Y-y_0\)</span> has domain <span class="math inline">\(M\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>example</li>
</ul>
<p>set <span class="math inline">\(S_4 = \{(1,1,1)&#39; + z, \; z \in S_2\}\)</span> is a flat, because <span class="math inline">\(0 \not \in S_4\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>example</li>
</ul>
<p>In <span class="math inline">\(C e^2\)</span>, consider <span class="math inline">\(M= \left \{ \alpha \begin{pmatrix} 1 \\ 2 \end{pmatrix} \Bigg \vert \; \alpha \in C e \right\}\)</span>, and <span class="math inline">\(y_0 = \begin{pmatrix} 2 \\ 2 \end{pmatrix}\)</span>.</p>
<p>Then the flat <span class="math inline">\(y_0 + M\)</span> is given by the set <span class="math inline">\(y_0 + M= \left \{ \begin{pmatrix} 2 \\ 2 \end{pmatrix} + \alpha \begin{pmatrix} 1 \\ 2 \end{pmatrix} \Bigg \vert \; \alpha \in C e \right\}\)</span>.</p>
<p>which is just a straight line that does not pass through the origin, but rather through the point <span class="math inline">\((2,2)\)</span>. The choice of <span class="math inline">\(y_0\)</span> is not unique and it can be any point <span class="math inline">\(y=y_0 + y_\alpha\)</span>, where <span class="math inline">\(y_\alpha = \alpha(1,2)&#39;\)</span>. For example, if <span class="math inline">\(\alpha = -2\)</span>, then <span class="math inline">\(y=(0,-2)&#39;\)</span> and if <span class="math inline">\(\alpha=+1\)</span>, then <span class="math inline">\(y=(3,4)&#39;\)</span>, and so on. For any <span class="math inline">\(y_0\)</span> not of this form, we simply get a different flat. This is summarized in the next remark.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 1</li>
</ul>
<p>The two spans</p>
<p>$
<span class="math display">\[\begin{align}

F_1 &amp;= \left\{ z \; \Big \vert  \; z=y_0 + x, \; \; \; y_0 \in V, \; \; \;  x \in M \subset V \right\}

\\

F_2 &amp;= \left\{ z \; \Big \vert  \; z=y_1 + x, \; \; \; y_1 \in F_1, \; \; \;  x \in M \subset V \right\}


\end{align}\]</span>
$</p>
<p>are the same subspace, so the representation of the flat is not unique.</p>
<p><br/>
<br/></p>
<ul>
<li>Definition 2 (Sum and intersection of subspaces)</li>
</ul>
<p>let <span class="math inline">\(H,K\)</span> be two linear subspaces. Then</p>
<p>$
<span class="math display">\[\begin{alignat}{2}


H + K &amp;= \Big\{ x+y \; &amp;&amp;\Big \vert  \; x \in H, \; \; \;  y \in K \Big\} \tag{sum of H and K}

\\

H \cap K &amp;= \Big\{ x \; &amp;&amp;\Big \vert  \; x \in H, \; \; \;  x \in K \Big\} \tag{intersection of H and K}



\end{alignat}\]</span>
$</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 2</li>
</ul>
<p>Both <span class="math inline">\(H + K\)</span> and <span class="math inline">\(H \cap K\)</span> are linear subspaces.</p>
<p><br/>
<br/></p>
<ul>
<li>Definition 3 (Disjoint subspaces)</li>
</ul>
<p>Two subspaces are <strong>disjoint</strong> if <span class="math inline">\(H \cap K = \big \{ 0 \big \}\)</span>, the <strong>null vector</strong>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 3</li>
</ul>
<p>If <span class="math inline">\(H \cap K = \big \{ 0 \big \}\)</span>, and <span class="math inline">\(z \in H +K\)</span>, then the decomposition <span class="math inline">\(z = x+y\)</span> with <span class="math inline">\(x \in H\)</span> and <span class="math inline">\(y \in K\)</span> is unique.</p>
<p>prf) suppose <span class="math inline">\(z=x+y\)</span> and <span class="math inline">\(z=x&#39; + y&#39;\)</span>. Then, <span class="math inline">\(x-x&#39; \in H\)</span> and <span class="math inline">\(y-y&#39; \in K\)</span>. We must have <span class="math inline">\(x+y = x&#39; + y&#39;\)</span> or <span class="math inline">\(x-x&#39;=y-y&#39;\)</span>, which in turn requires that <span class="math inline">\(x-x&#39; = y-y&#39; = 0\)</span>, since <span class="math inline">\(0\)</span> is the only vector common to <span class="math inline">\(H\)</span> and <span class="math inline">\(K\)</span>. Thus, <span class="math inline">\(x=x&#39;\)</span> and <span class="math inline">\(y=y&#39;\)</span>.</p>
<p><br/>
<br/></p>
<ul>
<li>Theorem 4</li>
</ul>
<p>if <span class="math inline">\(H \cap K = \big \{ 0 \big \}\)</span>, then <span class="math inline">\(\dim(H+K) = \dim(H) + \dim(K)\)</span>. In general, $(H+K) = (H) + (K) -(H K) $</p>
<p>Proof: Exercise.</p>
<p><br/>
<br/></p>
<ul>
<li>Definition 4 (Complement of a space)</li>
</ul>
<p>If <span class="math inline">\(M\)</span> and <span class="math inline">\(M^c\)</span> are disjoint subspaces of <span class="math inline">\(V\)</span> and <span class="math inline">\(V = M +M^c\)</span>, then <span class="math inline">\(M^c\)</span> is called a <strong>complement</strong> of <span class="math inline">\(M\)</span>.</p>
<ul>
<li>Remark 1: The complement is <strong>not unique</strong>. In <span class="math inline">\(\mathbb{R}^2\)</span>, a subspace <span class="math inline">\(M\)</span> of dimension 1 consists of a line through the origin. A complement of <span class="math inline">\(M\)</span> is given by any other line <span class="math inline">\(M^c \not = \alpha M\)</span> through the origin, because linear combinations of any two such lines span <span class="math inline">\(Ce^2\)</span>.</li>
</ul>
<p>In the linear model <span class="math inline">\(Y = X \beta + \epsilon\)</span>, we have that $= E(Y ) = X $, so that <span class="math inline">\(\mu \in \mathcal{C}(X)\)</span>. To estimate <span class="math inline">\(\mu\)</span> with <span class="math inline">\(\hat \mu\)</span>, we might want to require that <span class="math inline">\(\hat \mu \in \mathcal{C}(X)\)</span> (note: if <span class="math inline">\(X\)</span> includes a constant, then <span class="math inline">\(\mathcal{C}(X)\)</span> is a flat; otherwise, it is a subspace). The estimate would then depend upon <span class="math inline">\(Y\)</span> in a sensible way by <strong>moving</strong> <span class="math inline">\(Y\)</span> to the subspace. The method of moving is via projections. The optimality of moves depends on the way we measure distance - on an inner product defined on the vector space.</p>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
</div>
<div id="solutions-to-systems-of-linear-equations" class="section level3" number="6.7.2">
<h3 number="6.7.2"><span class="header-section-number">6.7.2</span> 2. Solutions to systems of linear equations</h3>
<p>Consider the Matrix equation <span class="math inline">\(X_{n \times p} \beta_{p \times 1} = y_{n \times 1}\)</span>. For a given <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> does there exist <span class="math inline">\(\beta\)</span> to these equations? Is it unique? If not unique, can we characterize all possible solutions?</p>
<p><br/>
<br/></p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(n=p\)</span> and <span class="math inline">\(X\)</span> is nonsingular, the unique solution is <span class="math inline">\(\beta = X^{-1} y\)</span>.</li>
</ol>
<p><br/>
<br/></p>
<ol start="2" style="list-style-type: decimal">
<li>If <span class="math inline">\(y \in \mathcal{C}(X)\)</span>, <span class="math inline">\(y\)</span> can be expressed as a linear combination of the columns of <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is of full column rank, then the columns of <span class="math inline">\(X\)</span> form a basis for <span class="math inline">\(\mathcal{C}(X)\)</span>, and the solution <span class="math inline">\(\beta\)</span> is just the coordinates of <span class="math inline">\(y\)</span> relative to this basis. For any g-inverse <span class="math inline">\(X^-\)</span>, we have <span class="math inline">\(XX^- y = y\)</span> for all <span class="math inline">\(y \in \mathcal{C}(X)\)</span>, and so a solution is given by <span class="math inline">\(\beta=X^- y\)</span>. <br/> If <span class="math inline">\(\rho (X) = rank \Big( \mathcal{C}(X) \Big) &lt; p\)</span>, then the solution is not unique. If <span class="math inline">\(\beta_0\)</span> as <strong>any</strong> solution, for example the solution is given by <span class="math inline">\(\beta=X^- y\)</span>, then so is <span class="math inline">\(\beta_0 + z, \;\;\;\;\; z\in N(X)\)</span>, which is null-space of <span class="math inline">\(X\)</span>. The set of solutions is given by <span class="math inline">\(\beta_0 + N(X)\)</span>, which is a <strong>flat</strong>.</li>
</ol>
<p><br/>
<br/></p>
<ol start="3" style="list-style-type: decimal">
<li>If <span class="math inline">\(y \not \in \mathcal{C}(X)\)</span>, then there is no exact solution. This is the usual situation in linear models, and leads to the estimation problem discussed in the next chapter.</li>
</ol>
<p>What we might do is get the <strong>closest</strong> solution by replacing <span class="math inline">\(Y\)</span> by another vector <span class="math inline">\(\hat Y\)</span> that is as close to <span class="math inline">\(Y\)</span> as possible; if we define close as <span class="math inline">\(\Vert Y - \hat Y \Vert^2\)</span> making small, we need to solve <span class="math inline">\(X \beta = P_{\mathcal{C}(X)}Y\)</span> insetead of the original equation. If <span class="math inline">\(X\)</span> has full column rank, this leads to the familiar solution:</p>
<p>$
<span class="math display">\[\begin{align}
\beta_0 &amp;= X^+ P y

\\
&amp;= (X&#39;X)^{-1} X&#39; X (X&#39;X)^{-1}X&#39; Y

\\

&amp; = (X&#39;X)^{-1}X&#39;Y

\tag{2}

\end{align}\]</span>
$</p>
<p>which is unique. If <span class="math inline">\(X\)</span> does not have not full column rank, then the set of solutions again forms a flat of the form <span class="math inline">\(\beta_0 + N(X)\)</span> with <span class="math inline">\(\beta_0\)</span> given by (2).</p>
<!--chapter:end:211407_Flat.Rmd-->
</div>
</div>
<div id="unified-approach-to-balanced-anova-models" class="section level2" number="6.8">
<h2 number="6.8"><span class="header-section-number">6.8</span> Unified Approach to Balanced ANOVA Models</h2>
<p>We can develop a unified approach to obtaining orthogonal projection operatores in arbitrary balanced <span class="math inline">\(k\)</span>-way ANOVA models by exploting the structure of design matrix. The structure of the design matrix can be easily examined using Kronecker products. Therefore, before we proceed further, we need to establish some more properties of Kronecker products.</p>
<p>Kronecker Product <span class="math inline">\(:= A \otimes B = (a_{ij}B)\)</span>.</p>
<p><br/>
<br/></p>
<p>Consider the balanced two-way ANOVA model with interaction. This model is given by</p>
<p>$
Y_{ijk} = + _ i + <em>j + </em>{ij} + _{ijk}
$</p>
<p>where <span class="math inline">\(i=1, \cdots, a\)</span>, <span class="math inline">\(j=1, \cdots, b\)</span>, <span class="math inline">\(k=1, \cdots, N\)</span>, and <span class="math inline">\(n=abN\)</span>.</p>
<p>We want to write</p>
<p>$
(M) = (M_) + (M_) + (M_) + (M_)
$</p>
<p>and be able to compute the orthogonal projection operators in an easy and unified way.</p>
<p>We can represent each subspace making up <span class="math inline">\(\mathcal{C}(M)\)</span> in terms of Kronecker produdcts. Once we do this, we can easily obtain the orthogonal projection operator for that space.</p>
<p>※ Notation: let <span class="math inline">\(s\)</span> be an arbitrary index. Define <span class="math inline">\(J_s\)</span> as the <span class="math inline">\(s \times 1\)</span> vector of ones, $P_s =  J_s J_s ’ $ and <span class="math inline">\(Q_s = I_s - P_s\)</span>, where <span class="math inline">\(I_s\)</span> is the <span class="math inline">\(s \times s\)</span> identity matrix.</p>
<p>Thus, <span class="math inline">\(P_s\)</span> is the orthogonal projection operator onto <span class="math inline">\(\mathcal{C}(J_s)\)</span> and <span class="math inline">\(Q_s\)</span> is the orthogonal projection operator onto <span class="math inline">\(\mathcal{C}(J_s)^\perp\)</span></p>
<p><br/>
<br/></p>
<p>※ Facts:</p>
<ol style="list-style-type: decimal">
<li>recall that the OPO onto <span class="math inline">\(\mathcal{C}(A)\)</span> is always given by by <span class="math inline">\(A(A&#39;A)^{-}A&#39;\)</span>.</li>
<li>if <span class="math inline">\(M\)</span> is an OPO, then <span class="math inline">\(M^{-} = M\)</span>.</li>
</ol>
<hr />
<p><br/>
<br/>
<br/>
<br/>
<br/></p>
<p>$ Kronecker Product forms for the OPO</p>
<ol style="list-style-type: decimal">
<li>Computing <span class="math inline">\(M_\mu\)</span>.</li>
</ol>
<p>We can write <span class="math inline">\(J_n = J_\a \otimes J_b \otimes J_N\)</span>, so that <span class="math inline">\(M_\mu\)</span> is the OPO onto <span class="math inline">\(\mathcal{C} \Big( J_\a \otimes J_b \otimes J_N \Big)\)</span>. Thus by Fact 1 above, we have</p>
<p>$</p>
<p>&amp; &amp;&amp;M_&amp;&amp; &amp;&amp;</p>
<p>\</p>
<p>&amp;=
&amp;&amp;( J_J_b J_N )
&amp;&amp;( ( J_a ’ J_b ’ J_N ’ ) ( J_a J_b J_N ) )^{-}
&amp;&amp;( J_a ’ J_b ’ J_N ’ )</p>
<p>\</p>
<p>&amp;=
&amp;&amp;( J_a J_b J_N )
&amp;&amp;( J_a ’ J_a J_b ’ J_b J_N ’ J_N)^{-}
&amp;&amp;( J_a ’ J_b ’ J_N ’ )</p>
<p>\</p>
<p>&amp;=
&amp;&amp;( J_a J_b J_N )
&amp;&amp;( ab N)^{-}
&amp;&amp;( J_a ’ J_b ’ J_N ’ )</p>
<p>&amp;=
&amp;&amp; J_a J_a ’ +  J_b J_b ’ +  J_N J_N’</p>
<p>\</p>
<p>&amp;=
&amp;&amp;P_a P_b P_N</p>
<p>$</p>
<p>Using the properties of Kronecker products, it can be easily shown that <span class="math inline">\(M = I_a \otimes I_b \otimes P_N\)</span>.</p>
<p>the error space is <span class="math inline">\(\mathcal{C}(I-M)\)</span> and</p>
<p>$</p>
<p>I-M</p>
<p>&amp;= I_{abN} - M \</p>
<p>&amp;= ( I_a I_b I_N ) - ( I_a I_b P_N ) \</p>
<p>&amp;= ( I_a ) ( I_N - P_N ) \</p>
<p>&amp;= I_a I_b Q_N</p>
<p>$</p>
<p>observe that</p>
<p>$</p>
<p><span class="math display">\[\begin{align}

M + I - M &amp;= ( I_a \otimes I_b \otimes P_N ) + (I_a \otimes I_b \otimes Q_N) \\

&amp;= ( I_a \otimes I_b) \otimes(P_N + Q_N) \\

&amp;= ( I_a \otimes I_b) \otimes (I_N) \\

&amp;= I_a \otimes I_b \otimes I_N \\

&amp;= I_n

\end{align}\]</span></p>
<p>$</p>
<p>We can summarize the subspace and the OPO for the two-way ANOVA model as follows.</p>
<p><img src = "8-1.png"></p>
<ul>
<li>Excercise</li>
</ul>
<p>Consider the three-way ANOVA model</p>
<ol style="list-style-type: decimal">
<li><p>write out the subspaces and all OPO corresponding to each term in the ANOVA model completlely in terms of Kronecker.</p></li>
<li><p>Find the simplest expression for <span class="math inline">\(M_\mu + M_\alpha + M_\eta\)</span>.</p></li>
</ol>
<p><a href="https://smartstore.naver.com/hidamari/products/5283571274" class="uri">https://smartstore.naver.com/hidamari/products/5283571274</a></p>
<p><a href="https://smartstore.naver.com/hidamari/products/3029413531" class="uri">https://smartstore.naver.com/hidamari/products/3029413531</a></p>
<!--chapter:end:211408_ANOVA.Rmd-->
</div>
</div>
<div id="part-21-02" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) 21-02</h1>
<!--chapter:end:212000.Rmd-->
</div>
<div id="network-stats" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Network Stats</h1>
<div id="introduction-2" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Introduction</h2>
<ul>
<li>Network = Graph: for mathematical purposes, networks are most commonly represented in a formal manner using graphs of various kinds</li>
</ul>
<p>Vertices (Vertex), Edges, directed, undirected</p>
<p><br>
<br>
<br></p>
<div id="types-of-network-analysis" class="section level3" number="7.1.1">
<h3 number="7.1.1"><span class="header-section-number">7.1.1</span> Types of Network Analysis</h3>
<ol style="list-style-type: decimal">
<li><p>Visualization</p></li>
<li><p>Numerical Summaries</p>
<ol style="list-style-type: decimal">
<li><p><strong>Transitivity</strong> (<strong>Clustering Coefficient</strong>): A-B, A-C 조합의 변호사가 동업할 때, B-C끼리도 동업할 확률은 얼마일까? 이는 social network에서의 <strong>transitivity</strong> 개념과 대응함. 소위 <strong>clustering coefficient</strong>로 요약되는, 삼각형을 이루는 (즉, 모든 세개의 vertex pair가 edge로 연결) vertex 3개 묶음들의 비율을 나열하는 것으로 수치적으로 획득 가능.</p></li>
<li><p><strong>Assortativity Coefficient</strong>: 2가지 종류의 변호사(corporate와 litigation)이 존재할 때, 동업과 더 일을 자주하는지 다른 분야와 더 일을 자주하는지, 그 비율은 어떻게 되는지 궁금할 수 있음. 이는 social network의 <strong>assortativity</strong> 개념과 대응하며, in which labels of connected pairs of vertices들이 compared되는, 소위 <strong>assortativity coefficient</strong>라고 불리는 correlation statistic으로 quantified될 수 있다.</p></li>
</ol></li>
<li><p>주된 관심은 네트워크의 vertex (변호사 케이스라면 변호사 실무) 에 있으며 네트워크 구조 레벨의 속성은 좀 더 역할이 흐릿한 편</p></li>
</ol>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="network-modeling-and-inference" class="section level3" number="7.1.2">
<h3 number="7.1.2"><span class="header-section-number">7.1.2</span> Network Modeling and Inference</h3>
<p>관찰 대상 네트워크가 어떻게 생겼는지 묻고 구조를 특성화하는 것을 넘어, 보다 근본적인 수준에서 우리는 네트워크가 어떻게 발생했는지 이해하는 데 관심이 있을 수 있다. 즉, 우리는 네트워크가 복잡한 관심 시스템과 관련된 몇 가지 기본적인 프로세스에서 비롯되었다고 생각하고 이러한 프로세스의 본질적인 측면이 무엇인지 물어볼 수 있다. 네트워크가 어떤 과정을 거쳐 획득되었는지 - 사용된 measurement와 construction process - 또한 숙고될만한 부분이다.</p>
<ol style="list-style-type: decimal">
<li><p>Network Modeling:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Mathematical Models: 간단한 확률 규칙에 의거하여 네트워크를 생산. 규칙은 특성한 메커니즘 혹은 원칙을 파악하기 위한 시도의 일환으로 정의됨 (ex: ‘the rich get richer’)</p></li>
<li><p>Statistical Models: 대부분, 아니면 일부분이나마, 관측된 데이터와 맥락을 같이 하기 위해 정의되는 모델 (자주 probabilistic하기도 함, 1번의 성질도 같이 갖는다는 소리) 이며 이의 fit함은 통계적 추론의 일반적인 원칙들을 사용하여 영향을 받고, 또 평가도 받음</p></li>
</ol>
<p>이러한 2개의 모델의 종류 사이에는 교집합이 존재하지만, 이 둘을 다루는 paper들 사이에는 그럼에도 불구하고 큰 차이들이 존재함</p></li>
<li><p>Erdos-Renyi Model: 각 vertex 쌍마다 iid 동전던지기를 통해 해당 쌍 사이에 edge를 둘지 안둘지를 랜덤하게 결정. 랜덤 그래프의 유명한 Erdos-Renyi 공식의 변형에 해당. 이는 성질이 정말 좋음. cohesive structure가 edge 1개에서의 확률의 함수로서 나타남. 또한 다른 더 복잡한 모델들과 비교되어 이해를 돕기 위한 교과서로서도.</p></li>
<li><p>Mathematical Network Model: 수학모델은 현실 네트워크 데이터에 비하면 보통 너무 간단하지만, edge 구성의 특정 메커니즘이 어떻게 네트워크의 구조에 영향을 미칠 수 있는가 하는 것과, 관측된 네트워크에서 획득할 수 있는 구조적 성질이 얼마나 “significance” 한지를 판정하기 위한 네트워크의 <strong>null classes</strong>로 작동할 수 있다는 것에서 여전히 공부할 가치가 있음.</p></li>
<li><p>Statistical Network Models: <strong>Exponential Random Graph Models</strong> 는 Generalized Linear Models (GLM)과 유사하며, 이는 둘다 지수족 형태(exponential family form)에 기반을 두고 있다. edge들이 unmeasured, 혹은 알려지지 않은 변수에 뿌리를 두고 있다는 것이 핵심인 <strong>Latent network models</strong>은 <strong>hierarchical modeling</strong>에서의 latent 변수 사용법과 정확하게 평행하다 <mark>즉, <strong><em>대비된다???</em></strong>.</mark> <strong>Stochastic block models</strong>는 mixture 모델의 형태로 볼 수도 있다. 여기서 중요한건 이렇게 나열해놨지만서도 고차원 데이터가 의존성 높은 데이터를 쓰면 이런 애들은 이렇게 표준화된 모델과 맞아떨어지는 정도가 낮아진다는 것이다.</p></li>
</ol>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="network-processes" class="section level3" number="7.1.3">
<h3 number="7.1.3"><span class="header-section-number">7.1.3</span> Network Processes</h3>
<p>복잡계의 요소들간의 상호작용을 모사하기 위해, 네트워크 그래프 자체는 보통 네트워크 분석의 주된 목표가 됨. 물론 네트워크 구성 요소 중 시스템 내의 다른 모든 요소들과 상호작용하는 변량 혹은 속성이 있다면 이녀석이 최고관심의 대상이 될 것. 그러나 그럼에도 불구하고 요소들간의 상호작용이 앞에서 언급한 최고관심 대상에게 영향을 줄 것이라고 생각하는 것이 비합리적이지 않으므로 네트워크 그래프 자체는 여전히 모델링과 분석의 대상이기에 합당함. 우리는 확률과정을 네트워크에서의 “삶”이라고 해석해볼 수 있으며 네트워크 안의 vertices에 의해 첨수(indexed)됨. 이러한 과정에 관한 다양한 질문들은 정적 network process에 관한 것이든 동적 network process에 관한 것이든 이들을 예측하고자 하는 문제로 해석될 수 있음.</p>
<p><br>
<br>
<br></p>
<div id="dynamic-processes" class="section level4" number="7.1.3.1">
<h4 number="7.1.3.1"><span class="header-section-number">7.1.3.1</span> Dynamic Processes</h4>
<p>network-based 관점에서 연구되는 많은 system들은 본질적으로 동적임. 동적이 얘들 특성과 더 잘 부합함.</p>
<p>수학적 모델링이 여전히 이러한 과정을 모델링하는데 있어 1번째로 사용되는 툴이지만, network-based 통계적 모델들이 점차적으로 그 사용이 늘어나고 있음. 왜냐고? contact network에 대한 더욱 대량의 데이터가 사용 가능해지고 있으니까.</p>
<p>네트워크 flow 를 분석하기 위한 통계적 방법론들. 시작점으로부터 도착점까지의 material, 사람, 상품 등의 움직임 등을 생각해보면, flow들은 커뮤니케이션 네트워크 (인터넷 패킷 등), transportation 네트워크에 필수불가결한 동적 프로세스 이며 이외에도 그러함. 이러한 동적 프로세스들은 기본적으로 특이점이 없다면 시간의 흐름에 따라 evolve 될 것이 기대되고 있음.</p>
<!--chapter:end:212101_Intro.Rmd-->
</div>
</div>
</div>
<div id="descriptive-statistics-of-networks" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Descriptive Statistics of Networks</h2>
<p>• In the study of a given complex system, questions of interest can often be re-phrased in a useful manner as questions regarding some aspect of the structure or characteristics of a corresponding network graph.</p>
<ul>
<li>Various types of basic social dynamics can be represented by triplets of vertices with a particular pattern of ties among them (i.e., triads).</li>
<li>Questions involving the movement of information or commodities usually can be posed in terms of paths on the network graph and flows along those paths.</li>
<li>Certain notions of the ‘importance’ of individual system elements may be captured by measures of how ‘central’ the corresponding vertex is in the network.</li>
<li>The search for ‘communities’ and analogous types of unspecified ‘groups’ within a system frequently may be addressed as a graph partitioning problem.</li>
</ul>
<p>• The structural analysis of network graphs has traditionally been treated primarily as a descriptive task, as opposed to an inferential task, and the tools commonly used for such purposes derive largely from areas outside of ‘mainstream’ statistics.
– An overwhelming proportion of these tools are naturally graph-theoretic in nature, and thus have their origins in mathematics and computer science.
– The field of social network analysis has been another key source, contributing tools usually aimed at least originally at capturing basic aspects of social structure and dynamics.
– The field of physics has also been an important contributor, with the proposed tools often motivated by analogues in statistical mechanics.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="vertex-and-edge-characteristics" class="section level3" number="7.2.1">
<h3 number="7.2.1"><span class="header-section-number">7.2.1</span> Vertex and Edge Characteristics</h3>
<p>• The fundamental elements of network graphs are their vertices and edges
• Characterization of the Vertex and Edges
– Characterizations based upon vertex degrees
– Characterizations seeking to capture some more general notion of the ‘importance’ of a vertex</p>
<p><br>
<br>
<br></p>
<div id="vertex-degree" class="section level4" number="7.2.1.1">
<h4 number="7.2.1.1"><span class="header-section-number">7.2.1.1</span> Vertex Degree</h4>
<p>• The degree dv of a vertex v, in a network graph G = (V, E), counts the number of edges in E incident upon v.
• Given a network graph G, define fd to be the fraction of vertices v ∈ V with degree dv = d.
• The collection {fd}d≥0 is called the degree distribution of G, and is simply a rescaling of the set of degree frequencies, formed from the original degree sequence.
Karate club network<br />
</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sand)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraphdata)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(karate)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">degree</span>(karate), <span class="at">col=</span><span class="st">&quot;lightblue&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">50</span>),</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="at">xlab=</span><span class="st">&quot;Vertex Degree&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Frequency&quot;</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">graph.strength</span>(karate), <span class="at">col=</span><span class="st">&quot;pink&quot;</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="at">xlab=</span><span class="st">&quot;Vertex Strength&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Frequency&quot;</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p>• The degree distribution
– There are three distinct groups of vertices, as measured by degree.
– The two most highly connected vertices correspond to actors 1 and 34 in the network, representing the instructor and administrator about whom the club eventually split.
– The next set of vertices consists of actors 2, 3, and also 33.</p>
<p>• Weighted Networks
– A useful generalization of degree is the notion of vertex strength, which is obtained simply by summing up the weights of edges incident to a given vertex.
– The distribution of strength sometimes called the weighted degree distribution is defined in analogy to the ordinary degree distribution</p>
<p>Figure 2: The vertex strength distribution for the Karate club network
A Network of Interactions among Protein Pairs in Yeast</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(yeast)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ecount</span>(yeast)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">vcount</span>(yeast)</span></code></pre></div>
<p>• Histogram: In particular, while there is a substantial fraction of vertices of quite low degree, of an order of magnitude similar to those of the karate network, there are also a non-trivial number of vertices with degrees at successively higher orders of magnitude.
• There is a fairly linear decay in the log-frequency as a function of log-degree.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>d.yeast <span class="ot">=</span> <span class="fu">degree</span>(yeast)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(d.yeast,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Degree&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Frequency&quot;</span>, <span class="at">main=</span><span class="st">&quot;Degree Distribution&quot;</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>dd.yeast <span class="ot">=</span> <span class="fu">degree.distribution</span>(yeast)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">max</span>(d.yeast)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>ind <span class="ot">=</span> (dd.yeast <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d[ind], dd.yeast[ind], <span class="at">log=</span><span class="st">&quot;xy&quot;</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">xlab=</span><span class="fu">c</span>(<span class="st">&quot;Log-Degree&quot;</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="at">ylab=</span><span class="fu">c</span>(<span class="st">&quot;Log-Intensity&quot;</span>), <span class="at">main=</span><span class="st">&quot;Log-Log Degree Distribution&quot;</span>)</span></code></pre></div>
<p>Figure 3: The degree distribution for protein interactions in Yeast
• It can be interesting to understand the manner in which vertices of different degrees are linked with each other.
• Useful in assessing this characteristic is the notion of the average degree of the neighbors of a given vertex.
• While there is a tendency for vertices of higher degrees to link with similar vertices, vertices of lower degree tend to link with vertices of both lower and higher degrees.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>a.nn.deg.yeast <span class="ot">=</span> <span class="fu">graph.knn</span>(yeast,<span class="fu">V</span>(yeast))<span class="sc">$</span>knn</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d.yeast, a.nn.deg.yeast, <span class="at">log=</span><span class="st">&quot;xy&quot;</span>, <span class="at">col=</span><span class="st">&quot;goldenrod&quot;</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="at">xlab=</span><span class="fu">c</span>(<span class="st">&quot;Log Vertex Degree&quot;</span>), <span class="at">ylab=</span><span class="fu">c</span>(<span class="st">&quot;Log Average Neighbor Degree&quot;</span>))</span></code></pre></div>
<p>Figure 4: The degree distribution for protein interactions in Yeast</p>
<p><br>
<br>
<br></p>
</div>
<div id="vertex-centrality" class="section level4" number="7.2.1.2">
<h4 number="7.2.1.2"><span class="header-section-number">7.2.1.2</span> Vertex Centrality</h4>
<p>• Many questions that might be asked about a vertex in a network graph essentially seek to understand
its ‘importance’ in the network.
– Which actors in a social network seem to hold the ‘reins of power?’
– How authoritative does a particular page in the World Wide Web seem to be considered?
– The deletion of which genes in a gene regulatory network is likely to be lethal to the corresponding organism?
– How critical is a given router in an Internet network to the flow of traffic?</p>
<p>• Measures of centrality are designed to quantify such notions of ‘importance’ and thereby facilitate the answering of such questions.
• Most widely used measure of vertex centrality: Vertex Degree.
• Three other classic types of vertex centrality measures: Closeness, Betweenness, and Eigenvector</p>
<ul>
<li><strong>centrality</strong>
• Closeness centrality measures attempt to capture the notion that a vertex is ‘central’ if it is ‘close’ to many other vertices.
– The standard approach is to let the centrality vary inversely with a measure of the total distance of a vertex from all others,</li>
</ul>
<p>cCL =
1
P
u∈V
dist(u, v)
,
where dist(v, u) is the geodesic distance between the vertices u, v ∈ V .</p>
<p>– Often, for comparison across graphs and with other centrality measures, this measure is normalized to lie in the interval [0, 1], through multiplication by a factor Nv1.</p>
<p>• Betweenness centrality measures are aimed at summarizing the extent to which a vertex is located ‘between’ other pairs of vertices.
– These centralities are based upon the perspective that ‘importance’ relates to where a vertex is located with respect to the paths in the network graph.
– If we picture those paths as the routes by which communication of some sort or another takes place, vertices that sit on many paths are likely more critical to the communication process.
– The most commonly used betweenness centrality is defined as</p>
<p>CB(v) = X
s6=t6=v∈V
σ(s, t | v)
σ(s, t)</p>
<p>where σ(s, t | v) is the total number of shortest paths between s and t that pass through v, and σ(s, t) is the total number of shortest paths between S and t (regardless of whether or not they pass through v).
– This centrality measure can be restricted to the unit interval through division by a factor of (Nv − 1)(Nv − 2)/2.</p>
<p>• Other centrality measures are based on notions of ‘status’ or ‘prestige’ or ‘rank.’
– Seek to capture the idea that the more central the neighbors of a vertex are, the more central that vertex itself is.
– These measures are inherently implicit in their definition and typically can be expressed in terms of eigenvector solutions of appropriately defined linear systems of equations.
– There are many such eigenvector centrality measures. For example,</p>
<p>CEi
(v) = α
X
{u,v}∈E
cEi
(u).
The vector CEi = (CEi
(1), · · · , CEi
(Nv))T</p>
<p>is the solution to the eigenvalue problem ACEi, where A is the adjacency matrix for the network graph G.</p>
<p>– An optimal choice of α−1 is the largest eigenvalue of A, and hence cEi is the corresponding eigenvector.
– When G is undirected and connected, the largest eigenvalue of A will be simple and its eigenvector will have entries that are all nonzero and share the same sign.
– Convention is to report the absolute values of these entries, which will automatically lie between 0 and 1 by the orthonormality of eigenvectors.
• An intuitively appealing way of displaying vertex centralities (for networks of small to moderate size) is to use a radial layout, with more central vertices located closer to the center.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;network&quot;, repos=&quot;http://cran.us.r-project.org&quot;)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;sna&quot;, repos=&quot;http://cran.us.r-project.org&quot;)</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">get.adjacency</span>(karate, <span class="at">sparse=</span><span class="cn">FALSE</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(network)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">as.network.matrix</span>(A)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sna)</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">degree</span>(g), <span class="at">main=</span><span class="st">&quot;Degree&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="at">edge.col=</span><span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">closeness</span>(g), <span class="at">main=</span><span class="st">&quot;Closeness&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="at">edge.col=</span><span class="st">&quot;darkgray&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;network&quot;, repos=&quot;http://cran.us.r-project.org&quot;)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;sna&quot;, repos=&quot;http://cran.us.r-project.org&quot;)</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">get.adjacency</span>(karate, <span class="at">sparse=</span><span class="cn">FALSE</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(network)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">as.network.matrix</span>(A)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sna)</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">betweenness</span>(g), <span class="at">main=</span><span class="st">&quot;Betweenness&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="at">edge.col=</span><span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, <span class="fu">evcent</span>(g), <span class="at">main=</span><span class="st">&quot;Eigenvalue&quot;</span>, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col =</span> <span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">32</span>), <span class="st">&quot;yellow&quot;</span>),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="at">edge.col=</span><span class="st">&quot;darkgray&quot;</span>)</span></code></pre></div>
<p>• Extensions of these centrality measures from undirected to directed graphs are straightforward.</p>
<p>Figure 6: Target plots showing various vertex centralities for the karate club network
– Characterizes the importance of so-called hub vertices by how many authority vertices they
point to, and so-called authority vertices by how many hubs point to them.
– Given an adjacency matrix A for a directed graph, hubs are determined according to the
eigenvector centrality of the matrix Mhub = AAT
, and authorities, according to that of
Mauth = AT A.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>l <span class="ot">=</span> <span class="fu">layout.kamada.kawai</span>(aidsblog)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aidsblog, <span class="at">layout=</span>l, <span class="at">main=</span><span class="st">&quot;Hubs&quot;</span>, <span class="at">vertex.label=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="at">vertex.size=</span><span class="dv">10</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">hub.score</span>(aidsblog)<span class="sc">$</span>vector))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aidsblog, <span class="at">layout=</span>l, <span class="at">main=</span><span class="st">&quot;Authorities&quot;</span>, <span class="at">vertex.label=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="at">vertex.size=</span><span class="dv">10</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">authority.score</span>(aidsblog)<span class="sc">$</span>vector))</span></code></pre></div>
<p>Figure 7: AIDS blog network with vertex area proportional to hubs and authority centrality measures</p>
<p><br>
<br>
<br></p>
</div>
<div id="characterizing-edges" class="section level4" number="7.2.1.3">
<h4 number="7.2.1.3"><span class="header-section-number">7.2.1.3</span> Characterizing Edges</h4>
<p>• Edge betweenness centrality which extends vertex betweenness centrality in a straightforward manner, by assigning to each edge a value that reflects the number of shortest paths traversing that edge is a natural quantity to use.</p>
<p>• Using edge betweenness with the karate network and examining, for instance, the edges with the three largest betweenness values</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>eb <span class="ot">=</span> <span class="fu">edge.betweenness</span>(karate)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">E</span>(karate)[<span class="fu">order</span>(eb, <span class="at">decreasing=</span>T)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]]</span></code></pre></div>
<p>• Many other vertex centrality measures do not extend as easily. One way around this problem is to apply vertex centrality measures to the vertices in the line graph of a network graph G.
• Line graph of G, say G0 = (V
0
, E0
), is obtained essentially by changing vertices of G to edges, and
edges, to vertices.
• The vertices v
0 ∈ V
0
represent the original edges e ∈ E, and the edges e
0 ∈ E0
indicate that the two corresponding original edges in G were incident to a common vertex in G.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="characterizing-network-cohesion" class="section level3" number="7.2.2">
<h3 number="7.2.2"><span class="header-section-number">7.2.2</span> Characterizing Network Cohesion</h3>
<p>• Questions involving network cohesion, the extent to which subsets of vertices are cohesive or ‘stuck
together’ with respect to the relation defining edges in the network graph.
– Do friends of a given actor in a social network tend to be friends of one another as well?
– What collections of proteins in a cell appear to work closely together?
– Does the structure of the pages in the World Wide Web tend to separate with respect to
distinct types of content?
– What portion of a measured Internet topology would seem to constitute the ‘backbone?’
• There are many ways that we can define network cohesion, depending on the context of the question
being asked.
– Definitions differ, for example, in scale, ranging from local (e.g., triads) to global (e.g., giant
components), and also in the extent to which they are specified explicitly (e.g., cliques) versus
implicitly (e.g., ‘clusters’ or ‘communities’)</p>
<p><br>
<br>
<br></p>
<div id="subgraphs-and-censuses" class="section level4" number="7.2.2.1">
<h4 number="7.2.2.1"><span class="header-section-number">7.2.2.1</span> Subgraphs and Censuses</h4>
<ul>
<li><strong>Cliques</strong></li>
</ul>
<p>Cliques are complete subgraphs and hence are subsets of vertices that are fully cohesive, in the
sense that all vertices within the subset are connected by edges.
• A census of cliques of all size can provide some sense of a ‘snapshot’ of how structured a graph is</p>
<p>For the karate network a census of this sort reflects that there are 34 nodes (cliques of size one)
and 78 edges (cliques of size two), followed by 45 triangles (cliques of size three).
• The largest cliques are of size five, of which there are only two</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(<span class="fu">cliques</span>(karate), length))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cliques</span>(karate)[<span class="fu">sapply</span>(<span class="fu">cliques</span>(karate), length) <span class="sc">==</span> <span class="dv">5</span>]</span></code></pre></div>
<p>The cliques of larger sizes necessarily include cliques of smaller sizes.
• A maximal clique is a clique that is not a subset of a larger clique</p>
<p>• Large cliques are relatively rare, as they necessarily require that a graph G itself be fairly dense,
while real-world networks are often sparse</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(<span class="fu">maximal.cliques</span>(karate), length))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">clique.number</span>(yeast)</span></code></pre></div>
<ul>
<li><strong><span class="math inline">\(k\)</span>-core</strong></li>
</ul>
<p>• Weakened Notions of Cliques. A <span class="math inline">\(k\)</span>-core of a graph G is a subgraph of G for which all vertex degrees are at least k, and such that
no other subgraph obeying the same condition contains it (i.e., it is maximal in this property).
• The notion of cores is particularly popular in visualization, as it provides a way of decomposing a
network into ‘layers.’</p>
<p>Figure 8: Visual representation of the k-core decomposition of the karate network</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>cores <span class="ot">=</span> <span class="fu">graph.coreness</span>(karate)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gplot.target</span>(g, cores, <span class="at">circ.lab =</span> <span class="cn">FALSE</span>, <span class="at">circ.col=</span><span class="st">&quot;skyblue&quot;</span>,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="at">usearrows =</span> <span class="cn">FALSE</span>, <span class="at">vertex.col=</span>cores, <span class="at">edge.col=</span><span class="st">&quot;darkgray&quot;</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(<span class="st">&quot;package:sna&quot;</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(<span class="st">&quot;package:network&quot;</span>)</span></code></pre></div>
<p>Figure 8: Visual representation of the k-core decomposition of the karate network</p>
<p>Vertices of coreness one (black), two (red), three (green), and four (blue) are shown at successively smaller
distances from the center, with the same distance for vertices within each core
Other Classes of Subgraphs in Defining Network Cohesion.
• Dyads are pairs of vertices and, in directed graphs, may take on three possible states: null (no
directed edges), asymmetric (one directed edge), or mutual (two directed edges).
• Triads are triples of vertices and may take on 16 possible states, ranging from the null subgraph
to the subgraph in which all three dyads formed by the vertices in the triad have mutual directed
edges.
The vast majority of the dyads are null and, of those that are non-null, almost all are asymmetric,
indicating a decided one-sidedness to the manner in which blogs in this network reference each other.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>aidsblog <span class="ot">=</span> <span class="fu">simplify</span>(aidsblog)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dyad.census</span>(aidsblog)</span></code></pre></div>
<p>Consistent with the observations from our earlier analysis of hubs and authorities in this network
• Small connected subgraphs of interest are commonly termed motifs.
• The notion of motifs is particularly popular in the study of biological networks, where arguments
often are made linking such network substructures to biological function.</p>
<p><br>
<br>
<br></p>
</div>
<div id="density-and-related-notions-of-relative-frequency" class="section level4" number="7.2.2.2">
<h4 number="7.2.2.2"><span class="header-section-number">7.2.2.2</span> Density and Related Notions of Relative Frequency</h4>
<ul>
<li><strong>Density</strong></li>
</ul>
<p>The density of a graph is the frequency of realized edges relative to potential edges. For example,
in a (undirected) graph G with no self-loops and no multiple edges, the density of a subgraph
H = (VH, EH) is</p>
<p>den(H) = |EH|
|VH|(|VH| − 1)/2</p>
<p>The value of den(H) will lie between zero and one and provides a measure of how close H is to
being a clique. In the case that G is a directed graph, the denominator is replaced by |VH|(|VH|1).
• Taking H = G yields the density of the overall graph G.
• Conversely, taking H = Hv to be the set of neighbors of a vertex v ∈ V , and the edges between
them, yields a measure of density in the immediate neighborhood of v.
• The subgraphs corresponding to each of the instructor and the administrator, in union with their
immediate respective neighborhoods i.e., the ego-centric networks around vertices 1 and 34 are
noticeably more dense than the overall network.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>ego.instr <span class="ot">=</span> <span class="fu">induced.subgraph</span>(karate,<span class="fu">neighborhood</span>(karate, <span class="dv">1</span>, <span class="dv">1</span>)[[<span class="dv">1</span>]])</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>ego.admin <span class="ot">=</span> <span class="fu">induced.subgraph</span>(karate,<span class="fu">neighborhood</span>(karate, <span class="dv">1</span>, <span class="dv">34</span>)[[<span class="dv">1</span>]])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(karate)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(ego.instr)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.density</span>(ego.admin)</span></code></pre></div>
<ul>
<li><strong>Clustering Coefficients</strong></li>
</ul>
<p>The standard use of the term clustering coefficient typically refers to the quantity
clT (G) = 3τ∆(G)
τ3(G)
,
where τ∆(G) is the number of triangles in the graph G, and τ3(G), the number of connected triples
(i.e., a subgraph of three vertices connected by two edges, also sometimes called a 2-star).
• The value clT (G) is alternatively called the transitivity of the graph, and is a standard quantity of
interest in the social network literature, where it is also referred to as the ‘fraction of transitive
triples.’</p>
<p>clT (G) is a measure of global clustering, summarizing the relative frequency with which connected
triples close to form triangles.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(karate)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(karate, <span class="st">&quot;local&quot;</span>, <span class="at">vids=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">34</span>))</span></code></pre></div>
<ul>
<li><strong>Reciprocity</strong>
• A concept unique to directed graphs
• In the case that dyads are used as units, reciprocity is defined to be the number of dyads with reciprocated (i.e., mutual) directed edges divided by the number of dyads with a single, unreciprocated
edge.
• Reciprocity is defined as the total number of reciprocated edges divided by the total number of
edges.</li>
</ul>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reciprocity</span>(aidsblog, <span class="at">mode=</span><span class="st">&quot;default&quot;</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">reciprocity</span>(aidsblog, <span class="at">mode=</span><span class="st">&quot;ratio&quot;</span>)</span></code></pre></div>
<p><br>
<br>
<br></p>
</div>
<div id="connectivity-cuts-and-flows" class="section level4" number="7.2.2.3">
<h4 number="7.2.2.3"><span class="header-section-number">7.2.2.3</span> Connectivity, Cuts, and Flows</h4>
<p>기본적으로 궁금한 건 주어진 그래프가 서로 다른 서브그래프로 쪼개질 수 있나 하는 것. 불가능하다면 해당 그래프가 이 쪼개질 수 있는 성질의 역치에 얼마나 가까운지를 체크하는 것이 목적이 된다.</p>
<p>만약 모든 vertex가 다른 모든 vertex에서 접근 가능하다면, 즉 adjacency Matrix가 diag 제외하고 모두 1이면, 그래프 <span class="math inline">\(G\)</span>는 <strong>connected</strong>라고 칭해진다. 그리고 그래프의 <strong>connected component</strong>는 maximally connected 서브그래프이다.</p>
<p>그래프 <span class="math inline">\(G\)</span>의 connected component 중 하나가 다른 모두를 위력에서 압도한다면, 이는 곧 해당 connected component가 <span class="math inline">\(G\)</span>의 대부분의 vertex를 포함하고 있다는 이야기. 이러한 component는 <strong>giant component</strong>라고 불리며 이는 random graph theory 출신 용어.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.connected</span>(yeast)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>comps <span class="ot">=</span> <span class="fu">decompose.graph</span>(yeast)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sapply</span>(comps, vcount))</span></code></pre></div>
<p>결과는 false로 나오지만 이에 대해 census 돌리면 giant component의 존재 확인 가능. 아래 예시의 경우 component 1개가 2375/2617로 90퍼 vertex랑 연결중임. 이는 현실 네트워크에서의 <strong>small world property</strong>와 연결. vertex 쌍들 collection에서의 minimum path는 보통 되게 작음. 대비되게 clustring은 상대적으로 높음. (ex) protein?</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>yeast.gc <span class="ot">=</span> <span class="fu">decompose.graph</span>(yeast)[[<span class="dv">1</span>]]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">average.path.length</span>(yeast.gc)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">diameter</span>(yeast.gc)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">transitivity</span>(yeast.gc)</span></code></pre></div>
<p>해당 네트워크에서의 shortest path는 <span class="math inline">\(N_v\)</span>보다 <span class="math inline">\(\log N_v\)</span>로 표현되는게 정확할 정도로 짧음. scales more like, thus considered small. 동시에 해당 네트워크에서의 clustering은 상대적으로 large, 이는 transitivity로 확인 가능.</p>
<ul>
<li><strong>Connectivity</strong></li>
</ul>
<p>그래프 <span class="math inline">\(G\)</span> 가
1. <strong><span class="math inline">\(k\)</span>-vertex-connected</strong>
- the number of vertices <span class="math inline">\(N_v &gt; k\)</span>
- cardinality <span class="math inline">\(|X|&lt;k\)</span>이며 <span class="math inline">\(X \subseteq V\)</span>인 vertex의 subset <span class="math inline">\(X\)</span>을 지우면 connected subgraph가 아니게 됨.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong><span class="math inline">\(k\)</span>-edge-connected</strong>
<ul>
<li><span class="math inline">\(N_v ≥ 2\)</span></li>
<li>cardinality <span class="math inline">\(|Y|&lt;k\)</span>이며 <span class="math inline">\(Y \subseteq E\)</span>인 edge의 subset <span class="math inline">\(Y\)</span>을 지우면 connected subgraph가 아니게 됨.</li>
</ul></li>
</ol>
<p>즉 <span class="math inline">\(G\)</span>의 vertex (edge) connectivity는 <span class="math inline">\(G\)</span>의 k-vertex(k-edge-) connected가 유지되는 가장 큰 integer. <mark> 이때 vertex connectivity <span class="math inline">\(\le\)</span> edge connectivity <span class="math inline">\(\le\)</span> minimum degree among vertex in <span class="math inline">\(G\)</span> (dmin).</mark> 따라서 이 서브그래프를 추가적인 component로 분해하기 위해서는 단 1개의 엄선된 vertex나 edge를 제거하는 것으로 충분하다.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vertex.connectivity</span>(yeast.gc)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">edge.connectivity</span>(yeast.gc)</span></code></pre></div>
<ul>
<li><strong>Cut</strong></li>
</ul>
<p>vertex (edge)의 subset <span class="math inline">\(S\)</span>를 제거하는 것으로 해당 그래프가 서브그래프로 조각난다면, <span class="math inline">\(S\)</span>는 vertex-cut (edge-cut). 여기서 vertex <span class="math inline">\(S\)</span>의 원소가 1개라면, 즉 vertex 1개만을 제거한 것으로 그래프가 조각났다면, 이는 cut vertex, 혹은 <strong>articulation point</strong>. 이러한 vertex의 여부를 식별하는 건 해당 네트워크가 외부 공격에 취약하는지를 파악하는데 도움이 됨. 해당 포인트 끊기면 네트워크 정상작동이 안되니까.</p>
<p>• Identification of such vertices can provide a sense of where a network is vulnerable (e.g., in the sense of an attack, where disconnecting produces undesired consequences, such as a power outage in an energy network).
• In the giant component of the yeast network, almost 15% of the vertices are cut vertices.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>yeast.cut.vertices <span class="ot">=</span> <span class="fu">articulation.points</span>(yeast.gc)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(yeast.cut.vertices)</span></code></pre></div>
<p>nontrivial 그래프 <span class="math inline">\(G\)</span>는 k-vertex (k-edge) connected <span class="math inline">\(\iff\)</span> 서로다른 vertex의 쌍 <span class="math inline">\(u, v \in V\)</span>가 k vertex-disjoint (edge-disjoint) paths에 의해 connected 가능.</p>
<p>이 결과는 그래프에서 특정 vertex (edge)가 제거된 상황에서도 그래프 내부에서 만들어지는 서로 다른 path 들이 얼마나 많은지를 통해 평가되는 그래프의 robust함과 연결되어 있다. 낮은 vertex (edge) connectivity 를 가지는 그래프는 따라서 path들을 가질 수 있으며, 이에 의해 그 path들을 통과했던 “information”들은 작은 숫자의 vertex (edge)를 없애는 것만으로 쉽게 방해되고 만다.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shortest.paths</span>()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.maxfow</span>()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">graph.mincu</span>()</span></code></pre></div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="graph-partitioning" class="section level3" number="7.2.3">
<h3 number="7.2.3"><span class="header-section-number">7.2.3</span> Graph Partitioning</h3>
<p><strong>Partitioning</strong>은 elements의 집합을 “발생이 자연스러운” 부분집합으로 분할하는 과정. 더 이론적으로 말하자면, finite set <span class="math inline">\(S\)</span>의 partition <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>는 <span class="math inline">\(S\)</span>를 <span class="math inline">\(K\)</span> 개의 disjoint로 decomposition 한 물건으로, 이인즉 <span class="math inline">\(\forall C_k \not = \emptyset: \cup_{k=1}^K C_k = S\)</span>.</p>
<p>네트워크 그래프 분석에서, partitioning은 겉으로 드러나지 않는 관계성 측면에서 vertex의 묶음이 “cohesiveness”를 가지고 있는지를 확인하기에 유용한 방법이다. vertex의 “cohesive”한 subset은 일반적으로 이하와 같은 걸 일컬음:
1. subset 내부에서, “동시에,” 잘 connected 되어 있어야 한다
2. subset 외부, 즉 남아있는 vertex들과 잘 seperated - 연결성이 없음</p>
<p>Graph partitioning algorithms 은 보통 그래프 <span class="math inline">\(G(V, E)\)</span>의 vertex set <span class="math inline">\(V\)</span> 의 partition <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>를 찾는 것을 그 목표로 함. 이를 위한 방법으로 <span class="math inline">\(C_k\)</span> 안의 vertex에서 <span class="math inline">\(C_k&#39;\)</span>로의 vertex로 잇는 edge의 sets <span class="math inline">\(E(C_k, C_k &#39;)\)</span>는 <span class="math inline">\(C_k\)</span> 내에서 vertex 를 잇는 edge들의 set <span class="math inline">\(E(C_k) = E(C_k , C_k)\)</span>보다 작다는 점을 활용함.</p>
<p>그래프 partitioning의 이 문제는 complex networks 문헌에서의 community detection에서도 동일하게 발생함. 이에 대한 해결책으로 큰 틀에서 2가지 접근법이 존재.</p>
<p><br>
<br>
<br></p>
<div id="hierarchical-clustering-1" class="section level4" number="7.2.3.1">
<h4 number="7.2.3.1"><span class="header-section-number">7.2.3.1</span> Hierarchical Clustering</h4>
<p>그래프 파티셔닝에 사용되는 대부분의 방법은 본질적으로 Hierarchical Clustering의 변용에 불과함. 여러가지 방법론이 제시되었지만, 그 차이는 결국 이하가 다를 뿐임.</p>
<ol style="list-style-type: decimal">
<li>proposed clusterings의 quality를 어떻게 측정하는가</li>
<li>연구자가 찾고 있는 해당 quality를 어떻게 최적화하는가. 보통 그리디 알고리즘으로 모든 가능한 partition <span class="math inline">\(C\)</span>의 space를 탐색하는 식으로 한다. 이 과정에서 계속해서 후보 partition을 갱신하고.</li>
</ol>
<p>Hierarchical methods 는 다음 둘로 분류됨.
1. agglomerative, 파티션을 합쳐나가는 것을 계속해나가는 것으로 크기를 키워가는 것에 기반 (coarsen)
2. divisive, 파티션을 쪼개나가는 것을 계속해나가는 것으로 연속으로 다듬어나가는 것</p>
<p>각 단계에서 현재의 후보 partition은 지정된 비용 측정값을 최소화한다는 목적으로 계속해서 정제되어 갑니다.
1. agglomerative 방법에서는, 2개의 이전의 partition elements 중 가장 저렴한 merge 방법이 실행된다
2. divisive 방법에서는, 1개의 이전의 partition 중 가장 저렴하게 2개로 split 할 수 있는 방법이 실행된다</p>
<p>비용측정의 기준은 vertex의 “cohesive” subset을 뭘 기준으로 판정할지 하는 연구자의 주관이 개입됨. 메이저한 기준은 <strong>modularity</strong>. <span class="math inline">\(C = \{ C_1, \cdots, C_K \}\)</span>를 주어진 후보 partition으로 하고, <mark><span class="math inline">\(f_{ij} = f_{ij}(\mathcal C)\)</span>는 <span class="math inline">\(C_i\)</span>의 vertex를 to be the fraction of edges in the original network that connect vertices in Ci with vertices in Cj.</mark> 이때 <span class="math inline">\(\mathcal C\)</span>의 <strong>modularity</strong>는</p>
<p><span class="math display">\[
\mod(\mathcal C) = \sum_{k=1}^K \left[ f_{kk}(\mathcal C) - f_{kk}^\ast \right]
\]</span></p>
<p><mark>
where <span class="math inline">\(f_{kk}^\ast\)</span>는 random edge assignment의 몇몇 모델을 두고 만들어진 <span class="math inline">\(f_{kk}\)</span>의 기댓값. <span class="math inline">\(f_{kk}^\ast\)</span>는 <span class="math inline">\(f_{k+} \cdot f_{+k}\)</span>이며 각각 <span class="math inline">\(f\)</span>의 k번째 rowsum과 colsum. 즉 <span class="math inline">\(f_{ij}\)</span>를 entry로 하는 <span class="math inline">\(K \times K\)</span> 매트릭스가 만들어짐. This choice corresponds to a model in which a graph is constructed to have the same degree distribution as <span class="math inline">\(G\)</span>, but with edges otherwise placed at random, without respect to the underlying partition elements dictated by <span class="math inline">\(C\)</span>.
</mark></p>
<p>In principle the optimization of the modularity requires a search over all possible partitions C, which is prohibitively expensive in networks of moderate size and larger.
• A fast, greedy approach to optimization has been proposed, in the form of an agglomerative hierarchical clustering algorithm, and implemented in igraph as fastgreedy.community.
• The result of this and related community detection methods in igraph is to produce an object of the class communities, which can then serve as input to various other functions.</p>
<p>Applying this method to the karate network,</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>kc <span class="ot">=</span> <span class="fu">fastgreedy.community</span>(karate)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(kc)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sizes</span>(kc)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">membership</span>(kc)</span></code></pre></div>
<p>The largest community of 18 members is centered around the administrator (i.e., John A, vertex ID 34).
• The second largest community of 11 members is centered around the head instructor (i.e., Mr Hi, vertex ID 1).</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(kc, karate)</span></code></pre></div>
<p>Figure 9: Partitioning of the Karate network obtained from hierarchical clustering</p>
<p>• Whether agglomerative or divisive, when used for network graph partitioning, hierarchical clustering methods actually produce, as the name indicates, an entire hierarchy of nested partitions of the graph, not just a single partition.
• The resulting hierarchy typically is represented in the form of a tree, called a dendrogram.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ape)</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dendPlot</span>(kc, <span class="at">mode=</span><span class="st">&quot;phylo&quot;</span>)</span></code></pre></div>
<p><br>
<br>
<br></p>
</div>
<div id="spectral-partitioning" class="section level4" number="7.2.3.2">
<h4 number="7.2.3.2"><span class="header-section-number">7.2.3.2</span> Spectral Partitioning</h4>
<p>spectral graph theory의 연구결과를 응용하여 그래프 <span class="math inline">\(G\)</span>의 connectivity를 특정 매트릭스의 eigen-analysis와 연관짓는 것.</p>
<p>adjacency matrix <span class="math inline">\(A\)</span>에 대한 그래프 <span class="math inline">\(G\)</span>의 그래프 Laplacian 은 <span class="math inline">\(L = D − A\)</span>이며, 이때 <span class="math inline">\(D = diag[(D_{vv} = d_v)]\)</span>, <span class="math inline">\(d_v\)</span>는 <span class="math inline">\(G\)</span>의 entries of the degree sequences.</p>
<p>spectral graph theory의 결과를 통해 우리는 다음을 파악 가능.</p>
<p>그래프 <span class="math inline">\(G\)</span>는 <span class="math inline">\(K\)</span> 개의 connected components로 구성 <span class="math inline">\(\iff\)</span> <span class="math inline">\(\lambda_1 (L) = \cdots = \lambda_K(L) = 0\)</span> 이며 <span class="math inline">\(\lambda_{K+1}(L)&gt;0\)</span>, where <span class="math inline">\(\lambda_1 \ge \lambda_2 \ge \cdots \ge \lambda_{N_v}\)</span>들은 L의 (not necessarily distinct) ev이며, <mark>ordered from small to large</mark>.</p>
<p>그래프 안의 component의 숫자는 그래프 Laplacian의 non-zero ev의 숫자과 직접적으로 연관되어 있음. <span class="math inline">\(L\)</span>의 최소 ev는 0임을 바로 보일 수 있다. evec <span class="math inline">\(x_1 = (1,\cdots,1)&#39;\)</span>에 대응하므로. 따라서 우리가 그래프 <span class="math inline">\(G\)</span>가 “거의” <span class="math inline">\(K=2\)</span> 개의 component들로 구성되어 있다고 추론한다면, 즉슨 2개로 쪼개기에 적합하다고 생각한다면, 이는 곧 우리는 해당 대상에 대해 <span class="math inline">\(\lambda_2(L)\)</span>가 0에 가까울 것이라고 추론할 것이라는 것과 동치이다. 이러한 추론은 <span class="math inline">\(\lambda_2\)</span>가 그래프 connectivity와 structure의 측정치의 값과 깊은 연관이 있기에 합리적이다. 특히 이러한 관계성은 <span class="math inline">\(\lambda_2\)</span>가 0에 가까울 수록 서브그래프 A과 서브그래프 B 사이를 통과하는 edge가 적을 것이기에 이렇게 둘로 쪼개는 것이 합리적일 것임을 보여준다. <span class="math inline">\(\lambda_2\)</span>를 그래프의 connectivity와 연관지은 제언자는 대응하는 evec <span class="math inline">\(x_2\)</span> 안의 entries들의 부호에 따라 vertex들을 쪼개는 것을 주장했다. 결과는 다음과 같다:</p>
<p><span class="math display">\[
S = \{v \in V: x_2 (v) \ge 0 \}
\\
\bar S = \{v \in V: x_2 (v) &lt; 0 \}
\]</span></p>
<p>즉, 2개의 vertex의 subset이 생산되며 (이를 보통 <strong>cut</strong>이라고 부름), 이 벡터 <span class="math inline">\(x_2\)</span>는 보통 <strong>Fiedler Vector</strong>라고 불리며 이에 대응하는 ev <span class="math inline">\(\lambda_2\)</span>는 <strong>Fiedler Value</strong>라고 부른다.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>k.lap <span class="ot">=</span> <span class="fu">graph.laplacian</span>(karate)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>eig.anal <span class="ot">=</span> <span class="fu">eigen</span>(k.lap)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eig.anal<span class="sc">$</span>values, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Eigenvalues of Graph Laplacian&quot;</span>)</span></code></pre></div>
<p>We plot the eigenvalues of the graph Laplacian.</p>
<ol style="list-style-type: decimal">
<li>0인 ev는 딱 하나. (해당 네트워크는 connected이므로 예상한 결과)</li>
<li>2번째로 작은 ev인 <span class="math inline">\(\lambda_2\)</span>는 0에 매우 가까움.</li>
</ol>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>faction <span class="ot">=</span> <span class="fu">get.vertex.attribute</span>(karate, <span class="st">&quot;Faction&quot;</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>f.colors <span class="ot">=</span> <span class="fu">as.character</span>(<span class="fu">length</span>(faction))</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>f.colors[faction <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">=</span> <span class="st">&quot;red&quot;</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>f.colors[faction <span class="sc">==</span> <span class="dv">2</span>] <span class="ot">=</span> <span class="st">&quot;cyan&quot;</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(f.vec, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">&quot;Actor Number&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Fiedler Vector Entry&quot;</span>, <span class="at">col=</span>f.colors)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;lightgray&quot;</span>)</span></code></pre></div>
<p>Fiedler vector를 생산하고 해당 vector의 요소들을 실제 actor number에 따라 배정한 그래프를 보면 이 spectral 방법이 faction label에 의해 네트워크 partitioning 을 획득할 수 있다는 것을 확인된다.</p>
<p>보통 우리는 네트워크가 서브그래프 2개보다는 더 잘게 쪼개질 수 있으리라고 예상 가능. spectral 방법을 iterative하게 적용하는 것으로 2개 이상으로 쪼갤 수 있음. 하지만 이러한 반복이 특정 목적 함수를 최적화할 수 있도록 목표하는 것이 바람직함. Newman은 spectral bisection method와 논리적 흐름이 유사하나 Laplacian <span class="math inline">\(L\)</span>이 아니라 이를 대체해서 modularity와 연관된 매트릭스를 사용하는 방법을 제안했다.(leading.eigenvector.community)</p>
<p><br>
<br>
<br></p>
</div>
<div id="validation-of-graph-partitioning" class="section level4" number="7.2.3.3">
<h4 number="7.2.3.3"><span class="header-section-number">7.2.3.3</span> Validation of Graph Partitioning</h4>
<p>validation 문제는 그래프 partitioning에 항상 중요하지만, 대부분의 경우 nontrivial 문제이다. 네트워크 그래프에 vertex의 cohesive subset 이 존재한다면, 이러한 subset의 기저에는 vertex에게 있어 vertex 간에 특정한 연관적인 특성 (또는 속성)에 일부 공통성이 있을 것으로 일반적으로 예상한다. 그래프 partitioning은 이러한 성질에 대한 지식이 없을때 그러한 subset을 발견하기 위한 도구로 인식될 수도 있다. 우리가 그래프 외부에서 정의된 클래스 멤버쉽에 대한 subset 정의를 알고 있다면, 그래프 내부에서의 partitioning으로 얻은 분절들과 비교하는 것도 흥미로움.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>func.class <span class="ot">=</span> <span class="fu">get.vertex.attribute</span>(yeast.gc, <span class="st">&quot;Class&quot;</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(func.class)</span></code></pre></div>
<p>해당 예시는 cell 구축에 있어 protein이 역할하는 바로 분절했음. 단백질들이 서로 다른 단백질들과 얼마나 유사한지는 특정 세포 역할에 해당 단백질이 무슨 일을 하는지와 연관되어 있다고 알려져 있음. 그래프 외부에서 이러한 단백질들을 분류하려는 시도는 분류된 결과가 그래프 내부에서 합리적은 partitioning 과정을 걸쳐 나온 결과물과 어느정도는 연관이 있는게 맞다. 아니면 partitioning이 잘못됐던가 그래프 외부 분절이 잘못됐던가.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>yc <span class="ot">=</span> <span class="fu">fastgreedy.community</span>(yeast.gc)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>c.m <span class="ot">=</span> <span class="fu">membership</span>(yc)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(c.m, func.class, <span class="at">useNA=</span><span class="fu">c</span>(<span class="st">&quot;no&quot;</span>))</span></code></pre></div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="assortativity-and-mixing" class="section level3" number="7.2.4">
<h3 number="7.2.4"><span class="header-section-number">7.2.4</span> Assortativity and Mixing</h3>
<ul>
<li><strong>Assortative mixing</strong></li>
</ul>
<p>특정 성질에 따라서 vertex 중에 선별적으로 연결.</p>
<ul>
<li>Assortativity coefficients</li>
</ul>
<p>assortative mixing의 정도를 량화하는 측도. 이는 correlation coefficients의 변용. vertex 특성은 categorical, ordinal, or continuous 다 가능. categorical 케이스를 가정하고, 그래프 <span class="math inline">\(G\)</span>의 각 vertex가 <span class="math inline">\(M\)</span>개의 카테고리 중에 label 될 수 있다고 생각하자. 이 세팅에서의 Assortativity coefficients <span class="math inline">\(r_a\)</span>는 아래와 같다.</p>
<p><span class="math display">\[
r_a = \frac{\sum_{i}f_{ii} - \sum_i f_{x+}f_{+y}}{1 - \sum_if_{x+}f_{+y}}
\]</span></p>
<p><mark>where fij is the fraction of edges in G that join a vertex in the i-th category with a vertex in the jth category, and fi+ and f+i denote the ith marginal row and column sums, respectively, of the resulting matrix f.</mark></p>
<p>이때 <span class="math inline">\(-1 \le r_a \le 1\)</span></p>
<p>– It is equal to zero when the mixing in the graph is no different from that obtained through a random assignment of edges that preserves the marginal degree distribution.
– It is equal to one when there is perfect assortative mixing (i.e., when edges only connect vertices of the same category).
– However, in the event that the mixing is perfectly disassortative, in the sense that every edge in the graph connects vertices of two different categories, the coefficient need not take the value −1.
• The fact that physical binding of proteins is known to be directly relevant to functional classes suggests that there will frequently be strong assortative mixing in protein-protein interaction networks with respective to these classes as attributes.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">assortativity.nominal</span>(yeast, (<span class="fu">V</span>(yeast)<span class="sc">$</span>Class<span class="sc">==</span><span class="st">&quot;P&quot;</span>)<span class="sc">+</span><span class="dv">1</span>, <span class="at">directed=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>• When the vertex characteristic of interest is continuous, rather than discrete, denote by (xe, ye) the
values of that characteristic for the vertices joined by an edge e ∈ E.
• A natural candidate for quantifying the assortativity in this characteristic is just the Pearson correlation coefficient of the pairs (xe, ye),</p>
<p><span class="math display">\[
r = \frac{\sum_{x,y}xy(f_{xy} - f_{x+}f_{+y})}{\sigma_x \sigma_y}
\]</span></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">assortativity.degree</span>(yeast)</span></code></pre></div>
<!--chapter:end:212102_DescriptiveStats.Rmd-->
</div>
</div>
<div id="data-collection-and-sampling" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Data Collection and Sampling</h2>
<p>Difficulties in Network Data Collection. 뭔 분야든 통계의 근간은 데이터 수집. 데이터가 <strong>IID</strong>라면 이 데이터는 sample이나 실험에서 확보한 데이터. 하지만 이는 네트워크 실험에서는 사실상 불가능. 따라서 우리는 샘플을 deal with 하기가 어려우며, 이전에 해왔던 것 대비 일이 무척 어려워짐. 이러한 복잡성은 empirical networks를 다룰 때는 너무나도 자주 무시되고 있어서 안타까운 실정임.</p>
<ul>
<li><strong>Sampling Procedures</strong></li>
</ul>
<p>이상적인 데이터에 해당하는 네트워크 census 를 생각해보자. 이는 모든 node 와 edge 를 기록하고 거기에 오류가 없음. 만약 완벽한 네트워크 census 데이터를 가지고 있는 케이스라면 샘플링 과정 스킵하고 바로 네트워크 formation 모델하는 단계로 넘어갈 수 있음.</p>
<p>하지만 그렇게 운좋을리가. 대다수의 경우에 보유한 네트워크 census 데이터는 불완전함. 보통 이런 실패는 네트워크의 성질과 mesurement process의 디테일 부족에서 옴. Survey 케이스를 생각해보자. survey 질문자, survey 답변자의 성격, survey 질문 구성 등으로 이런건 널뛰기함. 아니면 일부 질문 같은 경우에는 “가장 좋아하는 연예인 3명” 이런 식이라고 치자고. 이러면 4명 이하부터는 <strong>censoring</strong> 발생해서 이것도 완벽 데이터에서 왜곡됨.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="sampling-designs" class="section level3" number="7.3.1">
<h3 number="7.3.1"><span class="header-section-number">7.3.1</span> Sampling Designs</h3>
<p>우리가 <strong>true</strong>(참정보, 참값)를 확보하는 것이 불가능하다면, 우리는 IID 통계량에 의해 예시되었던 “population” graph <span class="math inline">\(G = (V, E)\)</span> 확보를 포기하고 “sample” graph <span class="math inline">\(G^\ast = (V^\ast, E^\ast)\)</span>를 얻는 쪽으로 선회한다. 이때 <span class="math inline">\(V^\ast \subset V\)</span>, <span class="math inline">\(E^\ast \subset E\)</span>.</p>
<p>이러한 sampled subgraphs를 얻기 위한 다양한 방법들에 대응되는 서로 다른 sampling designs들이 존재한다. 우선 population으로부터의 units들에 대한 simple random sample (SRS)를 이해하는 것이 샘플링을 이해하기 위한 1단계가 된다. 네트워크에서는 단순 랜덤 샘플마저도 복잡한 이해를 거쳐야 한다.</p>
<p><br>
<br>
<br></p>
<div id="induced-and-incident-subgraph" class="section level4" number="7.3.1.1">
<h4 number="7.3.1.1"><span class="header-section-number">7.3.1.1</span> Induced and Incident Subgraph</h4>
<p>node <span class="math inline">\(V\)</span>의 Simpl Random Sample (SRS)인 <span class="math inline">\(V^\ast\)</span>로부터 시작하자. 이로부터 발생시킨 (induced) subgraph <span class="math inline">\((i, j) \in E^\ast\)</span>. 이때 <span class="math inline">\((i, j) \in E^\ast \Leftrightarrow (i,j) \in E\)</span>, <span class="math inline">\(i \in V^\ast\)</span> and <span class="math inline">\(j \in V^\ast\)</span> 여야만 함. 이 정제되지 않은 natural 한 과정인 <strong>induced subgraph sampling</strong> 은 정말 간단한 네트워크 stats 에 대해서도 엄청 biased. bias를 계산해낸 후에 bias 를 보정할 수 있는 경우도 있지만 여하튼 bias 가 크다는게 장점은 아니지.</p>
<p>반면에 우리는 edge의 SRS에서 시작해볼 수도 있다. 이 경우 <span class="math inline">\(E^\ast\)</span>는 <span class="math inline">\(E\)</span>의 SRS. 이후 이 edge 양끝에 해당하는 발생을 node로서 잡는다. 이인즉슨 <span class="math inline">\(\exists j \in V:(i,j) \in E^\ast \Rightarrow i \in V^\ast\)</span>. 고전적 survey 에 대해 쌓인 경험에 비추어볼 때 <strong>incident-subgraph sampling</strong> 는 꽤 괴상해보이지만, 그럼에도 이쪽이 natural 한 경우가 꽤 있기는 함.</p>
<div id="example-of-a-bias" class="section level5" number="7.3.1.1.1">
<h5 number="7.3.1.1.1"><span class="header-section-number">7.3.1.1.1</span> Example of a Bias</h5>
<p>우리가 정말정말 간단하기 그지없는 작업인 node 의 랜덤 샘플링을 진행할 때조차도 샘플링이 왜 bias 를 유발해버리는 걸까? 이는 <strong>mean degree</strong> 를 생각해보면 쉽게 알 수 있다. 직관적으로 생각해보자. induced subgraph 를 하나 가지고 있다. 이때 우리는 induced subgraph 바깥인데 전체 그래프 안에 있는, 즉 induced subgraph 에 포함되지 못한 edge 는 관측할 수가 없다. 따라서 우리가 각 node 에 대해 기록할 수 있는 degree 는 많아봤자 그것들의 degree 참값에 불과할 것이다. 따라서 샘플된 그래프들의 mean degree 는 mean degree 의 참값보다 작아져버리겠지. bias 발생.</p>
<p>let <span class="math inline">\(k_i = \sum_{j=1}^n A_{ij}\)</span>, 즉 <span class="math inline">\(k_i\)</span>는 node <span class="math inline">\(i\)</span>의 degree. 이 경우 모든 네트워크에 걸친 mean degree는 $k =  <em>{i=1}^n k</em>{i} $. 여기서 <span class="math inline">\(m\)</span>개의 노드를 SRS 한다면, node <span class="math inline">\(i\)</span>에게 부여된 확률은 모든 각각의 node에게 부여된 확률과 같으므로, 따라서 <span class="math inline">\(\pi = \frac{m}{n}\)</span>.</p>
<p>여기서 <span class="math inline">\(Z_i\)</span>를 <span class="math inline">\(i \in V^\ast\)</span> 여부에 대한 indicator로 정의하자. 그렇다면 node <span class="math inline">\(i\)</span>가 샘플 안에 있을 경우 <span class="math inline">\(Z_i = 1\)</span>.</p>
<p>또한 관측된 graph <span class="math inline">\(G^\ast\)</span>는 관측된 adjacency matrix <span class="math inline">\(A^\ast\)</span>를 보유하며, <span class="math inline">\(A_{ij}^\ast =1\)</span> iff <span class="math inline">\(A_{ij}=1\)</span>이며 <span class="math inline">\(i,j\)</span> 양쪽 모두가 샘플에 있을 경우에만.</p>
<p>그렇다면 plug-in estimate <span class="math inline">\(\bar k\)</span> from <span class="math inline">\(G^\ast\)</span>의 기댓값 <span class="math inline">\(\bar k^\ast\)</span>는 어떻게 되는가?</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

E \left( \bar k^\ast \right)


&amp;= E \left( \frac{1}{m} \sum_{i \in V^\ast} k_i^\ast \right)

&amp;&amp;= E \left( \frac{1}{m} \sum_{i \in V^\ast} \sum_{j \in V^\ast} A_{ij}^\ast \right)

\\


&amp;= E \left( \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}Z_i Z_j \right)

&amp;&amp;= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  E \left(Z_i Z_j \right)

\\

&amp;= \frac{1}{m} \sum_{i=1}^n \sum_{j =1}^n A_{ij}  \pi^2

&amp;&amp;=\frac{1}{n \pi} \pi^2 \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

\\

&amp;= \frac{\pi}{n } \sum_{i=1}^n \sum_{j =1}^n A_{ij}  

&amp;&amp;= \pi \bar k




\end{alignat}\]</span>
$$</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="exploratory-sampling-design" class="section level4" number="7.3.1.2">
<h4 number="7.3.1.2"><span class="header-section-number">7.3.1.2</span> Exploratory Sampling Design</h4>
<p><strong>induced</strong> 와 <strong>incident</strong> 이외의 방법론을 쓰고 싶은 경우도 있지 않을까? <strong>induced</strong> 와 <strong>incident</strong> 서브그래프 샘플링 양쪽 모두에서 <strong>sampling frame</strong> 은 실제로 발생하는 그래프에 비하면 약간 좀 거리가 있고 이질적이다. 우리가 SRS 를 사용하는 대상인 population 은 모든 node를 포함하거나, 모든 edge를 포함해야 하지만, <mark>but doesn’t use the graph beyond that.</mark></p>
<p><strong>egocentric</strong> 디자인에서 우리는 nodes 들을 샘플링한 후에 이렇게 샘플링된 nodes 들의 local 이웃에 대해서만, 혹은 <strong>ego network</strong> 에 대해서만, 정보를 수집하고 기록한다. 혹은 <strong>“ego”</strong> 케이스에서 우리는 edge 들이나 initial node 의 이웃들의 edges 들이나 non-edges 들만 기록함; 이는 때때로 <strong>star design</strong> 이라고 불림. star design 케이스에서 우리는 local 그래프 이웃에 대한 정보를 수집한 후 이들이 중복되는 지점이 있는지를 확인함. 기록 과정을 뭘 쓰느냐에 달려있긴 한데 이 정보는 보통 수집 가능함.</p>
<p><br>
<br>
<br></p>
<div id="snowball-sampling" class="section level5" number="7.3.1.2.1">
<h5 number="7.3.1.2.1"><span class="header-section-number">7.3.1.2.1</span> Snowball Sampling</h5>
<p>seed node 로 부터 시작. 이의 직접적인 이웃을 바로 기록. 이후 그 이웃들로 이동한 후 또 직접적인 이웃을 기록. 이 작업을 새로운 node 가 더이상 발견되지 않거나, 정해진 size 에 도달할 때까지 함. 이때 seeds 는 여럿이 있을 수 있음. 이 여럿인 경우에, 가령 seeds 가 2개라면, 진행하다가 서로 다른 seed 로부터 촉발된 2개의 snowball 이 overlap 되는 상황에 마주쳤을 때 어느 snowball을 고를지 결정하는 문제가 생김.</p>
<p><strong>snowball 샘플링</strong>은 그래프에 대해, incuded 나 incident 에 의해 얻어지는 것 그 어느것과도 다른 분포를 얻게 되는 결과를 초래함. seed 가 SRS에 의해 정해졌더라도 snowball 에 의해 골라지는 다른 node 들은 랜덤샘플이 아님. initial node 이외의 node 들은 seed 로부터 길을 따라서 도착할 수 있는 node 다 보니, 그들은 적어도 degree 가 1은 보장되어야 하고, 약하게나마 seed 에 연결은 되어 있어야 하마, 일반적으로 평균보다는 높은 degree 를 갖는 경향성을 보임.</p>
<p><br>
<br></p>
</div>
<div id="respondent-driven-sampling" class="section level5" number="7.3.1.2.2">
<h5 number="7.3.1.2.2"><span class="header-section-number">7.3.1.2.2</span> Respondent-driven Sampling</h5>
<p><strong>Respondent-driven</strong> 샘플링은 소셜네트워크 상황에서 snowball 샘플링의 유의한 변주. 이는 낙인되었거나 혹은 불법적이라 그들의 존재를 관계적으로 잘 발견해내기 어려운 <strong>sub-populations</strong> 을 찾아내기 위한 방법으로서 태초의 목적은 이것이었음. 이건 연구중인 문제에 해당하는 그룹 안의 멤버를 한둘 골라내서 이들을 이니셜 멤버로 한 뒤 걔들한테 주위 사람들 좀 여기 참가시켜보라고 설득하는 거. 때때로는 이 이니셜 멤버들한테 물리적 토큰(표식)을 준 뒤 이 물리적 표식을 여기 참가하라고 꼬실 대상들한테 뿌리라고 하는 식으로 link 를 트랙하기도 함. 이 물리적 토큰 자체가 인센티브일 수도 있고. 이때 응답자 별로 줄 수 있는 (허락되는) 토큰의 총량이 정해져 있다면 이건 곧 degree 의 censoring 으로 기능함.</p>
<p><br>
<br></p>
</div>
<div id="trace-route-sampling" class="section level5" number="7.3.1.2.3">
<h5 number="7.3.1.2.3"><span class="header-section-number">7.3.1.2.3</span> Trace-route Sampling</h5>
<p><strong>Trace-route</strong> 샘플링은 네트워크를 통과하는 각 route 들을 추적하여 네트워크를 검색함. 절차는 아래와 같다:</p>
<ol style="list-style-type: decimal">
<li>source node의 set 을 지정</li>
<li>target node의 set 을 지정</li>
<li>각각의 source-target의 조합에 대해서, source 에서 target으로 도착하는 path 하나를 찾고, 그후 이 path에서 거친 모든 edge와 node를 기록함.</li>
</ol>
<p>물론 이 프로세스는 어떤 path 가 탐색되었는가에 크게 의존하긴 하는데 이건 적용 층위의 문제지 메커니즘 자체가 문제가 있다고 할 건 아님. route 추적이 어떻게 이루어졌는지에 따라 연구자는 “실패” (source 에서 target 으로 도착 못했음) 한 route 에 대한 정보를 얻을수도 있고 못얻을수도 있음.</p>
<p><strong>Trace-route</strong> 샘플링은 체계적으로 degree 분포를 왜곡하며 모든 종류의 그래프들로 하여금 그들이 heavy-tail 인 것처럼 보이게 할 수 있다. 그들이 실제로 heavy-tail 이었든 아니든.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
</div>
<div id="coping-strategies" class="section level3" number="7.3.2">
<h3 number="7.3.2"><span class="header-section-number">7.3.2</span> Coping Strategies</h3>
<div id="head-in-sand" class="section level4" number="7.3.2.1">
<h4 number="7.3.2.1"><span class="header-section-number">7.3.2.1</span> Head in Sand</h4>
<p>이인즉 샘플링으로 인한 왜곡이나 bias 를 싹 무시하고 우리가 현재 보고 있는 그래프가 그래프의 참값이라고 가정하는 것. <strong>당연히 좋은 생각은 아님.</strong> <strong>incuded</strong> 서브그래프 샘플링의 경우에 mean degree는 real degree 에서 bias 되어 있는데, 이 bias 는 계산 가능함. 실제로 모든 <mark>motif</mark>에 대해 motif count 의 샘플값도 또한 (얘도 계산 가능한 방법으로) 편향되어 있다. 얘들을 사후적으로 보정하는 건 꽤 쉬운 편. 하지만 다른 놈들은 복잡하게 꼬여있는데, 꼬여있는 놈들 중 일례로 degree 분포의 경우에는 매우 복잡하게 왜곡되어 있어서 사후적으로 보정하기가 드럽게 어렵다. 이건 induced 상황에서도 마찬가지로 복잡해서 사후적 보정이 난해함.</p>
<p><br>
<br>
<br></p>
</div>
<div id="learn-sampling-theory" class="section level4" number="7.3.2.2">
<h4 number="7.3.2.2"><span class="header-section-number">7.3.2.2</span> Learn Sampling Theory</h4>
<p><strong>Classical sampling theory</strong>은 통계적 추론에 대한 이론으로, <mark>probability assumption은 오직 샘플링 프로세스에 대해서만 (성립)만들어진다는 것을 그 골자로 한다.</mark> population의 참값은 unknown 하나 fixed 되어 이 참값이 어떻게 생산되었는지에 대해서는 어떤 stochastic 가정도 만들어지지 않는다. (이를 unknown population 에 대해 조건부를 건다고 생각해도 틀리지 않다.) 모든 probability assumption 들이 샘플링 디자인에 대해서만 논하며, 추론의 타당성은 오직 디자인이 정확히 모델링되었는지 여부에만 의존하므로, 이는 때때로 <strong>design-based</strong> 추론이라고도 불린다.</p>
<p>크기가 n 인 어떤 finite population 에 대한 어떤 quantity <span class="math inline">\(X_i\)</span> 의 평균을 a sample of units <span class="math inline">\(S\)</span> 를 사용해구하고자 하는 상황이라고 해보자. 간단하고 고전적인 해는 <strong>Horvitz-Thompson estimator</strong>:</p>
<p><span class="math display">\[
\hat \mu_{HT} \equiv \frac{1}{n} \sum_{i \in S}\frac{X_i}{\pi_i}
\]</span></p>
<ul>
<li><span class="math inline">\(\pi_i\)</span>는 unit <span class="math inline">\(i\)</span>의 (assumed-known) 포함확률, 즉 unit <span class="math inline">\(i\)</span>가 샘플에 포함될 확률.</li>
</ul>
<p>포함 확률은 <span class="math inline">\(\pi = \frac{|S|}{n}\)</span>로 모두 동일하다는 것을 notice. 즉 우리는 다시 sample mean <span class="math inline">\(X\)</span>로 되돌아감. 이에 대한 직관은 곧 우리가 1개의 unit을 보았고 그 unit의 포함확률이 <span class="math inline">\(\pi_i\)</span>라면, 우리가 보지 못한 <span class="math inline">\(\frac{1}{\pi_i}\)</span>개의 다른 것들이 있다는 것이 골자이다. 더 이론적으로 들어가자면 우리는 이것이 <strong>UE</strong>임을 보일 수 있다.</p>
<p>indicator 변수 <span class="math inline">\(Z_i = I(i \in S), i \in 1:n\)</span>을 도입하자. 이를 사용하여 <span class="math inline">\(\hat \mu_{HT}\)</span>의 기댓값을 구하면</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

E \left( \hat \mu_{HT} \right)


&amp;= E \left(\frac{1}{n} \sum_{i \in S} \frac{X_i}{\pi_i} \right)

&amp;&amp;= E \left(\frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} Z_i \right)

\\

&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} E \left( Z_i \right)

&amp;&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} P \left( Z_i =1 \right)

\\

&amp;= \frac{1}{n} \sum_{i \in 1:n} \frac{X_i}{\pi_i} \pi_i

&amp;&amp;= \frac{1}{n} \sum_{i \in 1:n} {X_i}

\\

&amp;= \mu

\end{alignat}\]</span>
$$</p>
<p>또한</p>
<p><span class="math display">\[
Var \left ( \hat \mu_{HT} \right )= \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]</span></p>
<p>이때 <span class="math inline">\(\pi_{ij}\)</span>는 joint 포함확률. 즉슨 <span class="math inline">\(i,j\)</span>가 한번에 샘플에 들어있을 확률. (<span class="math inline">\(\pi_{ii} = \pi_i\)</span>로 취급)</p>
<p>모든 <span class="math inline">\(\pi_i \rightarrow 1\)</span>로 가게 된다면, <span class="math inline">\(Var \rightarrow 0\)</span>.</p>
<p>이 Var 참값을 정확히 계산하는 건 불가능. 우리는 population 안의 모든 unknown units의 합을 구하는건 불가능하기 때문. 그러가 empirical 대체값은 주어져 있다. 이는</p>
<p><span class="math display">\[
\hat {Var} \left ( \hat \mu_{HT} \right) = \frac{1}{n^2} \sum_{i \in 1:n} \sum_{j \in 1:n} X_i X_j \left( \frac{\pi_{ij}}{\pi_i \pi_j} -1 \right)
\]</span></p>
<p><strong>sampling-theory approach</strong>는 population quantity의 평균 (혹은 총량) 으로 나타낼 수 있는 대상에게 적합. 혹은 샘플링 디자인에 대한 지식으로부터 포함 (inclusion) 확률을 파악할 수 있는 상황에 대해서도 쓸만하다. 많은 네트워크 stats는 <strong>평균</strong>으로 표현될 수 있지만 (때때로 “unit”을 정의하여 해결하기도 함, node 의 dyad 같은 거), inclusion 확률을 정확히 계산해내는 건 평균 구하는 것보다는 더 빡셈.</p>
<p><br>
<br>
<br></p>
</div>
<div id="missing-data-tools" class="section level4" number="7.3.2.3">
<h4 number="7.3.2.3"><span class="header-section-number">7.3.2.3</span> Missing Data Tools</h4>
<p>다른 방법은 네트워크에서 unobserved 된 부분을 missing data로 처리하고 이를 추론해버리는 것. 이건 simple imputation 전략부터 시작해서, EM 알고리즘과 같이 추론에 대한 복잡한 모델-based 전략에 이르기까지 다양한 것들이 속한다. EM 혹은 성공적인 imputation은 design-based 가 아니라 model-based 이며, 네트워크와 샘플링 프로세스 양쪽 모두에 대한 모델을 필요로 한다. 실전에서 “missing at random” 상황은 진짜 엄청나게 드물며, “missing completely at random” 상황조차도 흔하지 않다. <mark> let alone </mark></p>
<p><br>
<br>
<br></p>
</div>
<div id="model-the-effective-network" class="section level4" number="7.3.2.4">
<h4 number="7.3.2.4"><span class="header-section-number">7.3.2.4</span> Model the Effective Network</h4>
<p>마지막 전략은 observed 네트워크를 모델링하는 것. 즉 observation / 샘플링 프로세스와 실제 네트워크 양쪽 모두를 모델링하지만, 그 후 이 둘을 합치는 것으로 observed 그래프에 대한 확률 분포의 family 를 얻는 것이 가능함. 그 observed 네트워크는 underlying generative 모델의 패러미터에 대해 여전히 informative. 이게 알고 싶은 전부라면, 여기까지만 진행한 후에 종료해버릴 수 있음. 전부가 아니라면 이것 이후에 EM이나 imputation 써서 full 그래프를 복원하고자 시도하게 될 것이고.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="big-data-solves-nothing" class="section level3" number="7.3.3">
<h3 number="7.3.3"><span class="header-section-number">7.3.3</span> Big Data Solves Nothing</h3>
<p>“<span class="math inline">\(n =\)</span> all” 로 설정되고 모든 데이터가 자동적으로 기록된 경우에도 우리가 겪어온 모든 네트워크 샘플링 문제는 여전히 남아있음. 이런 상황에서도 우리가 얻은 데이터는 결국 biased convenience 샘플을 갖고 있는 것이지 가지고 있는 모든 자료가 참값이라고 말할 수가 없기 때문임. 네트워크에서는 특히 아래와 같은 3가지 문제가 두드러짐.</p>
<p><mark>Even when, as the promoters say, “n = all,” and the data are automatically recorded (voluntarily or involuntarily), almost all the network sampling issues we’ve gone over remain. After all, as the promoters do not say, you’re getting all of a biased convenience sample, not all of the truth. Three issues are particularly prominent for network.</mark></p>
<ol style="list-style-type: decimal">
<li>Entity Resolution</li>
<li>Diffusion</li>
<li>Performativity</li>
</ol>
<p><br>
<br>
<br></p>
<div id="entity-resolution" class="section level4" number="7.3.3.1">
<h4 number="7.3.3.1"><span class="header-section-number">7.3.3.1</span> Entity resolution</h4>
<p><strong>Entity resolution</strong>, 혹은 <strong>record linkage</strong> 라 불리는 것은 데이터 분석에서 메이저한 문제 중 하나. 이는 간단하게 말하면 동일 대상에 대해 서로 다른 시간대에 기록된 자료가 있다면 이 중 무엇을 쓸 것인가 하는 문제. 혹은 겉보기에 같은 대상에 대해 서술하는 것 같은 (co-referent) 기록들이 실제로는 다른 것들에 대해 이야기하고 있는 상황
. 네트워크에서 이는 보통 같은 underlying entity 로 직결되는 2개의 다른 node 들 중에 뭘 고를까 하는 문제가 됨.</p>
<p><br>
<br>
<br></p>
</div>
<div id="diffusion" class="section level4" number="7.3.3.2">
<h4 number="7.3.3.2"><span class="header-section-number">7.3.3.2</span> Diffusion</h4>
<p><strong>diffusion</strong>은 우리에게 빅데이터를 제공하는 많은 자동적으로 기록된 네트워크들이 다른 오래된 소셜 네트워크로 퍼져나가는 것. <mark>provide A with B</mark> 예를 들어 페북의 tie는 pre-페북의 소셜 네트워크과 diffusion 프로세스의 결과물이다. 이 결과물을 이해하는데에는 비교적 약간의 노력만이 이루어졌다. diffusion 프로세스가 모든 node 를 균질하게 취겁하더라도, diffusion을 당한 네트워크는 기반 네트워크와 그 특성이 근본적으로 다를 수 있다.</p>
<p><br>
<br>
<br></p>
</div>
<div id="performativity" class="section level4" number="7.3.3.3">
<h4 number="7.3.3.3"><span class="header-section-number">7.3.3.3</span> Performativity</h4>
<p>이론이 자기실현적 예전이 되어버리는 상황을 Performativity라고 함. 온라인 소셜 네트워크를 운영하는 회사들은 사용자들의 크고 조밀한 네트워크를 만들어낼 수 있도록 엄청나게 투자중. 이것이 그들이 link 제안 혹은 link 추천 서비스를 제공하는 이유임. 왜 당신이 아실지도 모르는 친구 이런거. 이러한 추천의 이면에 있는 알고리즘들은 소셜 네트워크가 어떻게 만들어지는지에 대한 이론과 그들이 어떤 link 패턴을 가져야하는지에 대한 이론 등이 반영되어 있다. 유저들이 이러한 추천 친구와 link 를 수락하는 순간 이 알고리즘 이면에 반영된 이론의 입맛에 맞는 케이스가 강화되는 거.</p>
<!--chapter:end:212103_DataCollection.Rmd-->
</div>
</div>
</div>
<div id="mathematical-models-for-network-graphs" class="section level2" number="7.4">
<h2 number="7.4"><span class="header-section-number">7.4</span> Mathematical Models for Network Graphs</h2>
<ol style="list-style-type: decimal">
<li>By a model for a network graph we mean effectively a collection
<ul>
<li><span class="math inline">\(G\)</span> 는 가능한 그래프들의 collection (혹은 ‘ensemble’)</li>
<li><span class="math inline">\(P_\theta\)</span>는 <span class="math inline">\(G\)</span>의 확률분포 (간단하게 쓰면 <span class="math inline">\(\cdot_\theta\)</span> 생략하고 <span class="math inline">\(P\)</span>만 씀)</li>
<li><span class="math inline">\(\theta\)</span>는 <span class="math inline">\(\Theta\)</span> 내부에서 가능한 값들 안에서 펼쳐져있는 (ranging over) 패러미터들(패러미터값들)의 벡터</li>
</ul></li>
</ol>
<p><span class="math display">\[
\Big \{ 
P_\theta (G), \; G \in \mathcal G \; \; : \; \; \theta \in \Theta
\Big \}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Variety of Purposes</li>
</ol>
<ul>
<li>The testing for ‘significance’ of a pre-defined characteristic(s) in a given network graph</li>
<li>The study of proposed mechanisms for generating certain commonly observed properties in real-world
networks (such as broad degree distributions or small-world effects),</li>
<li>The assessment of potential predictive factors of relational ties.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>The richness of network graph modeling derives largely from how we choose to specify P(·), with methods in the literature ranging from the simple to the complex.</p></li>
<li><p>It is useful for our purposes to distinguish, broadly speaking, between models defined more from (i) a mathematical perspective, versus (ii) a statistical perspective.
• Those of the former class tend to be simpler in nature and more amendable to mathematical analysis yet, at the same time, do not always necessarily lend themselves well to formal statistical techniques of model fitting and assessment.
• On the other hand, those of the latter class typically are designed to be fit to data, but their mathematical analysis can be challenging in some cases.
• Nonetheless, both classes of network graph models have their uses for analyzing network graph data.</p></li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br></p>
<div id="classical-random-graph-models" class="section level3" number="7.4.1">
<h3 number="7.4.1"><span class="header-section-number">7.4.1</span> Classical Random Graph Models</h3>
<ol style="list-style-type: decimal">
<li><p><strong>random graph model</strong>이라는 용어는 collection <span class="math inline">\(\mathcal G\)</span>과 <span class="math inline">\(\mathcal G\)</span>에 대한 uniform probability <span class="math inline">\(P(\cdot)\)</span>을 묶어 일컬음. 수학적 관점에서 가장 잘 정의된 네트워크 그래프 모델.</p></li>
<li><p>주어진 order와 size를 따르는 그래프에 대한 모든 후보군에 동일 확률 부여. <span class="math inline">\(|V|=N_v\)</span>, <span class="math inline">\(|E| = N_e\)</span>를 만족하는 모든 그래프 <span class="math inline">\(G=(V,E)\)</span>의 collection <span class="math inline">\(\mathcal G_{N_v, N_e}\)</span>을 정의하고, 각각의 <span class="math inline">\(G \in \mathcal G_{N_v, N_e}\)</span>에 확률 <span class="math inline">\(P(G) = {N \choose N_e}^{-1}\)</span>을 부여함. 이때 <span class="math inline">\(N= {N_v \choose 2}\)</span>는 서로 다른 vertex 2개를 묶은 쌍의 총 숫자.</p></li>
<li><p><span class="math inline">\(\mathcal G_{N_v, N_e}\)</span>의 변용이 실전에서는 더 자주 보임. 이 공식에서, <span class="math inline">\(\mathcal G_{N_v, p}\)</span>는 order <span class="math inline">\(N_v\)</span>의 모든 그래프 <span class="math inline">\(G\)</span>로 구성되어 있다. 이는 서로 다른 vertex의 쌍에 <span class="math inline">\(p \in (0,1)\)</span>의 확률로 edge 1개를 독립적으로 부여하는 것으로 얻어질 수 있다. 이러한 종류의 모델은 <strong>Bernoulli random graph model</strong>라고 불림. <span class="math inline">\(p\)</span>가 <span class="math inline">\(N_v\)</span>의 적절하게 정의된 함수이며, <span class="math inline">\(N_e \sim p N_v^2\)</span>하면, 이 모델들의 두 클래스는 large <span class="math inline">\(N_v\)</span>와 거의 동치된다.</p></li>
<li><p>The function erdos.renyi.game in igraph can be used to simulate classical random graphs of either type. The choice of Nv = 100 vertices and a probability of p = 0.02 of an edge between any pair of vertices.</p></li>
</ol>
<pre><code>library(sand)
g.er = erdos.renyi.game(100, 0.02)
par(mfrow=c(1,2))
plot(g.er, layout=layout.circle, vertex.label=NA)
hist(degree(g.er), col=&quot;lightblue&quot;, xlab=&quot;Degree&quot;, ylab=&quot;Frequency&quot;, main=&quot;&quot;)
is.connected(g.er)
table(sapply(decompose.graph(g.er),vcount))</code></pre>
<p><span class="math inline">\(\exists c&gt;1:p = \frac{c}{N_v}\)</span>가 성립한다면, classical random graph <span class="math inline">\(G\)</span>는 giant component를 보유할 확률이 높다.</p>
<p>위와 <span class="math inline">\(p\)</span>를 동일하게 정의한다면, <span class="math inline">\(c&gt;0\)</span>에 대해, degree distribution은 large <span class="math inline">\(N_v\)</span>에 대해 <span class="math inline">\(POI(c)\)</span>로 잘 모사된다. 이게 사실이라는 건 직관적으로 보이기도 쉽다. 아무 vertex나 하나 뽑았을 때 이의 degree가 <span class="math inline">\(B(N_v-1, p)\)</span>를 따르기 때문이다. 이는 곧 mean degree는 <span class="math inline">\(p(N_v-1)\)</span>에 근접한다는 소리.</p>
<p>classical random graph의 다른 성질은 vertex 쌍 사이에서 shortest path 위에는 상대적으로 적은 숫자의 vertex가 존재한다는 것이며 이로 인해 clustering도 low하다는 것이다. path가 길어야 상대적으로 공간이 넉넉해서 여러개의 vertex가 그 위에 안착할 가능성이 높은데 짧으면 그만큼 공간 좁아서 없는게 정상일테니까.</p>
<pre><code>average.path.length(g.er)
diameter(g.er)
transitivity(g.er)</code></pre>
<p><br>
<br>
<br>
<br>
<br>
<br></p>
</div>
<div id="generalized-random-graph-models" class="section level3" number="7.4.2">
<h3 number="7.4.2"><span class="header-section-number">7.4.2</span> Generalized Random Graph Models</h3>
<ol style="list-style-type: decimal">
<li><p>이하의 성질을 갖고, fixed order <span class="math inline">\(N_v\)</span>를 따르는 모든 그래프의 collection <span class="math inline">\(\mathcal G\)</span>를 정의한다. 각 그래프 <span class="math inline">\(G \in \mathcal G\)</span>에 동일 확률 부여</p></li>
<li><p>가장 자주 부여되는 성질은 fixed degree sequence의 그것. <span class="math inline">\(\mathcal G\)</span>를 모든 그래프 <span class="math inline">\(G\)</span>의 collection으로 정의, 이때 이는 미리 정해진 degree sequence를 따름. 이를 ordered form으로 적으면 <span class="math inline">\(\{d_{(1)}, \cdots, d_{(N_v)} \}\)</span>. 이 조건을 따르면서도 다른 모양의 그래프는 얼마든지 그려지며 따라서 isomorphic이 아님.</p></li>
</ol>
<pre><code>degs = c(2, 2, 2, 2, 3, 3, 3, 3)
g1 = degree.sequence.game(degs, method=&quot;vl&quot;)
g2 = degree.sequence.game(degs, method=&quot;vl&quot;)
par(mfrow=c(1,2))
plot(g1, vertex.label=NA)
plot(g2, vertex.label=NA)
#해당 케이스에선 N_v=8 vertex, 이중 절반은 degree=2, 나머지 절반은 3.</code></pre>
<pre><code>graph.isomorphic(g1, g2)
c(ecount(g1), ecount(g2))</code></pre>
<p>고정된 숫자의 vertex <span class="math inline">\(N_v\)</span>에서 fixed degree sequence를 따르는 랜덤 그래프들의 collection들은 모두 egde 숫자 <span class="math inline">\(N_e\)</span>로 동일하다. 이는 mean degree of sqeuence <span class="math inline">\(\{d_{(1)}, \cdots, d_{(N_v)}\}\)</span>는 <span class="math inline">\(\tilde d = \frac{2N_e}{N_v}\)</span>이니까.</p>
<p>따라서 이 collection은 랜덤 그래프의 collection <span class="math inline">\(\mathcal G_{N_v , N_e}\)</span> 안에 strictly 들어있음. 따라서 degree sequence의 가정된 형태의 추가는 원본 collection <span class="math inline">\(\mathcal G_{N_v , N_e}\)</span>에 조건부 분포를 걸어 우리의 모델을 특정짓은 것과 동일함. 다른말로 이는 degree sequence에 의해 제약되지 않은 부분은 얼마든지 vary 가능하다는 것을 의미.</p>
<pre><code>data(yeast)
degs = degree(yeast)
fake.yeast = degree.sequence.game(degs, method=c(&quot;vl&quot;))
all(degree(yeast) == degree(fake.yeast))
diameter(yeast)
diameter(fake.yeast)
transitivity(yeast)
transitivity(fake.yeast)
</code></pre>
<p>하지만 이렇게 고삐를 풀어버리면 원본 네트워크의 직경은 시뮬레이션된 물건의 2배에 달하며 사실상 만들어두었던 clustering들도 다 날아가버렸음. 원칙적으로 class <span class="math inline">\(\mathcal G\)</span>의 정의를 제한하는 편이 훨씬 쉬우며 그렇기에 degree sequence 이외의 다른 추가적인 특성들은 그냥 고정해버림. 이러한 collection으로부터 랜덤 그래프들 <span class="math inline">\(\mathcal G\)</span>을 생산해내는데에는 MCMC 방법론이 유명하다. 이때 MC에 의해 액세스되는 상태들 그 자체 각각들이 graph <span class="math inline">\(\mathcal G\)</span>에 해당함.</p>
<p><br>
<br>
<br>
<br>
<br>
<br></p>
</div>
<div id="network-graph-models-based-on-mechanisms" class="section level3" number="7.4.3">
<h3 number="7.4.3"><span class="header-section-number">7.4.3</span> Network Graph Models Based on Mechanisms</h3>
<p>모던 네트워크 그래프 모델링에서 가장 중요한 혁명 중 하나가 전통적인 랜덤 그래프 모델에서 실제 세계의 성질을 모사하는 쪽으로 옮겨갔다는 거임. 이건 그냥 간단한 몇몇 메커니즘 도입하는 것으로 성공되었음.</p>
<p><br>
<br>
<br></p>
<div id="small-world-models" class="section level4" number="7.4.3.1">
<h4 number="7.4.3.1"><span class="header-section-number">7.4.3.1</span> Small-World Models</h4>
<ul>
<li><strong>small-world network</strong></li>
</ul>
<p>대부분의 node가 다른 node들과 이웃이 아닌 케이스. 그러나 다른 node를 작은 횟수 거치면 모든 노드에 액세스 가능한 케이스. 해당하는 케이스 생산하는 방법으로 lattice 구조로 우선 잔 후에 적은 확률 부여해서 무작위로 각 node로 rewiring.</p>
<p><mark>We begin with a set of Nv vertices, arranged in a periodic faction, and join each vertex to r of its neighbors to each side. For each edge, independently and with probability p, one end of that edge will be moved to be incident to another vertex, where that new vertex is chosen uniformly, but with attention to avoid the construction of loops and multi-edges.</p>
<p>추가적인 조치 없이 lattice만 단독으로 있으면 (<span class="math inline">\(p=0\)</span> 상황에서 생산됨) 이 경우에는 clustering의 양이 상당하게 나오지만, vertex간의 거리는 non-trivial해짐. 이런 lattice에 상대적으로 적은 숫장 edge 대상으로 rewiring을 거치는 것만으로 vertex 사이의 거리를 극적으로 줄일 수 있다. 이때 clustering level은 높게 유지된다는 것이 포인트. 이 효과는 <span class="math inline">\(p\)</span>가 극적으로 작더라도 여전히 얻어질 수 있다.</p>
<pre><code>g.ws = watts.strogatz.game(1, 25, 5, 0.05)
plot(g.ws, layout=layout.circle, vertex.label=NA)
g.lat100 = watts.strogatz.game(1, 100, 5, 0)
transitivity(g.lat100)
plot(g.lat100, layout=layout.reingold.tilford, vertex.label=NA)
diameter(g.lat100)
average.path.length(g.lat100)
g.ws100 = watts.strogatz.game(1, 100, 5, 0.05)
diameter(g.ws100)
average.path.length(g.ws100)
transitivity(g.ws100)</code></pre>
<pre><code>steps = seq(-4, -0.5, 0.1)
len = length(steps)
cl = numeric(len)
apl = numeric(len)
ntrials = 100
for(i in 1:len){
cltemp = numeric(ntrials)
apltemp = numeric(ntrials)
for(j in 1:ntrials){
g = watts.strogatz.game(1, 1000, 10, 10ˆsteps[i])
cltemp[j] = transitivity(g)
apltemp[j] = average.path.length(g)
}
cl[i] = mean(cltemp)
apl[i] = mean(apltemp)</code></pre>
<p>이 결과는 (normalized 평균적인 path의 길이들과 clustering coefficient들의) 개략적인 기댓값을 p 대비로 plot한 것으로, p가 엄청나게 극단적인 값으로 가지 않은 이상 네트워크가 계속 높은 수준의 clustering을 유지하면서 작은 평균 거리를 보이는 것이 확인된다.</p>
<pre><code>plot(steps, cl/max(cl), ylim=c(0,1), lwd=3, type=&quot;l&quot;, col=&quot;blue&quot;,
xlab=expression(log[10](p)), ylab=&quot;Clustering and Average Path Length&quot;)
lines(steps, apl/max(apl), lwd=3, col=&quot;red&quot;)</code></pre>
<p><br>
<br>
<br></p>
</div>
<div id="preferential-attachment-models" class="section level4" number="7.4.3.2">
<h4 number="7.4.3.2"><span class="header-section-number">7.4.3.2</span> Preferential Attachment Models</h4>
<p>대부분의 네트워크는 시간에 따라 변화함. 주어진 시간 <span class="math inline">\(t\)</span>에 네트워크가 어떻게 변화하는지는 vertex preferences, fitness, age 등에 따라서든 다양. <strong>Preferential attachment</strong>는 많은 노드와 연결된 대형 노드가 추가적인 link를 확보할 가능성이 높다는 것. SNS에서의 셀럽 생각하면 됨.</p>
<p>undirected 네트워크의 <strong>Barabasi-Albert (BA) model</strong> 은 다음과 같음.</p>
<ol style="list-style-type: decimal">
<li><p>시작 vertex <span class="math inline">\(N_v^{(0)}\)</span>, 시작 edge <span class="math inline">\(N_e^{(0)}\)</span> 가지는 시작 그래프 <span class="math inline">\(G^{(0)}\)</span>로 시작.</p></li>
<li><p>각 시간 <span class="math inline">\(t = 1, 2, \cdots\)</span>에서 <span class="math inline">\(G^{(t-1)}\)</span> 기반으로 <span class="math inline">\(G^{(t)}\)</span> 생산. 추가적인 vertex 를 넣되 이 추가되는 vertex들의 degree는 <span class="math inline">\(m \ge 1\)</span>이고, <span class="math inline">\(m\)</span>개의 새로운 edge들이 <span class="math inline">\(m\)</span>개의 서로 다른 vertex에 들러붙음. 이때 새로운 vertex가 기존의 vertex에 들러붙을 확률은 <span class="math inline">\(\frac{d_v}{\sum_{v&#39; \in V}d_{v&#39;}}\)</span> 을 따름. 즉 기존 그래프에서 높은 degree를 가지고 있던 vertex가 새 vertex와도 들러붙을 확률 높음.</p></li>
<li><p>t번의 이터레이션 후에 결과값 그래프 <span class="math inline">\(G(t)\)</span>는 <span class="math inline">\(N_v^{(t)} = N_v^{(0)} + t\)</span> 개의 vertex와 <span class="math inline">\(N_e^{(t)} = N_e^{(0)} + tm\)</span> 개의 edge 를 가진다.</p></li>
</ol>
<p>이런 preferential attachment 경향성 때문에 이터레이션이 쌓일수록 높은 degree를 보유하는 vertex가 많아질 것을 기대할 수 있다.</p>
<pre><code>g.ba = barabasi.game(100, directed=FALSE)
par(mfrow=c(1,2))
plot(g.ba, layout=layout.circle, vertex.label=NA)
hist(degree(g.ba), col=&quot;lightblue&quot;, xlab=&quot;Degree&quot;, ylab=&quot;Frequency&quot;, main=&quot;&quot;)</code></pre>
<p>고전적인 랜덤 그래프 (SRS) 대비 vertex 쌍 사이의 edge가 uniform 분포를 따르지 않음을 유의. 이런 경향에 의해 edge를 다수 끌어모으고 있는 “hub”라 불릴만한 vertex가 있는 것으로 사료됨. 여기서 전체 분포는 꽤 heterogeneous한 감이 있는데, 대부분의 vertex는 degree가 2를 넘지도 못함.</p>
<pre><code>summary(degree(g.ba))</code></pre>
<p>이러한 <strong>preferential attachment</strong> 모델에서 특필될만한 특징은 <span class="math inline">\(t \rightarrow \infty\)</span> 따라서 그래프 <span class="math inline">\(G^{(t)}\)</span>의 degree distribution이 <span class="math inline">\(d^{-\alpha}\)</span>, <span class="math inline">\(\alpha = 3\)</span>의 형을 갖는 경향을 보인다는 것이다. 이러한 경향은 고전적인 랜덤 그래프와 큰 차이점임.</p>
<p>반면에 BA 모델에 의해 생성된 네트워크 그래프는 vertex 쌍 사이의 shotest path 위에 위치하는 vertex 숫자가 점점 적어지며 또한 low clustering이라는 고전적인 랜덤 그래프의 특징을 어느정도 공유한다. <mark>뭔소리야 BA가 preferential attachment 모델을 생산하려고 고안된게 아냐? BA가 preferential attachment 모사하려고 고안되긴 했는데 preferential attachment의 특성을 모두 복사하진 못했고 BA의 한계상 asymptotic 상황에서 고전적 랜덤 그래프 성질을 가져버렸다는건가?</mark></p>
<pre><code>average.path.length(g.ba)
diameter(g.ba)
transitivity(g.ba)</code></pre>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="assessing-significance-of-network-graph-characteristics" class="section level3" number="7.4.4">
<h3 number="7.4.4"><span class="header-section-number">7.4.4</span> Assessing Significance of Network Graph Characteristics</h3>
<p>위에서 설명한 네트워크 모델들은 관측된 네트워크들로 통계적 모델링하긴 너무너무 간단함. 간단해서 현실모사를 제대로 못해서 쓸모가 없음. 그래도 중요하긴 함. 통계적 가설 검정 측면에서는 말이지. 특히 네트워크 그래프 성질의 significance를 측정(test)하는데 있어 자주 쓰임.</p>
<p>우리가 observations으로부터 얻은 그래프 <span class="math inline">\(G^{obs}\)</span>를 가지고 있다고 가정하자. 우리는 이때 임의의 structural 특성인 <span class="math inline">\(\eta(\cdot)\)</span>에 관심있음. 이 경우 <span class="math inline">\(\eta(G^{obs})\)</span>가 unusual 이든 unexpected 이든 significant 한지를 체크하는 것은 중요함. 지금까지 위에서 언급해온 네트워크 모델들에 대한 이론은 바로 이 경우에 기준으로서 동작한다는 점에서 중요. 이인즉 우리가 가지고 있는 그래프들의 collection <span class="math inline">\(\mathcal G\)</span> 에 대해 <span class="math inline">\(\eta(G^{obs})\)</span>를 각 그래프들을 넣어본 값들의 collection <span class="math inline">\(\{ \eta(G): G \in \mathcal(G)\}\)</span> 과 비교해본다는 것이다. 이때 해당 collection에 들어있는 값들 대비 <span class="math inline">\(\eta(G^{obs})\)</span>가 극단적이라고 판정되면 <span class="math inline">\(\eta(G^{obs})\)</span>가 보유한 값이 unusual하다는 것을 판정내릴 수 있는 재료가 됨.</p>
<p>랜덤 그래프 모델을 사용할 경우 척도가 될 수 있는 distribution을 개발하고자 하는 움직임은 지극히 정상적임. 이는 <span class="math inline">\(\mathcal G\)</span> 안에 있는 각 그래프들 <span class="math inline">\(G\)</span> 각각에 uniform 확률을 부여해서 만들어보는 게 합리적. 이는 곧</p>
<p><span class="math display">\[
P_{\eta, \mathcal G} (t) = \frac{\text{#}\{ g \in \mathcal G \; : \; \eta(G) \le t \}}{| \mathcal G |}
\]</span></p>
<p><mark>만약 <span class="math inline">\(\eta(G^{obs})\)</span>가 이 분포를 따르지 않을 것 같은 확률이 높다면 <span class="math inline">\(G^{obs}\)</span>는 <span class="math inline">\(\mathcal G\)</span>로부터의 uniform draw가 아니라는 쪽에 힘이 실림.</mark> 이는 랜덤 그래프를 예쁘게 따르는 자주 발생하지 않는 상황 대비 실제 상황으로부터 서브그래프를 뽑아내게 되는 자주 마주치는 상황에 활용가능하다는 점에서 실용적.</p>
<p><br>
<br>
<br></p>
<div id="assessing-the-number-of-communities-in-a-network" class="section level4" number="7.4.4.1">
<h4 number="7.4.4.1"><span class="header-section-number">7.4.4.1</span> Assessing the Number of Communities in a Network</h4>
<p>위에서 karate 데이터에 hierarchical clustering 사용했더니 clustering 3개 발견했음. 이 karate 데이터에 비추어볼 그래프로 2개의 <span class="math inline">\(G\)</span>를 생각하자.</p>
<ol style="list-style-type: decimal">
<li>karate 네트워크와 동일하게 same order <span class="math inline">\(N_v = 34\)</span>, size <span class="math inline">\(N_e = 78\)</span></li>
<li>1번에 더해서 원본과 동일한 degree distribution 따름</li>
</ol>
<p>MCMC 써서 생산. <mark>뭐 deterministic 관점이었던 물건에 시뮬레이션을 통한 랜덤 관점으로 접근하는 거라는 이야기? 단점이란 소리인가?</mark></p>
<pre><code>data(karate)
nv = vcount(karate)
ne = ecount(karate)
degs = degree(karate)
ntrials = 1000</code></pre>
<p>• We then generate classical random graphs of this same order and size and, for each one, we use the
same community detection algorithm to determine the number of communities.</p>
<pre><code>num.comm.rg = numeric(ntrials)
for(i in 1:ntrials){
g.rg = erdos.renyi.game(nv, ne, type=&quot;gnm&quot;)
c.rg = fastgreedy.community(g.rg)
num.comm.rg[i] = length(c.rg)
}</code></pre>
<p>• Similarly, we do the same using generalized random graphs constrained to have the required degree
sequence.</p>
<pre><code>num.comm.grg = numeric(ntrials)
for(i in 1:ntrials){
g.grg = degree.sequence.game(degs, method=&quot;vl&quot;)
c.grg = fastgreedy.community(g.grg)
num.comm.grg[i] = length(c.grg)
}</code></pre>
<p>• The results may be summarized and compared using side by side bar plots.</p>
<pre><code>rslts = c(num.comm.rg,num.comm.grg)
indx = c(rep(0, ntrials), rep(1, ntrials))
counts = table(indx, rslts)/ntrials
barplot(counts, beside=TRUE, col=c(&quot;blue&quot;, &quot;red&quot;),
xlab=&quot;Number of Communities&quot;, ylab=&quot;Relative Frequency&quot;,
legend=c(&quot;Fixed Size&quot;, &quot;Fixed Degree Sequence&quot;))</code></pre>
<p>• Clearly the actual number of communities detected in the original karate network (i.e., three) would
be considered unusual from the perspective of random graphs of both fixed size and fixed degree
sequence.
• Accordingly, we may conclude that there is likely an additional mechanism(s) at work in the actual
karate club, one that goes beyond simply the density and the distribution of social interactions in
this network.</p>
<p><br>
<br>
<br></p>
</div>
<div id="assessing-small-world-properties" class="section level4" number="7.4.4.2">
<h4 number="7.4.4.2"><span class="header-section-number">7.4.4.2</span> Assessing Small World Properties</h4>
<p>small-world 여부를 확인하는 일반적인 방법론은 대상 네트워크의 clustering coefficient와 average (shortest) path 길이를 보정된 고전적 랜덤 그래프에서 확인할 수 있는 그것들과 비교하는 것이다. 고전적 랜덤 그래프의 그것과 비교했을 때, 만약 대상 네트워크가 small-world라면, clsutering coefficient는 고전적 랜덤 그래프보다 크되, average path 길이는 대충 비슷할 것으로 예상함.</p>
<pre><code>library(igraphdata)
data(macaque)
summary(macaque)</code></pre>
<p>해당 네트워크에서 clustering을 평가하기 위해 directed 네트워크에 해당하는 clustering coefficient 의 변형 사용. 이 변량은 모든 vertex <span class="math inline">\(v\)</span>에 대해 vertex 각각의 clsutering coefficient를 평균낸 것이 된다.</p>
<ul>
<li>A는 adjacency Matrix</li>
<li><span class="math inline">\(d_v^{tot}\)</span>는 vertex <span class="math inline">\(v\)</span>의 총 degree (i.e., in-degree plus out-degree)</li>
</ul>
<p><span class="math display">\[
cl(v) = \frac{\left( A+ A&#39; \right)^3_{vv}}{ 2 \left [ d_v^{tot}(d_v^{tot} - 1) - 2 (A^2)_{vv} \right]}
\]</span></p>
<pre><code>clust.coef.dir &lt;- function(graph){
A = as.matrix(get.adjacency(graph))
S = A + t(A)
deg = degree(graph, mode=c(&quot;total&quot;))
num = diag(S %*% S %*% S)
denom = diag(A %*% A)
denom = 2 * (deg * (deg - 1) - 2 * denom)
cl = mean(num / denom)
return(cl)
}</code></pre>
<p>비교하려면 고전적 랜덤 그래프를 생산하고 이의 각각의 clustering과 평균 path length를 계산하는 과정 필요.</p>
<pre><code>ntrials = 1000
nv = vcount(macaque)
ne = ecount(macaque)
cl.rg = numeric(ntrials)
apl.rg = numeric(ntrials)
for(i in 1:ntrials){
g.rg = erdos.renyi.game(nv, ne, type=&quot;gnm&quot;, directed=TRUE)
cl.rg[i] = clust.coef.dir(g.rg)
apl.rg[i] = average.path.length(g.rg)
}</code></pre>
<pre><code>summary(cl.rg)
summary(apl.rg)
clust.coef.dir(macaque)
average.path.length(macaque)</code></pre>
<p>위 예시에서 랜덤 네트워크에서 계산된 것 대비 clustering 숫자가 엄청 크지만, 동시에 vertex 쌍 사이의 shortest path들의 평균적인 길이 또한 눈에 띄게 길다. 따라서 small-world 여부는 명확하지 않으며, 이 결과는 분석 대상 네트워크가 고전적 랜덤 그래프보다도 훨씬 lattice에 가깝다는 것을 보여준다.</p>
<!--chapter:end:212104_Math.Rmd-->
</div>
</div>
</div>
<div id="introduction-to-ergm" class="section level2" number="7.5">
<h2 number="7.5"><span class="header-section-number">7.5</span> Introduction to ERGM</h2>
<div id="exponential-random-graph-models" class="section level3" number="7.5.1">
<h3 number="7.5.1"><span class="header-section-number">7.5.1</span> Exponential Random Graph Models</h3>
<p><br>
<br>
<br></p>
<div id="what-is-a-network" class="section level4" number="7.5.1.1">
<h4 number="7.5.1.1"><span class="header-section-number">7.5.1.1</span> What Is a Network?</h4>
<p>:= “relational data” 를 수학적 그래프로 나타낸 것. node의 set과 edge set의 복합이며, edge는 일부 node를 이음.</p>
<p>Adjacencey Matrix <span class="math inline">\(X_{ij} = 1\)</span>, if node <span class="math inline">\(i,j\)</span> are connected. <span class="math inline">\(0\)</span> o.w.</p>
<p><br>
<br>
<br></p>
</div>
<div id="exponential-random-graph-model-ergms" class="section level4" number="7.5.1.2">
<h4 number="7.5.1.2"><span class="header-section-number">7.5.1.2</span> Exponential Random Graph Model (ERGMs)</h4>
<p><span class="math display">\[
P_\theta (X=x) = \frac{1}{\kappa(\theta)} \exp \Big( \theta&#39; g(x) \Big)
\]</span></p>
<ul>
<li><span class="math inline">\(X\)</span>: A random network written as an adjacency Matrix
<ul>
<li><span class="math inline">\(X_{ij}\)</span> is an indicator of an edge from node i to node j.</li>
</ul></li>
<li><span class="math inline">\(g(x)\)</span>: A vector of network statistics of interest.</li>
<li><span class="math inline">\(\theta\)</span>: The vector of parameters measuring the <strong>strengths of the effects</strong> of the corresponding entries in the vector <span class="math inline">\(g(x)\)</span>.
<ul>
<li><span class="math inline">\(\theta &gt;0\)</span>: There exists a tendency to form <span class="math inline">\(g(x)\)</span> when changing <span class="math inline">\(X_{ij}\)</span> value from 0 to 1.</li>
<li><span class="math inline">\(\theta &gt;0\)</span>: There exists a tendency <strong>not</strong> to form <span class="math inline">\(g(x)\)</span> when changing <span class="math inline">\(X_{ij}\)</span> value from 0 to 1.</li>
</ul></li>
<li><span class="math inline">\(\kappa (θ)\)</span>: A normalizing constant</li>
</ul>
<p>네트워크의 전체 구조를 형성하는 로컬적인 selection force를 간략하게 설명함. 네트워크 데이터셋은 리그레션에서의 response 같은 것으로 간주될 수 있으며, 이때 predictor들은 “파트너십에서 개인들이 삼각형을 형성하는 성향” 과 같은 것임. <strong>즉, ERGM은 local transtivity의 정도, 위력을 량화하는데 도움을 줌.</strong> EGRM을 사용해 획득하는 정보는 특정 현상을 이해하거나 특정 네트워크로부터의 랜덤한 실현값을 시뮬레이션하는데에 쓰일 수 있음. 이때 랜덤한 실현값은 당연히 원본의 성질을 유지해야 하고.</p>
<p><br>
<br>
<br></p>
</div>
<div id="network-statistics" class="section level4" number="7.5.1.3">
<h4 number="7.5.1.3"><span class="header-section-number">7.5.1.3</span> Network Statistics</h4>
<p>Basic Markov Network Statistics</p>
<p><Pics></p>
<div id="degree-and-shared-partnership-distribution" class="section level5" number="7.5.1.3.1">
<h5 number="7.5.1.3.1"><span class="header-section-number">7.5.1.3.1</span> Degree and Shared Partnership Distribution</h5>
<ul>
<li><strong>Degree</strong>: The number of edges the node has to other nodes.
<ul>
<li><span class="math inline">\(D_k (x)\)</span>: The number of nodes with degree <span class="math inline">\(k\)</span>. 이때 <span class="math inline">\(\sum D_k(x) = n\)</span>.</li>
</ul></li>
<li>Shared Partnership Distribution:
<ul>
<li>The number of unordered pairs <span class="math inline">\((i, j)\)</span> for which <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> have exactly share <span class="math inline">\(k\)</span> common neighbors and
<ul>
<li><span class="math inline">\(EP_k (x)\)</span>: <span class="math inline">\(X_{ij} = 1\)</span></li>
<li><span class="math inline">\(NP_k (x)\)</span>: <span class="math inline">\(X_{ij} = 0\)</span></li>
<li><span class="math inline">\(DP_k (x)\)</span>: regardless of value <span class="math inline">\(X_{ij}\)</span></li>
</ul></li>
<li><span class="math inline">\(\sum EP_k(x) = S_1(x)\)</span> (edge counts) and <span class="math inline">\(\sum DP_k (x) = {n \choose x}\)</span> (dyad counts).</li>
</ul></li>
</ul>
<p><strong>geometrically weighted statistics</strong> for degree and shared partnership distribution 는 이하와 같이 정의된다. 여기에 추가된 패러미터 <span class="math inline">\(\tau\)</span>는 higher order terms 때 부과되는 weight의 decreasing rate를 나타냄.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

u(x | \tau) 
&amp;= e^\tau \sum_{i=1}^{n-2} \left \{ 1- \left ( 1-\frac{1}{e^\tau} \right)^i \right \} 
&amp;&amp;\cdot D_i(x)

\\

v(x | \tau) 
&amp;= \ditto
&amp;&amp;\cdot EP_i(x)

\\

w(x | \tau) 
&amp;= \ditto
&amp;&amp;\cdot DP_i(x)

\end{alignat}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
</div>
<div id="difficulty-in-parameter-estimation" class="section level3" number="7.5.2">
<h3 number="7.5.2"><span class="header-section-number">7.5.2</span> Difficulty in Parameter Estimation</h3>
<p><br>
<br>
<br></p>
<div id="intractable-normalizing-constants" class="section level4" number="7.5.2.1">
<h4 number="7.5.2.1"><span class="header-section-number">7.5.2.1</span> Intractable Normalizing Constants</h4>
<p><span class="math inline">\(\kappa (\theta) =\sum_{\text{all possible }x} \exp \Big \{ \theta&#39; g(\mathbf x) \Big \}\)</span> 는 ERGMs의 normalizing constant.</p>
<p>undirected 인 경우에조차도 <span class="math inline">\(2^{n \choose x}\)</span> 개의 네트워크가 존재하므로, <span class="math inline">\(\kappa(\theta)\)</span> 를 직접 계산하는건 불가능함. 이렇게 직접 계산하는게 불가능하기 때문에 MCMC 가 시뮬레이션과 통계적 추론 양쪽에 있어서 핵심이 된다. 하지만 일반적은 MH 알고리즘에 있어서는 acceptance probability에 알려지지 않은 constant ratio 인 <span class="math inline">\(\frac{\kappa(\theta)}{\kappa(\theta&#39;)}\)</span> 가 끼어있으므로 이를 직접적으로 계산하는 것 또한 실패하게 됨. 이때 <span class="math inline">\(\theta &#39;\)</span> denotes the proposed value.</p>
<p><br>
<br>
<br></p>
</div>
<div id="model-degeneracy" class="section level4" number="7.5.2.2">
<h4 number="7.5.2.2"><span class="header-section-number">7.5.2.2</span> Model Degeneracy</h4>
<p><span class="math inline">\(\theta\)</span>를 어떻게 설정하느냐에 따라서 ERGM은 full (모든 연결이 존재하는, <span class="math inline">\(J\)</span>) 혹은 empty (연결이 없는, <span class="math inline">\(\mathbf 0\)</span>) 네트워크를 거의 1에 가까운 확률로 생산하기도 한다.</p>
<p>Example: <strong>Basic Markovian Statistics</strong>. 네트워크에서 하나의 edge가 추가되거나 제거될때, 다른 통계량들이 비교적 크게 변하지 않을 때 basic Markovian 통계량만 엄청나게 요동치는 상황 발생할 수 있음. 따라서 dyadic dependence effects만 빠르게 뻥튀기되어서 모델이 degenerate 될 수 있음.</p>
<p>현재 사용되는 방법인 <strong>MCMLE</strong> and <strong>stochastic approximation</strong> 는 시작값이 degeneracy 영역에 있었다면 <span class="math inline">\(\theta\)</span>의 degenerate 추정값을 생산하기도 한다. 이러한 문제점을 일컫는 용어가 <strong>Local convergence property</strong>.</p>
<!--chapter:end:212105_ERGM.Rmd-->
</div>
</div>
</div>
<div id="parameter-estimation-of-ergm" class="section level2" number="7.6">
<h2 number="7.6"><span class="header-section-number">7.6</span> Parameter Estimation of ERGM</h2>
<p>Current Methods for ERGM</p>
<ol style="list-style-type: decimal">
<li>Approximation-based Algorithm: Maximize the likelihood function with MCMC samples.
<ul>
<li>Maximum Pseudo-likelihood Estimation (MPLE).</li>
<li>Markov Chain Monte Carlo Maximum Likelihood Estimation (MCMCMLE).</li>
<li>Markov Chain Monte Carlo Stochastic Approximation (MCMCSA).</li>
<li>Varying Truncation Stochastic Approximation MCMC Method with Trajectory Averaging (VTSAMCMC).</li>
</ul></li>
<li>Auxiliary Variable Markov Chain Monte Carlo (MCMC) Algorithm: Introduce auxiliary variables to cancel the normalizing constant ratio <span class="math inline">\(\frac{\kappa(\theta)} {\kappa(\theta&#39;)}\)</span> or to approximate the normalizing constant. Used for the Bayesian Inference.
<ul>
<li>The Exchange Algorithm.</li>
<li>Auxiliary Variable Metropolis-Hasting Algorithm (AVMH).</li>
<li>Adaptive Exchange Monte Carlo Algorithm (AEXMC).</li>
</ul></li>
</ol>
<p><br>
<br>
<br></p>
<div id="approximation-based-algorithm" class="section level3" number="7.6.1">
<h3 number="7.6.1"><span class="header-section-number">7.6.1</span> Approximation-based Algorithm</h3>
<div id="maximum-pseudo-likelihood-estimation" class="section level4" number="7.6.1.1">
<h4 number="7.6.1.1"><span class="header-section-number">7.6.1.1</span> Maximum Pseudo Likelihood Estimation</h4>
<p><span class="math inline">\(A\)</span> 내부의 성분 간의 의존성을 무시한 채로 조건부 likelihood 함수들의 series를 곱하는 것으로 likelihood 함수를 근사함. ERGMS 의 조건부이며 pseudo Likelihood 는 아래와 같음. 물론 이건 어디까지나 가장 간단한 방법으로서 제시되었을 뿐이고, 이 방법론은 의존성 구조를 완전히 무시했기 때문에 퍼포먼스가 구림.</p>
<p>$$
<span class="math display">\[\begin{align}
logit \left \{ P_\theta \Big (X_{ij} = 1 \Big | X_{ij}^c = x_{ij}^c \right \} &amp;= \theta &#39; g(x_{ij}^c)

\\

\log PL(\theta, x) &amp;= \sum_{ij} \theta &#39; g(x_{ij}^c) \cdot x_{ij} - \sum_{ij}\log \left \{ 1+ \theta &#39; g(x_{ij}^c) \right \}

\end{align}\]</span>
$$</p>
<p><br>
<br>
<br></p>
</div>
<div id="mcmcmle" class="section level4" number="7.6.1.2">
<h4 number="7.6.1.2"><span class="header-section-number">7.6.1.2</span> MCMCMLE</h4>
<p>Approximate <span class="math inline">\(\kappa(θ)\)</span> using Monte Carlo samples generated from a
distribution</p>
<p>f(x|θ
(0)
), where θ
(0)
is an initial estimate of θ.
Draw x1, · · · , xm denote random samples drawn from f(xobs|θ
(0)
) via
MCMC simulations, the log-ratio of likelihood can be approximated by</p>
<p><span class="math display">\[
I(\theta) - I(\theta^{(0)}) = \left (\theta - \theta^{(0)} \right) &#39; g(x_{obs}) - \log \left [ \frac{1}{m} \sum_{i=1}^m \exp \left \{ \left (\theta - \theta^{(0)}\right )&#39; g(x_i) \right \} \right ]
\]</span></p>
<p>) via θ will approximate θˆ (MLE).
The performance of MCMLE depends on the choice of θ
(0)
. If θ
(0)
does
not lie in the attraction region of true MLE, the method may converge to
a suboptimal solution or fail to converge.</p>
<p><br>
<br>
<br></p>
</div>
<div id="mcmc-stochastic-approximation" class="section level4" number="7.6.1.3">
<h4 number="7.6.1.3"><span class="header-section-number">7.6.1.3</span> MCMC Stochastic Approximation</h4>
<p>exponential family 에 대한 이론을 통해, 우리는 ERGMs을 maximize 하는 것은 <span class="math inline">\(E_{\hat \theta} \Big \{ g(X) \Big \} = g(x_{obs})\)</span> 라는 system 을 푸는 것과 동일하다는 것을 알 수 있다. 이 system 의 성립 여부는 이하와 iff (<span class="math inline">\(\iff\)</span>).</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\hat \theta = \hat \theta_{MLE}\)</span></li>
<li>Independent network generation</li>
<li>Parameter estimation update with stochastic approximation</li>
</ol>
<p>이 방법론은 independent 네트워크 샘플을 생산하는데에는 비효율적이다. 각 샘플 <span class="math inline">\(x_{k+1}\)</span>을 생산하기 위해 요구되는 이터레이션 스텝의 갯수는 order of <span class="math inline">\(100 n^2\)</span>. 이때 <span class="math inline">\(n\)</span>은 node 의 갯수.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="auxiliary-variable-mcmc-based-approaches" class="section level3" number="7.6.2">
<h3 number="7.6.2"><span class="header-section-number">7.6.2</span> Auxiliary Variable MCMC-based Approaches</h3>
<div id="exchange-algorithm-2" class="section level4" number="7.6.2.1">
<h4 number="7.6.2.1"><span class="header-section-number">7.6.2.1</span> Exchange Algorithm</h4>
<p>normalizing constant ratio <span class="math inline">\(\frac{\kappa(\theta)}{\kappa(\theta&#39;)}\)</span> 따위의 auxiliary 변수로 분포 <span class="math inline">\(f(x | \theta)\)</span> 를 augment. 이는 시뮬레이션 중에 canceled.</p>
<ol style="list-style-type: decimal">
<li>후보 point <span class="math inline">\(\theta &#39; \sim q(\theta &#39; | \theta, x)\)</span> 를 생산</li>
<li>perfect sampler 사용해서 auxiliary 변수 <span class="math inline">\(y \sim f(y | \theta &#39;)\)</span> 를 생산</li>
<li><span class="math inline">\(\theta&#39;\)</span>를 with probability <span class="math inline">\(1 \wedge r(\theta, \theta &#39; \Big | x)\)</span>로 채택. 이때</li>
</ol>
<p>$$
r(, ’ | x) =</p>
<p>$$</p>
<p>exchange 알고리즘은 <strong>Ising</strong> 이나 <strong>autologistic</strong> 과 같은 일부 discrete 모델에는 잘 작동. 하지만 <strong>perfect sampling</strong> 이 적용되지 않는 많은 다른 모델에는 적용할 수 없다. 우리는 MCMC 샘플을 통해 auxiliary 변수 <span class="math inline">\(y\)</span>를 생산할 수 있지만, 수렴 문제 부분에서 이론적인 흠결이 있음. 만약 MCMC 샘플의 mixing이 매우 느리다면 딴놈이 아니라 <span class="math inline">\(\theta_0\)</span> 가 매우 높은 확률로 채택되어버림. 그리고 이 MCMC 샘플의 mixing 이 느린 것 자체가 ERGMs 의 일반적인 특징임. 이래서 문제.</p>
<p><br>
<br>
<br></p>
</div>
<div id="monte-carlo-mh-algorithm" class="section level4" number="7.6.2.2">
<h4 number="7.6.2.2"><span class="header-section-number">7.6.2.2</span> Monte Carlo MH Algorithm</h4>
<p>MH 알고리즘의 MC 버전. 각 이터레이션에서 <strong>MCMH 알고리즘</strong>은 unknown normalizing constant ratio <span class="math inline">\(\frac{\kappa(\theta)}{\kappa(\theta&#39;)}\)</span> 를 MC estimate와 importance 샘플링 접근법으로 대체한다.</p>
<p>exchange 알고리즘과 다르게, MCMH 알고리즘은 perfect sampler 요구조건을 빗겨간다. 따라서 perfect sampler 를 못 쓰는 다수의 통계문제에 대해서도 얘를 쓸 수 있음. 하지만 얘도 여전히 수렴 문제가 존재함. 얘의 경우에는 importance sampling estimator 가 유한한 숫자의 샘플로는 ratio의 참값 <span class="math inline">\(\frac{\kappa(\theta)}{\kappa(\theta&#39;)}\)</span> 에 수렴하지 못할 수도 있음.</p>
<div class="figure" style="text-align: center">
<img src="pics/network/06/01.png" alt="Goodness-of-fit Plots, for ERGMs - for the high school student friendship network" width="939" />
<p class="caption">
(#fig:ERGMs)Goodness-of-fit Plots, for ERGMs - for the high school student friendship network
</p>
</div>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="varying-trunction-stochastic-approximation-mcmc" class="section level3" number="7.6.3">
<h3 number="7.6.3"><span class="header-section-number">7.6.3</span> Varying Trunction Stochastic Approximation MCMC</h3>
<p>ERGM 의 likelihood 함수는</p>
<p><span class="math display">\[
\begin{align}
&amp;f(y | \theta ) = \frac{1}{\kappa(\theta )} \exp \Big \{ \theta&#39; S(y)\Big \},
&amp;&amp;\theta = (\theta_1 , \cdots, \theta_d)&#39;$, 
&amp;&amp;$S(y) = \Big( S_1 (y), \cdots, S_d(y) \Big)&#39;
\end{align}
\]</span></p>
<p>이때 <strong><span class="math inline">\(\kappa(θ)\)</span>를 특정할 수 없다</strong> (intractability)는 점과 <strong>모델 degeneracy</strong> 때문에, <span class="math inline">\(\theta\)</span>를 정확하게 추정하는 것은 어렵다. 이 문제는 <strong>varying truncation stochastic approximation MCMC</strong> 를 사용하는 것으로 해결 가능.</p>
<p>Normalizing constant <span class="math inline">\(\kappa(\theta) = \sum_{\text{all possible }y} \exp \Big \{ \theta &#39; S(y)\Big\}\)</span>.</p>
<p>이로 인해 촉발되는 문제는?</p>
<ol style="list-style-type: decimal">
<li>MPLE: dyadic 독립을 가정하는 것으로 해결해보고자 함. 이건 observed 네트워크가 무엇이냐에 대해 과하게 의존.</li>
<li>MCMLE: <span class="math inline">\(\theta^{(0)}\)</span> 을 어떻게 고르느냐에 대해 과하게 의존. local 최적해로 수렴해버리거나 모델 degeneracy 로 수렴 자체가 실패하기도.</li>
</ol>
<p><br>
<br>
<br></p>
<div id="mcmc-stochastic-approximation-1" class="section level4" number="7.6.3.1">
<h4 number="7.6.3.1"><span class="header-section-number">7.6.3.1</span> MCMC Stochastic Approximation</h4>
<p><span class="math inline">\(h(\theta) = 0\)</span> 형의 system 을 풀자. 고전적인 <strong>SA 알고리즘</strong>은 이하와 같은 형태를 띈다. (<span class="math inline">\(a_k\)</span> , <span class="math inline">\(h\)</span>, <span class="math inline">\(\omgea_k\)</span> 에 대한) 적절한 조건 하에서, 이 알고리즘은 해로 수렴한다는 것을 실제로 보이는 것이 가능하다.</p>
<p>$$
<span class="math display">\[\begin{align}
\theta_{k+1} 
&amp;= \theta_k + a_k Y_k 

\\

&amp;=\theta_k + a_k \Big \{ h(\theta_k) + \omega_k \Big \}, &amp;&amp; k \ge 0 
\end{align}\]</span>
$$</p>
<ul>
<li><span class="math inline">\(Y = h(\theta) + \omega\)</span> 는 noisy estimate</li>
<li><span class="math inline">\(\omega\)</span> 는 mean-zero noise.</li>
</ul>
<p><span class="math inline">\(\theta_{MLE}\)</span> 를 찾는 것은 exponential family 안에서 <span class="math inline">\(E_\theta \{ S(Y) \} = S(\mathbf y_{obs})\)</span> 의 해를 찾는 것과 equivalent. 이는 이하의 단계를 거친다. 다만 이는 independent 네트워크 샘플을 생산하는데 있어 비효율적일 수밖에 없음. order of <span class="math inline">\(100n^2\)</span> 이라 연산을 엄청 먹으니까.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathbf y^{k+1} \sim f(\mathbf y | \theta^{(k)}\)</span>를 샘플링 (independence 네트워크 생산)</li>
</ol>
<p>각 arc 변수 <span class="math inline">\(Y_{ij}\)</span>가 독립적으로 정해지는 랜덤 그래프에서 시작. 이 변수에는 0 혹은 1이 0.5 확률로 할당. 이 랜덤 그래프를 Gibbs 샘플러든 MH 알고리즘이든 써서 업데이트.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>SA</strong> 를 통해 패러미터 estimate 업데이트.</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}
\theta^{(k+1)} &amp;= \theta^{(k)} - a_k D^{-1} \Big \{ U( \mathbf y_{k+1}, \bar {\mathbf y}_{k+1} ) - \mathbf S (\mathbf y_{obs} ) \Big \},
\\
\\
\\
U( \mathbf y_{k+1}, \bar {\mathbf y}_{k+1} ) - \mathbf S (\mathbf y_{obs} ) \Big 
\} &amp;= P(\bar {\mathbf y}_{k+1} \Big | \mathbf y_{k+1} ) \cdot \mathbf S (\mathbf {\bar y}_{k+1} ) 

\Big \{ 1-P(\mathbf {\bar y}_{k+1} \Big | \mathbf y_{k+1} ) \Big \} \cdot \mathbf S (\mathbf {\bar y}_{k+1} ) 

\\

\mathbf {\bar y}_{k+1} &amp;= 1- \mathbf y_{k+1} 

\end{align}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<div id="model-degeneracy-1" class="section level5" number="7.6.3.1.1">
<h5 number="7.6.3.1.1"><span class="header-section-number">7.6.3.1.1</span> Model Degeneracy</h5>
<p><span class="math inline">\(\theta\)</span>을 어떻게 정하느냐에 따라 모델은 그것의 확률을 (Complete (fully connected) 거나 empty (entirely unconnected) 네트워크와 같은) 1개 혹은 소수의 그래프에만 한정시켜서 부어버릴 수도 있다. (탐색 효율 쓰레기됨) 이 문제를 해결하기 위해선 탐색 전에 degeneracy 리전을 거의 포함하지 않는 패러미터 스페이스를 가지는 모델로 특정할 필요가 있다. 근데 이게 진짜 드럽게 어려움.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="varying-truncation-samcmc-for-ergms" class="section level4" number="7.6.3.2">
<h4 number="7.6.3.2"><span class="header-section-number">7.6.3.2</span> Varying Truncation SAMCMC for ERGMs</h4>
<div id="setup" class="section level5" number="7.6.3.2.1">
<h5 number="7.6.3.2.1"><span class="header-section-number">7.6.3.2.1</span> Setup</h5>
<p>$$
<span class="math display">\[\begin{align}

&amp;a_k = C_a \left( \frac{k_0}{(k_0 \vee k)}\right)^\eta, &amp;&amp;b_k = C_b \left( \frac{k_0}{(k_0 \vee k)}\right)^\xi \tag{C_1, set}

\end{align}\]</span>
$$</p>
<p><span class="math display">\[
\bigcup_{s \ge 0} \mathcal K_s = \Theta, \; \; \; \text{where } \mathcal K_s \subset \text{int}(\mathcal K_{s+1}) \tag{C_2}
\]</span></p>
<ul>
<li>for some constants <span class="math inline">\(k_0&gt;1\)</span>, <span class="math inline">\(\eta \in (\frac{1}{2},1)\)</span>, <span class="math inline">\(\xi \in (\frac{1}{2},\eta)\)</span>, <span class="math inline">\(C_a &gt; 0\)</span>, <span class="math inline">\(C_b &gt;0\)</span>.</li>
</ul>
<p>And also,</p>
<ul>
<li><p><span class="math inline">\(\mathcal X\)</span>: a space of social network</p></li>
<li><p><span class="math inline">\(\mathcal T\)</span>: <span class="math inline">\(\mathcal X \times \Theta \rightarrow \mathcal X_0 \times \mathcal K_0\)</span> (reinitialization mechanism)</p></li>
<li><p><span class="math inline">\(\sigma_k\)</span>: the number of reinitialization performed until iteration <span class="math inline">\(k\)</span>. (<span class="math inline">\(\sigma_0 = 0\)</span>)</p></li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="varying-truncation-samcmc-algorithm-for-ergms" class="section level5" number="7.6.3.2.2">
<h5 number="7.6.3.2.2"><span class="header-section-number">7.6.3.2.2</span> Varying truncation SAMCMC algorithm for ERGMs</h5>
<ol style="list-style-type: decimal">
<li><p>Gibbs 샘플러 사용해 <span class="math inline">\(m\)</span> sweeps 번 interate 해서 auxiliary network <span class="math inline">\(y_{k+1} \sim f(y | \theta^{(k)}\)</span> 생산</p></li>
<li><p>Set <span class="math inline">\(\theta^{(k + \frac{1}{2})} = \theta^{(k)} + a_k \Big \{ S(y_{k+1}) - S(y_{obs}) \Big \}\)</span></p></li>
<li><p>Set</p></li>
</ol>
$$
<span class="math display">\[\begin{cases}

\sigma_{k+1} = \sigma_k \; \text{ and } \left( y_{k+1}, \theta^{(k + {1})} \right) =  \left( y_{k+1}, \theta^{(k + \frac{1}{2})} \right)
\; \; \; \; \; \; \; \; \; \; 

&amp; 
\| \theta^{(k + \frac{1}{2})} - \theta^{(k)} \| \le b_k, \; \; \theta^{(k + \frac{1}{2})} \in \mathcal K_{\sigma_k}
\\
\sigma_{k+1} = \sigma_k+1 \; \text{ and } \left( y_{k+1}, \theta^{(k + {1})} \right) =  \mathcal T \left( y_{k}, \theta^{(k)} \right)
&amp;
o.w.
\end{cases}\]</span>
<p>$$</p>
<p><br>
<br>
<br></p>
</div>
<div id="trajectory-averaging-estimator" class="section level5" number="7.6.3.2.3">
<h5 number="7.6.3.2.3"><span class="header-section-number">7.6.3.2.3</span> Trajectory averaging estimator</h5>
<p>trajectory averaging estimator <span class="math inline">\(\bar \theta_n = \frac{1}{n}\sum_{k=1}^n \theta^{(k)}\)</span> 에 의해 <span class="math inline">\(\theta\)</span> 를 estimate 가능.</p>
<p>실전에서는 estimate 의 variation 을 줄이기 위해 대신 <span class="math inline">\(\theta\)</span> estimate 에 <span class="math inline">\(\bar \theta (n_0 , n) = \frac{1}{n-n_0}\sum_{k=n_0+1}^n \theta^{(k)}\)</span> 을 자주 사용함. 이 때 <span class="math inline">\(n_0\)</span> 는 burn-in 이터레이션의 숫자.</p>
<ul>
<li>Free parameters: <span class="math inline">\(\{a_k\}\)</span>, <span class="math inline">\(\{b_k\}\)</span>, <span class="math inline">\(\{\mathcal K_s, \; s \le 0\}\)</span>, <span class="math inline">\(m\)</span></li>
<li><span class="math inline">\(k_0 = 100\)</span>, <span class="math inline">\(\eta = 0.65\)</span>, <span class="math inline">\(\xi = \frac{0.5 + \eta}{2}\)</span>.</li>
<li><span class="math inline">\(C_a\)</span>, <span class="math inline">\(C_b\)</span>: adjusted for different examples</li>
<li>choose <span class="math inline">\(\mathcal K_0\)</span> to be around MPLE.</li>
<li>In this artical, we set <span class="math inline">\(\mathcal K_{s, 1} = \Big [ -4(s+1), 4(s+1) \Big]\)</span>, <span class="math inline">\(\mathcal K_{s, 2} = \cdots = \mathcal K_{s, d} = \Big [ -2(s+1), 2(s+1) \Big]\)</span>.</li>
<li><span class="math inline">\(m=1\)</span>.</li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="numerical-examples" class="section level5" number="7.6.3.2.4">
<h5 number="7.6.3.2.4"><span class="header-section-number">7.6.3.2.4</span> Numerical Examples</h5>
<p>Methods: MCMLE, SAA (Stochastic Approximation Algorithm), Varying truncation SAMCMC
SAMCMC: independent 5 runs(each of 200,000 iterations) (m=1, Ca = 0.01, Cb = 1000, η, ξ, κs are defalut)</p>
<!--chapter:end:212106_ParameterEstimationofERGM.Rmd-->
</div>
</div>
</div>
</div>
<div id="ergm-for-dynamic-networks" class="section level2" number="7.7">
<h2 number="7.7"><span class="header-section-number">7.7</span> ERGM for Dynamic Networks</h2>
<p><pic></p>
<p>However, a need for statistical models representing the evolving phenomena ⇒ ”Dynamic Models” with a temporal structure</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="temporal-ergm" class="section level3" number="7.7.1">
<h3 number="7.7.1"><span class="header-section-number">7.7.1</span> Temporal ERGM</h3>
<ul>
<li><strong>ERGM → TERGM → STERGM</strong></li>
</ul>
<p>One-step transition probability <span class="math inline">\((t-1) → (t)\)</span> (Markov Assumption)</p>
<p><span class="math display">\[
P_{\eta, g} \Big ( Y^t = y^t \Big | Y^{t-1} \; \; ; \; \; \theta \Big ) = \frac{\exp \Big \{ \eta(\theta) \cdot g(y^t, y^{t-1})\Big  \}}{c_{\eta, h}(\theta, y^{t-1})}
\]</span></p>
<ul>
<li><strong>TERGM: Temporal ERGM</strong></li>
</ul>
<p>시간 t에서의 네트워크는, t-1 시점의 (어쩌면 t-2도 가능하고) 네트워크로 조건을 건 ERGM 으로부터의 단일 생산으로 생각될 수 있음. 소셜 네트워크의 변화를 간단히 하기 위해 <strong>Markov assumption</strong> 적용. 이는 곧, <span class="math inline">\(A^t\)</span>가 t 시점에서의 단일-관계 소셜 네트워크의 weight 매트릭스를 표현하고, 우리에게 <span class="math inline">\(A^{t-1}\)</span> 의 값이 주어져 있다면, <span class="math inline">\(A^t\)</span> 는 <span class="math inline">\(A^1, \cdots, A^{t-2}\)</span> 으로부터는 독립임을 의미한다는 뜻. 수식으로 표현하면 아래와 같다.</p>
<p><span class="math display">\[
P\Big(A^2, A^3, \cdots, A^t \Big | A^1 \Big ) = P\Big(A^t \Big | A^{t-1} \Big ) P\Big(A^{t-1} \Big | A^{t-2} \Big ) \cdots P\Big(A^2 \Big | A^1 \Big ) \tag{Temporal ERGM}
\]</span></p>
<p>마르코프 가정이 주어져 있음을 고려하면, evolving 네트워크 전반에 대해 ERGM 을 일반화하는 방법이란 <span class="math inline">\(A^t \vert A^{t-1}\)</span> 가 ERGM 표현법을 채택했음을 가정하는 것. <mark>to assume <span class="math inline">\(A^t \vert A^{t-1}\)</span> admits an ERGM representation.</mark></p>
<p>함수 <span class="math inline">\(\Psi : \mathbb R_{n \times n} \times \mathbb R_{n \times n} \rightarrow \mathbb R^k\)</span> 를 생각해보자. 이는 시간적으로 인접한 2개의 네트워크 (<span class="math inline">\(t\)</span>, <span class="math inline">\(t-1\)</span> 등) 에 걸친 cliques 들의 잠재적은 potential로 인지될 수 있다. 이때 패러미터 벡터 <span class="math inline">\(\theta \in \mathbb R^k\)</span> 는 이하와 같은 conditional pdf를 갖는다.</p>
<p><span class="math display">\[
P \bigg( A^t \Big | A^{t-1}, \theta \bigg) = \frac{1}{\kappa(\theta, A^{t-1})} \exp \left\{ \theta&#39; \Psi \left ( A^t, A^{t-1} \right ) \right\}
\]</span></p>
<p>특히 우리는 해당 모델에서 이하와 같은 특수한 경우에 관심이 있다.</p>
<p><span class="math display">\[
\Psi \left ( A^t, A^{t-1} \right ) = \sum_{ij}\Psi_{ij} \left ( A^t_{ij}, A^{t-1} \right )
\]</span></p>
<p>이 형의 temporal potential 함수는 <span class="math inline">\(A^t | A^{t-1}\)</span>의 조건부 분포의 <mark>This form of the temporal potential function represents situations where the conditional distribution of <span class="math inline">\(A^t | A^{t-1}\)</span> factors over the entries <span class="math inline">\(A^t_{ij}\)</span> of <span class="math inline">\(A^t\)</span>.</mark></p>
<p><br>
<br>
<br></p>
<div id="network-statistics-for-temporal-ergm" class="section level4" number="7.7.1.1">
<h4 number="7.7.1.1"><span class="header-section-number">7.7.1.1</span> Network Statistics for Temporal ERGM</h4>
<p>$$
<span class="math display">\[\begin{align}
\Psi_D \left ( A^t , A^{t-1}\right)

&amp;=

\frac{1}{n-1} \sum_{ij} A^t_{ij}

\tag{Density}

\\

\Psi_S \left ( A^t , A^{t-1}\right)

&amp;=

\frac{1}{n-1} \sum_{ij}

\left \{ A^t_{ij} A^{t-1}_{ij} + \left (1-A^t_{ij} \right) \left (1-A^{t-1}_{ij} \right)
\right \}


\tag{Stability}

\\

\Psi_R \left ( A^t , A^{t-1}\right)


&amp;=

n \left ( \frac{\sum_\limits{ij} A_{ij}^t A_{ij}^{t-1}}{\sum_\limits{ij}A_{ij}^{t-1}}\right )

\tag{Reciprocity}

\\

\Psi_T \left ( A^t , A^{t-1}\right)

&amp;=

n \left ( \frac{\sum_\limits{ijk} A_{ik}^t A_{ij}^{t-1}A_{jk}^{t-1}}
{\sum_\limits{ijk}A_{ij}^{t-1}A_{jk}^{t-1}}\right )



\tag{Transitivity}

\end{align}\]</span></p>
<p>$$</p>
<ol style="list-style-type: decimal">
<li><strong>Density</strong> : 전체 네트워크에 들어있는 총 tie의 숫자.</li>
<li><strong>Stability</strong> : t-1 시점에 존재했던 link가 t 시점에도 여전히 존재하는 경향성</li>
<li><strong>Reciprocity</strong> : t-1 시점에 i에서 j로 향하는 link가 있었다면 t 시점에 j→i 링크가 생겨날 경향</li>
<li><strong>Transitivity</strong> : t-1 시점에 i→j와 j→k인 tie가 존재한다면, t에 i→k tie의 발생으로 이어지는 경향</li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="estimation-1" class="section level4" number="7.7.1.2">
<h4 number="7.7.1.2"><span class="header-section-number">7.7.1.2</span> Estimation</h4>
<ul>
<li>Notation <mark>&amp; Algorithm &amp; Convergence</mark></li>
</ul>
<p>observed 네트워크의 sequence <span class="math inline">\(N^1 , N^2 , \cdots, N^T\)</span> 를 사용하자. 무엇을 위해? 실제 패러미터값 <span class="math inline">\(\theta\)</span> 에 가까운 estimator <span class="math inline">\(\hat \theta\)</span> 을 찾기 위해. normalizing constant 는 보통 계산해내는 것이 불가능하여 MLE 방법론의 도입은 불가. 따라서 MCMC stochastic approximation 를 사용해 패러미터 estimate. 이하와 같이 notation 한다. 이때 t 시점의 네트워크인 랜덤변수 <span class="math inline">\(\underline N^t\)</span> 에 대해 기댓값들이 계산되었음을 notice.</p>
<p>$$</p>
<p>L(:N^{1},{ N}^{2}, ,{ N}^{T})=P({ N}^{2},{ N}^{3},,{ N}^{t},,{ N}^{1},),</p>
<p>\</p>
<p>M(t,)= E_{}(<sup>{t},v</sup>{t-1})^{t-1}),</p>
<p>\</p>
<p>G(t,) = E_{}((<sup>{t},</sup>{t-1})(<sup>{t},</sup>{t-1})^{T}=</p>
<p>$$</p>
<p>이때 이하의 기댓값들은 조건부 분포로부터 Gibbs 샘플링을 돌리는 것으로 근사 가능. Newton 방법론과 유사한 과정을 통해 unconstrained optimization 을 하자. 기댓값을 근사하고, Likelihood를 증가시키는 방향으로 패러미터값을 업데이트. 이 과정을 수렴하기까지 반복.</p>
<p>$$</p>
<p>(:N^1 , N^2 , , N^T ) =</p>
<p>_{t=2}^{T}(( N^t, N^{t-1} )-M(t,))</p>
<p>\</p>
<p>^{2} L(:N^1 , N^2 , , N^T)= _{t=2}<sup>{T}((t,)(t,)</sup>{}-{{C}}(t,))
$$</p>
<p><br>
<br>
<br></p>
<ul>
<li>algorithm</li>
</ul>
<p><span class="math inline">\(\hat{N}_{(i)}^{t,1}\,,\,\cdot\,\cdot\,\cdot\,,\,\hat{N}_{(i)}^{t,B}\,\sim\,\mathcal{D}\left(\frac{\Lambda^{t}}{\Omega}\,\mid\,{\Lambda^{l-1}}_{\cdot}\,\mathcal{O}^{(i)}\right)\)</span></p>
<p><span class="math inline">\(\hat{\cal M}_{(i)}^{t}\longrightarrow\ {\textstyle\frac{1}{B}}\sum_{\textstyle{\cal B}=1}^{B}\Psi\Big(\hat{\cal N}_{(i)}^{t,b},\Lambda^{t-1}\Big)\)</span></p>
<p><span class="math inline">\(\~\hat{G}_{(i)}^{t}\equiv\left.\frac{1}{B}\sum_{-b=1}^{B}\Psi\left(\hat{N}_{(i)}^{t,b},\Lambda^{t-1}\right)\Psi\left(\hat{N}_{(i)}^{t,b},\Lambda^{l-1}\right)^{\prime}\)</span></p>
<p><span class="math inline">\(\hat{H}_{(i)}\stackrel{\wedge}{=}\sum_{i=2}^{T}\left(\hat{\cal H}_{(i)}^{t}\hat{\mu}_{(i)}^{t}-\hat{G}_{(i)}^{t}\right)\)</span></p>
<p><span class="math inline">\(\theta^{(i+1)}\underline{{{\ge}}}\rightarrow\theta^{(i)}-\hat{\cal{H}}_{(i)}^{-1}\sum_{l=2}\left(\Psi\Big(\hat{N}_{(i)}^{t,b},\Lambda^{l-1}\Big)-\hat{\cal{H}}_{(i)}^{t}\Big)\right.\)</span></p>
</div>
<div id="degeneracy-of-temporal-ergms" class="section level4" number="7.7.1.3">
<h4 number="7.7.1.3"><span class="header-section-number">7.7.1.3</span> Degeneracy of Temporal ERGMs</h4>
<p>간단한 케이스에는, <mark>where the transition distribution factors over the edges</mark>, 이 모델들은 그러한 문제들에서 완전히 자유롭다는 것이 알려져 있음.</p>
<p>이는 직관적으로도 와닿음. <span class="math inline">\(A^t_{ij} | A^{t−1}\)</span> 의 개개의 조건부 분포가 과하게 극단적이지 않은 한, <span class="math inline">\(A^{t-1}\)</span>이 주어졌을 때 <span class="math inline">\(A^t\)</span>의 edge는 조건부 독립이기 때문이지. 따라서 <span class="math inline">\(A^t | A^{t−1}\)</span> 의 조건부 엔트로피는 커야 하며, 이에 의해 <span class="math inline">\(A^t\)</span>의 조건부 엔트로피도 커야 할테니까.</p>
<p>물론 이 명제는 <span class="math inline">\(A^{t−1}\)</span> 에 대한 <span class="math inline">\(A^t\)</span> 의 의존이 그렇게 강하지 않을 때만 성립하는 것임. 이때 이 의존의 위력은 패러미터들의 위력에 의해 결정되지. 그러니까 패러미터가 이상하게 잡히면 해당 명제의 전제가 깨진다는 거.</p>
<p>동일한 확률값을 가진다는 것을 analytic 하게 보일 수 있는 그래프들의 class들, 즉 equivalence 클래스들에 대해서 이를 계산해보고, 엔트로피 계산에서 각각의 클래스의 크기에 따라서 weight를 부여하자.</p>
<p>첫 플랏의 경우를 생각해보자. <span class="math inline">\(A^2 | A^1\)</span> 의 조건부 분포는 결국 <span class="math inline">\(A^2\)</span> 에 존재하는 edge의 갯수와, 얼마나 많은 <span class="math inline">\(ij\)</span> 값들에게서 <span class="math inline">\(A^2_{ij} = A^1_{ij}\)</span>가 성립하고 있느냐, 의 2개의 값에 대한 함수일 뿐이다. 이에 더해 <span class="math inline">\(A^1\)</span>의 edge들은 exchangeable 하다는 점도 있다. 이들을 모두 생각해보면 결국 우리는 <span class="math inline">\(A^2\)</span>의 marginal 분포를 순수하게 edge의 숫자를 통해서만 서술하는 것이 가능하다.</p>
<p>따라서 우리는 <span class="math inline">\(n(n − 1)\)</span>의 확률값만 계산해내면 되며, 따라서 엔트로피는 weighted sum이다. 이때 weight는 각각의 edge 숫자에 대해, that many edges 를 가지고 있는 그래프의 숫자가 반영된 combinatorial quantities 가 된다.</p>
<p><pics></p>
<p><br>
<br>
<br></p>
</div>
<div id="assessing-statistic-importance-and-quality-of-fit" class="section level4" number="7.7.1.4">
<h4 number="7.7.1.4"><span class="header-section-number">7.7.1.4</span> Assessing Statistic Importance and Quality of Fit</h4>
<p>Description of Network Statistics - 108th U.S. Senate Network Example</p>
<p>Three Parameter Model, Seven, Nine</p>
<p><span class="math inline">\(\Psi_{R T}\left(\mathcal{A}_{\ \cdot}\mathcal{A}_{\ \ \ \ \ \ \ \ \ \mu}^{t-1}\right)\equiv\mathcal{H}\!\left(\sum_{i j k}\mathcal{A}_{i j}^{t}\mathcal{A}_{j k}^{t-1}\mathcal{A}_{k i}^{t-1}\right)\big/\left(\sum_{i j k}\mathcal{A}_{j k}^{t-1}\mathcal{A}_{k i}^{t-1}\right).\)</span></p>
<p><span class="math inline">\(\Psi_{C S o}\Bigl(\lambda_{~,}^{t},\lambda_{~}^{t-1}\Bigr)\mathop{\displaystyle=\,1\atop i j k}\mathcal{A}_{i j}^{t}\bar{A}_{k j}^{t-1}\mathcal{A}_{k j}^{t-1}\Bigr)\Bigl(\sum_{i j k}\mathcal{A}_{k i}^{t-1}\mathcal{A}_{k j}^{t-1}\Bigr)\dots\)</span></p>
<p><span class="math inline">\(\Psi_{C S d}\Bigl(\lambda_{\phantom{0},K}^{t},\lambda_{\phantom{-1}}^{t-1}\Bigr)\not=\imath\Bigl(\sum_{i j k}\lambda_{i j}^{t}\lambda_{i k}^{t-1}\lambda_{j k}^{t-1}\Bigr)\Bigl/\Bigl(\sum_{\textstyle{\frac{i j k}{j k}}}\lambda_{i k}^{t-1}\lambda_{j k}^{t-1}\Bigr).\)</span></p>
<p><span class="math inline">\(\Psi_{P}\Bigl(\mathcal{A}_{\phantom{0},}^{t},\mathcal{A}^{t-1}\Bigr)\equiv\mathcal{H}\Bigl(\sum_{j k}\mathcal{A}_{k j}^{t}\mathcal{A}_{j j}^{t-1}\Bigr)\big/\left(\bigotimes_{i j}\mathcal{A}_{k j}^{t-1}\right).\)</span></p>
<p><span class="math inline">\(\Psi_{G}\Bigl(\partial_{~,}^{t},\partial_{}^{t-1}\Bigr)\Longrightarrow\left(\sum_{i j k}\mathcal{A}_{i k}^{t}\mathcal{A}_{i j}^{t-1}\right)\Bigl/\left(\sum_{i j}\mathcal{A}_{i k}^{t-1}\right).\)</span></p>
<p>Reverse-Transitivity:
Co-Supported:
Co-Supporting:
Popularity
Generosity</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="separable-temporal-ergm" class="section level3" number="7.7.2">
<h3 number="7.7.2"><span class="header-section-number">7.7.2</span> Separable Temporal ERGM</h3>
<p>STERGM = A Separable Model for Dynamic Network</p>
<p>Dynamic: social networks that evolve over time
Time(discrete): <span class="math inline">\(\cdots (t-2) → (t-1) → (t) → \cdots\)</span>
Shows longitudinal properties based on the ERGM</p>
<p>Separable
formation : new ties
duration : lasting ties</p>
<div id="temporal-ergm-interpretation" class="section level4" number="7.7.2.1">
<h4 number="7.7.2.1"><span class="header-section-number">7.7.2.1</span> Temporal ERGM Interpretation</h4>
<p>하지만 이때 패러미터 해석할 때 주의해야할 부분이 있음.</p>
<p>Property1: incidence of ties (the rate at which new ties are formed)
Property2: duration of ties (how long they tend to last once they do)</p>
<ul>
<li>Network statstic</li>
</ul>
<p>(ex) edge count <span class="math inline">\(g(y^t , y^{t-1}) = | y^t |\)</span></p>
<p>coefficient on <span class="math inline">\(g\)</span> <span class="math inline">\(\propto\)</span> possibility of a network with many ties. 따라서 <span class="math inline">\(g\)</span>의 계수가 올라가면 tie가 많은 네트워크의 발생 확률 올라감.</p>
<p>But, this term simultaneously increases the weight of preservation of extant ties (fewer dissolved) ⇒ Both incidence and duration ↑</p>
<p>The two-sided nature of these effects tends to muddle parameter interpretation. ⇒ STERGM which separates the incidence and duration of ties and allows for the separate interpretation.</p>
<ul>
<li>: incidence/tie formation <span class="math inline">\(y^+ = y^{t-1} \cup y^t\)</span>
– : duration/tie dissolution <span class="math inline">\(y^- = y^{t-1} \cap y^t \Rightarrow y^t = y^- \cup (y^+ \setminus y^{t-1})\)</span></li>
</ul>
<p><span class="math inline">\(P r(y^{+}=y^{+}\vert Y^{t-1}=y^{\iota-1};\theta^{+})=\frac{\theta x p(\eta^{+}(\theta^{+})*\mathcal{O}^{+}(y^{+},y^{I-1}))}{G_{\eta^{+},g^{+}}(\theta^{+},y^{\iota-1})}\)</span></p>
<p><span class="math inline">\(P r(Y^{-}=y^{-}|Y^{t-1}=y^{t-1};\theta^{-})=\frac{\theta x p(\eta^{-}(\theta^{-})*g^{-}(y^{-},y^{t-1}))}{c_{\eta^{-},g^{-}}(\theta^{-},y^{t-1})}\)</span></p>
<p><span class="math inline">\({\cal P}_{I}(\mathcal{V}^{t}\underline{{{-}}}\mathcal{V}^{t-1}\underline{{{-}}}\mathcal{D}^{t-1}\underline{{{-}}}\mathcal{J}) \times \text{incidence} \times \text{duration}\)</span></p>
<p><span class="math inline">\(P r(y^{+}=y^{+}\vert Y^{t-1}=y^{\iota-1};\theta^{+})\)</span></p>
<p><span class="math inline">\(P r(y^{-}=y^{-}\vert Y^{t-1}=y^{\iota-1};\theta^{-})\)</span></p>
<p><br>
<br>
<br></p>
<p>:::{.definition name = “1”}
Definition 1 We say that a dynamic model is separable if Y+ is conditionally independent of Y− given Y
t−1 and the parameter space of θ is the product of the individual parameter spaces of θ+ and θ−.</p>
<p>:::</p>
<ul>
<li>Assumption: During a given discrete time step, the process by which the ties form does not interact with the process by which they dissolve.</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Lost: In the parameterization in terms of formation and dissolution, some flexibility(formation and dissolution processes interact within a given time step) is lost</p></li>
<li><p>Gain: Ease of specification, tractability of the model and substantial improvement in interpretability of TERGM</p></li>
</ol>
<p>Now the parameter and its interpretation have an implicit direction.
(formation or duration)
- Formation network
(+) is related to formation network only</p>
<p><span class="math inline">\(\Pr(\mathbf{V}^{-}={\boldsymbol{y}}^{-}|\mathbf{V}^{t-1}={\boldsymbol{y}}^{t-1};{\boldsymbol{\theta}}^{-})={\frac{\exp\{(\theta^{+})^{\cdot7}g^{+}(y^{+},y^{\dot{t}-1})}{c_{g^{+}}(\theta^{+},y^{t-1})}}\)</span></p>
<ul>
<li>Duration network (or Dissolution network)</li>
</ul>
<p><span class="math inline">\(\Pr(\mathbf{V}^{-}={\boldsymbol{y}}^{-}|\mathbf{V}^{t-1}={\boldsymbol{y}}^{t-1};{\boldsymbol{\theta}}^{-})={\frac{\exp\{({\boldsymbol{\theta}}^{-}),{\boldsymbol{\gamma}}^{t-1}\}}{c_{o}({\boldsymbol{\theta}}^{-},{\boldsymbol{\gamma}}^{t-1})}}\)</span></p>
<p>(-) is related to duration network only</p>
<ul>
<li>Example of Parameter Interpretation (Edge Count)</li>
</ul>
<p>Now the parameter and its interpretation have an implicit direction.
(formation or duration)
Formation network
Edge count g
+
(y
+
, y
t−1
) = |y
+
|, y
+ = y
t−1 ∪ y
t
Recall, y
+
is network about formation
θ
+ means log-odds of gaining new tie from y
t−1 =⇒ y
t
Dissolution network
Edge count g
−(y
−, y
t−1
) = |y
−| , y
− = y
t−1 ∩ y
t
Recall, y
− is network about duration
θ
− means log-odds of existing tie to survive at y
t−1 =⇒ y</p>
<ul>
<li>Likelihood-based Inference for STERGM</li>
</ul>
<p>Fit STERGM by finding conditional MLE under an order 1 Markov assumption:</p>
<p>$$
<span class="math display">\[\begin{align}

\hat{\theta} 

&amp;= \arg\mathrm{max}_{\theta}&amp;&amp;\prod_{t=1}^{T}\mathrm{Pr} \Big ({Y}^{t}=y^{t} \Big | {Y}^{t-1}=y^{t-1} \Big)

\\



&amp;= &amp;&amp;\prod_{t=1}^{T}\frac{\exp \Big \{ (\theta^{+})^{\cdot T}g^{+}(y^{+},y^{t-1}) \Big\} } {c_{g^{+}}(\theta^{+},y^{t-1})}
\cdot
\frac{\exp\Big\{(\theta^{-})\cdot g^{-}(y^{-},y^{t-1})\Big\}}{c_{g^{-}}(\theta^{-},y^{t-1})}.

\end{align}\]</span>
$$</p>
<ul>
<li>where <span class="math inline">\(c_{g}(\theta,y^{t-1})=\sum_{y^{\prime}\in\psi}\exp \Big \{(\theta)^{\cdot T}g(y,y^{t-1}) \Big\}\)</span></li>
</ul>
<p>In practical, MLE can be obtained by maximizing the log-likelihood using numerical optimization.</p>
<p>The normalizing constant <span class="math inline">\(c_{g^+}(\theta^+,y^{t-1})\)</span> 와 <span class="math inline">\(c_{g^-}(\theta^-,y^{t-1})\)</span> 는 계산 불가. 각각은 시뮬레이션을 통해 (e.g. MCMCMLE) 를 통해 획득됨</p>
<p>i.e. maximizing <span class="math inline">\(I(\theta)-I(\theta^{0})=\{\theta-\theta^{0}\}\sum_{t=1}^{T}g(y^{t},y^{t-1})-\log\Big\{\prod_{t=1}^{T}\frac{c_{g}(\theta,y^{t-1})}{c_{g}(\theta^{0},y^{t-1})}\Big\}\)</span></p>
</div>
<div id="application-study" class="section level4" number="7.7.2.2">
<h4 number="7.7.2.2"><span class="header-section-number">7.7.2.2</span> Application Study</h4>
<p><br>
<br>
<br></p>
</div>
<div id="conclusion" class="section level4" number="7.7.2.3">
<h4 number="7.7.2.3"><span class="header-section-number">7.7.2.3</span> Conclusion</h4>
<ol style="list-style-type: decimal">
<li>Introduce statistical model for networks that evolve over time.</li>
<li>Separable parameterization of incidence and duration.</li>
<li>Greatly improve interpretability of model parameters, with sacrificing a little.</li>
<li>Identify the structure of incident and durational structure</li>
</ol>
<!--chapter:end:212107_ERGMforDynamicNetworks.Rmd-->
</div>
</div>
</div>
<div id="latent-network-models" class="section level2" number="7.8">
<h2 number="7.8"><span class="header-section-number">7.8</span> Latent Network Models</h2>
<div id="latent-position-model" class="section level3" number="7.8.1">
<h3 number="7.8.1"><span class="header-section-number">7.8.1</span> Latent Position Model</h3>
<p>ERGMs 와 다르게, 이 모델은 소셜 스페이스의 개념을 도입함. 이 소셜 스페이스에서는, 네트워크 관계에 있어 unobserved latent 특성이 potential transitive 경향을 represent, 즉 위력? 을 나타낼 수 있음. 이때 이 소셜 스페이스에서 각 actor (혹은 node) <span class="math inline">\(i\)</span>는 알려지지 않은 포지션 <span class="math inline">\(z_i\)</span>를 각각 차지하게 됨. 우리는 이를 <strong>latent position</strong> 이라고 부름.</p>
<p>여기서 우리는 주된 가정으로 ties 간의 <strong>조건부 독립</strong>을 가정한다. latent position이 주어진다면, 네트워크 안의 ties들은 조건부 독립임이 가정된다. 두 개인들 간의 특정한 tie의 확률은 그들의 positions 들의 함수로 모델링된다. 가령 소셜 스페이스 안에서의 두 actor 사이의 거리라던가.</p>
<p>이때 이를 노테이션으로 표기하자면 다음과 같다.</p>
<p><span class="math display">\[
P(Y | Z, X, \theta) = \prod_{i \not = j} P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)
\]</span></p>
<ul>
<li>sociomatrix <span class="math inline">\(Y_{n \times n}\)</span>, 이때 요소 <span class="math inline">\(y_{i,j}\)</span>는 actor <span class="math inline">\(i\)</span>로부터 <span class="math inline">\(j\)</span>로의 관계를 의미하는 값.</li>
<li>additional covariate information <span class="math inline">\(X\)</span></li>
<li>이때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(x_{i,j}\)</span>는 unobserved 성질이며, <span class="math inline">\(\theta\)</span>는 estimate되어야 하는 패러미터, <span class="math inline">\(Z\)</span>는 estimate 되어야 하는 포지션.</li>
</ul>
<p><br>
<br>
<br></p>
<div id="methods" class="section level4" number="7.8.1.1">
<h4 number="7.8.1.1"><span class="header-section-number">7.8.1.1</span> Methods</h4>
<div id="distance-models" class="section level5" number="7.8.1.1.1">
<h5 number="7.8.1.1.1"><span class="header-section-number">7.8.1.1.1</span> Distance Models</h5>
<p><span class="math inline">\(P(y_{i,j} | z_i , z_j , x_{i,j}, \theta)\)</span>는 로지스틱 회귀모형을 쓰면 편하게 패러미터化 할 수 있다. 이렇게 패러미터化 할 때 tie의 확률은 <span class="math inline">\(z_i , z_j \in \mathbb R\)</span> 인 <span class="math inline">\(z_i , z_j\)</span> 사이의 유클리디안 거리에 의존한다. 수식은 아래와 같다.</p>
<p><span class="math display">\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = \alpha + \beta &#39; x_{i,j} - |z_i - z_j |
\]</span></p>
<ul>
<li>이때 <span class="math inline">\(|z_i - z_j |&#39;\)</span> 는 그 어떤 metric으로도 대체될 수 있다는 것을 notice. 삼각부등식 <span class="math inline">\(d_{i,j} \le d_{i,k} + d_{k,j}\)</span>만 만족하면 됨.</li>
</ul>
<p>latent 포지션 모델은 본질적으로 reciprocal 하고 transitive 함. <mark>왜? 만약 <span class="math inline">\(i \rightarrow j\)</span> 이고 <span class="math inline">\(j \rightarrow k\)</span> 이라면, <span class="math inline">\(d_{i,j}\)</span> 와 <span class="math inline">\(d_{j,k}\)</span> 는 어쩌면 지나치게 크지는 않을 수도 있는 것이고, 이 경우에는 이하로 이어짐: </mark></p>
<ol style="list-style-type: decimal">
<li>events <span class="math inline">\(j \rightarrow i\)</span> (reciprocity)</li>
<li>그리고 <span class="math inline">\(i \rightarrow k\)</span> (transitivity)</li>
</ol>
</div>
<div id="projection-models" class="section level5" number="7.8.1.1.2">
<h5 number="7.8.1.1.2"><span class="header-section-number">7.8.1.1.2</span> Projection Models</h5>
<p>distance 모델은 본질적으로 symmetric 임. 즉 <span class="math inline">\(p(i → j) = p(j → i)\)</span>. 하지만 많은 (<strong>directed</strong>) 모델에서 이런 symmetry 는 성립을 안함. 예를 들어 actor <span class="math inline">\(i\)</span> 가 대량의 ties 들을 보내는 반면 <span class="math inline">\(j\)</span> 가 <span class="math inline">\(i\)</span> 에게서 ties 들을 받은 actors 전체 중 작은 subset 에게만 보낸다면? 따라서 행위의 변수 레벨은 관계에서 확률의 transitivity 를 allow하는 latent 포지션 모델의 맥락 속에서 모델링될 필요가 있다. 개개인의 소셜 활동의 특정한 수준도 고려되어야 함은 물론이다.</p>
<p>actor <span class="math inline">\(i\)</span>의 특성의 벡터 <span class="math inline">\(v_i\)</span>를 <strong>unit</strong> <span class="math inline">\(k\)</span>-dim 이라고 가정. <span class="math inline">\(i,j\)</span> 사이의 angle이 작으면 우리는 둘 사이에 tie가 존재할 가능성이 높다고 생각하자. 직각이면 중립, 둔각이면 낮다. actor <span class="math inline">\(i\)</span> 의 활동 레벨 <span class="math inline">\(a_i &gt;0\)</span> 를 설정한 후, <span class="math inline">\(i→j\)</span>의 tie의 존재 확률을 <span class="math inline">\(a_i v_i &#39; v_i = \frac{z_i&#39; z_j}{| z_j |}\)</span> (이때 <span class="math inline">\(z_i = a_i v_i\)</span>) 라고 설정한다면 이하의 등식이 성립.</p>
<p><span class="math display">\[
\eta_{i,j} = logodds (y_{i,j} = 1 | z_i , z_j , x_{i,j}, \alpha, \beta) = \alpha + \beta &#39; x_{i,j} + \frac{z_i&#39; z_j}{| z_j |}
\]</span></p>
</div>
</div>
<div id="estimation-2" class="section level4" number="7.8.1.2">
<h4 number="7.8.1.2"><span class="header-section-number">7.8.1.2</span> Estimation</h4>
<p><strong>Distance</strong> 모델 상황을 생각해보자. 유클리드 공간에서 set points 간의 거리는 회전, 반사, 이동에 불변 (invariant). 따라서 모든 각각의 latent postion의 행렬 <span class="math inline">\(Z_{k \times n}\)</span> 에 대해 같은 log-likelihood 를 갖는 다른 positions 을 표상하는 행렬이 존재한다.</p>
<p><span class="math inline">\(\mathcal Z\)</span> 를 회전, 반사, 이동에 불변한 <span class="math inline">\(Z\)</span>와 equivalent 한 postions들의 class 라고 하자. 각각의 <span class="math inline">\(\mathcal Z\)</span>에 대해 node 들 간의 거리를 모아 set 1개가 나옴. 이러한 positions 들의 class를 <strong>configuration</strong> 이라고 부름.</p>
<p>마찬가지로 Projection 모델에서의 <span class="math inline">\(Z\)</span> 에 대해서도 Projection 모델들은 positions 들의 회전과 반사에는 불변하지만, <mark>이동에 대해서는 불변이 아님.</mark></p>
<p>조건부 독립 모델의 log-likelihood 모델은 다음과 같다:</p>
<p><span class="math display">\[
\log P(Y | \eta ) = \sum_{i \not = j} \Big \{  \eta_{i,j}y_{i,j} - \log (1+\exp(\eta_{i,j})
\Big \}
\]</span></p>
<p>※ Steps:</p>
<ol style="list-style-type: decimal">
<li>각 j 에서 $z_j ’ $ 샘플링하기 위해 MH 스텝 거침. proposal 분포 <span class="math inline">\(\varphi(\cdot)\)</span> 으로부터 <span class="math inline">\(z_j&#39;\)</span> 생산하고 이를 이하의 확률 <span class="math inline">\(r_z \left ( z_j &#39; , z_j^{(t)} \right)\)</span> 로 채택. 비슷환 과정을 따라서 <span class="math inline">\(\alpha, \beta\)</span> 도 MH 이용해서 생산.</li>
</ol>
<p><span class="math display">\[
r_z \left ( z_j &#39; , .z_j^{(t)} \right)
= \frac{\pi \Big (z_j &#39;  \Big \vert Y, \alpha , \beta \Big )}{\pi \Big (z_j^{(t)}  \Big \vert Y, \alpha , \beta \Big )}
\cdot
\frac{\varphi \Big (z_j &#39; \rightarrow z_j^{(t)} \Big )}{\varphi \Big ( z_j^{(t)}\rightarrow z_j &#39; \Big )}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Procrustes</strong> 매칭 사용해서 MCMC 샘플 후처리.</p>
<ol style="list-style-type: lower-alpha">
<li>latent positions 들의 reference set 을 찾기 위해, MCMC 샘플로부터 latent positions들 중 full log posterior density가 가장 높은 latent positions들 <span class="math inline">\(Z_0\)</span>를 하나 뽑아서 쟁여둠</li>
<li><span class="math inline">\(Z_0\)</span>를 사용해서 각각의 MCMC 샘플에 Procrustes 매칭 적용</li>
</ol></li>
</ol>
<p><span class="math display">\[
Z^\ast  = \arg \min_{TZ} tr \Big \{ (Z_0 - TZ) &#39; (Z_0 - TZ) \Big \}
\]</span></p>
<p><br>
<br>
<br></p>
</div>
<div id="advantages" class="section level4" number="7.8.1.3">
<h4 number="7.8.1.3"><span class="header-section-number">7.8.1.3</span> Advantages</h4>
<p>네트워크 관계에 대한 시각적이고 모델에 기반한 공간적인 표현을 제공. 해석 용이함.</p>
<p>It is flexible and can be easily generalized to allow for multiple relationships, ties with varying strengths, and time-varying relations</p>
<p>deal easily with missing data, at least if information on ties is missing at random</p>
<p>the model is inherently transitive, and so we can expect an improved fit over models lacking such structure when the relations are transitive in nature</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="latent-position-cluster-model" class="section level3" number="7.8.2">
<h3 number="7.8.2"><span class="header-section-number">7.8.2</span> Latent Position Cluster Model</h3>
<p>$$
<span class="math display">\[\begin{align}


\log \frac{P(y_{i, j} = 1\Big | z_i , z_j , x_{i,j}, \beta)}{1 - P(y_{i, j} = 1 \Big | z_i , z_j , x_{i,j}, \beta)} &amp;= \beta_0 &#39; x_{i,j} - \beta_1 |z_i - z_j |

\\

P(Y | Z, X, \beta) &amp;= \prod_{i \not = j} P(y_{i, j} \Big | z_i , z_j , x_{i,j}, \beta) \tag{Likelihood}


\end{align}\]</span>
$$</p>
<ul>
<li><span class="math inline">\(z_i \sim \sum\limits_{g=1}^G \lambda_g \cdot MVN_d )\mu_g , \sigma^2_g I_d )\)</span>, where <span class="math inline">\(\sqrt{\frac{1}{n} \sum_i |z_i|^2} = 1\)</span>.</li>
<li><span class="math inline">\(\lambda_g\)</span>는 individual distribution의 비율</li>
</ul>
<p><br>
<br>
<br></p>
<div id="bayesian-estimation" class="section level4" number="7.8.2.1">
<h4 number="7.8.2.1"><span class="header-section-number">7.8.2.1</span> Bayesian Estimation</h4>
<p>※ Fully Bayesian Estimation Procedure</p>
<ol style="list-style-type: decimal">
<li>모델 패러미터 <span class="math inline">\(\beta, \lambda_g, \mu_g, \sigma_g^2\)</span> 들의 prior 분포 특정</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}

\beta &amp;\sim MVN_p \left( \xi , \Psi \right)

\\

\lambda &amp;\sim Dirichlet(\nu)

\\

\sigma^2_g &amp;\sim \sigma_0^2 Inv- \chi_\alpha^2 &amp;&amp; g = 1, \cdots, G

\\

\mu_g &amp;\sim MVN_d \left( 0, \omega^2 \cdot I_d \right) &amp;&amp; g = 1, \cdots, G


\end{align}\]</span>
$$</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\mathbf z_i , \beta, \lambda, \mu_g ,\sigma^2_g, K_i\)</span>의 full 조건부 posterior 분포 특정</li>
</ol>
<p>$$
<span class="math display">\[\begin{align}

{\bf z}_{i}\mid K_{i}=g,\mathrm{others}
&amp;\sim
\phi_{d}\bigl({\bf z}_{i};\mu_{g},\sigma_{g}^{2}I_{d}\bigr)
\cdot
P\bigl(\bf V\mid Z,X,\beta\bigr),\quad 

&amp;&amp;i=1,\cdots\cdot,n,

\\

\beta\mid \bf{Z},\mathrm{others}
&amp;\sim
\phi_{p}\Bigl(\beta;\xi,\Psi\Bigr)
\cdot
P\Bigl({Y}\mid\bf {Z},\bf {X},\beta\Bigr),

\\

\lambda\mid{\mathrm{others}}
&amp;\sim
{Dirichlet\Big (m + \nu \Big)}

\\

\mu_{g}\mid\mathrm{others}
&amp;\sim
MVN_{d}\left(\frac{m_{g}\bf z_{g}}{m_{g}+\sigma_{g}^{2}/\omega^{2}},\,\frac{\sigma_{g}^{2}}{m_{g}+\sigma_{g}^{2}/\omega^{2}}  \cdot I\right),\quad 

&amp;&amp;g=1,\cdot\cdot\cdot\cdot\cdot,G,


\\

\sigma_{g}^{2}\mid\mathrm{others}
&amp;\sim
\left(\sigma_{0}^{2}+d s_{g}^{2}\right) \cdot \mathrm{Inv-}\chi^2_{\alpha + m_s d},

&amp;&amp;g=1\,,\cdot\cdot\cdot\,,\,\bar{G},


\\

P\Bigl(K_{i}=g \bigg | \mathrm{others}\Bigr)
&amp;=
\frac{\lambda_{g}\phi_{d}\Bigl(z_{i};\mu_{g},\;\sigma_{g}^{2} \cdot I_{d}\Bigr)}
{\sum_{r=1}^{G}\lambda_{r}\phi_{d}\Bigl(z_{i};\mu_{r}, \; \sigma_{r}^{2} \cdot I_{d}\Bigr)},\quad 

&amp;&amp;g=1,\cdot\cdot\cdot,G.





\end{align}\]</span>
$$</p>
<p>Steps.</p>
<ol style="list-style-type: decimal">
<li><p>MH 스텝 이용해서 <span class="math inline">\(Z_{t+1}\)</span> 업데이트
1. proposal <span class="math inline">\(2_{i}^{\ast}\sim\left|l\right|/|\bigvee_{i}(\Sigma_{i},(\hat{L}_{i}^{\ast}|_{i})\)</span>, <span class="math inline">\(g=1, \cdots, G\)</span>
2. accept <span class="math inline">\(Z_i^\ast\)</span> as the i-th element of <span class="math inline">\(z_{t+1}\)</span> with probability <span class="math inline">\(\frac{P\big(\mathbf{V}|\mathbf{Z}^{*},\mathbf{X},\beta_{t}\big)\phi_{d}\big(\mathbf{Z}_{i}^{*},\mu K_{i},\sigma_{K}^{2}|_{d}\big)}{P\big(\mathbf{V}|\mathbf{Z}_{t},\mathbf{X},\beta_{t}\big)\phi_{d}\big(\mathbf{Z}_{i i};\mu K_{i},\sigma_{K}^{2}|_{d}\big)}\)</span></p></li>
<li><p>MH 스텝 이용해서 <span class="math inline">\(\beta_{t+1}\)</span> 업데이트
1. <span class="math inline">\(2_{i}^{\ast}\sim\left|l\right|/|\bigvee_{i}(\Sigma_{i},(\hat{L}_{i}^{\ast}|_{i})\)</span>, <span class="math inline">\(g=1, \cdots, G\)</span>
2. accept <span class="math inline">\(Z_i^\ast\)</span> as the i-th element of <span class="math inline">\(z_{t+1}\)</span> with probability <span class="math inline">\(\frac{{\cal P}\big(\mit{W}\lbrack\mathbf{Z}_{t+1},\mit{X},\beta^{*}\big)\phi_{\rho}\big(\beta^{*};\xi,\mit{\mit\Psi}\big)}{{\cal P}\Big(\mit{\bf V}\lbrack\Z_{t+1},\mit{\bf X},\beta_{t}\big)\phi_{\rho}\big(\beta_{t};\xi,\mit{\mit\Psi}\Big)}.\)</span></p></li>
<li><p>Update λ, µg, σ, g, Ki using full conditional posterior distributions</p></li>
</ol>
<p>Pros and Cons</p>
<ul>
<li>장점: 성능이 더 나음</li>
<li>단점: 더 복잡함</li>
</ul>
<p><br>
<br>
<br></p>
</div>
<div id="identifiability-of-positions-and-cluster-labels" class="section level4" number="7.8.2.2">
<h4 number="7.8.2.2"><span class="header-section-number">7.8.2.2</span> Identifiability of Positions and Cluster Labels</h4>
<p>Likelihood 에만 의존해서 cluster化 성능 평가하면 문제생김. positions 과 cluster labels 들의 Non-identifiabilities 문제. Likelihood 는 이하에 불변.</p>
<ol style="list-style-type: decimal">
<li>latent positions 들의 반사, 회전, translation</li>
<li>cluster 들의 relabeling. 이는 <strong>Label switching problem</strong>[^cluster 의 label 을 permute 하는 것은 Likelihood 에 변화를 가져오지 않지만, obs 들을 그룹에 넣는 과정에서 우리가 문제를 겪게 됨. Likelihood 는 같지만 label 이 다른 순간 이건 cluster 의 구성이 다른 것과 동일하니까.] 으로 이어짐.</li>
</ol>
<p>이를 해결하기 위한 방법으로 <strong>Minimizing Bayes risk</strong> 가 제시.</p>
<ol style="list-style-type: decimal">
<li>estimate 되는 Bayes risk[^Bayes risk = Expecation of loss function. 이때 loss function 으로는 Kullback-Leibler loss 를 사용한다.] 를 최소화하는 actor 들의 position 탐색</li>
<li>latent position 의 posterior 추출값 (draw) 를 Procrustes Transform 하고 동일한 Transformation Matrix 를 사용하여, cluster mean 와 Cov 를 transform</li>
<li>Estimate 된 Bayes risk 를 최소화하는 cluster membership 의 확률을 탐색</li>
</ol>
<p>이제 이하의 과정을 거쳐서 cluster 의 갯수를 정한다. Bayesian estimation - 이하의 equation, 즉 higehest posterior probability 를 가지는 model 을 선택.</p>
$$
<span class="math display">\[\begin{array}


&amp;P(Y,{\hat{Z}}|G)

&amp;=
&amp;&amp;\underbrace
{\int P(Y|{\hat{Z}},X,\beta)p(\beta)d\beta}
_{\substack{\text{integrated likelihood for the logistic regression} 
\\ \approx BIC_{lr}(\text{logistic regression})}}

&amp;&amp;\cdot 

&amp;&amp;\underbrace
{\int P({\hat{Z}}|\theta)p(\theta)d\theta}
_{\substack{\text{integrated likelihood for the mixture model} 
\\ \approx BIC_{mbc}(\text{mixture model})}}

\\

BIC &amp;= &amp;&amp;BIC_{lr} &amp;&amp;+ &amp;&amp;BIC_{mbc}

\\

&amp;= &amp;&amp; \left \{ 2 \log \Big [ P \Big \{ Y \Big | \hat Z , X, \hat \beta ( \hat Z ) \Big \} \Big ] - d_{logit} \log (n_{logit}) \right \}

&amp;&amp; +

&amp;&amp; 

\left\{ 2 \log \Big [ P \Big \{ \hat Z \Big | \hat \theta ( \hat Z ) \Big \} \Big ] - d_{mbc} \log (n) \right \}

\end{array}\]</span>
<p>$$</p>
<ul>
<li><span class="math inline">\(d_{logit} =\)</span> # of parameters in the logistic regression</li>
<li><span class="math inline">\(n_{logit} =\)</span> # of ties in data</li>
<li><span class="math inline">\(d_{mbc} =\)</span> # of parameters in the clustering model</li>
</ul>
<!--chapter:end:212108_Latent.Rmd-->
</div>
</div>
</div>
<div id="additive-and-multiplicative-effects-network-models" class="section level2" number="7.9">
<h2 number="7.9"><span class="header-section-number">7.9</span> Additive and Multiplicative Effects Network Models</h2>
<div id="introduction-3" class="section level3" number="7.9.1">
<h3 number="7.9.1"><span class="header-section-number">7.9.1</span> Introduction</h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="social-relations-regression" class="section level3" number="7.9.2">
<h3 number="7.9.2"><span class="header-section-number">7.9.2</span> Social Relations Regression</h3>
<p><br>
<br>
<br></p>
<div class="math-left-align">
<p><span class="math display">\[a+b=c\]</span></p>
</div>
<div class="math-left-align">
<p>$$
<span class="math display">\[\begin{alignat}{2}

y_{i,j} &amp;= &amp;&amp;\; \; \; \; \mu &amp;&amp; +a_{i}+b_{j}+\epsilon_{i,j} \tag{AEM}
\\
y_{i,j} &amp;= &amp;&amp;\; \; \; \; \mu &amp;&amp; +a_{i}+b_{j}+\epsilon_{i,j} \tag{SRM}
\\
y_{i,j} &amp;= \beta&#39; \mathbf x_{i,j} &amp;&amp; +\mu &amp;&amp; +a_{i}+b_{j}+\epsilon_{i,j} \tag{SR Regression M}
\\
y_{i,j} &amp;=\beta^{T} \mathbf x_{i,j} &amp;&amp; +\mathbf u_{i}^{T} \mathbf v_{j}  &amp;&amp; +{a}_{i}+b_{j}+\epsilon_{i,j}, \; \; \; \; \; \; \; \; \; \; \; \; \; \; 


&amp;&amp; \forall i&lt;j: &amp;&amp;\left(\epsilon_{i,j},\epsilon_{j,i}\right) &amp;&amp;\overset{iid}{\sim} 


N_{2} \Bigg( \mathbf 0 , \; \sigma^2 \begin{pmatrix} 1 &amp; \rho \\ \rho &amp; 1 \end{pmatrix} \Bigg) \tag{AMEM}

\\


&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp;(\mathbf u_1, \mathbf v_1), \cdots, (\mathbf u_n, \mathbf v_n) 
&amp;&amp;\overset{iid}{\sim} N_{2r}(\mathbf 0 , \Phi)

\\

&amp; &amp;&amp; &amp;&amp; &amp;&amp; &amp;&amp;(a_1 , b_1), \cdots, (a_n , b_n) 
&amp;&amp;\overset{iid}{\sim} N_2(\mathbf 0 , \Sigma) \tag{Random effects AMEM}

\\

V &amp;=M(X,\beta)+U V^{T} &amp;&amp;  &amp;&amp; +a{1}^{T}+1b^{T}+E \tag{Gibbs Sampling for the AME}


\end{alignat}\]</span></p>
<p>$$</p>
</div>
<p><span class="math display">\[
P(Y) \sim\exp\left(\mu\sum_{i,j}y_{i,j}+\sum_{i} \Bigg \{ a_{i}\sum_{j}y_{i,j}+b_{i}\sum_{j}y_{j,i} \Bigg\}+\rho\sum_{i,j}y_{i,j}y_{j,i}\right)
\]</span></p>
<div class="line-block">| <span class="math display">\[ | \]</span> | [^Combines a linear regression model with the covariance structure of the SRM as follows, where <span class="math inline">\(\mathbf x_{i,j}\)</span> is <span class="math inline">\(p\)</span>−dimensional vector of regressors and <span class="math inline">\(\beta\)</span> is a vector of regression coefficient to be estimated.] |</div>
<div id="addictive-effect-model-iid-model" class="section level4" number="7.9.2.1">
<h4 number="7.9.2.1"><span class="header-section-number">7.9.2.1</span> Addictive Effect Model (iid model)</h4>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Addictive Effect Model (iid model)</th>
<th align="center">Social Relations Model (SRM)</th>
<th align="center">Social Relations Regression Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Goal</td>
<td align="center">Consider Dependency</td>
<td align="center">Social Relations Model</td>
<td align="center">Quantify the association between a particular dyadic variable and some other dyadic or nodal variables</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(a_i\)</span></td>
<td align="center">sender effect (row means of the sociomatrix)</td>
<td align="center">zero-mean rv</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(b_j\)</span></td>
<td align="center">receiver effect (column means of the sociomatrix)</td>
<td align="center">zero-mean rv</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\epsilon_{i,j}\)</span></td>
<td align="center">-</td>
<td align="center">zero-mean rv</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center">(2)</td>
<td align="center">Limitation: Unable to represent higher-order network patterns (lack of fit)</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: decimal">
<li>with effects otherwise being independent</li>
</ol>
<p><span class="math display">\[
V a r\left[\begin{pmatrix}a_i \\ b_j\end{pmatrix}\right]=\Sigma={\left(\begin{array}{l l}{\sigma_{a}^{2}}&amp;{\sigma_{a b}}\\ {\sigma_{a b}}&amp;{\sigma_{b}^{2}}\end{array}\right)}
\\
V a r\left[\begin{pmatrix}\epsilon_{i,j} \\ \epsilon_{j,i}\end{pmatrix}\right]=\sigma^{2} \begin{pmatrix}1 &amp; \rho \\ \rho &amp; 1\end{pmatrix}
\]</span></p>
<ul>
<li><span class="math inline">\(a_i\)</span>: sender effect (row means of the sociomatrix),</li>
<li><span class="math inline">\(b_j\)</span>: receiver effect (column means of the sociomatrix)</li>
</ul>
<p>목표: dependency 고려</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="multiplicative-effects-models" class="section level3" number="7.9.3">
<h3 number="7.9.3"><span class="header-section-number">7.9.3</span> Multiplicative Effects Models</h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="inference-via-posterior-approximation" class="section level3" number="7.9.4">
<h3 number="7.9.4"><span class="header-section-number">7.9.4</span> Inference via Posterior Approximation</h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="discussion-and-example-with-r" class="section level3" number="7.9.5">
<h3 number="7.9.5"><span class="header-section-number">7.9.5</span> Discussion and Example with R</h3>
<!--chapter:end:212109_AddiMult.Rmd-->
</div>
</div>
</div>
<div id="high-dimension" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> High Dimension</h1>
<div id="introduction-4" class="section level2" number="8.1">
<h2 number="8.1"><span class="header-section-number">8.1</span> Introduction</h2>
<!--chapter:end:212301.Rmd-->
</div>
<div id="concentration-inequalities" class="section level2" number="8.2">
<h2 number="8.2"><span class="header-section-number">8.2</span> Concentration inequalities</h2>
<p>다양한 경우에 랜덤변수의 tails의 bound, 혹응 랜덤변수가 mean이나 median에 close 임을 보이기 위한 쌍방향 부등식의 획득은 괘 매력적임.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="motivation" class="section level3" number="8.2.1">
<h3 number="8.2.1"><span class="header-section-number">8.2.1</span> Motivation</h3>
<p><span class="math inline">\(X_1 , \cdots, X_n \overset{iid}{\sim}N(\mu, \sigma^2)\)</span> 일 경우에 <span class="math inline">\(\bar X \sim N(\mu, \frac{\sigma^2}{n})\)</span> 이며, 노멀분포의 tail bound (혹은 Chernoff bound 에 의해) 는 이하를 생산함:</p>
<p><span class="math display">\[
\forall t \ge 0 : P( | \bar X - \mu | \ge t) \le 2 \exp \left( - \frac{nt^2}{2\sigma^2}\right)
\]</span></p>
<p>따라서 샘플평균 <span class="math inline">\(\bar X\)</span>가 population 평균 <span class="math inline">\(\mu\)</span>와 크게 떨어져있을 확률은 빠르게 decay. 이를 응용해 finite 숫자의 샘플에 대해 과하게 많은 수의 가정 없이도 랜덤 샘플에 대한 bound 를 획득해보자.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="from-markov-to-chernoff" class="section level3" number="8.2.2">
<h3 number="8.2.2"><span class="header-section-number">8.2.2</span> From Markov to Chernoff</h3>
<ol style="list-style-type: decimal">
<li>Markov’s Inequality</li>
</ol>
<p>given <span class="math inline">\(X \ge 0\)</span> (nonnegative) 이며 <span class="math inline">\(|E(X)| &lt; \infty\)</span> (finite mean), 이하가 성립한다.</p>
<p><span class="math display">\[
\forall t \ge 0: P(X\ge t) \le\frac{E(X)}{t}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Chebyshev’s inequality</li>
</ol>
<p><span class="math inline">\(Var(X) &lt; \infty)\)</span> (finite variance) 일 때 이하가 성립. 이는 Markov 부등식을 nonnegative 랜덤변수 <span class="math inline">\((X-\mu)^2\)</span> 에 적용한것.</p>
<p><span class="math display">\[
\forall t \ge 0: P(|X - \mu| \ge t) \le\frac{Var(X)}{t^2}
\]</span></p>
<p>이는 즉 <span class="math inline">\(Var\)</span> 가 작을 때 <span class="math inline">\(X\)</span> 가 <span class="math inline">\(\mu\)</span> 와 가깝다는 것을 보장한다는 점에서 가장 기초적인 <strong>contentration ineqaulity</strong>. Markov 와 Chebyshev 는 <strong>sharp</strong> 이며, 이는 곧 이 둘이 일반적으로는 imporve 될 수 없다는 것을 뜻함.</p>
<ol start="3" style="list-style-type: decimal">
<li>Polynomial Markov</li>
</ol>
<p><span class="math inline">\(X\)</span>가 order <span class="math inline">\(k\)</span>의 central moment 를 가진다면, 랜덤변수 <span class="math inline">\(|X-\mu|^k\)</span> 에 Markov 부등식 적용하면 이하를 생산한다. 모든 integer <span class="math inline">\(k=1,2,\cdots\)</span>에 대해 order <span class="math inline">\(k\)</span> 의 central moment 가 존재한다면 2번째 ineq 도 성립.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}

\forall t \ge 0: P(|X-\mu| \ge t) &amp;\le &amp;&amp;\frac{E \Big [ |X-\mu|^k \Big]}{t^k}

\\

&amp;\le \lim_{k=0,1,2…} &amp;&amp;\frac{E \Big [ |X-\mu|^k \Big]}{t^k} \tag{2.1}

\end{alignat}\]</span>
$$</p>
<ol start="4" style="list-style-type: decimal">
<li>Chernoff bound</li>
</ol>
<p>랜덤변수 <span class="math inline">\(X\)</span> 가 0의 neighborhood 에서 mgf 를 가진다면, 즉 <span class="math inline">\(\exists b&gt;0, \forall \lambda\le|b|: \varphi(\lambda) = E \Big\{ e^{\lambda(X-\mu)}\Big \}\)</span> 라고 가정하자. 이때 <span class="math inline">\(\forall \lambda \in [0, b]\)</span> 에서 랜덤변수 <span class="math inline">\(Y = e^{\lambda(X-\mu)}\)</span> 에 대해 Markov 부등식을 적용할 수 있으며, 이에 의해 upper bound 를 획득할 수 있다. 우리가 선택하는 <span class="math inline">\(\lambda\)</span>를 Chernoff bound 에 최적화 시키면 (2.2)와 같이 나온다.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
&amp;P(X-\mu &gt; t) = P(e^{\lambda(X-\mu)} \ge e^{\lambda t}) &amp;&amp;\le \frac{E(e^{\lambda(X-\mu)})}{e^{\lambda t}}

\\

\log &amp;P(X-\mu &gt; t)  &amp;&amp;\le \inf_{\lambda \in [0, b]} \left \{ {\log E(e^{\lambda(X-\mu)})} - {{\lambda t}}
\right\}
\end{alignat}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="sub-gaussian-random-variables" class="section level3" number="8.2.3">
<h3 number="8.2.3"><span class="header-section-number">8.2.3</span> sub-Gaussian random variables</h3>
<p>모든 랜덤변수 <span class="math inline">\(X\)</span>에 대해 그것의 mgf 가 <span class="math inline">\(\forall \lambda \in \mathbb R : E \left \{ e^{\lambda (X-\mu)} \right\} \le e^{\frac{\sigma^2 \lambda^2}{2} }\)</span> 를 만족하면 특정 tail bound 가 성립된다. 이를 응용하면 아래의 개념을 얻을 수 있다.</p>
<div class="definition">
<p><span id="def:unlabeled-div-1" class="definition"><strong>(#def:unlabeled-div-1) (sub-Gaussian) </strong></span>평균이 <span class="math inline">\(\mu = E(X)\)</span> 인 랜덤변수 X에 대해 <span class="math inline">\(\exists \sigma &gt;0\)</span> 에 대해 이하가 성립하면 이는 sub-Gaussian 이며 <span class="math inline">\(X \in SG(\sigma^2)\)</span>.</p>
<p><span class="math display">\[
\forall \lambda \in \mathbb R : E \left \{ e^{\lambda (X-\mu)} \right\} \le e^{\frac{\sigma^2 \lambda^2}{2} }
\]</span></p>
</div>
<ul>
<li><span class="math inline">\(sigma\)</span> 는 sub-Gaussian 패러미터</li>
<li><span class="math inline">\(sigma^2\)</span> 는 variance proxy</li>
</ul>
<p>symmetry 해보면 <span class="math inline">\(X \in SG(\cdot)\)</span> 일 경우에만 <span class="math inline">\(-X \in SG(\cdot)\)</span>.</p>
<p>이하의 값은 Example 2.1 과 동일하며, 따라서 모든 SG 랜덤변수는 이하의 ineq 를 만족한다.</p>
<p><span class="math display">\[
\forall t \ge 0: P(|X-\mu| \ge t) \le 2 e^{-\frac{t^2}{2 \sigma^2}} \tag{2.4}
\]</span></p>
<ul>
<li>Jensen’s Ineq</li>
</ul>
<p>convex 함수 <span class="math inline">\(g: \mathbb R \mapsto \mathbb R\)</span> 에 대해 <span class="math inline">\(E \Big \{ g(X) \Big \} \ge g \Big \{ E(X) \Big \}\)</span>. g가 concave 면 逆.</p>
<p><strong>Proof:</strong></p>
<p><span class="math inline">\(\mu = E(X)\)</span> 로 하고, <span class="math inline">\(L_\mu (x) = a + bx\)</span> 가 <span class="math inline">\(\mu\)</span> 에서의 <span class="math inline">\(g\)</span> 에 대한 tangent line, i.e. <span class="math inline">\(L_\mu (\mu) = g(\mu)\)</span>. convexity 에 의해 <span class="math inline">\(\forall x:g(x) \ge L_\mu (x)\)</span>. 따라서</p>
<p><span class="math display">\[
E[g(X)] \ge E[L_\mu (X)] = E(a+bX) =a+b\mu= L_\mu (\mu) = g(\mu)
\]</span></p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="properties-of-sub-gaussian-random-variables" class="section level3" number="8.2.4">
<h3 number="8.2.4"><span class="header-section-number">8.2.4</span> Properties of sub-Gaussian random variables</h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \in SG(\cdot)\)</span> 일 경우 <span class="math inline">\(Var(X) \le \sigma^2\)</span></li>
<li><strong>Hoeffding’s lemma</strong>: almost surely 하게 <span class="math inline">\(a \le X-\mu \le b\)</span> 한 실수 <span class="math inline">\(a, b\)</span>가 있다면, <span class="math inline">\(X \in SG \Big ( (\frac{b-a}{2})^2\Big )\)</span>.</li>
<li><span class="math inline">\(X \in SG(\sigma^2)\)</span> 이며 <span class="math inline">\(Y \in SG(\tau^2)\)</span> 일 경우,
<ul>
<li>$a R: aX SG ( a^2 ^2 )</li>
<li><span class="math inline">\(X+Y \in SG \Big ( (\sigma + \gamma)^2\Big )\)</span></li>
<li>if <span class="math inline">\(X \perp Y\)</span>, then $X + Y SG ( ^2 + ^2 )</li>
</ul></li>
</ol>
<ul>
<li><ol style="list-style-type: decimal">
<li><span class="math inline">\(\forall \lambda \in \mathbb R: E \left \{ e^{\lambda (X-\mu)} \right\} \le e^{\frac{\sigma^2 \lambda^2}{2} }\)</span>, Taylor’s thm 에 의해 이하가 성립. 쌍방을 <span class="math inline">\(\labmda^2 &gt;0\)</span> 으로 나누고 <span class="math inline">\(\labmda \rightarrow 0\)</span> 를 취하는 것으로 (1) 성립.</li>
</ol></li>
</ul>
<p>$$
1 + _{=0}</p>
<ul>
<li><p> _{=Var(X)}</p></li>
<li><p>o(^2)  +  + o(^2 )
$$</p></li>
<li><ol start="2" style="list-style-type: decimal">
<li></li>
</ol></li>
</ul>
<p><span class="math inline">\(\forall \lambda \in \mathbb{R}:E [e^{\lambda\left(x-\mu\right)}]\ \le {\exp\left \{ \frac{\lambda^{2}\left(b-a\right)^{2}}{8} \right \}}\)</span> 인 것만 보이면 됨. WLOG, <span class="math inline">\(\mu=0\)</span> 임을 가정. <span class="math inline">\(\forall \lambda \in \mathbb R :e^{\lambda x}\)</span> 는 x의 convex 이므로,</p>
<p>$ a x b :e<sup>{x}e</sup>{a}+e^{b}$</p>
<p>따라서 <span class="math inline">\(\mu=0\)</span> 를 가정하면,</p>
<p><span class="math inline">\(\mathbb{R}[e^{\lambda X}]\leq\frac{b}{b-a}e^{\lambda a}-\frac{a}{b-a}e^{\lambda b}.\)</span></p>
<p>이때 <span class="math inline">\(h = \lambda(b-a)\)</span> 와 <span class="math inline">\(p = -\frac{a}{b-a}\)</span> 라고 하고, <span class="math inline">\(L(h) = -hp \log(1-p + pe^h)\)</span> 라고 하자. 이때 우리는 이하가 증명된다.</p>
<p><span class="math inline">\({\frac{b}{b-a}}e^{\lambda a}-{\frac{a}{b-a}}e^{\lambda b}\equiv e^{L(h)}.\)</span></p>
<p>이에 더해 <span class="math inline">\(L(0) = L&#39;(0) = 0\)</span> 이며 <span class="math inline">\(\forall h: L&#39;&#39;(h) \le \frac{1}{4}\)</span>. 따라서 Taylor expansion 에 의해</p>
<p><span class="math inline">\(L(h)\le\frac{1}{8}h^{2}=\frac{1}{8}\lambda^{2}(b-a)^{2}\)</span> 이며 따라서 <span class="math inline">\(E [e^{\lambda\left(x-\mu\right)}]\ \le {\exp\left \{ \frac{\lambda^{2}\left(b-a\right)^{2}}{8} \right \}}\)</span>.</p>
<ul>
<li><ol start="3" style="list-style-type: decimal">
<li></li>
</ol></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>는 SG 랜덤변수의 정의에 의해 trivial.</p></li>
<li><p>를 증명하자. <span class="math inline">\(E(X) = E(Y)=0\)</span> 임을 가정. 이때 이하가 도출된다.</p></li>
</ol>
<p>$$
[e^{(X+Y)}]=[e<sup>{X}e</sup>{Y}] ([e^{p X}])<sup>{1/p}([e^{q Y}])</sup>{1/q}
\
,e^{+}</p>
<p>\=
e<sup>{(p</sup>{2}+q^{2})}<br />
</p>
<p>\
,e<sup>{(+)</sup>{2}}
$$</p>
<ol style="list-style-type: decimal">
<li>Holder 부등식</li>
<li>by condition <span class="math inline">\(X\in SG(\sigma^2)\)</span>, <span class="math inline">\(Y\in SG(\tau^2)\)</span></li>
<li>by letting <span class="math inline">\(p = \frac{\tau}{\sigma}+1\)</span>, <span class="math inline">\(q = \frac{\sigma}{\tau}+1\)</span>.</li>
</ol>
<ol start="3" style="list-style-type: lower-alpha">
<li>를 증명하다. <span class="math inline">\(X \perp Y\)</span> 이므로, <span class="math inline">\(E(X) = E(Y)=0\)</span> 을 가정하는 것으로, 이하에 의해 성립.</li>
</ol>
<p><span class="math display">\[
\mathbb{E}[e^{\lambda(X+Y)}]=\mathbb{E}[e^{\lambda X}]\times\mathbb{E}[e^{\lambda Y}]\leq e^{\frac{\lambda^{2}(\sigma^{2}+\tau^{2})}{2}},
\]</span></p>
<ul>
<li><strong>Holder’s Inquality</strong></li>
</ul>
<p><span class="math inline">\(\forall p, q &gt;0\)</span> with <span class="math inline">\(\frac 1 p + \frac 1 q = 1\)</span>, it holds that</p>
<p><span class="math inline">\(\mathbb{E}[|X Y|]\leq||X||p||Y||_{q} = \{\mathbb{E}[|X|^{p}]\}^{1/p} \cdot \{\mathbb{E}[|Y|^{q}]\}^{1/q}\)</span></p>
<p>Proof. Observe that <span class="math inline">\(\forall a, b \ge 0: a b=e^{\log(a b)}=e^{\frac{1}{p}p\log a+\frac{1}{q}q\log b}\le\frac{1}{p}e^{p\log a}+\frac{1}{q}e^{q\log b}=\frac{1}{p}a^{p}+\frac{1}{q}b^{q}\)</span>, 이는 Jensen 에 의해 성립. 이제 <span class="math inline">\(a = \frac{X}{||X||_p}\)</span>, <span class="math inline">\(b=\frac{Y}{||Y||_q}\)</span> 로 하고 양쪽에 expectation 취하는 것으로 ineq 성립.
<br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="equivalent-definitions" class="section level3" number="8.2.5">
<h3 number="8.2.5"><span class="header-section-number">8.2.5</span> Equivalent definitions</h3>
<p>이하는 <span class="math inline">\(SG(\sigma&gt;0)\)</span> 여부에 대해 equivalent. <mark>(up to multiplicative constants).</mark></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-2" class="theorem"><strong>(#thm:unlabeled-div-2) </strong></span>zero-mean 인 모든 랜덤변수 <span class="math inline">\(X\)</span> 에 대해 이하의 성질은 equiv.</p>
<p>$$
<span class="math display">\[\begin{align}

&amp;\exists \sigma &gt;0:
&amp;&amp;\forall \lambda\in\mathbb{E}:
&amp;&amp;\mathbb{E}[e^{\lambda X}]\leq e^{\frac{\lambda^{2}\sigma^{2}}{2}}

\\

\iff
&amp;\exists c \ge 0, \exists Z \sim N(0, \tau^2):
&amp;&amp;\forall s \ge 0:
&amp;&amp;\mathbb{P}(|X|\geq s) \le c\mathbb{P}(|Z|\geq s)

\\

\iff
&amp;\exists \theta \ge 0:
&amp;&amp;\forall  k = 1, 2, \cdots:
&amp;&amp;\mathbb{E}[X^{2k}]\leq{\frac{(2k)!}{2^{k}k!}}\theta^{2k}

\\

\iff
&amp;\exists \sigma \ge 0:
&amp;&amp;\forall \lambda \in [0, 1):
&amp;&amp;\mathbb{E}\left[e^{\frac{\lambda X^{2}}{2\sigma^{2}}}\right]\leq{\frac{1}{\sqrt{1-\lambda}}}
\end{align}\]</span></p>
<p>$$</p>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="sub-gaussian-random-vectors" class="section level3" number="8.2.6">
<h3 number="8.2.6"><span class="header-section-number">8.2.6</span> Sub-Gaussian random vectors</h3>
<div class="definition">
<p><span id="def:unlabeled-div-3" class="definition"><strong>(#def:unlabeled-div-3) </strong></span>이하가 성립할 때 랜덤벡터 <span class="math inline">\(X\)</span> 는 <strong>sub-Gaussian</strong> with variance proxy <span class="math inline">\(\sigma^2\)</span>.</p>
<ol style="list-style-type: decimal">
<li>랜덤벡터 <span class="math inline">\(\mathbf X \in \mathbb R^d\)</span> 가 centered</li>
<li><span class="math inline">\(\forall u \in \mathbb R^d, \; ||u||_2 = 1:\)</span> 랜덤변수 <span class="math inline">\(u&#39;X \in SG(\sigma^2)\)</span>.</li>
</ol>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="hoeffdings-inequality" class="section level3" number="8.2.7">
<h3 number="8.2.7"><span class="header-section-number">8.2.7</span> Hoeffding’s inequality</h3>
<p>독립인 SG 랜덤변수의 샘플 평균은 <strong>Hoeffding’s inequality</strong> 라는 exponential tail bound 를 갖는다.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-4" class="theorem"><strong>(#thm:unlabeled-div-4) (Hoeffding’s inequality) </strong></span>independent <span class="math inline">\(X_i \in SG(\sigma_i^2)\)</span>, <span class="math inline">\(i = 1, \cdots, n\)</span> 들이 각각 <span class="math inline">\(E(X_i) = \mu_i\)</span> 라고 하자. 그러면 이하가 성립한다.</p>
<p><span class="math display">\[
\forall t \ge 0:
\mathbb{P}\left(\left|{\frac{1}{n}}\sum_{i=1}^{n}X_{i}-\mu_{i}\right|\geq t\right)\leq2\exp\left(-{\frac{n^{2}t^{2}}{2\sum_{i=1}^{n}\sigma_{i}^{2}}}\right)
\]</span></p>
<p>이는 Section 2.4의 property 3 과 inequality (2.4)에 의해 바로 구해진다.</p>
</div>
<p>Hoeffding bound 는 보통</p>
<p>bounded 랜덤변수의 특별한 경우로서만 논해진다.</p>
<p><span class="math inline">\(\forall i = 1, \cdots, n: X_i \in [a,b]\)</span> 를 가정하자.</p>
<p>이 경우 Hoeffding’s lemma (property 2 in Section 2.4) 에 의해 <span class="math inline">\(X_i \in \Bigg \{ \left( \frac{b-a}{2}\right )^2 \Bigg \}\)</span>, i.e., <span class="math inline">\(\forall i = 1, \cdots, n: \sigma_i^2 = \frac{(b-a)^2}{4}\)</span>. 따라서 위의 thm에 의해</p>
<p><span class="math display">\[
\mathbb{P}\biggl(\left|{\frac{1}{n}}\sum_{i=1}^{n}X_{i}-\mu_{i}\right|\geq t\biggr)\leq2\exp\biggl(-{\frac{2n t^{2}}{(b-a)^{2}}}\biggr)
\]</span>
<br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="maximal-inequalities" class="section level3" number="8.2.8">
<h3 number="8.2.8"><span class="header-section-number">8.2.8</span> Maximal inequalities</h3>
<p>finite 숫자의 SG 랜덤변수의 maximum 에 대한 tail / expectation bound 를 구할 수 있다.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-5" class="theorem"><strong>(#thm:unlabeled-div-5) </strong></span>let independent <span class="math inline">\(X_1 , \cdots, X_n \in SG(\sigma^2)\)</span>, <span class="math inline">\(E(X_i) = 0\)</span>. Then</p>
<p>$$
<span class="math display">\[\begin{align}
\mathbb{E}\ \Big[\operatorname*{max}_{i=1,\cdots,n}X_{i} \Big] &amp;\leq\sigma{\sqrt{2\log n}}

\\


\forall t \ge 0: \mathbb{P}\Bigl(\max\limits_{i=1,\cdots, n}X_{i}\geq t\Bigr) &amp;\leq n e^{-{\frac{t^{2}}{2\sigma^{2}}}}

\end{align}\]</span>
$$</p>
</div>
<p><strong>Proof</strong>:</p>
<p>$$</p>
<p>$$</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section" class="section level3" number="8.2.9">
<h3 number="8.2.9"><span class="header-section-number">8.2.9</span> </h3>
<p>$$
<span class="math display">\[\begin{align}


\mathbb{E}{\biggl[}\operatorname*{max}_{i=1,\dots,n}X_{i}{\biggr]}\ 

&amp;=\ \frac{1}{s}{\bf E}{\biggl[}\log{\biggl\{}\exp{\biggl(}s{\max_{i = 1, \cdots, n}}\,X_{i}{\biggr)}\Biggr\}

\\

&amp;\stackrel{(i)]}{\leq}~\frac{1}{s}\log\left\{\mathbb{E}\Big[\exp\left(s\operatorname*{max}_{i=1\ldots n}X_{i}\right)\Big]\right\}

&amp;&amp;= \frac{1}{s}\log\left\{\mathbb{E}\Big[\operatorname*{max}_{i=1\ldots n}e^{sX_{i}}\Big]\right\}

\tag{Jensen&#39;s inequality}

\\

&amp;\leq\ {\frac{1}{s}}\log\left\{\mathbb{E}\left[\sum_{i=1}^{n}e^{s X_{i}}\right]\right\}

\\

&amp;\stackrel{\mathrm{(ii)}}{\leq}\;\frac{1}{s}\log{\Big\{n e^{\frac{s^{2}\sigma^{2}}{2}}{\Big\}}}

&amp;&amp;=\frac{\log n}{s}+\frac{s\sigma^{2}}{2} \tag{2}


\end{align}\]</span>
$$</p>
<ul>
<li>(2): <span class="math inline">\(\forall i = 1, \cdots, n: \; E \Big( e^{s X_i}\Big) \le e^{\frac{s^2 \sigma^2}{2}}\)</span> condition 을 사용하면, 1번째는 <span class="math inline">\(s=\sqrt{\frac{2 \log n}{\sigma^2}}\)</span>, 2번째는 union bound 로 성립.</li>
</ul>
<p>위를 응용하면 이하로 이어짐. 이는 위의 thm에서 abs 씌우고 n 을 2n 으로 바꾼 형.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-6" class="exercise"><strong>(#exr:unlabeled-div-6) </strong></span><span class="math display">\[
\begin{align}
\mathbb{E} \Big[\max \limits_{i=1\ldots n}|X_{i}|{\Big\rbrack} 
&amp; \leq\sigma{\sqrt{2\log(2n)}}
\\
\forall t \ge0: \mathbb{P}{\Biggl(}\operatorname*{max}\limits_{i=1, \cdots, n}|X_{i}|\geq t{\Biggr)} 
&amp; \leq2n e^{-{\frac{t^{2}}{2\sigma^{2}}}}
\end{align}
\]</span></p>
</div>
<!--chapter:end:212302_ConIneq.Rmd-->
</div>
</div>
<div id="concentration-inequalities-1" class="section level2" number="8.3">
<h2 number="8.3"><span class="header-section-number">8.3</span> Concentration inequalities</h2>
<p>SG 는 꽤 빡빡한 strict 개념. mgf 여부에 기반한 sub-Exponential 은 좀 느슨함.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="sub-exponential-random-variables" class="section level3" number="8.3.1">
<h3 number="8.3.1"><span class="header-section-number">8.3.1</span> Sub-exponential random variables</h3>
<div class="definition">
<p><span id="def:unlabeled-div-7" class="definition"><strong>(#def:unlabeled-div-7) (sub-Exponential rv) </strong></span><span class="math inline">\(E(X) = \mu\)</span>, 패러미터 <span class="math inline">\(\exists (\nu, \alpha) \ge 0\)</span> 에 대해 이하가 성립하면 랜덤변수 <span class="math inline">\(X\)</span>는 <strong>sub-exponential</strong>.</p>
<p><span class="math display">\[
\forall |\lambda| &lt; \frac{1}{\alpha}: \mathbb{E}[e^{\lambda(X-\mu)}]\leq e^{\frac{\nu^{2}\lambda^{2}}{2}}
\]</span>
<strong>SG</strong> 또한 <span class="math inline">\(1/0 = +\infty\)</span> 로 해석할 경우 <span class="math inline">\(\nu = \sigma\)</span>, <span class="math inline">\(\alpha=0\)</span> 인 sub-exponential.</p>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="bernsteins-condition" class="section level3" number="8.3.2">
<h3 number="8.3.2"><span class="header-section-number">8.3.2</span> Bernstein’s condition</h3>
<p><span class="math inline">\(X\)</span>의 polynomial moment를 조작하는 것으로 <span class="math inline">\(X\)</span>의 sub-exponential 성질을 증명할 수 있다.</p>
<div class="definition">
<p><span id="def:unlabeled-div-8" class="definition"><strong>(#def:unlabeled-div-8) (Bernstein’s Condition) </strong></span>let <span class="math inline">\(E(X) = \mu\)</span>, <span class="math inline">\(Var(X) = \sigma^2 = E(X^2) - \mu^2\)</span> 인 랜덤변수 <span class="math inline">\(X\)</span>. 이하의 경우와 패러미터 <span class="math inline">\(b\)</span> 에 대해 Bernstein’s Condition 이 성립한다.</p>
<p>$$
<span class="math display">\[\begin{align}

&amp;\Bigg | E \Big [ (X-\mu)^k \Big ] \Bigg | \le \frac{1}{2} k! \sigma^2 b^{k-2}, &amp;&amp; k = 2, 3, 4, \cdots

\end{align}\]</span>
$$</p>
<p>이때, 모든 bounded 랜덤변수 (즉 <span class="math inline">\(|X-\mu| \le b\)</span>) 에 대해 Bernstein’s Condition 이 성립한다는 것을 파악해라.</p>
</div>
<p><br>
<br></p>
<p><span class="math inline">\(X\)</span>가 Bernstein’s condition 을 만족할 경우, X는 패러미터 <span class="math inline">\((\sqrt 2 \sigma, 2b)\)</span> 인 sub-exponential.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-9" class="theorem"><strong>(#thm:unlabeled-div-9) (Bernstein-type inequality) </strong></span>Bernstein’s Condition 을 만족하는 모든 랜덤변수에 대해 이하가 성립한다.</p>
<p><br>
<br></p>
<p>$$
<span class="math display">\[\begin{align}



&amp;\forall |\lambda|&lt; \tfrac{1}{b}: &amp;&amp;E \Big [ e^{\lambda(X-\mu)}\Big ] &amp;&amp;\le \exp \left( \frac{\frac{\lambda^2 \sigma^2}{2}}{1-b|\lambda|}\right)

\\

&amp;\forall t \ge 0:

&amp;&amp;P \Big( |X-\mu| \ge t \Big) &amp;&amp;\le 2 \exp \left( - \frac{t^2}{2(\sigma^2 + bt)}\right)

\end{align}\]</span></p>
<p>$$</p>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="mcdiarmids-inequality" class="section level3" number="8.3.3">
<h3 number="8.3.3"><span class="header-section-number">8.3.3</span> McDiarmid’s inequality</h3>
<div class="theorem">
<p><span id="thm:unlabeled-div-10" class="theorem"><strong>(#thm:unlabeled-div-10) (McDiarmid’s inequality) </strong></span>이하의 조건을 만족한다고 하자.</p>
<ol style="list-style-type: decimal">
<li>랜덤변수 <span class="math inline">\(X_1 , \cdots, X_n\)</span> 이 independent</li>
<li>함수 <span class="math inline">\(f: \mathbb R^n \mapsto \mathbb R\)</span>: <span class="math inline">\(\Big | f(x_1, \cdots, x_n) - f(x_1 , \cdots, x_{k-1} , x_k &#39; , x_{k+1} , \cdots, x_n) \Big | \le L_k\)</span> (bounded condition)</li>
</ol>
<p>위 둘이 성립하면 이하가 성립한다.</p>
<p><span class="math display">\[
\forall t \ge 0: P \left( \Big | f(X_1 , \cdots, X_n) - E \big[ f(X_1 , \cdots, X_n) \big]\Big | \ge t \right) \le 2 \exp \left( - \frac{2 t^2}{\sum_{k=1}^n L_k^2}\right)
\]</span></p>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="levys-inequality" class="section level3" number="8.3.4">
<h3 number="8.3.4"><span class="header-section-number">8.3.4</span> Levy’s inequality</h3>
<p>충분히 smooth 한 Gaussian 랜덤변수에 대해, 유사한 concentration inequality 가 존재한다. 이때는 다른 가정이 필요. <span class="math inline">\(X_1 , \cdots, X_n \overset{iid}{\sim} N(0,1)\)</span> 에 대해</p>
<p>$$
<span class="math display">\[\begin{align}

&amp;\forall x_{1},\cdot\cdot\cdot,x_{n},y_{1},\cdot\cdot\cdot,y_{n}\in\mathbb{R}
&amp;&amp;: 
&amp;&amp;\Bigg |f(x_{1},\ldots,x_{n})-f(y_{1},\ldots,y_{n}) \Bigg | 
&amp;&amp;\leq L{\sqrt{\sum_{i=1}^{n}(x_{i}-y_{i})^{2}}}

\\
\\

\Longrightarrow

&amp;\forall t \ge 0
&amp;&amp;:
&amp;&amp;\mathbb{P} \left( \Bigg| f(X_{1},\cdot\cdot\cdot,X_{n})-\mathbb{E} \Big [f(X_{1},\cdot\cdot\cdot,X_{n}) \Big] \Bigg |\geq t \right )
&amp;&amp;\leq2\exp\left(-{\frac{t^{2}}{2L^{2}}}\right)

\end{align}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="quadratic-form" class="section level3" number="8.3.5">
<h3 number="8.3.5"><span class="header-section-number">8.3.5</span> Quadratic form</h3>
<p><span class="math inline">\(Q\)</span> 가 symmetric Matrix 일 때 이하를 정의할 수 있다.</p>
<p>$$
<span class="math display">\[\begin{align}

\|Q\|_{\mathrm{{op}}}&amp;=\operatorname*{sup}_{\|u\|_{2}=1}\|Q u\|_{2} \tag{l2-operator norm}
\\
\|Q\|_{\mathrm{{F}}}&amp;={\sqrt{\sum_{i=1}^{n}\sum_{j=1}^{n}Q_{i j}^{2}}} \tag{Frobenius norm}

\end{align}\]</span>
$$</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-11" class="theorem"><strong>(#thm:unlabeled-div-11) (Hanson–Wright inequality) </strong></span>independent, zero-mean, <span class="math inline">\(X \in SG(\sigma^2)\)</span> 인 랜덤벡터 <span class="math inline">\(X = (X_1 , \cdots, X_n)&#39; \in \mathbb R^n\)</span> 를 정의하자. 그러면 <strong>Hanson–Wright inequality</strong> 에 의해 이하와 같이 quadratic form <span class="math inline">\(X&#39;QX\)</span> 의 tail bound 가 정의된다.</p>
<p><span class="math display">\[
\forall t \ge 0: \mathbb{P}\left( \Bigg|X^{\top}Q X-\mathbb{E}\Big [X^{\top}Q X \Big] \Bigg|\geq t\right)\leq2\exp\left(-\operatorname*{min}\left\{{\frac{c_{1}t^{2}}{\|Q\|_{\mathrm{F}}}},{\frac{c_{2}t}{\|Q\|_{\mathrm{op}}}}\right\}\right)
\]</span></p>
<p>이때 <span class="math inline">\(c_1 , c_2\)</span>는 SG 패러미터 <span class="math inline">\(\sigma\)</span> 에 의존하는 some constant. 증명 개어려움. decoupling 테크닉을 다수 쓰는데 궁금하면 Vershynin 책 찾아보던가.</p>
</div>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="the-johnsonlindenstrauss-lemma" class="section level3" number="8.3.6">
<h3 number="8.3.6"><span class="header-section-number">8.3.6</span> The Johnson–Lindenstrauss Lemma</h3>
<p>Example 3.5 에서 확인한 <span class="math inline">\(\chi^2\)</span> 의 tail bound 의 응용으로서 유명한 것 중 하나는 <strong>“random projection”</strong>. <span class="math inline">\(d\)</span> 가 충분히 큰 데이터셋 <span class="math inline">\(X_1 , \cdots, X_n \in \mathbb R^d\)</span> 을 가지고 있다고 치자. 이러한 데이터셋을 보관하는 것은 과한 비용을 요구하므로, 이를 해결하기 위해 우리는 이때 우리는 <span class="math inline">\(m \ll d\)</span> 인 map <span class="math inline">\(F: \mathbb R^d \mapsto \mathbb R^m\)</span> 을 만든 것이 목적인 <strong>“sketching”</strong>, 혹은 <strong>“random projection”</strong> 을 사용한다. 이를 적용한 이후에 우리는 앞서 말한 대용량 데이터셋을 저장하는 대신 <span class="math inline">\(\Big \{ F(X_1) , \cdots, F(X_n) \Big \}\)</span> 를 보관하게 된다. 여기서 관건은 오리지널 데이터셋의 본질을 해치지 않는 map <span class="math inline">\(F\)</span> 를 만들어내는 것이다. 특히, 우리는 모든 pair <span class="math inline">\((X_i , X_j)\)</span> 에 대해 이하가 성립하는 것을 목표로 하며, i.e., map 은 모든 pair-wise distance 를 <span class="math inline">\((1 \pm \epsilon)\)</span> factor 에 bound 되게 보존한다.</p>
<p><span class="math display">\[
(1-\epsilon)\Vert X_{i}-X_{j}\Vert_{2}^{2}\le\Vert F(X_{i})-F(X_{j})\Vert_{2}^{2}\le(1+\epsilon)\Vert X_{i}-X_{j}\Vert_{2}^{2}
\]</span></p>
<p>이때 <strong>Johnson-Lindenstrauss lemma</strong> 은 실로 놀라운 결과를 보여준다. <span class="math inline">\(m \ge \frac{16 \log \left(\frac{n}{\delta}\right)}{\epsilon^2}\)</span> 라는 조건이 주어져 있다면, simple randomized construction 만으로 그러한 map 을 with probability <span class="math inline">\(\max(c, 1-\delta)\)</span> 로 생산할 수 있다는 것이다.</p>
<p>이 결과는 원본 데이터셋의 dim <span class="math inline">\(d\)</span> 와는 완전히 독립이며</p>
<p>points 의 숫자 <span class="math inline">\(n\)</span> 에만 logarithmical 하게 의존한다는 것에 notice. 이 map 은 핵심적으로 모든 pairwise 거리를 보존하면서도 보관 비용을 획기적으로 줄일 수 있다.</p>
<p>map 그 자체의 방법론은 매우 간단하다. matrix <span class="math inline">\(\mathbf Z \in \mathbb R^{m \times d}\)</span>, <span class="math inline">\(Z_{jk} \overset{iid}{\sim} N(0,1)\)</span> 이 되도록 설계하고, map 이 <span class="math inline">\(F(X_i) = \frac{\mathbf Z X_i}{\sqrt m}\)</span> 되도록 정의한다.</p>
<p>이제 pair 중에 <span class="math inline">\((X_j , X_k)\)</span> 하나를 고르고 이하를 생각하자.</p>
<p><span class="math display">\[
\frac
{\Bigg\|F\left(X_{j}\right)-F\left(X_{k}\right)\Bigg\|^2_2}
{\Bigg\|X_{j}-X_{k}\Bigg \|^2_2
}
=
\left\|
\frac
{{\mathbf Z}(X_{j}-X_{k})}
{\sqrt{m}\Bigg\|X_{j}-X_{k} \Bigg\|_{2}}
\right\|^2_2
={\frac{1}{m}}\sum_{i=1}^{m}
\underbrace{\left \langle \mathbf Z_{i}, \; \; {\frac{X_{j}-X_{k}}{\Bigg\|X_{j}-X_{k}\Bigg\|_{2}}}\right\rangle^{2}}_{T_i}
\]</span></p>
<p>이때 <span class="math inline">\(\mathbf Z_i\)</span> 는 <span class="math inline">\(\mathbf Z\)</span> 의 i-th row. 이제, for some fixed numbers <span class="math inline">\(a_j\)</span> 에 대해, <span class="math inline">\(\sum\limits_{j=1}^d a_j Z_{ij} \sim N \left(0, \; \sum\limits_{j=1}^d a_j \right)\)</span>. 따라서 이에 의해 <span class="math inline">\(T_i \sim \chi^2\)</span> 이며 각각은 independent. 이제 <span class="math inline">\(\chi^2\)</span> 의 tail bound 를 적용하는 것으로 우리는 이하를 얻는다.</p>
<p><span class="math display">\[
\mathbb{P}\left(\left|{\frac{\bigg\|F(X_{j})-F(X_{k})\bigg\|_{2}^{2}}{\bigg\|X_{j}-X_{k}\bigg\|_{2}^{2}}}-1\right|\geq\epsilon\right)\leq2\exp \left (\frac{-m\epsilon^{2}}{8} \right)
\]</span></p>
<p>따라서 fixed pair <span class="math inline">\((X_i , X_j)\)</span> 에 대해, 우리의 map 이 distance 를 보존 (preserve) 하는데에 실패할 확률은 exponentially small, i.e., 최대로 해봐야 <span class="math inline">\(2 \exp \left (\frac{-m\epsilon^{2}}{8} \right)\)</span>. 이제 우리의 map 이 <span class="math inline">\(n \choose 2\)</span> 중 <strong>무엇 하나라도</strong> 보전에 실패할 확률은 단순히 union bound 적용해보면 해결됨. 이 계산을 통하면 <span class="math inline">\(P(\text{Failure}) \le 2 {n \choose 2} \exp \left (\frac{-m\epsilon^{2}}{8} \right)\)</span>.</p>
<p>따라서 <span class="math inline">\(m \ge \frac{16 \log \left(\frac{n}{\delta}\right)}{\epsilon^2}\)</span> 일때 위에서 이야기했던 확률이 최대로 해봐야 <span class="math inline">\(\delta\)</span> 임을 증명하는 건 쉽다. 여기서 note 해야 할 것은 <span class="math inline">\(m\)</span> 을 그러한 작은 값으로 이끄는 <strong>exponential concentration</strong> 이라는 개념이다. (i.e., 이는 그냥 sample size 에 맞춰서 logarithmically 하게 grow 하기만 하면 된다)</p>
<!--chapter:end:212303_ConIneq.Rmd-->
</div>
</div>
<div id="metric-entropy-and-its-uses" class="section level2" number="8.4">
<h2 number="8.4"><span class="header-section-number">8.4</span> Metric entropy and its uses</h2>
<p>set <span class="math inline">\(\mathcal I\)</span> 에 의해 index 된 랜덤변수의 collection <span class="math inline">\(\{X_i \}_{i \in \mathcal I}\)</span> 를 생각해보자. 이 경우, 우리는 보통 <span class="math inline">\(\max\limits_{i \in \mathcal I}X_i\)</span> 혹은 <span class="math inline">\(E \Big \{ \max\limits_{i \in \mathcal I}X_i \Big \}\)</span> 를 제어하는 것이 목적이 된다.</p>
<p>예를 들어 <span class="math inline">\(||X||_{2}=\operatorname*{max}\limits_{\alpha\in\mathbb{R}^{d}:\|\alpha\|_{2}=1}\alpha^{\top}X\)</span> 로 표기될 수 있는 랜덤벡터 <span class="math inline">\(X \in \mathbb R^d\)</span> 의 <span class="math inline">\(L_2\)</span> norm 을 제어하는데에 관심이 있다고 예를 들어보자. set <span class="math inline">\(\mathcal I\)</span> 의 크기가 무한하다면, uniform bound 를 구성하는 건 꽤나 빡센 일임. (e.g., Chapter 2 에서 논했던 maximal ineq. 등이 사용 불가.)</p>
<p>이를 해결하기 위해 <span class="math inline">\(\mathcal I\)</span> 의 finite subset <span class="math inline">\(\mathcal I_{sub}\)</span> 를 구하여 <span class="math inline">\(\mathcal I\)</span> 를 분절 (discrete) 하고 <span class="math inline">\(\max\limits_{i \in \mathcal I}X_i\)</span> 를 <span class="math inline">\(\max\limits_{i \in \mathcal I_{sub}}X_i\)</span> 로 모사 (approximate).</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="metric-space" class="section level3" number="8.4.1">
<h3 number="8.4.1"><span class="header-section-number">8.4.1</span> Metric space</h3>
<div class="definition">
<p><span id="def:unlabeled-div-12" class="definition"><strong>(#def:unlabeled-div-12) (Metric Space) </strong></span>이하가 성립할 때, ordered pair <span class="math inline">\((\mathcal X, \; d)\)</span> 는 <strong>metric space</strong>.</p>
<ul>
<li>set <span class="math inline">\(\mathcal X \not = \varnothing\)</span></li>
<li><span class="math inline">\(d\)</span> 는 <span class="math inline">\(d: \mathcal X \times \mathcal X \rightarrow \mathbb R\)</span> 을 따르는 <span class="math inline">\(\mathcal X\)</span> 에 대한 metric</li>
<li><span class="math inline">\(x, y, z \in \mathcal X\)</span> 에 대해 이하가 성립:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}
d(x,y) &amp;\ge 0 &amp;&amp;\text{ and } d(x,y) = 0 \iff x=y \tag{non-negative}

\\
d(x,y) &amp;= d(y,x) \tag{symmetric}

\\

d(x,z) &amp;\le d(x,y) + d(y,z) \tag{triangel ineq. holds}

\end{align}\]</span>
$$</p>
</div>
<p>:::</p>
<p>※ Remark:
The <span class="math inline">\(p\)</span>-norms (often denoteed by <span class="math inline">\(l_p\)</span>-norm) are nested: for <span class="math inline">\(1 \le p_1 &lt; p_2\)</span>, we have <span class="math inline">\(||x||_{p_2} \le ||x||_{p_1}\)</span>.</p>
<p><br>
<br>
<br></p>
<p>마지막으로 <mark><span class="math inline">\(L_p\)</span> function space</mark> 를 살펴보자.</p>
<p><span class="math inline">\(\mathcal X = \{ f: [0,1] \rightarrow \mathbb R \}\)</span> 을 함수의 set 이라고 하자.</p>
<p><span class="math inline">\([0,1]\)</span> 에 대한 <span class="math inline">\(L_p\)</span> function space 는 <span class="math inline">\(\mathcal X\)</span> 의 함수들 중에서도 절대값의 <span class="math inline">\(p\)</span>-th power 가 <span class="math inline">\(\mu\)</span>-integrable 한 함수들을 엄선하여 담고 있다.</p>
<p>즉</p>
<p><span class="math display">\[
||f||_p = \left( \int_0^1 |f|^p d \mu \right)^{\frac{1}{p}} &lt; \infty
\]</span></p>
<p>이때 <span class="math inline">\(\mu\)</span> 는 <span class="math inline">\([0,1]\)</span> 에서의 측도 (measure) 이며 <span class="math inline">\(p \ge 1\)</span>. (일반적으로 르베그 측도 사용 typically the Lebesgue measure) 보통 <span class="math inline">\(p=2\)</span> 를 <span class="math inline">\(p\)</span> 로 사용. 이 경우에 이론이 좀더 풍성하고 탄탄해짐.</p>
<p>$$
<span class="math display">\[\begin{align}
|| f-g||_p &amp;= \left( \int_0^1 \Bigg | f(x) - g(x) \Bigg |^p d \mu \right)^{\frac{1}{p}}

\tag{L_p distance b/w f and g}

\\

|| f-g||_\infty &amp;= \sup_{x \in [0,1]} \Bigg | f(x) - g(x) \Bigg |

\tag{when p = infty}

\end{align}\]</span>
$$</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="covering-numbers-and-metric-entropy" class="section level3" number="8.4.2">
<h3 number="8.4.2"><span class="header-section-number">8.4.2</span> Covering numbers and metric entropy</h3>
<p>metric space <span class="math inline">\(\mathcal X\)</span> 가 있을 때 해당 space 의 크기가 궁금함. metric space 의 크기를 구하는 방법은 보통 space 를 덮는데 필요한 radius <span class="math inline">\(\delta\)</span> 인 구의 크기로 보통 구함. 이게 covering.</p>
<p>:::{.definition “Covering number”}</p>
<p>set <span class="math inline">\(\mathcal X\)</span> 의 metric <span class="math inline">\(d\)</span> 에 비춘 <span class="math inline">\(\delta\)</span>-cover는 이하와 같다.</p>
<p><span class="math inline">\(set \{\theta_1, \cdots, \theta_N\} \in \mathcal X\)</span> s.t. <span class="math inline">\(\forall \theta \in \mathcal X, \exists i \in \{1 , \cdots, N \} : d(\theta, \theta_i) \le \delta\)</span>.</p>
<p>이때 <span class="math inline">\(\delta\)</span>-covering number <span class="math inline">\(N(\delta; \mathcal X , d)\)</span> 는 가장 작은 <span class="math inline">\(delta\)</span>-cover 의 cardinality.</p>
<p>:::</p>
<div class="definition">
<p><span id="def:unlabeled-div-13" class="definition"><strong>(#def:unlabeled-div-13) (Metric Entropy) </strong></span><span class="math inline">\((\mathcal X, d)\)</span> 의 <strong>metric entropy</strong> 는 <span class="math inline">\(\log N(\delta; \; \mathcal X, d)\)</span>.</p>
</div>
<p>보통 <span class="math inline">\(l_2\)</span>-norm <span class="math inline">\(||\cdot||_2\)</span> 을 가지는 p-차원 real space <span class="math inline">\(\mathbb R^p\)</span> 의 bounded subset 에 대해, metric entorpy 는 <span class="math inline">\(C \cdot p\log\left(\frac{1}{\delta} \right)\)</span> 로 scale 됨.</p>
<p>보통 <span class="math inline">\(\mathbb R^p\)</span> 의 bounded subset 은 <strong>“small”</strong> space 로 간주됨. (metric entropy 가 <span class="math inline">\(p\)</span> 에 대해 linearly 선형적으로 scale)</p>
<p>non-Euclindean space 에 대해 (e.g., function space), metric entropy 는 다른 식으로 salce 됨. 이들은 보통 <strong>“large”</strong> space 로 간주됨.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="packing-numbers" class="section level3" number="8.4.3">
<h3 number="8.4.3"><span class="header-section-number">8.4.3</span> Packing numbers</h3>
<p>:::{.def “Packing number”}</p>
<p>set <span class="math inline">\(\mathcal X\)</span> 의 metric <span class="math inline">\(d\)</span> 에 비춘 <span class="math inline">\(\delta\)</span>-packing은 이하와 같다.</p>
<p><span class="math inline">\(set \{\theta_1, \cdots, \theta_M\} \in \mathcal X\)</span> s.t. <span class="math inline">\(\forall i \not = j \in \{1, 2, \cdots, M\}: d(\theta_i, \theta_j) \ge \delta\)</span></p>
<p>이때 <span class="math inline">\(\delta\)</span>-packing number $M(; X , d) 는 가장 큰 <span class="math inline">\(delta\)</span>-packing 의 cardinality.</p>
<p>:::</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section-1" class="section level3" number="8.4.4">
<h3 number="8.4.4"><span class="header-section-number">8.4.4</span> </h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section-2" class="section level3" number="8.4.5">
<h3 number="8.4.5"><span class="header-section-number">8.4.5</span> </h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section-3" class="section level3" number="8.4.6">
<h3 number="8.4.6"><span class="header-section-number">8.4.6</span> </h3>
<!--chapter:end:212304_MetricSpace.Rmd-->
</div>
</div>
<div id="covariance-estimation" class="section level2" number="8.5">
<h2 number="8.5"><span class="header-section-number">8.5</span> Covariance estimation</h2>
<p><br>
<br>
<br></p>
<div id="matrix-algebra-review" class="section level3" number="8.5.1">
<h3 number="8.5.1"><span class="header-section-number">8.5.1</span> Matrix algebra review</h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="covariance-matrix-estimation-in-the-operator-norm" class="section level3" number="8.5.2">
<h3 number="8.5.2"><span class="header-section-number">8.5.2</span> Covariance matrix estimation in the operator norm</h3>
<div class="theorem">
<p><span id="thm:unlabeled-div-14" class="theorem"><strong>(#thm:unlabeled-div-14) (Covariance estimation) </strong></span><span class="math inline">\(X_1 , \cdots, X_n \overset {iid}\sim SG(\sigma)\)</span> s.t. <span class="math inline">\(E(X_1) = 0, Var(X_1) = \Sigma_{d \times d}\)</span>.</p>
<p>Let sample Cov matrix <span class="math inline">\(\hat \Sigma = \frac{1}{n} \sum X_i X_i &#39;\)</span> based on <span class="math inline">\(X_1 , \cdots, X_n\)</span>.</p>
<p>Then there exists a universal constant <span class="math inline">\(C &gt;0\)</span> s.t. below holds with probabilty at least <span class="math inline">\(1-\sigma\)</span>.</p>
<p><span class="math display">\[
\forall \sigma \in (0,1): \frac{\|\hat \Sigma - \Sigma \|_{op}}{\sigma^2} \le C \max \left \{ \sqrt{\frac{d + \log(\frac{2}{\sigma})}{n}}, \; {\frac{d + \log(\frac{2}{\sigma})}{n}}\right \}
\]</span></p>
</div>
<p><br></p>
<ul>
<li>이건 결국 <span class="math inline">\(\lim_{n \rightarrow \infty \frac{d}{n} \rightarrow 0}\)</span> 일 때 operator norm 안의 <span class="math inline">\(\Sigma\)</span>를 계속해서 estimate 할 수 있다는 것을 말함. 실제로 추가적인 가정 없이는 이 rate 이상으로 측정을 정밀화할 수 없음.</li>
</ul>
<p><br>
<br></p>
<p>증명을 2단계로 분할.</p>
<ol style="list-style-type: decimal">
<li>discretization argument 를 써서 문제를 finitely 많은 랜덤변수의 maximum 을 제어하는 문제로 변경. 이하의 정보와 함께 finite maximum 라는 사실 사용해서 <span class="math inline">\(\|\hat \Sigma - \Sigma \|_{op}\)</span> 에 대한 상한 생산.</li>
</ol>
<p>let <span class="math inline">\(A = A&#39; \in \mathbb R^{d \times d}\)</span> 로 하고, <span class="math inline">\(N_\epsilon = \{ y_1 , \cdots, y_N \}\)</span> 을 <span class="math inline">\(\mathbb S^{d-1}\)</span> 의 <span class="math inline">\(\epsilon\)</span>-covering 으로 함.</p>
<p>이때 <span class="math inline">\(\| A \|_{op} \le \frac{1}{1-2\epsilon} \cdot \max_{y \in N_\epsilon} | y&#39; A y |\)</span>.</p>
<p>이를 증명하자. <span class="math inline">\(x \in \mathbb S^{d-1}\)</span> 에 대해 <span class="math inline">\(\| x-y \|_2 \le \epsilon\)</span> 만족하는 <span class="math inline">\(y \in N_\epsilon\)</span> 선택. 이때 <span class="math inline">\(A\)</span>는 symmetric Matrix 이므로,</p>
<p>여기서 <span class="math inline">\(\hat \Sigma - \Sigma\)</span> 는 symmetric Matrix 이므로, <span class="math inline">\(\|\hat \Sigma - \Sigma \|_{op} \le \frac{1}{1-2\epsilon} \max_{y \in N_\epsilon} | y&#39; (\hat \Sigma - \Sigma) y |\)</span>.</p>
<p><span class="math display">\[
\vert x^{\textsf{T}}A x-y^{\textsf{T}}A y\vert\ =\ \vert x^{\textsf{T}}A(x-y)-y^{\textsf{T}}A(y-x)\vert
\leq\;\left|x^{\textsf{T}}A(x-y)\right|+\left|y^{\textsf{T}}A(y-x)\right| \tag{triangle ineq.}
\]</span></p>
<p><span class="math display">\[
|x^{\textsf{T}}A(x-y)|\ \stackrel{(1)}{\le}\ ||A(x-y)||_{2}||x||_{2} \tag{Cauchy–Schwarz inequality}
\\
\overset{(2)}{\le} {{||A||_{\mathrm{op}}||x-y||_{2}}}
\\
\overset{(3)}{\le} \epsilon\|A\|_{\mathrm{op}}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(|| x||_2 = 1\)</span>, and <span class="math inline">\(\forall v \in \mathbb R^d:||A v ||_2 \le ||A||_{op} ||v||_2\)</span></li>
<li><span class="math inline">\(||x-y||_2 \le \epsilon\)</span></li>
</ol>
<p>Applying the same argument to <span class="math inline">\(|y^T A(y-x)|\)</span> then gives <span class="math inline">\(|x^T Ax - y^T Ay| \le 2 \epsilon ||A||_{op}\)</span>.</p>
<p>To complete the proof of inequality (5.1), note that</p>
<p><span class="math display">\[
|x^{\textsf{T}}A x|=|x^{\textsf{T}}A x-y^{\textsf{T}}A y+y^{\textsf{T}}A y| \leq\ \left|x^{\top}A x-y^{\top}A y\right|+\left|y^{\top}A y\right|
\leq 2\epsilon || A||_{\mathrm{op}}+|y^{T}A y \rvert
\]</span></p>
<p>This implies that <span class="math inline">\(||A||_{op} \le 2 \epsilon ||A||_{op} + \max_{y \in N_\epsilon} |y^T A y|\)</span> and rearranging the terms yields inequality (5.1).</p>
<p><br>
<br></p>
<ol start="2" style="list-style-type: decimal">
<li>standard concentration inequality 사용.</li>
</ol>
<p>Step 2. By choosing  = 1/4, inequality (5.2) becomes</p>
<p><span class="math display">\[
||\hat{\Sigma} - \Sigma||_\mathrm{op} \leq 
2 \max_{y\in{N_{1/4}}}
|\mathcal{y}^{\top} \big(\hat{\Sigma} - \Sigma\big)\mathcal{y}|
\]</span></p>
<p>Therefore by the union bound</p>
<p><span class="math display">\[
P(||\hat{\Sigma} - \Sigma||_\mathrm{op} \ge t) \leq 
P \left ( 2 \max_{y\in{N_{1/4}}}
|\mathcal{y}^{\top} \big(\hat{\Sigma} - \Sigma\big)\mathcal{y}|
\ge t \right )
 \leq 
\sum_{y\in{ N_{1/4}}} P \left( |\mathcal{y}^{\top} \big(\hat{\Sigma} - \Sigma\big)\mathcal{y}| \ge \frac{t}{2} \right)
\]</span>
Note that we can write</p>
<p><span class="math inline">\(y^{\top}(\hat{\Sigma}-\Sigma)y=\frac{1}{n}\sum_{i=1}^{n}\left\{(y^{\top}X_{i})^{2}-\mathbb{E}[(y^{\top}X_{i})^{2}]\right\}\)</span></p>
<p>We saw earlier in Lemma 3.3 that the square of a sub-Gaussian random variable is sub-exponential with parameters <span class="math inline">\((\nu, \alpha) = (16 \sigma^2, 16 \sigma^2)\)</span>. This property implies that <span class="math inline">\(\left\{(y^{\top}X_{i})^{2}-\mathbb{E}[(y^{\top}X_{i})^{2}]\right\}\)</span> is sub-exponential with <span class="math inline">\((16\sigma^2 , 16\sigma^2)\)</span>. Applying the sub-exponential tail bound, especially inequality (3.2), yields</p>
<p><span class="math display">\[
\mathbb{P}(\|\widehat\Sigma-\Sigma\|_{\mathrm{lop}}\geq t)\ \leq\ 2\ \underbrace{\mathrm{l}N_{1/4}}_{\mathrm{extrianitv}}
\times 
\exp\Biggl(-{\frac{1}{2}}\operatorname{min}\Biggl\{{\frac{n t}{16\sigma^{2}}},\ {\frac{n t^{2}}{16^{2}\sigma^{4}}}\Biggr\}\Biggr)
\\
\leq\ 2\times9^{d}\times\exp\biggl(-\frac{1}{2}\operatorname*{min}\Biggl\{\frac{n t}{16\sigma^{2}},\ \frac{n t^{2}}{16^{2}\sigma^{4}}\Biggr\}\biggr)
\]</span></p>
<p>where the last step uses the result in Lecture 4, which shows that the cardinality of <span class="math inline">\(N_{1/4}\)</span> is
bounded by <span class="math inline">\(|N_{1/4}| ≤ 9\)</span>. (here note that <span class="math inline">\(\mathbb{S}^{d-1}\subset\mathbb{B}=\{\theta\in\mathbb{R}^{d}:||\theta||_{2}\leq1\}\})\)</span>). Finally, inverting the bound gives the desired result.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="bounds-for-structured-covariance-matrices" class="section level3" number="8.5.3">
<h3 number="8.5.3"><span class="header-section-number">8.5.3</span> Bounds for structured covariance matrices</h3>
<p>우리의 주된 목적은 샘플 Cov를 경유하여 unstructured Cov Matrix를 estimate 하는 것. Cov Matrix 가 추가적인 structure 를 품고 있다면, 샘플 Cov 가 아니라 다른 estimator 를 사용해서 좀더 연산이 빠른 estimate 가 가능.</p>
<p><br></p>
<ul>
<li><strong>Diagonal matrix</strong></li>
</ul>
<p><strong>Cov Matrix 가 diagonal이라는 정보</strong>를 가지고 있다고 해보자. 이때 <span class="math inline">\(\hat \Sigma_{diag} = diag \{ \hat \Sigma_{11}, \cdots, \hat \Sigma_{dd}\)</span> 로 estimate 하는 것은 자연스럽다. 이 경우 sub-Gaussinianity 를 가정한다면 어떻게 될까? unstructured 케이스에서 order 가 <span class="math inline">\(\sqrt{\frac{d}{n}}\)</span> rates (단, <span class="math inline">\(d \le n\)</span>) 였던 것과 대비되게 estimation error of the order $ 가 생산된다.</p>
<p>좀 더 자세히 살펴보자. diagonal 케이스에서, <span class="math inline">\(\hat \Sigma_{diag} - \Sigma\)</span> 의 operator norm 은 본질적으로 <span class="math inline">\(d\)</span> 개의 entry값 <span class="math inline">\(\{| \hat \Sigma_{diag,11} - \Sigma_{11} |, \cdots, | \hat \Sigma_{diag,dd} - \Sigma_{dd} |\}\)</span> 중의 maximum 이다. 그렇다면 여기서 the union bound argument along with an exponential tail bound 를 통해 우리는 <span class="math inline">\(\sqrt{\frac{\log d}{n}} → 0\)</span> 일 때 operator norm 이 0로 decay 된다는 것을 파악할 수 있다. <mark> See Theorem 2.11 for a similar argument.</mark></p>
<p><br></p>
<ul>
<li><strong>Unknown sparsity and thresholding</strong></li>
</ul>
<p>좀더 일반적인 케이스를 생각해보자. Cov Matrix가 상대적으로 sparse 하다는 사실이 알려져 있지만, 어느 entry가 non-zero인지는 알려져있지 않다. 이때 estimator가 thresholding 에 기반하고 있다고 생가가흔 넉승 나젼스럽다. 이때 <span class="math inline">\(\lambda &gt;0\)</span> 라는 패러미터가 주어져 있다고 생각할 때, hard-thresholding 을 통해 얻어지는 Cov estimator 의 <span class="math inline">\((i,j)\)</span> entry 는 <span class="math inline">\([T_\lambda (\hat \Sigma)]_{ij} = \hat \Sigma_{ij} \cdot I(|\hat \Sigma_{ij}&gt;\lambda)\)</span>.</p>
<p>let <span class="math inline">\(\Sigma\)</span>의 adjacency matrix <span class="math inline">\(A \in \mathbb R^{d \times d}\)</span>, <span class="math inline">\(A_{ij} = I(\Sigma_{ij}) \not = 0\)</span>. adjacency matrix 의 operator norm <span class="math inline">\(\| A \|_{op}\)</span> 는 sparsity 에 대한 natural measure 를 제공한다. 이때 우리는 <span class="math inline">\(\Sigma\)</span> 가 row 별로 <span class="math inline">\(s\)</span> 개의 non-zero entry를 갖고 있다면 <span class="math inline">\(\| A \|_{op} \le s\)</span> 임을 보일 수 있다. 또한 thresholded 샘플 Cov Matrix 는 다음과 같은 concentration bound를 가짐.</p>
<p><br>
<br></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-15" class="theorem"><strong>(#thm:unlabeled-div-15) (Thresholding-based covariance estimation) </strong></span><span class="math inline">\(X_1 , \cdots, X_n \overset {iid} \sim\)</span>, s.t. <span class="math inline">\(E(X_1) = 0, Var(X_1) = \Sigma_{d \times d}\)</span>, and suppose each component <span class="math inline">\(X_{ij}\)</span> is sub-Gaussinian with 패러미터 at most <span class="math inline">\(\sigma\)</span>.</p>
<p>만약 <span class="math inline">\(n &gt; 16 \log d\)</span> 라면, <span class="math inline">\(\forall \delta&gt;0\)</span>에 대해, thresholded 샘플 Cov Matrix <span class="math inline">\(T_{\lambda_n} (\hat \Sigma)\)</span> with <span class="math inline">\(\frac{\lambda_n}{\sigma^2} = 8 \sqrt{\frac{\log d}{n}} + \delta\)</span> 는 이하를 만족한다.</p>
<p><span class="math display">\[
P \Big (
\| T_{\lambda_n} ( \hat \Sigma ) - \Sigma \|_{op} \ge 2 \| A \|_{op} \cdot \lambda_n
 \Big)
\le 8 \exp \Big( -\frac{n}{16} (\delta \wedge \delta^2)\Big)
\]</span></p>
</div>
<p><br></p>
<ul>
<li><p>위의 부등식은 높은 확률로 <span class="math inline">\(\| T_{\lambda_n} ( \hat \Sigma ) - \Sigma \|_{op} \lesssim \| A \|_{op} \sqrt{\log d}{n}\)</span> 임을 보여줌. 이에 더해서 <span class="math inline">\(\sigma\)</span> 가 row 당 최대 <span class="math inline">\(s\)</span> 개의 non-zero entry 를 가진다는 조건을 생각하자. 이는 곧 <span class="math inline">\(\|A\|_2 \le s\)</span> 라는 의미가 됨. 그렇다면 thresholded Cov Matrix는 <span class="math inline">\(s\sqrt{\frac{\log d}{n}}→0\)</span> 일 때 consistent 하며, 이는 곧 특히 <span class="math inline">\(s\)</span> 가 작을 때 <span class="math inline">\(\sqrt{\frac{d}{n}}\)</span> 보다 훨씬 빠르다.</p></li>
<li><p>thresholding 패러미터는 sub-Gaussian 패러미터 <span class="math inline">\(\sigma\)</span>에 의존하는데, 이는 실전 상황에서는 대부분 unknown.</p></li>
</ul>
<p><br>
<br></p>
<p><strong>Proof</strong>: Let us denote the elementwise infinity norm of the error matrix <span class="math inline">\(\hat \Delta = \hat \Sigma - \Sigma\)</span> by <span class="math inline">\(|| \hat \Delta ||_\infty = \max_{1\le j , \; \; j \le d} |\hat \Delta_{ij}|\)</span>. The proof of the theorem is based on two intermediate results:</p>
<p><br />
</p>
<ol style="list-style-type: decimal">
<li>Under the assumptions of the theorem,</li>
</ol>
<p><span class="math inline">\(\mathbb{P}(||\widehat{\Delta}||_{\infty}/\sigma^{2}\geq t)\leq8e^{-{\frac{n}{16}}\operatorname*{min}\{t,t^{2}\}+2\log d}\quad\mathrm{for~all~}t\gt 0 \tag{5.3}\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>For any choice of <span class="math inline">\(\lambda_n\)</span> such that <span class="math inline">\(|| \hat \Delta ||_\infty \le \lambda_n\)</span> we are guaranteed that</li>
</ol>
<p><span class="math inline">\(||\widehat{\Sigma}-\Sigma||_{\mathrm{lop}}\leq\ 2||A||_{\mathrm{op}}\lambda_{n} \tag{5.4}\)</span></p>
<p><br />
</p>
<p>Having these results in place, the theorem follows by taking <span class="math inline">\(t = \frac{\lambda_n}{\sigma^2} = 8 \sqrt{\frac{\log d}{n}} + \delta\)</span>in inequality (5.3) and see</p>
<p><span class="math inline">\(8e^{-\frac{n}{16}\operatorname*{min}\{t,t^{2}\}+2\log d}\lt 8e^{-\frac{n}{16}\operatorname*{min}\{\delta,\delta^{2}\}},\)</span></p>
<p>, when <span class="math inline">\(n &gt; 16 log d\)</span>. Thus</p>
<p>It remains to prove inequality (5.3) and inequality (5.4), which are left as exercises (see Section 6.5 of Martin’s book)</p>
<p><span class="math display">\[
|\mathbb{P} \Bigg (||T_{\lambda_{n}}(\hat{\Sigma})\to\Sigma||_{\mathrm{op}}\geq\ 2||{A}||_{\mathrm{op}}\lambda_{n} \Bigg)
 \le P (||\widehat\Delta||_{\infty}\ge\,\lambda_{n})\le8e^{-\frac n{16}\it\ m i n}\{\delta,\delta^{2}\}_{.}
\]</span></p>
<p>It remains to prove inequality (5.3) and inequality (5.4), which are left as exercises (see Section 6.5 of Martin’s book)</p>
<!--chapter:end:212305_CovEst.Rmd-->
</div>
</div>
<div id="matrix-concentration-inequalities" class="section level2" number="8.6">
<h2 number="8.6"><span class="header-section-number">8.6</span> Matrix concentration inequalities</h2>
<p>이전 강의에서는 샘플 Cov Matrix의 tail bound를 discretization argument 를 통해 탐색했음. 여기선 Matrix Chernoff 테크닉을 통해 탐색한 후 랜덤 매트릭스에 Hoeffding bound 와 Bernstein bound 를 제시할거임.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="matrix-calculus" class="section level3" number="8.6.1">
<h3 number="8.6.1"><span class="header-section-number">8.6.1</span> Matrix calculus</h3>
<p>symmetric Matrix 의 set <span class="math inline">\(\mathcal S^{d \times d} = \{ X \in \mathbb R^{d \times d} : X = X&#39; \}\)</span> 와 ev 가 non-negative 인 PSD Matrix의 subset <span class="math inline">\(\mathcal S^{d \times d}_+\)</span> 를 사용할 것.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="matrix-chernoff" class="section level3" number="8.6.2">
<h3 number="8.6.2"><span class="header-section-number">8.6.2</span> Matrix Chernoff</h3>
<p>independent symmetric 랜덤 매트릭스의 collection <span class="math inline">\(X_1 , \cdots, X_n \in \mathcal S^{d \times d}\)</span> 가 주어졌고 <span class="math inline">\(E(X_1) = 0\)</span>. 이때 <span class="math inline">\(\bar X\)</span>의 maximum ev를 $P(_{max} (X) T) 와 같이 bound하고 싶다. Chernoff argument 를 쓰는 것이 일반적. 적용하면:</p>
<p>$$
<span class="math display">\[\begin{align}

\forall s &gt;0 :

P[\lambda_{max}(\bar X) \ge t]


&amp;=
P[\exp \Big[ \lambda_{max}(s \bar X) \Big] \ge \exp(st)]
\\

&amp;=
P[ \lambda_{max}(\exp \Big[s \bar X \Big]) \ge \exp(st)]
\\



&amp;le
\exp(-st) \cdot E \Big [ \lambda_{max}(\exp \Big[s \bar X \Big]) \Big ]
\\


&amp;le
\exp(-st) \cdot E \Big [ \tr (\exp \Big[s \bar X \Big]) \Big ]


\end{align}\]</span>
$$</p>
<ul>
<li>2번째 등식에선 exponential 함수의 spectral mapping property 과 monotonicity 사용
function</li>
<li>standard Markov 부등식</li>
<li><span class="math inline">\(\exp(s \bar X)\)</span> 가 PSD Matrix 라는 사실 활용</li>
<li>trace 가 linear operator이며, it can commute with expectation</li>
</ul>
<p>위의 전개에서 모든 <span class="math inline">\(s&gt;0\)</span> 에 inf를 적용하면 Chernoff argument 완성. 이제 <span class="math inline">\(tr(E[exp(sX)])\)</span> 를 bound 해야 함. 일반적인 스칼라 케이스에서 평균의 exponential 은 그냥 prod 로 쓰일 수 있음. 이를 연장하여 우리는 개별 랜덤변수들의 mgf 생산까지도 끌고갈 수 있음. 하지만 매트릭스 exponential 에서 <span class="math inline">\(e^{X+Y} = e^X e^Y\)</span> 려면 <span class="math inline">\(XY=YX\)</span> 여야 함. 따라서 우리는 <span class="math inline">\(X_1 , \cdots, X_n\)</span>의 임의의 실현값에 직접적으로 factorization 적용하는 건 불가능함. 이때 <strong>Lieb’s inequality</strong> 적용하면 이 난점 돌파 가능.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="sub-gaussian-and-sub-exponential-matrices" class="section level3" number="8.6.3">
<h3 number="8.6.3"><span class="header-section-number">8.6.3</span> Sub-Gaussian and sub-exponential matrices</h3>
<p>실값 랜덤변수의 케이스와 같이, 우리는 랜덤 매트릭스의 class 를 이들의 mgf 사용해서 특성을 드러내는 것이 가능.</p>
<p>:::{..def “Sub-Gaussian random matrices”}</p>
<p>symmetric Matrix <span class="math inline">\(X \in \mathcal S^{d \times d}\)</span>, 이때 <span class="math inline">\(E(X) = 0\)</span>, 는 이하를 만족할 경우 matrix 패러미터 <span class="math inline">\(V \in \mathcal S^{d \times d}_+\)</span> 를 가지는 sub-Gaussian.</p>
<p><span class="math display">\[
\forall t \in \mathbb R: E \Big [\exp(tX) \Big ] \le \exp \left( \frac{t^2 V}{2} \right)
\]</span>
:::</p>
<ul>
<li>※Remark: 패러미터 <span class="math inline">\(V\)</span> 를 가지는 Sub-Gaussian 랜덤 매트릭스는 패러미터 <span class="math inline">\((V , 0)\)</span>을 가지는 sub-exponential이기도 하다.</li>
</ul>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="랜덤-매트릭스에-대한-hoeffding-and-bernstein-bounds" class="section level3" number="8.6.4">
<h3 number="8.6.4"><span class="header-section-number">8.6.4</span> 랜덤 매트릭스에 대한 Hoeffding and Bernstein bounds</h3>
<p><br>
<br>
<br></p>
<div id="hoeffding-bound" class="section level4" number="8.6.4.1">
<h4 number="8.6.4.1"><span class="header-section-number">8.6.4.1</span> Hoeffding bound</h4>
<p>:::{..def “Hoeffding bound for random matrices”}</p>
<p>Let independent 한 zero-mean symmetric 랜덤 매트릭스의 sequence <span class="math inline">\(\{ X_i \}^n_{i=1}\)</span>, 이에 더해 이 랜덤 매트릭스들은 패러미터 <span class="math inline">\(\{ V_i \}^n_{i=1} \in S_+^{d \times d}\)</span> 를 가지는 sub-Gaussian 조건을 만족한다. 이때 우리는 이하와 같은 upper tail bound 를 얻는다.</p>
<p>$$
<span class="math display">\[\begin{align}
&amp;P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le d \exp \left( - \frac{nt^2}{2\sigma^2}\right), &amp;&amp;\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n V_i \|_{op}
\end{align}\]</span>
$$</p>
<p>:::</p>
<p><br>
<br>
<br></p>
</div>
<div id="bernstein-bound" class="section level4" number="8.6.4.2">
<h4 number="8.6.4.2"><span class="header-section-number">8.6.4.2</span> Bernstein bound</h4>
<p>:::{..def “Variance of random matrices”}</p>
<p>랜덤 매트릭스 <span class="math inline">\(X \in S^{d \times d}\)</span>에 대해, 이의 Var을 아래와 같이 정의한다. 이때 Var(X)는 자연스럽게 PSD.</p>
<p><span class="math display">\[
Var(X) = E(X^2 ) - \left[ E(X) \right]^2
\]</span></p>
<p>:::</p>
<p>:::{..def “Bernstein bound for random matrices”}</p>
<p>bounded operator norm 을 가지는, zero-mean independent symmetric 랜덤 매트릭스의 sequence 를 <span class="math inline">\(\{ X_i \}^n_{i=1}\)</span> 로 하자. 이에 더해 <span class="math inline">\(\exists b&gt;0, \forall i : \| X_i \|_{op}\)</span>. 이때</p>
<p>:::</p>
<p>Let independent 한 zero-mean symmetric 랜덤 매트릭스의 sequence <span class="math inline">\(\{ X_i \}^n_{i=1}\)</span>, 이에 더해 이 랜덤 매트릭스들은 패러미터 <span class="math inline">\(\{ V_i \}^n_{i=1} \in S^{d \times d}\)</span> 를 가지는 sub-Gaussian 조건을 만족한다. 이때 우리는 이하와 같은 upper tail bound 를 얻는다.</p>
<p>$$
<span class="math display">\[\begin{align}
&amp;P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le d \exp \left( - \frac{nt^2}{2\sigma^2}\right), &amp;&amp;\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n V_i \|_{op}
\end{align}\]</span>
$$</p>
<p>:::</p>
<p>$$
<span class="math display">\[\begin{align}
&amp;P \Big [ \lambda_{max}(\bar X) \ge t \Big ] \le 2d \exp \left( - \frac{nt^2}{2(\sigma^2  bt)}\right), &amp;&amp;\sigma^2 = 

\textstyle

\| \tfrac{1}{n} \sum_{i=1}^n Var(X_i) \|_{op}
\end{align}\]</span>
$$</p>
<p><br>
<br>
<br></p>
</div>
<div id="generalization-to-non-symmetricrectangular-matrices" class="section level4" number="8.6.4.3">
<h4 number="8.6.4.3"><span class="header-section-number">8.6.4.3</span> Generalization to non-symmetric/rectangular matrices</h4>
<p>이렇게 symmetric (그리고 당연히 square) 매트릭스의 concentration bounds 를 살펴봤음. 하지만 이 bounds는 non-symmetric 에도, 그리고 nonsquare 에도 적용할 수 있도록 확장 가능함. 바로 <strong>self-adjoint dilation</strong> 을 사용해서.</p>
<p>랜덤 매트릭스 <span class="math inline">\(X_i \in \mathbb R^{d_1 \times d_2}\)</span> 가 주어졌음. 이제 다음과 같은 매트릭스 생산:</p>
<p><span class="math display">\[
Y_i = \begin{bmatrix} 0_{d_1 \times d_1} &amp; X_i \\ X_i &#39; &amp; 0_{d_2 \times d_2}\end{bmatrix} \in \mathbb R^{(d_1 + d_2) \times (d_1 + d_2)}
\]</span></p>
<p><span class="math inline">\(Y_i\)</span> 가 symmetric 임을 보이는 건 쉬움. 더욱 중요한 것은, <span class="math inline">\(\|X_i \|_{op} = \|Y_i \|_{op}\)</span> 임을 보이는 것도 가능.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> 따라서 이하와 같으며, <span class="math inline">\(Y_i\)</span>의 mgf 에 특정한 조건을 부여하는 것으로 위에서 진행해온 프로세스를 그대로 적용할 수 있다.</p>
<p><span class="math display">\[
P(\| \bar X \|_{op} \ge t)= P(\| \bar Y \|_{op} \ge t) 
\]</span></p>
<!--chapter:end:212306_MatConIneq.Rmd-->
</div>
</div>
</div>
<div id="principal-component-analysis" class="section level2" number="8.7">
<h2 number="8.7"><span class="header-section-number">8.7</span> Principal Component Analysis</h2>
<p>Principal Component Analysis (PCA) 는 차원축소에 가장 유명한 방법론 중 하나. 데이터의 저차원 표현을 통해 데이터를 보여주고 또 해석하는 것이 가능. 이는 Var 의 대부분을 포착 (capture, 설명가능) 한 저차원 subspace 를 탐색해내거나, 혹은 equivalent 하게 분포의 maximal Var component 를 탐색해내는 것으로 성립. 샘플의 finite collection 이 주어졌을 때 PCA 의 empirical form 은 샘플 Cov Matrix 의 상위 evec 의 subset 을 계산해내는 것으로 작동함. 관심대상은 언제 이 evec 들이 population Cov Matrix 의 상위 evec 들에 의해 span 되는 subspace 를 잘 모사해내는가, 그 condition. 초기형 tool 들을 사용해 고차원 상황이랑 non-asymptotic framework 에서 해당 이슈를 살펴보자.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="pca-1" class="section level3" number="8.7.1">
<h3 number="8.7.1"><span class="header-section-number">8.7.1</span> PCA</h3>
<p>let <span class="math inline">\(E(X)=0\)</span>, <span class="math inline">\(Cov(X) = \Sigma\)</span> 인 랜덤벡터 <span class="math inline">\(X \in \mathbb R^d\)</span>. ev Decompostion 을 고려하자. 즉 <span class="math inline">\(\Sigma = V \Lambda V&#39;\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>PCA 에 던지는 질문은 결국 이거다. unit norm vector <span class="math inline">\(v\)</span>, 즉 <span class="math inline">\(v \in \mathbb S^{d-1} = \Big \{ v \in \mathbb R^d : || v ||_2 =1 \Big \}\)</span> 에 대해, 어떤 <span class="math inline">\(v\)</span> 를 골라야 랜덤변수 <span class="math inline">\(v&#39;X\)</span> 의 Var 이 최대화되는가?</p>
<p>더 이론적인 이야기를 해보자. 우리는 <span class="math inline">\(v_1 = \arg \max\limits_{v \in \mathbb S^{d-1}} Var(v&#39;X) = \arg \max\limits_{v \in \mathbb S^{d-1}} \langle v, \Sigma \rangle\)</span> 를 만족하는 direction <span class="math inline">\(v_1\)</span> 을 찾는 것에 목적을 둔다. 이를 <strong>first principal component</strong> 라고 부르자. 이를 일반화하면 <span class="math inline">\(\Sigma\)</span> 의 top <span class="math inline">\(k\)</span> principal component <span class="math inline">\(\{v_1 , \cdots, v_k \}\)</span> 를 구성할 수 있다. 이때 각각은 for <span class="math inline">\(2 \le j \le k: v_j = \arg \max\limits_{\substack{v \in \mathbb S^{d-1},\\ \langle v, \Sigma v_i \rangle = 0,\\ 1 \le \forall i \le j}} \langle v, \Sigma \rangle\)</span> 를 만족해야 한다.</p>
<p>이 principal component 들은 단순히 <span class="math inline">\(\Sigma\)</span> 의 top <span class="math inline">\(k\)</span> evec, 즉, <span class="math inline">\(V\)</span>의 first <span class="math inline">\(k\)</span> 개의 column 이 된다. PCA 는 보통 <span class="math inline">\(k\)</span> 를 작게 잡고 노는 걸 좋아함.</p>
<ul>
<li><strong>Best rank k approximation</strong></li>
</ul>
<p>PCA 는 low-rank 근사 (approximation) 의 관점으로도 해석될 수 있다. 우리가 rank 가 커봐야 <span class="math inline">\(k\)</span> 인 <span class="math inline">\(Z^\ast_{d \times d} = \arg \min\limits_{rank(Z) \le k} ||\Sigma Z||_F\)</span> 를 찾는다고 하자. 이에 대한 optimal solution 이 <span class="math inline">\(Z^\ast = \sum\limits^k_{i=1} \lambda_1 v_i v_i&#39;\)</span> 이며 <span class="math inline">\(\Bigg\|\Sigma - Z^\ast \Bigg\|^2_F = \sum\limits^d_{i=k+1}\lambda_i^2\)</span> 임을 알 수 있다.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="matrix-perturbation" class="section level3" number="8.7.2">
<h3 number="8.7.2"><span class="header-section-number">8.7.2</span> Matrix Perturbation</h3>
<p>실전에서 <span class="math inline">\(\Sigma\)</span> 는 불명이며 PCA 가 적용되는건 언제나 샘플 Cov <span class="math inline">\(\hat \Sigma\)</span> 이다. 이때 주된 질문은 샘플에서 얻은 ev 와 evec 들이 그들의 population Cov 를 얼마나 잘 근사하는지 하는 것이다. 이 질문에 답하기 위한 tool 들은 아래와 같다.</p>
<div id="ev-의-estimation" class="section level4" number="8.7.2.1">
<h4 number="8.7.2.1"><span class="header-section-number">8.7.2.1</span> ev 의 estimation</h4>
<p>let <span class="math inline">\(\hat \Sigma = \Sigma + \underbrace{E}_{\text{noise matrix}}\)</span>. 이때 maimum ev 의 정의에 의해</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_{max} (\hat \Sigma) &amp;= \max_{v \in \mathbb R^{d-1}} v&#39;(\Sigma + E)v

\\

&amp;\le \lambda_{max}(\Sigma) + ||E||_{op}

\end{align}\]</span>
$$</p>
<p><span class="math inline">\(\hat \Sigma\)</span> 와 <span class="math inline">\(\Sigma\)</span> 의 역할이 뒤바뀌었을 때도 동일한 argument 가 성립하므로 동시에 <span class="math inline">\(\lambda_{max} (\Sigma) \le \lambda_{max}(\hat \Sigma) + ||E||_{op}\)</span> 이기도 하다. 이 둘을 합하면 결국 <span class="math inline">\(\Big | \lambda_{max} (\Sigma) - \lambda_{max}(\hat \Sigma) \Big |\le ||E||_{op}\)</span>.</p>
<p>이를 더 일반화시키면 이하와 같다.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-16" class="theorem"><strong>(#thm:unlabeled-div-16) (Weyl’s inequality) </strong></span><span class="math display">\[
\max\limits_{i=1, \cdots, d} \Big | \hat \lambda_i - \lambda_i \Big | \le ||E||_{op} = ||\hat Sigma - \Sigma ||_{op}
\]</span></p>
<p>where <span class="math inline">\(\hat \lambda_1, \cdots, \hat \lambda_d\)</span> are the ordered ev of <span class="math inline">\(\hat \Sigma\)</span>.</p>
</div>
<p>이것이 의미하는 바는 명확함. <span class="math inline">\(\forall i = 1,\cdots,d: ||\hat \lambda - \lambda||_{op} \Longrightarrow\)</span> <span class="math inline">\(\{\hat \lambda_i\)</span> 는 <span class="math inline">\(\lambda_i\)</span> 의 consistent estimator <span class="math inline">\(\}\)</span>라는 이야기. 실제로 SG assumption 하에서, <span class="math inline">\(|| \hat \Sigma - \Sigma || \lesssim \max \left( \sqrt{\frac{d}{n}}, \frac{d}{n} \right)\)</span> with high probability. 따라서 개별 empirical ev 값은 이 경우에 <span class="math inline">\(\frac{d}{n} \rightarrow 0\)</span> 일 경우 consistent.</p>
<p><br>
<br>
<br></p>
</div>
<div id="evec-의-estimation" class="section level4" number="8.7.2.2">
<h4 number="8.7.2.2"><span class="header-section-number">8.7.2.2</span> evec 의 estimation</h4>
<p>ev 는 일반적으로 stable 하지만 evec 의 경우에는 그렇지 않음.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="spiked-cov-model" class="section level3" number="8.7.3">
<h3 number="8.7.3"><span class="header-section-number">8.7.3</span> Spiked Cov Model</h3>
<div class="definition">
<p><span id="def:unlabeled-div-17" class="definition"><strong>(#def:unlabeled-div-17) (Spiked Cov model) </strong></span>Cov matrix <span class="math inline">\(\Sigma \in \mathbb R^{d \times d}\)</span> 가 이하의 형을 만족하면 이는 <strong>Spiked Covariance Model 를 만족한다</strong> 고 불림. 이때 vector <span class="math inline">\(v\)</span> 는 <strong>spike</strong> 라고 명명.</p>
<p><span class="math display">\[
\exists \theta &gt; 0, \exists v \in \mathbb S^{d-1}: \Sigma = \theta v v&#39; + I_d
\]</span></p>
</div>
<p>이러한 spiked Cov model 에 있어, <span class="math inline">\(\max(ev) = \theta + 1\)</span>, corresponding evec (largest evec) <span class="math inline">\(=v\)</span> 이라는 관점이 성립하는 것을 note. <span class="math inline">\(v\)</span> 의 natural estimate 는 empirical Cov Matrix 의 largest evec <span class="math inline">\(\hat v\)</span>. 우리의 목적은 고차원 setting에서 <span class="math inline">\(\hat v\)</span>와 <span class="math inline">\(v\)</span> 가 얼마나 가까운지 보는 것.</p>
<p>이때 <span class="math inline">\(u\)</span> 가 symmetric Matrix 의 evec 이라고 하면, <span class="math inline">\(-u\)</span> 또한 같은 ev 에 묶인 evec. <mark>따라서 우리가 <span class="math inline">\(v\)</span> 를 estimate 해봐야 최대로 estimate 가능한 종착지는 참값의 sign flip 까지가 한계. This means that we can only estimate <span class="math inline">\(v\)</span> up to a sign flip.</mark> 이 문제를 해결하기 위해 우리는 2개의 벡터 <span class="math inline">\(u, v\)</span> 사이가 얼마나 가까운지 proximity 를 그들 각각의 linear span 사이의 <strong>principal angle</strong> 이라는 개념을 이용하여 설명한다.</p>
<p><span class="math display">\[
\angle(u,v) = \arccos \left( \Bigg | u&#39;v \Bigg | \right)
\]</span></p>
<p>Davis–Kahan <span class="math inline">\(\sin(\theta)\)</span> thm 은 eigenspace 들 사이의 principal angle 의 <span class="math inline">\(\sin\)</span> 에 대한 bound 를 생산함. 이하는 1차원 eigenspace 들 사이의 principal angle 에 대해 사용되는 Davis–Kahan <span class="math inline">\(\sin(\theta)\)</span> thm 의 간단한 버전.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-18" class="theorem"><strong>(#thm:unlabeled-div-18) (Davis–Kahan sin(θ) theorem) </strong></span>let <span class="math inline">\(A_{d \times d}, B_{d \times d} \in PSD\)</span>.</p>
<p><span class="math inline">\(\lambda_{1} \ge {\lambda}_{2} \ge \cdots: \; (\lambda_{1},u_{1}),\cdots,(\lambda_{d,}^{\cdot}\,u_{d})\)</span> is pairs of ev and evec of <span class="math inline">\(A\)</span>.</p>
<p><span class="math inline">\(\mu_{1} \ge {\mu}_{2} \ge \cdots: \; \; (\mu_{1},v_{1}),\cdots,(\mu_{d,}^{\cdot}\,v_{d})\)</span> is pairs of ev and evec of <span class="math inline">\(B\)</span>.</p>
<p>이때</p>
<p>$$
<span class="math display">\[\begin{align}
&amp;\sin \Big (\angle(u_{1},v_{1}) \Big )\leq{\frac{2}{\operatorname*{max} \Big (\lambda_{1}-\lambda_{2},\mu_{1}-\mu_{2} \Big )}}\|A-B\|_{\mathrm{op}}

\\

\operatorname*{min}\limits_{\epsilon\in\{\pm1\}} \Big \|\epsilon \cdot u_{1}-v_{1} \Big \|_{2}^{2}\le

2&amp;\mathrm{sin}^{2} \Big (\angle(u_{1},v_{1}) \Big )
\end{align}\]</span>
$$</p>
</div>
<ul>
<li><strong>Proof:</strong></li>
</ul>
<p>여기서 Matrix 에 대한 Holder ineq. 를 적용하자. 이때 <span class="math inline">\(u_1 &#39; A u_1 = \lambda_1\)</span>, i.e. maxiumum ev. 여기서</p>
<p>$$
<span class="math display">\[\begin{align}
\forall x \in \mathbb S^{d-1}: x^{\textsf{T}}A x\ =\ x^{\textsf{T}}\!\left(\sum_{i=1}^{d}\lambda_{i}u_{i}u_{i}^{\top}\right)\!x
&amp;=\sum_{i=1}^{d}\lambda_{i}(u_{i}^{\top}x)^{2}



\\

&amp;\leq\;\ \lambda_{1}(u_{1}^{\top}x)^{2}+\lambda_{2}\sum_{i=2}^{d}(u_{i}^{\top}x)^{2}

\\

&amp;\overset{(\mathrm{i})}{=}~\lambda_{1}\big(u_{1}^{\top}x\big)^{2}\,+\,\lambda_{2}\big(1\,-\,\big(u_{1}^{\textsf{T}}x\big)^{2}\big)

\\

&amp;\overset{(\mathrm{ii})}{=} \lambda_{1}\cos^{2}\Big(\angle(u_{1},x)\Big)+\lambda_{2}\sin^{2}\Big(\angle(u_{1},x)\Big),
\end{align}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(x = \sum\limits_{i=1}^d u_u(u_i &#39; x)\)</span> 이며 <span class="math inline">\(x&#39;x = \sum\limits_{i=1}^d(u_i &#39; x)^2 =1\)</span> 이라는 사실 사용</li>
<li>trigonometric identity <span class="math inline">\(\cos^2 + \sin^2 = 1\)</span></li>
</ol>
<p>따라서 여기에 <span class="math inline">\(x = v_1\)</span> 으로 잡는 것으로</p>
<p>$$
<span class="math display">\[\begin{align}

u_{1}^{\top}A u_{1}-v_{1}^{\top}A v_{1}\ &amp;\geq\ \lambda_{1}-\lambda_{1}\mathrm{cos}^{2}\Big(\angle(u_{1},x) \Big)-\lambda_{2}\mathrm{sin}^{2} \Big (\angle(u_{1},x) \Big )

\\

&amp;=\;(\lambda_{1}-\lambda_{2}){\sin}^{2} \Big (\angle(u_{1},x) \Big )

\end{align}\]</span>
$$</p>
<p>On the other hand,</p>
<p>$$
<span class="math display">\[\begin{align}

u_{1}^{\textsf{T}}A u_{1}-v_{1}^{\textsf{T}}A v_{1}\ \ &amp;=\ \ u_{1}^{\textsf{T}}B u_{1}-v_{1}^{\textsf{T}}A v_{1}+u_{1}^{\textsf{T}}(A-B)u_{1}

\\

&amp;\overset{\mathrm{(i)}}{\leq}~v_{1}^{\top}B v_{1}-v_{1}^{\top}A v_{1}+u_{1}^{\top}(A-B)u_{1}

\\

&amp;=\;\Big\langle A-B, \; u_{1}u_{1}^{\top}-v_{1}v_{1}^{\top} \Big \rangle

\\

&amp;\overset{(ii)}\le \left|\right|A-B||_{\infty}||u_{1}u_{1}^{\top}-v_{1}v_{1}^{\top}||_{1}

\\

&amp;\overset{(iii)}\le \vert\vert A-B\vert\vert_{\mathrm{op}}\sqrt{2}\vert\vert u_{1}u_{1}^{\textsf{T}}-v_{1}v_{1}^{\textsf{T}}\vert\vert_{2},

\end{align}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(v_1\)</span> 이 <span class="math inline">\(B\)</span> 의 leading evec 이므로</li>
<li>Holder ineq.</li>
<li><span class="math inline">\(||A-B||_\infty = ||A-B||_{op}\)</span> 이며, <span class="math inline">\(rank(u_1u_1&#39; - v_1v_1&#39; )\le 2\)</span> 와 함께 CS ineq. 사용.</li>
</ol>
<p>이하는 명확함.</p>
<p><span class="math display">\[
||u_{1}u_{1}^{\top}-v_{1}v_{1}^{\top}||_{2}^{2}=2-2(u_{1}^{\top}v_{1})^{2}=2\mathrm{sin}^{2}(\angle(u_{1},v_{1}))
\]</span></p>
<p>이제 모든 조각을 모으면 이하가 성립.</p>
<p><span class="math display">\[
\left(\lambda_{1}-\lambda_{2}\right)\mathrm{sin}^{2} \bigg(\angle(u_{1},v_{1}) \bigg)\leq2\|A-B\|_{\mathrm{op}} \mathrm{sin}\bigg(\angle(u_{1},v_{1}) \bigg)
\]</span></p>
<p>이는 곧 thm 의 첫번째 부분을 보여줌. <span class="math inline">\(A\)</span>와 <span class="math inline">\(B\)</span> 에 대해 결과가 완벽하게 symmetric 이므로 <span class="math inline">\(\lambda_1 - \lambda_2\)</span> 를 <span class="math inline">\(\mu_1 - \mu_2\)</span> 로 대체할 수 있음을 note.</p>
<p>이제 thm 의 2번째 부분만 보이면 됨. 이는 이하의 ineq. 를 통해 성립함이 분명. 이하의 ineq. 는 <span class="math inline">\(|u_{1}^{\top}v_{1}|\leq\|u_{1}\|_{2}\|v_{1}\|_{2}=1.\)</span> 이므로 성립함.</p>
<p><span class="math display">\[
\operatorname*{min}_{\epsilon\in\{\pm1\}}||\epsilon u_{1}-v_{1}||_{2}^{2}=2-2|u_{1}^{\top}v_{1}|\le2-2|u_{1}^{\top}v_{1}|^{2}=\sin^{2}(2(u_{1},v_{1})
\]</span></p>
<p><br>
<br></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-19" class="theorem"><strong>(#thm:unlabeled-div-19) (Holder’s inequality for matrices) </strong></span>let <span class="math inline">\(A_{d \times d}, B_{d \times d} \in PSD\)</span>, 그리고 각각의 ev들을 <span class="math inline">\(\lambda_1 , \cdots, \lambda_d\)</span>, <span class="math inline">\(\mu_1 , \cdots, \mu_d\)</span>. 이를 이하와 같이 쓸 수 있다.</p>
<p><span class="math display">\[
||A||_{p}=\left(\sum_{i=1}^{d} \Big |\lambda_{i} \Big |^{p}\right)^{\frac1p}
\; \; \; \; \; 
\; \; \; \; \; 
||B||_{q}=\left(\sum_{i=1}^{d} \Big |\mu_{i} \Big |^{q}\right)^{\frac1q}
\]</span></p>
<p>이때
<span class="math inline">\(\forall p, q \; \; \text{ s.t. } \; \; \frac1p + \frac1q = 1, p,q \in [1, \infty]: \; \; \langle A, B \rangle = tr(A&#39;B) = tr(B&#39;A) \le ||A||_{p} ||B||_{q}\)</span>.</p>
</div>
<p><br>
<br></p>
<p>“Davis–Kahan sin(θ) theorem” 을 thm 5.1 과 조합하는 것으로 이하의 결과를 얻을 수 있음.</p>
<p><br>
<br></p>
<div class="corollary">
<p><span id="cor:unlabeled-div-20" class="corollary"><strong>(#cor:unlabeled-div-20) (Empirical principal component) </strong></span><span class="math inline">\(E(X_1) = 0\)</span>, <span class="math inline">\(Var(X_1) = \Sigma_{d \times d}\)</span> 인 랜덤벡터의 sequence <span class="math inline">\(X_1 , \cdots, X_n \overset{iid}{\sim} \in SG(\sigma^2)\)</span>, i.e., sequnce of <span class="math inline">\(\sigma\)</span>-sub-Gaussian random vectors.</p>
<p>let 샘플 Cov Matrix <span class="math inline">\(\hat \Sigma = \frac{1}{n} \sum_{i=1}^n X_i X_i &#39;\)</span>.</p>
<p>assume <span class="math inline">\(\Sigma = \theta v v&#39; + I_d\)</span> <strong>spiked Cov model</strong> 만족. 그렇다면 <span class="math inline">\(\hat \Sigma\)</span> 의 largest evec <span class="math inline">\(\hat v\)</span> 는 이하를 with probability <span class="math inline">\(1-\delta\)</span> 로 만족.</p>
<p><span class="math display">\[
\operatorname*{min}_{\epsilon\in\{\pm1\}}\left|\right|\epsilon \cdot \widehat{v}-v||_{2} 
\lesssim 
\frac{1}{\theta}\,\mathrm{max}\left\{\sqrt{\frac{d+\log(\frac2\delta)}{n}},\;\frac{d+\log(\frac2\delta)}{n}\right\}
\]</span></p>
</div>
<p>이 결과를 통해 저차원 상황 (<span class="math inline">\(d \ll n\)</span>) 에서의 PCA 를 진행할 때 population Cov <span class="math inline">\(\Sigma\)</span> 를 샘플 Cov <span class="math inline">\(\hat \Sigma\)</span> 로 대체하는 것이 정당화된다.</p>
<p>고차원 상황 (<span class="math inline">\(d \gg n\)</span>) 일 때는 <span class="math inline">\(\hat \Sigma\)</span> 를 써서 PCA 를 진행하면 결과값이 구리다는 것이 증명되어 있다. 실제로 <span class="math inline">\(\frac dn\)</span> 이 0에서 bounded away 되어있는 한, population evec 에 대한 consistent estimator 를 생산할 수 있는 <strong>방법 자체가 아예 없다</strong> 는 것을 보이는 것이 가능하다. 하지만 evec 에 대해 certain structure 가 존재한다면 고차원에서도 population evec 을 consistently estimate 하는 것이 가능하긴 하다.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="sparse-pca" class="section level3" number="8.7.4">
<h3 number="8.7.4"><span class="header-section-number">8.7.4</span> sparse PCA</h3>
<p>evec 에 sparsity 개념을 도입하자. leading evec <span class="math inline">\(v\)</span> 가 <span class="math inline">\(k\)</span>-sparse<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>, 즉 <span class="math inline">\(||v||_0 = \sum\limits^d_{i=1}|v_i|^0 = k\)</span><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>.</p>
<p>이 경우 <span class="math inline">\(v\)</span> 를 추정하기 위한 natural candidate 는 <span class="math inline">\(\hat v_{sp} = \arg \max\limits_{u \in \mathbb S^{d-1}, ||u||_0 = k} u&#39; \hat \Sigma u\)</span>.</p>
<p>이 estimator 는 이하를 통해 타당화.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-21" class="theorem"><strong>(#thm:unlabeled-div-21) (Sparse PCA) </strong></span>Corollary 7.4 와 같은 setting 을 생각하자. 여기에 추가로 leading evec <span class="math inline">\(v\)</span> 가 $k d 2: ||v||_0 k $ 를 만족한다고 assume. 이때 <span class="math inline">\(\hat \Sigma\)</span> 의 k-sparse largest evec <span class="math inline">\(\hat v_{sp}\)</span> 는 with probability <span class="math inline">\(1-\delta\)</span> 로 이하를 만족.</p>
<p><span class="math display">\[
\operatorname*{min}_{\epsilon\in\{\pm1\}}
\|\epsilon \cdot \widehat{v}_{\mathrm{sp}}-v\|_{2}
\lesssim
\frac{1}{\theta}\operatorname*{max}\left\{
\sqrt{\frac{k\log(\frac{e d}k)+\log(\frac2\delta)}{n}},\;
\frac{k\log(\frac{e d}k)+\log(\frac2\delta)}{n}\right\},
\]</span></p>
<ul>
<li>※ REMARK. 일반적인 PCA 와 달리, k-sparcity 가 만족되었다면, <span class="math inline">\(d \gg n\)</span> 상황에서도 <span class="math inline">\(\hat v_{sp}\)</span> 는 consistent 가능.</li>
</ul>
</div>
<ul>
<li>Detour: <span class="math inline">\(1 \le \forall k \in \mathbb Z \le n : {n \choose k} \le \left( \frac{en}{k}\right)^k\)</span></li>
</ul>
<p>Proof:</p>
<p>thm 7.3 과 동일한 과정을 거쳐</p>
<p><span class="math inline">\(v^{\top}\Sigma v-\widehat{v}_{\mathrm{sp}}^{\top}\Sigma\widehat{v}_{\mathrm{sp}}\leq \Big \langle\widehat{\Sigma}-\Sigma, \; \widehat{v}_{\mathrm{sp}}\widehat{v}_{\mathrm{sp}}^{\top}-v v^{\top} \Big \rangle\)</span></p>
<p><span class="math inline">\(v\)</span> 와 <span class="math inline">\(\hat v_{sp}\)</span> 양쪽 모두가 k-sparse 이므로, cardinality <span class="math inline">\(|S| \le 2k\)</span> 이며, <span class="math inline">\((i,j) \not = S \times S\)</span> 일 때 <span class="math inline">\(\{\hat v_{sp} \hat v_{sp}&#39; - vv&#39;\}_{ij}=0\)</span> 를 만족하는 랜덤 set <span class="math inline">\(S \subset \{1, \cdots, d\}\)</span> 가 존재한다. 이는 곧 이하를 생산한다.</p>
<p><span class="math display">\[
\Big \langle\widehat\Sigma-\Sigma,\; \widehat{v}_{\mathrm{sp}}\widehat{v}_{\mathrm{sp}}^{\intercal}-v v^{\top}  \Big \rangle= \Big \langle\widehat{\Sigma}(S)-\Sigma(S), \;  \widehat{v}_{\mathrm{sp}}(S)\widehat{v}_{\mathrm{sp}}(S)^{\intercal}-v(S)v(S)^{\intercal} \Big \rangle
\]</span></p>
<p>이때 <span class="math inline">\(\forall M_{d \times d}\)</span> 에 대해, 우리는 <span class="math inline">\(S\)</span> 에 의해 row 와 col 이 index 되도록 구성된 <span class="math inline">\(M\)</span> 의 submatrix <span class="math inline">\(M(S)_{|S| \times |S|}\)</span> 를 정의하자. 또 <span class="math inline">\(\forall \in \mathbb R^d\)</span> 에 대해, <span class="math inline">\(S\)</span> 로 그것의 coordinate 가 index 된 x의 sub-vector <span class="math inline">\(x(S) \in \mathbb R^{|S|}\)</span> 를 정의하자. 여기서 Matrix 에 대한 Holder ineq. 를 적용하는 것으로 이하가 생산된다.</p>
<p><span class="math display">\[
v^{\top}\Sigma v-\widehat{v}_{\mathrm{sp}}^{\top}\Sigma\widehat{v}_{\mathrm{sp}}\leq  \Big \|\widehat{\Sigma}(S)-\Sigma(S) \Big \|_{\mathrm{op}}  \Big \|\widehat{v}_{\mathrm{sp}}(S)\widehat{v}_{\mathrm{sp}}(S)^{\top}-v(S)v(S)^{\top} \Big \|_{1}
\]</span></p>
<p>이제 thm 7.3 과 동일한 과정을 거치는 것으로 이하의 관계를 얻는다.</p>
<p><span class="math display">\[
\sin \bigg (\angle(\hat{v}_{\mathrm{sp}},v) \bigg)\leq\frac{2}{\theta}\operatorname*{sup}\limits_{S:|S\vert=2k}  \Big  \|\hat{\Sigma}(S)-\Sigma(S) \Big \|_{\mathrm{op}}
\]</span></p>
<p>증명을 마무리하기 위해 <span class="math inline">\(\sup_{S:|S|=2k} \Bigg \| \hat \Sigma(S) - \Sigma(S) \Bigg \|_{op}\)</span> 를 control 하는 일이 남아있다. 이를 위해 이하를 보이자.</p>
<p>$$
<span class="math display">\[\begin{align}

\forall t\ge0:\mathbb{P}{\Biggl(}\operatorname*{sup}_{S:\mathbf{|}S|=2k} \bigg \|{\hat{\Sigma}}(S)-\Sigma(S) \bigg \|_{\mathrm{op}}\geq t{\Biggr)}

&amp;\leq\ \sum_{S:|S|=2k}\mathbb{P}{\Bigg(} \bigg \|{\hat{\boldsymbol{\Sigma}}}(S)-\Sigma(S) \bigg \|\log\geq t{\Bigg)}

\\

&amp;\stackrel{(i)}{\leq}~{d \choose {2k}} \times2\times9^{2k}\times\exp\Biggl(-\frac{1}{2}\operatorname*{min}\biggl\{\frac{n t}{16\sigma^{2}},~\frac{n t^{2}}{16^{2}\sigma^{4}}\biggr\}\Biggr)


\\

&amp;\stackrel{(ii)}{\leq}~{d \choose {2k}}
2 \exp\Biggl(-\frac{1}{2}\operatorname*{min}\biggl\{\frac{n t}{16\sigma^{2}},~\frac{n t^{2}}{16^{2}\sigma^{4}}\biggr\}+ 2k \log 9 + k \log\left( \frac{en}{k} \right) \Biggr  )

\end{align}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li>thm 5.1. 의 증명을 사용.</li>
<li>ineq. (7.2) 에 의해 증명.</li>
</ol>
<p>이제 충분히 큰 <span class="math inline">\(C&gt;0\)</span> 에 대해서, 이하의 식에 의해 <span class="math inline">\(t\)</span> 에 대해 with probabilty at least <span class="math inline">\(1-\delta\)</span> 로 desired bound 가 성립하며, 그러한 <span class="math inline">\(t\)</span> 를 고르면 된다.</p>
<p><span class="math display">\[
t\geq C\sigma^{2}\operatorname*{max}\left\{\sqrt{\frac{k\log(\frac{ed}k)+\log(\frac2\delta)}{n}},\;\frac{k\log(\frac{e d}k)+\log(\frac2\delta)}{n}\right\}
\]</span></p>
<p>Fin.</p>
<!--chapter:end:212307_PCA.Rmd-->
</div>
</div>
<div id="linear-regression" class="section level2" number="8.8">
<h2 number="8.8"><span class="header-section-number">8.8</span> Linear Regression</h2>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="problem-formulation" class="section level3" number="8.8.1">
<h3 number="8.8.1"><span class="header-section-number">8.8.1</span> Problem formulation</h3>
<p>unknown vector 인 <strong>regression vector</strong> <span class="math inline">\(\theta^\ast \in \mathbb R^d\)</span> 설정.</p>
<p>벡터 <span class="math inline">\(Y = (Y_1 , \cdots, Y_n)&#39; \in \mathbb R^n\)</span> 를 관측했으며, linear model <span class="math inline">\(Y=X\theta^{*}+\epsilon\)</span> 를 통해 이와 관계되어 있는 <span class="math inline">\(X \in \mathbb R^{n \times d}\)</span> 를 가정하자. 이때 <span class="math inline">\(\epsilon\;=\;\left(\epsilon_{1},\cdot\cdot\cdot,\epsilon_{n}\right)^{\top}~\in~\mathbb{R}^{n}\;\)</span> 이며, 각각은 independent zero-mean <span class="math inline">\(\epsilon_1 , \cdots, \epsilon_n \in SG(\sigma^2)\)</span>.</p>
<p>이제 <span class="math inline">\(\hat \theta\)</span> 를 <span class="math inline">\(\theta^\ast\)</span> 의 estimator 로 잡는다. 이하의 2가지가 주된 관심사.</p>
<ol style="list-style-type: decimal">
<li>Prediction</li>
</ol>
<p><span class="math inline">\(X \theta^\ast + \tilde \epsilon = \tilde Y \overset{iid} \sim Y\)</span> 라고 설정하자. 우리의 목적은 <span class="math inline">\(\theta^\ast\)</span> 에 대한 우리의 estimate <span class="math inline">\(\hat \theta\)</span> 의 구현값을 사용해서 <span class="math inline">\(\tilde Y\)</span> 를 predict. performance 에 대한 natural measure 는 이하와 같다. 이때 unavoidable error 는 말 그대로 unavoidable 이므로, 우리는 후자인 MSE, 즉 <span class="math inline">\(\mathbb{E}\left [\Bigg \|X(\theta^{*}-{\widehat{\theta}})\Bigg \|_{2}^{2}\right ]\)</span>, 를 조사하고자 한다.</p>
<p><span class="math display">\[
\frac{1}{n}\mathbb{E}\left [\Bigg \|{\tilde{Y}}-X{\widehat{\theta}}\Bigg \|_{2}^{2}\right ]
=
\frac{1}{n}\mathbb{E}\left [\Bigg \|{\tilde{\epsilon}}+X(\theta^{*}-{\widehat{\theta}})\Bigg \|_{2}^{2}\right ]
=
\underbrace{\frac{1}{n}\mathbb{E}\left [\Bigg \|\tilde \epsilon\Bigg \|_{2}^{2}\right ]}_{\text{unavoidable error}}
+
\underbrace{\frac{1}{n}\mathbb{E}\left [\Bigg \|X(\theta^{*}-{\widehat{\theta}})\Bigg \|_{2}^{2}\right ]}_{\text{Mean Squared Error}}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Parameter Estimation</li>
</ol>
<p>위와는 다른 케이스로, 몇몇 경우에 우리는 regression vector <span class="math inline">\(\theta*\ast\)</span> 를 조사하고 싶어하는 경우가 있으며, 이 경우에 관심사 (조사대상) 는</p>
<p><span class="math display">\[
\mathbb{E}\left [\Bigg \|\theta^{*}-{\widehat{\theta}}\Bigg \|_{2}^{2}\right ]
\]</span></p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="least-squares-estimator-in-high-dimensions" class="section level3" number="8.8.2">
<h3 number="8.8.2"><span class="header-section-number">8.8.2</span> Least Squares Estimator in high dimensions</h3>
<p>고전적인 LR 은 LS 문제를 풀어내는 것과 같다. 이하의 형을 구한다는 것과 equivalent 이며, 이는 보통 <strong>Ordinary Least Squares (OLS) estimator</strong> 로 통칭됨.</p>
<p><span class="math inline">\({\widehat{\theta}}_{\mathrm{LS}}=(X^{\top}X)^{-1}X^{\top}Y=\arg \min\limits_{\theta \in \mathbb R^d}\|Y-X\theta\|_{2}^{2}\)</span></p>
<p>Gauss–Markov thm 에 의해 우리는 OLS Estimator 가 Best Linear Unbiased Estimator (BLUE) 임을 알고 있음. 왜냐고 특정 condition 하에서의 Linear Unbiased Estimator 들의 class 내에서 OLS Estimator 가 가장 작은 Var 을 가지고 있으니까. 하지만 이 estimator 는 <span class="math inline">\(X&#39;X\)</span> 가 uninvertible 하면 존재할 수 없음. 다른 말로, <span class="math inline">\(n \ge d\)</span> 인 경우에만 존재할 수 있다는 거임. <span class="math inline">\(d&gt;n\)</span> 라도, <span class="math inline">\(\operatorname*{min}_{\theta\in\mathbb{R}^{d}}\|Y-X\theta\|_{2}^{2}\)</span> 라는 문제에 대한 해를 찾아내는 건 가능함. 다음과 같이 매핑하는 function <span class="math inline">\(\theta\mapsto\|Y=X\theta\|_{2}^{2}\)</span> 는 convex 이므로, 1차 optimality condition 인 <span class="math inline">\(\nabla_{\theta}\|Y-X\theta\|_{2}^{2}=0\quad\Longleftrightarrow\quad X^{\top}X\theta=X^{\top}Y\)</span> 를 체크하는 것만으로 충분함. 이의 해는 이하에 제시된 MP-pseudo Inverse <span class="math inline">\(X&#39;X\)</span> 의 형으로 서술될 수 있음.</p>
<p><br>
<br>
<br></p>
<div id="mean-squared-error-of-the-least-squares-estimator" class="section level4" number="8.8.2.1">
<h4 number="8.8.2.1"><span class="header-section-number">8.8.2.1</span> Mean Squared Error of the Least Squares Estimator</h4>
<div class="theorem">
<p><span id="thm:unlabeled-div-22" class="theorem"><strong>(#thm:unlabeled-div-22) (Least Squares Estimator) </strong></span>let linear model <span class="math inline">\(Y=X\theta^{*}+\epsilon\)</span>, 이때 <span class="math inline">\(\epsilon\)</span> 의 elements 각각은 independent zero-mean <span class="math inline">\(\epsilon_1 , \cdots, \epsilon_n \in SG(\sigma^2)\)</span>.</p>
<p>이때 <span class="math inline">\(\hat \theta_{LS}\)</span> 는 이하를 만족하며, 2번째 ineq는 with probability at least <span class="math inline">\(1-\delta\)</span> 로 만족.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
&amp; &amp;&amp;\frac{1}{n}E \Bigg ( &amp;&amp; \Bigg \| X\bigl(\widehat{\theta}_{\mathrm{LS}}-\theta^{*}\bigr) \Bigg \|_{2}^{2} \Bigg) &amp;&amp;\lesssim \sigma^{2}\frac{r}{m} &amp;&amp; \; \; \; \; \; \; \; \; \;\;r= rank(X&#39;X)

\\

&amp;\forall \delta&gt;0: &amp;&amp; {\frac{1}{n}} &amp;&amp;\|X(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})\|_{2}^{2} &amp;&amp;\lesssim\sigma^{2} \left({\frac{r+\log(\frac 1 \delta)}{n}} \right) 
\end{alignat}\]</span>
$$</p>
</div>
<ul>
<li>Remark</li>
</ul>
<p><span class="math inline">\(d \le n\)</span> 이며 <span class="math inline">\(rank(B) = rank \left( \frac{X&#39;X}{n}\right) =d\)</span> 일 때, 이하가 성립한다. 이때 <span class="math inline">\(\lambda_{\mathrm{min}}(B)\)</span> 는 <span class="math inline">\(B\)</span> 의 ev 중 최소인 값이며, 따라서 이에 <span class="math inline">\(\|\hat \theta_{LS} - \theta^\ast \|^2_2\)</span> 를 탐색하기 위해 thm 8.2. 를 바로 적용하는 것이 가능하다.</p>
<p>그러나 고차원 케이스에서는 <span class="math inline">\(d&gt;n\)</span> 일 때 <span class="math inline">\(\lambda_{\mathrm{min}}(B) = 0\)</span> 이므로 이 방법론을 쓸 수 없다. 따라서 MSE 의 형으로 <span class="math inline">\(\lambda_{\mathrm{min}}(B)\)</span> 의 bound 를 설정할 필요가 있기 때문에 가정이 추가적으로 필요하다.</p>
<p><span class="math display">\[
\begin{alignat}{2}
&amp; &amp;&amp; \lambda_{\mathrm{min}}(B) &amp;&amp;\Bigg \|\widehat{\theta}_{\mathrm{LS}}-\theta^{*}\Bigg \|_{2}^{2} &amp;&amp;\leq\left(\widehat{\theta}_{\mathrm{LS}}-\theta^{*}\right)^{\top}B&amp;&amp;(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})
\\
&amp; &amp;&amp; \lambda_{\mathrm{min}}(B) &amp;&amp;\Bigg \|\widehat{\theta}_{\mathrm{LS}}-\theta^{*}\Bigg \|_{2}^{2} &amp;&amp;\leq\left(\widehat{\theta}_{\mathrm{LS}}-\theta^{*}\right)^{\top}\frac{X&#39;X}{n}&amp;&amp;(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})
\\
&amp;\iff &amp;&amp; &amp;&amp; \Bigg \|{\widehat\theta}_{\mathrm{LS}}-\theta^{*} \Bigg \|_{2}^{2} &amp;&amp;\leq{\frac{1}{\lambda_{\mathrm{min}}(B)}}\cdot\frac{1}{n} &amp;&amp;\Bigg \|X({\widehat\theta}_{\mathrm{LS}}-\theta^{*}) \Bigg \|_{2}^{2}
\end{alignat}
\]</span></p>
<ul>
<li>Proof</li>
</ul>
<p>8.2 의 증명은 <strong>basic inequality</strong> 와 <strong>sup-out</strong> 테크닉에 의존.</p>
<ol style="list-style-type: decimal">
<li>Basic ineq.</li>
</ol>
<p>첫줄의 ineq. 는 의 정의에 의해 성립. 이때 <span class="math inline">\(\epsilon\)</span> 과 <span class="math inline">\(\hat \theta_{LS}\)</span> 는 dependent 하기 때문에 <span class="math inline">\(\frac{\epsilon^{\top}X(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})}{||X(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})||_{2}}\)</span> 를 control 하기가 어렵다는 것을 note. dependence structure 가 complicated 하다면 더더욱 그럴 것. 이 dependence 를 지워 없애기 위해 sup-out tachnique 를 사용. 이의 maximal ineq. 를 적용하는 것이 해당 문제 해결의 열쇠가 된다.</p>
$$
<span class="math display">\[\begin{array}
&amp;
&amp;
&amp;\|Y-X{\widehat{\theta}}_{\mathrm{LS}}\|_{2}^{2}
&amp;\leq
&amp;\|Y-X\theta^{*}\|_{2}^{2} 
&amp;=
\|\epsilon\|_{2}^{2}

\\
&amp;=
&amp; \| \epsilon + X(\theta^\ast - \hat \theta_{LS})\| &amp;
\\
&amp;=
&amp;\|\epsilon\|_{2}^{2}+2\epsilon^{\mathsf{T}}X(\theta^{*}-{\widehat{\theta}}_{\mathsf{L S}})+\|X(\theta^{*}-{\widehat{\theta}}_{\mathsf{L S}})\|_{2}^{2} &amp;&amp;

\\

\iff
&amp;
&amp;\|X(\theta^{*}-\hat{\theta}_{\mathrm{LS}})\|_{2}^{2}\;
&amp;\leq
&amp;\;2\epsilon^{\top}X(\hat{\theta}_{\mathrm{LS}}-\theta^{*})
&amp;
&amp;=
&amp;2\|X(\hat{\theta}_{\mathrm{LS}}-\theta^{*})\|_{2}\times\frac{\epsilon^{\top}X(\hat{\theta}_{\mathrm{LS}}-\theta^{*})}{\|X(\hat{\theta}_{\mathrm{LS}}-\theta^{*})\|_{2}}



\end{array}\]</span>
<p>$$</p>
<ol start="2" style="list-style-type: decimal">
<li>Sup-Out</li>
</ol>
<p><span class="math inline">\(X\)</span>의 column span 의 orthonormal basis 를 <span class="math inline">\(\Psi = [\psi_1, \cdots, \psi_r] \in \mathbb R^{n \times r}\)</span> 라고 하자. (SVD 를 생각하자.) 특히, <span class="math inline">\(\exists \nu \in \mathbb R^r : X(\hat \theta_{LS} - \theta^\ast) = \Psi \nu\)</span>. 이때 이 <span class="math inline">\(\nu\)</span> 에 대해</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
&amp;
&amp;&amp;\frac{\epsilon^{\top}X(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})}{||X(\widehat{\theta}_{\mathrm{LS}}-\theta^{*})||_{2}}
=\frac{\epsilon^{\top}\Psi\nu}{||\Psi \nu||_{2}}
&amp;&amp;=\frac{\epsilon^{\top}\Psi\nu}{||\nu||_{2}}

\\
&amp;
&amp;&amp;
&amp;&amp;=\frac{\tilde \epsilon^{\top}\Psi}{||\nu||_{2}}
&amp;&amp;\le&amp;&amp;\sup\limits_{u\in\mathbb{R}^{r}:||u||_{2}=1}\tilde{\epsilon}^{\top}u

\\
&amp; \iff
&amp;&amp;
&amp;&amp;||X(\theta^{*}-\widehat{\theta}_{\mathrm{LS}})||_{2}^{2}
&amp;&amp;\leq4 \cdot &amp;&amp;\sup\limits_{u\in\mathrm{R}^{r}:\|u\|_{2}=1}(\tilde{\epsilon}^{\mathsf{T}}u)^{2}
\end{alignat}\]</span>
$$</p>
<p>since <span class="math inline">\(\forall u \in \mathbb S^{r-1} : u^{\textsf{T}}\Psi^{\textsf{T}}\Psi u=u^{\textsf{T}}u=1\)</span>,<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> <span class="math inline">\(\forall s \in \mathbb R: \mathbb{E}[e^{s{\tilde{\epsilon}}^{\top}}u]=\mathbb{E}[e^{s\epsilon^{\top}\Psi u}]\leq e^{{\frac{s^{2}\sigma^2}{2}}}\)</span>.</p>
<p>이는 곧 <span class="math inline">\(\tilde \epsilon \in SG(\sigma^2)\)</span> 이라는 소리. 이때 <span class="math inline">\(X\sim SG(\sigma^2) \Longrightarrow Var(X) \le \sigma^2\)</span> (Lecture 2). 따라서 CS ineq. 에 의해 <span class="math inline">\(\mathbb{E}\left[\sup\limits_{u\in\mathbb{R}^{r}:\|u\|_{2}=1} ({\tilde{\epsilon}}^{\mathsf{T}}u)^{2}\right] \leq\sum\limits_{i=1}^{r}\mathbb{E}\left[{\widetilde{\epsilon}}_{i}^{2}\right]\leq r\sigma^{2}\)</span>. 이것이 thm 8.2. 의 첫번째 claim 을 증명.</p>
<p>bound in Probability 를 보이기 위해, 우리는 standard discretization argument 를 사용. <span class="math inline">\(N_{\frac12}\)</span> 를 <span class="math inline">\(\mathbb S^{r-1}\)</span> 의 <span class="math inline">\(\frac12\)</span>-covering 이라고 하자. 그러면 Lecture 4 에서의 결과물을 사용하는 것으로 <span class="math inline">\(\sup\limits_{u\in\mathbb{R}^{r}:\|u\|_{2}=1} \widetilde{\epsilon}^{\top}u\le2\operatorname*{max}_{u\in{N}_{\frac12}}\widetilde{\epsilon}^{\top}u\)</span> 가 얻어진다.</p>
<p>따라서 이하가 성립하며 이를 만족시키는 임의의 <span class="math inline">\(\delta\)</span> 를 잡았을때 이에서 파생되는 임의의 <span class="math inline">\(t\)</span> 를 얻는다.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
\mathbb{P}(\|X(\theta^{*}-{\widehat{\theta}}_{LS})\|_{2}^{2}\geq t)&amp;\leq\mathbb{P}{\Big(}\max\limits_{u\in{ N}_{\frac12}}({\tilde{\epsilon}}^{T}u)^{2}\geq \frac t {16}{\Big)}
\\
&amp;\leq \Bigg|{ N}_{\frac 12} \Bigg|e^{-{\frac{t}{32 \sigma^2}}}
\\
&amp;\leq5^{r}e^{-{\frac{t}{32 \sigma^2}}}

\\

\exists \delta: &amp;\le \delta &amp;&amp;\iff \exists t: t \ge 32 \sigma^2 \left \{ r \log 5 + \log \left( \frac {1} {\delta} \right) \right \}
\end{alignat}\]</span>
$$</p>
<p>따라서 with probability at least <span class="math inline">\(1-\delta\)</span>, <span class="math inline">\(||X(\theta^{*}-\hat{\theta}_{\mathrm{LS}})||_{2}^{2}\lesssim \sigma^{2}\{r+\log \left (\frac1 \delta \right)\}\)</span>.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="sparse-linear-regression" class="section level3" number="8.8.3">
<h3 number="8.8.3"><span class="header-section-number">8.8.3</span> Sparse linear regression</h3>
<p>이상을 통해 우리는 <span class="math inline">\(\frac d n \righarrow 0\)</span> 일 때 <span class="math inline">\(\hat \theta_{LS}\)</span> 가 consistent 함을 확인. 따라서 <span class="math inline">\(\frac d n \righarrow 0\)</span> 가 우리가 바랄 수 있는 최적의 condition. 특히 <span class="math inline">\(\frac d n\)</span> 이 0에서 bounded away 된 채로 남는다면 consistent estimator 를 획득하는 건 <strong>불가능</strong>함. (minimax point of view 에서는.) 이러한 이유로 <span class="math inline">\(d &gt; n\)</span> 상황에서 작업을 할 때는 unknown regression vector <span class="math inline">\(\theta^\ast\)</span> 에 추가적인 structure 을 얹는 게 필수가 됨. 이제 <span class="math inline">\(\theta^\ast\)</span> 의 대다수가 0이라는 조건인 <strong>sparse condition</strong> 에 대해서 논해보자.</p>
<p><br>
<br>
<br></p>
<div id="lasso" class="section level4" number="8.8.3.1">
<h4 number="8.8.3.1"><span class="header-section-number">8.8.3.1</span> Lasso</h4>
<p>linear model (8.1)에서 <span class="math inline">\(\theta\)</span> 의 support set <span class="math inline">\(S(\theta^{*})=\{j\in\{1,\ldots, d\}:\theta_{j}^{*}\not=0\}\)</span> 이 cardinality <span class="math inline">\(s=|S(\theta^\ast)| \overset{substantially}{&lt;} d\)</span>, 즉 s-sparse 인 상황 가정. regularized estimator 로서, <strong>lasso estimator</strong> <span class="math inline">\(\widehat{\theta}_{\mathrm{lasso}}=\arg\min\limits_{\theta\in\mathbb{R}^{d}}\left\{\frac{1}{2n}\|Y-X\theta\|_{2}^{2}+\lambda_{n}\|\theta\|_{1}\right\}\)</span> 는 이러한 sparse structural assumption 에 대한 설명력을 가진다. lasso esimator 는 for many <span class="math inline">\(j \in \{1, \cdots, d\}:\hat_{lasso, \; j} = 0\)</span> 라는 <strong>sparcity property</strong> 를 가지며 이건 <span class="math inline">\(\lambda_n\)</span> 을 무엇으로 골랐는지에 의존한다. 위의 등식 (8.3)은 <strong>lasso problem</strong> 이라고 불리며, 이는 convex optimization problem 이고, computationally tractable.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-23" class="lemma"><strong>(#lem:unlabeled-div-23) (Basic inequality) </strong></span>lasso estimator 에 대한 basic ineq.</p>
<p><span class="math display">\[
{\frac{1}{2n}}\|X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})\|_{2}^{2}\ \leq\ {\frac{\epsilon^{\top}X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})}{n}}+\lambda_{n}(\|\theta^{*}\|_{1}-\|\widehat{\theta}_{\mathrm{lasso}}\|_{1})
\]</span></p>
</div>
<ul>
<li>Proof.</li>
</ul>
<p>Lasso 의 정의에 의해,</p>
<p><span class="math display">\[
\frac{1}{2n}\Vert Y-X\widehat{\theta}_{\mathrm{lasso}}\Vert_{2}^{2}+\lambda_{n}\Vert\widehat{\theta}_{\mathrm{lasso}}\Vert_{1}\ \leq\ \frac{1}{2n}\Vert Y-X\theta^{*}\Vert_{2}^{2}+\lambda_{n}\Vert\theta^{*}\Vert_{1} = \frac{1}{2n} ||\epsilon||_2^2 + \lambda_n ||\theta^\ast ||_1
\]</span></p>
<p>그리고 MSE 를 확장하는 것으로</p>
<p><span class="math display">\[
{\frac{1}{2n}}\|Y-X{\widehat{\theta}}_{\mathrm{lasso}}\|_{2}^{2}\ =\ {\frac{1}{2n}}\|\epsilon\|_{2}^{2}+{\frac{1}{2n}}\|X({\widehat{\theta}}_{\mathrm{lasso}}-\theta^{*})\|_{2}^{2}+{\frac{\epsilon^{\top}X(\theta^{*}-{\widehat{\theta}}_{\mathrm{laaso}})}{n}}
\]</span></p>
<p>둘을 복합.</p>
<p><br>
<br>
<br></p>
</div>
<div id="slow-convergence-rate" class="section level4" number="8.8.3.2">
<h4 number="8.8.3.2"><span class="header-section-number">8.8.3.2</span> Slow convergence rate</h4>
<p>위에서의 basic inequality (lemma 8.3) 이 주어졌을 때, 우리는 lasso estimator <span class="math inline">\(\hat \theta_{lasso}\)</span> 의 consistency 를 보장하는 sufficient condition 생성 가능. 이는 deterministic bound 를 구하는 것부터 시작함.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-24" class="theorem"><strong>(#thm:unlabeled-div-24) (Slow Convergence Rate) </strong></span><span class="math inline">\(X_j\)</span> 를 <span class="math inline">\(X\)</span> 의 j-th column 이라고 하고, <span class="math inline">\(\lambda_{n}\,\geq\,\left|\left|\frac{X^{\top}\epsilon}{n}\right|\right|_{\infty}\ = \max_{i \le j \le d}\left|\frac{X_{j}^{\textsf{T}}\epsilon}{n}\right|\)</span> 라고 가정하자. 이 때 lasso estimator 는 이하를 만족.</p>
<p><span class="math display">\[
\frac{1}{n} \Bigg\| X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*}) \Bigg\| _{2}^{2}\leq4\lambda_{n} \Bigg\| \theta^{*} \Bigg\| _{1}
\]</span></p>
</div>
<ul>
<li>Proof:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}
\frac{1}{2n}||X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})||_{2}^{2}\ &amp;\leq\ \frac{\epsilon^{\top}X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})}{n}
&amp;&amp;+\lambda_{n}(||\theta^{*}||_{1}-||\widehat{\theta}_{\mathrm{lasso}}||_{1})

\\

&amp;\overset{(i)}{\le} {\frac{1}{n}}\|\epsilon^{\mathsf{T}}X\|_{\infty}\|\widehat{\theta}_{\mathrm{lasso}}-\theta^{*}\|_{1}
&amp;&amp;+\lambda_{n}(\|\theta^{*}\|_{1}-\|\widehat{\theta}_{\mathrm{lasso}}\|_{1})

\\

&amp;\overset{(ii)}{\le}\frac{1}{n}||\epsilon^{\top}X||_{\infty}(||\widehat{\theta}_{\mathrm{lasso}}||_{1}+||\theta^{*}||_{1})
&amp;&amp;+\lambda_{n}(||\theta^{*}||_{1}-||\widehat{\theta}_{\mathrm{lasso}}||_{1})

\\

&amp;= \|\widehat\theta_{\mathrm{lasso}}\|_{1}\left(\frac{1}{n}\|\epsilon^{\mathsf{T}}X\|_{\infty}-\lambda_{n}\right)
&amp;&amp;+\|\theta^{*}\|_{1}\left(\frac{1}{n}\|\epsilon^{\mathsf{T}}X\|_{\infty}+\lambda_{n}\right)

\\

&amp;\stackrel{(iii)}{\le}2\lambda_{n}\vert\vert\theta^{*}\|_{1}
\end{align}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li>휠더 부등식</li>
<li>triangle ineq.</li>
<li>(8.4) 의 <span class="math inline">\(\lambda_n\)</span> 에 대해 걸었던 condition.</li>
</ol>
<p>th, 8.4. 의 error bound 는 (8.4) 에서 <span class="math inline">\(\lambda_n\)</span> 에 대해 걸었던 condition 에 의존. 이제 좀 더 자세히 살펴보자.</p>
<ul>
<li><span class="math inline">\(lambda_n\)</span> 의 good choice 는 무엇인가?</li>
</ul>
<p>랜덤벡터 <span class="math inline">\(\epsilon \in SG(\sigma^2)\)</span> 이었음을 상기. 이제 <span class="math inline">\(\exists C&gt;0:\max\limits_{1\le j\le d} \|X_i\|_2 \le C\sqrt n\)</span> 라고 가정 assume 하자. 이때 <span class="math inline">\(\forall n, d:\max\limits_{ 1 \le j \le d}\left\{\frac{1}{n}\sum_{i=1}^{n}X_{i j}^{2}\right\}\le C\)</span> 가 성립한다. 이를 통해 standard argument 를 만들수 있다:</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
\mathbb{P}\!\left(\frac{1}{n}||\epsilon^{\textsf{T}}X||_{\infty}\geq t\right)\ 
&amp;= \mathbb{P}\!\left(\max\limits_{1\le j \le d} |X_{j}^{\textsf{T}}\epsilon|\geq\,t n\right)

\\
&amp;\leq\mathrm{~}\sum_{j=1}^{d}\mathbb{P}(|X_{j}^{\top}\epsilon|\geq\,t n)



\\

&amp;=\;\sum_{j=1}^{d}\mathbb{P}\left({\frac{|X_{j}^{\top}\epsilon|}{||X_{j}||_{2}}}\geq\,{\frac{t n}{||X_{j}||_{2}}}\right)


\\
&amp;\leq\ 2d\exp\left(-\,\frac{n^{2}t^{2}}{2\sigma^{2}\,\max\limits_{1\le j\le d}\,||X_{j}||^{2}}\right)



\\
&amp;\leq\ 2d\exp\left(-\,\frac{n t^{2}}{2C^{2}\sigma^{2}}\right) &amp;&amp;=\delta

\end{alignat}\]</span>
$$</p>
<p>마지막 ineq. 는 시작 전 더해둔 assumption <span class="math inline">\(\max\limits_{1\leq j\leq d}\|X_{j}\|_{2}\leq C{\sqrt{n}}.\)</span> 에 의해서 성립. 이제 <span class="math inline">\(t=\lambda_{n}^{*}=\sqrt{\frac{2\sigma^{2}C^{2}}{n} \left \{\log(\frac 1 \delta)+\log(\frac 2d) \right\}}\)</span> 를 하나 고르는 것으로, 우리는 with probability <span class="math inline">\(1-\delta\)</span> 에 의해 <span class="math inline">\({\frac{1}{n}}\|\epsilon^{\mathsf{T}}X\|_{\infty}\leq\lambda_{n}^{*}\)</span> 가 성립한다는 사실을 파악할 수 있다.</p>
<p>따라서 <span class="math inline">\(\delta = \frac 1n\)</span> 으로 잡는 것으로, thm 8.4 를 적용하는 것으로 <span class="math inline">\(\lambda_n^\ast\)</span> 가 주어진 lasso estimator 는 이하를 보장한다.</p>
<p><span class="math display">\[
{\frac{1}{n}}\|X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})\|_{2}^{2}\lesssim \|\theta^{*}\|_{1} \cdot \sigma\sqrt{\frac{\log(d)+\log(n)}{n}}
\]</span></p>
<p>여기에 추가로 <span class="math inline">\(\max\limits_{1\leq j\leq d}\left|\theta_{j}^{\ast}\right|\)</span> 가 uniformly bounded 되어 있다고 suppose 한다면? 그 경우 <span class="math inline">\(\theta^\ast\)</span> 의 <span class="math inline">\(s\)</span>-sparcity 하에서, <span class="math inline">\(s \sqrt{\frac {\log(d)} n} \rightarrow 0\)</span> 이 1번이라도 발생한 순간 MSE 는 0으로 간다.</p>
<ul>
<li>Parameter Estimation</li>
</ul>
<p>위에서 언급되었 듯이, <span class="math inline">\(\d \le n\)</span> 이며 <span class="math inline">\(\lambda_{\mathrm{min}} \left(\frac{X^{\textsf{T}}X}n \right)\;\geq\;C_{\mathrm{min}}\;\gt \;0,\)</span> 일 경우, 앞의 결과는 이하를 보장한다. 안타깝게도 이 전략은 <span class="math inline">\(d&gt;n\)</span> 인 경우에는 작동하지 않는다. <span class="math inline">\(X&#39;X\)</span> 가 rank-deficient 가 되어 버리므로.</p>
<p><span class="math display">\[
||{\widehat\theta}_{\mathrm{lasso}}-\theta^{*}||_{2}^{2} \lesssim {\frac{||\theta^{*}||_1}{C_{\mathrm{min}}}} \cdot \sigma\sqrt{\frac{\log(d)+\log(n)}{n}}
\]</span></p>
<p><br>
<br>
<br></p>
</div>
<div id="fast-convergence-rate" class="section level4" number="8.8.3.3">
<h4 number="8.8.3.3"><span class="header-section-number">8.8.3.3</span> Fast Convergence Rate</h4>
<p>디자인 매트릭스 <span class="math inline">\(X\)</span> 에 추가적인 assumption 을 붙이는 것으로 좀 더 빠른 convergence rate 를 얻는 것이 가능. 여기선 Restricted Ev (RE) condition 을 사용할 것. <span class="math inline">\(\{ 1, \cdots, d\}\)</span> 의 subset <span class="math inline">\(S\)</span> 에 대해 <span class="math inline">\(Z_S = (Z_{S,1}, \cdots, Z_{S, d}) \in \mathbb R^d)\)</span> 이며 <span class="math inline">\(\forall j \in S:Z_{S,j} = Z_j\)</span>, o.w. <span class="math inline">\(Z_{S, j} = 0\)</span> 으로 정의.</p>
<p><span class="math inline">\(S^c\)</span> 를 <span class="math inline">\(S\)</span> 의 complement 로 잡자. 즉슨 <span class="math inline">\(Z_{S^c}\)</span> 도 <span class="math inline">\(Z_S\)</span> 와 유사하게 정의. 이때 <span class="math inline">\(\forall \alpha\ge1:C(\alpha,S)=\{\Delta\in\mathbb{R}^{d}:||\Delta_{S^{c}}||_{1}\leq\alpha\|\Delta_{S}\|_{1}\}\)</span>. 이 notation 들을 써서 이하 정의.</p>
<div class="definition">
<p><span id="def:unlabeled-div-25" class="definition"><strong>(#def:unlabeled-div-25) (RE condition) </strong></span>매트릭스 <span class="math inline">\(X\)</span> 는 이하를 만족할 경우, 패러미터 <span class="math inline">\((\alpha, \kappa)\)</span> 와 함께 <span class="math inline">\(S\)</span> 에 대해 <strong>RE condition</strong> 을 만족한다.</p>
<p><span class="math display">\[
forall \Delta\in C(\alpha,S):{\frac{1}{n}}\|X\Delta\|_{2}^{2}\geq\kappa\|\Delta\|_{2}^{2}
\]</span></p>
</div>
<ul>
<li>Remark.</li>
</ul>
<p>RE condition 에 대한 직관을 좀 얻어보자. cost difference <span class="math inline">\(\mathcal{L}_{n}(\widehat{\theta}_{\mathrm{lasso}})-\mathcal{L}_{n}(\theta^{*})=\frac{1}{2n}\vert\vert Y-X\widehat{\theta}_{\mathrm{lasso}}\vert\vert_{2}^{2}-\frac{1}{2n}\vert\vert Y-X\theta^{*}\vert\vert_{2}^{2}\)</span> 가 작다면, error vector <span class="math inline">\(\hat \theta_{lasso} - \theta^\ast\)</span> 도 또한 작다는 것을 장담할 수 있을까? 일반적으로 이는 그렇다고 할 수 없다. 특히 cost function <span class="math inline">\(\mathcal L_n(\theta)\)</span> 가 <strong>flat</strong> 할 경우에는 더더욱. 이 flat 상황을 피하기 위해 cost function <span class="math inline">\(\mathcal L_n (\theta)\)</span> 로 하여금 이의 optimum <span class="math inline">\(\hat \theta_{lasso}\)</span> 주위에서 높은 <strong>curvature</strong> 를 갖도록 하는 것이 요구됨. <strong>curvature</strong> 는 Hessian MAtrix <span class="math inline">\(\nabla^{2}{\mathcal{L}}_{n}(\theta)={\frac{1}{n}}X^{\top}X\)</span> 의 구조에 의해 결정됨. 만약 우리가 이 Hessian Matrix 의 ev 가 0 에서 bounded away 되었다고 장담할 수 있다면, 즉, <span class="math inline">\(\forall \Delta\in\mathbb{R}^{d}\setminus\{0\}:\frac{1}{n}||X\Delta||_{2}^{2}\geq\kappa||\Delta||_{2}^{2}\gt 0\)</span> 라면, 우리는 모든 지점에서 curvature 를 갖는다는 것을 확신할 수 있을 것.</p>
<p>하지만 고차원 상황 <span class="math inline">\(d&gt;n\)</span> 에서는 Hessian Matrix 는 0 ev 를 가져야만 하고, condition (8.7) (바로 위 상황) 은 성립할 수 없다. 역으로 우리는 <span class="math inline">\(C(\alpha, S)\)</span> 로 정의된 특정한 지점에서 cost function 이 curved 한지를 고려한다. 이 직관을 써서 RE condition 하에서 lasso estimator 에 대한 deterministic bound 를 생산할 수 있다. 이것이 아래의 thm.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-32" class="theorem"><strong>(#thm:unlabeled-div-32) (Fast Convergence Rate) </strong></span>linear model (8.1) 을 살피고, <span class="math inline">\(S=\{i : \theta^\ast_i \not = 0 \}\)</span> 에 대해 패러미터 <span class="math inline">\((3, \kappa)\)</span> 를 통해 RE condition 을 만족하는 <span class="math inline">\(X\)</span> 를 assume. 이때, <span class="math inline">\(S\)</span> 의 cardinality 가 <span class="math inline">\(s\)</span> 를 쓰자. 여기서 만약 <span class="math inline">\(\lambda_{n}\geq2\left\| \frac{X^{\textsf{T}}\epsilon}{n}\right\|_{\infty}\)</span> 가 성립한다면 이하가 성립.</p>
<p><span class="math display">\[
{\frac{1}{n}}||X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})||_{2}^{2}\leq9{\frac{s\lambda_{n}^{2}}{\kappa}}, \; \; \; \; \; \; \; \; \; \; \; ||\widehat{\theta}_{\mathrm{lasso}}-\theta^{*}||_{2} \le3{\frac{\sqrt{s}\lambda_{n}}{n}}
\]</span></p>
<ul>
<li>Proof:</li>
</ul>
<p>편의를 위해 <span class="math inline">\(\hat \Delta = \hat \theta_{lasso} - \theta^\ast\)</span>. 주어진 condition 하에서 <span class="math inline">\(\hat \Delta \in C(3, S)\)</span> 임을 먼저 보이자. basic ineq. (lemma 8.3) 을 사용하면 <span class="math inline">\({\frac{1}{2n}}||X\hat{\Delta}||_{2}^{2}\; \leq \;{\frac{\epsilon^{\top}X\hat{\Delta}}{n}}+\lambda_{n}(||\theta^{*}||_{1}-||\hat{\theta}_{\mathrm{lasso}}||_{1})\)</span> 임을 보일 수 있다. <span class="math inline">\(\theta^\ast\)</span> 가 s-sparse 이며 <span class="math inline">\(\hat \Delta = \hat \theta_{lasso}-\theta^\ast\)</span> 이므로 이하가 성립.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
\|\theta^{*}\|_{1}-\|{\widehat{\theta}}_{\mathrm{lasso}}\|_{1}

&amp;=\|\theta_{S}^{*}\|_{1}-\|\widehat{\theta}_{\mathrm{lasso}}\|_{1}

\\

&amp;= \| \theta_{S}^{*}\|_{1}-\|{\hat{\Delta}}+\theta^{*}\|_{1} 

\\

&amp;=\|\theta_{S}^{*}\|_{1}
&amp;&amp;-\|\widehat{\Delta}_{S}+\theta_{S}^{*}\|_{1} - \| \hat \Delta_{S^c} \|_1

\\

&amp;\leq \|\hat{\Delta}_{S}\|_{1}+\ \|\widehat{\Delta}_{S}+\theta_{S}^{*}\|_{1} 
&amp;&amp;-  \|\widehat{\Delta}_{S}+\theta_{S}^{*}\|_{1}\nonumber-\|\widehat{\Delta}_{S^{c}}\|_{1}\nonumber \tag{triangle ineq.}

\\

&amp;= \| \hat \Delta_S \|_1 - \| \hat \Delta_{S^c}\|_1
\end{alignat}\]</span>
$$</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
0\;\leq\;\frac{1}{n}\Vert X\hat{\Delta}\Vert_{2}^{2}
&amp;\stackrel{(i)}{\le}\;\frac{2}{n}\Vert\epsilon^{\top}X\Vert_{\infty}\Vert\hat{\Delta}\Vert_{1}
&amp;&amp;+2\lambda_{n}(\Vert\hat{\Delta}_{S}\Vert_{1}-\Vert\hat{\Delta}_{S^{c}}\Vert_{1})

\tag{Holder}

\\

&amp;
{\stackrel{\mathrm{(ii)}}{\leq}}\ \ \lambda_{n}\|{\widehat\Delta}\|_{1}
&amp;&amp;+2\lambda_{n}(\|{\hat\Delta}_{S}\|_{1}-\|{\hat\Delta}_{S^{c}}\|_{1})

\tag{condition (8.8) on λ_n}

\\


&amp;= \lambda_n (\| \hat \Delta_S \|_1 + \| \hat \Delta_{S^c}\|_1 ) 
&amp;&amp;+2\lambda_n (\| \hat \Delta_S \|_1 - \| \hat \Delta_{S^c}\|_1 )

\\


&amp;=\lambda_{n}(3||\widehat\Delta_{S}||_1-||\widehat\Delta_{S^{c}}||_1)
\end{alignat}\]</span>
$$</p>
<p>이를 통해 <span class="math inline">\(\hat \Delta \in C(3,S)\)</span> 라고 결론지을 수 있으며, 우리는 <span class="math inline">\(X\)</span> 가 패러미터 <span class="math inline">\((3, \kappa)\)</span> 와 함께 RE condition 을 만족한다고 assume 했으므로, 이는 곧 <span class="math inline">\({\frac{1}{n}}\|X{\hat{\Delta}}\|_{2}^{2}\geq\kappa\|{\hat{\Delta}}\|_{2}^{2}\)</span> 라는 것을 보여준다.</p>
<p>앞의 과정을 다시 사용해서 이제</p>
<p>$$
<span class="math display">\[\begin{align}
{\frac{1}{n}}\|X{\widehat{\Delta}}\|_{2}^{2}\;&amp;\leq\;\lambda_{n}(3\|\widehat{\Delta}_{S}\|_{1}-\|\widehat{\Delta}_{S^{c}}\|_{1})\leq3\lambda_{n}\|\widehat{\Delta}_{S}\|_{1}

\\

&amp;\overset{(i)}{\le} 3 \lambda_{n}\sqrt{s}||\hat{\Delta}_{S}||_{2} \tag{1}

\\

&amp;\leq\ 3\lambda_{n}\sqrt{s}||\hat{\Delta}||_{2}

\\

&amp;\overset{(ii)}{\le}\frac{3\lambda_{n}\sqrt{s}}{\sqrt{n\kappa}}\|X\widehat{\Delta}\|_{2} \tag{ineq. (8.9)}

\\

\iff {\frac{1}{n}}\|X(\widehat{\theta}_{\mathrm{lasso}}-\theta^{*})\|_{2}^{2} &amp; \leq9{\frac{s\lambda_{n}^{2}}{\kappa}}
\end{align}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\forall x\in\mathbb{R}^{d},\,\|x\|_{1}\leq{\sqrt{d}}\|x\|_{2}\)</span></li>
</ol>
<p>따라서 위의 마지막 ineq. 와 ineq. (8.9) 를 다시 한번 적용하면 증명 완료.</p>
<ul>
<li>Remark.</li>
</ul>
<p><span class="math inline">\(\lambda_{n} \asymp \sigma\sqrt{\frac{\log(d)+\log(n)}{n}}\)</span> 상황이라고 가정하자. 이 경우 design 매트릭스에 (8.5) 와 유사한 condition 을 두고 같은 argument 를 적용하면 <span class="math inline">\(\lambda_{n}\geq2 \left \| \frac{X^{\top}\epsilon}{n} \right \|_{\infty}\)</span> with probability at least <span class="math inline">\(1-\frac {1} {n^c}\)</span> for some constant <span class="math inline">\(c&gt;0\)</span> 임을 보일 수 있다. 이는 또한 (<span class="math inline">\(d \gg n\)</span> 일 때) <span class="math inline">\({\frac{1}{n}}\|X({\widehat{\theta}}_{\mathrm{lasso}}-\theta^{*})\|_{2}^{2}\lesssim{\frac{s\log(d)}{n}}\)</span> 라는 것으로도 이어지며, 따라서 RE condition 하에서 once <span class="math inline">\(\frac{s \log(d)}{n}\rightarrow 0\)</span> 라면 lasso estimator 는 consistent 하다.</p>
<p>이와 별개로 <span class="math inline">\(\lim\limits_{n \rightarrow \infty} \lambda_n = 0\)</span> 를 가정하는 것으로, thm 8.6 의 결과가 8.4의 결과를 former의 upper bound 가 <span class="math inline">\(\lambda_n\)</span> 이 아니라 <span class="math inline">\(\labmda_n^2\)</span> 에 의존한다는 것으로 진화시킨다는 것을 발견할 수 있다.</p>
<!--chapter:end:212308_LR.Rmd-->
<div id="survival-analysis" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> Survival Analysis</h1>
<div id="introduction-5" class="section level2" number="9.1">
<h2 number="9.1"><span class="header-section-number">9.1</span> Introduction</h2>
<ol style="list-style-type: decimal">
<li><p>SA의 결과물은 보통 <em>time-to-event</em>, 즉슨 대부분의 경우에 nonnegative이며, 이는 곧 time domain을 한정함.</p></li>
<li><p>time-to-event의 distribution은 보통 <em>skewed</em>.</p></li>
<li><p>Survival data은 자주 <em>right censored</em>. 조사 대상자들은 조사 기간중에만 생존했음을 알며, 조사 기간 넘어서 죽으면 해당 시간이 정확히 기록되지 않음.</p></li>
<li><p>tail probability. 충분한 후속연구 후에는, tail of survival curve에 해당하는 subject들이 보통 되게 적음. estimation of the tail of the survival curve can be quite difficult. tail에서 survival density는 엄청 적어짐. 따라서 총 표본 수가 많이 확보되어 있지 않으면 tail에 해당하는 분석결과는 확보하기가 어렵다.</p></li>
<li><p>모든 연구의 시간은 finite이므로 모든 subjects들에게서 발생한 event of interest 중 일부는 육안으로 관찰 못 할수도 있다. 장기적으로 발생은 했는데, 그게 우리 손닿는 곳에서 터지지 않았음.</p></li>
<li><p>일반적으로 관측안된 failure time 들이 포함되어 있으면 기존 통계 테크닉은 사용할 수 없음.</p></li>
<li><p>failure time 이 관측되지 않은 subject들은 censored 되었다고 표현.</p></li>
<li><p>censored observations를 포함한 자료에서 정보를 뽑아내는 것이 SA의 estimation methods의 목적.</p></li>
</ol>
<div id="censoring-sources" class="section level4" number="9.1.0.1">
<h4 number="9.1.0.1"><span class="header-section-number">9.1.0.1</span> Censoring Sources</h4>
<ol style="list-style-type: decimal">
<li>Adminisitrative censoring</li>
</ol>
<ul>
<li>event 발생 전에 연구 종료
often independent of failure time</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Loss to follow-up</li>
</ol>
<ul>
<li>subject들이 더이상 트랙 불과, 관찰 하에 있지 않음 (후속연구 개시했는데 예전에 살던 사람이 동네 떠났음)
censoring may be related (indirectly) to the failure time</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>withdrawl from study</li>
</ol>
<ul>
<li>너무 아프거나 증상이 낫던가 해서 연구에서 이탈
dependent censoring (<em>informative drop-out</em>), censoring이 failure time에 연관되어 있다는 점이 고민해야할 거리가 된다.</li>
</ul>
<div id="임시방편" class="section level9" number="9.1.0.1.0.0.0.0.1">
<p class="heading" number="9.1.0.1.0.0.0.0.1"><span class="header-section-number">9.1.0.1.0.0.0.0.1</span> 임시방편</p>
<ol style="list-style-type: decimal">
<li><p>censor된 시간을 failure time으로 인식. <span class="math inline">\(\bar X \le E(X)\)</span> (underestimate).</p></li>
<li><p>censor 관측치를 전부 삭제. loss of infomration.</p></li>
</ol>
</div>
<div id="notation-1" class="section level6" number="9.1.0.1.0.1">
<h6 number="9.1.0.1.0.1"><span class="header-section-number">9.1.0.1.0.1</span> notation</h6>
<p><span class="math inline">\(T_i\)</span>: potential failure time for the i-th subject
<span class="math inline">\(C_i\)</span>: potential censoring time for the i-th subject
<span class="math inline">\(X_i = \min(T_i , C_i )\)</span> observed time
<span class="math inline">\(\delta_i = \begin{cases} 1, &amp; T_i \le C_i &amp; \text{(uncensored)} \\ 0, &amp; T_i &gt; C_i &amp; \text{(censored)} \end{cases}\)</span></p>
</div>
</div>
<div id="right-censoring-most-of-the-course" class="section level4" number="9.1.0.2">
<h4 number="9.1.0.2"><span class="header-section-number">9.1.0.2</span> Right Censoring (most of the course)</h4>
<p>Fail이 확실하게 터진 경우에만 fail, 이외의 경우에는 censor. 조사기간 종료까지 발병하지 않았거나, 이외의 이유로 종료 이전에 연구 이탈하면 양쪽 모두 censored.</p>
<div id="type-of-data-to-be-analyzed-in-survival-analysis" class="section level6" number="9.1.0.2.0.1">
<h6 number="9.1.0.2.0.1"><span class="header-section-number">9.1.0.2.0.1</span> Type of Data to be analyzed in survival analysis</h6>
<ol style="list-style-type: decimal">
<li>Type Ⅰ Censoring:
특정 시점이 왔을 때 연구 종료. ex) 쥐한테 특정 영양소 먹이고 언제까지 생존하는지</li>
</ol>
<ol style="list-style-type: decimal">
<li>Progressive Type Ⅰ Censoring: 대상들이 다른, 고정된 sacrifice time 보유 ex) 도즈 레벨 4개로 나누고 각 그룹에 다른 sacrifice 기간 적용, 비용 효율화</li>
<li>Generalized Type Ⅰ Censoring: subject들이 각각 다른 시기에 연구에 참여개시하고 정해진 시간에 연구 종료됨. subject가 참여할 때 censoring time 다 알려짐.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Type Ⅱ Censoring:
reliabilty 분석에서 흔함. 특정 횟수 failure 발생시 연구 종료.</li>
</ol>
<p>※ Right Censoring: 개인의 정확한 survival time은 follow-up period의 우측에서는 incomplete해짐.</p>
<ol start="3" style="list-style-type: decimal">
<li>Random Censoring:
Censoring times are random.</li>
</ol>
<p>※ let’s focus on right censoring. Suppose <span class="math inline">\(T_1 , \cdots, T_n \sim f(t)\)</span> and <span class="math inline">\(C_1 , \cdots, C_n \sim g(c)\)</span>. Then, we observe <span class="math inline">\(X_i = \min(T_i , C_i )\)</span> for <span class="math inline">\(i = 1, \cdots, n\)</span>. In type Ⅰ censoring, <span class="math inline">\(C_i\)</span> is fixed (at <span class="math inline">\(C_r\)</span> or <span class="math inline">\(C_{r_i}\)</span>). In random censoring, <span class="math inline">\(C_i\)</span> is random.</p>
</div>
</div>
<div id="left-censoring" class="section level4" number="9.1.0.3">
<h4 number="9.1.0.3"><span class="header-section-number">9.1.0.3</span> Left Censoring</h4>
<p>less common in practice</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda(t) S(t)&amp;= f(t) \\

\lambda(t) &amp;= \dfrac{f(t)}{S(t)} \\

\lambda(t) &amp;= \dfrac{f(t)}{} \dfrac{d}{dS(t)}\log S(t) \\


\end{align}\]</span>
$$</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda(t) &amp;= - \dfrac{d}{dt} \log S(t) \\

\lambda(t) &amp;= - \dfrac {dS(t)}{dt} \dfrac{d}{dS(t)} \log S(t) \\

\lambda(t) &amp;= - \dfrac {d[1-F(t)]}{dt} \dfrac{1}{S(t)} \\

\lambda(t) &amp;= - (-f(t)) \dfrac{1}{S(t)} \\

S(t)\lambda(t) &amp;= f(t)

\end{align}\]</span>
$$</p>
<p><span class="math display">\[
A = A&#39;\; \; \; \Longrightarrow \; \; \; \exists \text{basis for } C(A):\text{constisting of evec of nonzero ev&#39;s.}
\]</span></p>
<p>linear transformation, span, trace, nonsingular, null space</p>
<p><span class="math display">\[
tr(ABC) = tr(BCA)=tr(CAB)
\]</span>
<span class="math display">\[
r(A_{n \times n})=r, \; \; \; r[\mathcal{N}(A)] = n-r
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> is ev of <span class="math inline">\(A\)</span>, <span class="math inline">\(v\)</span> is evec of <span class="math inline">\(A\)</span>.</p>
<p>$$
<span class="math display">\[\begin{alignat}{3}

&amp;\forall \lambda_i \not = 0 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp;
&amp;&amp; \forall v_i : 
&amp;&amp; span(v_i) \subset \mathcal{C}(A)

\\

&amp;A = A&#39;, \; \lambda_i \not = \lambda_j 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; v_i \perp v_j,
&amp;&amp;
&amp;&amp;span(v_i, v_j) \subset \mathcal{C}(A)


\\

&amp;\exists A^{-1} 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; \prod \lambda\not = 0
&amp;&amp;
&amp;&amp;

\\

&amp;A = A&#39;
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; 
&amp;&amp;
&amp;&amp;\exists \text{basis for } \mathcal{C}(A) \text{ consists of } v_i \text{ of } \lambda_i \not = 0



\\

&amp;A_{n \times n} = A&#39;, \; \prod \lambda \not = 0 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; \mathcal C (A)=\mathbb R^n,
&amp;&amp;
&amp;&amp;span( v) = \mathbb{R}^n



\\

&amp;A_{n \times n} = A&#39;, \; \forall \lambda_i \not = 0 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; 
&amp;&amp;
&amp;&amp;span(\forall v_i) = \mathcal{C}(A) \subset \mathbb{R}^n






\\

&amp;A_{n \times n} = A&#39;, \; \forall \lambda_i  = 0 
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; 
&amp;&amp;
&amp;&amp;span(\forall v_i) = \mathcal{N}(A)

\\

&amp;A = A&#39;
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; 
&amp;&amp;
&amp;&amp;\mathcal{N}(A) = \mathcal C (A)^\perp

\\

&amp;A_{n \times n} = A&#39;
&amp;&amp;\; \; \; \Longrightarrow \; \; \; 
&amp;&amp; 
&amp;&amp;
&amp;&amp;


\exists v_i : span(v_i) = \mathcal C (A), \; v_i \perp v_j 
\; \; \tiny {\bigoplus} \; \; \normalsize \exists A^{-1} : \mathcal C(A) = \mathbb{R}^n
\; \; \tiny {\bigoplus} \; \; \normalsize \text{if normalized, orthonormal}

\end{alignat}\]</span>
$$</p>
<!--chapter:end:212501_Intro.Rmd-->
</div>
</div>
<div id="section-4" class="section level2" number="9.2">
<h2 number="9.2"><span class="header-section-number">9.2</span> </h2>
<!--chapter:end:212502.Rmd-->
</div>
<div id="counting-processes-and-martingales" class="section level2" number="9.3">
<h2 number="9.3"><span class="header-section-number">9.3</span> Counting Processes and Martingales</h2>
<p>1샘플 estimator 를 위해 counting process 사용했었음. 이에서 N-A estimator 의 asymptotic 성질을 확인했고. 하지만 아직 <span class="math inline">\(n^{\frac 12} \{ \hat \Lambda(t) - \Lambda(t)\}\)</span> 의 limiting distribution 을 획득하진 않았고. <span class="math inline">\(\hat \Lambda(t)\)</span> 의 성질을 얻는데 있어서는 conditioning 이 핵심. 모든 이론적 기반은 이 conditioning 에 있음. Martingales 포함. Martingale Central Limit Theorem (MCLT) 은 자동적으로 Normal 로의 convergence 가 보장되는 마일드한 condition 이하에서 성립되었음.</p>
<p><br>
<br>
<br></p>
<div class="definition">
<p><span id="def:unlabeled-div-26" class="definition"><strong>(#def:unlabeled-div-26) (Probability space) </strong></span>모든 가능한 결과의 abstract space Ω, σ-algebra <span class="math inline">\(\mathcal F\)</span>, set function (measure) <span class="math inline">\(P\)</span> 가 주어졌을 때 확률공간 (Probability space) <span class="math inline">\((Ω, \mathcal F, P)\)</span> 가 성립.</p>
</div>
<p><span class="math inline">\(\mathcal A\)</span> 가 <span class="math inline">\(\Omega\)</span> 로부터의 결과값의 subset 의 collection 이라고 하자.
- 이하를 만족하면 <span class="math inline">\(\mathcal A\)</span> 는 <strong>algebra</strong>.
1. <span class="math inline">\(E \in \mathcal A\)</span> 이 complement <span class="math inline">\(\bar E \in \mathcal A\)</span> 를 보장
2. <span class="math inline">\(E_1 \in \mathcal A\)</span> 이며 <span class="math inline">\(E_2 \in \mathcal A\)</span> 인 것이 <span class="math inline">\(E_1 \cup E_2 \in \mathcal A\)</span> 를 보장
- 이하를 만족하면 <span class="math inline">\(\mathcal A\)</span> 는 <strong><span class="math inline">\(\sigma\)</span>-algebra</strong>.
1. <span class="math inline">\(E \in \mathcal A\)</span> 이 complement <span class="math inline">\(\bar E \in \mathcal A\)</span> 를 보장
2. <span class="math inline">\(\forall j=1,2,\cdots:E_j \in \mathcal A\)</span> 가 <span class="math inline">\(E_1 \cup E_2 \cdots \in \mathcal A\)</span> 를 보장</p>
<p>즉 <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> 는 <strong>countable union</strong> 과 <strong>intersection</strong> 에 <strong>closed</strong> 인 collection of events.</p>
<p><br>
<br>
<br></p>
<div class="definition">
<p><span id="def:unlabeled-div-27" class="definition"><strong>(#def:unlabeled-div-27) (Stochastic Process) </strong></span>랜덤변수의 collection <span class="math inline">\(X=\{X(t) ; t \in \mathcal T\}\)</span>^[흔히 <span class="math inline">\(\mathcal T = [0,\infty)\)</span>, 혹은 <span class="math inline">\(\mathcal T = (0,\tau_\ast)\)</span> where <span class="math inline">\(\forall n=1, \cdots, n:P(X_i &gt; \tau_\ast)&gt;0\)</span>.] 가 같은 확률공간 안에서 정의되어 있을때 이는 <strong>Stochastic Process</strong>.</p>
<p>e.g., 주어진 확률공간 <span class="math inline">\((Ω, \mathcal F, P)\)</span> 과 measurable space <span class="math inline">\((S, \Sigma)\)</span> 에서, <span class="math inline">\(S\)</span>-valued 랜덤변수들의 collection 을 <strong>stochastic process</strong> 라고 하며, 이는 <span class="math inline">\(X=\{X(t) ; t \in \mathcal T\}\)</span>.</p>
<p>이때 <span class="math inline">\(S\)</span> 는 mathematical space 이며 이건 <span class="math inline">\(\sigma\)</span>-algebra 에 비추어 measurable 해야함.</p>
</div>
<p>Stochastic Process 의 실현값 을 <strong>Path</strong> 라고 부른다. 여기 path 에 이하의 조건이 더해진다면 이는 추가로 <strong>counting process</strong><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.</p>
<ol style="list-style-type: decimal">
<li>non-decreasing</li>
<li>piece-wise constant</li>
<li>cadlag</li>
<li>step-function with increments of size 1</li>
</ol>
<p><br>
<br>
<br></p>
<div class="definition">
<p><span id="def:unlabeled-div-28" class="definition"><strong>(#def:unlabeled-div-28) (Filtration) </strong></span><span class="math inline">\(\sigma\)</span>-algebra 들의 increasing family, e.g., <span class="math inline">\(\{\mathcal F_t : t \ge 0\}\)</span></p>
<p>increasing Filtration 이라는 것은 <span class="math inline">\(s\get: \mathcal F_s \subset \mathcal F_t\)</span>, e.g., <span class="math inline">\(A \in \mathcal F_s \Longrightarrow A \in \mathcal F_t\)</span>.</p>
</div>
<p><span class="math inline">\(\forall t: X(t)\)</span> 가 <span class="math inline">\(\mathcal F_t\)</span>-measurable 일 경우, stochastic process <span class="math inline">\(X\)</span> 는 <strong>adapted</strong> to <span class="math inline">\(\mathcal F_t\)</span>. 특히, 변량에 대해 유의미한 probability statement 가 서술될 수 있다면 이 변량은 measurable.</p>
<ul>
<li><span class="math inline">\(X(t)\)</span> 가 <span class="math inline">\(\mathcal F_t\)</span> 에 adapted <span class="math inline">\(\iff\)</span> <span class="math inline">\(E \Big [X(t) \Bigg | \mathcal F_t \Big] = X(t)\)</span>.</li>
</ul>
<p>모든 process 는 그 자신의 역사 (과거 실현값) 에 adapted. SA 에서는 <span class="math inline">\(\mathcal F_t\)</span> = own history, e.g., <span class="math inline">\(\mathcal F_t = \sigma \{X(s); 0 \le s\ le t\}\)</span> 로 두는 것이 편리하고 쓸만함. 이때 <span class="math inline">\(\mathcal F_t\)</span> 는 <span class="math inline">\((0, t]\)</span> 에 걸친 <span class="math inline">\(X\)</span> 의 실현값, 즉 <span class="math inline">\(X\)</span> 에 의해 생산된 모든 데이터를 담고 있음. 일례로 <span class="math inline">\(\mathcal F_t\)</span> 는 선풍기들이 돌기 시작한 시점부터 선풍기 전부를 관찰하고 있던 관찰자의 뇌속 기억. 언제 고장났는지 혹은 censoring 당했는지 다 암.</p>
<p>자주 쓰이는 filtration 은 <span class="math inline">\(\mathcal F_t = \sigma \{ N_i (s) , Y_i (s+) \; ; \; s\in (0,t], i=1, \cdots, n\}\)</span>.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="conditional-expectation" class="section level3" number="9.3.1">
<h3 number="9.3.1"><span class="header-section-number">9.3.1</span> Conditional Expectation</h3>
<p>랜덤변수 <span class="math inline">\(X\)</span> 가 <span class="math inline">\(\mathcal F\)</span>-measurable 이며 <span class="math inline">\(\mathcal G \subset \mathcal F\)</span> 이라면:</p>
<p><span class="math display">\[
\begin{align}
E(X|\mathcal F) &amp;= X
\\
E(aX|\mathcal F) &amp;= aX
\\
E(XY|\mathcal F) &amp;= X \cdot E(Y|\mathcal F)
\\
E(X | \mathcal G) &amp;= \mathcal G \text{-measurable}
\\
\forall \text{ events } B \in \mathcal G : E \Big[X \cdot I(B) \Big] &amp;= E \Big[E(X|\mathcal G) \cdot I(B) \Big]
\end{align}
\]</span></p>
<p>이하의 조건이 만족된다면 Stochastic Process 는 tag 안의 property 가 성립.</p>
<p><span class="math display">\[
\sup\limits_{t\in T}E[|X(t)|]\lt \infty\
\tag{integrable}
\\
\sup\limits_{t\in{\mathcal{T}}}E[X(t)^{2}]\lt \infty
\tag{square integrable}
\\
P\left\{\operatorname*{sup}_{t\in T}|X(t)|\lt c\right\}=1
\tag{uniformly bounded}
\]</span></p>
<p><br>
<br>
<br></p>
<p>counting process <span class="math inline">\(N(t)\)</span>, filtration <span class="math inline">\(\mathcal F_t\)</span> 가 있을때, 이에 엮인 intensity process <span class="math inline">\(A(t)\)</span> 는 다음과 같다.</p>
<p>set <span class="math inline">\(A(t)=\int_0^t dA(s)\)</span>. where</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
d A(t) &amp;= E[d N(t)]\mathcal{F}_{t^{-}}] &amp;&amp; &amp;&amp; =Y(t)\lambda(t)d t

\\

&amp;=\lim\limits_{d t\uparrow0}E[N(t^{-}+d t)-N(t^{-}) &amp;&amp;| {\mathcal{F}}_{t^{-}}]
\tag{1}

\\

&amp;=\lim\limits_{d\uparrow 0}\{N(t^{-}+d t)-N(t^{-})=1 &amp;&amp;\vert{\mathcal F}_{t^{-}}\}
\tag{2}
\end{alignat}\]</span>
$$</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathcal F_{t^-}\)</span> 는 (0, t) 에 대한 정보 보유.</li>
<li><span class="math inline">\([t, t+dt)\)</span> 에서 event 발생이 1번을 초과할 가능성은 negligable 하다고 set. 즉, <span class="math inline">\(\lim\limits_{d t\downarrow0}P\{N(t^{-}+d t)-N(t^{-})\gt 1|\mathcal{F}_{t^{-}}\}\;=\;\ o(d t^{2})\)</span>.</li>
</ol>
<p><br>
<br>
<br></p>
</div>
<div id="martingale" class="section level3" number="9.3.2">
<h3 number="9.3.2"><span class="header-section-number">9.3.2</span> Martingale</h3>
<div class="definition">
<p><span id="def:unlabeled-div-29" class="definition"><strong>(#def:unlabeled-div-29) (Martingale) </strong></span>이하의 조건을 만족할 때, right-continuous 인 stochastic process <span class="math inline">\(X=\{X(t):t \ge 0\}\)</span> 는 filtration <span class="math inline">\(\{\mathcal F_t : t \ge 0\}\)</span> 에 대해 <strong>martingale</strong>.</p>
<ol style="list-style-type: decimal">
<li>X 가 <span class="math inline">\(\mathcal F_t\)</span> 에 대해 adapted.</li>
<li><span class="math inline">\(\forall t &lt; \infty : E[ \Big | X(t) \Big | ] &lt; \infty\)</span></li>
<li><span class="math inline">\(\forall t, s \ge 0: E[ X(t+s) | \mathcal F_t] = X(t)\)</span>
3-(1). <span class="math inline">\(\forall t, s \ge 0: E[ X(t+s) | \mathcal F_t] \ge X(t)\)</span>, <strong>sub-martingale</strong>
3-(2). <span class="math inline">\(\forall t, s \ge 0: E[ X(t+s) | \mathcal F_t] \le X(t)\)</span>, <strong>super-martingale</strong></li>
</ol>
</div>
<p>martingale 은 pure random noice process. 즉슨 history 가 주어졌을 때 조건부 평균이 0이며, conditional centered process 이고, <span class="math inline">\(t\)</span> 에 걸쳐 mean 중심으로 랜덤하게 fluctuate. random walk, 페어 갬블링 등이 예시가 됨.</p>
<p><span class="math inline">\(X\)</span> 의 matringale increment <span class="math inline">\(dX(t)=X(t^- + dt) - X(t^-)\)</span> 를 정의. 앞의 성질을 통해 <span class="math inline">\(E[dX(t)|\mathcal F_{t^-}] = 0\)</span> 임이 보장되었다. 이제 <span class="math inline">\(\mathcal F_t\)</span> martingale 인 <span class="math inline">\(X\)</span> 가 uncorrelated increment 를 가지고 있음을 보일 것.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>$$
<span class="math display">\[\begin{align}
s\lt t,\;E[X(s)\{X(t)-X(s)\}]
&amp;= E\, \Big [E[X(s)\{X(t)-X(s)\}|\mathcal{F}_{s} \Big ]

\\
&amp;= E\, \Big [X(s) \cdot E[\{X(t)-X(s)\}|\mathcal{F}_{s} \Big ]
\\
&amp;= {{E \Big [ X(s)\cdot \Big \{E[X(t)|\mathcal{F}_{s}]-E[X(s)|\mathcal{F}_{s}]  \Big \}  \Big ]}} &amp;&amp;= 0
\end{align}\]</span>
$$</p>
<p>univariate survival 에 자주 사용되는 counting process 는 <span class="math inline">\(N(t) = I(X \le t , \Delta = 1)\)</span>. 이제 이하로 설정해보자.</p>
<p>$$
<span class="math display">\[\begin{align}
M(t) &amp;= N(t) - A(t)
\\
A(t) &amp;= \int_0^t dA(s)
\\
dA(t) &amp;= Y(t)\lambda(t) dt
\\
&amp;=E[dN(t) | \mathcal F_{t^-}]

\end{align}\]</span>
$$</p>
<p>이제 intentisy process 의 integration 인 <span class="math inline">\(A(t)\)</span> 을 <span class="math inline">\(N(t)\)</span> 의 <strong>compensator</strong> 라고 명명한다. 이는 process 를 centerin, 즉 중앙쪽으로 보정한다는 의미.</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
<div id="centering-increments" class="section level4" number="9.3.2.1">
<h4 number="9.3.2.1"><span class="header-section-number">9.3.2.1</span> Centering Increments</h4>
<p><span class="math inline">\(A(t)\)</span> 가 실제로 <span class="math inline">\(N(t)\)</span> 의 <strong>compensator</strong> 임을 보이자. failure time 이 indenpendent (right) censoring 에 유관함을 suppose. 그렇다면 pertinent counting process 는 <span class="math inline">\(N(t)\)</span> 로 설정되며, filtration <span class="math inline">\(\mathcal F_{t} = \sigma \{N_i(s) , Y_i (s+); i = 1, \cdots, n;s \in (0, t]\}\)</span> 가 된다. 이때 compensator increment 는 이하로 주어진다.</p>
<p>$$
<span class="math display">\[\begin{alignat}{2}
E[d N_{i}(t)]{\mathcal{F}}_{t^{-}}]&amp;=&amp;&amp; P[d N_{i}(t)=1&amp;&amp;|{\mathcal{F}}_{t^{-}}]

\\

&amp;=&amp;&amp;P[d N_{i}(t)=1&amp;&amp;|Y(t)]

\\


&amp;=Y_{i}(t) \cdot &amp;&amp;P[t\leq T_{i}\lt t+d t&amp;&amp;|t\leq T_{i},t\leq C_{i}]

\\

&amp;=Y_{i}(t) \cdot &amp;&amp;P[t\leq T_{i}\lt t+d t&amp;&amp;|t\leq T_{i}]

\\

&amp;=Y_{i}(t) \cdot &amp;&amp;d A(t)
\end{alignat}\]</span>
$$</p>
<p>이때, <span class="math inline">\(M=N-A\)</span> 가 성립하는가? 다른 말로, <span class="math inline">\(\operatorname{E}[N_{i}(t)]=\operatorname{E}[A(t)]\)</span> 인가?</p>
<p><br>
<br>
<br></p>
<p>이제 <strong>Predictable</strong> 에 대해 생각해보자. <strong>Predictable Process</strong> 란 무엇인가? <span class="math inline">\(H(t)\)</span> 의 값이 <span class="math inline">\(\mathcal F_{t^-}\)</span> 의 함수, 혹은 특정된다면, stochastic process <span class="math inline">\(H\)</span> 는 <span class="math inline">\(\forall t:\)</span> 의 filtration <span class="math inline">\(\mathcal F_t\)</span> 에 대해 <strong>predictable</strong>. 이는 곧 <span class="math inline">\(H\)</span> <span class="math inline">\(t\)</span> 시점의 값이 <span class="math inline">\(t-\)</span> 까지의 정보로 인해 고정된다면, 즉 <span class="math inline">\(H\)</span> 의 행위가 <span class="math inline">\([0,t)\)</span> 까지 해왔던 행위로 인해 고정된다는 것과 동일. predictable 의 성질은 이하와 같다.
- left-continuous process 는 predictable (e.g., <span class="math inline">\(Y(t)\)</span>)
- 모든 deterministic function 은 predictable (e.g., $S(t), (t))
- <span class="math inline">\(E[H(t) | \mathcal F_{t^-} = H(t)]\)</span></p>
<div class="definition">
<p><span id="def:unlabeled-div-30" class="definition"><strong>(#def:unlabeled-div-30) (Stochastic Integral) </strong></span><span class="math inline">\(M\)</span> 이 <span class="math inline">\(\mathcal F\)</span>-matringale 이라고 가정. 이때 process <span class="math inline">\(Z(t)~=~\int_{0}^{t}H(s)d M(s)\)</span> 는 <span class="math inline">\(M(t)\)</span> 에 대한 <strong>Stochastic Integral</strong>.</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-31" class="theorem"><strong>(#thm:unlabeled-div-31) </strong></span>이하의 조건이 만족될 때, <span class="math inline">\(M(t)\)</span> 에 대한 Stochastic Integral <span class="math inline">\(Z(t)~=~\int_{0}^{t}H(s)d M(s)\)</span> 는 <span class="math inline">\(\mathcal F\)</span> matringale.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H\)</span> 가 filtration <span class="math inline">\(\mathcal F\)</span> 에 대해 predictable</li>
<li><span class="math inline">\(M\)</span> 이 <span class="math inline">\(\mathcal F\)</span> matringale</li>
</ol>
</div>
<p>증명을 위해서는 궁극적으로 <span class="math inline">\(E[Z(t)-Z(s)|{\mathcal{F}}_{s}]=0\)</span> 임을 보여야 한다.</p>
<p>$$
<span class="math display">\[\begin{align}
E[Z(s)|\mathcal{F}_{s}]\;\;&amp;=\;\;E\left[\int_{0}^{s}H(u)d M(u)|\mathcal{F}_{s}\right]

\\

&amp;=\ \int_{0}^{s}E[H(u)d M(u) \Bigg |\mathcal{F}_{s}]

\\

&amp;=\ \int_{0}^{s}H(u)d M(u)

&amp;&amp;= Z(s)

\\
\\

E[Z(t)|{\mathcal{F}}_{s}]~&amp;=~E\left[\int_{0}^{t}H(u)d M(u)\Bigg|{\mathcal{F}}_{s}\right]

\\

&amp;=\;\int_{0}^{t}E[H(u)d M(u)|\mathcal{F}_{s}]

&amp;&amp;=\;\;Z(s)+\int_{s}^{t}E[H(u)d M(u)|\mathcal{F}_{s}]
\end{align}\]</span>
$$</p>
<p>이전과 같이 conditioning 을 적용. 단 이번에는 conditional quantity 쪽에. 먼저 conditional expectation 을 고려. 조건부 기댓값을 반복하는 것으로 이하가 발생.</p>
<p>$$
<span class="math display">\[\begin{align}
E \Big [H(u)d M(u) \Big |\mathcal{F}_{s}\Big ]

&amp;=\;\;E \Bigg [E \Big [H(u)d M(u) \Big |\mathcal{F}_{s},\mathcal{F}_{u^{-}} \Big ] \Bigg |\mathcal{F}_{s} \Bigg ]

\\

&amp;=\;\;E \Bigg [E \Big [H(u)d M(u) \Big |\mathcal{F}_{u^{-}} \Big ] \Bigg |\mathcal{F}_{s} \Bigg ]

\\

&amp;=\;\;E \Bigg [H(u) \cdot E \Big [d M(u) \Big |\mathcal{F}_{u^{-}} \Big ] \Bigg |\mathcal{F}_{s} \Bigg ] &amp;&amp;= 0
\end{align}\]</span>
$$</p>
<p>따라서 <span class="math inline">\(E[Z(t)]\mathcal{F}_{s}]\ \ =\ \ Z(s)\)</span> 이며, 이인즉 <span class="math inline">\(E[Z(t)-Z(s)|\mathcal F_{s}]=0\)</span>. 이를 통해 martingale <strong>에 대해</strong> 적분한 stochastic integral 은 그자체로 martingale 임을 보일 수 있다.</p>
<p><br>
<br>
<br></p>
</div>
</div>
<div id="key-martingales-properties" class="section level3" number="9.3.3">
<h3 number="9.3.3"><span class="header-section-number">9.3.3</span> Key Martingales Properties</h3>
<p>위에서 martingale 의 핵심 성질이라고 말했던 (3) 을 increment 의 형식을 빌려 직접 표현하는 것이 가능.</p>
<p>천하쌍살단
살인시동
ㄱ</p>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section-5" class="section level3" number="9.3.4">
<h3 number="9.3.4"><span class="header-section-number">9.3.4</span> </h3>
<p><br>
<br>
<br></p>
<p><br>
<br>
<br></p>
</div>
<div id="section-6" class="section level3" number="9.3.5">
<h3 number="9.3.5"><span class="header-section-number">9.3.5</span> </h3>
<!--chapter:end:212503_Martin.Rmd-->
</div>
</div>
<div id="section-7" class="section level2" number="9.4">
<h2 number="9.4"><span class="header-section-number">9.4</span> </h2>
<!--chapter:end:212504.Rmd-->
</div>
<div id="cox-regression" class="section level2" number="9.5">
<h2 number="9.5"><span class="header-section-number">9.5</span> Cox Regression</h2>
<div id="proportional-hazards-model" class="section level4" number="9.5.0.1">
<h4 number="9.5.0.1"><span class="header-section-number">9.5.0.1</span> Proportional Hazards Model</h4>
<p>Proposed by Cox (1972, JRSS-B), primarily to model the relationship between <strong>hazard function</strong> and <strong>covariates</strong>. most cited paper in statistics ( 41; 000 as of April 2016), one of the most cited in science.</p>
<p>Several extensions to more complex data structures, e.g., clustered failure time data, or recurrent event data, etc.</p>
<p>※ Data Structure</p>
<p>Observed data: <span class="math inline">\(\Big \{ X_i = T_i \wedge C_i, \; \; \; \Delta_i = I(T_i &lt; C_i), \; \;\; \mathbf Z_i (\cdot) \Big \} \overset {iid} \sim\)</span></p>
<p>추가로 <span class="math inline">\(N_i = I(X_i \le t , \; \Delta_i = 1)\)</span>, <span class="math inline">\(Z_i(t)\)</span> = covariate vector (possibly time-dependent).</p>
</div>
<div id="cox-ph-model" class="section level4" number="9.5.0.2">
<h4 number="9.5.0.2"><span class="header-section-number">9.5.0.2</span> Cox PH Model</h4>
<p><span class="math display">\[
\lambda_i (t) = \lambda (t \vert Z_i ) = \lambda_0 (t) \exp (\beta&#39; Z_i) \tag{Cox Model}
\]</span></p>
<p>semiparametric model:</p>
<ul>
<li><span class="math inline">\(\exp(\beta &#39; Z_i)\)</span>, parametric assumption on covariate effects</li>
<li>multiplicative model</li>
<li><span class="math inline">\(\beta\)</span> : <span class="math inline">\(p \times 1\)</span> vector, <span class="math inline">\(p &lt; \infty\)</span></li>
<li><span class="math inline">\(\lambda_0(t)\)</span>, nonparametric; is <span class="math inline">\(\infty\)</span> dimensional</li>
<li>shape of hazard function is unspecified</li>
</ul>
<p>Due to nonparametric component, <strong>standard maximum likelihood theory</strong> does <strong>not</strong> apply</p>
<p>Let <span class="math inline">\(Z_{ij}\)</span> be the <span class="math inline">\(j\)</span>-th element of <span class="math inline">\(Z_i\)</span>
- <span class="math inline">\(\beta_j\)</span> = difference in log hazards
- <span class="math inline">\(\exp(\beta_j)\)</span> = ratio of hazards; assumed constant for all <span class="math inline">\(t\)</span></p>
<ul>
<li><span class="math inline">\(\lambda_0(t)\)</span>: baseline hazard; common to all subjects, <span class="math inline">\(\lambda_0(t) = \lambda_i(t \big | Z_i = \mathbf 0)\)</span></li>
</ul>
<p>The hazard ratio, <span class="math inline">\(\exp(\beta_j)\)</span>, is sometimes referred to as a <strong>relative risk</strong>
- risk = <strong>probability</strong>, not a rate
- hazard is a <strong>rate</strong>, not a probability
- in ratio of hazards, time dimension cancels out</p>
<p>Direction of effect:
$$
<span class="math display">\[\begin{align}

\beta_j &gt; 0: &amp;&amp;\uparrow\lambda_i &amp;&amp;\downarrow S_i(t)
\\
\beta_j &lt; 0: &amp;&amp;\downarrow\lambda_i &amp;&amp;\uparrow S_i(t)


\end{align}\]</span>
$$</p>
<p>Magnitude of effect is easy to interpret w.r.t. <span class="math inline">\(\lambda_i(t)\)</span></p>
<p>Cumulative hazard function:</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_i (t) &amp;= \lambda_0(t) \exp(\beta Z_i)
\\
\Lambda_i (t) &amp;= \int_0^t \lambda_0(s) \exp(\beta Z_i) ds
\\
&amp;= \Lambda_0(t) \exp(\beta Z_i)

\end{align}\]</span>
$$</p>
<p>Survival function:</p>
<p>$$
<span class="math display">\[\begin{align}
S_i (t) &amp;= \exp \Big \{ -\Lambda_i (t) \Big\}
\\
&amp;= \exp \Big \{ -\Lambda_0 (t) \exp(\beta &#39; Z_i)\Big\}
\\
&amp;= S_0(t)^{\exp \Big \{ \beta&#39;Z_i \Big\}}


\end{align}\]</span>
$$</p>
<p>By fitting a Cox model, one can readily interpret the multiplicative effect on the hazard:
- ex) randomized trial: treatment (<span class="math inline">\(Z_i=1\)</span>) versus placebo (<span class="math inline">\(Z_i=0\)</span>); <span class="math inline">\(\hat \beta = 0.405\)</span> (<span class="math inline">\(\exp(\hat \beta)=1.5\)</span>)
- <span class="math inline">\(\lambda_i(t)\)</span> for treated patients is 50% more of that of the controls.
- irrespective of <span class="math inline">\(\lambda_0(t)\)</span></p>
<p>Nevertheless, <span class="math inline">\(\Lambda_0(t)\)</span> is required in order to <strong>determine <span class="math inline">\(Z_i\)</span>’s effect on <span class="math inline">\(S_i(t)\)</span></strong>, e.g.,</p>
<p>$$
<span class="math display">\[\begin{align}

S(t \Big | Z_i = 0) = 0.95 &amp;&amp; vs. &amp;&amp; S(t \Big | Z_i = 1) = 0.93


\\
S(t \Big | Z_i = 0) = 0.70 &amp;&amp; vs. &amp;&amp; S(t \Big | Z_i = 1) = 0.59



\end{align}\]</span>
$$</p>
<div id="cox-model-independent-censoring" class="section level6" number="9.5.0.2.0.1">
<h6 number="9.5.0.2.0.1"><span class="header-section-number">9.5.0.2.0.1</span> Cox Model: Independent Censoring</h6>
<p>Independent censoring assumption is less stringent than in nonparametric estimation.</p>
<p>Assumption is often written as <span class="math inline">\(T_i \perp C_i \Big \vert Z_i\)</span>:
$$
<span class="math display">\[\begin{alignat}{2}

&amp;\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i &lt; t+ \delta \Big | T_i \ge t , \; C_i \ge t , &amp;&amp;\; Z_i)
\\
= &amp;\lim_{\delta \rightarrow 0} \frac{1}{\delta} P(t \le T_i &lt; t+ \delta \Big | T_i \ge t ,  &amp;&amp;\; Z_i)

\end{alignat}\]</span>
$$</p>
<p>※ Note: <span class="math inline">\(C_i\)</span> is allowed to depend on <span class="math inline">\(Z_i\)</span></p>
</div>
</div>
<div id="semiparametric-ph-model-general" class="section level4" number="9.5.0.3">
<h4 number="9.5.0.3"><span class="header-section-number">9.5.0.3</span> Semiparametric PH Model: General</h4>
<ul>
<li>General expression for multiplicative proportional hazards model:</li>
</ul>
<p><span class="math display">\[
\lambda_i (t) = \lambda_0 (t) g(\beta &#39; Z_i )
\]</span></p>
<p><span class="math inline">\(g(x)\)</span> is link function, specified. <span class="math inline">\(\forall x: g(x) \ge 0\)</span>, <span class="math inline">\(\exists g&#39;&#39;(x)\)</span>, and in special case, <span class="math inline">\(g(x) = \exp(x)\)</span>.</p>
<ul>
<li>Other choices for link function (e.g., Self &amp; Prentice, 1983):
<span class="math inline">\(g(x) = 1+x = (1+x)^{-1} = \log(1+x)\)</span></li>
</ul>
<p>※ Notes:
- not all choices of <span class="math inline">\(g(x)\)</span> lead to clear interpretation of <span class="math inline">\(\beta_j\)</span>
- certain choices of <span class="math inline">\(g(x)\)</span> lead to numerical issues; e.g., likelihood is flat; local maxima, etc.
- <span class="math inline">\(g(x) \not = exp(x)\)</span> has received little attention in the literature</p>
</div>
<div id="multiplicative-model" class="section level4" number="9.5.0.4">
<h4 number="9.5.0.4"><span class="header-section-number">9.5.0.4</span> Multiplicative Model</h4>
<p><strong>Cox model</strong> is a <strong>multiplicative model</strong>, i.e., covariates assumed to affect survival probability by multiplying the baseline hazard.</p>
<ul>
<li>Additive models also been proposed</li>
</ul>
<p><span class="math display">\[
\]</span></p>
</div>
<div id="proportional-hazards-regression-and-multiplicative-intensity-model" class="section level4" number="9.5.0.5">
<h4 number="9.5.0.5"><span class="header-section-number">9.5.0.5</span> Proportional Hazards Regression and Multiplicative Intensity Model</h4>
<ul>
<li>Recall Counting process: martingale representation</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

N(t) &amp;= I(X\le t , \; \Delta = 1)
\\
Y(t) &amp;= I(X \ge t)
\\
M(t) &amp;= N(t) - \int_0^t Y(u)\lambda_0(u) e^{\beta &#39; Z } du \tag{1}
\\
\mathcal F_t &amp;= \sigma \Big \{ N(u) , Y(u+) , Z: \; \; 0 \le u \le t \Big \}



\end{align}\]</span></p>
<p>$$</p>
<ol style="list-style-type: decimal">
<li>intensity <span class="math inline">\(l(u) = Y(u)\lambda_0(u) e^{\beta &#39; Z }\)</span>, therefore integrated form is cumulative intensity <span class="math inline">\(A(t)\)</span>.</li>
</ol>
<ul>
<li>Multiplicative Intensity Model:</li>
</ul>
<p><span class="math display">\[
l(t) = Y(t)\lambda_0(t) e^{\beta &#39; Z(t) }
\]</span></p>
<ul>
<li><p>Counting process: <span class="math inline">\(N(t)\)</span> = Number of events of a specified type that have occurred by time <span class="math inline">\(t\)</span></p>
<ul>
<li><span class="math inline">\(N(t)\)</span> may take more than one jump</li>
<li>multiple infections, repeated breakdowns, hospital admissions</li>
<li><span class="math inline">\(EN(t) &lt; \infty\)</span></li>
</ul></li>
<li><p>At-risk process: <span class="math inline">\(Y(t)\)</span>, left-continuous process, <span class="math inline">\(1\)</span> if failure can be observed at time <span class="math inline">\(t\)</span>, otherwise <span class="math inline">\(0\)</span>.</p>
<ul>
<li><span class="math inline">\(Y(t)\)</span> can be used to represent situation in which a subject enter and exit risk sets several times</li>
<li><span class="math inline">\(Y(t)\)</span> may be <span class="math inline">\(1\)</span> even after an observed failure</li>
</ul></li>
<li><p>Covariate process: <span class="math inline">\(Z(t)\)</span> = (bounded) predictable process</p>
<ul>
<li>time-dependent treatment, risk factors</li>
<li>model checking and relaxing PH assumption</li>
</ul></li>
<li><p>Baseline hazard function: <span class="math inline">\(\lambda_0(\cdot)\)</span> = an arbitrary deterministic function</p></li>
<li><p>Filtration: <span class="math inline">\(\mathcal F_t = \sigma \Big \{ N(u) , Y(u+) , Z(u): \; \; 0 \le u \le t \Big \}\)</span></p></li>
<li><p>Martingale: <span class="math inline">\(M(t) = N(t) - \int_0^t l(u) du\)</span></p></li>
<li><p>Intensity function: $ E { dN(t) | F_{t-} } = l(t) dt$</p></li>
<li><p>Data: <span class="math inline">\(n\)</span> independent observations on $ { N(), ; Y(), ; Z() }$</p></li>
</ul>
</div>
<div id="likelihood-conditional-marginal-and-partial-likelihoods" class="section level4" number="9.5.0.6">
<h4 number="9.5.0.6"><span class="header-section-number">9.5.0.6</span> Likelihood; conditional, marginal and partial likelihoods</h4>
<ul>
<li><p><span class="math inline">\(X =\)</span> vector of observations; <span class="math inline">\(f_X(x, \theta) =\)</span> density of <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\theta =\)</span> vector parameter; <span class="math inline">\(\theta = (\beta &#39; , \phi&#39;)&#39;\)</span></p></li>
<li><p><span class="math inline">\(\beta =\)</span> parameter of interest; <span class="math inline">\(\phi =\)</span> nuisance parameter</p></li>
<li><p><strong>likelihood</strong>: <span class="math inline">\(f_X(x, \theta) = f_{W|V} (w \Big | v, \theta )f_V (v, \theta)\)</span></p>
<ul>
<li><span class="math inline">\(X = (V&#39;, W&#39;)&#39;\)</span></li>
<li>infinite-dimensional <span class="math inline">\(\phi\)</span></li>
<li><span class="math inline">\(f_{W|V} (w \Big | v, \theta )\)</span> does not involve <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use <span class="math inline">\(f_{W|V} (w \Big | v, \beta )\)</span> (conditional likelihood)</li>
<li><span class="math inline">\(f_V (v, \theta)\)</span> does not involve <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use <span class="math inline">\(f_V (v, \beta)\)</span> (marginal likelihood)</li>
</ul></li>
</ul>
<p><span class="math display">\[
X = (V_1 , W_1 , \cdots, V_K , W_K)
\]</span></p>
<p>$$
<span class="math display">\[\begin{align}


f_X(x, \theta) &amp;= f_{V_1 , W_1 , \cdots, V_K , W_K} (v_1 , w_1 , \cdots, v_K , w_K\; ;\; \theta)
\\

&amp;= 
f_{V_1}(v_1 \; ; \; \theta)

f_{W_1 | V_1}(w_1 | v_1\; ; \; \theta)

f_{V_2 | V_1, W_1}(v_2 |  v_1, w_1\; ; \; \theta) \times \cdots

\\

&amp;= \left \{ \prod_{i=1}^K f_{W_i | Q_i } (w_i \Big | q_i \; ; \theta) \right \}


\left \{ \prod_{i=1}^K f_{V_i | P_i } (v_i \Big | p_i \; ; \theta) \right \}

\end{align}\]</span>
$$</p>
<p>$$
<span class="math display">\[\begin{align}


P_1 = \phi,&amp; &amp;&amp; P_i =(V_1 , W_1 , \cdots, V_{i-1} , W_{i-1})
\\
Q_1 = V1,&amp; &amp;&amp; Q_i =(V_1 , W_1 , \cdots , W_{i-1}, V_i)

\end{align}\]</span>
$$</p>
<p>$<em>{i=1}^K f</em>{W_i | Q_i } (w_i | q_i ; ; ) $ is free of <span class="math inline">\(\phi\)</span> <span class="math inline">\(\Rightarrow\)</span> use $ <em>{i=1}^K f</em>{W_i | Q_i } (w_i | q_i ; ; ) $ (partial likelihood)</p>
<div id="partial-marginal-likelihoods" class="section level6" number="9.5.0.6.0.1">
<h6 number="9.5.0.6.0.1"><span class="header-section-number">9.5.0.6.0.1</span> Partial &amp; Marginal Likelihoods</h6>
<p>Focus on Proportional Hazards Model: i.e., <span class="math inline">\((X_i, \; \delta_i, \; Z_i), \; i = 1, \cdots, n\)</span> (<span class="math inline">\(n\)</span> independent triplets)</p>
<p>$$
<span class="math display">\[\begin{align}

&amp;\lambda(t \Big | Z ) = \lambda_0 (t) e^{\beta &#39; Z} &amp;&amp;S(t \Big | Z) = \Big \{ S_0(t) \Big \}^{e^{\beta &#39; Z}} \tag{1}

\end{align}\]</span>
$$</p>
<p>위에서 $ _0 (t)$는 <strong>unspecified</strong>.</p>
<ul>
<li><strong>Partial Likelihood</strong>: assume no ties, absolutely continuous failure distribution</li>
</ul>
<p>Suppose there are L observed failures at <span class="math inline">\(\tau_1 &lt; \cdots &lt; \tau_L\)</span> (set <span class="math inline">\(\tau_0 \equiv 0\)</span> &amp; <span class="math inline">\(\tau_{L+1} \equiv \infty\)</span>)</p>
<p>16.png</p>
<p>Let (i) be the label for individual failing at <span class="math inline">\(\tau_i\)</span> (set <span class="math inline">\((L + 1) \equiv n + 1\)</span>). Note <span class="math inline">\(t_{(i)} = \tau_i\)</span></p>
<p>Covariates for <span class="math inline">\(L\)</span> failures: <span class="math inline">\((Z_{(1)}, \cdots, Z_{(L)})\)</span>. (Hereafter, condition on $ { Z_i : i = 1, , n }$)</p>
<p>Censorship times in <span class="math inline">\([\tau_i; \tau_{i+1})\)</span>: <span class="math inline">\((\tau_{i1}, \cdots, \tau_{i, m_i})\)</span> with covariates <span class="math inline">\((Z_{(i,1)}, \cdots, Z_{(i,m_i)})\)</span>, i.e., <span class="math inline">\((i, j)\)</span> is label for item censored at <span class="math inline">\(\tau_{ij}\)</span></p>
<p>17.png</p>
<p>The data can be divided into sets</p>
<p><span class="math display">\[
(V_1 , W_1, \cdots, V_{L+1} ,  W_{L+1})
\]</span></p>
<p>where, for <span class="math inline">\(i = 1, \cdots, L, L+1\)</span>,</p>
<p>$$
<span class="math display">\[\begin{align}
V_i &amp;= \Big \{ \tau_i , \tau_{i-1, j}  \; \; ; \; \; (i-1, j):j = 1, \cdots, m_{i-1} \Big \}

\\

and \; \; \; \;W_i &amp;= \Big \{ (i) \Big \}


\end{align}\]</span>
$$</p>
<p>18.png</p>
<p>19.png</p>
<p>GOAL: Build a likelihood on a subset of the full data set
- carrying most of the information about <span class="math inline">\(\beta\)</span>
- carrying no information on nuisance parameters <span class="math inline">\(\Big \{ \lambda_0 (t) : t \ge 0 \Big \}\)</span></p>
<p>PROPOSAL: Generate likelihood of <span class="math inline">\(\Big \{ W_1, \cdots, W_L \Big \}\)</span></p>
<p>JUSTIFICATION, WHY?:
- Timing of events <span class="math inline">\(\Big \{ \tau_1 , \cdots, \tau_L \Big \}\)</span> can be explained by <span class="math inline">\(\lambda_0(\cdot)\)</span>.
- Censoring <strong>times and labels</strong> can be ignored if we assume <strong>non-informative censorship</strong> (independent censoring).</p>
<p>So this is a partial likelihood in the sense that it is only part of the likelihood of the observed data.</p>
<p>If <span class="math inline">\(Q_i \equiv (V_1, W_1 , \cdots, V_{i-1}, W_{i-1}, V_i)\)</span> and <span class="math inline">\(\mathcal F_{\tau_i} \equiv (Q_i, Z)\)</span>, the partial likelihood is <span class="math inline">\(\prod_{i=1}^L P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)\)</span>, i.e., given the risk set at <span class="math inline">\(\tau_i\)</span>, and given event occurs at <span class="math inline">\(\tau_i\)</span>.</p>
<p>Denote <span class="math inline">\(R_i \equiv \Big \{ j : X_j \ge \tau_i \Big \}\)</span> as risk set at <span class="math inline">\(\tau_i\)</span>. Then, by the assumption of independent censoring,</p>
<p>$$
<span class="math display">\[\begin{align}
P \Big ( W_i = (i) \Big | \mathcal F_{\tau_i} \Big)




&amp;=
\frac{


P \Bigg \{ t_{(i)} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - (i)} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} 
}{

\sum\limits_{l \in R_i} 
\left[
P \Bigg \{ t_{l} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} \cdot 
\prod\limits_{j \in R_i - l} P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}
\right]
}
\tag{a}





\\
\\
\\


&amp;=
\frac{
d\Lambda \Big( \tau_i \Big | Z_{(i)} \Big)
\prod\limits_{j \in R_i - (i)} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \}
}{
\sum\limits_{l \in R_i} \left [ d\Lambda \Big( \tau_i \Big | Z_{l} \Big)
\prod\limits_{j \in R_i - l} \bigg \{ 1 - d\Lambda \Big( \tau_i \Big | Z_{j} \Big) \bigg \} \right ]
}


\; \; \; \div \; \; \; \frac{d\tau_i}{d\tau_i}

\tag{2}
\\
\\
\\

&amp;= \frac{\lambda\Big(\tau_i \Big | Z_{(i)} \Big)}{ \frac{P \Big\{T\in [t, t+dt) \Big | T \ge t , Z \Big\}}{dt}= \sum\limits_{l\in R_i} \left[ \lambda\Big(\tau_i \Big | Z_{l} \Big) \right]}

\; \; \; \overset {(1)}{=}  \; \; \; 


\frac{\exp(\beta &#39; Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta &#39; Z_{l})}





\end{align}\]</span>
$$
- at (a), <span class="math inline">\(P \Bigg \{ t_{j} \not \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \} = 1 - P \Bigg \{ t_{j} \in \big[\tau_i , \tau_i + d\tau \big) \Bigg |\mathcal F_{\tau_i} \Bigg \}\)</span>
- at (2), $ d( <em>i | Z</em>{j} ) = 0$</p>
<p>Thus, the <strong>Partial Likelihood</strong> is</p>
<p><span class="math display">\[
\prod^L_{i=1}\frac{\exp(\beta &#39; Z_{(i)})}{\sum\limits_{l\in R_i} \exp(\beta &#39; Z_{l})} = L(\beta)\tag{3}
\]</span></p>
<p>Note: unspecified <span class="math inline">\(\lambda_0(\cdot)\)</span> + noninformative censoring <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\prod\limits_{i=1}^L f_{V_i \big | P_i} (v_i \Big | p_i ; \theta)\)</span> contains little or no information about <span class="math inline">\(\beta\)</span>.</p>
<ul>
<li>Counting process notation:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}
L(\beta) = \prod^n_{i=1}\prod_{t\ge0} \left \{ 

\frac{\exp(\beta &#39; Z_{i})}{\sum\limits_{j=1}^n Y_j(t) \exp(\beta &#39; Z_{j})}

\right\}^{dN_i(t)}


, &amp;&amp; dN_i(t) = \begin{cases} 1 &amp; N_i(t) - N_i {(t-)} =1\\0 &amp; o.w.\end{cases}

\end{align}\]</span>
$$</p>
<ul>
<li><p>Maximum partial likelihood estimator (MPLE): <span class="math inline">\(L( \hat \beta) = \max_\beta L(\beta)\)</span> (using Newton-Raphson (NR) algorithm)</p>
<ul>
<li>Specifically, the <strong>log partial likelihood</strong> is then</li>
</ul>
<p><span class="math display">\[
l(\beta) = \sum_{i=1}^n \int_0^\infty \left[ Y_i (t) Z_i \beta - \log\left( \sum_{j=1}^n Y_j(t) \exp(\beta &#39; Z_j ) \right) \right]dN_i(t)
\]</span></p>
<ul>
<li><strong>The score vector</strong>, <span class="math inline">\(U(\beta)\)</span>, can be obtained by differentiating <span class="math inline">\(l(\beta)\)</span> w.r.t. <span class="math inline">\(\beta\)</span>:</li>
</ul>
<p>$$
<span class="math display">\[\begin{alignat}{2}
U(\beta) &amp;= \sum_{i=1}^n \int_0^\infty \Big \{ Z_i - \bar Z(\beta, t) \Big \}&amp;&amp;dN_i (t)

\\

&amp;= \sum_{i=1}^n \int_0^\infty \left \{ Z_i - \frac{\sum_{i=1}^n Y_i (t) Z_i \exp(\beta &#39; Z_i)}{\sum_{i=1}^n Y_i (t) \exp(\beta &#39; Z_i)} \right \}&amp;&amp;dN_i (t)

\end{alignat}\]</span>
$$</p>
<ul>
<li><p>where <span class="math inline">\(\bar Z(\beta, t)\)</span> is a weighted mean of <span class="math inline">\(Z\)</span> over those observations still at risk at time <span class="math inline">\(t\)</span>.</p></li>
<li><p>The information matrix, <span class="math inline">\(\mathcal I(\beta)\)</span>, is the negative second derivative where</p></li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

\mathcal I(\beta) &amp;= \sum\limits_{i=1}^n \int_0^\infty V(\beta, t) dN_i(s)

\\
\\

V(\beta, t) &amp;= \frac{\sum\limits_{i=1}^n Y_i(t) \exp(\beta &#39; Z_i ) \Big \{ Z_i - \hat Z (\beta, t)\Big\}&#39;\Big \{ Z_i - \hat Z (\beta, t)\Big\}}{\sum\limits_{i=1}^n Y_i(t) \exp(\beta &#39; Z_i )}

\end{align}\]</span>
$$</p>
<ul>
<li>and <span class="math inline">\(V(\beta, t)\)</span> is the weighted variance of <span class="math inline">\(Z\)</span> at time <span class="math inline">\(t\)</span>.</li>
</ul></li>
</ul>
<p>Then, the MPLE, <span class="math inline">\(\hat \beta\)</span>, is found by solving the partial likelihood equation: <span class="math inline">\(U(\hat \beta) = 0\)</span>.</p>
<p>Under some regularity conditions, <span class="math inline">\(\hat \beta\)</span> is consistent and asymptotically normally distributed with mean <span class="math inline">\(\beta\)</span> and variance <span class="math inline">\(E \Big \{ \mathcal I(\beta) \Big\}^{-1}\)</span> (will be shown later.)</p>
<p>The NR algorithm to solve the partial likelihood equation: Compute iteratively until convergence (requires an initial value <span class="math inline">\(\hat \beta^{(0)}\)</span>).</p>
<p><span class="math display">\[
\hat\beta^{(n+1)} = \hat\beta^{(n)} + \mathcal I ^{-1} \Big( \hat \beta^{(n)}\Big) \cdot U \Big( \hat \beta^{(n)}\Big)
\]</span></p>
<p>※ Note:
1. (incredibly) Robust algorithm!
2. <span class="math inline">\(\hat \beta^{(0)} = 0\)</span> usually works.</p>
</div>
</div>
<div id="cox-proportional-hazards-model" class="section level4" number="9.5.0.7">
<h4 number="9.5.0.7"><span class="header-section-number">9.5.0.7</span> Cox Proportional Hazards Model</h4>
<p>Cox model:</p>
<p>$$
<span class="math display">\[\begin{align}

\lambda_i(t) = \lambda(t \Big | Z_i ) 
&amp;= \lambda_0 (t) \exp(\beta &#39; Z_i) 
\\
&amp;= \lambda_0(t) \exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})
\\
&amp;\Updownarrow
\\

\log \lambda(t \Big | Z_i ) &amp;= \log \Big[ \lambda_0(t) \Big] +\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik}
\\
S(t \Big | Z_i ) &amp;= 



\Big[ S_0(t) \Big]^{\exp(\beta_1 Z_{i1} + \cdots + \beta_k Z_{ik})}


\end{align}\]</span>
$$</p>
<p>※ Note:</p>
<p>$$
<span class="math display">\[\begin{align}
\lambda_0 (t) &amp;= \lambda(t \Big | Z_1 = \cdots = Z_k = 0)
\\
\\
\exp(\beta_1 Z_{1} + \cdots + \beta_k Z_{k}) &amp;= RR 



\\
&amp;= \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 = \cdots = Z_k = 0)} \tag{1}
\end{align}\]</span>
$$
- (1) is relative risk of hazard of death comparing covariates values <span class="math inline">\(Z_1,\cdots, Z_k\)</span> to <span class="math inline">\(Z_1 = \cdots = Z_k = 0\)</span></p>
<p>Interpreting Cox Model Coeffcients: <span class="math inline">\(\beta_k\)</span> is the log RR (hazard ratio) for a unit change in <span class="math inline">\(Z_k\)</span>, given all other covariates remain constant, i.e.,</p>
<p>$$
<span class="math display">\[\begin{align}


\frac
{\lambda\Big[t \Big | Z_1 , \cdots, (Z_{k&#39;}+1), \cdots, Z_k \Big]}
{\lambda\Big[t \Big | Z_1 , \cdots, Z_{k&#39;}, \cdots, Z_k \Big]} 


&amp;= \exp \Big (\beta_1 \cdot 0 + \cdots + \beta_{k&#39;} \cdot (Z_{k&#39;} +1 - Z_{k&#39;}) + \cdots + \beta_k \cdot 0 \Big)

\\

&amp;= \exp(\beta_{k&#39;})


\end{align}\]</span>
$$</p>
<p>The RR comparing 2 sets of values for the covariates <span class="math inline">\((Z_1 , \cdots, Z_k)\)</span> vs. <span class="math inline">\((Z_1&#39; , \cdots, Z_k&#39;)\)</span>:</p>
<p><span class="math display">\[
RR = \frac{\lambda(t \Big | Z_1 , \cdots, Z_k)}{\lambda(t \Big | Z_1 &#39;, \cdots, Z_k&#39;)} =\exp \Big \{ \beta_1(Z_1 - Z_1&#39;) + \cdots + \beta_k(Z_k - Z_k&#39;) \Big \}
\]</span></p>
<p>20.png</p>
</div>
<div id="comparison-of-nested-models" class="section level4" number="9.5.0.8">
<h4 number="9.5.0.8"><span class="header-section-number">9.5.0.8</span> Comparison of Nested Models</h4>
<ul>
<li>Nested Models:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

\lambda(t) &amp;= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p + \beta_{p+1} Z_{p+1} +\cdots + \beta_{k} Z_{k}\Big) \tag{Full Model}

\\

&amp;= \lambda_0(t) \exp \Big ( \beta_1 Z_1 + \cdots \beta_p Z_p \Big) \tag{Reduced Model}


\end{align}\]</span></p>
<p>$$</p>
<p>To test:</p>
<ul>
<li>Nested Models:</li>
</ul>
<p>$$
<span class="math display">\[\begin{align}

&amp;H_0:  &amp;&amp;RM &amp;&amp; \Leftrightarrow &amp;&amp; H_0: \beta_{p+1} = \cdots = \beta_k = 0
\\
&amp;H_A:  &amp;&amp;RM &amp;&amp; \Leftrightarrow &amp;&amp; H_A:  \not = \text{ somewhere}

\end{align}\]</span></p>
<p>$$</p>
<p>Use the <strong>partial likelihood ratio statistic</strong>, <span class="math inline">\(X^2_{Cox} = -2 \Big[ \log PL(RM) - \log PL(FM)\Big]\)</span>.</p>
<p>Under <span class="math inline">\(H_0\)</span>: Reduced model, and when <span class="math inline">\(n\)</span> is large:
<span class="math display">\[
\begin{align}
X^2_{Cox} \sim \chi^2_{k-p} &amp;&amp; k-p \text{ is the ## of parameters set to 0 by }H_0
\end{align}
\]</span></p>
<p>20.png, 21.png</p>
</div>
<div id="stratification" class="section level4" number="9.5.0.9">
<h4 number="9.5.0.9"><span class="header-section-number">9.5.0.9</span> Stratification</h4>
<p>Two Ways to Stratify. Suppose a confounder <span class="math inline">\(C\)</span> has 3 levels on which we would like to stratify when comparin
g <span class="math inline">\(\lambda(t \Big | E )\)</span> and <span class="math inline">\(\lambda ( t \Big | \bar E )\)</span>. How? <span class="math inline">\(X_E = \begin{cases}1&amp;E&amp;\text{(exposed)}\\0&amp;\bar E&amp;\text{(not exposed)}\end{cases}\)</span></p>
<p>22.png</p>
<ul>
<li>Which Way to Stratify?</li>
</ul>
<ol style="list-style-type: decimal">
<li>Under dummy variable stratification model, the proportional stratum-to-stratum hazards assumption may not be correct. If not, the con-founder <span class="math inline">\(C\)</span> may be inadequately controlled.</li>
<li>Proportionality assumption can be checked using time-dependent covariates.</li>
<li>True stratification is a more thorough adjustment, as long as observations within each level are homogeneous. If <span class="math inline">\(C\)</span> can be measured continuously and the strata were formed by grouping values of it, better control for <span class="math inline">\(C\)</span> might be achieved with continuous (could be time-dependent) covariate adjustment.</li>
<li>If <span class="math inline">\(C\)</span> is controlled using the true stratification there is no way to estimate one summary relative risk comparing two levels of <span class="math inline">\(C\)</span>. However, we can estimate <span class="math inline">\(\lambda_{0i}(t)\)</span> for each stratum then we can estimate a RR function.</li>
<li>True stratification generally requires more data to obtain the same precision in coefficient estimates.</li>
</ol>
<p>23.png</p>
<p>24.png</p>
</div>
<div id="test-statistics" class="section level4" number="9.5.0.10">
<h4 number="9.5.0.10"><span class="header-section-number">9.5.0.10</span> Test statistics</h4>
<p>The standard asymptotic likelihood inference tests, Wald, score, and likelihood ratio (LR), still can be applied for the Cox partial likelihood.</p>
<p>25.png</p>
<p>Their finite sample properties may differ; in general, the LRT is the most reliable, the Wald test is the least.</p>
<p>26.png</p>
<p>When <span class="math inline">\(p = 1\)</span> and the single covariate is categorical, the score test is identical to the log-rank test.</p>
<p>27.png</p>
</div>
<div id="handling-ties" class="section level4" number="9.5.0.11">
<h4 number="9.5.0.11"><span class="header-section-number">9.5.0.11</span> Handling ties</h4>
<p>Real data sets often contain tied event times.</p>
<ul>
<li>When do we have ties?</li>
</ul>
<ol style="list-style-type: decimal">
<li>Continuous event times are grouped into intervals.</li>
<li>Event time scale is discrete.</li>
</ol>
<p>Four commonly used ways of handling ties: 1) Breslow approximation, 2) Efron approximation, 3) Exact partial likelihood, and 4) Averaged likelihood.</p>
<p>When the underlying time is continuous but ties are generated due to a grouping, the contribution to the partial likelihood for the <span class="math inline">\(i\)</span>-th event at time <span class="math inline">\(t_i\)</span> is <span class="math inline">\(\frac{\exp(\beta &#39; Z_i)}{ \sum\limits_{j \in R_i} Y_j(t_i) \exp(\beta &#39; Z_j)}\)</span></p>
<p>Two commonly used methods are
1. Breslow approximation
2. Efron approximation</p>
<p>Example: Assume 5 subjects are at risk of dying at time <span class="math inline">\(t\)</span> and two die at the same time <span class="math inline">\(t\)</span> (because of grouping of time) If the time data had been more precise, then the first two terms in the likelihood would be either</p>
<p>28.png</p>
<p>29.png</p>
<p>30.png</p>
<!--chapter:end:212505_Cox.Rmd-->
</div>
</div>
<div id="filtration의-개념을-정복하자" class="section level2" number="9.6">
<h2 number="9.6"><span class="header-section-number">9.6</span> Filtration의 개념을 정복하자!</h2>
<p>도대체 Filtration(Filtration event)을 정복해야 하는 이유가 무엇인가?</p>
<p>금융공학 특히 금융수학을 공부하는데 있어서 가장 핵심이 되는 것 중에 하나가 Stochastic Differencial Equation 이다. 금융수학책들을 보면 다들 처음에는 확률(이 바닥에서는 측도론을 건드리는 것이 일반적)을 다룬 다음에 Stochastic Process를 다루고 Ito’s lemma를 거쳐 Black Sholes PDE 한번 찍어주고 Girsanov를 돌아서 Feynmman-Kac Theory로 끝내곤 한다.</p>
<p>특히 표준 금융수학 전반에 걸쳐서 Stochastic Process가 들어가는데 개인적으로는 이거 처음에 개념잡기가 힘들었다.. 왜냐하면 확률을 측도론(Measure Theory)에서 접근을 해야 하니 측도론을 조금은 알아야 하고(덧붙여 약간의 함수해석학…) Random process, Stopping Time… 등등… 이것들의 성질이 Ft-measurable이므로 Ft-measurable이라는 의미를 잘 알아야 할 필요성까지 있기 때문이다.</p>
<p>뭐 Ft-measurable, 좀더 분해해서 Ft라는 filtration 과 measurable이라는 성질을 논리적으로 완벽하게 정의하는데 드는 노력은 A4용지에 반정도 끄적이면 충분하다. 그러니 어디서 누가 물으면 답변하는 정도로는 그냥 암기해 버리면 그만이 아닐까 생각한다.</p>
<p>그러나 정의를 주저리주저리 외우고 다닌다고 하는 것은 그 대상을 아는 것은 아니다.… 애매한 문제에 엄밀한 판결을 내릴 수 있도록 능력이 되려면 수학적 정의가 포함하는 세계가 머리속에 익숙해 져야 한다고 생각한다.</p>
<p>어째든지 Random process이던 Stopping Time 이건, Girsanov이건간에, 수학적인 내용이 나오면 적어도 머리속에는 간략화되고 가시적인 예제들이 Simulation되어야지 그 개념들이 ‘눈에’ 보이게 되는데 Filtration의 구체적인 모습들이 떠오르지 않으니까 나머지도 거기서 더 이상 이해가 되지 않았다. 이것이 본인이 Filtration을 한번 손봐야 겠다고 맘먹은 직접적인 동기이다.</p>
<div id="random-process를-이야기-하기까지의-긴-여정의-요약" class="section level3" number="9.6.1">
<h3 number="9.6.1"><span class="header-section-number">9.6.1</span> Random Process를 이야기 하기까지의 긴 여정의 요약</h3>
<p>확률공간 (Ω, F, P)의 정의에 대해서 이야기하자면 많은 사람들이 이미 알겠지만 측도론(Measure Theory)에 대한 고된 과정을 거쳐야지만 비로서 이야기할 수 있게 된다. Measure Theory는 미적분 함수해석학 등을 최신(?)관점에서 접근하도록 만들어진 이론체계인데 실해석학(Real Analysis)이라는 과목에서 주로 다루게 된다. 여기에서 Measure라는 개념 – 우리말로 하면 측도 라는 것은 말 그대로 측정한다는 것인데 이런 류로 쉽게 생각할 수 있는 것은 ‘길이’ 이다…. 혹은 넓이, 부피, 기타 등등. 여기에 쓰이는 측도의 개념을 확률에다가 접근 시킨 사람이 콜모고로프라는 라는 것은 이미 널리 알려진 바이다. 길이, 확률의 기초적 개념은 초딩때 이미 섭렵했는데 굳이 어렵게 이해할 필요가 있는가 할 수도 있겠지만 아무래도 무한대이고 연속의 세계에서는 별의별 해괴한 일이 벌어지기 때문에 유치한(유치하다는 것은 경멸적인 이야기가 아니라 덜 세련된… 정도로 생각을 해주면 된다.) 차원의 접근방법은 더 이상 통하지 않고, 집합론, 해석학의 고등 주제들을 총 동원해야 모호한 문제에 비로소 해답을 내릴 수 있다. 그러니 해석학을 하기 위해서는 집합론을 먼저 알아야 하는데 이것도 중고딩때 하던 겉핥기 식의 집합론이 아닌 무한차원을 다룬 진검승부의 집합론이 필요하다. 하여튼지 간에 이렇게 금융수학을 공부하기 위해서 선행적으로 해야 할 아주 높은 산들이 산적해 있는데.. 이걸 다 언급하는 것은 이 글의 주제를 넘어서는 것 같구… 차후에 ‘금융수학을 공부하기 위한 로드맵’에 좀더 자세히 언급하겠다. 여기서 이야기 하고 싶은 것은 <strong>확률과정</strong>(Random Process)를 실해석학 위에서 가지고 노는 것은 나름대로 다 이유가 있다는 말을 하고 싶은 것이다. 기존의 유치한 확률론으로 접근해서 나름대로 이론을 쌓을 수 있다면 아주 happy한 case이지만 그렇다 하더라도 표준적으로 쓰여있는 paper나 text가 마팅게일이니, Girsanov니.. 이런 식으로 쓰여져 있으니 뭐라고 하는지 이해는 할 수 있어야 할 것 아닌가, 더욱이 수학이 어렵다고 하는데 솔직히 공부하는 것은 아주 어려운 것 맞다. 하지만 어려운 것은 익숙지 않다는 것뿐이다. 익숙해지면 세상이 참 쉽게 보인다. 복잡한 것은 수학이 아니라 세상이다. 공부하기 어려운 수학에 익숙해지면 복잡하게만 보였던 세상이 수학에 의해서 간략하게 보이게 된다. 세상 만만하게 보인다는 이야기이다. 어렵게 공부한 사람만 볼 수 있으니 개인적 보람도 아주 크다.</p>
<div id="sigma-algebrasigma-field" class="section level4" number="9.6.1.1">
<h4 number="9.6.1.1"><span class="header-section-number">9.6.1.1</span> Sigma-Algebra(Sigma-Field)</h4>
<p>Sigma-Algebra 라는 것은 measure를 다루기 위한 기본 개념인데 Sigma-Field와 같은 개념이다. 확률을 다루는 바닥에서는 Sigma-algebra 대신에 Sigma-Field라는 말을 쓴다. 참고로 Algebra, Field 라는 것은 Abstract Algebra(추상대수학)이라는 수학의 큰 줄기와 그 안의 체(Field)를 연상시키는데 연결고리에 대해서 약간의 심증은 가지고 있지만 물증은 찾지 못했다. 하여튼 간에 집합 A 위의 Sigma-Algebra(본인은 이 용어를 쓰겠다)의 정의는 다음의 말이 되는 A의 부분집합 E 들의 모임이다.
1. 공집합과 A는 Sigma-Algebra에 속한다.
2. E가 Sigma-Algebra에 속하면 E의 여집합도 Sigma-Algebra에 속한다.
3. E1과 E2가 Sigma-Algebra에 속하면 E1과 E2의 합집합도 Sigma-Algebra에 속한다.</p>
<p>뭐 여기까지는 상식적으로 이해가 된다.</p>
<ol start="4" style="list-style-type: decimal">
<li>Ei(I는 집합의 첨수족이고 자연수N의 원소이다) 가 Sigma-Algebra에 속하면 모든 Ei 의 합집합도 Sigma-Algebra에 속한다.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>과 (4) 는 같은 이야기 인 것이 아닌가? 하는 의문이 있을 수 있겠다. 즉 (3)을 반복적으로 적용하면 결국 (4)가 아닌가 하는 생각이 바로 그것이다. 답은 “같지 않다”이다. 이것이 다르다는 것을 이해하는데 에는 집합론을 깊이 아는 것이 필요하다. 뭐 그것은 그러려니 하자…. 그런데 문제는 이것뿐만이 아니다. (4) 의 내용을 이렇게 바꾸어 말할 수 있는가?</li>
</ol>
<p>「Sigma-Algebra에 속하는 모든 E들을 무한히 합집합을 취한 것도 Sigma-Algebra에 속한다」</p>
<p>답의 yes, no 차원을 떠나서 위의 문제는 참으로 무책임한 질문이다. 왜냐하면 <strong>무한히</strong> 라는 것도 모호한 말이기 때문이다. 정확히는 <strong>가부번수만큼</strong> 합집합을 취한 것이 Sigma-algebra에 속한다. 가부번수라는 것은 자연수의 개수와 같으므로 위의 (4) 라는 표현을 쓴 것이다. 무한에는 가부번수라는 것도 있고 비가부번수가 있다. 짝수, 홀수, 자연수, 유리수등등 이것이 다 같은 개수를 가진다고 생각을 하고 그것을 가부번수라고 한다. 그리고 실수 무리수 같은 수는 비가부번 수이다. 그러므로 <strong>(4) 에서 I 가 N 의 집합이 아닌 실수R의 집합이나. 무리수Qc 의 집합이라고 적어 놓으면 더 이상 Sigma-algebra가 아닌 다른 무엇이 되고 마는 것이다</strong>.
참고로 (4)의 조건이 없어지면 Sigma-algebra가 아닌 Algebra가 된다. 참고로 컴퓨터 이론의 기초를 이루는 2진수 연산인 <strong>Bool algebra</strong>(불대수)도 따지고 보면 여기서 말하는 algebra이다. 그리고 (3) 의 조건을 비가부번수까지 포함해서의 합집합에 대해서 라는 조건으로 바꾸어주고 유한개의 교집합에 대해서 닫혀 있으면 <strong>위상(Topology)</strong>가 된다. 이렇듯 쉽게 보이는 것도 엄밀하게 따지지 않으면 안 되는 이유가 바로 이것이다.</p>
<p>무한이고 연속인 것을 머리 속에서 엄밀한 Simulation을 할 수가 없는데 이럴 경우 쉽게 볼 수 있는 간단한 discrete case를 가지고 머리 속에서 가지고 놀면 된다. 대상을 간단하게 한다고 하지만 그 대상에 대해서 무한과 연속을 다루는 규칙을 똑같이 적용하면 적어도 오류에 다다르지는 않는다. 그리고 때때로 그 결과는 그대로 연속일 때로 확장시켜 생각해도 된다. 물리학에서도 discrete로 모델을 만들고 모델을 미소변화량에 대한 연속모델로 만드는 것과 비슷하다. 게다가 <strong>Caratheodory Extension</strong>와 <strong>Pi-System</strong> 같은 도구들은 이론적으로 그러한 것이 타당하다는 보장까지 하니… 맘놓고 생각해도 된다. Caratheodory Extension 이니 Pi system이니 하는 것은 일단은 몰라도 된다. 이제 Sigma-Algebra에 대해서 조금 더 생각해 보자.</p>
<p>A={w1,w2, w3}</p>
<p>인 A의 <strong>(2개의 원소를 가진)</strong> Sigma Algebra <span class="math inline">\(F\)</span>들을 구해보면</p>
<p>F1={ Ø, A}</p>
<p>위 F1은 A위에서 Sigma Algebra의 1,2,3 을 만족시킨다. <strong>유한집합이므로 3을 만족시키는 것은 4도 만족시킨다</strong>. 하지만 <strong>이것은 무한집합에서는 일반적인 것은 아니다</strong>.</p>
<p>F2={ Ø, {w1}, {w2,w3}, {w1,w2, w3}}</p>
<p>F3={ Ø, {w1}, {w2}, {w3}, {w1, w2}, {w2, w3}, {w1, w3}, {w1, w2, w3}}</p>
<p>어째든지 F1, F2, F3 셋 다 A위의 Sigma – Algebra이다. 그리고 F1⊆F2⊆F3이다.</p>
<p>F1, F2, F3, 중에서 {w2, w3}을 포함하는 Sigma-Algebra 는 F2, F3이다. 그런데 F2와 F3중에서 크기가 작은 것은 F2이다. 즉 <strong>F2는 {w2, w3}을 포함하는 가장 작은 Sigma-Algebra</strong>이다. 이것은 {w2, w3}이 생성(generate)하는 Sigma-Algebra이다. 기호로는 Sigma({w2,w3}) 이다. 또한 Sigma({w1, w3})=F3이다. 그리고 짐작을 했겠지만 A의 모든 부분집합의 모임인 <strong>P(A)가 가장 큰 Sigma Field이다</strong>.</p>
<p>어떤 집합(A)의 모든 열린집합들이 Generate하는 Sigma algebra를 <strong>Borel Field</strong> 라고 하고 B(A) 라고 쓰고 그 원소를 <strong>Borel Set</strong>이라고 한다. 어떤 집합이 실수의 집합이면 B(A)는 실수의 모든 열린집합들이 Generate하는 Sigma algebra 가 된다. 이딴거 어따쓰나 생각할지 모르겠지만 이것이 바로 <strong>‘길이’</strong> 라고 부를 수 있는 대상들의 모임인 것이다. 길이measure도 어렵게 말하면 lebegue measure라고 한다.</p>
<p>머리에서 김 나겠지만 좀더 생각해 보자. **수직선 위의 어느 한 점으로 이뤄진 집합도, 그러한 점들이 자연수개수만큼씩 있는 집합도 다 __Borel set__이므로 길이를 생각할 수 있다<strong>. 그 길이는 무엇일까? 답은 0 이다. 0과 1 사이의 모든 유리수 집합도 그 길이는 0이다. 가부번 집합의 길이는 0이 된다. </strong>연속적인 실수의 구간은 역시 Borel set<strong>이고 </strong>양끝의 값의 차이가 당근 길이이다<strong>. 그리고 그 구간에서 가부번 집합을 뺀 – 예를 들어 실수에서 유리수를 뺀 무리수의– 길이도 양끝 길이의 차이와 같다 왜냐하면 가부번 집합의 길이가 0이기 때문이다. </strong>무리수구간의 길이<strong>는 같은 끝점을 가진 실수 구간의 길이에서 유리수 길이를 빼야 하는데 </strong>그 값, 즉 유리수의 길이,**이 0이므로 실수 구간의 길이와 같게 된다.</p>
<p><strong>가부번 집합</strong>이 아닌 경우에 반드시 길이가 있는가? 답은 No 이다. 칸토르 집합의 경우 <strong>비가부번 집합</strong>이지만 전체 길이는 0 인 황당한 case 가 있기는 있다.</p>
<p>가부번, 비가부번 집합이란 둘 다 무한집합(원소의 개수가 무한개인 집합)을 의미한다.</p>
<p>참고로 측도가 0인 집합을 영집합(Null Set)이라고 하는데 해석학이건 확률론이건 확률미분방정식(Stochastic Differential Equation) 등에서 의외로 중요한 개념이므로 반드시 한번 더 보고 가자.</p>
<p>또한 실수에서 길이를 생각할 때 <strong><strong>왜</strong> 실수집합의 <strong>모든 부분집합</strong> 위에서 길이를 생각하지 않고 꼭 Borel Set위에서 정의를 하냐</strong>고 생각할 수 있겠는데… 이것은 아마도 실수의 부분집합들 중에 길이의 대상이 되기에 부적합한 부분집합들이 존재하기 때문이라고 생각된다.</p>
<p>솔직하게 이쯤 되면 이제 머리 속에서 속속들이 Simulation을 하는 것은 포기해야 한다. 어떤 집합은 (보통) 무한집합인데 무한집합의 Sigma-algebra를 적는 것은 사실상 불가능 할뿐더러 열린집합들의 모임이라는 것도 그리 생각하는 것이 쉽지 않다. 그러니 그것이 generate하는 것을 머리에 어떻게 떠올린다는 것인가? 수학도들은 숱한 반복적인 증명연습과 연습문제 풀이로 장님 코끼리 만지듯이 <strong>감각을 키워나가지만</strong> 문제는 시간이다… 하루아침에 되는 것이 아니기 때문이다.</p>
<p>그렇지만 이것만 우선 먼저. 측도라는 것은 측정에 관한 이야기이다. 길이도 가장 간단한 측도이다. 길이의 대상이 되는 것들을 생각해 보자. 각각의 대상을 합해 놓아도 길이의 대상이 된다. 뿐만 아니라 <strong>두 측도 값의 합이 바로 합집합의 측도값이 된다. Sigma–Algebra의 특성인 ‘합집합에 대해서 닫혀 있음’이 바로 이것을 의미한다. </strong></p>
<p>위의 A집합에 대해서 F2를 생각해 보자.</p>
<p>F2={ Ø, {w1}, {w2,w3}, {w1,w2, w3}}</p>
<p>Ø → 0
{w1} → 0.4
{w2, w3} → 0.6
{w1,w2,w3} → 1</p>
<p>이렇게 Sigma Algebra의 각 값에 대해서 측도 값을 부여하였다. <strong>물리적인 의미는 없고</strong>, <strong>측도의 논리</strong>에 틀리지 않게 구성이 되어 있다. 한번 보자 “어떠한 원소들의 여집합이 Sigma Algebra의 원소이다.”
확률의 경우를 생각해 보면 <strong>어떤 사건이 일어난 확률이 <strong>있다면</strong> 그것이 일어나지 않을 확률이 반드시 <strong>있다</strong></strong>는 의미와 같다.</p>
<p>있다면 = <span class="math inline">\(\sigma\)</span>-field에 속한다면
있다 = <span class="math inline">\(\sigma\)</span>-field에 속한다</p>
<p>“어떠한 원소들의 합집합이 Sigma Algebra의 원소이다.”</p>
<p>또한 <strong>두 독립적 사건의 확률을 각각 계산할 수 있다면 반드시 두 사건 중 하나가 일어날 확률도 계산할 수 있다</strong>는 것을 의미한다.
또한 <strong>두 독립적 사건의 동시에 일어날 확률(합집합)은 각 확률(measure)의 합</strong>이다.</p>
<p>이러한 생각으로 위 측도값들을 보면 전혀 모순이 없다는 것을 알 수 있다. 물론 이러한 측도값은 하나만 있는 것이 아니다.</p>
<p>Ø → 0
{w1} → 0.2
{w2, w3} → 0.8
{w1,w2,w3} → 1</p>
<p>이렇게 해도 부여한 측도값에는 전혀 문제 없다.</p>
<p><mark>
<strong>그런데 {w2}에 대해서 측도값(확률)을 부여할 수 있는가?</strong> 예를 들어 {w2}라는 사건이 존재한다면 뭐 억지로 어떤 값을 부여 했다고 하자. 그러면 {w2}가 일어나지 않는 경우에 대한 확률을 구할 수 있을까? 게다가 {w1} 또는 {w2}가 일어날 사건도 생각할 수 있는가? 대답할 수 없을 것이다. <strong>이러한 예는 왜 확률을 생각할 때 Sigma Algebra를 생각해야 하는지를 설명해 준다.</strong>
</mark></p>
<p>즉, {2}는 가측(measurable)인가?</p>
</div>
</div>
<div id="ft-measurable" class="section level3" number="9.6.2">
<h3 number="9.6.2"><span class="header-section-number">9.6.2</span> Ft-measurable</h3>
<p>위의 내용은 초보자에게는 접근할 수 있는 흥미를, 이미 내용을 알고 있는 사람들에게는 일종의 쉬어가는 페이지가 되었을 것 같다. 이제는 좀더 엄밀하게 접근을 하려고 한다.</p>
<p>Ft-measurable 이라는 것은 Ft라는 Filtration에 measurable 하다는 이야기이다. <strong>Filtration</strong>은 Sample Space Ω 의 Sigma Algebra 들의 모임인데 Ft1⊆Ft2⊆Ft3 (t1&lt;t2&lt;t3) 로 되어 있어서 시간이 지날수록 점점 Sigma Algebra들이 이전 <span class="math inline">\(\sigma\)</span>-Algebra를 포함하면서 커지도록 되어 있다. 이 절의 내용은 바로 이 Filtration의 몇 가지 가시적인 예제를 보여줄 것이고 그것이 엄밀한 수학적 정의와 어떻게 연결되는지를 따져 볼 것이다. 그렇게 해서 얻어진 가시적인 예제들은 장차 Stochastic Process에서 나오는 여러 가지 수학적인 개념들을 머리에서 Simulation 해서 각자의 이해의 영역으로 확보하는 과정에서 크나큰 역할을 하기만을 바랄 뿐이다.</p>
<div id="가측measurable이란" class="section level4" number="9.6.2.1">
<h4 number="9.6.2.1"><span class="header-section-number">9.6.2.1</span> 가측(measurable)이란</h4>
<p>먼저 measurable의 정의를 보자. Measurable의 의미를 따지기 전에 우선 임의의 하나의 함수를 생각해 보자. 그러한 함수는 집합A의 원소에서 실수로 간다고 하자. $f:A R</p>
<p><pics></p>
<p>위와 같은 예가 될 수 있겠다.</p>
<p><mark>
그 다음은 역상에 대해서 생각해 보자. (역상도 집합이다.) A의 부분집합 Ω 위로의 역상은 <span class="math inline">\(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\)</span> 으로 정의된다.</p>
<p><span class="math inline">\(f\)</span>의 정의역은 <span class="math inline">\(A\)</span>, 치역은 <span class="math inline">\(E\)</span>. 단, E는 보렐집합 (가측집합).
역함수, 역상과 <span class="math inline">\(\sigma\)</span>-algebra의 관계는?</p>
<p>조금만 생각해 보면 <span class="math inline">\(f^{-1}\)</span>는 결국 다음과 같은 하나의 함수이다.</p>
<p><span class="math display">\[
f^{-1} : B(R) \rightarrow \sigma
\]</span></p>
<p>Sigma(<span class="math inline">\(\sigma\)</span>)는 (Ω 위의 = <span class="math inline">\(\Omega\)</span>가 생성하는) Sigma algebra이다. 즉 정의구역은 Borel Set(<span class="math inline">\(B(R)\)</span>) 들이고 공변역(치역)은 Ω의 Sigma algebra이다.
</mark></p>
<p>E는 실수의 Borel set 의 원소이다. 모든 E를 다 여기서 명세할 수는 없지만 몇가지 경우로 분류할 수는 있다.
1. r1을 원소로 포함한 E들 — 이것들의 무리를 E1이라고 하자
2. r1를 원소로 포함하지 않는 E들 — 이것들의 무리를 E1’이라고 하자</p>
<p><span class="math display">\[
\begin{align}
E &amp;= E_1 \cup E_2
E_1 \cap E_2 &amp;= \emptyset
\end{align}
\]</span></p>
<p>E1에 속한 E의 경우 <span class="math inline">\(f^{-1}(E)\)</span> 는 Ω가 된다. <mark>Check it!</mark>
E1’에 속한 E의 경우 <span class="math inline">\(f^{-1}(E)\)</span> 는 Ø가 된다. <mark>Check it!</mark></p>
<p>이때 주의해야 할 점은 E의 원소로 r2, r3, r4, 가 있는 경우이다. 이 경우 이들에 대한 f의 역함수 값은 A에는 존재할 수도 있다. 하지만 Ω의 원소 중에는 그런 없기 때문에 Ø 되는 것이다. 다시 한번 정의를 살펴보자.
<span class="math inline">\(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\)</span> 이다. x는 Ω의 원소이어야만 한다. 그런 원소가 아니면 공집합이 된다.
Ω 와 Ø 의 모임인 {Ω , Ø} 는 Ω 위의 Sigma algebra 이다. 특별히 Ω 가 Generate하는 Sigma algebra 라고 한번 생각해 주고 넘어가자.</p>
<p>이제 measurable의 정의를 보자.</p>
<p>함수 f: Ω → R이 F – measurable 이면, <span class="math inline">\(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\)</span> 가 Ω 위에서 Sigma Algebra F의 원소이다.</p>
<p>그런데 어떤 책에서는</p>
<p>함수 f: Ω → R이 F – measurable 이면 <span class="math inline">\(f^{-1} (E) = \{ x | x \in \Omega, \; f(x) \in E \subseteq B(R)\}\)</span> 가 Ω 위에서 Sigma Algebra 를 이룬다.</p>
<p>라고 해서 사람을 헷갈리게 만든다. 이게 왜 사람 헷갈리게 만드는가 하면 F 안의 원소인 e1의 상이 B(R) 의 원소가 아닐 경우 위의 두 개의 정의는 동치가 되기 때문이다.
아직 이 문제는 개인적으로는 해결이 안되었고 학습에는 그다지 큰 문제는 아니므로 첫 번째 정의를 받아들이자.</p>
</div>
<div id="filtration" class="section level4" number="9.6.2.2">
<h4 number="9.6.2.2"><span class="header-section-number">9.6.2.2</span> Filtration</h4>
<div id="t-0-일때-ft" class="section level5" number="9.6.2.2.1">
<h5 number="9.6.2.2.1"><span class="header-section-number">9.6.2.2.1</span> t =0 일때 Ft</h5>
<p>Ω={w1, w2, w3, w4} 라고 하자.</p>
<p><pics></p>
<p>B(R) 들의 원소 들 E 들은 r1 을 원소로 같는 E 들의 무리 E1 이 있고 그렇지 못한 무리 E2 가 있을 수 있다.
앞의 경우에서 해설한 바 몇 가지 점을 유의하면 다음과 같은 결과를 얻는다.</p>
<ol style="list-style-type: decimal">
<li>무리 E1 들의 역상은 Ω 이다.</li>
<li>무리 E2 들의 역상은 Ø 이다.</li>
<li>따라서 B(R)의 모든 역상들의 모임은 {Ω, Ø} 이다.</li>
<li>Ft(t=0) = F0 을 {Ω, Ø}이라고 하면 함수 f 는 위 정의에 의하여 F0 measurable이다.</li>
<li>결과적으로 보니까. F0는 partition{Ω, Ø} 이 generate하는 Sigma Algebra로 볼 수 있다.</li>
</ol>
</div>
<div id="t-1-일-때-ft" class="section level5" number="9.6.2.2.2">
<h5 number="9.6.2.2.2"><span class="header-section-number">9.6.2.2.2</span> t =1 일 때 Ft</h5>
<p><pics></p>
<p>앞에서와 같이 B(R)을 다음과 같이 나눌 수 있다. 그리고 앞에서 한 분석을 다시 해보면 다음과 같은 결과가 나온다.</p>
<table>
<thead>
<tr class="header">
<th align="center">E의 그룹</th>
<th align="center">그룹의 성격</th>
<th align="center">그룹내 모든 E들의 역상</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">E1</td>
<td align="center">r1 을 원소로 갖는 E들</td>
<td align="center">{w1}</td>
</tr>
<tr class="even">
<td align="center">E2</td>
<td align="center">r2 을 원소로 갖는 E들</td>
<td align="center">{w2, w3, w4}</td>
</tr>
<tr class="odd">
<td align="center">E12</td>
<td align="center">r1과 r2 모두를 원소로 갖는 E들</td>
<td align="center">{w1, w2, w3, w4}</td>
</tr>
<tr class="even">
<td align="center">En</td>
<td align="center">r1과 r2 모두를 원소로 갖지 않는 E들</td>
<td align="center">Ø</td>
</tr>
</tbody>
</table>
<p>마지막 열의 집합들은 partition{{w1}, {w2, w3, w4}} 이 generate하는 F1 내에 속하게 된다.</p>
</div>
<div id="t-2-일때-ft" class="section level5" number="9.6.2.2.3">
<h5 number="9.6.2.2.3"><span class="header-section-number">9.6.2.2.3</span> t =2 일때 Ft</h5>
<p>앞의 분석을 여기서 다시 하면 다음과 같은 결과를 얻을 수 있다.</p>
<table>
<thead>
<tr class="header">
<th align="center">E의 그룹</th>
<th align="center">그룹의 성격</th>
<th align="center">그룹내 모든 E 들의 역상</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">E1</td>
<td align="center">r1 을 원소로 갖는 E들</td>
<td align="center">{w1}</td>
</tr>
<tr class="even">
<td align="center">E2</td>
<td align="center">r2 을 원소로 갖는 E들</td>
<td align="center">{w2}</td>
</tr>
<tr class="odd">
<td align="center">E3</td>
<td align="center">r3 을 원소로 갖는 E들</td>
<td align="center">{w3, w4}</td>
</tr>
<tr class="even">
<td align="center">E12</td>
<td align="center">r1과 r2를 동시에 원소로 갖는 E들</td>
<td align="center">{w1, w2}</td>
</tr>
<tr class="odd">
<td align="center">E13</td>
<td align="center">r1과 r3를 동시에 원소로 갖는 E들</td>
<td align="center">{w1, w3, w4}</td>
</tr>
<tr class="even">
<td align="center">E23</td>
<td align="center">r2과 r3를 동시에 원소로 갖는 E들</td>
<td align="center">{w2, w3, w4}</td>
</tr>
<tr class="odd">
<td align="center">E123</td>
<td align="center">r1, r2, r3를 동시에 원소로 갖는 E</td>
<td align="center">{w1, w2, w3, w4}</td>
</tr>
<tr class="even">
<td align="center">En</td>
<td align="center">r1, r2, r3를 원소로 갖지 않는 E</td>
<td align="center">Ø</td>
</tr>
</tbody>
</table>
<p>확인해보면 마지막 컬럼의 집합들은 {{1},{2},{3, 4} }이 Generate하는 Sigma algebra의 원소들이다.</p>
<p>이제 어느 정도 요령이 생기고 규칙 같은 것들이 생길 것이다. 쉽게 말하면 Sample space를 partition 해서 Sigma Algebra Ft들을 generate하는 것이다. <mark>t가 증가함에 따라 partition을 좀더 세분화 하면 Ft1⊆Ft2⊆Ft3… 이런식으로 Filtration 을 만들 수 있다.</mark></p>
</div>
</div>
<div id="좀더-현실적인-예" class="section level4" number="9.6.2.3">
<h4 number="9.6.2.3"><span class="header-section-number">9.6.2.3</span> 좀더 현실적인 예</h4>
<p>좀더 많이 볼 수 있는 Random process 에 적합한 예를 만들어 보자. 동전을 던져서 앞이 나오면 1 뒤가 나오면 0을 점수에 더하는 것으로 하자. 점수는 random process(라고 보아도 되는 것)이다. 동전던지기는 (최대) 3회까지 하는 것으로 하자. Sample space Ω 는 다음과 같이 구성할 수 있다.</p>
<p><pics></p>
<p>동전던지기 첫회 시행에 위, 그 다음 시행에 아래, 그 다음 시행에 위가 나오는 경우는 Wudu 이라고 보면 된다. T=0 시점은 동전던지기를 시행하기 전이다.</p>
<p>각 동전던지기 수행 시점에서 Random process인 점수를 다음 테이블에 표시하였다.</p>
<p><pics></p>
<p>앞의 예제들로 요령이 생겼으니 각각의 시점에서 해당 Sigma – algebra를 얻을 수 있을 것이다. T=0 일 경우에는 { Ø, Ω } 가 generate하는 Sigma-algebra이고 t=1 인 경우에는 Ω 를 1인 값과 0인 값으로 partition을 하고 그것으로부터 Sigma-algebra를 생성(generate)할 수 있다.</p>
<p>각각에 대해서 증대하는 Sigma – algebra인 filtration을 볼 수 있으면 random process가 Ft에 measurable이라는 것이 어떠한 것인지 적어도 논리적으로 알 수 있을 것이다.</p>
</div>
<div id="정보-집합으로서의-filtration" class="section level4" number="9.6.2.4">
<h4 number="9.6.2.4"><span class="header-section-number">9.6.2.4</span> 정보 집합으로서의 Filtration</h4>
<p>Stochastic process에서 나오는 이론적인 case에서는 위의 예제를 머리 속에서 굴려보면 충분히 이해가 될 듯 싶다. 그런데 간간히 들리는 이야기는 Filtration을 시장을 움직이는 정보들의 모임이라고 보는 견해가 있다. 이것을 알면 증대해 나가는 Sigma algebra에 대한 색다른 관점을 가지게 되는 것이고 또한 금융수학이 목적이면 우리가 사는 세상과 이 수학적 모델이 어떤 연결고리를 가지고 있는 것인지를 알아볼 수 있는 기회가 된다고 생각된다.</p>
<p>3개의 현실세계에서 주식가격을 움직이는 사건이 있다고 치자.</p>
<p>A. 2000년 4월 금리인하조치 발표 – 발생될 경우 주식가격 10% 상승
B. 2001년 9월 11일 뉴욕 무역센터 건물 붕괴 – 발생될 경우 주식가격 30% 하락
C. 2002년 3월 예상을 웃도는 회계실적 발표 – 발생될 경우 주식가격 15% 상승</p>
<p>일어난다면 대문자 일어나지 않는다면 소문자로 표기하면 WABc는 A는 일어나고 B도 일어나고 c는 일어나지 않는다는 case이다.</p>
<p>위의 세 사건말고는 절대 주식가격이 움직이지 않는다고 가정한다.</p>
<p><pics></p>
<ol style="list-style-type: decimal">
<li>1999.12 에는 Sigma Algebra가 { Ø, Ω } 이었다. 모든 사건들의 case는 아직 일어나지 않았다.</li>
<li>2000년 4월에 Sigma Algebra는 { {WABC, WABc, WAbC, WAbc}, {WaBC, WaBc, WabC, Wabc}}이라는 partition이 Generate하는 것이다. W의 첨자 중에서 첫번째 첨자가 가격을 결정한 것이다. 100원이 될지 110원이 될지는 첫 번째 첨자에 해당하는 사건의 정보가 나타났기 때문이다. 다시 말하면 2000년 4월에 100원 또는 110원을 결정하는 것은 2000년 4월에 일어난 ‘사건’이다. 이런 식으로 점점 잘게 partition 을 쪼개어 나가고 그것이 generate하는 것이 Filtration 이고 정보가 점점 증가된다.</li>
<li>위의 모델을 잘 살펴보면 특정시점의 주식가격의 결정은 그때까지의 모든 발생된 정보에 의해서 결정된다. 2001년 9월 직후의 주식가격은 첨자A와 첨자 B에 해당하는 사건발생여부의 ‘정보’가 가격을 결정한다.</li>
</ol>
</div>
<div id="natural-filtration" class="section level4" number="9.6.2.5">
<h4 number="9.6.2.5"><span class="header-section-number">9.6.2.5</span> Natural Filtration</h4>
<ol style="list-style-type: decimal">
<li>실제로는 주식가격을 결정하는 정보는 무한이고 그에 따른 주식가격의 변화도 연속적으로 바뀐다. 하지만 모든 정보의 결과가 주식가격으로 나타나니까. t시점의 정보의 변화는 t시점의 가격으로 반영이 된다. Sigma algebra가 어떤 partition에 의해 generate되는 것이라면 그 partition들을 이루는 집합들은 마치 t시점의 주식가격을 index처럼 가지고 있는 것처럼 만들어야 한다. 다시 말하면 partition내의 집합마다 각각 다른 St값을 가지고 있어야 한다. 이를테면 { …{St=99, …}, {St=100…}, {St=101…}, …} 이런 식으로 partition을 하면 된다.</li>
<li>t에서 dt만큼 지난 t’ 시점에서는 위의 각각의 partition 들을 다시 각각 쪼갠다. 쪼개는 방법은 각각의 partition의 집합들이 St와 St’ 2개의 index로 가지도록 하면 된다. 이렇게… {…{St=99, St’=99…}, {St=99, St’=100…}, {St=99, St’=101},… {St=100, St’=99…}, {St=100, St’=100…}, {St=100, St’=101},… ,{St=101, St’=99…}, {St=100, St’=100…}, {St=99, St’=101}…} 이런 식으로 말이다.</li>
<li>위의 식을 간략하게 말해보자. 첫 번째 t에서의 Partition(또는 책에 따라서는 Decomposition이라고 하기도 하더구먼)을 D(St)라고 표현해본다. St가 generate 하는 Partition이라고 생각하면 된다. 구체적인 방법은 위에 설명했다. T’에서는 어떻게 될까? D(St, St’) 두 개의 주식가격(또는 Random variable)에 의해서 generate되는 partition인 것이다.</li>
<li>일반적으로 보면 D(S0, S1, S2,….St)가 된다. T시점의 Sigma algebra Ft는 D(S0, S1,S2, …St)가 generate하는 Sigma-algebra이다. 이것을 σ(S0, S1, S2…St)라고 표시한다.</li>
</ol>
<p>마지막 절을 다룬 것은 몇몇의 다른 책에 위와 같은 notation이 있기 때문이다.</p>
</div>
</div>
<div id="epilogue" class="section level3" number="9.6.3">
<h3 number="9.6.3"><span class="header-section-number">9.6.3</span> EPILOGUE</h3>
<p>하여튼지 수학책에는 St까지의 Random process가 generate하는 partition이니 Decomposition이니 또 그것이 Generate하는 Sigma-algebra니… 이러니까. 논리적으로는 깔끔해 보이지만 그게 눈으로 들어오기까지는 참으로 죽을 맛이더라. 하긴 이렇게 깔끔한 표현이 도움이 되긴 한다. 앞에서도 말했지만 앞에서 13페이지가 넘게 주저리주저리 써 놓은 것을 수학책에서는 몇 줄로 표현을 하니까.. 깔끔스럽기는 이보다 더하지는 못할 것이다. 많이 생각한 수학의 정의는 대부분 암기하게 되는데… 그게 외우려고 외워지는 것이 아니다. 애매한 예들을 적용하려고 Definition을 수십 번 들춰보게 되는데 그러면 자연스럽게 토씨 하나까지 암기 하게 된다. 이것은 토씨 하나에 따라 정말 많은 것이 좌우되기 때문인데 이때마다. 수학적 정의가 얼마나 정교하게 만들어진 것인지를 새삼 깨닫게 된다. 그렇다 하더라도 개인적으로는 수학자들에게 불만이 많다. 깔끔하게 써 놓은 것도 이해는 가지만, 좀 이해하기 좋게 주저리주저리 쓰는 개인교습교재를 함께 만들었으면 하는 바람 때문이다. 말이 나왔으니 말인데, 수학책들은 두께는 얇으면서도 내용은 많고 비싸기로 유명하다. 비싼 것은 대중적이지 않으니까 그렇다 쳐도, 내용이 많은 것은 그 많은 내용을 압축해서 썼기쓰여졌기 때문이다. 고딩 때 정석책도 그런 식으로 쓰면 아마 책 내용이 1/7로 줄을 것 같다. 반대로 중편소설책 같은 분량의 수학책도 고딩 때 정석책처럼 주저리주저리 설명을 하려면 아마도 백과사전 책의 몇 권이 될 것 같다. 실제로 수학책의 강의노트들은 두꺼운 파일로 정리해도 네댓 개는 나온다. 강의노트 없이 그리고 정식 수학과정을 밟지 않은 공돌이가 맨땅에 헤딩해보니까. 나오는 것은 머리에 피나는 일밖에 없더라. 방법은 그저 조금 더 생각해 보고 써보고 낮은 포복이라도 멈추지 않고 기어가는 길일 것이다. 그래도 이렇게 쓰는 일로 해서 다른 사람들이 좀더 빨리 이해하고 도움이 되면 그간의 고통이 보람이 될 것이라고 믿는다. 여기의 모든 예들은 본인이 직접 고안한 것이다. 뭐, 저작권을 이야기 하려는 것은 아니고 다만 공인된 내용이 아니라(그래도 곡학아세로 혹세무민하는 일은 결코 없다.)그래도 수학이니 엄밀성을 요하는 부분에 부족한 점이 있을 수 있다는 것을 말하려는 것이다. 해서 보다 고수님들이 이 부분을 지적해 주면 더할 나위 없이 고맙겠다. 또한 충분히 설명을 하려고 했으나, 생각지 못한 부분이 있을 수 있으니 보다가 모르는 부분이 있으면 같이 생각하는 것도 또한 쌍방의 유익이 될 것도 같다. 하나 알아둘 것은 본 내용은 Self-Contained이지 않다. 무슨 이야긴고 하면 Sigma-algebra이고 measure고 Random Process이고 생판 모르는 사람이 본 이 내용을 보고 예수가 장님 눈뜨게 하듯 번쩍 뜨일 것 같지는 않을 것 같다는 말이다. 적어도 한번은 수학책을 보고 고민해서 이 생각 저 생각쯤은 한번쯤 한 사람들에게 도움이 되지 않을까?</p>
<p>아직은 장마다. 주룩주룩 내리는 비속에서 스타벅스같은 데서 노트북이나 두드리는 한가함을 기대해보면서 이만 펜을 놓는다.</p>
<!--chapter:end:212598_Filtration.Rmd-->
</div>
</div>
<div id="concepts" class="section level2" number="9.7">
<h2 number="9.7"><span class="header-section-number">9.7</span> Concepts</h2>
<p><span class="math inline">\(S(t)\)</span>: survival function. 시점 <span class="math inline">\(t\)</span>까지는 살아있을 확률.</p>
<p><span class="math inline">\(h(t) = \lambda(t) = \frac{f(t)}{S(t)}\)</span>: hazard function. 시점 <span class="math inline">\(t\)</span>에서 사망할 확률.</p>
<!--chapter:end:212599_Notion.Rmd-->
</div>
</div>
<div id="appendix-00-00" class="section level1 unnumbered">
<h1 class="unnumbered">(APPENDIX) 00-00</h1>
</div>
<div id="r-bookdown" class="section level1" number="10">
<h1 number="10"><span class="header-section-number">10</span> R Bookdown</h1>
<div id="tutorial" class="section level2" number="10.1">
<h2 number="10.1"><span class="header-section-number">10.1</span> Tutorial</h2>
<div id="about" class="section level3" number="10.1.1">
<h3 number="10.1.1"><span class="header-section-number">10.1.1</span> About</h3>
<p>This is a <em>sample</em> book written in <strong>Markdown</strong>. You can use anything that Pandoc’s Markdown supports; for example, a math equation <span class="math inline">\(a^2 + b^2 = c^2\)</span>.</p>
<div id="usage" class="section level6" number="10.1.1.0.0.1">
<h6 number="10.1.1.0.0.1"><span class="header-section-number">10.1.1.0.0.1</span> Usage</h6>
<p>Each <strong>bookdown</strong> chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter <em>must</em> start with a first-level heading: <code>### A good chapter</code>, and can contain one (and only one) first-level heading.</p>
<p>Use second-level and higher headings within chapters like: <code>###### A short section</code> or <code>######### An even shorter section</code>.</p>
<p>The <code>index.Rmd</code> file is required, and is also your first book chapter. It will be the homepage when you render the book.</p>
</div>
<div id="render-book" class="section level6" number="10.1.1.0.0.2">
<h6 number="10.1.1.0.0.2"><span class="header-section-number">10.1.1.0.0.2</span> Render book</h6>
<p>You can render the HTML version of this example book without changing anything:</p>
<ol style="list-style-type: decimal">
<li><p>Find the <strong>Build</strong> pane in the RStudio IDE, and</p></li>
<li><p>Click on <strong>Build Book</strong>, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files.</p></li>
</ol>
<p>Or build the book from the R console:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>bookdown<span class="sc">::</span><span class="fu">render_book</span>()</span></code></pre></div>
<p>To render this example to PDF as a <code>bookdown::pdf_book</code>, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): <a href="https://yihui.org/tinytex/" class="uri">https://yihui.org/tinytex/</a>.</p>
</div>
<div id="preview-book" class="section level6" number="10.1.1.0.0.3">
<h6 number="10.1.1.0.0.3"><span class="header-section-number">10.1.1.0.0.3</span> Preview book</h6>
<p>As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book,” or from the R console:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>bookdown<span class="sc">::</span><span class="fu">serve_book</span>()</span></code></pre></div>
</div>
</div>
<div id="hello-bookdown" class="section level3" number="10.1.2">
<h3 number="10.1.2"><span class="header-section-number">10.1.2</span> Hello bookdown</h3>
<p>All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (<code>###</code>) per .Rmd file.</p>
<div id="a-section" class="section level6" number="10.1.2.0.0.1">
<h6 number="10.1.2.0.0.1"><span class="header-section-number">10.1.2.0.0.1</span> A section</h6>
<p>All chapter sections start with a second-level (<code>######</code>) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter.</p>
<div id="an-unnumbered-section" class="section level9 unnumbered">
<p class="heading" class="unnumbered">An unnumbered section</p>
<p>Chapters and sections are numbered by default. To un-number a heading, add a <code>{.unnumbered}</code> or the shorter <code>{-}</code> at the end of the heading, like in this section.</p>
</div>
</div>
</div>
<div id="cross-references" class="section level3" number="10.1.3">
<h3 number="10.1.3"><span class="header-section-number">10.1.3</span> Cross-references</h3>
<p>Cross-references make it easier for your readers to find and link to elements in your book.</p>
<div id="chapters-and-sub-chapters" class="section level6" number="10.1.3.0.0.1">
<h6 number="10.1.3.0.0.1"><span class="header-section-number">10.1.3.0.0.1</span> Chapters and sub-chapters</h6>
<p>There are two steps to cross-reference any heading:</p>
<ol style="list-style-type: decimal">
<li>Label the heading: <code>### Hello world {###nice-label}</code>.
<ul>
<li>Leave the label off if you like the automated heading generated based on your heading title: for example, <code>### Hello world</code> = <code>### Hello world {###hello-world}</code>.</li>
<li>To label an un-numbered heading, use: <code>### Hello world {-###nice-label}</code> or <code>{### Hello world .unnumbered}</code>.</li>
</ul></li>
<li>Next, reference the labeled heading anywhere in the text using <code>\@ref(nice-label)</code>; for example, please see Chapter <code>\@ref(cross)</code>.
<ul>
<li>If you prefer text as the link instead of a numbered reference use: <a href="###cross">any text you want can go here</a>.</li>
</ul></li>
</ol>
</div>
<div id="captioned-figures-and-tables" class="section level6" number="10.1.3.0.0.2">
<h6 number="10.1.3.0.0.2"><span class="header-section-number">10.1.3.0.0.2</span> Captioned figures and tables</h6>
<p>Figures and tables <em>with captions</em> can also be cross-referenced from elsewhere in your book using <code>\@ref(fig:chunk-label)</code> and <code>\@ref(tab:chunk-label)</code>, respectively.</p>
<p>See Figure @ref(fig:nice-fig).</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, .<span class="dv">1</span>, .<span class="dv">1</span>))</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pressure, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="_main_files/figure-html/nice-fig-1.png" alt="Plot with connected points showing that vapor pressure of mercury increases exponentially as temperature increases." width="80%" />
<p class="caption">
(#fig:nice-fig)Here is a nice figure!
</p>
</div>
<p>Don’t miss Table @ref(tab:nice-tab).</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(pressure, <span class="dv">10</span>), <span class="at">caption =</span> <span class="st">&#39;Here is a nice table!&#39;</span>,</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">booktabs =</span> <span class="cn">TRUE</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption>(#tab:nice-tab)Here is a nice table!</caption>
<thead>
<tr class="header">
<th align="right">temperature</th>
<th align="right">pressure</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.0002</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">0.0012</td>
</tr>
<tr class="odd">
<td align="right">40</td>
<td align="right">0.0060</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">0.0300</td>
</tr>
<tr class="odd">
<td align="right">80</td>
<td align="right">0.0900</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="right">0.2700</td>
</tr>
<tr class="odd">
<td align="right">120</td>
<td align="right">0.7500</td>
</tr>
<tr class="even">
<td align="right">140</td>
<td align="right">1.8500</td>
</tr>
<tr class="odd">
<td align="right">160</td>
<td align="right">4.2000</td>
</tr>
<tr class="even">
<td align="right">180</td>
<td align="right">8.8000</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="parts" class="section level3" number="10.1.4">
<h3 number="10.1.4"><span class="header-section-number">10.1.4</span> Parts</h3>
<p>You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file.</p>
<p>Add a numbered part: <code>### (PART) Act one {-}</code> (followed by <code>### A chapter</code>)</p>
<p>Add an unnumbered part: <code>### (PART\*) Act one {-}</code> (followed by <code>### A chapter</code>)</p>
<p>Add an appendix as a special kind of un-numbered part: <code>### (APPENDIX) Other stuff {-}</code> (followed by <code>### A chapter</code>). Chapters in an appendix are prepended with letters instead of numbers.</p>
</div>
<div id="footnotes-and-citations" class="section level3" number="10.1.5">
<h3 number="10.1.5"><span class="header-section-number">10.1.5</span> Footnotes and citations</h3>
<div id="footnotes" class="section level6" number="10.1.5.0.0.1">
<h6 number="10.1.5.0.0.1"><span class="header-section-number">10.1.5.0.0.1</span> Footnotes</h6>
<p>Footnotes are put inside the square brackets after a caret <code>^[]</code>. Like this one.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
</div>
<div id="citations" class="section level6" number="10.1.5.0.0.2">
<h6 number="10.1.5.0.0.2"><span class="header-section-number">10.1.5.0.0.2</span> Citations</h6>
<p>Reference items in your bibliography file(s) using <code>@key</code>.</p>
<p>For example, we are using the <strong>bookdown</strong> package <span class="citation">(<a href="#ref-R-bookdown" role="doc-biblioref">Xie 2021</a>)</span> (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and <strong>knitr</strong> <span class="citation">(<a href="#ref-xie2015" role="doc-biblioref">Xie 2015</a>)</span> (this citation was added manually in an external file book.bib).
Note that the <code>.bib</code> files need to be listed in the index.Rmd with the YAML <code>bibliography</code> key.</p>
<p>The RStudio Visual Markdown Editor can also make it easier to insert citations: <a href="https://rstudio.github.io/visual-markdown-editing/###/citations" class="uri">https://rstudio.github.io/visual-markdown-editing/###/citations</a></p>
</div>
</div>
<div id="blocks" class="section level3" number="10.1.6">
<h3 number="10.1.6"><span class="header-section-number">10.1.6</span> Blocks</h3>
<div id="equations" class="section level6" number="10.1.6.0.0.1">
<h6 number="10.1.6.0.0.1"><span class="header-section-number">10.1.6.0.0.1</span> Equations</h6>
<p>Here is an equation.</p>
<p><span class="math display">\[\begin{equation} 
  f\left(k\right) = \binom{n}{k} p^k\left(1-p\right)^{n-k}
\end{equation}\]</span></p>
<p>You may refer to using <code>\@ref(eq:binom)</code>, like see Equation <code>\@ref(eq:binom)</code>.</p>
</div>
<div id="theorems-and-proofs" class="section level6" number="10.1.6.0.0.2">
<h6 number="10.1.6.0.0.2"><span class="header-section-number">10.1.6.0.0.2</span> Theorems and proofs</h6>
<p>Labeled theorems can be referenced in text using <code>\@ref(thm:tri)</code>, for example, check out this smart theorem .</p>
<p>::: {.theorem ###tri}
For a right triangle, if <span class="math inline">\(c\)</span> denotes the <em>length</em> of the hypotenuse
and <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> denote the lengths of the <strong>other</strong> two sides, we have
<span class="math display">\[a^2 + b^2 = c^2\]</span></p>
</div>
</div>
</div>
</div>
</div>
<p>Read more here <a href="https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html" class="uri">https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html</a>.</p>
<div id="callout-blocks" class="section level6" number="10.1.6.0.0.3">
<h6 number="10.1.6.0.0.3"><span class="header-section-number">10.1.6.0.0.3</span> Callout blocks</h6>
<p>The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: <a href="https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html" class="uri">https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html</a></p>
</div>
</div>
</div>
<div id="sharing-your-book" class="section level3" number="10.1.7">
<h3 number="10.1.7"><span class="header-section-number">10.1.7</span> Sharing your book</h3>
<div id="publishing" class="section level6" number="10.1.7.0.0.1">
<h6 number="10.1.7.0.0.1"><span class="header-section-number">10.1.7.0.0.1</span> Publishing</h6>
<p>HTML books can be published online, see: <a href="https://bookdown.org/yihui/bookdown/publishing.html" class="uri">https://bookdown.org/yihui/bookdown/publishing.html</a></p>
</div>
<div id="pages" class="section level6" number="10.1.7.0.0.2">
<h6 number="10.1.7.0.0.2"><span class="header-section-number">10.1.7.0.0.2</span> 404 pages</h6>
<p>By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a <code>_404.Rmd</code> or <code>_404.md</code> file to your project root and use code and/or Markdown syntax.</p>
</div>
<div id="metadata-for-sharing" class="section level6" number="10.1.7.0.0.3">
<h6 number="10.1.7.0.0.3"><span class="header-section-number">10.1.7.0.0.3</span> Metadata for sharing</h6>
<p>Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the <code>index.Rmd</code> YAML. To setup, set the <code>url</code> for your book and the path to your <code>cover-image</code> file. Your book’s <code>title</code> and <code>description</code> are also used.</p>
<p>This <code>gitbook</code> uses the same social sharing data across all chapters in your book- all links shared will look the same.</p>
<p>Specify your book’s source repository on GitHub using the <code>edit</code> key under the configuration options in the <code>_output.yml</code> file, which allows users to suggest an edit by linking to a chapter’s source file.</p>
<p>Read more about the features of this output format here:</p>
<p><a href="https://pkgs.rstudio.com/bookdown/reference/gitbook.html" class="uri">https://pkgs.rstudio.com/bookdown/reference/gitbook.html</a></p>
<p>Or use:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>?bookdown<span class="sc">::</span>gitbook</span></code></pre></div>
</div>
</div>
<div id="references" class="section level3 unnumbered">
<h3 class="unnumbered">References</h3>
<!--chapter:end:990000_Tutorial.Rmd-->
</div>
</div>
</div>
<div id="noname" class="section level1" number="11">
<h1 number="11"><span class="header-section-number">11</span> NoName</h1>
<p>모먼트, MLE (2차까지 확인)</p>
<p>MLE 불변성</p>
<p>MSE를 통해 통계량 성능 비교 가능함
bias</p>
<p>MSE = precision + accuracy</p>
<p>UMVUE 7.5</p>
<p>크래머-라오 부등식 : 최저 분산 뽑아내는 수단</p>
<p>피셔 정보</p>
<p>2차원 피셔 정보</p>
<p>라오-블랙웰 : uniform better UE 뽑아내는 수단</p>
<p>unique best UE</p>
<p>best UE는 오직 하나뿐</p>
<p>(레만쉐페) CSS에 기반한 UE는 오직 유일함</p>
<p>W가 best UE면 W는 다른 모든 0에 대한 추정자들과 무연관 7.7</p>
<p>consistent (점근성)</p>
<p>충분통계량에 기반한 가설검정은 원본데이터 가설검정과 결과 동일</p>
<p>test으 unbaised 8.8</p>
<p>네이만 피어슨</p>
<p>카를린 루빈 8.3</p>
<p>빅 샘플 추정자들과 8.5</p>
<p>스코어 스탯 8.12</p>
<p>왈드 테스트 8.13</p>
<p>1-a confidence iterval = acceptance region of level 알파 test</p>
<p>뒤집은 테스트의 성질은 컨피던스 인터벌에도 전이됨</p>
<p>pivotal 주어진 X랑 모수로 다른 변량 만들었을 때 이것이 오리지널 모수와 무관한 분포 따름. CLT.</p>
<p>MLE는 asymptotic 성질 갖음. MLE를 asymptotic 했을 때 이는 정규분포 따름. 따라서 MLE의 함수는 추축변량.</p>
<p>cdf는 출신과 무관하게 U(0,1)을 따르므로 이를 추축변량으로 삼는게 가능. 이떄 자주 쓰이는건 알파/2.</p>
<p>감마와 포아송간 변환</p>
<p>유니모달 cdf가 이하의 조건을 지키면 shortest. 9.5.</p>
<p>dog-tired</p>
<p>Bubble Plot
3D Scatter Plot
Star Plot
Chernoff Faces
Parallel Coordinate Plot</p>
<p>1.Q-Q Plot
Shapiro-Wilks Test
Kolmogorov-Smirnov Test
Skewness Test ( )
Kurtosis Test: ( )
Lin and Mudholkar</p>
<p>Scatter Plot
Squared Generalized Distances
Chi-Square Plot (Gamma Plot)</p>
<p>nqplot
contour plot
cqplot</p>
<p>(Python – assumption check)</p>
<!--chapter:end:990101_NoName.Rmd-->
</div>
<div id="abstract-1" class="section level1" number="12">
<h1 number="12"><span class="header-section-number">12</span> ABSTRACT</h1>
<p>Graph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data, Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore, Cluster-GCN allows us to train much deeper GCN without much time and memory overhead, which leads to improved prediction accuracy—using a 5-layer Cluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI dataset, while the previous best result was 98.71 by [16]. Our codes are publicly available at <a href="https://github.com/google-research/google-research/" class="uri">https://github.com/google-research/google-research/</a> tree/master/cluster_gcn</p>
<p>1 INTRODUCTION</p>
<p>Graph convolutional network (GCN) [9] has become increasingly popular in addressing many graph-based applications, including semi-supervised node classification [9], link prediction [17] and recommender systems [15]. Given a graph, GCN uses a graph convolution operation to obtain node embeddings layer by layer—at each layer, the embedding of a node is obtained by gathering the embeddings of its neighbors, followed by one or a few layers of linear transformations and nonlinear activations. The final layer embedding is then used for some end tasks. For instance, in node classification problems, the final layer embedding is passed to a classifier to predict node labels, and thus the parameters of GCN can be trained in an end-to-end manner.</p>
<p>Since the graph convolution operator in GCN needs to propagate embeddings using the interaction between nodes in the graph, this makes training quite challenging. Unlike other neural networks that the training loss can be perfectly decomposed into individual terms on each sample, the loss term in GCN (e.g., classification loss on a single node) depends on a huge number of other nodes, especially when GCN goes deep. Due to the node dependence, GCN’s training is very slow and requires lots of memory – backpropagation needs to store all the embeddings in the computation graph in GPU memory</p>
<p>Previous GCN Training Algorithms: To demonstrate the need of developing a scalable GCN training algorithm, we first discuss the pros and cons of existing approaches, in terms of 1) memory requirement1 , 2) time per epoch2 and 3) convergence speed (loss reduction) per epoch. These three factors are crucial for evaluating a training algorithm. Note that memory requirement directly restricts the scalability of algorithm, and the later two factors combined together will determine the training speed. In the following discussion we denote N to be the number of nodes in the graph, F the embedding dimension, and L the number of layers to analyze classic GCN training algorithm.</p>
<p>• Full-batch gradient descent is proposed in the first GCN paper [9]. To compute the full gradient, it requires storing all the intermediate embeddings, leading to O(N F L) memory requirement, which is not scalable. Furthermore, although the time per epoch is efficient, the convergence of gradient descent is slow since the parameters are updated only once per epoch. [memory: bad; time per epoch: good; convergence: bad]</p>
<p>Mini-batch SGD is proposed in [5]. Since each update is only based on a mini-batch gradient, it can reduce the memory requirement and conduct many updates per epoch, leading to a faster convergence. However, mini-batch SGD introduces a significant computational overhead due to the neighborhood expansion problem—to compute the loss on a single node at layer L, it requires that node’s neighbor nodes’ embeddings at layer L − 1, which again requires their neighbors’ embeddings at layer L − 2 and recursive ones in the downstream layers. This leads to time complexity exponential to the GCN depth. GraphSAGE [5] proposed to use a fixed size of neighborhood samples during back-propagation through layers and FastGCN [1] proposed importance sampling, but the overhead of these methods is still large and will become worse when GCN goes deep. [memory: good; time per epoch: bad; convergence: good]</p>
<p>Mini-batch SGD is proposed in [5]. Since each update is only based on a mini-batch gradient, it can reduce the memory requirement and conduct many updates per epoch, leading to a faster convergence. However, mini-batch SGD introduces a significant computational overhead due to the neighborhood expansion problem—to compute the loss on a single node at layer L, it requires that node’s neighbor nodes’ embeddings at layer L − 1, which again requires their neighbors’ embeddings at layer L − 2 and recursive ones in the downstream layers. This leads to time complexity exponential to the GCN depth. GraphSAGE [5] proposed to use a fixed size of neighborhood samples during back-propagation through layers and FastGCN [1] proposed importance sampling, but the overhead of these methods is still large and will become worse when GCN goes deep. [memory: good; time per epoch: bad; convergence: good]</p>
<p>loiting the graph clustering structure. We find that the efficiency of a mini-batch algorithm can be characterized by the notion of “embedding utilization,” which is proportional to the number of links between nodes in one batch or within-batch links. This finding motivates us to design the batches using graph clustering algorithms that aims to construct partitions of nodes so that there are more graph links between nodes in the same partition than nodes in different partitions. Based on the graph clustering idea, we proposed Cluster-GCN, an algorithm to design the batches based on efficient graph clustering algorithms (e.g., METIS [8]). We take this idea further by proposing a stochastic multi-clustering framework to improve the convergence of Cluster-GCN. Our strategy leads to huge memory and computational benefits. In terms of memory, we only need to store the node embeddings within the current batch, which is O(bF L) with the batch size b. This is significantly better than VR-GCN and full gradient decent, and slightly better than other SGD-based approaches. In terms of computational complexity, our algorithm achieves the same time cost per epoch with gradient descent and is much faster than neighborhood searching approaches. In terms of the convergence speed, our algorithm is competitive with other SGD-based approaches. Finally, our algorithm is simple to implement since we only compute matrix multiplication and no neighborhood sampling is needed. Therefore for Cluster-GCN, we have [memory: good; time per epoch: good; convergence: good].</p>
<p>We conducted comprehensive experiments on several large-scale graph datasets and made the following contributions:</p>
<p>• Cluster-GCN achieves the best memory usage on large-scale graphs, especially on deep GCN. For example, Cluster-GCN uses 5x less memory than VRGCN in a 3-layer GCN model on Amazon2M. Amazon2M is a new graph dataset that we construct to demonstrate the scalablity of the GCN algorithms. This dataset contains a amazon product co-purchase graph with more than 2 millions nodes and 61 millions edges.</p>
<p>• Cluster-GCN achieves a similar training speed with VR-GCN for shallow networks (e.g., 2 layers) but can be faster than VRGCN when the network goes deeper (e.g., 4 layers), since our complexity is linear to the number of layers L while VR-GCN’s complexity is exponential to L.</p>
<p>• Cluster-GCN is able to train a very deep network that has a large embedding size. Although several previous works show that deep GCN does not give better performance, we found that with proper optimization, deeper GCN could help the accuracy. For example, with a 5-layer GCN, we obtain a new benchmark accuracy 99.36 for PPI dataset, comparing with the highest reported one 98.71 by [16].</p>
<p>Implementation of our proposed method is publicly available.3</p>
<ol start="2" style="list-style-type: decimal">
<li>BACKGROUND</li>
</ol>
<p>Suppose we are given a graph G = (V, E,A), which consists of N = |V | vertices and |E | edges such that an edge between any two vertices i and j represents their similarity. The corresponding adjacency matrix A is an N ×N sparse matrix with (i, j) entry equaling to 1 if there is an edge between i and j and 0 otherwise. Also, each node is associated with an F -dimensional feature vector and X ∈ R N ×F denotes the feature matrix for all N nodes. An L-layer GCN [9] consists of L graph convolution layers and each of them constructs embeddings for each node by mixing the embeddings of the node’s neighbors in the graph from the previous layer:</p>
<ol style="list-style-type: decimal">
<li></li>
</ol>
<p>where X (l) ∈ R N ×Fl is the embedding at the l-th layer for all the N nodes and X (0) = X; A ′ is the normalized and regularized adjacency matrix andW (l) ∈ R Fl ×Fl+1 is the feature transformation matrix which will be learnt for the downstream tasks. Note that for simplicity we assume the feature dimensions are the same for all layers (F1 = · · · = FL = F ). The activation function σ(·) is usually set to be the element-wise ReLU. Semi-supervised node classification is a popular application of GCN. When using GCN for this application, the goal is to learn weight matrices in (1) by minimizing the loss function</p>
<ol start="2" style="list-style-type: decimal">
<li></li>
</ol>
<p>where YL contains all the labels for the labeled nodes; z (L) i is the i-th row of Z (L) with the ground-truth label to be yi , indicating the final layer prediction of node i. In practice, a cross-entropy loss is commonly used for node classification in multi-class or multi-label problems.</p>
<ol start="3" style="list-style-type: decimal">
<li>PROPOSED ALGORITHM</li>
</ol>
<p>We first discuss the bottleneck of previous training methods to motivate the proposed algorithm.</p>
<p>In the original paper [9], full gradient descent is used for training GCN, but it suffers from high computational and memory cost. In terms of memory, computing the full gradient of (2) by backpropagation requires storing all the embedding matrices {Z (l) } L l=1 which needs O(N F L) space. In terms of convergence speed, since the model is only updated once per epoch, the training requires more epochs to converge.</p>
<p>It has been shown that mini-batch SGD can improve the training speed and memory requirement of GCN in some recent works [1, 2, 5]. Instead of computing the full gradient, SGD only needs to calculate the gradient based on a mini-batch for each update. In this paper, we use B ⊆ [N] with size b = |B| to denote a batch of node indices, and each SGD step will compute the g</p>
<p>to perform an update. Despite faster convergence in terms of epochs, SGD will introduce another computational overhead on GCN training (as explained in the following), which makes it having much slower per-epoch time compared with full gradient descent.</p>
<p>Why does vanilla mini-batch SGD have slow per-epoch time?: We consider the computation of the gradient associated with one node i : ∇loss(yi , z (L) i ). Clearly, this requires the embedding of node i, which depends on its neighbors’ embeddings in the previous layer. To fetch each node i’s neighbor nodes’ embeddings, we need to further aggregate each neighbor node’s neighbor nodes’ embeddings as well. Suppose a GCN has L + 1 layers and each node has an average degree of d, to get the gradient for node i, we need to aggregate features fromO(d L ) nodes in the graph for one node. That is, we need to fetch information for a node’s hop-k (k = 1, · · · , L) neighbors in the graph to perform one update. Computing each embedding requires O(F 2 ) time due to the multiplication withW (l) , so in average computing the gradient associated with one node requires O(d L F 2 ) time.</p>
<p>Embedding utilization can reflect computational efficiency.: If a batch has more than one node, the time complexity is less straightforward since different nodes can have overlapped hopk neighbors, and the number of embedding computation can be less than the worst case O(bdL ). To reflect the computational efficiency of mini-batch SGD, we define the concept of “embedding utilization” to characterize the computational efficiency. During</p>
<p>the algorithm, if the node i’s embedding at l-th layer z (l) i is computed and is reused u times for the embedding computations at layer l + 1, then we say the embedding utilization of z (l) i is u. For mini-batch SGD with random sampling, u is very small since the graph is usually large and sparse. Assume u is a small constant (almost no overlaps between hop-k neighbors), then mini-batch SGD needs to compute O(bdL ) embeddings per batch, which leads to O(bdL F 2 ) time per update and O(NdL F 2 ) time per epoch.</p>
<p>We illustrate the neighborhood expansion problem in the left panel of Fig. 1. In contrary, full-batch gradient descent has the maximal embedding utilization—each embedding will be reused d (average degree) times in the upper layer. As a consequence, the original full gradient descent [9] only needs to compute O(N L) embeddings per epoch, which means on average only O(L) embedding computation is needed to acquire the gradient of one node.</p>
<p>To make mini-batch SGD work, previous approaches try to restrict the neighborhood expansion size, which however do not improve embedding utilization. GraphSAGE [5] uniformly samples a fixed-size set of neighbors, instead of using a full-neighborhood set. We denote the sample size as r. This leads to O(r L ) embedding computations for each loss term but also makes gradient estimation less accurate. FastGCN [1] proposed an important sampling strategy to improve the gradient estimation. VR-GCN [2] proposed a strategy to store the previous computed embeddings for all the N nodes and L layers and reuse them for unsampled neighbors. Despite the high memory usage for storing all the N L embeddings, we find their strategy very useful and in practice, even for a small r (e.g., 2) can lead to good convergence.</p>
<p>We summarize the time and space complexity in Table 1. Clearly, all the SGD-based algorithms suffer from exponential complexity with respect to the number of layers, and for VR-GCN, even though r can be small, they incur huge space complexity that could go beyond a GPU’s memory capacity. In the following, we introduce our Cluster-GCN algorithm, which achieves the best of two worlds— the same time complexity per epoch with full gradient descent and the same memory complexity with vanilla SGD.</p>
<p>3.1 Vanilla Cluster-GCN</p>
<p>Our Cluster-GCN technique is motivated by the following question: In mini-batch SGD updates, can we design a batch and the corresponding computation subgraph to maximize the embedding utilization? We answer this affirmative by connecting the concept of embedding utilization to a clustering objective.</p>
<p>Consider the case that in each batch we compute the embeddings for a set of nodes B from layer 1 to L. Since the same subgraph AB, B (links within B) is used for each layer of computation, we can then see that embedding utilization is the number of edges within this batch ∥AB, B ∥0. Therefore, to maximize embedding utilization, we should design a batch B to maximize the within-batch edges, by which we connect the efficiency of SGD updates with graph clustering algorithms.</p>
<p>Now we formally introduce Cluster-GCN. For a graph G, we partition its nodes into c groups: V = [V1, · · · Vc ] where Vt consists of the nodes in the t-th partition. Thus we have c subgraphs as</p>
<p>where each Et only consists of the links between nodes in Vt . After reorganizing nodes, the adjacency matrix is partitioned into c 2 submatrices as</p>
<p>where each diagonal block At t is a |Vt | × |Vt | adjacency matrix containing the links within Gt . A¯ is the adjacency matrix for graph G¯; Ast contains the links between two partitions Vs and Vt ; ∆ is the matrix consisting of all off-diagonal blocks of A. Similarly, we can partition the feature matrix X and training labels Y according to the partition [V1, · · · , Vc ] as [X1, · · · ,Xc ] and [Y1, · · · ,Yc ] where Xt and Yt consist of the features and labels for the nodes in Vt respectively.</p>
<p>The benefit of this block-diagonal approximation G¯ is that the objective function of GCN becomes decomposible into different batches (clusters). Let A¯′ denotes the normalized version of A¯, the final embedding matrix becomes</p>
<p>due to the block-diagonal form ofA¯(note thatA¯′ t t is the corresponding diagonal block of A¯′ ). The loss function can also be decomposed into</p>
<p>The Cluster-GCN is then based on the decomposition form in (6) and (7). At each step, we sample a cluster Vt and then conduct SGD to update based on the gradient of LA¯′ t t , and this only requires the sub-graph At t , the Xt , Yt on the current batch and the models {W (l) } L l=1 . The implementation only requires forward and backward propagation of matrix products (one block of (6)) that is much easier to implement than the neighborhood search procedure used in previous SGD-based training methods.</p>
<p>We use graph clustering algorithms to partition the graph. Graph clustering methods such as Metis [8] and Graclus [4] aim to construct the partitions over the vertices in the graph such that withinclusters links are much more than between-cluster links to better capture the clustering and community structure of the graph. These are exactly what we need because: 1) As mentioned before, the embedding utilization is equivalent to the within-cluster links for each batch. Intuitively, each node and its neighbors are usually located in the same cluster, therefore after a few hops, neighborhood nodes with a high chance are still in the same cluster. 2) Since we replace A by its block diagonal approximation A¯ and the error is proportional to between-cluster links ∆, we need to find a partition to minimize number of between-cluster links.</p>
<p>In Figure 1, we illustrate the neighborhood expansion with full graph G and the graph with clustering partition G¯. We can see that cluster-GCN can avoid heavy neighborhood search and focus on the neighbors within each cluster. In Table 2, we show two different node partition strategies: random partition versus clustering partition. We partition the graph into 10 parts by using random partition and METIS. Then use one partition as a batch to perform a SGD update. We can see that with the same number of epochs, using clustering partition can achieve higher accuracy. This shows using graph clustering is important and partitions should not be formed randomly.</p>
<p>Time and space complexity.: Since each node in Vt only links to nodes inside Vt , each node does not need to perform neighborhoods searching outside At t . The computation for each batch will purely be matrix products A¯′ t tX (l) t W (l) and some element-wise operations, so the overall time complexity per batch isO(∥At t ∥0F + bF 2 ). Thus the overall time complexity per epoch becomesO(∥A∥0F+ N F 2 ). In average, each batch only requires computingO(bL) embeddings, which is linear instead of exponential to L. In terms of space complexity, in each batch, we only need to load b samples and store their embeddings on each layer, resulting in O(bLF ) memory for storing embeddings. Therefore our algorithm is also more efficient than all the previous algorithms. Moreover, our algorithm only requires loading a subgraph into GPU memory instead of the full graph (though graph is usually not the memory bottleneck). The detailed time and memory complexity are summarized in Table 1.</p>
<p>3.2 Stochastic Multiple Partitions</p>
<p>Although vanilla Cluster-GCN achieves good computational and memory complexity, there are still two potential issues:</p>
<p>• After the graph is partitioned, some links (the ∆ part in Eq. (4)) are removed. Thus the performance could be affected.
• Graph clustering algorithms tend to bring similar nodes together. Hence the distribution of a cluster could be different from the original data set, leading to a biased estimation of the full gradient while performing SGD updates.</p>
<p>In Figure 2, we demonstrate an example of unbalanced label distribution by using the Reddit data with clusters formed by Metis. We calculate the entropy value of each cluster based on its label distribution. Comparing with random partitioning, we clearly see that entropy of most clusters are smaller, indicating that the label distributions of clusters are biased towards some specific labels. This increases the variance across different batches and may affect the convergence of SGD.</p>
<p>To address the above issues, we propose a stochastic multiple clustering approach to incorporate between-cluster links and reduce variance across batches. We first partition the graph into p clusters V1, · · · , Vp with a relatively large p. When constructing a batch B for an SGD update, instead of considering only one cluster, we randomly choose q clusters, denoted as t1, . . . ,tq and include their nodes {Vt1 ∪ · · · ∪Vtq } into the batch. Furthermore, the links between the chosen clusters,</p>
<p>are added back. In this way, those between-cluster links are reincorporated and the combinations of clusters make the variance across batches smaller. Figure 3 illustrates our algorithm—for each epochs, different combinations of clusters are chosen as a batch. We conduct an experiment on Reddit to demonstrate the effectiveness of the proposed approach. In Figure 4, we can observe that using multiple clusters as one batch could improve the convergence. Our final Cluster-GCN algorithm is presented in Algorithm 1.</p>
<p>3.3 Issues of training deeper GCNs</p>
<p>Previous attempts of training deeper GCNs [9] seem to suggest that adding more layers is not helpful. However, the datasets used in the experiments may be too small to make a proper justification. For example, [9] considered a graph with only a few hundreds of training nodes for which overfitting can be an issue. Moreover, we observe that the optimization of deep GCN models becomes difficult as it may impede the information from the first few layers being passed through. In [9], they adopt a technique similar to residual connections [6] to enable the model to carry the information from a previous layer to a next layer. Specifically, they modify (1) to add the hidden representations of layer l into the next layer.</p>
<p>Here we propose another simple technique to improve the training of deep GCNs. In the original GCN settings, each node aggregates the representation of its neighbors from the previous layer. However, under the setting of deep GCNs, the strategy may not be suitable as it does not take the number of layers into account. Intuitively, neighbors nearby should contribute more than distant nodes. We thus propose a technique to better address this issue. The idea is to amplify the diagonal parts of the adjacency matrix A used in each GCN layer. In this way, we are putting more weights on the representation from the previous layer in the aggregation of each GCN layer. An example is to add an identity to A¯ as follows.</p>
<p>While (9) seems to be reasonable, using the same weight for all the nodes regardless of their numbers of neighbors may not be suitable. Moreover, it may suffer from numerical instability as values can grow exponentially when more layers are used. Hence we propose a modified version of (9) to better maintain the neighborhoods information and numerical ranges. We first add an identity to the original A and perform the normalization, (10)</p>
<p>and then consider</p>
<p>Experimental results of adopting the “diagonal enhancement” techniques are presented in Section 4.3 where we show that this new normalization strategy can help to build deep GCN and achieve SOTA performance.</p>
<p>4 EXPERIMENTS</p>
<p>We evaluate our proposed method for training GCN on two tasks: multi-label and multi-class classification on four public datasets. The statistic of the data sets are shown in Table 3. Note that the Reddit dataset is the largest public dataset we have seen so far for GCN, and the Amazon2M dataset is collected by ourselves and is much larger than Reddit (see more details in Section 4.2). We include the following state-of-the-art GCN training algorithms in our comparisons:</p>
<p>• Cluster-GCN (Our proposed algorithm): the proposed fast GCN training method.
• VRGCN4 [2]: It maintains the historical embedding of all the nodes in the graph and expands to only a few neighbors to speedup training. The number of sampled neighbors is set to be 2 as suggested in [2]5 .
• GraphSAGE6 [5]: It samples a fixed number of neighbors per node. We use the default settings of sampled sizes for each layer (S1 = 25, S2 = 10) in GraphSAGE.</p>
<p>We implement our method in PyTorch [13]. For the other methods, we use all the original papers’ code from their github pages. Since [9] has difficulty to scale to large graphs, we do not compare with it here. Also as shown in [2] that VRGCN is faster than FastGCN, so we do not compare with FastGCN here. For all the methods we use the Adam optimizer with learning rate as 0.01, dropout rate as 20%, weight decay as zero. The mean aggregator proposed by [5] is adopted and the number of hidden units is the same for all methods. Note that techniques such as (11) is not considered here. In each experiment, we consider the same GCN architecture for all methods. For VRGCN and GraphSAGE, we follow the settings provided by the original papers and set the batch sizes as 512. For Cluster-GCN, the number of partitions and clusters per batch for each dataset are listed in Table 4. Note that clustering is seen as a preprocessing step and its running time is not taken into account in training. In Section 6, we show that graph clustering only takes a small portion of preprocessing time. All the experiments are conducted on a machine with a NVIDIA Tesla V100 GPU (16 GB memory), 20-core Intel Xeon CPU (2.20 GHz), and 192 GB of RAM.</p>
<p>4.1 Training Performance for median size datasets</p>
<p>Training Time vs Accuracy: First we compare our proposed method with other methods in terms of training speed. In Figure 6, the x-axis shows the training time in seconds, and y-axis shows the accuracy (F1 score) on the validation sets. We plot the training time versus accuracy for three datasets with 2,3,4 layers of GCN. Since GraphSAGE is slower than VRGCN and our method, the curves for GraphSAGE only appear for PPI and Reddit datasets. We can see that our method is the fastest for both PPI and Reddit datasets for GCNs with different numbers of layers.</p>
<p>For Amazon data, since nodes’ features are not available, an identity matrix is used as the feature matrix X. Under this setting, the shape of parameter matrix W (0) becomes 334863x128. Therefore, the computation is dominated by sparse matrix operations such as AW (0) . Our method is still faster than VRGCN for 3-layer case, but slower for 2-layer and 4-layer ones. The reason may come from the speed of sparse matrix operations from different frameworks. VRGCN is implemented in TensorFlow, while Cluster-GCN is implemented in PyTorch whose sparse tensor support are still in its very early stage. In Table 6, we show the time for TensorFlow and PyTorch to do forward/backward operations on Amazon data, and a simple two-layer network are used for benchmarking both frameworks. We can clearly see that TensorFlow is faster than PyTorch. The difference is more significant when the number of hidden units increases. This may explain why Cluster-GCN has longer training time in Amazon dataset.</p>
<p>Memory usage comparison: For training large-scale GCNs, besides training time, memory usage needed for training is often more important and will directly restrict the scalability. The memory usage includes the memory needed for training the GCN for many epochs. As discussed in Section 3, to speedup training, VRGCN needs to save historical embeddings during training, so it needs much more memory for training than Cluster-GCN. GraphSAGE also has higher memory requirement than Cluster-GCN due to the exponential neighborhood growing problem. In Table 5, we compare our memory usage with VRGCN’s memory usage for GCN with different layers. When increasing the number of layers, Cluster-GCN’s memory usage does not increase a lot. The reason is that when increasing one layer, the extra variable introduced is the weight matrix W (L) , which is relatively small comparing to the sub-graph and node features. While VRGCN needs to save each layer’s history embeddings, and the embeddings are usually dense and will soon dominate the memory usage. We can see from Table 5 that Cluster-GCN is much more memory efficient than VRGCN. For instance, on Reddit data to train a 4-layer GCN with hidden dimension to be 512, VRGCN needs 2064MB memory, while Cluster-GCN only uses 308MB memory.</p>
<p>4.2 Experimental results on Amazon2M</p>
<p>A new GCN dataset: Amazon2M. By far the largest public data for testing GCN is Reddit dataset with the statistics shown in Table 3, which contains about 200K nodes. As shown in Figure 6 GCN training on this data can be finished within a few hundreds seconds. To test the scalability of GCN training algorithms, we constructed a much larger graph with over 2 millions of nodes and 61 million edges based on Amazon co-purchasing networks [11, 12]. The raw co-purchase data is from Amazon-3M7 . In the graph, each node is a product, and the graph link represents whether two products are purchased together. Each node feature is generated by extracting bag-of-word features from the product descriptions followed by Principal Component Analysis [7] to reduce the dimension to be 100. In addition, we use the top-level categories as the labels for that product/node (see Table 7 for the most common categories). The detailed statistics of the data set are listed in Table 3.</p>
<p>In Table 8, we compare with VRGCN for GCNs with a different number of layers in terms of training time, memory usage, and test accuracy (F1 score). As can be seen from the table that 1) VRGCN is faster than Cluster-GCN with 2-layer GCN but slower than ClusterGCN when increasing one layer while achieving similar accuracy. 2) In terms of memory usage, VRGCN is using much more memory than Cluster-GCN (5 times more for 3-layer case), and it is running out of memory when training 4-layer GCN, while Cluster-GCN does not need much additional memory when increasing the number of layers, and achieves the best accuracy for this data when training a 4-layer GCN.</p>
<p>4.3 Training Deeper GCN</p>
<p>In this section we consider GCNs with more layers. We first show the timing comparisons of Cluster-GCN and VRGCN in Table 9. PPI is used for benchmarking and we run 200 epochs for both methods. We observe that the running time of VRGCN grows exponentially because of its expensive neighborhood finding, while the running time of Cluster-GCN only grows linearly.</p>
<p>Next we investigate whether using deeper GCNs obtains better accuracy. In Section 4.3, we discuss different strategies of modifying the adjacency matrix A to facilitate the training of deep GCNs. We apply the diagonal enhancement techniques to deep GCNs and run experiments on PPI. Results are shown in Table 11. For the case of 2 to 5 layers, the accuracy of all methods increases with more layers added, suggesting that deeper GCNs may be useful. However, when 7 or 8 GCN layers are used, the first three methods fail to converge within 200 epochs and get a dramatic loss of accuracy. A possible reason is that the optimization for deeper GCNs becomes more difficult. We show a detailed convergence of a 8-layer GCN in Figure 5. With the proposed diagonal enhancement technique (11), the convergence can be improved significantly and similar accuracy can be achieved.</p>
<p>State-of-the-art results by training deeper GCNs.: With the design of Cluster-GCN and the proposed normalization approach, we now have the ability for training much deeper GCNs to achieve better accuracy (F1 score). We compare the testing accuracy with other existing methods in Table 10. For PPI, Cluster-GCN can achieve the state-of-art result by training a 5-layer GCN with 2048 hidden units. For Reddit, a 4-layer GCN with 128 hidden units is used.</p>
<p>5 CONCLUSION</p>
<p>We present ClusterGCN, a new GCN training algorithm that is fast and memory efficient. Experimental results show that this method can train very deep GCN on large-scale graph, for instance on a graph with over 2 million nodes, the training time is less than an hour using around 2G memory and achieves accuracy of 90.41 (F1 score). Using the proposed approach, we are able to successfully train much deeper GCNs, which achieve state-of-the-art test F1 score on PPI and Reddit datasets.</p>
<p>Acknowledgement: CJH acknowledges the support of NSF via IIS-1719097, Intel faculty award, Google Cloud and Nvidia.</p>
<!--chapter:end:990102_Abs.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-xie2015" class="csl-entry">
Xie, Yihui. 2015. <em>Dynamic Documents with <span>R</span> and Knitr</em>. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. <a href="http://yihui.org/knitr/">http://yihui.org/knitr/</a>.
</div>
<div id="ref-R-bookdown" class="csl-entry">
———. 2021. <em>Bookdown: Authoring Books and Technical Documents with r Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>random increment<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The ordering of updates made to the components of X in the basic Gibbs sampler can change from one cycle to the next. Random ordering each cycle can be effective when parameters are highly correlated. In practice without specialized knowledge for a particular model, we recommend trying both deterministic and random scan Gibbs sampling when parameters are highly correlated from one iterations to the next.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Tropp, Joel A. ”User-friendly tail bounds for sums of random matrices.” Foundations of computational mathematics 12.4 (2012): 389-434<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><span class="math inline">\(V_{d \times d} V&#39; s= V&#39;V = I\)</span><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>diagonal Matrix <span class="math inline">\(\lambda_{d \times d}\)</span>, entries with ev <span class="math inline">\(\lambda_1 \ge \cdots \ge \lambda_d \ge 0\)</span><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>vector 안에 들어있는 non-zero elements 의 갯수가 <span class="math inline">\(k\)</span><a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>이때 <span class="math inline">\(0^0 = 0\)</span>이라고 정의<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p><span class="math inline">\(\mathbb S^{r-1} =\{x\in\mathbb{R}^{r}: \|x\|_2 = 1\}\)</span><a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>일반적인 counting process 에 대해, <span class="math inline">\(N(0)\)</span> 이며 <span class="math inline">\(\forall t \in \mathcal T:N(t)&lt;0\)</span>.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>증명에 <span class="math inline">\(E[X(t)|\mathcal{F}_{s}]=X(s)\mathrm{~for~}s\lt t\)</span> 가 사용되었다. 이는 위에서 보였다.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>This is a footnote.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
